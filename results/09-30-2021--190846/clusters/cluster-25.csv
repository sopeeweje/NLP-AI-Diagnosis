text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Advancing artificial intelligence algorithms for chest x-ray screening and visualization This year we updated our CXR screening algorithms to include Convolutional Neural Network-based (CNN) Deep Learning models that resulted in improvements in classification performance. We studied several pre-trained off-the-shelf deep learning frameworks and compared their performance against a custom designed CNN architecture. The outcomes were visualized with a novel visualization algorithm; and then field-tested on a CXR screening system deployed in rural parts of western Kenya through collaboration with Indiana University, AMPATH (a Kenyan NGO); and an expert radiologist from the University of California, San Francisco.  We expanded our interest in CXR disease classification to include pneumonia in both adults and children, and also evaluated ability of artificial intelligence algorithms in detecting drug-resistant variants of TB in chest x-rays. There is a need for further work in separating pulmonary opacity pneumonia from TB, particularly in HIV-positive children. Further, we showed that it is possible to separate drug resistant from non-drug resistant TB in adults using artificial intelligence, albeit with a lower confidence. We also studied the ability of deep learning algorithm in detecting and staging the severity of cardiomegaly using CXRs.  We also studied the use of generative adversarial networks (GANs) in a pilot study to evaluate their ability to produce deepfake CXR images to increase the number of training images with a goal to improve deep learning-algorithm based classification outcomes. We found the results to be mediocre toward meeting this goal. Further study is needed on the statistical variation needed in image datasets to improve artificial intelligence algorithm outcomes. Finally, we studied the use of adversarial networks in automatically generating radiology reports. n/a",Advancing artificial intelligence algorithms for chest x-ray screening and visualization,10016025,ZIALM010004,"['AIDS population', 'AIDS/HIV problem', 'Adult', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'California', 'Cardiomegaly', 'Child', 'Classification', 'Collaborations', 'Custom', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Drug resistance', 'Goals', 'HIV Seropositivity', 'HIV/TB', 'Image', 'Image Analysis', 'Imagery', 'Indiana', 'Kenya', 'Lung', 'Modeling', 'Network-based', 'Outcome', 'Performance', 'Pilot Projects', 'Pneumonia', 'Radiology Specialty', 'Reporting', 'Rural', 'San Francisco', 'Severities', 'Staging', 'System', 'Thoracic Radiography', 'Training', 'Tuberculosis', 'Universities', 'Update', 'Variant', 'Work', 'base', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'disease classification', 'field study', 'improved', 'interest', 'machine learning algorithm', 'meetings', 'non-drug', 'novel', 'radiologist', 'screening']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2019,533106,-0.002559286549223445
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,-0.0016517571768203075
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,9976740,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Heterogeneity', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2019,299197,-0.0008068280014990528
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,9819865,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Fall injury', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'artificial neural network', 'base', 'clinical decision-making', 'comparative effectiveness', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'effectiveness research', 'experience', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'secondary outcome', 'skills', 'standard of care', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2019,186183,0.008548418236402195
"Opthalmic Image analysis and machine learning for eye disease detection Glaucoma: In a collaboration with the National Eye Institute (NEI), we applied several Convolutional Neural Network (CNN) Deep Learning (DL) models to detect regions of interest (ROI) on ophthalmic fundus images to segment optic disc and cup. We used three different DL models: modified LeNet, Faster Region-based CNN (Faster RCNN), and RetinaNet. For the MESSIDOR dataset containing 1,200 fundus images, the modified LeNet showed 0.9950 accuracy in ROI detection, but needed long processing time. Faster RCNN improved the processing time (about 1.5 second per image) and resulted in an accuracy of 0.9900. RetinaNet showed the best performance with 1.0000 accuracy and the best processing time (0.2 second per image). Optic disc and cup segmentation from the ROI in fundus images is the second step. We used Fully Convolutional Network (FCN) models. In the case of optic disc, we trained two different FCNs: FCN2 (FCN for two classes) and FCNM (FCN for multi classes). The RIGA dataset, containing 750 fundus images with annotations by six ophthalmologists from three different datasets (MESSIDOR, Bin Rushed, and Megrabi), was used for the test. The results showed that FCN2 had the best performance with 0.9430 Jaccard Index, 0.9702 F-measure, and 0.9889 Accuracy. In the case of cup, we used the two FCNs (FCN2 and FCNM) and two different ROIs (original ROI and ROI masked by optic disc (masked ROI)) for the test. The FCN2 using the masked ROI showed the best performance with 0.8037 Jaccard Index, 0.8873 F-measure, and 0.9882 Accuracy. Our results showed over 1% better performance in optic disc and 2% better performance in cup than other existing methods. The next step will be to apply these techniques and estimate optic disc and cup ratio on the RIGA dataset and AREDS dataset from NEI.  AMD: NEIs AREDS dataset contains fundus images of 4,757 patients with AMD and no AMD. NEI categorizes the fundus images into twelve AMD severity levels. We developed CNN-based techniques to classify fundus images into the twelve severity levels. 84,448 images were collected for training and 13,181 images were for testing from the dataset. Two CNN models, VGG16 and ResNet101, were used for training. The test results showed that VGG16 had 0.6267 accuracy and ResNet101 had 0.6628 accuracy. We plan to use several different CNN models and different loss functions to improve the accuracy.  Uveitis: We also experimented with FCN models to segment leakage and blood vessel areas in fluorescein angiography (FA) images. Since uveitis is a rare disease, there were not many images to use. We received 90 images from NEI, among which 50 were annotated. Five-fold cross-validation, image cropping, and image augmentation techniques were used for the test. We trained two FCNs to segment leakage and blood vessel in the FA images. In the case of leakage, the FCN showed 0.3157 Jaccard index, 0.6241 sensitivity, 0.9669 specificity, and 0.9611 accuracy. In the case of blood vessel, the FCN showed 0.4022 Jaccard index, 0.7168 sensitivity, 0.9824 specificity, and 0.9766 accuracy. The next step is to improve segmentation accuracy by using more FA images and different FCN models. n/a",Opthalmic Image analysis and machine learning for eye disease detection,10016031,ZIALM010015,"['Affect', 'Age related macular degeneration', 'Area', 'Artificial Intelligence', 'Blindness', 'Blood Vessels', 'Caliber', 'Collaborations', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drusen', 'Early Diagnosis', 'Early treatment', 'Exhibits', 'Extravasation', 'Exudative age-related macular degeneration', 'Eye', 'Eye diseases', 'Family', 'Fluorescein Angiography', 'Glaucoma', 'Image', 'Image Analysis', 'Inflammation', 'Intraobserver Variability', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Fibers', 'Network-based', 'Neural Network Simulation', 'Ophthalmologist', 'Optic Disk', 'Optic Nerve', 'Patients', 'Performance', 'Pigments', 'Rare Diseases', 'Retinal', 'Retinal Neovascularization', 'Severities', 'Specificity', 'Techniques', 'Test Result', 'Testing', 'Time', 'Tissues', 'Training', 'Uveitis', 'Validation', 'Variant', 'base', 'convolutional neural network', 'deep learning', 'deep neural network', 'disease diagnosis', 'experimental study', 'fundus imaging', 'geographic atrophy', 'improved', 'indexing', 'interest', 'loss of function', 'macula', 'network models', 'optic cup', 'pressure']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2019,296170,0.025493798520262692
"Machine Learning for Detecting Malaria and Other Infectious Diseases Data scientists at the Communications Engineering Branch (CEB) of the Lister Hill National Center for Biomedical Communications (LHC) at the National Library of Medicine (NLM) have developed new intelligent methods to screen for infectious diseases, such as malaria and tuberculosis. These methods take advantage of the latest results in machine learning, which is a subfield of artificial intelligence. Particularly, scientists used deep learning methods to detect and count infected red blood cells and parasites. Deep learning is a family of machine learning methods based on artificial neural networks, which are inspired by biological neural networks of the central nervous system of animals. Scientists at CEB advanced and adapted these methods to take account of the specific features of blood smear images, in particular the relatively small size of parasites. Other challenges that scientists had to overcome include variations of color, lighting, and similar variations introduced by smear preparation and subsequent image capture.  The data scientists at CEB developed deep learning networks for both thin and thick smears, which are the two types of bloods smears used by experts in the field to diagnose malaria. The networks can detect blood cells in thin smears and classify them into infected and uninfected cells. They can also detect parasites in thick smears, which is a new feature developed this fiscal year, thus covering the full screening spectrum in practice.  Scientists laid special focus on executing trained deep learning networks on Android smartphones. This required research into designing new and smaller network structures that can cope with the lower hardware specifications of smartphones in terms of processing units and memory. Scientists were able to develop and execute smaller networks than can provide the same performance and that can run in reasonable time on smartphones. They were able to do so for thin and thick smears. The developed system is the first smartphone application for malaria screening that can process both thin and thick smears using deep learning. A better implementation of the software, exploiting parallelization, and modifications to the user interface improved the runtime and general usability of the smartphone application. This also includes a cloud-based image upload function for uploading images to a central server for further processing or archiving, and language support for multiple languages.  To train the mobile smartphone application for thick smears, scientists used an annotated image set from 200 patients, which they acquired the year before at a hospital in Chittagong, Bangladesh. This set includes about 3000 thick smear images with 85,000 parasites and 60,000 white blood cells, all manually annotated. This data was acquired for Plasmodium falciparum, which is the deadliest parasite species causing malaria in humans. In this fiscal year, similar data has been acquired for thin smears featuring Plasmodium vivax, which is another common parasite species causing malaria. In addition, data acquisition for Plasmodium vivax in thick smears has started. Once this data acquisition is completed, it will allow training of deep learning networks for detecting and discriminating parasite species.  CEB has made the software publicly available in the Google Play Store (NLM MalariaScreener), where researchers can download it for testing or contributing training data. Scientists at CEB have been actively collaborating with several sites in Thailand, Bangladesh, Kenya, Uganda, Pakistan, Thailand, and Mali for field-testing the software with blood smear images from different labs. n/a",Machine Learning for Detecting Malaria and Other Infectious Diseases,10016026,ZIALM010006,"['Africa South of the Sahara', 'Android', 'Animals', 'Archives', 'Artificial Intelligence', 'Asia', 'Bangladesh', 'Biological Neural Networks', 'Bite', 'Blood', 'Blood Cells', 'Cause of Death', 'Cells', 'Cellular Phone', 'Cessation of life', 'Color', 'Communicable Diseases', 'Communication', 'Computer software', 'Country', 'Culicidae', 'Data', 'Data Science', 'Data Scientist', 'Developing Countries', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Drug resistance', 'Engineering', 'Erythrocytes', 'Family', 'Field Workers', 'Film', 'Goals', 'Hospitals', 'Human', 'Image', 'Immigrant', 'Infectious Lung Disorder', 'Intelligence', 'Kenya', 'Language', 'Learning', 'Leukocytes', 'Light Microscope', 'Lighting', 'Machine Learning', 'Malaria', 'Mali', 'Manuals', 'Memory', 'Methods', 'Microscope', 'Modernization', 'Modification', 'Neuraxis', 'Pakistan', 'Parasites', 'Patients', 'Performance', 'Persons', 'Plasmodium falciparum', 'Plasmodium vivax', 'Play', 'Preparation', 'Process', 'Public Health', 'Research', 'Research Personnel', 'Role', 'Running', 'Scientist', 'Severity of illness', 'Site', 'Standardization', 'Structure', 'System', 'Testing', 'Thailand', 'Thick', 'Thinness', 'Time', 'Training', 'Tuberculosis', 'Uganda', 'United States', 'United States National Library of Medicine', 'Variant', 'artificial neural network', 'base', 'cloud based', 'data acquisition', 'deep learning', 'design', 'digital imaging', 'disorder control', 'drug testing', 'experience', 'field study', 'fighting', 'global health', 'improved', 'learning network', 'learning strategy', 'malaria transmission', 'novel vaccines', 'parallelization', 'portability', 'resistant strain', 'screening', 'smartphone Application', 'success', 'usability', 'vector control']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2019,888509,-0.12419432868475624
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9748523,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,195128,0.01549491960747274
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9784818,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation Dose Unit', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'neural network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2019,78500,0.025445939610790676
"Advancing artificial intelligence algorithms for cervical cancer diagnostics  We validated and published a landmark paper 1, 2 describing a breakthrough two-stage Convolutional Neural Network (CNN) based deep learning algorithm trained, validated, and tested on cervical images selected from a dataset of 9,450-woman, population-based longitudinal cohort (ages 18-92) acquired by the NCI in Guanacaste, Costa Rica. The cohort provided cervical training/validation images and clinical endpoints. The algorithm, called automated visual evaluation (AVE) of the acetowhitened cervix, generates a severity score (0 to 1) that indicates the likelihood that the cervix in the image is precancerous. Applied to enrollment cervical images, it outperformed standard screening tests (clinician interpretation of the same cervical images, Pap smears, and even HPV testing) in predicting cumulative risk of precancer/cancer. AVE provides sensitive screening with minimal clinical training or cost. Overtreatment still must be addressed by further improvements, unless lower sensitivity is accepted.   The AVE algorithm depends on good quality images where quality is a combination of optimal lighting, adequate framing of the cervix, absent any occluding artefacts (e.g., swab, speculum, unrelated anatomy, etc.), and sharp focus. Of these, sharp focus is relatively easily measurable and subsumes lighting and cervix framing. We developed two novel deep learning algorithms  one that detects if a cervix is in focus 3 and the other that uses adversarial deep learning networks to deblur out of focus images 4. Both algorithms can be further engineered to be a part of image acquisition phase that would provide acceptable quality images to the AVE algorithm.  Cytology / Pap smear analysis is the non-inferiority test for AVE. We have started work toward creating a novel deep learning algorithm-based cytology image classifier for whole-slide images. We worked on a small deidentified dataset of liquid pap-smear slides from Beckton-Dickinson that came from a joint study they participated in with NCI. Our deep learning algorithm operated on cytologist marked high-sensitive regions on the whole slide image; i.e. those that contained high likelihood of abnormal cells, to detect and segment nuclei and classify them as one of several abnormal categories. For this we transferred knowledge from another cervical cytology slide dataset which only provided truth as individual segmented cells.   Other cervicographic images, we also continued efforts toward furthering prior work in deep learning-based classification of histopathology images. We continue to develop a novel algorithm that localizes epithelial region of interest on the image to which prior work in image classification can then be applied. In prior efforts, the region of interest was manually marked. n/a",Advancing artificial intelligence algorithms for cervical cancer diagnostics ,10016030,ZIALM010014,"['Abnormal Cell', 'Acetic Acids', 'Address', 'Age', 'Algorithms', 'Anatomy', 'Artificial Intelligence', 'Biopsy', 'Cancer Diagnostics', 'Cancer Etiology', 'Categories', 'Cell Nucleus', 'Cells', 'Cervical', 'Cervix Uteri', 'Classification', 'Clinical', 'Colposcopes', 'Costa Rica', 'Cytology', 'Cytology Histology', 'Data Set', 'Engineering', 'Enrollment', 'Epithelial', 'Etiology', 'Goals', 'Health', 'Histopathology', 'Human Papilloma Virus Vaccination', 'Human Papillomavirus', 'Image', 'Image Analysis', 'Individual', 'International', 'Joints', 'Knowledge', 'Lesion', 'Lighting', 'Liquid substance', 'Longitudinal cohort', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measurable', 'Methods', 'Morphologic artifacts', 'Pap smear', 'Paper', 'Phase', 'Premalignant', 'Prevention', 'Publishing', 'Resources', 'Risk', 'Severities', 'Slide', 'Speculums', 'Swab', 'Testing', 'Tissue imaging', 'Training', 'Validation', 'Visual', 'Woman', 'Work', 'authority', 'automated visual evaluation', 'base', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'handheld mobile device', 'interest', 'learning network', 'mortality', 'novel', 'overtreatment', 'population based', 'prevent', 'screening', 'screening program', 'whole slide imaging']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2019,562723,0.044232999107638706
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9783816,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,438449,0.0466276648488818
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9752639,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation Dose Unit', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'neural network', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2019,196250,0.044455182151265996
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9751222,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,373460,-0.009299165570238523
"Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment PROJECT SUMMARY We propose a study of radiomic texture analysis in terms of robustness assessment and classification utility. We will introduce novel robustness metrics geared towards assessment of radiomic features in comparison across two image conditions, and apply these metrics to study feature robustness across imaging parameters and patient biology. In addressing the utility of radiomic features in cancer risk assessment, we will identify and evaluate texture signatures from mammography and tomosynthesis datasets. The field of radiomics is evolving fast, and quantitative texture analysis is being applied to a growing number of applications in medical imaging. By performing a thorough investigation of the robustness of these radiomic features to dataset heterogeneities we aim to identify the strengths and weaknesses of commonly used features to guide their implementations on future applications.  Two clinical tasks will be studied under the proposed research: 1) risk assessment and cancer prediction and 2) malignancy evaluation. Multiple modalities including tomosynthesis, mammography and MRI will be involved in studies geared towards addressing these clinical questions. An evaluation of the robustness of commonly employed radiomic features will help guide the field of medical texture analysis and contribute to meaningful conclusions in future studies throughout the field of quantitative image analysis. The first aim of the proposed research involves the proposition and evaluation of novel robustness metrics for investigations lacking a classification task. The second aim will extend the study of radiomics to investigate the utility of robust features in classification tasks and identification of texture signatures relate to biomedical characteristics. The third aim will build upon the two previous aims and culminate in the application of cutting-edge technologies in machine learning and deep learning in further promoting image processing in the field of medical physics. PROJECT NARRATIVE The goal of the proposed research is to evaluate and improve the application of radiomic texture features in cancer risk assessment. We will accomplish this by evaluating the robustness of various radiomic metrics, testing the classification utility of texture features in clinical tasks, and extending current classification methods to include cutting-edge developments in machine learning technology. Careful preliminary studies have demonstrated methods for selection of robust texture features and improvement in classification tasks by emphasizing feature robustness in feature selection methodology and we therefore believe that a meticulous evaluation of the impact of imaging parameters on feature calculations will lead to overall improvement of computer-aided diagnosis and clinical translation to progress in cancer screening protocols.",Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment,9683697,F31CA228247,"['Address', 'Benign', 'Biological', 'Biology', 'Breast', 'Breast Cancer Risk Factor', 'Characteristics', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Eligibility Determination', 'Emerging Technologies', 'Evaluation', 'Family', 'Future', 'Goals', 'Heterogeneity', 'Image', 'Image Analysis', 'Impact evaluation', 'Incidence', 'Intuition', 'Investigation', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Maps', 'Mathematics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Output', 'Patients', 'Pattern', 'Performance', 'Physics', 'Protocols documentation', 'Psychological Transfer', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Screening for cancer', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Variant', 'Work', 'base', 'breast imaging', 'cancer risk', 'clinical translation', 'deep learning', 'expectation', 'high risk', 'image processing', 'image registration', 'imaging modality', 'imaging system', 'improved', 'innovation', 'molecular subtypes', 'multimodality', 'novel', 'outcome forecast', 'patient population', 'quantitative imaging', 'radiomics', 'response', 'tomosynthesis', 'tumor']",NCI,UNIVERSITY OF CHICAGO,F31,2019,24304,-0.014771959331329599
"Generalizing Deep Learning Reconstruction for Free-Breathing and Quantitative MRI Project Summary/Abstract The goal of this project is to increase the precision and resolution of quantitative magnetic resonance imaging (MRI). Quantitative information such as tissue relaxation parameters (e.g., T1 and T2) measure tissue function and indicate disease-related changes in the heart, liver, brain, and other organs. For instance, T1 changes can provide evidence of diffuse fibrosis in the myocardium that can signal heart disease. Quantitative maps also are reproducible, directly comparable longitudinally and across subjects, and less affected by the properties of the scanner used, when compared versus common weighted (non-quantitative) clinical imaging. But, quantitative imaging involves more complicated and time-consuming pulse sequences. To accomplish this goal, this project will develop new machine learning algorithms for high-quality parameter mapping from free-breathing data. The first aim of this project will increase parameter map resolution achievable from highly accelerated, noisy data. The proposed method will integrate existing deep cascade network-based image reconstructions with convolutional network-based blocks for super-resolution and parameter map estimation. Preliminary studies suggest these new blocks improve sharpness and mitigate artifacts in the reconstructed parameter maps. The next aim will improve the training precision of such artificial neural networks to account for the significant per-voxel nonlinear fit variability in quantitative MRI. The proposed method will reweight the loss function used for calibrating these networks by the goodness-of-fit (coefficient of determination) of the reference maps obtained from fully sampled training data. Preliminary results demonstrate that quality-aware reweighting significantly improves reconstructed image quality when working with noisy training data. Experiments will evaluate the precision of both of these innovations against existing deep-learning-based reconstructions on T1 maps obtained from pre- and post-contrast cardiac images of volunteer patients. The final aim will address motion during the acquisition by estimating and tracking nonrigid motion in the data consistency stages of the deep cascade artificial neural network architecture. Two methods are proposed: deformable motion estimation already demonstrated on compressive model-based image reconstructions, and a new “re-blurring” convolutional neural network that automatically introduces artifacts into a “clean” image to match the motion-corrupted data. Both of these methods enforce consistency between motion-affected data and a motion-free image during the reconstruction. Both methods will be validated on both cardiac and abdominal images for motion artifacts and reconstruction quality against breath-held parameter mapping acquisitions. Project Narrative Quantitative magnetic resonance imaging noninvasively measures physical properties of tissue connected to cardiovascular disease and many other conditions. Novel machine learning methods for processing data to produce higher quality maps will facilitate earlier and more accurate treatment of these diseases. This project will facilitate rapid quantitative imaging with freely breathing subjects.",Generalizing Deep Learning Reconstruction for Free-Breathing and Quantitative MRI,10007241,R56EB028254,"['Abdomen', 'Address', 'Adoption', 'Affect', 'Algorithms', 'Awareness', 'Balance training', 'Brain', 'Breathing', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Consumption', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Disease', 'Fibrosis', 'Financial compensation', 'Goals', 'Heart', 'Heart Diseases', 'Heart failure', 'Image', 'Infiltration', 'Literature', 'Liver', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myocardium', 'Network-based', 'Noise', 'Non-linear Models', 'Organ', 'Patients', 'Physiologic pulse', 'Process', 'Property', 'Protocols documentation', 'Relaxation', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Signal Transduction', 'Techniques', 'Time', 'Tissues', 'Training', 'Weight', 'artificial neural network', 'base', 'clinical imaging', 'clinically relevant', 'computerized data processing', 'contrast imaging', 'convolutional neural network', 'coronary fibrosis', 'data space', 'deep learning', 'design', 'experimental study', 'heart imaging', 'image reconstruction', 'improved', 'innovation', 'learning strategy', 'loss of function', 'machine learning algorithm', 'motion sensitivity', 'multitask', 'neural network architecture', 'non-invasive imaging', 'novel', 'physical property', 'quantitative imaging', 'reconstruction', 'volunteer']",NIBIB,UNIVERSITY OF VIRGINIA,R56,2019,347527,0.013670444829441254
"Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis,9742424,R00AR070902,"['3-Dimensional', 'Algorithms', 'Atlases', 'Award', 'Big Data', 'Big Data Methods', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imagery', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Differences', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'deep learning', 'design', 'epidemiology study', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'multidimensional data', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R00,2019,249000,-0.04463332201629907
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting confidence in scientific inquiry. Identification of biomarkers and cellular targets following microscopy requires manual analysis of biomedical images, which is time intensive, difficult, and prone to bias and errors. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce error in clinical diagnostics. We recently developed a “beta” software package designed to improve automation and standardization of image analysis, called “PIPSQUEAK” (Perineuronal net Intensity Program for the Standardization and Quantification of Extracellular matrix Analysis Kit). Since its publication in 2016, PIPSQUEAK beta has amassed approximately 1,300 users worldwide who use it to quantify the intensity and number of perineuronal nets and other neural markers in the brain. This technology significantly increases data reliability between image raters and decreases the time required for analysis by more than 100-fold. However, PIPSQUEAK beta currently uses target detection algorithms that require high-contrast images to automatically identify neurons as clusters of bright pixels on dark backgrounds. A significant current limitation to PIPSQUEAK beta, and other available imaging programs, is that detection of biomarkers can be difficult unless image conditions are ideal. Suboptimal conditions, like high background staining, off-target structures, overlapping or clustered biomarkers, and atypical morphologies, can lead to artifacts and consequently to inaccurate results and erroneous conclusions. Here, we propose to develop a user-friendly artificial intelligence (AI) platform for the automated detection of targeted biomarkers in digital microscopy that reduces this error by learning to distinguish between true cellular biomarkers and artifacts. We propose to integrate AI capabilities into our PIPSQUEAK technology to produce an adaptive, high-throughput, biomedical image analysis platform that quickly and accurately identifies biomarker targets from bench to bedside. A key advantage is that this AI program will be user friendly and available online, making it highly accessible to basic researchers and to technicians and clinicians identifying human pathologies. Thus, successful development of our AI program has a high translational potential. The goal of this proposal is 1) to develop and validate a machine learning model that is capable of detecting common histological marker morphologies in digital microscopy, and 2) to test the feasibility of adapting our AI platform to new biomarker datasets with minimal additional supervised training. Our end goal is to advance the reliability and speed of research findings and clinical diagnoses by making this technology widely available to researchers and clinicians. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduces bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments. Application of artificial intelligence for the detection of disease or cellular targets has the potential to improve the reliability of research findings and clinical diagnoses, while reducing waste, time, and expense. We propose a method to improve the quality of biomedical research reproducibility and clinical diagnoses by developing a high-throughput, adaptive artificial intelligence platform for automated analysis of cellular and disease targets in digital microscopy images, which will be made available to scientists and clinicians as a user-friendly analysis platform.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,9845994,R43GM134789,"['Abbreviations', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Biological Markers', 'Biomedical Research', 'Brain', 'Cell Line', 'Cell model', 'Cellular Morphology', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Coupled', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Evidence Based Medicine', 'Extracellular Matrix', 'FOS gene', 'Fluorescence', 'Future', 'Glial Fibrillary Acidic Protein', 'Goals', 'Histologic', 'Histology', 'Human Pathology', 'Image', 'Image Analysis', 'Immunoassay', 'Immunohistochemistry', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Neurons', 'Nuclear', 'Pathologist', 'Performance', 'Procedures', 'Psychological Transfer', 'Publications', 'Rattus', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Shapes', 'Speed', 'Stains', 'Standardization', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Banks', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Zebrafish', 'automated analysis', 'base', 'bench to bedside', 'bioimaging', 'biomarker identification', 'cell type', 'cellular targeting', 'clinical Diagnosis', 'clinical diagnostics', 'contrast imaging', 'design', 'digital', 'digital imaging', 'extracellular', 'histological specimens', 'histological stains', 'imaging biomarker', 'imaging program', 'improved', 'interest', 'lateral line', 'microscopic imaging', 'predictive marker', 'programs', 'relating to nervous system', 'software as a service', 'statistics', 'targeted biomarker', 'tool', 'user-friendly', 'wasting']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R43,2019,224915,0.019684419324248373
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning. !",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,9776655,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis\xa0', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2019,185379,0.021928632926054455
"Imaging cellular assemblies with three-dimensional electron microscopy Focused ion beam scanning electron microscopy (FIB-SEM), also referred to as ion abrasion scanning electron microscopy (IA-SEM), is a technology that we have been developing in the lab to image cells and tissues in 3D at high resolution. Imaging cells and tissues by FIB-SEM at high resolution offers many exciting possibilities for biological research; however, at high resolution, this technology produces enormous amounts of data, and is extremely slow. Moreover, one of the most promising aspects of this technology is the ability to quantitatively analyze ultrastructural morphology. Thus in addition to using FIB-SEM to study 3D architecture in cells and tissues, we have also been developing imaging methods and techniques that align the technology with the goal of automated, quantitative analysis of 3D structure at electron microscopy resolutions. As we make progress on a variety of projects related to cancer and aging, we have also been developing methods to process FIB-SEM data more effectively. In a collaboration with Dr. Amitabh Varshney's team at the University of Maryland, we published a paper in January 2-18 in IEEE Transactions in Visualization and Computer Graphics that reports the use of deep learning methods for 3D image segmentation. Designing volume visualizations showing various structures of interest is critical to the exploratory analysis of volumetric data. The last few years have witnessed dramatic advances in the use of convolutional neural networks for identification of objects in large image collections. Whereas such machine learning methods have shown superior performance in a number of applications, their direct use in volume visualization has not yet been explored. In the IEEE paper, we presented a deep-learning-assisted volume visualization to depict complex structures, which are otherwise challenging for conventional approaches. A significant challenge in designing volume visualizations based on the high-dimensional deep features lies in efficiently handling the immense amount of information that deep-learning methods provide. In this paper, we present a new technique that uses spectral methods to facilitate user interactions with high-dimensional features. We also present a new deep-learning-assisted technique for hierarchically exploring a volumetric dataset. We validated our approach with two volumes generated using electron microscopy and one with magnetic resonance imaging. n/a",Imaging cellular assemblies with three-dimensional electron microscopy,10014335,ZIABC010278,"['3-Dimensional', 'Aging', 'Architecture', 'Biology', 'Cells', 'Collaborations', 'Collection', 'Complex', 'Computer Graphics', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electron Beam', 'Electron Microscopy', 'Eukaryotic Cell', 'Generations', 'Goals', 'Image', 'Imagery', 'Imaging Techniques', 'Ions', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Maryland', 'Methods', 'Microscopy', 'Morphology', 'Optics', 'Paper', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Scanning', 'Scanning Electron Microscopy', 'Series', 'Site', 'Specimen', 'Structure', 'Surface', 'Techniques', 'Technology', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Transact', 'Universities', 'Use of New Techniques', 'base', 'biological research', 'cellular imaging', 'clinical application', 'convolutional neural network', 'deep learning', 'design', 'high dimensionality', 'imaging Segmentation', 'imaging modality', 'interest', 'learning strategy', 'three dimensional structure', 'tool']",NCI,DIVISION OF BASIC SCIENCES - NCI,ZIA,2019,295761,-0.025310250016946204
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9762102,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2019,460690,0.021797551589761995
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9746373,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Computer software', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,234000,0.022684123783079886
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,0.02656844330173737
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9706921,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2019,381629,0.009788876519051607
"Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking PROJECT SUMMARY  Quantitative magnetic resonance imaging (MRI) measures tissue parameters such as T1, T2, T2*, and diffusion to detect subtle differences in tissue states (such as microstructure, diffuse fibrosis, edema, hemorrhage, and iron content) from neurological, oncological, and cardiovascular diseases. Because each parameter offers complementary tissue information, multiparameter mapping is very promising for risk assessment, early detection, accurate staging, and treatment monitoring of disease. However, quantitative MRI is typically very time consuming and difficult to perform. Each parameter is typically measured from its own series of images, so measuring multiple parameters leads to long, inefficient scanning sessions. Furthermore, cardiac and breathing motion creates misalignment between images, causing additional problems.  The standard approach to motion is to either remove it (e.g., ask the patient to hold their breath) or to synchronize image acquisition with it (e.g., using electrocardiography (ECG) to monitor cardiac motion). This approach makes scan times even longer, limits imaging to patients who can repeatedly perform long breath holds (which is difficult for aging or weak patients) and who have predictable cardiac motion (which is not true of patients with cardiac arrhythmias). Furthermore, these methods are often unreliable and difficult to perform.  This project is to develop and validate a new technology, MR Multitasking, to perform multiple simultaneous measurements in a single, push-button scan that is both comfortable for patients and simple for technologists to perform. MR Multitasking redesigns quantitative MRI around the concept of images as functions of many time dimensions, each corresponding to a different dynamic process (e.g., motion, T1, T2, T2*, and diffusion), and then uses mathematical models called low-rank tensors to perform fast, multidimensional imaging. This allows continuous acquisition of imaging data even while the subject is moving, providing motion-resolved parameter maps without breath holding or motion synchronization. We will scan healthy subjects, liver patients, prostate cancer patients, and cardiovascular patients to develop and validate this technology and use artificial intelligence to quickly reconstruct images from the collected data. The resulting tool will be applicable to any organ system, offering clinicians and investigators a valuable tool to answer a wide range of biomedical questions. PROJECT NARRATIVE  This project is to develop and validate a one-stop, push-button solution for comprehensive, motion- resolved quantitative magnetic resonance imaging (MRI). This will be accomplished by cultivating a new technology, MR Multitasking, which can measure multiple tissue biomarkers in a single scan, even in moving organs. The resulting technology will be applicable to any organ system, offering clinicians and investigators a valuable tool to diagnose, monitor, and study a wide range of diseases.","Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking",9766063,R01EB028146,"['Address', 'Aging', 'Algorithms', 'Arrhythmia', 'Artificial Intelligence', 'Blood flow', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Collection', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diffuse', 'Diffusion', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Electrocardiogram', 'Fibrosis', 'Hemorrhage', 'Image', 'Iron', 'Joints', 'Lead', 'Lipids', 'Liver', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetism', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Nature', 'Neurologic', 'Organ', 'Patients', 'Physiological', 'Positioning Attribute', 'Predisposition', 'Process', 'Property', 'Recovery', 'Reproducibility', 'Research', 'Research Personnel', 'Respiration', 'Risk Assessment', 'Scanning', 'Series', 'Signal Transduction', 'Source', 'Staging', 'System', 'Technology', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Validation', 'body system', 'deep learning', 'heart motion', 'image reconstruction', 'magnetic field', 'magnetohydrodynamic', 'mathematical model', 'multitask', 'new technology', 'prospective', 'quantitative imaging', 'reconstruction', 'respiratory', 'time use', 'tissue biomarkers', 'tool']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R01,2019,676760,-0.010816521038933843
"Gadgetron Global Network and Artificial Intelligence Powered Cardiac Imaging Past year saw new development in AI applications and data curation. Following applications had been developed and deployed to clinical scanners: . Cardiac perfusion mapping with AI based segmentation and reporting . Cardiac cine imaging with AI based contouring, for retro-gated and free-breathing imaging . AI based cine strain mapping and reporting . Ischemic disease classification using shallow neural nets and reporting on MR scanner . Deep neural net based image enhancement . Deep learning based MR reconstruction  More applications are under development: . Lung Cyst detection and auto reporting from MRI . Cardiac function quantification and reporting from cine imaging using AI . Fast cardiac MR imaging and reporting with free-breathing data acquisition        - 5 patients per hour protocols for non-contrast CMR study, with full reporting for functional parameters using AI        - 3 patients per hour protocols for contrast study, with full reporting of functional parameters, perfusion flow mapping and LGE findings        - Clinical evidences collection for values generated by AI powered CMR  Is it possible to double the CMR patient throughput with the help of AI, including both faster imaging and faster reporting? . AI powered body and organ fat quantification from free-breathing fat-water MRI  Besides developing more AI applications, future work should focus more on AI strategy, infrastructure and evidences for clinical value:  . AI strategy: how to develop a system to keep producing AI applications? How to ensure the developed applications have clinical value, besides making publications? How to ensure the involvement of clinical collaborators to guide AI development?   . Infrastructure: to support curation of significant amount of data with different sources/types/formats, to support curation of labelled data, to support iterative training/testing/deployment, to ensure ethical compliance and enable international collaboration  . Evidences: methods and tools to collect proof that AI applications actually generate values as a part of clinical workflow, e.g. better imaging efficiency (e.g. imaging more patients per day) and better or novel diagnosis. We want to show AI is more than just fancy research. n/a",Gadgetron Global Network and Artificial Intelligence Powered Cardiac Imaging,10023854,ZIAHL006242,"['Artificial Intelligence', 'Biological Markers', 'Breathing', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cloud Computing', 'Collaborations', 'Collection', 'Computer software', 'Cyst', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Disease model', 'EFRAC', 'Ensure', 'Ethics', 'Fatty acid glycerol esters', 'Feedback', 'Free Will', 'Future', 'Goals', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Image Enhancement', 'Individual', 'Infrastructure', 'International', 'Label', 'Lead', 'Life Cycle Stages', 'Link', 'Lung', 'Magnetic Resonance Imaging', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Myocardial Infarction', 'Organ', 'Patients', 'Performance', 'Perfusion', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Reading', 'Recording of previous events', 'Reporting', 'Research', 'Services', 'Software Tools', 'Source', 'Speed', 'Suggestion', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'Water', 'Work', 'accurate diagnosis', 'base', 'clinical imaging', 'clinical practice', 'cohort', 'data acquisition', 'deep learning', 'deep neural network', 'disease classification', 'heart function', 'heart imaging', 'imaging biomarker', 'improved', 'novel', 'reconstruction', 'relating to nervous system', 'research and development', 'software development', 'tool']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIA,2019,34618,0.012986281472110457
"Biomedical Image Analysis and Informatics The Biomedical Image Analysis and Services Section (BIRSS) is committed to providing computational and engineering expertise to a variety of clinical and biomedical informatics activities at NIH. Specifically, biomedical imaging research in PET, ultrasound, CT, MRI, microscopy, cancer research, and neural dysfunction have been supported extensively. To advance and empower scientific research in the NIH intramural program, CIT has developed and continues to enhance a sophisticated open source, platform-independent, n-dimensional, extensible image processing and visualization application. The MIPAV (Medical Image Processing Analysis and Visualization) (http://mipav.cit.nih.gov/) is an application that enables quantitative analysis and visualization of biomedical imaging modalities (from micro to macro) and is used by researchers at NIH and around the world. At NIH, MIPAV has been used to analyze anatomical structures in CT datasets, analysis of MRI datasets for NIMH, and has been used by NCI for the analysis of 2D and 3D microscopic samples.   In addition, BIRSS leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based system to support the collection and analysis of research studies and clinical trials, using a set of modular components that cover all stages of the research life cycle. And because BRICS is un-branded and not associated with a particular disease or organization, it can be efficiently custom-tailored for many research programs.  MIPAV's integrated set of biomedical imaging algorithms and its extensibility have been used by BIRSS to implement many solutions to imaging problems in the NIH intramural research community.  To create custom workflows and solutions for intramural collaborators, BIRSS team members can build plug-ins that leverage the algorithms and tools in MIPAV to solve complex imaging research questions.  For example, BIRSS continues to develop a novel MIPAV plug-in as part of a collaboration with Dr. Hari Shroffs lab in the National Institute of Biomedical Imaging and Bioengineering (NIBIB) to untwist four-dimensional high-resolution microscopy images of the Caenorhabditis elegans nematode embryo throughout its development.  This plug-in used the image registration and visualization tools already developed by BIRSS for MIPAV, along with novel fiducial annotation and lattice warping tools, to allow the NIBIB researchers to annotate and regularize the C. elegans embryo data through its twitching phase of development, which has not previously been possible algorithmically.  This, in turn, allowed Dr. Shroffs group to investigate neurodevelopmental events in late embryogenesis and apply it to track the 3D positions of seam cell nuclei, neurons, and neurites in multiple elongating embryos. The detailed positional information obtained enabled NIBIB to develop a composite model showing movement of these cells and neurites in an 'average' worm embryo. The untwisting and cell tracking capabilities of this plug-in provides a foundation on which to catalog C. elegans neurodevelopment, allowing interrogation of developmental events in previously inaccessible periods of embryogenesis.  Accurate automatic organ segmentation is an important yet challenging task for medical image analysis.  Anatomical variability in shape and texture feature inhibits traditional segmentation methods from achieving high accuracies.    Machine learning has dominated the medical imaging research field in the past decade.  Initially, pioneer work with decent feature extraction and SVM based image classification achieves better results.  Later, learning based detection algorithm began to dominate the machine learning tools like boosting trees, random forest.   More recently the deep learning based Deep Convolutional Neural Networks (DCNNs) become the mainstream of the medical imaging research field for the past two years.   Using and enhancing the MIPAV application has allowed us to rapidly build the new machine learning component integral to the MIPAV software and is being used to support automated segmentation of the prostate.  BIRSS also leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based informatics system to support the collection and analysis of research studies and clinical trials. BRICS is un-branded and not associated with a particular disease or organization, therefore, it can be efficiently custom-tailored for many research programs. For example, in collaboration with the National Institute of Neurological Disorders and Stroke (NINDS), BIRSS has developed two informatics systems, using the BRICS system, in support of Traumatic Brain Injury (TBI)(http://fitbir.nih.gov/)research, the Parkinsons Disease Biomarker Program (PDBP) (http://pdbp.ninds.nih.gov/), as well as, collaborated with the National Eye Institute developed an informatics system for rare eye diseases, eyeGENE (https://eyegene.nih.gov/).  The TBI informatics system is called the Federal Interagency TBI Research (FITBIR) database to acknowledge the interagency participation and shared interests. FITBIR serves as a repository for TBI research, is supported by multiple federal agencies, and consolidates high quality, uniformly collected, and contemporary data that can be accessed and analyzed by scientific experts.  Over one million records have been uploaded to FITBIR thus far for 66,00 subjects enrolled in 105 different research studies. Currently there are 145 studies expected to contribute to FITBIR and the number of studies is growing every year. Within FITBIR are clinical outcome data and imaging data of which 36,000+ records are of imaging data (MRI, CT, PET and Diffusion) from 45,000+ individual subjects. A summary of the data can be found here: https://fitbir.nih.gov/content/submitted-data.  The goal of the PDBP, a BRICS system, is to support new and existing research and resource development promoting biomarker discovery for Parkinson's disease. Although our understanding of the biology and genetics associated with Parkinson's disease (PD) is advancing rapidly, gaps remain between promising laboratory discoveries and the realization of treatments that will cure or slow progression of PD. To address the needs of the PD community, NINDS has established the PDBP program focused on promoting the discovery of biomarker candidates for early detection and measurement of disease progression.  To date, the PDBP prospective consortium has 100% accrual at nine sites across the US with more than 1,600 enrolled subjects of which biorepository samples have been collected from 1,501 subjects. A summary of the data can be found here: https://pdbp.ninds.nih.gov/Data  The National Eye Institute (NEI) has also adopted the BRICS system to support The National Ophthalmic Disease Genotyping and Phenotyping Network (eyeGENE) (https://eyegene.nih.gov/). The eyeGENE project is a research venture created by NEI in response to promising scientific discoveries in genetics. eyeGENE aims to advance studies of eye diseases and their genetic causes by giving researchers access to DNA samples, clinical information, and patients looking to participate in research studies and clinical trials.  A summary of the data can be found here: https://eyegene.nih.gov/node/35. n/a",Biomedical Image Analysis and Informatics,9997618,ZIACT000272,"['3-Dimensional', 'Address', 'Adopted', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biology', 'Biomedical Research', 'Caenorhabditis elegans', 'Catalogs', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Custom', 'DNA', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Embryo', 'Embryonic Development', 'Engineering', 'Enrollment', 'Event', 'Eye diseases', 'Foundations', 'Four-dimensional', 'Genetic', 'Genotype', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging problem', 'Individual', 'Informatics', 'Infrastructure', 'Intramural Research', 'Intramural Research Program', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Measurement', 'Medical Imaging', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Nematoda', 'Neurites', 'Neuronal Dysfunction', 'Neurons', 'Online Systems', 'Organ', 'Outcome', 'Parkinson Disease', 'Patients', 'Phase', 'Phenotype', 'Plug-in', 'Positioning Attribute', 'Positron-Emission Tomography', 'Prostate', 'Records', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resolution', 'Resource Development', 'Resources', 'Sampling', 'Services', 'Shapes', 'Site', 'Speed', 'System', 'Techniques', 'Texture', 'Traumatic Brain Injury', 'Trees', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization software', 'Work', 'anticancer research', 'base', 'biobank', 'bioimaging', 'biomarker discovery', 'biomedical informatics', 'candidate marker', 'cell motility', 'clinical imaging', 'convolutional neural network', 'deep learning', 'high dimensionality', 'image processing', 'image registration', 'image visualization', 'imaging informatics', 'imaging modality', 'informatics infrastructure', 'interest', 'member', 'microscopic imaging', 'n-dimensional', 'neurodevelopment', 'novel', 'open source', 'platform-independent', 'programs', 'prospective', 'random forest', 'repository', 'research and development', 'research study', 'response', 'tool', 'web-based informatics']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2019,1976426,0.02411143456251746
"IEEE International Symposium on Biomedical Imaging Project Summary This proposal requests funds to provide travel support for graduates to attend and participate in the IEEE Inter- national Symposium on Biomedical Imaging (ISBI) 2019 conference, Venice, Italy on April 08-11, 2019. The main objective of the IEEE ISBI is to bring together researchers with interests in mathematical and computa- tional aspects of biomedical imaging, with a focus on addressing problems of significance to the development and application of imaging systems across spatial scales, from microscopy to whole-body imaging. ISBI partici- pants – on the order of 600-700 from across the world are involved in biomedical imaging research and development in academic institutions, government laboratories, or R&D departments of private companies. ISBI is co-sponsored by two IEEE societies: Signal Processing Society (SPS) and Engineering in Medicine and Biology Society (EMBS), representing academia, industry, and healthcare, and considered the world's foremost societies in biomedical engineering and imaging. SPS and EMBS publish IEEE Transactions on Medical Imag- ing, Transactions on Image Processing, Transactions on Biomedical Engineering, Transactions on Computational Imaging, and IEEE Journal of Biomedical and Health Informatics, among others. Since incep- tion in 2002, ISBI has become the leading international conference bringing together researchers from diverse algorithmic fields, applications, modalities, and size scales, to facilitate cross-fertilization of ideas across imag- ing modalities and scales. Conference topics include physical, biological and statistical modeling, image formation and reconstruction, computational and statistical image analysis, visualization and image quality as- sessment, and artificial intelligence and machine learning for big image data. ISBI, like other IEEE SPS and EMBS conferences, requires submission and review of a 4-page paper. Peer reviews are handled by a 50-mem- ber editorial board (area editors) of leading experts in the community, who in turn assign papers to well- qualified reviewers. All oral and poster papers are published in IEEExplore as Proceedings of ISBI. If awarded, IEEE anticipates the primary impact of this R13 grant will be increased attendance of U.S.-based students, postdoctoral fellows, and early career faculty. By offering to cover a significant portion of attendee's travel expenses, the cost-benefit ratio for attending ISBI 2019 will be extremely favorable. Furthermore, IEEE will award travel grants based on need and scientific excellence, creating opportunities for those early career researchers who have accepted papers (of which less than 50% are accepted to ISBI) and who have limited means to travel. IEEE will be particularly supportive in providing travel awards to women, under-represented groups, and persons with disabilities. Benefits can largely be summarized as “exposure” and education. ISBI provides opportunity for student exposure to many more areas of computational imaging research than generally available in her/his home institution, and concurrently provides opportunity for students to interact with leaders in the field through tutorials, plenary, oral, and poster presentations, and individual discussions. This proposal requests funds to provide travel support for graduate to attend and participate in the IEEE International Symposium on Biomedical Imaging (ISBI) 2019 conference, to be held in Venice, Italy on April 08-11, 2019. The main objective of the IEEE international Symposium on Biomedical Imaging is to bring together researchers with interests in the mathematical and computational aspects of biomedical imaging, with a focus on addressing problems of significance to the development and application of imaging systems across spatial scales, from microscopy to whole-body imaging. The conference covers biomedical imaging problems of high relevance to human health, and hence is of high relevance to the interests of the National Institute of Health.",IEEE International Symposium on Biomedical Imaging,9685477,R13EB027566,"['Academia', 'Address', 'Algorithms', 'Appointment', 'Area', 'Artificial Intelligence', 'Award', 'Biological Models', 'Biology', 'Biomedical Computing', 'Biomedical Engineering', 'Breeding', 'Budgets', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Costs and Benefits', 'Data', 'Development', 'Disabled Persons', 'Education', 'Engineering', 'Exposure to', 'Fertilization', 'Funding', 'Future', 'Generations', 'Goals', 'Government', 'Grant', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging problem', 'Individual', 'Industry', 'Institution', 'International', 'Italy', 'Journals', 'Laboratories', 'Location', 'Machine Learning', 'Mathematics', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Microscopic', 'Microscopy', 'Modality', 'Modeling', 'Oral', 'Paper', 'Participant', 'Peer Review', 'Postdoctoral Fellow', 'Privatization', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Request for Proposals', 'Research', 'Research Personnel', 'Series', 'Societies', 'Statistical Models', 'Students', 'System', 'Training', 'Transact', 'Travel', 'Underrepresented Groups', 'United States National Institutes of Health', 'Woman', 'authority', 'base', 'biocomputing', 'bioimaging', 'biomedical informatics', 'body system', 'career', 'computerized tools', 'cost', 'early-career faculty', 'editorial', 'graduate student', 'image processing', 'imaging modality', 'imaging system', 'innovation', 'interest', 'meetings', 'member', 'physical model', 'posters', 'programs', 'reconstruction', 'research and development', 'signal processing', 'student participation', 'success', 'supportive environment', 'symposium', 'whole body imaging']",NIBIB,UNIVERSITY OF IOWA,R13,2019,10000,-0.00958050353884992
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9669002,R61AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2019,447173,0.02979488515340594
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9765316,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Endothelium', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Tissue Transplantation', 'Topical Corticosteroids', 'Translating', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2019,200104,0.01850240214301396
"Automated end-to-end retinal screening system with robotic image capture and deep learning analysis Abstract  In this SBIR project, we propose EyeScreenBot, an end-to-end automated retinal im- age capture and analysis system, comprising a self-driven, robotic fundus camera plat- form for automated image capture and a deep learning-based image analysis engine for generation of automated screening outcome. With the large, growing, and aging popula- tion and the increased prevalence of diabetes, a large number of people are at risk for vision loss due to several eye diseases including diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma. Although eye screening is effective in re- ducing vision loss, there are not enough clinical personnel and eye-care experts for pop- ulation-wide eye screening. Recent advances with automated image analysis are helping alleviate the situation, but they are still limited by the need for good quality images of the patients captured by trained technicians or expensive retinal cameras equipped for auto- mated capture. EyeScreenBot will be developed to provide a truly end-to-end screening solution that is cost-effective and suitable for deployment in primary care clinics or op- tometrist sites, addressing both automated capture and subsequent automated analysis, all without the need for trained technicians or eye experts at the point of care. When deployed and commercialized, this device will rapidly aid scaling of eye screening for the masses, thereby having an enormous impact in improving the quality and accessibility of eye care and helping reduce preventable vision loss. Narrative EyeScreenBot, an end-to-end automated screening system with intelligent image capture and analysis, will truly enable eye screening at massive scale, which is necessary and urgent since the population at risk for preventable vision loss due to retinal diseases (such as diabetic retinopathy) is growing at a staggering rate. Triaging and identification of at-risk patients will allow for timely intervention to prevent, slow, or even reverse the disease progression and loss of vision.",Automated end-to-end retinal screening system with robotic image capture and deep learning analysis,9847891,R43EY029652,"['Address', 'Age', 'Age related macular degeneration', 'Algorithms', 'Area', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Color', 'Computational algorithm', 'Computer Vision Systems', 'County', 'Coupled', 'Development', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease Progression', 'Evaluation', 'Eye', 'Eye diseases', 'Fundus', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Hand', 'Health', 'Health Services', 'Human', 'Human Resources', 'Image', 'Image Analysis', 'Institutes', 'Intelligence', 'Intervention', 'Intuition', 'Los Angeles', 'Manuals', 'Mass Screening', 'Measures', 'Medical', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Pilot Projects', 'Population', 'Populations at Risk', 'Prevalence', 'Primary Health Care', 'Process', 'Pupil', 'Retinal', 'Retinal Diseases', 'Risk', 'Robot', 'Robotics', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Surveys', 'System', 'Systems Analysis', 'Testing', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Visual impairment', 'Work', 'aging population', 'automated analysis', 'automated image analysis', 'base', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'diabetic', 'digital imaging', 'experience', 'fundus imaging', 'improved', 'interest', 'macula', 'point of care', 'portability', 'prevent', 'professor', 'programs', 'retinal imaging', 'robot interface', 'robotic system', 'screening', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2019,218618,-0.03579131708227059
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9791176,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Infrastructure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'feature detection', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2019,1339073,0.014043397962715838
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,9827476,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Quality', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2019,401628,-0.01708535014846615
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9818000,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,489349,0.021097612853143155
"Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment Project Summary More than 20,000 hematopoietic stem cell transplants (including bone marrow transplants) are performed in the U.S. each year to cure a range of diseases ranging from leukemias to sickle cell anemia to autoimmune deficiencies in children. Unfortunately, most long-term non-relapse survivors will die of chronic graft-versus-host disease (cGVHD), which remains a disease of steadily increasing incidence and profound unmet need. A fundamental barrier in cGVHD management and research is a lack of sensitive and objective assessment tools that permit objective and reproducible measures of disease severity and progression. Skin is the most commonly affected organ in cGVHD and automated techniques capable of measuring precisely the surface area of involved skin in photographs may provide the tools necessary for effectively evaluating patient progress. We propose to (1) create the data set necessary to develop machine learning-based methods for the automatic analysis of cGVHD images, and (2) implement and evaluate these methods. Project Narrative  Chronic graft-versus-host disease (cGVHD) is a lethal disease that affects most long-term hematopoietic stem cell transplant (including bone marrow transplants) recipients. Skin images are used to assess disease severity and progression but the technology required to quantitatively and reproducibly analyze these images is lacking. This project aims at developing and evaluating this technology.",Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment,9648538,R21AR074589,"['3-Dimensional', 'Achievement', 'Affect', 'Agreement', 'Allogenic', 'Area', 'Assessment tool', 'Autoimmune Process', 'Body Surface', 'Bone Marrow Transplantation', 'Characteristics', 'Child', 'Circumscribed Lesion', 'Clinic', 'Clinical', 'Clinical Research', 'Cutaneous', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dermatologic', 'Dermatologist', 'Disease', 'Disease Management', 'Disease Progression', 'Documentation', 'Erythema', 'Exanthema', 'Future', 'Goals', 'Hematologic Neoplasms', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic System', 'Human', 'Image', 'Incidence', 'Industry', 'Institution', 'Label', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methods', 'Morbidity - disease rate', 'Organ', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Protocols documentation', 'Psoriasis', 'Reaction', 'Reproducibility', 'Research', 'Resources', 'Role', 'Scanning', 'Severities', 'Severity of illness', 'Sickle Cell Anemia', 'Site', 'Skin', 'Skin Cancer', 'Standardization', 'Surface', 'Survivors', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-dimensional analysis', 'Time', 'Transplant Recipients', 'Visit', 'Vitiligo', 'automated analysis', 'base', 'cancer imaging', 'chronic graft versus host disease', 'data warehouse', 'deep learning', 'deep neural network', 'digital', 'graft vs host disease', 'high risk', 'image processing', 'improved', 'interdisciplinary approach', 'learning strategy', 'leukemia', 'machine vision', 'mortality', 'network architecture', 'neural network architecture', 'novel therapeutics', 'patient subsets', 'prototype', 'repository', 'response', 'skin disorder', 'skin lesion', 'stereoscopic', 'success', 'tool']",NIAMS,VANDERBILT UNIVERSITY,R21,2019,179706,-0.008549514267606773
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9797689,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,748584,0.028597522278036542
"A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides Abstract/Summary In this SBIR, we propose to validate our handcrafted image analysis algorithm for auto-detecting Mycobacterium tuberculosis (MTB) in a digitized sputum smear. Once validated in a blinded study against manual microscopy and culture (the gold standard), we will try to improve our handcrafted algorithm by integrating, where appropriate, deep-learning approaches (via Convolutional Neural Networks (CNN)). Our novel diagnostic device (the Diascopic iON platform) uses automated image analysis to detect pathogens of interest. Through a blinded study (400 slides), we will assess the iON's effectiveness in detecting MTB. Our aim is to achieve >99% accuracy vs. microscopy, and sensitivity-specificity vs. culture of 80% and 99%, respectively. Currently, the iON platform can detect MTB on a Ziehl-Neelsen (ZN) stained sputum smear in less than 60 seconds, with accuracy of 95% vs. microscopy. The primary objective of this SBIR is to meet or exceed the minimal requirements for the WHO Target Product Profile (published 2014) of a rapid sputum-based test for detecting TB at the microscopy-center level of the health-care system. We will accomplish this feasibility study through a collaborative effort with the Case Western Reserve University-Uganda (UCRC) research team. A full-slide digitization and automated image analysis of 400 ZN slides is planned while on the ground in Uganda. Results will be published in an appropriate peer-reviewed journal for dissemination to the relevant TB pathology and provider community. A secondary objective of this SBIR is to improve our handcrafted algorithm through the use of deep- learning techniques (CNN). We will collaborate with Dr. Madabhushi (Case Western Reserve) - a world leader in Deep Learning methodologies – on this portion of the study. We are optimistic that by combining our handcrafted approach with a deep-learning approach, we can identify MTB bacilli more effectively (i.e. faster and more accurately). We will leverage the lessons-learned in this study to develop algorithms for other developing-world diseases like Onchocerca (river blindness), Plasmodium (malaria), and Shistomes (schistosomaisis). Successful completion of this SBIR will show that the iON can truly become a platform for automated pathogen detection, which will shift lab practices toward faster & more standardized routines that are performed by unskilled workers. If we're successful in this Phase I SBIR, we will develop auto-detect algorithms for 3-4 other pathogens in a phase II SBIR. We will then market the iON platform to resource-limited clinics in countries adversely affected by developing-world diseases. It is our experience that such clinics are seeking a rapid, low cost, accurate and simple diagnostic tool to improve their efficiency and their ability to detect and treat diseases. Narrative This SBIR is a validation study of a digital pathology platform to detect TB in digitized Ziehl–Neelsen (ZN) slides. We aim to establish a high accuracy (>99%) vs. manual microscopy and a sensitivity & specificity of 80% and 99%, respectively, vs. culture. The TB analysis occurs rapidly, with results available in <60 seconds. We will investigate whether algorithm improvements are possible by combining our handcrafted approach with deep-learning approaches to improve accuracy and efficiency. If high accuracy and sensitivity-specificity can be achieved for TB detection, this low-cost technology can have a significant impact on TB laboratory operations around the world. The technology can also be applied to other pathogens whose primary method of detection is microscopy.",A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides,9851233,R43EB028736,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Bacillus (bacterium)', 'Blinded', 'Case Study', 'Clinic', 'Clinical', 'Color', 'Communities', 'Complex', 'Country', 'DNA', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Feasibility Studies', 'Funding', 'Gold', 'Hand', 'Health Status', 'Healthcare Systems', 'Image', 'Image Analysis', 'Infection', 'Infrastructure', 'Ions', 'Journals', 'Laboratories', 'Low income', 'Malaria', 'Manuals', 'Methodology', 'Methods', 'Microscopy', 'Morbidity - disease rate', 'Mycobacterium tuberculosis', 'Ocular Onchocerciasis', 'Onchocerca', 'Pathogen detection', 'Pathology', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Plasmodium', 'Preparation', 'Process', 'Provider', 'Publishing', 'Quality Control', 'Readiness', 'Reporting', 'Research', 'Resources', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Small Business Innovation Research Grant', 'Specificity', 'Specimen', 'Sputum', 'Stains', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tuberculosis', 'Uganda', 'Universities', 'automated image analysis', 'base', 'cohort', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'digital pathology', 'experience', 'improved', 'innovation', 'interest', 'man', 'mortality', 'novel', 'novel diagnostics', 'operation', 'pathogen', 'portability', 'prevent', 'remote location', 'tool', 'tuberculosis diagnostics', 'validation studies']",NIBIB,"DIASCOPIC, LLC",R43,2019,225000,0.012040498654602333
"Ultraportable Stroke CT Based on Stationary Carbon Nanotube X-ray Source and Deep Learning Image Formation PROJECT SUMMARY The goal of this 12-month SBIR phase 1 project is developing an imaging device that will enable highly efficient and cost-effective stroke imaging for patients suffered trauma events. The expected technical outcome will be a proof-of-concept head CT imaging system with sub- second imaging speed, sub-mSv radiation dose, and high-quality images. Imaging systems with such capabilities will address the current deficiency in timely diagnosis of stroke patients, and benefit society with higher efficiency and lower cost. Such imaging device will make a strong economic impact on the global head CT imaging market, which is estimated to be about $36 billion in the U.S. In a longer term, the novel imaging technology could be translated into markets for security screening, industry inspection, and dental imaging. This project is based on the recent research results by Dr. Cao's team under the support of an NSF CAREER award (PI Dr. Cao, 08/01/2014-07/31/2019, $400,000) and a Dr. Cao's Commonwealth Research Commercialization Fund (CRCF) award (Title: “Computed Tomography Without Moving Parts for Fast and Portable Biomedical Imaging”, 07/01/2017- 06/30/2019, $100,000). The project has a strong footing in intellectual property. The technology is protected by a few patent applications at the Virginia Tech, including US. 62/316649, “Ultrafast Micro-CT for Imaging Free-Moving Animals” (Inventor: Guohua Cao), and PCT/US2013/061049 and US14/429835, “System and Method of Stationary Source Computed Tomography” (Inventor: Guohua Cao, et. al.). In this project, the team will design and build a proof-of-concept head CT platform to test the feasibility of ultraportable and compact head CT based on the stationary carbon nanotube x-ray source design and deep learning image reconstruction algorithm. The expected outcomes from this project include demonstration of the feasibility for ultrafast, low dose, and diagnostic imaging capabilities for intracerebral hemorrhage in head phantoms (ICH), with potential automatic ICH identification through deep learning algorithm. A ready-to- prototype head CT device will be optimized and designed, and a corresponding business plan will be developed. PROJECT NARRATIVE Stroke is a common of death in the world at tremendous social and healthcare costs. Currently head CT is typically used for initial evaluation of stroke patients for signs of intracerebral hemorrhage. An ultraportable stroke CT that can be mounted in a small minivan would significantly shorten the time it takes for the diagnosis of intracerebral hemorrhage, particularly from trauma incidents. This technology will save life and overall healthcare costs.",Ultraportable Stroke CT Based on Stationary Carbon Nanotube X-ray Source and Deep Learning Image Formation,9909721,R43NS115277,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Architecture', 'Award', 'Beds', 'Businesses', 'Carbon Nanotubes', 'Cerebral hemisphere hemorrhage', 'Cessation of life', 'Data', 'Dental', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Dose', 'Employment', 'Evaluation', 'Event', 'Funding', 'Future', 'Goals', 'Head', 'Health Care Costs', 'Human', 'Image', 'Imaging Device', 'Industry', 'Intellectual Property', 'Legal patent', 'Life', 'Low Dose Radiation', 'Measurement', 'Methods', 'Noise', 'Outcome', 'Patient imaging', 'Performance', 'Phase', 'Radiation Dose Unit', 'Research', 'Roentgen Rays', 'Security', 'Site', 'Small Business Innovation Research Grant', 'Societies', 'Source', 'Speed', 'Spottings', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Translating', 'Trauma', 'Tube', 'Validation', 'Virginia', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'clinical imaging', 'commercialization', 'cost', 'cost effective', 'data acquisition', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'detector', 'economic impact', 'experimental study', 'foot', 'image reconstruction', 'imaging capabilities', 'imaging system', 'innovation', 'microCT', 'neural network algorithm', 'novel imaging technology', 'off-patent', 'portability', 'prototype', 'reconstruction', 'screening', 'social', 'stroke patient', 'tomography']",NINDS,"IMAGINGX, INC.",R43,2019,225052,-0.06641193363454666
"31st Annual International MR Angiography Conference Project Summary The objective of the 31st Annual Workshop on Magnetic Resonance Angiography is to provide a forum for scientists and scientist-clinicians, clinical staff and industry interested in MR angiography techniques. The Workshop is the annual meeting of the Society for Magnetic Resonance Angiography (SMRA). At this meeting, emerging techniques and exciting new applications to visualize the vascular system, measure and display blood flow and improve patient outcomes will be presented. MR angiography is an important clinical tool that is applied to millions of patients annually and accounts for an estimated 10% of all MR procedures. Recent advances in time-resolved imaging, non-contrast imaging, post-processing techniques, flow measurements, and flow visualization, as well other innovations, continue to make MRA a dynamic, cutting-edge area of interest for scientific investigation. A major goal of this SMRA Workshop is to provide scientists, clinicians, and students with the opportunity to build connections, pool their knowledge, and educate each other in order to accelerate the refinement of MRA technology and critically how to apply it in clinical practice. Topics for the MRA Workshop will include: vascular disease mechanisms, vessel wall and plaque imaging, quantification of blood flow dynamics, applications of artificial intelligence (AI) and deep learning, MRA of the brain, heart, abdomen, and extremities; contrast agents, cardiac MR, assessment of cardiac structure and function, clinical study design, new MRA techniques, MRI of implanted devices, technology assessment, comparing MRI with other imaging modalities and critically translating advanced MRA techniques into day-to- day clinical practice. The 3-day workshop will be preceded by an informative one-day educational program that will include both fundamental and advanced lectures from international experts in the field. These topics and educational objectives of the 31st Annual Workshop on Magnetic Resonance Angiography are directly related to the NHLBI mission to provide global leadership for research, training, and education to promote the prevention and treatment of heart and blood diseases. The scientific presentations will include new discoveries about the causes of disease and as such contribute to the translation of basic discoveries into clinical practice. In addition, the proposed educational activities as well as discussion among participants will foster training and mentoring of emerging scientists and physicians. In this context, the workshop will support a collaborative research infrastructure, including participants from academic institutions and industry. Project Narrative This proposed “31st Annual Workshop on Magnetic Resonance Angiography” will provide a forum in which researchers and clinicians interested in MRA can build connections, pool their knowledge, and educate students and fellow scientists in order to further develop MRA technology and translate it into clinical practice.",31st Annual International MR Angiography Conference,9837090,R13HL149441,"['Abdomen', 'Angiography', 'Area', 'Artificial Intelligence', 'Award', 'Biology', 'Blood flow', 'Brain', 'Cardiac', 'Catheters', 'Clinical', 'Clinical Research', 'Contrast Media', 'Development', 'Diagnostic Imaging', 'Disease', 'Educational Activities', 'Educational workshop', 'Engineering', 'Female', 'Fertilization', 'Fostering', 'France', 'Funding', 'Genetic Medicine', 'Genetics and Medicine', 'Goals', 'Growth', 'Heart', 'Heart Diseases', 'Hematological Disease', 'Image', 'Imagery', 'Industry', 'Institution', 'International', 'Investigation', 'Ionizing radiation', 'Knowledge', 'Leadership', 'Limb structure', 'Magnetic Resonance', 'Magnetic Resonance Angiography', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Minority', 'Mission', 'Morphologic artifacts', 'National Heart, Lung, and Blood Institute', 'Oral', 'Organ', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Physics', 'Postdoctoral Fellow', 'Prevention', 'Procedures', 'Protocols documentation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Training', 'Scientist', 'Secure', 'Societies', 'Standardization', 'Structure', 'Students', 'Techniques', 'Technology', 'Technology Assessment', 'Time', 'Tissue Viability', 'Training', 'Training and Education', 'Translating', 'Translational Research', 'Translations', 'Travel', 'Vascular Diseases', 'Vascular System', 'Venous', 'Woman', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'clinical application', 'clinical practice', 'computer science', 'deep learning', 'imaging modality', 'implantable device', 'improved', 'innovation', 'interest', 'lectures', 'meetings', 'minority trainee', 'posters', 'programs', 'research and development', 'student participation', 'success', 'supportive environment', 'symposium', 'tool']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R13,2019,10000,0.0049996445459402
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9618878,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2019,401916,0.020958841551139588
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9752019,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2019,991516,-0.0010840053068292325
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",9640524,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Injury', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Receiver Operating Characteristics', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'disorder subtype', 'elastography', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,462750,0.006014142363428086
"Prospective Slice Tracking for Cardiac MRI Project Summary/Abstract Cardiac Magnetic Resonance (CMR) provides arguably the most comprehensive evaluation of the cardiovascular system; however, respiratory motion continues to adversely impact CMR, causing artifacts that lead to poor image quality, repeated scans, and decreased throughput, and thus represents a significant obstacle to clinical utility. For single-shot CMR, cardiac and breathing motions are “frozen” by limiting the acquisition to an end-diastolic window less than 200 ms. For first pass perfusion, breathing motion cannot be eliminated because data from 50 to 60 consecutive heartbeats are required to capture contrast dynamics. For other single-shot applications such as late gadolinium enhancement (LGE) and parameter mapping, respiratory motion is introduced when the acquisition is repeated across several heartbeats to improve spatial and temporal resolution. To eliminate respiratory motion from single-shot images, non-rigid motion correction (MOCO) has been promoted as an attractive option that provides 100% acquisition efficiently. MOCO can be used either after the reconstruction or during the reconstruction. Such techniques, however, cannot account for through-plane motion, which can only be corrected prospectively, and can fail depending on image quality and the extent of motion. Prospective compensation of the respiratory motion has been recognized as an attractive alternative to existing gating and MOCO methods. Proposed methods use one or more navigator echoes—incompatible with or inefficient for many CMR protocols—to capture the respiratory motion and rely on simple parametric models that are inadequate to describe complex respiratory-induced cardiac motion. Due to these limitations, prospective methods have found limited applicability even in research settings. We propose a new framework to prospectively compensate respiratory motion. The proposed method, called PROspective Motion compensation using Pilot Tone (PROMPT), employs Pilot Tone technology and leverages machine learning principles to first learn complex respiratory-induced cardiac motion on a patient-specific basis and then prospectively compensate the motion by tracking the imaging plane, in real time, as a function of a Pilot Tone based respiratory signal. If successful, this synergistic combination of Pilot Tone and machine learning will lead to 100% efficiency for single-shot CMR exams performed under free-breathing conditions, will eliminate the need to setup navigator echoes, respiratory bellows, or other inefficient prospective gating measures, will minimize through-plane motion that can render the images non-diagnostic for CMR applications including fast-pass perfusion, parameter mapping, LGE, and coronary angiography, will provide a reliable surrogate measure of respiratory motion, and will facilitate highly accelerated compressive recovery. Project Narrative Magnetic Resonance Imaging (MRI) has many potential advantages over currently used imaging methods to diagnose heart disease, but MRI images can be ruined if the patient breathes during the scan. In this project, we will develop a method that is insensitive to breathing motion and compare it to existing methods. These efforts should lead to significant improvements in diagnosis of heart disease so that patients may benefit from appropriate treatment.",Prospective Slice Tracking for Cardiac MRI,9762101,R21EB026657,"['Anatomy', 'Breathing', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Complex', 'Coronary Angiography', 'Data', 'Dependence', 'Diagnosis', 'Evaluation', 'Financial compensation', 'Freezing', 'Gadolinium', 'Heart Diseases', 'Image', 'Imaging Techniques', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Patients', 'Perfusion', 'Positioning Attribute', 'Protocols documentation', 'Recovery', 'Research', 'Resolution', 'Respiration', 'Scanning', 'Signal Transduction', 'Slice', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'artificial neural network', 'base', 'computerized data processing', 'data acquisition', 'healthy volunteer', 'heart motion', 'imaging modality', 'improved', 'prospective', 'reconstruction', 'respiratory', 'technology development', 'temporal measurement', 'volunteer']",NIBIB,OHIO STATE UNIVERSITY,R21,2019,223680,0.0312936218435676
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),9804438,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'off-patent', 'open source', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2019,1715698,0.033045775848745094
"Innovations in cervical cancer diagnosis for low resource settings using advanced optical imaging and machine learning diagnostic algorithms. The broad goal of this project is to adapt a portable, low-cost, easy-to-use Pocket-sized Colposcope (developed under other funding) for use in a community setting, and develop automated algorithms that combine neovascularization, glycogen depletion and acetowhitening to provide comparable diagnosis to an expert. This work will be done in a collaboration between 3rd Stone Design, Inc, Duke University and Kenya Medical Research Institute. The specific aims of this proposal are:  Aim 1 (Phase I): Improve Pocket colposcope by designing continuous magnification mechanism and improving device workflow integration to eliminate between-use disinfection through the use of a disposable optically clear sterile sleeve. Provider feedback on our previously developed Pocket colposcope has unanimously suggested the addition of a slider mechanism to control coarse zoom and a sleeve consumable to the Pocket colposcope design.  Aim 2 (Phase I): Automated algorithms and software for cervical pre-cancer detection We will improve the specificity of VIA using a novel software application with embedded machine learning diagnostic algorithms for automated cervical cancer screening. We will apply and validate the individual algorithms for VIA and GIVI (green illumination vascular imaging) to existing images obtained from a 200-patient clinical study with the Pocket colposcope. We will then compare the performance of the algorithms to expert physician interpretation of the same images, with pathology serving as the gold standard.  Aim 3 (Phase II): Document user experience with Pocket colposcope in Kenya. We will develop a culturally relevant training package directly in the community healthcare setting. We will collect quantitative and qualitative data including surveys, in-depth interviews, and clinic observations from both naive providers and patients and use these findings to and use these findings to improve the introduction of the Pocket colposcope in Kenya and simultaneously, inform the clinical investigations in Aim 4.  Aim 4 (Phase II): Compare the performance of the Pocket colposcope to Visual Inspection with Acetic Acid for triage of HPV+ women in Kenya. We will carry out a cluster-randomized trial among 400 HPV+ women to compare the standard triage with that using the Pocket colposcope in Kisumu, Kenya. All HPV+ women will undergo biopsy to determine sensitivity, specificity and positive and negative predictive values of the different triage strategies. Data will be used to model the performance of the algorithm against that of expert colposcopists.  Aim 5 (Phase II): Assess the costs, incremental cost-effectiveness and population health impact of HPV-based cervical cancer screening programs with proposed triage strategies. We will determine the incremental cost-effectiveness ratio and the absolute and relative costs for four triage strategies by measuring the costs and model population health outcomes (cancer cases, deaths and disability adjusted life years). NARRATIVE The SBIR activities proposed by 3rd Stone Design and Duke University will advance the state of the art in cervical cancer imaging through the R&D of novel optics for a portable colposcope combined with automated algorithms for diagnosis. The project will confirm the benefits of these innovations through a clinical trial in Kenya conducted by the Kenya Medical Research Institutes. The innovations developed have tremendous potential to effect public health by increasing diagnostic acuity and decreasing costs of healthcare delivery which ultimately will reduce the impact of the deadly disease.",Innovations in cervical cancer diagnosis for low resource settings using advanced optical imaging and machine learning diagnostic algorithms.,9778122,R44CA240019,"['Acetic Acids', 'Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Ambulatory Care', 'American Society of Clinical Oncology', 'Back', 'Biopsy', 'Blood Vessels', 'Cancer Burden', 'Cervical', 'Cervical Cancer Screening', 'Cessation of life', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Cluster randomized trial', 'Collaborations', 'Colposcopes', 'Colposcopy', 'Community Health', 'Community Healthcare', 'Computer software', 'Cost Analysis', 'Cost Measures', 'Country', 'Coupled', 'Cytology', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Disinfection', 'Feedback', 'Fogs', 'Foundations', 'Funding', 'Glycogen', 'Goals', 'Gold', 'Guidelines', 'Health Care Costs', 'Healthcare', 'Human Papillomavirus', 'Image', 'Incidence', 'Individual', 'Infrastructure', 'International', 'Interview', 'Kenya', 'Lesion', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Medical Research', 'Modeling', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Phase', 'Physicians', 'Predictive Value', 'Prevention', 'Primary Health Care', 'Protocols documentation', 'Provider', 'Public Health', 'Research Institute', 'Resources', 'Rural', 'Sensitivity and Specificity', 'Site', 'Sledding', 'Small Business Innovation Research Grant', 'Specificity', 'Sterility', 'Surveys', 'Technology', 'Testing', 'Training', 'Triage', 'Universities', 'Vagina', 'Visual', 'Woman', 'Work', 'World Health Organization', 'base', 'burden of illness', 'cancer diagnosis', 'cancer imaging', 'clinical investigation', 'cohort', 'community setting', 'cost', 'cost effectiveness', 'cost-effectiveness ratio', 'design', 'disability-adjusted life years', 'experience', 'health care delivery', 'health care settings', 'improved', 'incremental cost-effectiveness', 'innovation', 'low and middle-income countries', 'mortality', 'neovascularization', 'novel', 'optical imaging', 'overtreatment', 'point of care', 'population health', 'portability', 'primary care setting', 'relative cost', 'research and development', 'screening', 'screening program']",NCI,CALLA HEALTH FOUNDATION,R44,2019,299992,-0.017420756831130535
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this SBIR project, we present EyeMark, a set of advanced image analysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we will develop tools for computation of microaneurysm (MA) ap- pearance and disappearance rates (jointly known as turnover rates) for use as a bi- omarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high positive influ- ence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a MA turnover computation prototype tool that ro- bustly registers longitudinal images (even with multiple lesion changes) and effectively detects DR lesions (lesion level AUROC>=0.95). The tool provides graceful degradation to confounding image factors by reporting MA turnover as a range, thereby capturing the inherent confidence in MA detection. By the end of Phase IIB we will develop a market ready, clinically validated end-to-end desktop software for robust, automated longitudinal lesion analysis and characterization that can work on the cloud to produce results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,9735477,R44TR000377,"['Adult', 'Age', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Biometry', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Consumption', 'County', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Digital Imaging and Communications in Medicine', 'Early identification', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Joints', 'Lesion', 'Los Angeles', 'Machine Learning', 'Measures', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Patients', 'Pattern Recognition', 'Pear', 'Performance', 'Phase', 'Picture Archiving and Communication System', 'Process', 'Protocols documentation', 'ROC Curve', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Retrieval', 'Risk', 'Sampling', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'application programming interface', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'computerized', 'computerized tools', 'convolutional neural network', 'deep neural network', 'design', 'diabetic patient', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'high throughput analysis', 'image registration', 'imaging biomarker', 'improved', 'interest', 'longitudinal analysis', 'macula', 'medical schools', 'novel marker', 'novel therapeutics', 'prevent', 'programs', 'prototype', 'response', 'retinal imaging', 'screening', 'screening program', 'serial imaging', 'success', 'tool', 'usability', 'validation studies']",NCATS,"EYENUK, INC.",R44,2019,750000,0.0009870692973666631
"An Integrated CT-based Image-Guided Neurosurgical System An Integrated CT-based Image-Guided Neurosurgical System In this SBIR Phase IIb proposal Xoran intends to commercialize a compact and affordable, yet highly- functional, system to provide real time image updates and navigation guidance in support of minimally invasive cranial and spinal neurosurgical procedures. The effort builds on previously developed compact and portable flat-panel Computed Tomography (CT) technology which has been commercialized for hard tissue applications, and incorporates work done in earlier phases of this project to generate viable high- quality images of the soft tissue structures in the brain. Intraoperatively obtained images tightly integrated into an onboard surgical navigation will provide updated instrument localization using next generation electromagnetic tool tip guidance. Workflow optimizations become possible when the imaging and guidance are one device, including fast local image updates, automatic image-to-world registration, as well as speed and simplicity of use. The project includes expansion of the system capabilities to facilitate precise minimally-invasive surgical removal of tumors in both the head and spine. It incorporates a machine-learning based deep neural network method for image finalization to allow high quality, low radiation image updates. The three-year project involves meeting technical milestones of system development including imaging capability, registration, navigation accuracy, speed, workflow, radiation dose considerations and cost. Clinical evaluations will take place at University of Michigan, and a team of consulting physicians has been assembled for oversight, input and feedback. Narrative / Relevance to Public Health Minimally invasive surgical procedures have many benefits to public health including reducing the medical risks and costs associated with brain cancer and spine surgery. However such procedures are often time consuming and technically difficult as the surgeon is unable to directly visualize the area of the operation. In this project, an intraoperative surgical system is developed with onboard imaging capability in order to enable minimally invasive surgeries to be performed more safely and completely, by providing hi-resolution imaging of the brain and spine while the surgeon operates.",An Integrated CT-based Image-Guided Neurosurgical System,9764897,R44CA112966,"['3-Dimensional', 'Address', 'Agreement', 'American', 'Anatomy', 'Animals', 'Area', 'Benefits and Risks', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Businesses', 'Caliber', 'Cancer Etiology', 'Canis familiaris', 'Capital', 'Central Nervous System Neoplasms', 'Cephalic', 'Cessation of life', 'Clinic', 'Clinical', 'Consensus', 'Consult', 'Consumption', 'Data', 'Devices', 'Diagnosis', 'Dose', 'Electromagnetics', 'Environment', 'Evaluation', 'Excision', 'Feedback', 'Fluoroscopy', 'Funding', 'Goals', 'Head', 'Image', 'Image-Guided Surgery', 'Institutional Review Boards', 'Investments', 'Licensing', 'Machine Learning', 'Malignant neoplasm of brain', 'Mediation', 'Medical', 'Medical Imaging', 'Metals', 'Metastatic Neoplasm to the Bone', 'Michigan', 'Minimally Invasive Surgical Procedures', 'Monitor', 'Navigation System', 'Neoplasm Metastasis', 'Neurosurgeon', 'Neurosurgical Procedures', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Pennsylvania', 'Phase', 'Physicians', 'Pituitary Neoplasms', 'Positioning Attribute', 'Procedures', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Resolution', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Spinal', 'Spine surgery', 'Structure', 'Surgeon', 'Survival Rate', 'System', 'Systems Development', 'Technology', 'Time', 'Tissues', 'Tomography, Computed, Scanners', 'United States National Institutes of Health', 'Universities', 'Update', 'Vertebral column', 'Veterinary Medicine', 'Veterinary Schools', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer site', 'cancer surgery', 'commercial application', 'cost', 'cranium', 'deep neural network', 'human subject', 'image guided', 'image reconstruction', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'instrument', 'interest', 'meetings', 'minimally invasive', 'neurosurgery', 'next generation', 'operation', 'point of care', 'portability', 'real-time images', 'research clinical testing', 'soft tissue', 'spine bone structure', 'tool', 'tumor', 'validation studies']",NCI,"XORAN TECHNOLOGIES, LLC",R44,2019,1350820,0.010175229520902447
"Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities. This suggests that abnormalities are subtle, and perhaps postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a collaboration supported by our concluding Fogarty project, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images produced as part of our concluding Fogarty project, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the arrangement of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high-resolution images of Bielschowsy stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This yields clear and measurable images of individual axons. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin-related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models to combine these various types of data with known properties of CNS white matter and myelin to build a model of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. In the process of completing these scientific aims, we will pursue the pedagogic goals of training the first two professional biostatisticians in Macedonia, and an academic pathologist. We will also hold a seminar course for biological researchers to build awareness and understanding of the power of biostatistical and other computational methods to enrich their research. NARRATIVE Our ongoing Fogarty/NIMH research project in Macedonia (R01 MH060877, “Building Schizophrenia Research in Macedonia”), has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale.",Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia,9953486,R56MH117769,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Architecture', 'Autopsy', 'Awareness', 'Axon', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Assay', 'Biometry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Charge', 'Collaborations', 'Complex', 'Computer-Assisted Diagnosis', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electron Microscope', 'Electrons', 'Fiber', 'Goals', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'International', 'Knowledge', 'Learning', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurable', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Morphology', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofilament Proteins', 'Paraffin', 'Pathologist', 'Pathology', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Schizophrenia', 'Scientist', 'Silver Staining', 'Stains', 'Statistical Data Interpretation', 'Statistical Methods', 'Structural Models', 'Students', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Transcript', 'Translational Research', 'Triad Acrylic Resin', 'base', 'cognitive function', 'computerized', 'computerized tools', 'data modeling', 'deep neural network', 'diffusion anisotropy', 'high resolution imaging', 'histological image', 'histological studies', 'imaging study', 'innovation', 'interest', 'low and middle-income countries', 'microscopic imaging', 'multidimensional data', 'multimodality', 'network models', 'novel', 'pedagogy', 'reconstruction', 'sex', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R56,2019,10000,-0.01292936244293982
"Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities. This suggests that abnormalities are subtle, and perhaps postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a collaboration supported by our concluding Fogarty project, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images produced as part of our concluding Fogarty project, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the arrangement of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high-resolution images of Bielschowsy stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This yields clear and measurable images of individual axons. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin-related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models to combine these various types of data with known properties of CNS white matter and myelin to build a model of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. In the process of completing these scientific aims, we will pursue the pedagogic goals of training the first two professional biostatisticians in Macedonia, and an academic pathologist. We will also hold a seminar course for biological researchers to build awareness and understanding of the power of biostatistical and other computational methods to enrich their research. NARRATIVE Our ongoing Fogarty/NIMH research project in Macedonia (R01 MH060877, “Building Schizophrenia Research in Macedonia”), has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale.",Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia,9953486,R56MH117769,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Architecture', 'Autopsy', 'Awareness', 'Axon', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Assay', 'Biometry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Charge', 'Collaborations', 'Complex', 'Computer-Assisted Diagnosis', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electron Microscope', 'Electrons', 'Fiber', 'Goals', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'International', 'Knowledge', 'Learning', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurable', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Morphology', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofilament Proteins', 'Paraffin', 'Pathologist', 'Pathology', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Schizophrenia', 'Scientist', 'Silver Staining', 'Stains', 'Statistical Data Interpretation', 'Statistical Methods', 'Structural Models', 'Students', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Transcript', 'Translational Research', 'Triad Acrylic Resin', 'base', 'cognitive function', 'computerized', 'computerized tools', 'data modeling', 'deep neural network', 'diffusion anisotropy', 'high resolution imaging', 'histological image', 'histological studies', 'imaging study', 'innovation', 'interest', 'low and middle-income countries', 'microscopic imaging', 'multidimensional data', 'multimodality', 'network models', 'novel', 'pedagogy', 'reconstruction', 'sex', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R56,2019,481148,-0.01292936244293982
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9782996,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'comparative effectiveness', 'cost', 'deep learning', 'diagnosis standard', 'effectiveness research', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics\xa0tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2019,348107,0.007853820925514648
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9790958,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Financial Hardship', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'central database', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2019,199142,0.005723536890931616
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, image refers not only to biomedical images, but also to illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. We are seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. To meet these objectives, we use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions). In FY2019, we established that recently available deep learning features help finding relevant images better than the traditional image features, such as color and texture. We have accordingly updated these features for image searches.   A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. To support this research, we maintain the MedPix database (https://medpix.nlm.nih.gov/home) that contains and continues accepting medical cases submitted by radiologists through the case upload server (https://cup.nlm.nih.gov/login).   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and the modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   To evaluate and demonstrate our techniques, we have developed Open-i (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. The Open-i system enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 1,651,647 open access articles and 5,362,166 illustrations from the biomedical literature hosted at the National Library of Medicine's PubMed Central repository; including, over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays; 67,517 images from NLM History of Medicine collection; and about 2,064 orthopedic anatomy illustrations provided by Norris Medical Library, University of Southern California. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publisher's Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to search for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using a clinical image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. Open-i indexes all the text and illustrations in medical articles by features, both textual and image-based. Open-i also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and de-identified patient records, as well as the orthopedic and historical images. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first and perhaps only production-quality system of its kind in the biomedical domain, Open-i has enabled medical professionals and the public to access visual information from biomedical articles that are highly relevant to their query, as well as the ""take away"" messages of the articles. The quality of the information delivered by Open-i has been evaluated in international competitions, in which the system consistently ranks among the best. For the past years the site has attracted over 10,000 unique visitors daily (excluding bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. During the 2019 reporting period, the Open-i user interface was redesigned to provide equal quality of retrieval results for all types of devices used to access the site.   Using images from Open-i and MedPix, we have created several collections of clinically relevant question-answer pairs pertaining to images and used the collections in the biomedical VQA challenges, which we co-organized with Philips research within the international ImageCLEF evaluations. n/a",Integrating image and text information for biomedical information retrieval,10016941,ZIALM010001,"['Anatomy', 'Bibliography', 'California', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Devices', 'Differential Diagnosis', 'Electronic Health Record', 'Evaluation', 'Eye', 'Goals', 'Graph', 'History of Medicine', 'Home environment', 'Hybrids', 'Image', 'Indiana', 'Information Retrieval', 'International', 'Journals', 'Knowledge', 'Link', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Medical', 'Medical Libraries', 'MedlinePlus', 'Methods', 'Multimedia', 'Natural Language Processing', 'Orthopedics', 'Outcome', 'Patients', 'Performance', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Research', 'Research Support', 'Resources', 'Retrieval', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Texture', 'Thoracic Radiography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Update', 'Visual', 'Work', 'base', 'bioimaging', 'clinical imaging', 'clinically relevant', 'cluster computing', 'computational platform', 'deep learning', 'digital', 'imaging modality', 'improved', 'indexing', 'journal article', 'multimodality', 'patient oriented', 'phrases', 'radiological imaging', 'radiologist', 'repository', 'search engine', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2019,770042,-0.013862999967416101
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9791188,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2019,22992,0.005584209991568385
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9791188,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2019,514000,0.005584209991568385
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",9882865,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2019,340827,0.002067356577915763
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",9746883,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'injured', 'innovation', 'learning strategy', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2019,824785,0.014485816699720001
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9624738,R01CA193730,"['3-Dimensional', 'Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation Dose Unit', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'primary endpoint', 'public health relevance', 'quality assurance', 'radiation delivery', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2019,343572,-0.010717456739707604
"Augmented reality visualization for intraoperative guidance based on fluorescence lifetime Project summary/Abstract Optical imaging techniques have demonstrated potential to delineate tumor margins in vivo during surgery as they can rapidly characterize structural, biochemical or functional properties of tissue. Implementation in clinical practice demands rapid visualization and augmentation of imaging data but is often limited by the difficulty in dynamic registration, slow image reconstruction, lack of real- time ability or the need for contrast agents. The goal of this proposal is to implement the recently released Microsoft HoloLens with fiber-based imaging techniques to dynamically augment tissue characteristics directly on the interrogated area in the surgeon’s field of view. The specific aims of this proposal are as follows: (1) To realize a prototype of the augmented reality visualization platform and to combine it with our fluorescence lifetime imaging (FLIm) system, implement a user interface for a convenient interaction with the device. (2) To evaluate and optimize the scanning resolution and the registration precision using fluorescence phantoms and demonstrate the system in vivo for ten patients undergoing lumpectomy surgery. A current pilot study has demonstrated the potential of FLIm to localize tumor margins on excised breast specimen. The acquired in vivo data will help to systematically analyze differences between ex vivo and in vivo fluorescence decay signatures and provide initial data for a large-scale study that will be necessary to delineate tumor margins in vivo. The innovation of this proposal is that it will realize an augmented reality visualization platform for FLIm and other fiber based optical imaging modalities providing dynamic (continuous) augmentation of tissue properties directly on the interrogated area (surgeon’s field of view) in real-time without requiring the injection of contrast agents. The successful completion of this work has consequently the potential for significant impact in the field of surgical navigation. Project narrative This project seeks to realize an augmented and mixed reality visualization based on autofluorescence lifetime and any other fiber-based imaging technique for surgical navigation. The proposed research is consequently relevant to public health as it constitutes a critical part of surgical workflow to enable surgeon finding specific targets, avoiding areas of risk, and providing intraoperative orientation leading to higher resection precision and less interruptions in the surgical workflow.",Augmented reality visualization for intraoperative guidance based on fluorescence lifetime,9770855,R03EB026819,"['Achievement', 'Address', 'Algorithms', 'Anatomy', 'Area', 'Augmented Reality', 'Biochemical', 'Breast', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Research', 'Communication', 'Computer Vision Systems', 'Computer software', 'Contrast Media', 'Data', 'Devices', 'Excision', 'Fiber', 'Fiber Optics', 'Fluorescence', 'Goals', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Techniques', 'In Situ', 'Infrastructure', 'Injections', 'Interruption', 'Intuition', 'Laboratories', 'Machine Learning', 'Mammary Neoplasms', 'Measurement', 'Medical Imaging', 'Modification', 'Near-infrared optical imaging', 'Operating Rooms', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Pilot Projects', 'Positioning Attribute', 'Postoperative Procedures', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Public Health', 'Research', 'Resolution', 'Risk', 'Scanning', 'Specimen', 'Stains', 'Structure', 'Surgeon', 'Surgical margins', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'breast lumpectomy', 'cancer therapy', 'clinical practice', 'design', 'design and construction', 'fluorescence lifetime imaging', 'human subject', 'image processing', 'image reconstruction', 'imaging modality', 'imaging system', 'improved outcome', 'in vivo', 'innovation', 'mixed reality', 'optical imaging', 'prototype', 'real-time images', 'tumor']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2019,74276,-0.03743349793218702
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9746721,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Infrastructure', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'classification algorithm', 'clinical practice', 'community involvement', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,334204,0.016505465945273818
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,434944,0.02229960032088547
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,100000,0.02229960032088547
"Automatic SUV Extraction and Biodistribution Analysis of Preclinical PET Preclinical positron emission tomography (PET) plays a significant role in monitoring radiotracer biodistributions for the development of new therapies. The standardized uptake value (SUV) has become one of the most important quantitation measures in PET analysis. However, SUV extraction from PET data hinges on the ability to clearly delineate the organ region-of-interest (ROI) from an anatomical reference. Cross-comparison of different organ SUVs and biodistributions is also cumbersome due to complex registration strategies of each animal with an unknown pose and size. Operator bias and lack of efficient co-registration strategies results in poor data reproducibility, high data variability, low data throughput and prohibits the use of fully-automated data parsing and data analysis for predicting early therapy outcomes with high sensitivity. In Vivo Analytics will directly address these shortcomings by developing InVivoPET. It will be a cloud-based PET data analysis tool, which will enable automatic organ SUV extraction followed by an instantaneous biodistribution analysis. InVivoPET will automatically coregister PET images to the animal’s anatomy and will calculate biodistributions in almost real-time. InVivoPET consists of several parts. First, a Body Conforming Animal Mold (BCAM) enables consistent spatial and longitudinal registration of the animal’s pose and location to the PET data. Second, a statistical mouse atlas based on an Organ Probability Map (OPM) provides a digital and operator-independent organ ROI template. Third, a cloud-based software with a browser-based user interface enables an automatic organ SUV extraction with following biodistribution analysis. Last, machine learning and data mining algorithms can be applied in the future that will further enhance study outcomes. InVivoPET does not rely on manual delineation of organs. A machine-driven data analysis fully eliminates operator-dependent variability and increases data reproducibility. It will enable the drug development team to quantitate the impact of candidate therapeutics with the highest accuracy, reduces the time to enter clinical trials, reduces costs, and ensures the quantification and consistency of PET data. Therefore, the hypothesis is that the organ SUV can automatically be extracted from PET data using the BCAM and OPM. In Aim 1, we will modify the BCAM for housing mice with surface-protruding tumors and confirm the ability for spatially aligning mice with tumor xenografts to the OPM. In Aim 2, we will perform PET imaging of tumor bearing mice using 18F-FDG and confirm the ability for automatically extracting the organ SUV based on the OPM. The successful completion of the proposed project will help to commercialize InVivoPET, which will be sold as a plug-in to existing PET systems and as a PET- manufacturer independent Software-as-a-Service (SaaS). Project Narrative: InVivo Analytics seeks funding for demonstrating the feasibility of automatically analyzing radiotracer biodistributions of small animal positron emission tomography (PET). Biodistribution analysis is currently operator-dependent, time-consuming, and prone to error while reducing the reproducibility of study results. The proposed technology will be fully automated, operator- independent, and will facilitate the development of new therapies in small animal models of infection, inflammation, and cancer.",Automatic SUV Extraction and Biodistribution Analysis of Preclinical PET,9680585,R43CA224841,"['Address', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Atlases', 'Automation', 'Biodistribution', 'Biotechnology', 'Clinical Trials', 'Complex', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease', 'Drug Kinetics', 'Early treatment', 'Ensure', 'Funding', 'Future', 'Geometry', 'Goals', 'Housing', 'Image', 'Infection', 'Inflammation', 'Knowledge', 'Location', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Manufacturer Name', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molds', 'Molecular Target', 'Monitor', 'Mus', 'Optics', 'Organ', 'Outcome Study', 'Persons', 'Phase', 'Play', 'Plug-in', 'Positron-Emission Tomography', 'Posture', 'Probability', 'Radiation therapy', 'Radioisotopes', 'Reproducibility', 'Roentgen Rays', 'Role', 'Shoulder', 'Skeleton', 'Standardization', 'Surface', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translations', 'X-Ray Computed Tomography', 'animal imaging', 'base', 'cancer imaging', 'cloud based', 'commercial application', 'contrast enhanced', 'cost', 'data mining', 'digital', 'dosimetry', 'drug development', 'fluorodeoxyglucose', 'imaging Segmentation', 'imaging platform', 'imaging study', 'improved', 'in vivo', 'interest', 'novel therapeutics', 'platform-independent', 'pre-clinical', 'radiotracer', 'sex', 'software as a service', 'subcutaneous', 'therapeutic candidate', 'therapy development', 'therapy outcome', 'tool', 'tumor', 'tumor xenograft', 'uptake']",NCI,"IN VIVO ANALYTICS, INC.",R43,2019,222931,-0.007298631802280094
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9753130,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Infrastructure', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Modernization', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Prediction of Response to Therapy', 'Privatization', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissues', 'Tumor Burden', 'base', 'cancer biomarkers', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'clinical predictors', 'cloud based', 'disorder subtype', 'feature detection', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'specific biomarkers', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2019,567509,-0.0031273751225334634
"Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography PROJECT SUMMARY Integrated analysis of coronary anatomy and biology using 18F-fluoride PET and CT angiography Each year, 735,000 Americans have an acute myocardial infarction (heart attack), and approximately 120,000 die from it. Heart attacks occur most commonly due to rupture of atherosclerotic plaques in coronary arteries. Despite this, current diagnostic and treatment algorithms make no allowance for the assessment of disease activity and currently all patients with atherosclerosis are treated in a similar manner. This failure to differentiate stable from active disease may result in potentially unnecessary or insufficient therapies. In a breakthrough series of studies, our co-investigators discovered that positron emission tomography (PET) with 18F-sodium- fluoride (18F-NaF; an inexpensive and widely available tracer approved by Food and Drug Administration) can readily identify plaque rupture and increased coronary plaque activity. We propose to build further on this success, by addressing several important remaining limitations that prevent us from translating this technology to broad clinical use. The limitations include complicated and subjective image analysis, underutilization of the concomitant coronary computed tomography angiography (CTA) for plaque characterization, inability to utilize prior CTA for the analysis of 18F-NaF PET, lack of methods to integrate all available PET and CTA data and significant motion of the coronaries during the PET scan. We propose a multi-faceted approach to automate and improve coronary 18F-NaF PET imaging by full integration with CTA and correction for cardiac, respiratory, and patient motion. The overall goal of the proposal is to optimize the measurement of disease activity in coronary atherosclerosis using integrated 18F-NaF PET/CTA imaging, with the opportunity to validate this development against clinical outcome in a “real-world” multicenter patient study. For this work, we propose the following 3 specific aims: 1) to integrate quantification of CTA and PET image data 2) to develop new methods for simultaneous correction of cardiac, respiratory, and patient motion for coronary PET, and 3) to clinically evaluate new methods in a multicenter clinical trial (separately funded and already underway), further refining risk prediction for heart attacks with integrated PET+CTA risk score derived by machine learning. This work will lead to a robust and reproducible clinical method for stratification of patients for risk of heart attacks, with potential to be applied for the identification of patients who would most benefit from expensive, and potentially risky treatments. Our techniques could also be used in future clinical trials to test the efficacy of novel therapies. Moreover, the new analysis will be applicable to other PET tracers that may be developed to investigate other pathological processes in the coronary vasculature. The resulting software will be shared with clinical institutions performing coronary PET to facilitate standardization and automation of this novel plaque imaging technique. NARRATIVE A heart attack, a major cause of death, is most commonly caused by rupture of deposits in heart vessels, leading to sudden blockage of the blood flow in the vessels and disruption of blood supply to the heart muscle. Currently there is no reliable test to identify deposits at the highest risk of rupture, but in a recent scientific breakthrough, positron emission tomography has demonstrated capability to image disease activity inside these deposits, linked to their rupture; this technique, however, is currently hampered by lack of anatomical reference, image blurring due to heart motion, and variability of manual analysis. We propose to address these problems by developing automatic software that precisely integrates anatomical and biological information and virtually “freezes” vessel motion, validating this new approach in a large “real-world” multicenter patient study.",Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography,9755492,R01HL135557,"['Acute myocardial infarction', 'Address', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Area', 'Arterial Fatty Streak', 'Atherosclerosis', 'Automation', 'Binding', 'Biological', 'Biological Process', 'Biology', 'Blood flow', 'Breast Microcalcification', 'Cardiac', 'Cause of Death', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer software', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Emission-Computed Tomography', 'Enrollment', 'Event', 'FDA approved', 'Failure', 'Fluorides', 'Freezing', 'Funding', 'Future', 'Goals', 'Heart', 'Histologic', 'Image', 'Image Analysis', 'Imaging Techniques', 'Inflammation', 'Institution', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Motion', 'Multi-Institutional Clinical Trial', 'Myocardial', 'Myocardial Infarction', 'Myocardium', 'Noise', 'Outcome', 'Pathologic Processes', 'Patient risk', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Radiation', 'Recurrence', 'Reporting', 'Reproducibility', 'Research Personnel', 'Risk', 'Risk Assessment', 'Rupture', 'Scanning', 'Series', 'Signal Transduction', 'Sodium Fluoride', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tracer', 'Translating', 'United States Food and Drug Administration', 'Vascular blood supply', 'Work', 'X-Ray Computed Tomography', 'atherosclerotic plaque rupture', 'automated analysis', 'coronary computed tomography angiography', 'coronary plaque', 'coronary vasculature', 'cost', 'disorder risk', 'efficacy testing', 'experience', 'fluorodeoxyglucose positron emission tomography', 'heart motion', 'high risk', 'imaging study', 'improved', 'novel', 'novel strategies', 'novel therapeutics', 'patient stratification', 'prevent', 'prospective', 'respiratory', 'success', 'uptake', 'virtual']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2019,756169,0.017391526361552098
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,9831425,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2019,409911,0.044724220549096146
"Functional Cardiovascular 4D MRI in Congenital Heart Disease SUMMARY / ABSTRACT Congenital heart disease (CHD) is the most common birth defect, affecting 1.2% of all live births. Imaging plays a major role in managing CHD but remains challenging for evaluating complex cardiac and vascular abnormalities across a wide range of age and habitus. To address these limitations, the PIs have developed cardiovascular 4D flow MRI which can measure complex 3D blood flow in-vivo, a task difficult or impossible to obtain with other imaging strategies. Recent efforts have focused on two forms of CHD: 1) bicuspid aortic valve (BAV) which is the most common form of CHD, and 2) single ventricle physiology (SVP), one of the most severe forms of CHD. Our 4D flow MRI studies have successfully identified new hemodynamic biomarkers to better characterize CHD. We were the first to establish a physiologic link between aberrant 3D blood flow, elevated wall shear stress (WSS), aortopathy phenotype, and aortic wall tissue degeneration on histopathology in patients with BAV. In patients with SVP, our findings demonstrated relationships between surgical correction strategies and flow distribution to the lungs, a known factor implicated in SVP outcome. We have achieved successful clinical translation at Northwestern, where 4D flow MRI is now used as a clinical tool in diagnostic MRI exams for patients with CHD and aortic disease. Over the past four years, the PIs have assembled one of the largest 4D MRI databases with over 2500 patient exams. For this renewal application, we identified a need to increase the dynamic range of 4D MRI flow sensitivity to account for data complexity (3D + time) and the wide age range in CHD by a combination of dual-venc flow encoding, compressed sensing, and SSFP imaging. Second, three is a need for longitudinal studies to identify predictors of BAV and SVP outcome. Third, making these unique but complex 4D MRI data sets and analysis tools more widely available to the greater research community is challenging. In addition, no automated methods currently exist for advanced processing such as atlas based analysis across large cohorts. Analysis is thus time consuming and requires manual interactions (e.g. 3D vessel segmentation) which limits reproducibility and translation. To address this need, an established Northwestern data archival and pipeline processing resource based on remote high-performance computing clusters (NUNDA) will be utilized for standardized data archival, sharing, and pipeline processing of 4D MRI data. This platform will provide the unique opportunity to utilize annotated data available in the 4D MRI database (>1300 BAV, SVP, and control 4D MRI data analyzed in the initial funding cycle) for application of machine learning concepts to establish (semi-)automated 4D MRI analysis workflows in NUNDA. Thus, the renewal application for this study aims to 1) develop a rapid (15 min) non-contrast 4D MRI for clinical translation, 2) leverage the existing large 4D MRI database to identify 4D MRI metrics predictive of long-term (> 5 years) CHD patient outcome, and 3) establish a remote NUNDA platform for 4D MRI data sharing and automated analysis across large cohorts. PROJECT NARRATIVE Our goal is to develop non-contrast 4D MRI, a new diagnostic test to achieve an improved assessment for the most common and one of the most severe forms of congenital heart disease: bicuspid aortic valve and single ventricle physiology. We will leverage an existing large 4D MRI database to allow for long-term 5-8-year follow-up to establish new measures for improved outcome prediction and therapy management for patients with bicuspid aortic valve and single ventricle physiology. A comprehensive data archive will be established to allow for the dissemination of the 4D MRI data, analysis tools, and study results to the greater research community.",Functional Cardiovascular 4D MRI in Congenital Heart Disease,9663985,R01HL115828,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Aortic Diseases', 'Archives', 'Atlases', 'Biological Markers', 'Blood flow', 'Cardiac Output', 'Cardiovascular system', 'Child', 'Clinical', 'Common Ventricle', 'Communities', 'Complex', 'Congenital Abnormality', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease Progression', 'Exposure to', 'Funding', 'General Anesthesia', 'Goals', 'Growth', 'Heart Abnormalities', 'Heart Rate', 'High Performance Computing', 'Histopathology', 'Hospitals', 'Image', 'Infant', 'Link', 'Live Birth', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Operative Surgical Procedures', 'Outcome', 'Outcome Study', 'Oxygen', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Play', 'Population', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Role', 'Secure', 'Sex Differences', 'Standardization', 'Testing', 'Time', 'Translations', 'adverse outcome', 'analysis pipeline', 'aortic valve', 'automated analysis', 'base', 'bicuspid aortic valve', 'clinical translation', 'cluster computing', 'cohort', 'congenital heart disorder', 'data archive', 'data pipeline', 'data sharing', 'design', 'exercise capacity', 'flexibility', 'follow-up', 'hemodynamics', 'improved', 'improved outcome', 'in vivo', 'novel', 'novel diagnostics', 'outcome prediction', 'patient population', 'pediatric patients', 'prevent', 'shear stress', 'spatiotemporal', 'tissue degeneration', 'tool', 'vascular abnormality']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,740572,0.005458814886254317
"LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research PROJECT SUMMARY Imaging forms the backbone of living subjects research. Living subjects research is both essential to the progress of translational medicine and very expensive. The research community actively seeks to develop and validate new clinical endpoints to solve a range of etiology, natural history, diagnostic and prognostic problems. This project aims to develop and commercialize LATTICE, an Electronic Research Record, Image Management and Sharing Solution, and Deep Learning Platform. LATTICE is designed to increase the efficiency of imaging-driven biomedical research and clinical trials. This efficiency is accomplished first through a structured workflow that includes protocol management, subject scheduling, and records collection from multiple imaging modalities. Access to imaging and associated data within the same workflow simplifies the process for the research team. Structuring the data into a de-identified, privacy-managed Image Bank enables sharing for collaboration and re-use for retrospective research. Image processing algorithms connected to the Image Bank facilitate batch analysis, while the system also provides a platform for the development of new image-based outcome measures and clinical endpoints. A key objective of LATTICE is to enable investigators and collaborators to accelerate the translation of insights to the clinic with maximum efficiency. Successful translation requires structuring the workflow, record keeping, and protocols into a rigorous, transparent, reproducible and validated process. LATTICE is designed to reduce the friction in translating successful research projects to the clinic. Researchers in the Advanced Ocular Imaging Program (AOIP) at the Medical College of Wisconsin developed elements of LATTICE as separate technologies. The Specific Aims of this proposal are directed to an integrated workflow addressing a broader set of objectives. The AOIP LATTICE Electronic Research Record will be translated into a commercially managed repository and brought under regulatory Design Control. The current AOIP Image Bank containing 3,000,000 de- identified retinal images will be integrated into the LATTICE workflow. Critically, this integration will allow the sharing of the Image Bank with external researchers. Three retinal image process algorithms that operate on retinal images will integrate into this workflow. These algorithms include analysis of adaptive optics images of the fundus, analysis of the foveal avascular zone from optical coherence tomography angiography (OCTA), and model-based analysis of the fovea imaged with OCT. A computational deep learning workflow will also be prototyped using a cloud-based architecture. This final workflow will be constructed to demonstrate the feasibility of deploying a collaborative deep learning environment for the development of new clinical endpoints using shared, de-identified images. LATTICE will be a unique system for both prospective and retrospective translational research. LATTICE will make a profound impact on the cost of managing image-based research and add leverage to translational research expenditures for moving insights into the clinic. PROJECT NARRATIVE LATTICE is an innovative electronic research record and development platform for image-based ophthalmic research. LATTICE is designed to reduce the cost of translational research, promote the re- use of images, and simplify the development and application of new techniques to analyze medical images. LATTICE will integrate research workflow tools with a database of 3,000,000 retinal images and advanced image processing software to accelerate the process of translating eye research insights from the lab to the clinic.",LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research,9777970,R43EY030408,"['Address', 'Algorithmic Software', 'Algorithms', 'Angiography', 'Architecture', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnostic', 'Documentation', 'Elements', 'Etiology', 'Expenditure', 'Eye', 'Friction', 'Future', 'Health Insurance Portability and Accountability Act', 'Image', 'Libraries', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Natural History', 'Optical Coherence Tomography', 'Outcome Measure', 'Output', 'Privacy', 'Process', 'Protocols documentation', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Scanning', 'Schedule', 'Secure', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Translational Research', 'Translations', 'Vertebral column', 'Wisconsin', 'Writing', 'adaptive optics', 'base', 'cloud based', 'cost', 'deep learning', 'design', 'educational atmosphere', 'fovea centralis', 'fundus imaging', 'image processing', 'imaging modality', 'imaging platform', 'imaging program', 'innovation', 'insight', 'medical schools', 'ocular imaging', 'operation', 'prognostic', 'programs', 'prospective', 'prototype', 'repository', 'retinal imaging', 'system architecture', 'tool', 'translational medicine', 'web services', 'wiki']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R43,2019,299999,0.047296021951553247
"Development of a Rapid Method for Imaging Regional Ventilation in Small Animals w/o Contrast Agents The objective of this R01 application is to develop a rapid method for imaging regional ventilation and lung compliance in small animals without contrast agents. Much of our current understanding of the normal functioning of the lung and mechanisms of lung disease comes from small animal studies. However, lung function imaging in small animal models is technically challenging due to motion and the relatively small size of the lungs. Pulmonary function testing using plethysmography has been employed to assess lung function and injury with limited validity and utility, particularly in small animals. Additionally, only aggregate measures of functional performance are produced and no regional lung changes can be assessed. An improved imaging method that could provide spatially- and temporally-resolved information regarding ventilation would be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases. It would also facilitate drug discovery and efficacy studies aimed to mitigate respiratory pathology. The ideal method would provide quantitative regional functional information, be applicable to longitudinal studies (low radiation dose), and have a simple and affordable implementation that permits widespread use. Currently available imaging methods including micro-CT or MRI fall short in one or more of these requirements.  To address this need, we will establish and evaluate a novel, easy to implement, and highly effective X- ray phase-contrast (XPC) method for ventilation imaging in small animal models. The lung is ideally suited to XPC imaging because it is comprised mainly of air spaces separated by thin tissue structures. The air-tissue interfaces cause the X-ray beam to experience numerous and strong refractions that produce a distinctive texture in the intensity measured over the lungs known as speckle. Detailed information regarding the regional lung air volume (RLAV) distribution is encoded in the speckle. The benefits of exploiting lung speckle for detecting and monitoring lung function are numerous but remain entirely unexplored for benchtop imaging.  Our approach involves a high degree of technical innovation regarding image formation methods and will significantly extend the current boundaries of functional lung imaging in small animals. The proposed method, referred to as parametric XPC (P-XPC) imaging, will produce 2D parametric images that depict the projected RLAV distribution. When differential images are computed for any given two points in the breathing cycle, ventilation or lung compliance imaging will be achieved. Preliminary in vivo and computational studies have been conducted in support of the proposed research. The specific aims of the project are as follows. Aim 1: Develop P-XPC image formation methods for estimating the projected RLAV distribution; Aim 2: Optimize an XPC imaging system for P-XPC imaging. Aim 3: Evaluate the diagnostic capability of P-XPC imaging in two pre-clinical animal models of disease in vivo. The proposed research will result in a novel, easy to implement, and highly effective X-ray phase-contrast (XPC) method for functional lung imaging in small animal models. It will provide spatially- and temporally- resolved information regarding lung ventilation that will be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases.",Development of a Rapid Method for Imaging Regional Ventilation in Small Animals w/o Contrast Agents,9927856,R01EB023045,"['Address', 'Air', 'Animal Disease Models', 'Animal Model', 'Animals', 'Breathing', 'Communities', 'Contrast Media', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Functional Imaging', 'Image', 'Imaging technology', 'Longitudinal Studies', 'Low Dose Radiation', 'Lung', 'Lung Compliance', 'Lung diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Monitor', 'Motion', 'Mus', 'Pathology', 'Performance', 'Phase', 'Physics', 'Physiology', 'Plethysmography', 'Process', 'Pulmonary Emphysema', 'Pulmonary function tests', 'Radiation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Resource Sharing', 'Respiratory physiology', 'Roentgen Rays', 'Scientist', 'Source', 'Structure', 'System', 'Technical Degree', 'Techniques', 'Texture', 'Thinness', 'Time', 'Tissues', 'Translating', 'animal imaging', 'base', 'computer studies', 'contrast imaging', 'cost', 'detector', 'drug discovery', 'drug efficacy', 'efficacy study', 'experience', 'falls', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'learning strategy', 'lung imaging', 'lung injury', 'lung pressure', 'lung volume', 'microCT', 'mouse model', 'novel', 'parametric imaging', 'pre-clinical', 'pressure', 'rapid technique', 'respiratory', 'supervised learning']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2019,408514,-0.007344899037082696
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9761481,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2019,873369,0.004999748394405727
"Functional MRI Core Facility Space Utilization:  The Functional Magnetic Resonance Imaging Facility (FMRIF) currently occupies approximately 5000 sq ft of space in Building 10, divided between the B1level scanner bays, control rooms and electronics/machine rooms for 3TA/3TB, 3TC, and the Siemens 7T-Classic, (about 1800 sq ft, 1100 sq ft and 1300 sq ft respectively) and office space within the Nuclear Magnetic Resonance (NMR) center. On the first floor are the Functional MRI Facility and the Section on Functional Imaging Methods suites (approximately 800 sq ft total) for office space and shared conference space for all staff employed full-time by the facility.  Staff:  The FMRIF staff (currently 14 full- time positions) consists of: the facility director, four staff scientists to keep the scanners running, six MRI technologists, an information technology specialist, a programmer, and an administrative laboratory manger.  Investigators:  The functional MRI facility supports the research of over 30 Principal Investigators translating to over 300 researchers overall. Over 70 research protocols are active and making use of FMRIF scanners. Each scanner has scheduled operating hours of 105 hours per week.  Papers published using the core:  A strong measure of the utility of a core facility is the quantity and quality of scientific papers published by investigators using the facility. We have kept careful records of papers published and their corresponding citations, such that we have been able to create a core facility h-index.   Since its inception in 2000 until August 2019, a total of 1,159 peer-reviewed publications from intramural investigators have used data acquired in the FMRIF core facility. The total is distributed among 658 papers from NIMH, 329 papers from NINDS, and 172 from the other institutes. These papers have been cited a total of 128,839 times for a combined h-index of 175. In other words, 175 papers using the FMRIF have been cited at least 175 times.   Core Projects of the Staff Scientists:  Staff Scientists working on projects are designated as: Sean Marrett (SM), Vinai Roopchansingh (VR), Andy Derbyshire (AD), and Linqing Li (LL). Other staff are Jan Varada (JV) and Roark Maccado (RM). These projects span training, subject interface, IT infrastructure, pulse sequences, processing, and hardware development.  Training:   We continue to provide support for high-resolution FMRI - working with individual groups to implement 1mm-1.6mm resolution  protocols using the CMRR-MB sequence. On the FMRIF-7T,  this is about 75-80% of research FMRI scans. The FMRIF also added support for  novel  methods for ultra-high-resolution on the FMRIF-7T, including VASO and VAPER.  SM organized a small training workshop on non-BOLD VASO contrast for acquiring sub-millimeter layer-specific FMRI images. This session was videoed. Training text and scripting was provided by Dr. Laurentius Huber (SFIM). The workshop focused on practical techniques for improving image quality by optimizing acquisition and reconstruction parameters.  Final integration of the most up-to-date computer console for the FMRIF-7T that increased storage and processing capacity, enabling easier custom pulse sequence development and raw data migration using a high-capacity portable disk subsystem.  SM worked on safety testing and integration of a new version of a 32-channel surface array coil organized into 2 flexible 16-channel modules . This coil  was custom built for FMRIF via a specialty company. This is a collaboration with Joe Murphy-Boesch of NINDS who designed the interface logic to integrate this coil with his custom head-transmit coil and also with Dr. Huber (SFIM).  PAB organized a summer neuroimaging course centered on current issues and controversies. This consisted of 24 lectures (2 per week) from June to Sept.  Subject Interface:   SM installed a DLP projector for the 7T as well as standardized high-speed eye-tracking solutions across all our scanners.  A custom eye-tracker and screen assembly is in development for the FMRIF-7T in collaboration with the Section on Instrumentation and Dr. Eli Merriam. The FMRIF improved audio stimulus delivery with integration and training for an active noise cancelling system that is now available on all FMRIF scanners. This new system also allows for robust collection of speech data from patients concurrently with fMRI exams (e.g. for Dr. Sara Inati, NINDS).  Finally, SM has worked closely with Dr. Peter Molfese (Center for Multimodal Neuroimaging (CMN)/SFIM ) to support concurrent high-density Electroencephalography (EEG) data collection on 3TB and 3TD (with Dr. Jen Evans/Zarate group).  IT infrastructure:   A prototype pipeline for deploying automated MRI quality control (MRIQC) and a pilot Django-based system for secure archiving, retrieval and better meta-data searching of FMRIF image data was developed by JV.   A replacement and upgrade of the storage area network that is the backbone of the FMRIF computing and data archiving network is underway (RM). This will expand the current storage capacity from 200TB to 384 TB and increase access speed.  VR upgraded internal networks on all FMRIF scanners to stream raw data using 10-gigabit connections.  Pulse sequences: (all pulse sequence testing used Protocol number 93-M-0170, NCT00001360)  LL has been developing an imaging technique DANTE prepared EPI for quantitative mapping of cerebral blood volume (CBV) and cerebral blood flow (CBF) of brain activity. Results were presented at the International Society for Magnetic Resonance Imaging in Medicine (ISMRM) 2019.  LL and Yuhui Chai (SFIM) developed the use of DANTE (Delay Alternating with Nutation for Tailored Excitation) pulse trains combined with 3D-EPI to acquire an integrated VASO and perfusion (VAPER) contrast.  LL in collaboration with the Spectroscopy core developed a method for quantitative measurement of brain neurotransmitter glutamate.  AD has maintained a virtual-machine based implementations of the Siemens IDEA Pulse Sequence Development environments  currently including VB17A, VD13A, VD13D, VE11C, VE11U, VE11K and VE12U.  Processing  An updated neuro-feedback API in AFNI, which allowed AFNI to communicate with PsychoPy, thereby allowing its use in neuro-feedback experiments, was developed by VR and collaborators.  AFNIs real-time plugin was updated by VR working with Dr Gonzalez-Castillo from the Section on Functional Imaging Methods SFIM, and Richard Reynolds, from the Scientific and Statistical Computing Core) to provide researchers the ability to use multi-echo FMRI data for real-time neuro-feedback studies.  This is currently being used by Dr Ramot (from Dr Martins Section Cognitive Neuropsychology in NIMH) on the FMRIFs 3TB scanner. JAD has developed methods to recover lost/hidden scan parameters from legacy and current GE DICOM image data  in particular the identification of blip-up versus blip-down EPI trajectories.  This is helpful for re-processing legacy/historical fMRI data from image databases using newer image processing algorithms and pipelines.  Working with John Rogers-Lee (then in the Data Science and Sharing Team, latterly AFNI group) these methods have been incorporated into the dcm2niix software package widely used by the neuroimaging community.  VR and AD helped to develop and implement new cross-vendor sharable raw data format called ISMRMRD.  Hardware  AD has initiated the system integration effort for the head gradient coil that is being sourced by NIBIB (Carlo Pierpaoli is PI) is from Stanford University and is being built at the University of Western Ontario. In use, the head gradient will offer significantly higher gradient performance: amplitude 120mT/m and slew rate 1200mT/m/ms. n/a",Functional MRI Core Facility,10015097,ZICMH002884,"['3-Dimensional', 'Algorithms', 'Archives', 'Area', 'Biological Markers', 'Brain', 'Cerebrovascular Circulation', 'Clinical', 'Cognitive', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'Core Facility', 'Custom', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Deposition', 'Development', 'Digital Imaging and Communications in Medicine', 'Disease', 'Educational workshop', 'Electroencephalography', 'Electronics', 'Environment', 'Equilibrium', 'Extramural Activities', 'Eye', 'Feedback', 'Financial compensation', 'Floor', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Glutamates', 'Goals', 'Head', 'Hour', 'Image', 'Imaging Techniques', 'Individual', 'Information Technology', 'Infrastructure', 'Institutes', 'International', 'Iron', 'Laboratories', 'Lamivudine', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Motion', 'Myelin', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Neuropsychology', 'Neurotransmitters', 'Noise', 'Nuclear Magnetic Resonance', 'Nuts', 'Ontario', 'Paper', 'Patients', 'Peer Review', 'Performance', 'Perfusion', 'Physiologic pulse', 'Positioning Attribute', 'Principal Investigator', 'Protocols documentation', 'Publications', 'Publishing', 'Quality Control', 'Ramp', 'Records', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Resources', 'Retrieval', 'Role', 'Running', 'Scanning', 'Schedule', 'Scientist', 'Secure', 'Services', 'Societies', 'Source', 'Specialist', 'Spectrum Analysis', 'Speech', 'Speed', 'Standardization', 'Statistical Computing', 'Stimulus', 'Stream', 'Structure', 'Surface', 'System', 'Systems Integration', 'Techniques', 'Testing', 'Text', 'Time', 'Traction', 'Training', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Vertebral column', 'Vision', 'Work', 'base', 'cerebral blood volume', 'computerized data processing', 'data archive', 'data format', 'data sharing', 'deep learning', 'density', 'design', 'experimental study', 'flexibility', 'functional MRI scan', 'image processing', 'imaging facilities', 'imaging modality', 'improved', 'indexing', 'instrumentation', 'lectures', 'medical specialties', 'migration', 'multimodality', 'neurofeedback', 'neuroimaging', 'neuroregulation', 'novel', 'portability', 'prototype', 'reconstruction', 'safety testing', 'scientific computing', 'symposium', 'trend', 'ultra high resolution', 'virtual']",NIMH,NATIONAL INSTITUTE OF MENTAL HEALTH,ZIC,2019,3554064,-0.008437172165948114
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9740493,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Augmented Reality', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Imagery', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Visual', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'tool', 'trend', 'virtual reality', 'web services']",NIBIB,"KITWARE, INC.",R01,2019,508446,0.02022255949284849
"ClearScope Combined in vivo and ex vivo three‐dimensional (3D) whole‐brain imaging of non‐transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole‐brain datasets, the best approach is brain clearing followed by whole‐brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole‐brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo‐bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide‐spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state‐of‐the‐art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large‐scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,9677046,R44MH116827,"['3-Dimensional', 'Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Confocal Microscopy', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Dimensions', 'Human', 'Image', 'Immersion Investigative Technique', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'multiphoton microscopy', 'neural network', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'off-patent', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,699967,0.009793425068072186
"Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research PROJECT SUMMARY/ABSTRACT This proposal represents a vertical advancement in neighborhood effects research, producing for the first time, national neighborhood indicators of the built environment. Thus far, only local studies have been conducted due to the resource-intensive nature of site visits to conduct assessments of community features and also manual annotations of street images. With the recent advancement of computer vision and the emergence of massive sources of image data, we will leverage our team’s abilities to develop a data collection strategy utilizing geographic information systems to assemble a national collection of Google Street View images of all road intersections and street segments in the United States. We will utilize this data bank, and develop informatics algorithms to produce neighborhood summaries of built environment that have been theoretically and empirically identified to be important for health outcomes. After the creation of Neighborhood Looking Glass, we will conduct investigations into the impact of neighborhood environments on health utilizing medical records from hundreds of thousands of patients and accounting for predisposing characteristics in analyses. Our investigative team—comprised of experts in the field of epidemiology, computer vision, bioinformatics, and computer science—is uniquely suited to implement the study aims. Our Specific Aims are: 1) Develop informatics techniques to produce neighborhood quality indicators; 2) Measure the accuracy of data algorithms and construct an interactive geoportal for neighborhood data visualization and data sharing, 3) Utilize Neighborhood Looking Glass and a large collection of medical records from Intermountain Healthcare to investigate neighborhood influences on the risk of obesity and substance abuse. The epidemic rise in chronic health conditions is recent and as such suggests its cause is social, cultural, and constructed rather than purely biological. Thus, we have the possibility of intervening on the environment to better support health. Recent studies suggest that the current cohort of young adults may face historically high cardiovascular disease risk and chronic disease burden. Our substantive investigation of the impact of neighborhood factors on chronic conditions will contribute further to the understanding of contextual influences on the health of this cohort at the forefront of a chronic disease epidemic. Moreover, the dramatic rise in overdoses, accidental poisonings, and mental health issues contributing to premature mortality warrants further investigation into risk-inducing environmental factors for substance abuse. Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics. Results can be utilized to inform population-based strategies to reduce health disparities and improve health. Project Narrative/Relevance to Public Health The epidemic rise in obesity, related chronic diseases, and substance abuse in recent decades signal the importance of structural forces and social processes, but the dearth of data on contextual factors limits the investigation of multilevel effects on health. The development of the Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics with potential impact on health. Results from our project can be utilized to inform system-wide and local strategies to improve community health.",Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research,9756470,R01LM012849,"['Accounting', 'Alcohol or Other Drugs use', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Chronic', 'Chronic Disease', 'Cities', 'Collection', 'Communities', 'Community Health', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Collection', 'Data Sources', 'Development', 'Disease', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Family', 'Food', 'Food Access', 'Geographic Information Systems', 'Geography', 'Glass', 'Grant', 'Happiness', 'Health', 'Health Food', 'Health Personnel', 'Health behavior', 'Health care facility', 'Healthcare', 'Image', 'Individual', 'Informatics', 'Investigation', 'Label', 'Literature', 'Manuals', 'Measures', 'Medical Records', 'Mental Health', 'Methods', 'Nature', 'Neighborhoods', 'Obesity', 'Outcome', 'Overdose', 'Patients', 'Physical activity', 'Physical environment', 'Premature Mortality', 'Process', 'Public Health', 'Quality Indicator', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Signal Transduction', 'Site Visit', 'Social Environment', 'Social Processes', 'Source', 'Structure', 'Substance abuse problem', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Visit', 'built environment', 'burden of illness', 'cardiovascular disorder risk', 'cohort', 'computer science', 'contextual factors', 'convolutional neural network', 'cost', 'crowdsourcing', 'data management', 'data mining', 'data resource', 'data sharing', 'data visualization', 'data warehouse', 'density', 'health care availability', 'health disparity', 'improved', 'land use', 'obesity risk', 'object recognition', 'physical conditioning', 'population based', 'social', 'social media', 'walkability', 'young adult']",NLM,"UNIV OF MARYLAND, COLLEGE PARK",R01,2019,329730,-0.008113509730077538
"Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging PROJECT SUMMARY Optical imaging methods are well-established in neuroscience, but high-speed, high- resolution volumetric imaging of neural activity in deep tissue remains a challenge. A number of techniques address limited aspects of this goal, and most are applicable primarily to acute preparations. We propose to develop and test a novel approach to achieve three-dimensional “deep-tissue” imaging for high spatial and temporal resolution neural recording by combining aspects of embedded optical probes with computational imaging techniques. Rather than use a single micro-endoscopic probe, we propose to utilize an array of narrower probes, or optrodes, to reduce the volume of tissue displacement. Computational imaging through each probe can be performed to achieve a field of view (FOV) at a desired distance from the probe tip. Combining the fields of view from multiple probes arranged in an array then provides a composite image field that is much larger than achievable from a single micro-endoscope. In our approach, each ∼0.1 mm diameter probe of the array acts as an independent micro- endoscope. In order to achieve full-field imaging across the array, the individual fields must intersect, and the computational method must be scaled to accommodate, and stitch, multiple fields. In pursuit of these goals, we propose three Aims: Optimizing the FOV of a single micro-endoscope - The purpose of this Aim is to characterize the FOV for an individual probe at multiple depths, and optimize the FOV to about 0.3mm through control over the shape of the probe tip and light collection numerical aperture. Accelerating calibration and reconstruction - In this Aim, we will pursue efficient computational approaches for calibration based upon ray-tracing simulations and image reconstruction based on deep learning. Scaling the FOV with an endoscope array - The computational image reconstruction method will be scaled to accommodate small micro-endoscope arrays (e.g. 4 element) arranged in a hexagonal lattice with FOV of 0.6mm at a 1.5mm depth. NARRATIVE Imaging deep inside tissue, including the brain, is critical to understanding various biological processes. Doing so through a small probe is also of primary importance for minimizing tissue damage. In this proposal, we apply computational techniques to create fluorescent images using an array of microscopic glass needles to guide light in and out of a mouse brain. The simplicity and small footprint of our system have the potential for deep-brain imaging (depths > 1.5 mm) across a large (mm) field of view, which should enable a wide variety of biological and neuroscience studies in the future.",Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging,9829467,R21EY030717,"['3-Dimensional', 'Acute', 'Address', 'Biological', 'Biological Process', 'Brain', 'Brain imaging', 'Caliber', 'Calibration', 'Collection', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Confocal Microscopy', 'Coupled', 'Devices', 'Dimensions', 'Elements', 'Endoscopes', 'Fluorescence Microscopy', 'Fluorescent Probes', 'Future', 'Glass', 'Goals', 'Head', 'Holography', 'Image', 'Imaging Techniques', 'Individual', 'Light', 'Methods', 'Microscope', 'Microscopic', 'Microscopy', 'Miniaturization', 'Mus', 'Needles', 'Neurosciences', 'Optics', 'Penetration', 'Preparation', 'Resolution', 'Risk', 'Running', 'Scanning', 'Shapes', 'Source', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Work', 'absorption', 'adaptive optics', 'attenuation', 'base', 'cost', 'deep learning', 'fluorescence imaging', 'image reconstruction', 'imaging modality', 'improved', 'in vivo', 'interest', 'lens', 'microendoscope', 'multi-photon', 'neural circuit', 'novel strategies', 'optical fiber', 'optical imaging', 'reconstruction', 'relating to nervous system', 'retinal rods', 'simulation', 'temporal measurement']",NEI,UNIVERSITY OF UTAH,R21,2019,456800,-0.023560674299788673
"Quantitative Renal Imaging for Kidney Diseases Contrast Enhanced Magnetic Resonance Angiography (CEMRA) with gadolinium (Gd) provides high resolution visualization of the vascular compartment, but is rarely used in patients with advanced chronic kidney disease (CKD) (estimated glomerular filtration rate (eGFR) < 30 mL/min/1.73m2) due to the risk of nephrogenic systemic fibrosis (NSF). There is thus an unmet need to develop MRI techniques that can both replace Gd and provide new insights into the etiology and severity of CKD.  PI Sridhar and his team at Northeastern University (NEU) have developed a new technique, Quantitative Ultra-short Time-to-Echo Contrast-Enhanced (QUTE-CE) MRI, leads to quantifiable positive contrast images of the vasculature with unprecedented clarity and definition. QUTE-CE is particularly optimal using Ferumoxytol (Feraheme), an FDA approved iron-oxide nanopharmaceutical, that is already routinely used for iron-deficient anemia therapy in CKD patients. Under an ongoing clinical trial (NCT03266848) we have demonstrated QUTE- CE MRI for renal and cerebral imaging in humans at 3T.  This R21 project will develop the QUTE-CE MRI method for kidney imaging in patients with both normal kidney function as well as with CKD. We propose to scan 25 total patients (10 in Year 1 and 15 in Year 2) who are already scheduled to receive ferumoxytol infusion for iron-deficiency anemia therapy. The specific aims of this project are summarized below. Specific Aim 1: Renal Vascular Angiograms of CKD Patients. These studies will be conducted at NEU and Massachusetts General Hospital (MGH) using Siemens Prisma MRI scanners. Three tasks will be pursued to develop the optimizing protocol. Task 1: Develop a robust QUTE-CE imaging protocol. Task 2: Implement a robust methodology for accounting for B1 inhomogeneity. Task 3: Develop a robust trajectory for improved image reconstruction including motion correction. We hypothesize that QUTE-CE MRI will lead to high resolution angiograms that will allow for the safe diagnosis of existing pathologies such as renal artery stenosis in addition to the novel identification of kidney micro-vascular disease. Specific Aim 2: Obtain quantitative renal blood volume (RBV) maps and develop machine learning algorithms (MLA) to better understand the severity of kidney disease. The renal angiograms will be analyzed to obtain renal blood volume (RBV) maps. The RBV maps will be analyzed in terms of Machine-Learning algorithms (MLA) to explore whether we can identify common etiologies of CKD as well as estimate the severity of kidney disease. The MLA will enable organ segmentation, automatized renal parenchyma volumetry, as well as automated extraction and labeling of lesions. The MLA results will be compared with radiological scoring, estimated GFR, and degree of albuminuria. We hypothesize that the absolute RBV maps will enable quantitative monitoring of blood volume in cortex and medulla, and that RBV could be a surrogate parameter for renal microvascular rarefaction, a central mechanism in CKD initiation and progression. PROJECT NARRATIVE TITLE: Quantitative Renal Imaging for Kidney Disease This project will develop a quantitative magnetic resonance imaging technique QUTE-CE MRI for studies of chronic kidney disease (CKD). The QUTE-CE MRI methodology provides very clear and high resolution angiographic images of vasculature using a safe and clinically approved nanoparticle contrast agent, that will transform standard of care by enabling diagnostic imaging for a large population of patients with CKD who cannot be imaged with the current gadolinium contrast agent due to its toxicity.",Quantitative Renal Imaging for Kidney Diseases,9824779,R21DK118449,"['Accounting', 'Acute Renal Failure with Renal Papillary Necrosis', 'Address', 'Adult', 'Albuminuria', 'Algorithms', 'Anemia', 'Angiography', 'Arteries', 'Biological Markers', 'Blood Vessels', 'Blood Volume', 'Cerebrum', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Computer software', 'Contrast Media', 'Cyst', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Disease Progression', 'Etiology', 'FDA approved', 'Gadolinium', 'Gaussian model', 'General Hospitals', 'Glomerular Filtration Rate', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Techniques', 'Infusion procedures', 'Iodine', 'Iron', 'Iron deficiency anemia', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Label', 'Lesion', 'Liver', 'Magnetic Resonance Angiography', 'Magnetic Resonance Imaging', 'Magnetic nanoparticles', 'Maps', 'Massachusetts', 'Medical center', 'Methodology', 'Methods', 'Microvascular Dysfunction', 'Modeling', 'Monitor', 'Motion', 'Nephrogenic Systemic Fibrosis\xa0', 'Nephrology', 'Organ', 'Pathology', 'Patients', 'Population', 'Proteinuria', 'Protocols documentation', 'Public Health', 'Radiation Toxicity', 'Radiology Specialty', 'Renal Artery Stenosis', 'Renal function', 'Research', 'Resolution', 'Risk', 'Scanning', 'Schedule', 'Severities', 'Techniques', 'Testing', 'Time', 'Tissues', 'Toxic effect', 'Ultrasonography', 'United States', 'Universities', 'Veins', 'X-Ray Computed Tomography', 'clinical imaging', 'contrast enhanced', 'contrast imaging', 'expectation', 'ferumoxytol', 'high risk', 'image reconstruction', 'imaging modality', 'improved', 'insight', 'instrument', 'iron oxide', 'kidney biopsy', 'kidney imaging', 'kidney vascular structure', 'machine learning algorithm', 'multidisciplinary', 'nanodrug', 'nanoparticle', 'novel', 'nuclear imaging', 'patient population', 'prisma', 'prognostic', 'standard of care']",NIDDK,NORTHEASTERN UNIVERSITY,R21,2019,220889,0.013497843402800334
"Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms Project Summary This project will create and assess new optical imaging and computational technologies with the goal of improving the detection rates of precancerous, non-polypoid lesions during colonoscopy screening. Identifying and removing these subtle lesions is critical to improving the protective value of colonoscopy in reducing mortality from colorectal cancer. However, current approaches to non-polypoid lesion detection are largely unsuccessful because they are time-consuming and require specialized training (chromoendoscopy), or they start with poor image contrast (software analysis of conventional video). This project focuses on developing a novel technique, called quantitative topographic endoscopy (QTE), that optically measures colon surface properties via a modified commercial colonoscope. The key innovation in this proposal is to utilize structured illumination and build on concepts from computer vision and optical engineering to acquire high-resolution 3D images of the colon surface through a custom endoscope. The project will be implemented through three specific aims: (1) develop a miniaturized, quantitative, high-resolution topography system, (2) implement QTE in a modified commercial colonoscope ready for clinical testing, and (3) determine the validity of QTE in a phantom model and its clinical feasibility in a pilot human study. QTE systems developed in this project will be tested in tissue-mimicking phantoms with a goal of achieving better than 1-mm height sensitivity, in ex-vivo resected colon samples with a goal of accurately reconstructing surface shapes from a complex tissue, and in a pilot human study with the goal of obtaining surface topography non-polypoid lesions. Beyond increasing non-polypoid lesion detection rates, QTE has the potential to address other limitations of colonoscopy, including preventing missed polypoid lesions, classifying lesions for resect-and-discard strategies, and improving colonoscopy quality metrics. Additionally, the development of a QTE system that is approved for human studies will serve as a platform for future clinical assessment of other optical techniques such as spatial frequency domain imaging and speckle imaging in a variety of gastroenterology applications. Project Narrative Colorectal cancer is the second leading cause of cancer death in the United States. Screening colonoscopy can significantly reduce mortality from colorectal cancer but is limited by high miss rates for precancerous non- polypoid lesions. This project will develop new imaging and computational techniques for improving the detection rates of these lesions during colonoscopy screening.",Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms,9769725,R21EB024700,"['3-Dimensional', 'Address', 'Adult', 'Algorithms', 'American', 'Area', 'Biopsy', 'Caliber', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical assessments', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Color', 'Colorectal', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Custom', 'Data', 'Detection', 'Development', 'Dyes', 'Effectiveness', 'Elements', 'Endoscopes', 'Endoscopy', 'Engineering', 'Foundations', 'Frequencies', 'Future', 'Gastroenterology', 'Goals', 'Height', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Interobserver Variability', 'Knowledge', 'Large Intestine', 'Lesion', 'Light', 'Lighting', 'Malignant - descriptor', 'Maps', 'Measurement', 'Measures', 'Morphology', 'Motion', 'Mucous Membrane', 'Optics', 'Patients', 'Pilot Projects', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Premalignant', 'Procedures', 'Research', 'Research Proposals', 'Resected', 'Resolution', 'Sampling', 'Shapes', 'Source', 'Spatial\xa0Frequency\xa0Domain\xa0Imaging', 'Structure', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Image', 'Time', 'Tissues', 'Training', 'United States', 'adenoma', 'base', 'chromoscopy', 'colorectal cancer risk', 'computer aided detection', 'contrast imaging', 'human study', 'imaging system', 'improved', 'innovation', 'miniaturize', 'mortality', 'mortality risk', 'novel', 'optical imaging', 'phantom model', 'prevent', 'research clinical testing', 'routine screening', 'screening', 'vector']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,327488,-0.04422336545410892
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,9881453,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2019,397500,-0.010916534529304085
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9787575,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2019,291536,0.0016420151957678634
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,9817807,R01AR074492,"['Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dimensions', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Kinetics', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'extracellular', 'flexibility', 'gait examination', 'gait retraining', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2019,561592,-0.03000952742075383
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9765383,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,113241,0.0038909702902889826
"STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients Project Summary/Abstract Lung cancer is the leading cause of cancer death and one of the most common cancers among both men and women in the United States. Recent advances in high-resolution imaging set the stage for radiomics to become an active emerging field in cancer research. However, the promise of radiomics is limited by a lack of image standardization tools, because computed tomography (CT) images are often acquired using scanners from different vendors with customized acquisition parameters, posing a fundamental challenge to radiomic studies across sites. To overcome this challenge, especially for large-scale, multi-site radiomic studies, advanced algorithms are required to integrate, standardize, and normalize CT images from multiple sources. We propose to develop STAN-CT, a deep learning software package that can automatically standardize and normalize a large volume of diagnostic images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification. By precisely mitigating the differences in advanced radiomic features of CT images, STAN-CT will overcome research silos and promote medical image resource sharing, ultimately improving the diagnosis and treatment of lung cancer. Our goal will be achieved through two Aims. In Aim 1, we will develop a working prototype to standardize CT images. First, we will collect raw image data from lung cancer patients and reconstruct CT images using multiple image reconstruction parameters, and we will scan a multipurpose chest phantom along with five different nodule inserts. Then, we will develop and train STAN-CT for CT image standardization. An alternative training architecture will be developed to achieve the improved model training stability. In Aim 2. We will deploy and test STAN-CT for image standardization locally and across three medical centers. First, we will make the STAN-CT software package available to the public by providing a menu-driven web-interface so that that users can conveniently convert medical images that were taken using non-standard protocols to one or multiple standards that they specify. Second, we will deploy STAN-CT at the University of Kentucky for local performance validation. We will test the functionality, reliability, and performance of STAN-CT using both patient chest CT image data collected at large-scale and the phantom image data, both independent to training. Third, we will deploy and test STAN-CT at the University of Kentucky as well as the University of Texas Southwestern Medical Center and Emory University for cross- center performance validation. We will use the same multipurpose chest phantom and both standard and non- standard protocols to validate STAN-CT at the three centers. We will test the generalizability of STAN-CT using clinical CT images of human patients and will determine whether a model trained using the data from one medical center are applicable for images collected at another place. Finally, we will distribute the software package of STAN-CT for public use. STAN-CT will enable a wide range of radiomic researches to identify diagnostic image features that strongly associated with lung cancer prognosis. Project Narrative Computed tomography (CT) is one of the most popular diagnostic image modalities routinely used for assessing anatomical tissue characteristics for disease management. However, CT images are often acquired using scanners from different vendors with different imaging standards, posing a fundamental challenge to radiomic studies across sites. The goal of the Standardization and Normalization of CT images for lung cancer patients (STAN-CT) project is to develop a deep learning software package that can automatically standardize and normalize a large volume of chest CT images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification.",STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients,9827910,R21CA231911,"['Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Cancer Etiology', 'Cancer Patient', 'Cancer Prognosis', 'Cessation of life', 'Characteristics', 'Chest', 'Clinical', 'Communities', 'Computer software', 'Custom', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Disease Management', 'Evolution', 'Faculty', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Kentucky', 'Life', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical Imaging', 'Medical center', 'Modeling', 'Multi-Institutional Clinical Trial', 'Names', 'Nodule', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Protocols documentation', 'Quality Control', 'Radiology Specialty', 'Research', 'Resource Sharing', 'Scanning', 'Site', 'Source', 'Specific qualifier value', 'Standardization', 'Stratification', 'Survival Rate', 'System', 'Testing', 'Texas', 'Tissues', 'Tomography, Computed, Scanners', 'Training', 'United States', 'Universities', 'Validation', 'Vendor', 'Woman', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'chest computed tomography', 'computational platform', 'data to knowledge', 'deep learning', 'high resolution imaging', 'human imaging', 'image reconstruction', 'imaging modality', 'improved', 'lung imaging', 'member', 'men', 'outcome forecast', 'prototype', 'quantitative imaging', 'radiomics', 'response', 'spatial temporal variation', 'tool', 'trait', 'tumor', 'web interface']",NCI,UNIVERSITY OF KENTUCKY,R21,2019,213271,-0.017298006902362356
"Multiband ASL for Neurodevelopment Study Project Summary/Abstract The developmental period between childhood to adolescence and young adulthood is marked by a mix of potential and vulnerability. A number of potentially life-long behavioral and emotional problems emerge during this critical period, including alcohol and illicit drug use, risky behaviors, and the first signs of emotional disorders. It is important to understand detailed patterns of typical development, so alterations can be identified and rectified as early as possible. As an entirely noninvasive and quantitative imaging method, arterial spin labeled (ASL) perfusion MRI is increasingly being recognized as an important biomarker for functional brain development in both healthy populations and neurodevelopmental disorders. However, there remain significant challenges for making ASL an impactful tool in studying neurodevelopment, including: 1) a coarse spatial resolution of ~4x4x4mm3, 2) susceptibility to head motion with segmented 3D acquisitions, and 3) potential confounding effects of age dependent variations in arterial transit time using a single post-labeling delay (PLD) scan. Simultaneous multi-slice (SMS) or multiband (MB) is a new accelerated imaging technology that simultaneously excites multiple slices and recovers each slice with parallel imaging techniques. Preliminary studies combining MB with ASL showed that MB can reduce T1 relaxation of the label, improve spatial coverage and/or resolution compared to those of standard 2D ASL. MB imaging may also overcome the limitation of 3D ASL acquisitions in terms of head motion and spatial blurring. However, the signal-to-noise ratio (SNR) of existing MB ASL is inferior to that of 3D ASL. This project builds on two recent innovations from our lab: 1) a constrained slice-dependent (CSD) background suppression (BS) technique that improves the SNR of 2D MB pCASL to be comparable to that of 3D pCASL; and 2) a single-shot 3D GRASE pCASL method with 2D CAIPIRINHA accelerations that improves the imaging speed of 3D pCASL. The goal of this R01 project is to develop and evaluate cutting-edge MB pCASL protocols that are able to offer a high spatial resolution of isotropic 2mm or higher, resistance to head motion and multi-delay capability for accurate perfusion quantification in pediatric populations. A convolutional neural network (CNN) based denoising algorithm for multi-delay MB pCASL will be further developed. The developed suite of MB pCASL protocol and post- processing algorithms will be evaluated in 40 typically developing children and adolescents. The successful completion of this R01 project will lead to a robust multi-delay MB pCASL protocol that is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care. To maximize the scientific and clinical impact, we will continue disseminating the pulse sequence and associated post-processing software as we have been doing in the past decade. Relevance to Public Health A number of potentially life-long behavioral and emotional problems emerge during the developmental period between childhood to adolescence and young adulthood, including alcohol and illicit drug use, risky behaviors, and emotional disorders. This project will develop a robust noninvasive imaging technique using magnetic resonance imaging (MRI) that offers high spatial resolution, resistance to head motion and accurate quantification of cerebral blood flow in children and adolescents. The developed technology is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care.",Multiband ASL for Neurodevelopment Study,9800619,R01EB028297,"['3-Dimensional', 'Acceleration', 'Adolescence', 'Adolescent', 'Affect', 'Age', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Behavior Disorders', 'Behavioral', 'Biological Markers', 'Brain', 'Cerebrovascular Circulation', 'Child', 'Childhood', 'Clinical', 'Computer software', 'Data', 'Databases', 'Development', 'Emotional', 'Emotional disorder', 'Goals', 'Head', 'Image', 'Imaging Techniques', 'Imaging technology', 'Inferior', 'Joint repair', 'Label', 'Life', 'Magnetic Resonance Imaging', 'Methods', 'Motion', 'Network-based', 'Neurodevelopmental Disorder', 'Noise', 'Pattern', 'Performance', 'Perfusion', 'Perfusion Weighted MRI', 'Phase', 'Physiologic pulse', 'Population', 'Predisposition', 'Principal Component Analysis', 'Protocols documentation', 'Public Health', 'Publishing', 'Relaxation', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Risk Behaviors', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Speed', 'Spin Labels', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'age effect', 'age related', 'autism spectrum disorder', 'base', 'child depression', 'clinical care', 'convolutional neural network', 'critical period', 'denoising', 'developmental disease', 'illicit drug use', 'imaging modality', 'improved', 'innovation', 'neurodevelopment', 'non-invasive imaging', 'novel', 'perfusion imaging', 'potential biomarker', 'quantitative imaging', 'socioeconomics', 'time use', 'tool', 'young adult']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,445500,-0.015464026237249077
"Development of a computer-guided orthopedic laser surgical system – vision & measurement Spatial Surgical is developing a novel, first-in-class orthopedic laser system that rapidly and safely ablates soft tissue and bone through a single handpiece. Spatial’s technology couples a laser with a real-time digital video system to offer computer-guided surgery that stands to replace traditional orthopedic saws, drills, and cauterization tools. The digital 3D video system is two miniaturized CMOS-based cameras built into the laser hand- piece. By eliminating mechanical tools an unobstructed, intra-operative view of the surgical site is possible for the first time ever. In-between the laser pulses, the cameras flash to capture an unobstructed view of the surgical site. The dual cameras are connected to a 3D display. Advances in autostereoscopic 3D displays have eliminated the need for 3D glasses, referred to as “glasses-free”, and enabled wide angle viewing. 3D viewing of the surgical area promotes increased spatial understanding of complex/ambiguous scenes and enhances surgical efficiency (McIntire 2014). Coupling image recognition software with the 3D vision enables AI measurement and computer assisted navigation. Orthopedic surgical success, measured as less patient pain and fewer revisions, has been shown when measurement and navigation are used, but existing systems are expensive and slow. A laser surgical hand-piece coupled with HD 3D vision and measurement will enable more accurate implant placement and restored range of motion while reducing infections and decreasing surgical times. This SBIR program models, tests, and demonstrates 3D viewing including digital zoom. Initially a multi-element design is modeled to predict what lens assembles would match with the digital CMOS imager appropriate for the orthopedic HD 3D application. Secondly off-the-shelf, OTS, lens stacks are chosen based on the optical modeling, and are tested to define the balance between the FOV, focal length, object distance and image size. Lens stack stereo characteristics are recorded and subsequently derive the forward-looking design requirements. Additionally, various illumination levels are explored to determine the optimum lighting for each lens stack. A standard vision calibration chart, like Mil-Std-150A, is used for alignment and the edge response is used to define spatial resolution. Multiple bone cut samples are measured with a confocal microscope and then viewed in 2D with the various OTS lens stacks. Optical measurement software is used to process the OTS lens camera images and are graphed versus the microscope data to determine peak image performance for spatial resolution. The introduction of HD autostereoscopic monitors and high pixel count CMOS global imagers enable a 3D surgical vision system to aid in orthopedic surgical applications by providing 3D glasses-free and wide angle viewing to improve spatial understanding of joints for faster and more precise surgery.",Development of a computer-guided orthopedic laser surgical system – vision & measurement,9846664,R43AR075447,"['3-Dimensional', 'Acoustics', 'Anatomy', 'Architecture', 'Area', 'Articular Range of Motion', 'Artificial Intelligence', 'Budgets', 'Calibration', 'Cauterize', 'Cellular Phone', 'Characteristics', 'Color', 'Complex', 'Computer Assisted', 'Computer software', 'Computer-Assisted Surgery', 'Computers', 'Consumption', 'Coupled', 'Couples', 'Coupling', 'Data', 'Development', 'Elements', 'Equilibrium', 'Fracture', 'Graph', 'Hand', 'Healthcare', 'Image', 'Implant', 'Implantation procedure', 'Infection', 'Joints', 'Lasers', 'Lead', 'Length', 'Lighting', 'Liquid substance', 'Measurement', 'Measures', 'Mechanics', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Optics', 'Orthopedic Procedures', 'Orthopedic Surgery procedures', 'Orthopedics', 'Pain', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Process', 'Quality of life', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Robot', 'Robotics', 'Sampling', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Vision', 'base', 'bone', 'cost', 'cost effective', 'design', 'digital', 'flexibility', 'imager', 'imaging system', 'improved', 'lens', 'miniaturize', 'novel', 'preservation', 'programs', 'response', 'skills', 'soft tissue', 'solid state', 'success', 'tool', 'usability']",NIAMS,SPATIAL SURGICAL LLC,R43,2019,246510,-0.014452016669815583
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,9877321,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2019,195110,0.002961256899174035
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,9886087,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Quality', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Drug effect disorder', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'deep learning', 'denoising', 'detector', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,344862,-0.000577422688628081
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9750285,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2019,679852,0.017422856912198446
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9879968,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2019,167376,0.017422856912198446
"Medical Image Perception Society XVIII Conference MIPS XVIII brings together an international community of experts including radiologists, pathologists, other image-based clinicians, psychologists, statisticians, physicists, engineers, and computer scientists investigating the extraction of diagnostic information from medical images. The meeting forges research and learning opportunities for new students and young researchers in a dedicated forum unmatched by other meetings. MIPS XVIII is being organized by the Medical Image Perception Society (a US-based society; Elizabeth Krupinski, PhD President) in conjunction with local hosts Trafton Drew, PhD (University of Utah Psychology) and William Auffermann, MD, PhD (University of Utah Radiology); and committee Lauren Williams (University of Utah) trainee member, David Alonso trainee member (University of Utah). It will run July 14-17, 2019 at the University of Utah Guest House & Conference Center located near the University of Utah campus. Nine topic areas have been selected for MIPS XVIII, reflecting important dimensions of medical image interpretation. This year’s special focus theme is addressing other image-based specialties outside radiology. Studying how clinicians extract diagnostic information from images identifies the causes of missed diagnoses and ways to eliminate these errors. Careful design and evaluation of imaging systems are critical in view of their enormous costs. With the current emphasis in the practice of medicine on “meaningful use” and “accountable care” to improve the quality, safety, and efficiency of care, the role the clinician as decision-maker cannot be ignored. Medical image perception research develops and applies modern methods to the evaluation of observer performance in diagnostic imaging tasks. Understanding basic aspects of the perception of medical images can reduce diagnostic error and improve medical decision-making quality. This grant will support 10 students to attend and present their research at MIPS XVIII. To date, 115 students have been awarded scholarships. The primary goal in supporting these students is to create opportunities and offer supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success. The meeting brings together researchers investigating the process of extracting diagnostic information from medical images to render accurate and efficient diagnostic decisions. Opportunities for advanced, interdisciplinary training of young scientists interested in medical image perception research and its relevance to disease prevention and treatment are often quite limited at the university level. Since 1997, 115 students have been awarded MIPS scholarships, having a significant impact on the field by creating opportunities and offering supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success as independent basic science and clinician-scientist researchers.",Medical Image Perception Society XVIII Conference,9833051,R13EB028683,"['3-Dimensional', 'Acquired Immunodeficiency Syndrome', 'Address', 'American', 'Area', 'Attention', 'Award', 'Basic Science', 'Behavior', 'Caring', 'Clinical', 'Clinical Trials', 'Cognition', 'Cognitive', 'Color', 'Communities', 'Computers', 'Data Set', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Dimensions', 'Discrimination', 'Doctor of Philosophy', 'Engineering', 'Evaluation', 'Failure', 'Fatigue', 'Frequencies', 'Goals', 'Grant', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institute of Medicine (U.S.)', 'International', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Malpractice', 'Medical', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Modern Medicine', 'Modernization', 'Ophthalmology', 'Pathologist', 'Patients', 'Pattern', 'Perception', 'Performance', 'Physician&apos', 's Role', 'Physicians', 'Population', 'Prevention', 'Process', 'Psychologist', 'Psychology', 'Psychophysics', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Running', 'Safety', 'Scholarship', 'Scientist', 'Societies', 'Students', 'Technology', 'Telemedicine', 'Training', 'United States National Institutes of Health', 'Universities', 'Utah', 'Work', 'automobile accident', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'design', 'disorder prevention', 'health care quality', 'image processing', 'imaging system', 'improved', 'interest', 'malignant breast neoplasm', 'medical specialties', 'meetings', 'member', 'outcome forecast', 'prognostic', 'radiologist', 'statistics', 'success', 'symposium', 'whole slide imaging']",NIBIB,EMORY UNIVERSITY,R13,2019,10000,-0.01585145532997912
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9784742,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data pipeline', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2019,533529,0.007782822129024382
"UC Davis Alzheimer's Core Center PROJECT SUMMARY/ABSTRACT As reflected in recent budget increases in the National Institutes of Health, and in line with the National Alzheimer’s Project Act, there is a need to enhance and leverage resources to decrease dementia disparities and change the trajectory of Alzheimer’s disease and related dementias. To fill this gap, we seek to enhance the University of California Davis Alzheimer’s Disease Center (UCD ADC), which contains a diverse ethnoracial cohort (having Hispanic, Black, and non-Hispanic White decedents), through implementation of digital pathology within our Neuropathology Core. This implementation will allow for rapid transmission of pathological data for consultation and collaborations, distribution of materials for educational purposes, tissue specimen archiving, and image analysis. In addition, by having a digital pathology with immunofluorescent capabilities will allow for viewing of the distribution (including overlap) of multiple proteins at one time within a tissue specimen. This can enhance biological studies by providing spatial relationships of proteins resulting in a deeper phenotype of disease. This supplement application is designed to support equipment and leverage and enhance infrastructure to allow the UCD ADC the ability to 1) purchase a whole slide image system to digitize existing and future histologically stained samples 2) leverage and enhance current servers and database systems to allow for storage and rapid retrieval of digital images and their data and 3) leverage and enhance hardware to develop and deploy pipelines for quantitative computational methodologies for pathologies found within a diverse ethnoracial cohort of Alzheimer’s disease brains. The UCD ADC continues to excel and expand in its research initiatives to collect and provide brain specimens and pathological data on a diverse population of individuals at various stages of cognitive ability and dementia risk. This supplement will further enable suitable infrastructure for enhancement of current collaborations and facilitate emerging collaborations by providing a means to share and analysis pathology on digitized whole slide images. PROJECT NARRATIVE Digital microscopy paired with machine learning algorithms has aided in diagnosis and provide more quantitative pathology data to unlock the secrets of diseases. These technologies are needed within the dementia field, specifically in diverse cohorts, as disease presentations may differ. By implementing state of the art imaging systems and analysis, the goals of this supplement are to enhance the ADC’s ability to provide greater access to high quality pathological data for educational, consultation and collaborative purposes, infrastructure to pursue digital solutions for more quantitative analysis, and safe secure storage of histologic specimens.",UC Davis Alzheimer's Core Center,9852188,P30AG010129,"['Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Archives', 'Autopsy', 'Back', 'Basic Science', 'Biological', 'Brain', 'Brain Diseases', 'Budgets', 'California', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Consultations', 'Data', 'Database Management Systems', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Educational Materials', 'Equipment', 'Extramural Activities', 'Future', 'Generations', 'Genetic', 'Genetic Variation', 'Glass', 'Glean', 'Goals', 'Grant', 'Heterogeneity', 'Hispanics', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Individual', 'Infrastructure', 'Infusion procedures', 'Knowledge', 'Measurement', 'Measures', 'Medical Genetics', 'Methods', 'Microscope', 'Microscopy', 'Modernization', 'Neurodegenerative Disorders', 'Not Hispanic or Latino', 'Outcome', 'Paper', 'Pathologic', 'Pathologist', 'Pathology', 'Phenotype', 'Population Heterogeneity', 'Proteins', 'Publishing', 'Research', 'Research Infrastructure', 'Resources', 'Retrieval', 'Sampling', 'Scientist', 'Secure', 'Senile Plaques', 'Slide', 'Specimen', 'Stains', 'Structure', 'Systems Analysis', 'Technology', 'Thioflavin S', 'Time', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Work', 'analysis pipeline', 'base', 'beta pleated sheet', 'cognitive ability', 'cohort', 'cost effective', 'data resource', 'data sharing', 'dementia risk', 'design', 'digital', 'digital imaging', 'digital pathology', 'disease phenotype', 'histological specimens', 'histological stains', 'human tissue', 'imaging system', 'machine learning algorithm', 'neuropathology', 'novel therapeutic intervention', 'spatial relationship', 'synergism', 'transmission process', 'whole slide imaging']",NIA,UNIVERSITY OF CALIFORNIA AT DAVIS,P30,2019,289154,-0.03817651926683434
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,9782929,K01DK110136,"['3-Dimensional', 'Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Consumption', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2019,154915,0.006105706688597255
"Image analysis and machine learning for pulmonary disease screening Our research toward the development of these algorithms has resulted in novel image analysis algorithms (graph cut, atlas based) that identify lung boundaries and delineate lung regions in the posteroanterior CXR. The research has also resulted in novel combinations of shape, edge and texture descriptors computed from pixels within the lung boundaries. These image descriptors are then used to train  supervised machine learning classifiers (e.g., Convolutional Neural Network-based (CNN) Deep Learning, SVM).   We have acquired 4 datasets for testing these algorithms and have made them publicly available for enabling scientific research on the topic. These datasets have been downloaded by over 250 researchers from academic and industrial research labs worldwide.   Performance of our lung segmentation algorithm has been shown to be over 95% accurate. In addition, the classification accuracy for TB detection has been shown to be 88% which is measured as area under the receiver operating characteristic (ROC) curve. The curve measures the response of the classifier at various operating points and indicates the trade-off between sensitivity and specificity of its performance. Both results have been published in high quality archival journals.  This year we advanced our machine learning methods to include CNN-based Deep Learning models that have advanced classification performance significantly. We arebeta-testing our machine learning models in the field to differentiate between normal CXR and those exhibiting lung diseases. The implemented system, which received an HHS Innovates Award, is installed in a truck equipped with a mobile x-ray unit and is deployed by a Kenyan-NGO (Academic Model for Providing Access to Healthcare, AMPATH) and is traveling through numerous sites in rural western Kenya, visiting scores of patients weekly. Research continues with acquiring digital CXR from the field for further training and testing of the algorithms, and the implementation of deep learning techniques (CNN) for fine-tuned classification of the CXR. n/a",Image analysis and machine learning for pulmonary disease screening,9787042,ZIALM010004,"['AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Archives', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Cardiomegaly', 'Cardiopulmonary', 'Classification', 'Comorbidity', 'Country', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Epidemic', 'Exhibits', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Industrialization', 'Journals', 'Kenya', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Modeling', 'Network-based', 'Patients', 'Performance', 'Pneumothorax', 'Process', 'Publishing', 'Pulmonary Tuberculosis', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Rural', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Supervision', 'System', 'Techniques', 'Testing', 'Texture', 'Thoracic Radiography', 'Training', 'Travel', 'Tuberculosis', 'Visit', 'base', 'burden of illness', 'cost', 'deep learning', 'digital', 'health care availability', 'improved', 'innovation', 'learning strategy', 'mortality', 'novel', 'response', 'screening']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2018,708315,-0.01239702396197817
"Opthalmic Image analysis and machine learning for eye disease detection Glaucoma. In a collaboration with the National Eye Institute (NEI), we experimented with several Convolutional Neural Network-based (CNN) Deep Learning (DL) models to detect regions of interest (ROI) in ophthalmic fundus images. Localizing the ROI is necessary, as a first step, to accurately detect optic cup and disc areas  to compute the likelihood of glaucoma. Importantly, we found that results were improved by using blood vessels as features. These blood vessels were extracted by an algorithm we developed using image analysis techniques and also experimenting with the SegNet DL technique.  Several open image data sets were used for the analysis including 600 images from the MESSIDOR set (original images and the ones embedded with blood vessels) for training the DL algorithm. For testing we used 1800 images from MESSIDOR, 6 other open source datasets and the AREDS dataset from NEI. The results showed that using the images embedded with blood vessels yielded the best performance overall: 99.33% accuracy for MESSIDOR, 97.74% for Open Sources, and 90.25% for AREDS (from NEI). These results are 2 to 3% better than previous experiments done without blood vessels as features. The next step is to use the ROI to detect cup and disc areas.   We also developed a CNN-based technique to classify age-related macular degeneration (AMD) disease into levels of severity. NEI categorizes the images in six stages of increasing severity (1, 2, 3a, 3b, 4a, and 4b). We collected 5,898 images and trained a CNN (VGGNet16) DL model to classify images into two classes: Stages 1 and 2 (low) vs. Stages 3 and 4 (severe). 4,719 images were used for training and 1,179 images were used for testing. The test results showed an accuracy of only 85.58%, since 55 images from Categories 1 and 2 and 115 images from Categories 3 and 4 were misrecognized. Research toward reducing these errors is ongoing. n/a",Opthalmic Image analysis and machine learning for eye disease detection,9787050,ZIALM010015,"['Age related macular degeneration', 'Algorithms', 'Area', 'Biological Neural Networks', 'Blindness', 'Blood Vessels', 'Blood flow', 'Caliber', 'Categories', 'Collaborations', 'Data Set', 'Detection', 'Diagnosis', 'Disease', 'Eye', 'Eye diseases', 'Family', 'Glaucoma', 'Hemorrhage', 'Image', 'Image Analysis', 'Intraobserver Variability', 'Machine Learning', 'Macular degeneration', 'Measures', 'Modeling', 'National Eye Institute', 'Nerve Fibers', 'Network-based', 'Ophthalmologist', 'Optic Disk', 'Optic Nerve', 'Performance', 'Research', 'Resources', 'Severities', 'Techniques', 'Test Result', 'Testing', 'Training', 'Uveitis', 'base', 'deep learning', 'experimental study', 'fundus imaging', 'improved', 'interest', 'open source', 'optic cup', 'pressure']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2018,320955,-0.011110896990448722
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9600285,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biological Neural Networks', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,194115,0.01549491960747274
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9651713,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Biological Neural Networks', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Dose', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2018,78500,0.025445939610790676
"Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery Abstract  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques to quantitative image analysis and image reconstruction. There are 12 specific NIH projects that will benefit from the proposed computing infrastructure system. We present the 12 projects through examples from within four Specific Research Topics areas: (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The proposed system is a computing cluster, which uses ScaleMP's Versatile SMP software to aggregate the cluster nodes into a single symmetric multiprocessing computer. The major hardware components consist of 1 HP Enterpris\e ProLiant DL380 server and 8 Apollo 6500 compute nodes, with a total of 2.1 TB of main memory, 18 Intel Xeon E5-2640v4 10-core CPUs, and 32 nVidia Tesla P100 GPUs. The servers will be connected via a 100Gbps EDR Infiniband network. In addition, three important software components, which aim to reduce the complexity of the computing environment and increase researcher productivity, will be integrated into the hardware components: the aforementioned ScaleMP vSMP to create a single virtual computer from the cluster nodes, Cendio ThinLinc to provide remote desktop graphical login services, and Bitfusion Flex AI Platform which provides GPU virtualization, scheduling, and optimization, as well as curated container deployment of common deep learning frameworks. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many-dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA- compliant sharable environment. Project Narrative  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques within four Specific Research Topics areas of (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many- dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA-compliant sharable environment.",Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery,9494294,S10OD025081,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Characteristics', 'Complex', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Development', 'Dimensions', 'Environment', 'Funding', 'Health Insurance Portability and Accountability Act', 'High Performance Computing', 'Image', 'Image Analysis', 'Machine Learning', 'Medical Imaging', 'Memory', 'Productivity', 'Protocols documentation', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Schedule', 'Secure', 'Services', 'System', 'Techniques', 'Translating', 'United States National Institutes of Health', 'biological systems', 'cluster computing', 'computer cluster', 'deep learning', 'genomic data', 'image reconstruction', 'imaging system', 'phenotypic data', 'quantitative imaging', 'radiomics', 'reconstruction', 'tomography', 'tumor', 'virtual']",OD,UNIVERSITY OF CHICAGO,S10,2018,338913,0.04475787425975106
"MalariaScreener: image analysis and machine learning for detecting malaria in blood   film Scientists at the Communications Engineering Branch (CEB) of the Lister Hill National Center for Biomedical Communications (LHC) at the National Library of Medicine (NLM) have done research in deep machine learning methods and image analysis for malaria screening and diagnosis.  To enable their research, acquisition of big malaria image data was essential. With the support of collaborators in the field, LHC acquired about 3000 thick smear images from 200 patients at Chittagong Hospital in Bangladesh. An expert on site manually annotated 85,000 parasites and more than 60,000 white blood cells in these images, allowing training of deep neural networks. Together with 1300 fully annotated thin smear images, which have been acquired earlier and which have infected and uninfected red blood cells marked for training and testing, this set is one of the largest image repositories in the world for malaria blood smears. LHC is going to make this repository publicly available to the research community, and has already released 27,000 cell images of parasitized and uninfected red blood cells.  In machine learning research, LHC has been one of the first institutes to apply deep learning to malaria diagnosis in blood smears. LHC has shown that deep machine learning methods can outperform traditional machine learning methods and can provide high sensitivity and specificity. In fact, LHC has been able to train deep neural network classifiers for both thin and thick smears. Furthermore, research has revolved around finding small and powerful network models that can be executed on smartphones for field use. LHC has successfully implemented a prototype smartphone application for processing thin smears, which achieves the same performance as a full-fledged implementation on more powerful stationary hardware. The search for a similar portable model architecture for thick smears is ongoing, with first experiments showing promising results. Other research into machine learning has focused on using deep learning for detecting and segmenting individual blood slides and parasites to cope with the segmentation problem of touching or overlapping cells.  For image analysis, research has concentrated on solving key problems of blood smear imaging. Specifically, LHC investigated methods that can detect white blood cells in thick and thin smears, which is an important part of the malaria diagnosis protocol. LHC has also studied different methods for finding parasite candidates in thick smears, including both traditional methods and deep learning methods. Other research performed in image analysis has produced methods for normalizing or reducing staining variations, enhancing image quality, and improving illumination.  To validate the research results and to acquire more training and testing data for research into big data, LHC has made its smartphone software available for download so that interested researchers can collaborate. About twenty experts in five countries are currently collaborating with LHC, contributing images, annotations, and valuable feedback. LHC is planning to make its research available via the Open Microscopy Environment (OMERO), where researchers can upload their images and have them processed by LHCs machine learning and image analysis methods. n/a",MalariaScreener: image analysis and machine learning for detecting malaria in blood   film,9787044,ZIALM010006,"['Africa South of the Sahara', 'Architecture', 'Asia', 'Bangladesh', 'Big Data', 'Bite', 'Blood', 'Cells', 'Cellular Phone', 'Cessation of life', 'Communication', 'Communities', 'Computer software', 'Country', 'Culicidae', 'Data', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug resistance', 'Engineering', 'Environment', 'Erythrocytes', 'Feedback', 'Film', 'Goals', 'Hospitals', 'Image', 'Image Analysis', 'Image Enhancement', 'Immigrant', 'Individual', 'Institutes', 'Knowledge', 'Leukocytes', 'Lighting', 'Machine Learning', 'Malaria', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Parasites', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Running', 'Scientist', 'Sensitivity and Specificity', 'Site', 'Slide', 'Stains', 'Standardization', 'System', 'Testing', 'Thick', 'Thinness', 'Touch sensation', 'Training', 'United States', 'United States National Library of Medicine', 'Variant', 'base', 'cellular imaging', 'deep learning', 'deep neural network', 'experimental study', 'fighting', 'global health', 'improved', 'interest', 'learning strategy', 'light microscopy', 'mortality', 'network models', 'portability', 'prototype', 'repository', 'screening', 'smartphone Application', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2018,863259,-0.07667775213771665
"Image analysis and machine learning for cervical cancer diagnostics This year we worked with colleagues from the National Cancer Insitutes (NCI) and their collaborators at Intellectual Ventures-Global Good, the Bill and Melinda Gates Foundation, and Mobile ODT. We validated a Convolutional Neural Network (CNN) based DL algorithm trained and tested on a sample of cervical images selected from a large archive of digitized cervical images from a 9,450-woman, population-based longitudinal cohort (ages 18-92) acquired by the NCI in Guanacaste, Costa Rica. The cohort provided cervical training/validation images and clinical endpoints. AVE generates a severity score (0 to 1); the positivity threshold can be adjusted to balance precancer detection with numbers of women unnecessarily treated. AVE screening very accurately identified prevalent precancer/cancer (AUC = 0.95).  Applied to enrollment cervical images, it outperformed standard screening tests (clinician interpretation of the same cervical images, Pap smears, and even HPV testing) in predicting cumulative risk of precancer/cancer. AVE provides sensitive screening with minimal clinical training or cost. Overtreatment still must be addressed by further improvements, unless lower sensitivity is accepted.   Other the cervicographic images, we also devoted efforts toward analysis DL-based classification of histology images acquired from tissue biopsy slides. This year  a deep learning (DL)-based nuclei segmentation approach was investigated based on gathering localized information through the generation of superpixels using a simple linear iterative clustering algorithm and training with a CNN-DL algorithm. The proposed approach was evaluated on a dataset of 133 digitized histology images and achieved an overall nuclei detection (object-based) accuracy of 95.97%, with demonstrated improvement over imaging-based and clustering-based benchmark techniques.  Building on our previous research, we also introduced an automated localized, fusion-based algorithm to classify squamous epithelium in histology images into Normal, and various Cervical Intraepithelial Neoplasia (CIN) grades, viz. CIN1, CIN2, and CIN3. The approach partitioned the epithelium into 10 segments. Image analysis algorithms were used to extract features from each segment. The features were then used to classify each segment and these results were subsequently fused to classify the whole epithelium. This research applies CNN-DL algorithm and resulted in an increased classification accuracy to 77.25%. n/a",Image analysis and machine learning for cervical cancer diagnostics,9787049,ZIALM010014,"['Acetic Acids', 'Address', 'Age', 'Algorithmic Analysis', 'Algorithms', 'Archives', 'Benchmarking', 'Biological Neural Networks', 'Biopsy', 'Cancer Diagnostics', 'Cancer Etiology', 'Cell Nucleus', 'Cervical', 'Cervical Intraepithelial Neoplasia', 'Classification', 'Clinical', 'Colposcopes', 'Costa Rica', 'Cytology Histology', 'Data Set', 'Detection', 'Enrollment', 'Epithelium', 'Equilibrium', 'Etiology', 'Evaluation', 'Foundations', 'Generations', 'Goals', 'Health', 'Histology', 'Human Papilloma Virus Vaccination', 'Human Papillomavirus', 'Image', 'Image Analysis', 'International', 'Lesion', 'Longitudinal cohort', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Methods', 'Network-based', 'Pap smear', 'Premalignant', 'Prevention', 'Research', 'Resources', 'Risk', 'Sampling', 'Severities', 'Slide', 'Squamous Epithelium', 'Techniques', 'Testing', 'Tissue imaging', 'Tissues', 'Training', 'Validation', 'Visual', 'Woman', 'Work', 'authority', 'base', 'cohort', 'cost', 'deep learning', 'deep neural network', 'handheld mobile device', 'mortality', 'novel', 'overtreatment', 'population based', 'prevent', 'screening', 'screening program']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2018,265618,0.023673630655637153
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9521289,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,471965,0.0466276648488818
"A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies PROJECT SUMMARY/ABSTRACT More people die every year from kidney disease than breast or prostate cancer. Kidney transplantation is life-saving but is limited by a shortage of organ donors and an unacceptably high donor organ discard rate. The decision to use or discard a donor kidney relies heavily on manual quantitation of key microscopic findings by pathologists. A major limitation of this microscopic examination is human variability and inefficiency in interpreting the findings, resulting in potentially healthy organs being deemed unsuitable for transplantation or potentially damaged organs being transplanted inappropriately. Our team developed the first Deep Learning model capable of automatically quantifying percent global glomerulosclerosis in whole slide images of donor kidney frozen section wedge biopsies. This innovative approach has the potential to transform donor kidney biopsy evaluation by improving pathologist efficiency, accuracy, and precision ultimately resulting in optimized donor organ utilization, diminished health care costs, and improved patient outcomes. The goal of this project is to establish our Deep Learning automated quantitative evaluation as the standard practice of donor kidney evaluation prior to transplantation. This will be achieved by assembling a team of expert kidney pathologists and computer scientists specializing in machine learning. The proposal will evaluate the accuracy and precision of the computerized approach to quantifying percent global glomerulosclerosis and compare these results with current standard of care pathologist evaluation. The feasibility of deploying the Deep Learning model to analyze whole slide images on the cloud will also be examined. The end product of this STTR will be a web-based platform to securely deploy Deep Learning image analysis as a tool to assist pathologists with donor kidney biopsy evaluation. PUBLIC HEALTH RELEVANCE STATEMENT Before a kidney can be transplanted, the tissue must be assessed under a microscope to ensure the organ is healthy enough for transplant. A major limitation of microscopic examination is human variability in interpreting the findings, resulting in healthy organs being deemed unsuitable for transplantation. This funding will support developing computer algorithms to assist pathologists in microscopic examination of donor kidney tissues, resulting in more consistent and objective biopsy interpretations, minimizing discard of potentially usable kidneys and optimizing organ placement for transplant.",A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies,9678574,R41DK120253,"['Address', 'Biopsy', 'Blinded', 'Caring', 'Cessation of life', 'Charge', 'Chronic', 'Chronic Kidney Failure', 'Clinical', 'Computational algorithm', 'Computer Assisted', 'Computer software', 'Computers', 'Cost of Illness', 'Data Set', 'Ensure', 'Evaluation', 'Freezing', 'Frozen Sections', 'Funding', 'Goals', 'Health Care Costs', 'Healthcare Systems', 'Human', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Transplantation', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuals', 'Measures', 'Medicare', 'Microscope', 'Microscopic', 'Modeling', 'Online Systems', 'Organ', 'Organ Donor', 'Outcome', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Personal Satisfaction', 'Phase', 'Process', 'Quantitative Evaluations', 'Reproducibility', 'Research Personnel', 'Savings', 'Scientist', 'Secure', 'Slide', 'Small Business Technology Transfer Research', 'Speed', 'Testing', 'Time', 'Tissues', 'Translating', 'Transplantation', 'Transplanted tissue', 'Universities', 'Washington', 'Work', 'base', 'clinical practice', 'cloud based', 'commercial application', 'computerized', 'deep learning', 'digital', 'glomerulosclerosis', 'improved', 'innovation', 'learning network', 'malignant breast neoplasm', 'meetings', 'power analysis', 'predictive modeling', 'public health relevance', 'software development', 'standard of care', 'technological innovation', 'tool', 'whole slide imaging']",NIDDK,"NEWVENTUREIQ, LLC",R41,2018,214009,-0.019099089856018766
"MRI near Total Joint replacements Project Abstract Overview: The parent project for this supplement aims to provide routine MRI of subjects with total joint replacements by reducing the severe image artifacts near metal, while offering highly efficient patient-specific scans that can detect bone loss, infection, and temperature changes near the implant in clinically feasible scan times. The supplement aims to incorporate deep learning techniques to better meet the parent grant goals. Relevance: Total joint replacements are one of the most successful orthopedic procedures, used annually to reduce pain from joint diseases in about one million patients in the United States (a number projected to double by 2030). However, about 10% of joint replacements fail in 5-10 years due to bone loss (osteolysis), infection, or other complications, often leading to revision surgery. Accurate, early, non-invasive assessment of complications remains limited, but would offer earlier and less invasive treatments, reduce unnecessary surgery, or allow better surgical planning. Approach: Prior to, and during the parent grant period, we have developed novel “multi-spectral imaging” (MSI) MRI techniques that allow visualization of pathology adjacent to metallic implants, and together with other groups have successfully applied them to imaging of patients with devices including joint replacements and spinal fixation hardware. However these methods remain slow, have limited spatial resolution, and are challenging to use routinely. The recent growth of the machine learning field including convolutional neural networks (CNNs), and its application to medical imaging offers unique opportunities to substantially improve MRI near metal, and specifically the goals of the parent grant. We propose 3 small, independent aims in the supplement: (1) to bring fast, isotropic imaging near metal to clinical practice by using CNN-based methods to reduce reconstruction times to under 30 seconds, (2) to improve image quality away from metal by using a new reconstruction and CNN to avoid needing standard imaging in addition to MSI methods and (3) to reduce background-gradient induced artifacts near to metal using a CNN-based approach to enable better diagnosis of abnormalities adjacent to metal. Summary: We aim to supplement our parent grant with CNN-based approaches to speed up scanning and image reconstruction, and to improve image quality near to and way from metal. These techniques will allow routine, non-invasive evaluation for earlier and more accurate detection and treatment of complications in these patients, as well as numerous other applications of MRI near metal implants. Project Narrative There is a growing need for accurate diagnosis of complications surrounding joint arthroplasty, where MRI would provide excellent contrast if not for the fact that the presence of metal severely degrades images. Building on recent ideas in MRI and deep learning, we propose to develop practical methods for routine clinical imaging of patients with metal implants by increasing speed as well as offering image contrast that shows infection and other complications near the metal devices. Ultimately these methods will be tested and offered for widespread use to enable earlier and better treatment of complications resulting from arthroplasty, as well as for better understanding of the implications of different devices.",MRI near Total Joint replacements,9750463,R01EB017739,"['Address', 'Biological Neural Networks', 'Clinical', 'Code', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Evaluation', 'Frequencies', 'Goals', 'Grant', 'Gray unit of radiation dose', 'Growth', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Infection', 'Joint repair', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metals', 'Methods', 'Morphologic artifacts', 'Network-based', 'Operative Surgical Procedures', 'Orthopedic Procedures', 'Osteolysis', 'Pathology', 'Patients', 'Phase', 'Principal Component Analysis', 'Protocols documentation', 'Replacement Arthroplasty', 'Residual state', 'Resolution', 'Scanning', 'Signal Transduction', 'Slice', 'Speed', 'Spinal', 'Stretching', 'Techniques', 'Temperature', 'Testing', 'Time', 'United States', 'Unnecessary Surgery', 'Variant', 'Vendor', 'Work', 'accurate diagnosis', 'arthropathies', 'bone loss', 'clinical imaging', 'clinical practice', 'cluster computing', 'contrast imaging', 'cost', 'deep learning', 'field study', 'image reconstruction', 'imaging approach', 'imaging modality', 'improved', 'learning strategy', 'metallicity', 'novel', 'pain reduction', 'parent grant', 'parent project', 'reconstruction', 'response', 'sample fixation', 'spectrograph']",NIBIB,STANFORD UNIVERSITY,R01,2018,156870,0.02451896008274026
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9586688,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Biological Neural Networks', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Dose', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2018,221250,0.044455182151265996
"Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis,9723310,R00AR070902,"['Algorithms', 'Atlases', 'Award', 'Big Data', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imagery', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Characteristics', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'deep learning', 'design', 'epidemiology study', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R00,2018,249000,-0.04463332201629907
"Imaging cellular assemblies with three-dimensional electron microscopy Focused ion beam scanning electron microscopy (FIB-SEM), also referred to as ion abrasion scanning electron microscopy (IA-SEM), is a technology that we have been developing in the lab to image cells and tissues in 3D at high resolution. Imaging cells and tissues by FIB-SEM at high resolution offers many exciting possibilities for biological research; however, at high resolution, this technology produces enormous amounts of data, and is extremely slow. Moreover, one of the most promising aspects of this technology is the ability to quantitatively analyze ultrastructural morphology. Thus in addition to using FIB-SEM to study 3D architecture in cells and tissues, we have also been developing imaging methods and techniques that align the technology with the goal of automated, quantitative analysis of 3D structure at electron microscopy resolutions. As we make progress on a variety of projects related to cancer and aging, we have also been developing methods to process FIB-SEM data more effectively. In a collaboration with Dr. Amitabh Varshney's team at the University of Maryland, we published a paper in January 2-18 in IEEE Transactions in Visualization and Computer Graphics that reports the use of deep learning methods for 3D image segmentation. Designing volume visualizations showing various structures of interest is critical to the exploratory analysis of volumetric data. The last few years have witnessed dramatic advances in the use of convolutional neural networks for identification of objects in large image collections. Whereas such machine learning methods have shown superior performance in a number of applications, their direct use in volume visualization has not yet been explored. In the IEEE paper, we presented a deep-learning-assisted volume visualization to depict complex structures, which are otherwise challenging for conventional approaches. A significant challenge in designing volume visualizations based on the high-dimensional deep features lies in efficiently handling the immense amount of information that deep-learning methods provide. In this paper, we present a new technique that uses spectral methods to facilitate user interactions with high-dimensional features. We also present a new deep-learning-assisted technique for hierarchically exploring a volumetric dataset. We validated our approach with two volumes generated using electron microscopy and one with magnetic resonance imaging. n/a",Imaging cellular assemblies with three-dimensional electron microscopy,9779602,ZIABC010278,"['Aging', 'Architecture', 'Biological Neural Networks', 'Biology', 'Cells', 'Collaborations', 'Collection', 'Complex', 'Computer Graphics', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electron Beam', 'Electron Microscopy', 'Eukaryotic Cell', 'Generations', 'Goals', 'Image', 'Imagery', 'Imaging Techniques', 'Ions', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Maryland', 'Methods', 'Microscopy', 'Morphology', 'Optics', 'Paper', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Scanning', 'Scanning Electron Microscopy', 'Series', 'Site', 'Specimen', 'Structure', 'Surface', 'Techniques', 'Technology', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Transact', 'Universities', 'Use of New Techniques', 'base', 'biological research', 'cellular imaging', 'clinical application', 'deep learning', 'design', 'high dimensionality', 'imaging Segmentation', 'imaging modality', 'interest', 'learning strategy', 'three dimensional structure', 'tool']",NCI,DIVISION OF BASIC SCIENCES - NCI,ZIA,2018,497025,-0.025310250016946204
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9580704,R01EB026708,"['Abdomen', 'Air', 'Algorithms', 'Area', 'Biological Neural Networks', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,460690,0.021797551589761995
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9754513,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,30000,-0.05098120049665315
"Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9466642,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,217746,-0.05465868037978628
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9523267,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2018,385011,-0.009299165570238523
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,0.0292746657047411
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,0.02656844330173737
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9422606,R01EB008374,"['4D Imaging', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Pharmacology', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'clinical diagnostics', 'clinical predictors', 'computerized tools', 'deep learning', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'predictive modeling', 'public health relevance', 'serial imaging', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,451650,-0.019237302566677997
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9518217,R01HL142036,"['Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2018,392932,0.009788876519051607
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Project​ ​Summary/Abstract This​ ​SBIR​ ​Phase​ ​I​ ​project​ ​will​ ​develop​ ​a​ ​deep​ ​learning-based​ ​clinical​ ​decision​ ​support​ ​algorithm for​ ​identifying​ ​aortic​ ​stenosis​ ​from​ ​heart​ ​sounds​ ​recorded​ ​using​ ​the​ ​Eko​ ​Core​ ​Digital Stethoscope.​ ​This​ ​screening​ ​tool​ ​will​ ​help​ ​to​ ​decrease​ ​the​ ​number​ ​of​ ​patients​ ​with​ ​severe asymptomatic​ ​aortic​ ​stenosis​ ​that​ ​remain​ ​undertreated​ ​simply​ ​because​ ​the​ ​condition​ ​is​ ​not diagnosed.​ ​Auscultation​ ​is​ ​commonly​ ​the​ ​method​ ​by​ ​which​ ​valvular​ ​heart​ ​disease​ ​is​ ​first detected,​ ​but​ ​cases​ ​often​ ​fail​ ​to​ ​be​ ​referred​ ​to​ ​echocardiography​ ​for​ ​diagnosis​ ​because clinicians​ ​fail​ ​to​ ​detect​ ​heart​ ​murmurs,​ ​particularly​ ​in​ ​noisy​ ​or​ ​rushed​ ​environments.​ ​To​ ​address this​ ​challenge,​ ​Eko​ ​had​ ​developed​ ​the​ ​Core,​ ​a​ ​digital​ ​stethoscope​ ​attachment​ ​that​ ​can​ ​be​ ​added in-line​ ​to​ ​a​ ​clinician’s​ ​existing​ ​stethoscope​ ​that​ ​amplifies​ ​heart​ ​sounds​ ​and​ ​streams​ ​digitized phonocardiograms​ ​to​ ​a​ ​smartphone,​ ​tablet​ ​or​ ​personal​ ​computer.​ ​There,​ ​the​ ​signal​ ​can​ ​be analyzed​ ​with​ ​the​ ​decision​ ​support​ ​algorithm​ ​we​ ​will​ ​develop​ ​as​ ​part​ ​of​ ​this​ ​project.​ ​The​ ​specific aims​ ​of​ ​this​ ​study​ ​are​ ​(1)​ ​to​ ​​collect​ ​a​ ​database​ ​with​ ​condition-specific​ ​recording​ ​labels​ ​to enable​ ​deep​ ​learning​ ​for​ ​heart​ ​sounds​ ​though​ ​clinical​ ​data​ ​collection​ ​at​ ​UCSF​ ​and​ ​(2)​ ​to develop​ ​and​ ​evaluate​ ​a​ ​deep​ ​convolutional​ ​neural​ ​network-based​ ​algorithm​ ​trained​ ​on​ ​the database.​ ​By​ ​integrating​ ​this​ ​deep​ ​learning​ ​algorithm​ ​into​ ​Eko’s​ ​mobile​ ​and​ ​cloud​ ​software platform,​ ​currently​ ​used​ ​by​ ​clinicians​ ​at​ ​over​ ​700​ ​institutions​ ​worldwide,​ ​we​ ​anticipate​ ​this algorithm​ ​will​ ​enable​ ​more​ ​accurate​ ​screening​ ​for​ ​aortic​ ​stenosis,​ ​leading​ ​to​ ​earlier​ ​diagnosis and​ ​better​ ​patient​ ​outcomes. SBIR​ ​Project​ ​Narrative Valvular​ ​heart​ ​disease,​ ​and​ ​aortic​ ​stenosis​ ​in​ ​particular,​ ​are​ ​becoming​ ​increasingly​ ​prevalent manifestations​ ​of​ ​poor​ ​cardiovascular​ ​health​ ​in​ ​both​ ​the​ ​developed​ ​and​ ​developing​ ​world.​ ​A highly-accurate​ ​clinical​ ​decision​ ​support​ ​algorithm​ ​that​ ​is​ ​able​ ​to​ ​detect​ ​aortic​ ​stenosis​ ​will impact​ ​public​ ​health​ ​by​ ​reducing​ ​unnecessary​ ​referrals​ ​for​ ​echocardiography​ ​and​ ​promoting early​ ​and​ ​accurate​ ​diagnosis​ ​in​ ​underserved​ ​areas​ ​with​ ​limited​ ​access​ ​to​ ​subspecialty​ ​care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,9621223,R43HL144297,"['Address', 'Algorithms', 'Aortic Valve Stenosis', 'Area', 'Auscultation', 'Benign', 'Biological Neural Networks', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Data Collection', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Environment', 'Evaluation', 'FDA approved', 'Future', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Heart Abnormalities', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Hospitals', 'Human', 'Image', 'Imaging Techniques', 'Institution', 'Label', 'Learning', 'Medical Device', 'Medicare', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Monitor', 'Network-based', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physicians', 'Positioning Attribute', 'Public Health', 'Resources', 'Screening procedure', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Tablet Computer', 'Testing', 'Training', 'Weight', 'accurate diagnosis', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinically significant', 'cloud software', 'commercialization', 'cost', 'deep learning', 'deep neural network', 'diagnosis standard', 'digital', 'innovation', 'screening', 'speech recognition']",NHLBI,"EKO DEVICES, INC.",R43,2018,295881,-0.011242884712835787
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9592472,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Topical Corticosteroids', 'Translating', 'Transplantation', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2018,240000,0.01850240214301396
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9724174,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,24598,0.02979488515340594
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9526090,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,399482,0.02979488515340594
"Biomedical Image Analysis and Informatics The Biomedical Image Analysis and Services Section (BIRSS) is committed to providing computational and engineering expertise to a variety of clinical and biomedical informatics activities at NIH. Specifically, biomedical imaging research in PET, ultrasound, CT, MRI, microscopy, cancer research, and neural dysfunction have been supported extensively. To advance and empower scientific research in the NIH intramural program, CIT has developed and continues to enhance a sophisticated open source, platform-independent, n-dimensional, extensible image processing and visualization application. The MIPAV (Medical Image Processing Analysis and Visualization) (http://mipav.cit.nih.gov/) is an application that enables quantitative analysis and visualization of biomedical imaging modalities (from micro to macro) and is used by researchers at NIH and around the world. At NIH, MIPAV has been used to analyze anatomical structures in CT datasets, analysis of MRI datasets for NIMH, and has been used by NCI for the analysis of 2D and 3D microscopic samples.   In addition, BIRSS leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based system to support the collection and analysis of research studies and clinical trials, using a set of modular components that cover all stages of the research life cycle. And because BRICS is un-branded and not associated with a particular disease or organization, it can be efficiently custom-tailored for many research programs.  MIPAV's integrated set of biomedical imaging algorithms and its extensibility have been used by BIRSS to implement solutions to imaging problems in the NIH intramural research community dozens of times over.  To create custom workflows and solutions for intramural collaborators, BIRSS team members can build plug-ins that leverage the algorithms and tools in MIPAV to solve complex imaging research questions.  For example, BIRSS continues to develop a novel MIPAV plug-in as part of a collaboration with Dr. Hari Shroffs lab in the National Institute of Biomedical Imaging and Bioengineering (NIBIB) to untwist four-dimensional high-resolution microscopy images of the Caenorhabditis elegans nematode embryo throughout its development.  This plug-in used the image registration and visualization tools already developed by BIRSS for MIPAV, along with novel fiducial annotation and lattice warping tools, to allow the NIBIB researchers to annotate and regularize the C. elegans embryo data through its twitching phase of development, which has not previously been possible algorithmically.  This, in turn, allowed Dr. Shroffs group to investigate neurodevelopmental events in late embryogenesis and apply it to track the 3D positions of seam cell nuclei, neurons, and neurites in multiple elongating embryos. The detailed positional information obtained enabled NIBIB to develop a composite model showing movement of these cells and neurites in an 'average' worm embryo. The untwisting and cell tracking capabilities of this plug-in provides a foundation on which to catalog C. elegans neurodevelopment, allowing interrogation of developmental events in previously inaccessible periods of embryogenesis.  Accurate automatic organ segmentation is an important yet challenging task for medical image analysis.  Anatomical variability in shape and texture feature inhibits traditional segmentation methods from achieving high accuracies.    Machine learning has dominated the medical imaging research field in the past decade.  Initially, pioneer work with decent feature extraction and SVM based image classification achieves better results.  Later, learning based detection algorithm began to dominate the machine learning tools like boosting trees, random forest.   More recently the deep learning based Deep Convolutional Neural Networks (DCNNs) become the mainstream of the medical imaging research field for the past two years.   Using and enhancing the MIPAV application has allowed us to rapidly build the new machine learning component integral to the MIPAV software and is being used to support automated segmentation of the prostate.  BIRSS also leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based informatics system to support the collection and analysis of research studies and clinical trials. BRICS is un-branded and not associated with a particular disease or organization, therefore, it can be efficiently custom-tailored for many research programs. For example, in collaboration with the National Institute of Neurological Disorders and Stroke (NINDS), BIRSS has developed two informatics systems, using the BRICS system, in support of Traumatic Brain Injury (TBI)(http://fitbir.nih.gov/)research, the Parkinsons Disease Biomarker Program (PDBP) (http://pdbp.ninds.nih.gov/), as well as, collaborated with the National Eye Institute developed an informatics system for rare eye diseases, eyeGENE (https://eyegene.nih.gov/).  The TBI informatics system is called the Federal Interagency TBI Research (FITBIR) database to acknowledge the interagency participation and shared interests. FITBIR serves as a repository for TBI research, is supported by multiple federal agencies, and consolidates high quality, uniformly collected, and contemporary data that can be accessed and analyzed by scientific experts.  Over one million records have been uploaded to FITBIR thus far for 66,00 subjects enrolled in 105 different research studies. Currently there are 145 studies expected to contribute to FITBIR and the number of studies is growing every year. Within FITBIR are clinical outcome data and imaging data of which 36,000+ records are of imaging data (MRI, CT, PET and Diffusion) from 45,000+ individual subjects. A summary of the data can be found here: https://fitbir.nih.gov/content/submitted-data.  The goal of the PDBP, a BRICS system, is to support new and existing research and resource development promoting biomarker discovery for Parkinson's disease. Although our understanding of the biology and genetics associated with Parkinson's disease (PD) is advancing rapidly, gaps remain between promising laboratory discoveries and the realization of treatments that will cure or slow progression of PD. To address the needs of the PD community, NINDS has established the PDBP program focused on promoting the discovery of biomarker candidates for early detection and measurement of disease progression.  To date, the PDBP prospective consortium has 100% accrual at nine sites across the US with more than 1,600 enrolled subjects of which biorepository samples have been collected from 1,501 subjects. A summary of the data can be found here: https://pdbp.ninds.nih.gov/Data  The National Eye Institute (NEI) has also adopted the BRICS system to support The National Ophthalmic Disease Genotyping and Phenotyping Network (eyeGENE) (https://eyegene.nih.gov/). The eyeGENE project is a research venture created by NEI in response to promising scientific discoveries in genetics. eyeGENE aims to advance studies of eye diseases and their genetic causes by giving researchers access to DNA samples, clinical information, and patients looking to participate in research studies and clinical trials.  A summary of the data can be found here: https://eyegene.nih.gov/node/35. n/a",Biomedical Image Analysis and Informatics,9772045,ZIACT000272,"['Address', 'Adopted', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Biology', 'Biomedical Research', 'Caenorhabditis elegans', 'Catalogs', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Custom', 'DNA', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Embryo', 'Embryonic Development', 'Engineering', 'Enrollment', 'Event', 'Eye diseases', 'Foundations', 'Four-dimensional', 'Genetic', 'Genotype', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging problem', 'Individual', 'Informatics', 'Intramural Research', 'Intramural Research Program', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Measurement', 'Medical Imaging', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Nematoda', 'Neurites', 'Neuronal Dysfunction', 'Neurons', 'Online Systems', 'Organ', 'Outcome', 'Parkinson Disease', 'Patients', 'Phase', 'Phenotype', 'Plug-in', 'Positioning Attribute', 'Positron-Emission Tomography', 'Prostate', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resolution', 'Resource Development', 'Resources', 'Sampling', 'Services', 'Shapes', 'Site', 'Speed', 'System', 'Techniques', 'Texture', 'Time', 'Traumatic Brain Injury', 'Trees', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization software', 'Work', 'anticancer research', 'base', 'biobank', 'bioimaging', 'biomarker discovery', 'biomedical informatics', 'candidate marker', 'cell motility', 'clinical imaging', 'deep learning', 'forest', 'high dimensionality', 'image processing', 'image registration', 'image visualization', 'imaging informatics', 'imaging modality', 'informatics infrastructure', 'interest', 'member', 'microscopic imaging', 'n-dimensional', 'neurodevelopment', 'novel', 'open source', 'platform-independent', 'programs', 'prospective', 'repository', 'research and development', 'research study', 'response', 'tool', 'web-based informatics']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2018,1041664,0.0242944270777338
"30th Annual MR Angiography Meeting Project Summary The objective of the 30th Annual Workshop on Magnetic Resonance Angiography is to provide a forum for scientists and scientist-clinicians, clinical staff and industry interested in MR angiography techniques. The Workshop is the annual meeting of the Society for Magnetic Resonance Angiography (SMRA). At this meeting, emerging techniques and exciting new applications to visualize the vascular system, measure and display blood flow and improve patient outcomes will be presented. MR angiography is an important clinical tool that is applied to millions of patients annually and accounts for an estimated 10% of all MR procedures. Recent advances in time-resolved imaging, non-contrast imaging, post-processing techniques, flow measurements, and flow visualization, as well other innovations, continue to make MRA a dynamic, cutting-edge area of interest for scientific investigation. A major goal of this SMRA Workshop is to provide scientists, clinicians, and students with the opportunity to build connections, pool their knowledge, and educate each other in order to accelerate the refinement of MRA technology and critically how to apply it in clinical practice. Topics for the MRA Workshop will include: vascular disease mechanisms, vessel wall and plaque imaging, quantification of blood flow dynamics, machine learning including deep learning plus `Big Data', vessel lumen imaging, MRA of the brain, heart, abdomen, and extremities; contrast agents, cardiac MR, assessment of cardiac structure & function, clinical study design, new MRA techniques, interventional MRI, MRI of implanted devices, technology assessment, and comparing MRI with other medical imaging modalities. The 3-day workshop will be preceded by an informative one-day educational program that will include both fundamental and advanced lectures from international experts in the field. These topics and educational objectives of the 30th Annual Workshop on Magnetic Resonance Angiography are directly related to the NHLBI mission to provide global leadership for research, training, and education to promote the prevention and treatment of heart and blood diseases. The scientific presentations will include new discoveries about the causes of disease and as such contribute to the translation of basic discoveries into clinical practice. In addition, the proposed educational activities as well as discussion among participants will foster training and mentoring of emerging scientists and physicians. In this context, the workshop will support a collaborative research infrastructure, including participants from academic institutions and industry. Project Narrative This proposed “30th Annual Workshop on Magnetic Resonance Angiography” will provide a forum in which researchers and clinicians interested in MRA can build connections, pool their knowledge, and educate students and fellow scientists in order to further develop MRA technology and translate it into clinical practice.",30th Annual MR Angiography Meeting,9613125,R13HL144016,"['Abdomen', 'Angiography', 'Area', 'Award', 'Big Data', 'Biology', 'Blood flow', 'Brain', 'Cardiac', 'Catheters', 'Clinical', 'Clinical Research', 'Contrast Media', 'Development', 'Diagnostic Imaging', 'Disease', 'Educational Activities', 'Educational workshop', 'Engineering', 'Female', 'Fertilization', 'Fostering', 'Funding', 'Genetic Medicine', 'Genetics and Medicine', 'Goals', 'Growth', 'Heart', 'Heart Diseases', 'Hematological Disease', 'Image', 'Imagery', 'Industry', 'Institution', 'International', 'Intervention', 'Investigation', 'Ionizing radiation', 'Knowledge', 'Leadership', 'Limb structure', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Angiography', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Minority', 'Mission', 'Morphologic artifacts', 'National Heart, Lung, and Blood Institute', 'Oral', 'Organ', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Physics', 'Postdoctoral Fellow', 'Prevention', 'Procedures', 'Protocols documentation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Training', 'Scientist', 'Scotland', 'Secure', 'Societies', 'Standardization', 'Structure', 'Students', 'Techniques', 'Technology', 'Technology Assessment', 'Time', 'Tissue Viability', 'Training', 'Training and Education', 'Translating', 'Translational Research', 'Translations', 'Travel', 'Vascular Diseases', 'Vascular System', 'Venous', 'Woman', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'clinical application', 'clinical practice', 'collaborative environment', 'computer science', 'deep learning', 'imaging modality', 'implantable device', 'improved', 'innovation', 'interest', 'lectures', 'meetings', 'minority trainee', 'posters', 'programs', 'research and development', 'student participation', 'success', 'tool']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R13,2018,10000,0.007166283545394283
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9789424,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2018,293560,0.014043397962715838
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9633463,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2018,1583573,0.014043397962715838
"Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy Project Summary We propose to introduce and optimize a new method of radiomics extraction via transfer learning with deep convolutional neural networks (CNNs) and to compare it to the conventional segmentation-based radiomics approach on breast dynamic contrast-enhanced magnetic resonance images (DCE-MRIs). The field of breast radiomics has been expanding fast, with many clinical conclusions being successfully derived from medical images using qualitative analysis. In the past couple of years, deep learning has experienced explosive growth in image recognition, easily solving complex problems. Deep CNNs achieve remarkable classification results on everyday image datasets. We propose to investigate the utility of deep neural networks with regards to the medical image datasets, specifically on the breast DCE-MRI dataset. Given the relatively small sizes of these datasets, CNNs previously trained on non-medical images will be utilized for clinical classifications as feature extractors. We will investigate multiple parameters involved in the CNN feature extraction methodology and their effect on classification performance. Two clinical tasks will be studied under the proposed research: 1) malignancy assessment and 2) response to therapy prediction. The optimized CNN method will be compared to and combined with the conventional segmentation- based radiomics method. Furthermore, we aim to investigate the robustness of the segmentation-based features across MR scanners of different manufacturers. The first aim of the proposed research will study the robustness of the segmentation- based features extracted from images acquired on MR scanners of two different manufacturers. The robustness will be investigated under four clinical tasks, such as lymph node involvement and receptor statuses. The second aim will be focused on optimization of CNN feature extraction and subsequent classifier design. Lastly, under the third aim we will compare and combine the CNN and segmentation-based radiomics in the classification tasks of malignancy assessment and response to therapy prediction. Project Narrative The goal of the proposed research is to improve breast cancer diagnosis and prognosis based on dynamic contrast-enhanced magnetic resonance images by introducing novel deep learning methods to medical image classification and combining it with the conventional radiomics systems. The incredible power of deep learning methods to classify everyday images shows great promise to make predictions based on medical image datasets. Our thorough investigation of deep learning methods and their combination with conventional radiomics methods has potential to improve breast cancer management.",Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy,9469826,F31CA221193,"['Benign', 'Biological Neural Networks', 'Breast', 'Cancer Prognosis', 'Characteristics', 'Classification', 'Clinical', 'Complement', 'Complex', 'Computers', 'Data', 'Data Set', 'Effectiveness', 'Evaluation', 'Goals', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intuition', 'Investigation', 'Lesion', 'Lymph Node Involvement', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical Imaging', 'Methodology', 'Methods', 'Nature', 'Neoadjuvant Therapy', 'Performance', 'Prediction of Response to Therapy', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Research', 'Standardization', 'System', 'Techniques', 'Training', 'Variant', 'base', 'breast cancer diagnosis', 'chemotherapy', 'computerized', 'contrast enhanced', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'learning strategy', 'malignant breast neoplasm', 'novel', 'radiomics', 'receptor', 'response']",NCI,UNIVERSITY OF CHICAGO,F31,2018,26048,-0.06732461975635402
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. Narrative There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9680657,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'professional atmosphere', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,449918,0.028538365350543913
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9496652,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2018,425994,0.020958841551139588
"Prospective Slice Tracking for Cardiac MRI Project Summary/Abstract Cardiac Magnetic Resonance (CMR) provides arguably the most comprehensive evaluation of the cardiovascular system; however, respiratory motion continues to adversely impact CMR, causing artifacts that lead to poor image quality, repeated scans, and decreased throughput, and thus represents a significant obstacle to clinical utility. For single-shot CMR, cardiac and breathing motions are “frozen” by limiting the acquisition to an end-diastolic window less than 200 ms. For first pass perfusion, breathing motion cannot be eliminated because data from 50 to 60 consecutive heartbeats are required to capture contrast dynamics. For other single-shot applications such as late gadolinium enhancement (LGE) and parameter mapping, respiratory motion is introduced when the acquisition is repeated across several heartbeats to improve spatial and temporal resolution. To eliminate respiratory motion from single-shot images, non-rigid motion correction (MOCO) has been promoted as an attractive option that provides 100% acquisition efficiently. MOCO can be used either after the reconstruction or during the reconstruction. Such techniques, however, cannot account for through-plane motion, which can only be corrected prospectively, and can fail depending on image quality and the extent of motion. Prospective compensation of the respiratory motion has been recognized as an attractive alternative to existing gating and MOCO methods. Proposed methods use one or more navigator echoes—incompatible with or inefficient for many CMR protocols—to capture the respiratory motion and rely on simple parametric models that are inadequate to describe complex respiratory-induced cardiac motion. Due to these limitations, prospective methods have found limited applicability even in research settings. We propose a new framework to prospectively compensate respiratory motion. The proposed method, called PROspective Motion compensation using Pilot Tone (PROMPT), employs Pilot Tone technology and leverages machine learning principles to first learn complex respiratory-induced cardiac motion on a patient-specific basis and then prospectively compensate the motion by tracking the imaging plane, in real time, as a function of a Pilot Tone based respiratory signal. If successful, this synergistic combination of Pilot Tone and machine learning will lead to 100% efficiency for single-shot CMR exams performed under free-breathing conditions, will eliminate the need to setup navigator echoes, respiratory bellows, or other inefficient prospective gating measures, will minimize through-plane motion that can render the images non-diagnostic for CMR applications including fast-pass perfusion, parameter mapping, LGE, and coronary angiography, will provide a reliable surrogate measure of respiratory motion, and will facilitate highly accelerated compressive recovery. Project Narrative Magnetic Resonance Imaging (MRI) has many potential advantages over currently used imaging methods to diagnose heart disease, but MRI images can be ruined if the patient breathes during the scan. In this project, we will develop a method that is insensitive to breathing motion and compare it to existing methods. These efforts should lead to significant improvements in diagnosis of heart disease so that patients may benefit from appropriate treatment.",Prospective Slice Tracking for Cardiac MRI,9587091,R21EB026657,"['Anatomy', 'Breathing', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Complex', 'Coronary Angiography', 'Data', 'Dependence', 'Diagnosis', 'Evaluation', 'Financial compensation', 'Freezing', 'Gadolinium', 'Heart Diseases', 'Image', 'Imaging Techniques', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Patients', 'Perfusion', 'Positioning Attribute', 'Protocols documentation', 'Recovery', 'Research', 'Resolution', 'Respiration', 'Scanning', 'Signal Transduction', 'Slice', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'artificial neural network', 'base', 'computerized data processing', 'data acquisition', 'healthy volunteer', 'heart motion', 'imaging modality', 'improved', 'prospective', 'reconstruction', 'respiratory', 'technology development', 'temporal measurement', 'volunteer']",NIBIB,OHIO STATE UNIVERSITY,R21,2018,185264,0.0312936218435676
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9669491,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2018,252169,0.005723536890931616
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9640372,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'comparative effectiveness', 'cost', 'deep learning', 'diagnosis standard', 'effectiveness research', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2018,347584,0.007853820925514648
"2018 Image Science Gordon Research Conference & Gordon Research Seminar Project Summary: The proposal requests support for early-career investigators to attend the 2018 Gordon Research Conference on Image Science. The unique feature of this conference in its third offering compared with others in medical imaging is the bringing together of renown speakers from disparate application areas, including astronomy, biology, medicine, remote sensing, and security and defense industries, in a forum that encourages each to describe their greatest challenges and most promising solutions. All speakers are invited based on their leadership in their field and their willingness to debate fundamental issues shared by everyone developing, evaluating, and applying imaging in medicine and biology. We believe the GRC format placed in the context of a small-college venue promotes the type of innovative interdisciplinary thinking that leads to breakthroughs. An environment where leading senior scientists debate core issues is valuable to young investigators trying to build successful independent careers in medical imaging in industry and academia. All attendees are invited to present a poster describing their research in poster sessions that are a key element of the Gordon Conference format. The June 17-22, 2018 GRC conference theme is “Image Science: Creating Knowledge from Information,” which is focused on appropriate acquisition and efficient uses of the massive volume of imaging information now collected from patients. Speakers give 40 minutes presentations in a single-track format with 20 minute discussions following each presentation that are led by experts in the field. Topic range from “Imaging in Brain Science Discovery” to “Advanced Machine Learning” and “Computational Imaging.” At the center of each presentation is a discussion of the core challenges shared by image scientists and novel techniques for acquiring and displaying information in a manner that maximizes decision performance. Given the success of the previous meeting, we will hold the first-ever, student-run Gordon Research Seminars (GRS) on Image Science June 16, 17, 2018. Our aim is to build Image Science as an independent field of study through detailed interdisciplinary discussions and by fostering the success of a new generation of image scientists. Project Narrative: Solutions to very difficult problems often emerge from discussions among experts in different fields of study being challenged by the same core problems. The 2018 GRC on Imaging Science strives to build a community of problem solvers by creating an environment for detailed discussions among senior investigators that involves young investigators at a time when they are building careers. This is a proposal to fund young investigators to attend the conference.",2018 Image Science Gordon Research Conference & Gordon Research Seminar,9461211,R13EB025662,"['Academia', 'Area', 'Astronomy', 'Big Data', 'Biology', 'Brain', 'Collaborations', 'Communities', 'Computational Science', 'Data', 'Data Analytics', 'Development', 'Disabled Persons', 'Discipline', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Fees', 'Female', 'Financial Support', 'Fostering', 'Funding', 'Housing', 'Human', 'Image', 'Industry', 'Information Sciences', 'Interdisciplinary Study', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Minority', 'Modeling', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Recruitment Activity', 'Request for Proposals', 'Research', 'Research Personnel', 'Resource Development', 'Risk-Taking', 'Role', 'Running', 'Science', 'Scientist', 'Security', 'Senior Scientist', 'Series', 'Societies', 'Source', 'Statistical Models', 'Students', 'Systems Development', 'Techniques', 'Thinking', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'career', 'college', 'cost', 'design', 'disabled students', 'educational atmosphere', 'field study', 'frontier', 'graduate student', 'image reconstruction', 'imaging scientist', 'imaging system', 'information display', 'innovation', 'instrument', 'meetings', 'minority student', 'multidisciplinary', 'next generation', 'novel', 'posters', 'preference', 'remote sensing', 'skills', 'success', 'symposium', 'training opportunity', 'virtual', 'willingness']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,10000,0.013421670784311675
"2018 International Molecular and Functional Pulmonary Imaging Workshop SUMMARY This application requests funding to support the 2018 International Workshop on Pulmonary Imaging, a three- day meeting scheduled for December 6-8, 2018, which will be the sixth of its kind hosted by the University of Pennsylvania. The requested funds will primarily be used to cover travel and housing expenses for undergraduate, graduate and junior faculty speakers. Some may also be used to support live webcasting and publication of the workshop proceedings. As in the past, it is our intention to broadcast each session of the meeting online in real-time, enabling interested parties who cannot physically attend to access them free of charge. Pulmonary diseases constitute a significant and rising cause of morbidity and mortality worldwide, and imaging is becoming an increasingly important source of innovative techniques for both diagnosing and treating these pathologies. The field of pulmonary imaging currently encompasses a wider range of techniques for the functional, structural and molecular assessment of lung disorders than ever before, which are being developed and refined by investigators across a diverse set of fields such as biology, physics, chemistry, medicine and engineering, computer science and machine learning. Given the rapidly-developing nature of the pulmonary imaging field, it is of the utmost importance that a regular forum exists for scientists and clinicians to communicate and debate their ideas with one another. In the absence of other meetings with a similar focus, our previous workshops have provided such a forum, bringing together the diverse components of the field into the kind of rigorous, focused exchange needed to advance the field. The specific aims of the proposed workshop are as follows: (1) keep the pulmonary imaging community informed about the latest developments in structural, functional and molecular lung imaging; (2) examine the use of pulmonary imaging to assess therapeutic response, including strategies for overcoming the challenges inherent in this objective; (3) explore the integration of machine learning with pulmonary imaging techniques to more accurately phenotype disease and predict injury progression; (4) broadcast the entire proceedings live over the web, allowing non-attendees to freely access the proceedings, and enabling the online audience to participate in workshop discussions in real-time. Based on feedback from participants that previous meetings tended to be overly dense and predominantly didactic in nature, we have also implemented a significant format change for proposed 2018 meeting. With the exception of a few keynote presentations, we plan to limit the percentage of formal lecture in each invited speaker’s talk to one-third of their allotted time, with the rest dedicated to a period of discussion that will be driven by a panel of moderators as well as audience questions. For each presentation, the moderators will prepare a list of questions focusing on three main points: 1) the translatability of the research being presented, 2) the scientific gap which this research aims to address, and 3) the necessity of identifying lung disorders that are suitable for longitudinal studies, as well as which imaging parameters are best suited to the longitudinal study of lung disease. In addition to this change in format, the 2018 workshop will continue efforts to strike a more even balance between functional, structural and molecular imaging approaches to pulmonary disease. Finally, we will also continue to foreground the important issue of using imaging techniques to assess treatment response, which was first introduced at the 2017 pulmonary imaging workshop. NARRATIVE This application requests funding to support the 2018 International Workshop on Pulmonary Imaging at the University of Pennsylvania. The proposed meeting will provide a valuable opportunity for researchers engaged in the development of functional, structural, and molecular imaging techniques for assessing lung diseases—such as COPD, ARDS, IPF and lung cancer—to meet and discuss their work with one another. The entirety of the workshop will be broadcast live online, giving interested individuals who are not able to attend in person the ability to both view and participate in its proceedings.",2018 International Molecular and Functional Pulmonary Imaging Workshop,9613494,R13HL144010,"['Address', 'Adult Respiratory Distress Syndrome', 'Anatomy', 'Area', 'Biology', 'Charge', 'Chemistry', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Data', 'Development', 'Diagnosis', 'Disease Progression', 'Educational workshop', 'Engineering', 'Equilibrium', 'Faculty', 'Feedback', 'Fostering', 'Functional Imaging', 'Funding', 'Future', 'Gases', 'Heart', 'Housing', 'Image', 'Imaging Techniques', 'Individual', 'Injury', 'Intention', 'International', 'Internet', 'Learning', 'Location', 'Longitudinal Studies', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant neoplasm of lung', 'Medicine', 'Metabolic', 'Molecular', 'Morbidity - disease rate', 'Movement', 'Nature', 'Participant', 'Pathology', 'Pennsylvania', 'Persons', 'Phenotype', 'Physics', 'Physiological', 'Physiology', 'Positron-Emission Tomography', 'Postdoctoral Fellow', 'Protons', 'Public Health', 'Publications', 'Pulmonology', 'Radiology Specialty', 'Request for Applications', 'Research', 'Research Personnel', 'Rest', 'Schedule', 'Scientist', 'Source', 'Students', 'Techniques', 'Time', 'Travel', 'Universities', 'Work', 'base', 'computer science', 'density', 'disease phenotype', 'imaging approach', 'imaging biomarker', 'improved', 'innovation', 'interest', 'lectures', 'lung imaging', 'meetings', 'molecular imaging', 'mortality', 'non-invasive imaging', 'novel', 'patient response', 'single photon emission computed tomography', 'treatment response', 'undergraduate student']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R13,2018,29805,-0.0023019324401398356
"2018 OSA Topical Meetings: Optical Tomography and Spectroscopy; and Microscopy, Histopathology and Analytics. Discussing New Research in Biomedical Imaging and Bioengineering. FOA: PA-16-294 Opportunity Title: NIH Support for Conferences and Scientific Meetings (R13/U13) Agency: NIH - NIBIB Proposal Title: 2018 OSA Topical Meetings: Optical Tomography and Spectroscopy; and  Microscopy, Histopathology and Analytics. Discussing New Research in  Biomedical Imaging and Bioengineering Principal Investigator: Gregory J. Quarles, Ph.D., Chief Scientist, The Optical Society  2010 Massachusetts Ave, NW, Washington, DC  gquarles@osa.org, 202-416-1954 Project Summary /Abstract:  The 2018 OSA Biophotonics Congress: Biomedical Optics, 3-6 April 2018, Hollywood, FL, consists of four topical meetings. Two of these meetings, Optical Tomography and Spectroscopy (OTS) and Microscopy, Histopathology and Analytics (Microscopy) provide broad exposure to a very active multidisciplinary field in biomedical imaging and bioengineering focused on illness treatment and health enhancement. The interdisciplinary nature of the co- located meetings will provide cross-fertilization of concepts and techniques between fields with the resulting synergies obtained from such interactions. This proposal is to provide registration and travel support for students and early career professionals presenting at one of these topical meetings.  OTS will focus on new developments in diffuse optics, spectroscopy and other non- invasive tomographic imaging approaches, including the fields of diffuse optical tomography (DOT), photoacoustic tomography (PAT), optical coherence tomography (OCT), wavefront engineering to overcome scattering, as well as new developments in spectroscopic technologies.  Microscopy will include topics central to the development of optical microscopy and in vitro optical sensing for the clinic. Areas such as novel optical approaches, including computational optics, new image processing and segmentation techniques, development of decision-assistance algorithms via machine-learning and other strategies, testing technologies in pre-clinical models, applications to clinical samples, and validation in the clinic will be discussed. Optically enabled microfluidics are included in this track as well. The goal of these efforts should be towards clinical translation.  The general purpose of these meetings is to create an inclusive, open forum for the presentation of high-quality scientific research through plenary and technical sessions, short courses, panels, networking and special events. This method of face-to-face information sharing allows researchers to learn what others in their field and related disciplines are doing and to efficiently learn about new research, tools, and techniques that might be relevant to their work. It allows conversations with colleagues from different institutions around the world and engenders far reaching scientific collaborations – both domestic and international. FOA: PA-16-294 Opportunity Title: NIH Support for Conferences and Scientific Meetings (R13/U13) Agency: NIH - NIBIB Proposal Title: 2018 OSA Topical Meetings: Optical Tomography and Spectroscopy; and  Microscopy, Histopathology and Analytics. Discussing New Research in  Biomedical Imaging and Bioengineering. Principal Investigator: Gregory J. Quarles, Ph.D., Chief Scientist, The Optical Society  2010 Massachusetts Ave, NW, Washington, DC  gquarles@osa.org, 202-416-1954 Project Narrative The 2018 OSA Optical Tomography and Spectroscopy; and Microscopy, Histopathology and Analytics Topical Meetings will discuss important, highly interdisciplinary areas that focus on technological solutions to medical challenges and medical applications, and will cover a diversity of cutting-edge research and innovative new tools and techniques, especially in biomedical imaging and bioengineering. These Topical Meetings will bring together researchers working in all aspects of this field and will serve as a forum for discussion of existing and emerging techniques as well as future directions.","2018 OSA Topical Meetings: Optical Tomography and Spectroscopy; and Microscopy, Histopathology and Analytics. Discussing New Research in Biomedical Imaging and Bioengineering.",9543795,R13EB026325,"['Academic Training', 'Algorithms', 'Area', 'Biomedical Engineering', 'Biophotonics', 'Birds', 'Career Mobility', 'Clinic', 'Clinical', 'Collaborations', 'Congresses', 'Development', 'Diffuse', 'Digital Libraries', 'Discipline', 'Doctor of Philosophy', 'Engineering', 'Ensure', 'Event', 'Exhibits', 'Exposure to', 'Fertilization', 'Fostering', 'Future', 'Goals', 'Grant', 'Health', 'Hearing', 'Histopathology', 'In Vitro', 'Industry', 'Institution', 'International', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Massachusetts', 'Medical', 'Methods', 'Microfluidics', 'Microscopy', 'National Institute of Biomedical Imaging and Bioengineering', 'Nature', 'Optical Coherence Tomography', 'Optical Tomography', 'Optics', 'Outcome', 'Paper', 'Participant', 'Peer Review', 'Physicians', 'Pre-Clinical Model', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scientist', 'Services', 'Societies', 'Special Event', 'Spectrum Analysis', 'Students', 'Techniques', 'Technology', 'Testing', 'Time', 'Translating', 'Travel', 'Underrepresented Minority', 'United States National Institutes of Health', 'Validation', 'Washington', 'Work', 'academic standard', 'base', 'bioimaging', 'career', 'clinical application', 'clinical translation', 'diffuse optical tomography', 'graduate student', 'image processing', 'imaging Segmentation', 'imaging approach', 'indexing', 'innovation', 'meetings', 'multidisciplinary', 'novel', 'optoacoustic tomography', 'posters', 'programs', 'symposium', 'synergism', 'technique development', 'tomography', 'tool']",NIBIB,OPTICAL SOCIETY OF AMERICA,R13,2018,10000,-0.0015029665472756997
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9616697,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2018,29442,0.005584209991568385
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9616697,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2018,514000,0.005584209991568385
"Advanced Medical Image Reconstruction Background 	 Medical imaging plays a major role in the diagnosis and treatment of cardiovascular disease. The process of generating a medical image consists of two parts; data acquisition and image reconstruction. Image reconstruction transforms the acquired raw data signals into images that can be interpreted by clinician to aid in the diagnosis of a disease or used to guide a procedure. The raw data is frequently corrupted by instrument imperfections and patient motion. It is also common for datasets to be incomplete since there is a limited amount of time or other patient exposure available for data acquisition. Consequently, modern image reconstruction software is fairly complex. The source code for these complex image reconstruction algorithms is most often proprietary information retained by the system vendors and scientists working in the field of medical image reconstructions are forced to implement their own versions of existing algorithms that they then build on and improve. Because of this reimplementation and lack of open standards, many of the published literature on medical image reconstruction is not reproducible. The overarching goal of this project is to develop novel advanced image reconstruction algorithms and to do that in such a way that other scientists (and system vendors) can reproduce the presented results and use the methods in future work. The Laboratory of Imaging Technology, NHLBI, is particularly focused on Magnetic Resonance Imaging (MRI) techniques, but the developed principles apply to other techniques as well.   Goals/Objectives  The Laboratory of Imaging Technology develops and maintains two major software packages that support ongoing research projects. The first is the ISMRM Raw Data format (https://ismrmrd.github.io), which is an open raw data standard for MR experiments. It is a requirement for sharing algorithms and methods that there is common understanding of how to describe the raw data and this package provides a framework for this. We also aim to maintain data conversion tools from major device manufacturers proprietary formats to this vendor-independent format. The second software package is the Gadgetron (https://gadgetron.github.io), which is an advanced image reconstruction package that contains toolboxes and a streaming pipeline architecture for processing the raw data that is acquired by the imaging instrument. We aim to expand this software package and support the growing user base around the world. There are a number of technical innovations that we are currently pursuing:   -	Expansion of the ISMRMRD format to include waveforms and telemetry from other instruments -	Formal definition and implementation of ISMRMRD communication protocol -	The use of cloud computing for MRI reconstruction  -	MRI raw data compression  -	Correction of measurement system imperfections -	Tight integration of the Gadgetron with specific vendor instruments  In addition to these infrastructure goals, we are developing and testing new imaging reconstruction techniques to solve specific clinical questions:   -	Real-time imaging sequences for interventional MRI  -	Real-time measurements of blood flow -	Motion corrected, free-breathing techniques for measuring cardiac function and parametric maps.   -	Quantitative assessment of myocardial perfusion   Progress in fiscal year 2018  In the past year, significant progress has been made on the integration of machine learning into the Gadgetron framework. This is motivated by the increasing demand for machine learning algorithms in image reconstruction and processing. A framework for network training and application has been integrated into the Gadgetron infrastructure and tested for processing tasks. This integration will enable fast prototyping of new algorithms and easy deployment in the clinical research environment.   As we move to non-Cartesian imaging for an increasing number of applications, we have initiated the development of a generic reconstruction pipeline for non-Cartesian imaging. This pipeline is intended to be flexible such that a variety of acquisition types can be managed by the infrastructure. This includes the correction of system imperfections and management of physiological information for functional scans.  The next generation of the ISMRM raw data format has been developed and tested. This new format extends the definition of the data format and enables simultaneous streaming of MRI raw data with other relevant waveforms, including physiological and system data. Access to these data will expand the capabilities of our reconstruction platform, the Gadgetron.    Our cloud deployments of the Gadgetron have been frequently updated to include new features. The cloud based reconstruction platform is used by our collaborators for clinical applications that demand high-performance computing.   We continue to work with the MRI community more broadly on both the Gadgetron and ISMRM Raw Data software packages. n/a",Advanced Medical Image Reconstruction,9787981,ZIAHL006214,"['Algorithms', 'Architecture', 'Breathing', 'Cardiovascular Diseases', 'Clinical', 'Clinical Research', 'Cloud Computing', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Compression', 'Data Set', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Disease', 'Environment', 'Future', 'Generic Drugs', 'Goals', 'High Performance Computing', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Laboratories', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Maps', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modernization', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Heart, Lung, and Blood Institute', 'Patients', 'Physiological', 'Play', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Role', 'Scanning', 'Scientist', 'Signal Transduction', 'Source Code', 'Stream', 'System', 'Techniques', 'Telemetry', 'Testing', 'Time', 'Training', 'Update', 'Vendor', 'Work', 'algorithmic methodologies', 'base', 'blood flow measurement', 'clinical application', 'cloud based', 'correctional system', 'data acquisition', 'data format', 'experimental study', 'flexibility', 'heart function', 'image processing', 'image reconstruction', 'improved', 'innovation', 'instrument', 'next generation', 'novel', 'open source', 'prototype', 'quantitative imaging', 'reconstruction', 'research study', 'temporal measurement', 'tool']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIA,2018,23608,0.05190722652158009
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment Project Summary NIH is increasing its investment in large mutli-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several open-source software systems. For example, the NIH NIAAA and BD2K funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements that called for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for multi-site QC workflows as that would require a unified platform, design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that supports simplified creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific findings findable, accessible, interoperable, and reusable.  Specifically, our multi-site open-source software platform for Medical Image Quality Assurance (mIQa) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system, machine learning to aid in QC process, and an interactive electronic notebook platform. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automating notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, mIQa is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop multi-site, open-source software for Medical Image Quality Assurance (mIQa) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. mIQa will enable efficient and accurate QC processing by levering open-source, state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive review and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment,9622218,R43MH119022,"['Active Learning', 'Address', 'Adolescence', 'Alcohols', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Sources', 'Development', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Environment', 'Evaluation', 'FAIR principles', 'Four-dimensional', 'Funding', 'Geography', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'International', 'Internet', 'Investments', 'Label', 'Libraries', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical', 'Medical Imaging', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Visual', 'Work', 'Writing', 'application programming interface', 'base', 'cohesion', 'cost', 'dashboard', 'data access', 'data management', 'design', 'experience', 'flexibility', 'image archival system', 'imaging study', 'improved', 'innovation', 'member', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'prototype', 'quality assurance', 'research study', 'software systems', 'success', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R43,2018,225001,0.028359000222130976
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Supplement Title: Deep learning-based methods for PET image reconstruction and segmentation to enhance radionuclide therapy dosimetry Abstract There is much recent interest in quantitative imaging of yttrium-90 (Y-90) for dosimetry because of the promise of novel Y-90 labelled radionuclide therapies. Deep learning methods are well suited for addressing the challenges of Y-90 positron emission tomography (PET) imaging, where compared with diagnostic FDG PET, true coincidence count-rates are very low while random coincidences are high. The potential of deep learning-based algorithms to outperform conventional algorithms in medical imaging is well recognized, however research in applying these methods to nuclear medicine imaging modalities such as PET is very limited. The few studies applying deep learning to PET imaging have been mostly limited to post-reconstruction image processing/analysis for denoising and feature extraction, and not in the image formation/reconstruction process. Additionally, deep learning research in PET thus far have focused on improving diagnostic imaging, not quantitative imaging, which together with accurate lesion/organ segmentation are pre-requisite for accurate dosimetry. In this supplement, we propose to develop and evaluate deep learning-based image reconstruction and lesion/organ segmentation for low count PET applications such as Y-90 PET. Our approach starts with the raw projection data and utilizes a deep recurrent network in the image formation process. Because the two tasks are mutually dependent, our formalism takes the novel approach of joint reconstruction-segmentation with multi-modality (PET/CT) data. Specifically, we will 1) develop and evaluate Y-90 PET image reconstruction with a deep recurrent network for the regularizer, 2) develop and evaluate deep-learning based joint PET segmentation-reconstruction using multi- modal 90Y PET/CT data. To train/validate/test the proposed methods, we will use clinically realistic phantom measurements and simulations as well as leverage on existing patient data from the parent grant where thus far, PET data and radiologist defined morphologic liver/lesion contours for over 50 cases and 150 lesions are available. We will compare the new Y-90 PET reconstruction with the formulation we recently developed under the parent grant (using conventional untrained regularizers) that showed promising results but suffered from resolution- noise tradeoff. The expected outcome of this work is a well validated deep learning reconstruction- segmentation framework for challenging PET imaging applications where conventional methods are suboptimal. The proposed research is expected to result in new and accurate tools for quantitative image reconstruction and lesion/organ segmentation that have the potential to contribute significantly toward improving dosimetry in internal radionuclide therapy such as Yttrium- 90 radioembolization in liver malignancies. This study is relevant to public health because a dosimetry-guided personalized approach to radionuclide therapy is highly likely to substantially improve patient outcomes compared to current standard practice. !",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,9750430,R01EB022075,"['90Y', 'Address', 'Algorithms', 'Clinical', 'Data', 'Diagnostic', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Formulation', 'Image', 'Joint repair', 'Joints', 'Label', 'Lesion', 'Liver', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Morphology', 'Noise', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Positron-Emission Tomography', 'Process', 'Public Health', 'Radioembolization', 'Radionuclide therapy', 'Recurrence', 'Research', 'Resolution', 'Testing', 'Training', 'Work', 'base', 'deep learning', 'dosimetry', 'image processing', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'interest', 'learning strategy', 'novel', 'novel strategies', 'parent grant', 'personalized approach', 'personalized cancer therapy', 'quantitative imaging', 'radiologist', 'reconstruction', 'simulation', 'tool']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,102093,0.03884998503569149
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9414991,R01CA193730,"['Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modality', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'primary endpoint', 'public health relevance', 'quality assurance', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2018,354198,-0.010717456739707604
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,444363,0.02229960032088547
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,100000,0.02229960032088547
"Augmented reality visualization for intraoperative guidance based on fluorescence lifetime Project summary/Abstract Optical imaging techniques have demonstrated potential to delineate tumor margins in vivo during surgery as they can rapidly characterize structural, biochemical or functional properties of tissue. Implementation in clinical practice demands rapid visualization and augmentation of imaging data but is often limited by the difficulty in dynamic registration, slow image reconstruction, lack of real- time ability or the need for contrast agents. The goal of this proposal is to implement the recently released Microsoft HoloLens with fiber-based imaging techniques to dynamically augment tissue characteristics directly on the interrogated area in the surgeon’s field of view. The specific aims of this proposal are as follows: (1) To realize a prototype of the augmented reality visualization platform and to combine it with our fluorescence lifetime imaging (FLIm) system, implement a user interface for a convenient interaction with the device. (2) To evaluate and optimize the scanning resolution and the registration precision using fluorescence phantoms and demonstrate the system in vivo for ten patients undergoing lumpectomy surgery. A current pilot study has demonstrated the potential of FLIm to localize tumor margins on excised breast specimen. The acquired in vivo data will help to systematically analyze differences between ex vivo and in vivo fluorescence decay signatures and provide initial data for a large-scale study that will be necessary to delineate tumor margins in vivo. The innovation of this proposal is that it will realize an augmented reality visualization platform for FLIm and other fiber based optical imaging modalities providing dynamic (continuous) augmentation of tissue properties directly on the interrogated area (surgeon’s field of view) in real-time without requiring the injection of contrast agents. The successful completion of this work has consequently the potential for significant impact in the field of surgical navigation. Project narrative This project seeks to realize an augmented and mixed reality visualization based on autofluorescence lifetime and any other fiber-based imaging technique for surgical navigation. The proposed research is consequently relevant to public health as it constitutes a critical part of surgical workflow to enable surgeon finding specific targets, avoiding areas of risk, and providing intraoperative orientation leading to higher resection precision and less interruptions in the surgical workflow.",Augmented reality visualization for intraoperative guidance based on fluorescence lifetime,9585701,R03EB026819,"['Achievement', 'Address', 'Algorithms', 'Anatomy', 'Area', 'Augmented Reality', 'Biochemical', 'Breast', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Research', 'Communication', 'Computer Vision Systems', 'Computer software', 'Contrast Media', 'Data', 'Devices', 'Excision', 'Fiber', 'Fiber Optics', 'Fluorescence', 'Goals', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Techniques', 'In Situ', 'Injections', 'Interruption', 'Intuition', 'Laboratories', 'Machine Learning', 'Mammary Neoplasms', 'Measurement', 'Medical Imaging', 'Modification', 'Near-infrared optical imaging', 'Operating Rooms', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Pilot Projects', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Process', 'Property', 'Protocols documentation', 'Public Health', 'Research', 'Research Infrastructure', 'Resolution', 'Risk', 'Scanning', 'Specimen', 'Stains', 'Surgeon', 'Surgical margins', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'breast lumpectomy', 'cancer therapy', 'clinical practice', 'design', 'design and construction', 'fluorescence lifetime imaging', 'human subject', 'image processing', 'image reconstruction', 'imaging modality', 'imaging system', 'improved outcome', 'in vivo', 'innovation', 'optical imaging', 'prototype', 'tumor']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2018,62883,-0.03743349793218702
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9536759,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,619539,0.012686012897553426
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9525950,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,333515,0.016505465945273818
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9476341,R01HL122484,"['3D ultrasound', '4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Discipline of Nuclear Medicine', 'Dose', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radiation exposure', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical imaging', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging approach', 'imaging modality', 'improved', 'individual patient', 'interest', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2018,770494,0.04630148028577662
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this SBIR project, we present EyeMark, a set of advanced image analysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we will develop tools for computation of microaneurysm (MA) ap- pearance and disappearance rates (jointly known as turnover rates) for use as a bi- omarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high positive influ- ence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a MA turnover computation prototype tool that ro- bustly registers longitudinal images (even with multiple lesion changes) and effectively detects DR lesions (lesion level AUROC>=0.95). The tool provides graceful degradation to confounding image factors by reporting MA turnover as a range, thereby capturing the inherent confidence in MA detection. By the end of Phase IIB we will develop a market ready, clinically validated end-to-end desktop software for robust, automated longitudinal lesion analysis and characterization that can work on the cloud to produce results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,9622980,R44TR000377,"['Adult', 'Age', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Biometry', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Color', 'Communication', 'Computer Vision Systems', 'Computer software', 'County', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Early identification', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Joints', 'Lesion', 'Los Angeles', 'Machine Learning', 'Measures', 'Medicine', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Patients', 'Pattern Recognition', 'Pear', 'Performance', 'Phase', 'Picture Archiving and Communication System', 'Process', 'Protocols documentation', 'ROC Curve', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Retrieval', 'Risk', 'Sampling', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'application programming interface', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'computerized', 'computerized tools', 'deep neural network', 'design', 'diabetic patient', 'digital imaging', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'high throughput analysis', 'image registration', 'improved', 'interest', 'longitudinal analysis', 'macula', 'medical schools', 'novel marker', 'novel therapeutics', 'prevent', 'programs', 'prototype', 'response', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability', 'validation studies']",NCATS,"EYENUK, INC.",R44,2018,750000,0.0009870692973666631
"2018 In Vivo Magnetic Resonance Gordon Research Conference & Gordon Research Seminar PROJECT SUMMARY  The field of magnetic resonance (MR) is in the midst of a revolution. Disruptive external forces, such as the advent of powerful new Artificial Intelligence methods, coupled with a recent creative ferment in method development within the field, is changing the way we think about the acquisition, the reconstruction, and the interpretation of MR data. Meanwhile, MR has long been an indispensable tool not only for basic discovery but also for medical diagnostics, but the value proposition of clinical MR imaging is also changing, against the backdrop of a shifting healthcare landscape.  There is a palpable need to explore the full scope of these changes, in a forum that enables deep dives and focused discussion, without losing the necessary breath of perspective. While large meetings such as the annual scientific meeting of the International Society for Magnetic Resonance in Medicine (ISMRM) have the necessary breath, the sheer size and pace of such meetings work against the requisite focus. On the other hand, short focused workshops are better suited to the evaluation of progress in well-defined subfields.  The goal of this grant application is to support a high-impact conference with a time-tested format which is ideally suited to assess recent changes in the field of in vivo MR. The tenth Gordon Research Conference (GRC) on In Vivo Magnetic Resonance will be held July 15 to 20, 2018, at Proctor Academy, in Andover, NH. Our GRC will also be associated with the first-ever trainee-organized and trainee-focused Gordon Research Seminar (GRS) on In Vivo Magnetic Resonance, which will take place on the weekend before the GRC (July 14-15, 2018). The trainee seminar meshes well with our goal of preparing young scientists for a changing field and a changing world. We request funding to support graduate students and postdoctoral fellows attending these meetings, which will focus explicitly on the shifting role of MR in a rapidly changing world.  The GRC, subtitled “Challenging assumptions about MR technology and applications in a changing world,” will be led by Chair Daniel K. Sodickson, MD, PhD, and Vice Chair Jeff F. Dunn, PhD, and will build upon a rich history of In Vivo MR GRCs. The GRS, subtitled “The Changing World of Magnetic Resonance: Old Physics, New Techniques,” will be led by Chair Scott Beeman, PhD, and Vice Chair Carson Hoffman, BSc, and will further enhance the experience of trainees with tailored opportunities for mentorship, networking, and scientific exchange.  Specific aims of our 2018 GRC and GRS on In Vivo MR are as follows:  1. Explore disruptive forces and marshal disruptive innovation in the field of in vivo MR  2. Foster connections between MR and surrounding disciplines  3. Prepare young scientists to make a difference in a rapidly changing world PROJECT NARRATIVE Support is requested for graduate students and postdoctoral fellows to attend the tenth Gordon Research Conference (GRC) on In Vivo Magnetic Resonance, scheduled for July 15-20, 2018, and the inaugural trainee- focused Gordon Research Seminar (GRS) to precede the conference on July 14-15, 2018. The GRC will be focused on “Challenging assumptions about MR technology and applications in a changing world,” with the goal of taking the measure of disruptive forces such as Artificial Intelligence, and marshaling disruptive innovations in the acquisition, reconstruction, and interpretation of MR data. The companion GRS will have a related focus on “The changing world of magnetic resonance: old physics, new techniques,” and will provide trainees (who will attend the GRC as well) with opportunities for presentation of their work to peers and thought leaders, discussion of emerging areas of MR, and focused networking and mentorship.",2018 In Vivo Magnetic Resonance Gordon Research Conference & Gordon Research Seminar,9608839,R13EB026933,"['Academy', 'Address', 'Anniversary', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Awareness', 'Biological', 'Biological Neural Networks', 'Books', 'Characteristics', 'Clinical', 'Companions', 'Complex', 'Coupled', 'Data', 'Development', 'Diagnostic', 'Discipline', 'Doctor of Philosophy', 'Educational workshop', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Goals', 'Healthcare', 'Human', 'Imaging technology', 'International', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Marshal', 'Measures', 'Medical', 'Medicine', 'Mentorship', 'Methods', 'Modernization', 'Palpable', 'Physics', 'Postdoctoral Fellow', 'Recording of previous events', 'Research', 'Role', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Societies', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Work', 'biophysical model', 'c new', 'commune', 'comparative', 'computer science', 'design', 'experience', 'graduate student', 'in vivo', 'innovation', 'insight', 'interest', 'magnetic field', 'meetings', 'method development', 'peer', 'posters', 'programs', 'reconstruction', 'symposium', 'tool']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,5000,-0.005181216560780774
"2018 In Vivo Magnetic Resonance Gordon Research Conference & Gordon Research Seminar PROJECT SUMMARY  The field of magnetic resonance (MR) is in the midst of a revolution. Disruptive external forces, such as the advent of powerful new Artificial Intelligence methods, coupled with a recent creative ferment in method development within the field, is changing the way we think about the acquisition, the reconstruction, and the interpretation of MR data. Meanwhile, MR has long been an indispensable tool not only for basic discovery but also for medical diagnostics, but the value proposition of clinical MR imaging is also changing, against the backdrop of a shifting healthcare landscape.  There is a palpable need to explore the full scope of these changes, in a forum that enables deep dives and focused discussion, without losing the necessary breath of perspective. While large meetings such as the annual scientific meeting of the International Society for Magnetic Resonance in Medicine (ISMRM) have the necessary breath, the sheer size and pace of such meetings work against the requisite focus. On the other hand, short focused workshops are better suited to the evaluation of progress in well-defined subfields.  The goal of this grant application is to support a high-impact conference with a time-tested format which is ideally suited to assess recent changes in the field of in vivo MR. The tenth Gordon Research Conference (GRC) on In Vivo Magnetic Resonance will be held July 15 to 20, 2018, at Proctor Academy, in Andover, NH. Our GRC will also be associated with the first-ever trainee-organized and trainee-focused Gordon Research Seminar (GRS) on In Vivo Magnetic Resonance, which will take place on the weekend before the GRC (July 14-15, 2018). The trainee seminar meshes well with our goal of preparing young scientists for a changing field and a changing world. We request funding to support graduate students and postdoctoral fellows attending these meetings, which will focus explicitly on the shifting role of MR in a rapidly changing world.  The GRC, subtitled “Challenging assumptions about MR technology and applications in a changing world,” will be led by Chair Daniel K. Sodickson, MD, PhD, and Vice Chair Jeff F. Dunn, PhD, and will build upon a rich history of In Vivo MR GRCs. The GRS, subtitled “The Changing World of Magnetic Resonance: Old Physics, New Techniques,” will be led by Chair Scott Beeman, PhD, and Vice Chair Carson Hoffman, BSc, and will further enhance the experience of trainees with tailored opportunities for mentorship, networking, and scientific exchange.  Specific aims of our 2018 GRC and GRS on In Vivo MR are as follows:  1. Explore disruptive forces and marshal disruptive innovation in the field of in vivo MR  2. Foster connections between MR and surrounding disciplines  3. Prepare young scientists to make a difference in a rapidly changing world PROJECT NARRATIVE Support is requested for graduate students and postdoctoral fellows to attend the tenth Gordon Research Conference (GRC) on In Vivo Magnetic Resonance, scheduled for July 15-20, 2018, and the inaugural trainee- focused Gordon Research Seminar (GRS) to precede the conference on July 14-15, 2018. The GRC will be focused on “Challenging assumptions about MR technology and applications in a changing world,” with the goal of taking the measure of disruptive forces such as Artificial Intelligence, and marshaling disruptive innovations in the acquisition, reconstruction, and interpretation of MR data. The companion GRS will have a related focus on “The changing world of magnetic resonance: old physics, new techniques,” and will provide trainees (who will attend the GRC as well) with opportunities for presentation of their work to peers and thought leaders, discussion of emerging areas of MR, and focused networking and mentorship.",2018 In Vivo Magnetic Resonance Gordon Research Conference & Gordon Research Seminar,9608839,R13EB026933,"['Academy', 'Address', 'Anniversary', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Awareness', 'Biological', 'Biological Neural Networks', 'Books', 'Characteristics', 'Clinical', 'Companions', 'Complex', 'Coupled', 'Data', 'Development', 'Diagnostic', 'Discipline', 'Doctor of Philosophy', 'Educational workshop', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Goals', 'Healthcare', 'Human', 'Imaging technology', 'International', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Marshal', 'Measures', 'Medical', 'Medicine', 'Mentorship', 'Methods', 'Modernization', 'Palpable', 'Physics', 'Postdoctoral Fellow', 'Recording of previous events', 'Research', 'Role', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Societies', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Work', 'biophysical model', 'c new', 'commune', 'comparative', 'computer science', 'design', 'experience', 'graduate student', 'in vivo', 'innovation', 'insight', 'interest', 'magnetic field', 'meetings', 'method development', 'peer', 'posters', 'programs', 'reconstruction', 'symposium', 'tool']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,10000,-0.005181216560780774
"Functional Cardiovascular 4D MRI in Congenital Heart Disease SUMMARY / ABSTRACT Congenital heart disease (CHD) is the most common birth defect, affecting 1.2% of all live births. Imaging plays a major role in managing CHD but remains challenging for evaluating complex cardiac and vascular abnormalities across a wide range of age and habitus. To address these limitations, the PIs have developed cardiovascular 4D flow MRI which can measure complex 3D blood flow in-vivo, a task difficult or impossible to obtain with other imaging strategies. Recent efforts have focused on two forms of CHD: 1) bicuspid aortic valve (BAV) which is the most common form of CHD, and 2) single ventricle physiology (SVP), one of the most severe forms of CHD. Our 4D flow MRI studies have successfully identified new hemodynamic biomarkers to better characterize CHD. We were the first to establish a physiologic link between aberrant 3D blood flow, elevated wall shear stress (WSS), aortopathy phenotype, and aortic wall tissue degeneration on histopathology in patients with BAV. In patients with SVP, our findings demonstrated relationships between surgical correction strategies and flow distribution to the lungs, a known factor implicated in SVP outcome. We have achieved successful clinical translation at Northwestern, where 4D flow MRI is now used as a clinical tool in diagnostic MRI exams for patients with CHD and aortic disease. Over the past four years, the PIs have assembled one of the largest 4D MRI databases with over 2500 patient exams. For this renewal application, we identified a need to increase the dynamic range of 4D MRI flow sensitivity to account for data complexity (3D + time) and the wide age range in CHD by a combination of dual-venc flow encoding, compressed sensing, and SSFP imaging. Second, three is a need for longitudinal studies to identify predictors of BAV and SVP outcome. Third, making these unique but complex 4D MRI data sets and analysis tools more widely available to the greater research community is challenging. In addition, no automated methods currently exist for advanced processing such as atlas based analysis across large cohorts. Analysis is thus time consuming and requires manual interactions (e.g. 3D vessel segmentation) which limits reproducibility and translation. To address this need, an established Northwestern data archival and pipeline processing resource based on remote high-performance computing clusters (NUNDA) will be utilized for standardized data archival, sharing, and pipeline processing of 4D MRI data. This platform will provide the unique opportunity to utilize annotated data available in the 4D MRI database (>1300 BAV, SVP, and control 4D MRI data analyzed in the initial funding cycle) for application of machine learning concepts to establish (semi-)automated 4D MRI analysis workflows in NUNDA. Thus, the renewal application for this study aims to 1) develop a rapid (15 min) non-contrast 4D MRI for clinical translation, 2) leverage the existing large 4D MRI database to identify 4D MRI metrics predictive of long-term (> 5 years) CHD patient outcome, and 3) establish a remote NUNDA platform for 4D MRI data sharing and automated analysis across large cohorts. PROJECT NARRATIVE Our goal is to develop non-contrast 4D MRI, a new diagnostic test to achieve an improved assessment for the most common and one of the most severe forms of congenital heart disease: bicuspid aortic valve and single ventricle physiology. We will leverage an existing large 4D MRI database to allow for long-term 5-8-year follow-up to establish new measures for improved outcome prediction and therapy management for patients with bicuspid aortic valve and single ventricle physiology. A comprehensive data archive will be established to allow for the dissemination of the 4D MRI data, analysis tools, and study results to the greater research community.",Functional Cardiovascular 4D MRI in Congenital Heart Disease,9515521,R01HL115828,"['4D MRI', 'Acceleration', 'Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Aortic Diseases', 'Archives', 'Atlases', 'Biological Markers', 'Blood flow', 'Cardiac Output', 'Cardiovascular system', 'Child', 'Clinical', 'Common Ventricle', 'Communities', 'Complex', 'Congenital Abnormality', 'Contrast Media', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease Progression', 'Exposure to', 'Funding', 'General Anesthesia', 'Goals', 'Growth', 'Heart Abnormalities', 'Heart Rate', 'High Performance Computing', 'Histopathology', 'Hospitals', 'Image', 'Infant', 'Link', 'Live Birth', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Operative Surgical Procedures', 'Outcome', 'Outcome Study', 'Oxygen', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Play', 'Population', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Role', 'Secure', 'Standardization', 'Testing', 'Time', 'Translations', 'adverse outcome', 'aortic valve', 'base', 'bicuspid aortic valve', 'clinical translation', 'cluster computing', 'cohort', 'congenital heart disorder', 'data archive', 'data sharing', 'design', 'exercise capacity', 'flexibility', 'follow-up', 'hemodynamics', 'improved', 'improved outcome', 'in vivo', 'novel', 'novel diagnostics', 'outcome prediction', 'patient population', 'pediatric patients', 'prevent', 'sex', 'shear stress', 'spatiotemporal', 'tissue degeneration', 'tool', 'vascular abnormality']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2018,704597,0.005458814886254317
"Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography PROJECT SUMMARY Integrated analysis of coronary anatomy and biology using 18F-fluoride PET and CT angiography Each year, 735,000 Americans have an acute myocardial infarction (heart attack), and approximately 120,000 die from it. Heart attacks occur most commonly due to rupture of atherosclerotic plaques in coronary arteries. Despite this, current diagnostic and treatment algorithms make no allowance for the assessment of disease activity and currently all patients with atherosclerosis are treated in a similar manner. This failure to differentiate stable from active disease may result in potentially unnecessary or insufficient therapies. In a breakthrough series of studies, our co-investigators discovered that positron emission tomography (PET) with 18F-sodium- fluoride (18F-NaF; an inexpensive and widely available tracer approved by Food and Drug Administration) can readily identify plaque rupture and increased coronary plaque activity. We propose to build further on this success, by addressing several important remaining limitations that prevent us from translating this technology to broad clinical use. The limitations include complicated and subjective image analysis, underutilization of the concomitant coronary computed tomography angiography (CTA) for plaque characterization, inability to utilize prior CTA for the analysis of 18F-NaF PET, lack of methods to integrate all available PET and CTA data and significant motion of the coronaries during the PET scan. We propose a multi-faceted approach to automate and improve coronary 18F-NaF PET imaging by full integration with CTA and correction for cardiac, respiratory, and patient motion. The overall goal of the proposal is to optimize the measurement of disease activity in coronary atherosclerosis using integrated 18F-NaF PET/CTA imaging, with the opportunity to validate this development against clinical outcome in a “real-world” multicenter patient study. For this work, we propose the following 3 specific aims: 1) to integrate quantification of CTA and PET image data 2) to develop new methods for simultaneous correction of cardiac, respiratory, and patient motion for coronary PET, and 3) to clinically evaluate new methods in a multicenter clinical trial (separately funded and already underway), further refining risk prediction for heart attacks with integrated PET+CTA risk score derived by machine learning. This work will lead to a robust and reproducible clinical method for stratification of patients for risk of heart attacks, with potential to be applied for the identification of patients who would most benefit from expensive, and potentially risky treatments. Our techniques could also be used in future clinical trials to test the efficacy of novel therapies. Moreover, the new analysis will be applicable to other PET tracers that may be developed to investigate other pathological processes in the coronary vasculature. The resulting software will be shared with clinical institutions performing coronary PET to facilitate standardization and automation of this novel plaque imaging technique. NARRATIVE A heart attack, a major cause of death, is most commonly caused by rupture of deposits in heart vessels, leading to sudden blockage of the blood flow in the vessels and disruption of blood supply to the heart muscle. Currently there is no reliable test to identify deposits at the highest risk of rupture, but in a recent scientific breakthrough, positron emission tomography has demonstrated capability to image disease activity inside these deposits, linked to their rupture; this technique, however, is currently hampered by lack of anatomical reference, image blurring due to heart motion, and variability of manual analysis. We propose to address these problems by developing automatic software that precisely integrates anatomical and biological information and virtually “freezes” vessel motion, validating this new approach in a large “real-world” multicenter patient study.",Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography,9539728,R01HL135557,"['Acute myocardial infarction', 'Address', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Area', 'Arterial Fatty Streak', 'Atherosclerosis', 'Automation', 'Binding', 'Biological', 'Biological Process', 'Biology', 'Blood flow', 'Breast Microcalcification', 'Cardiac', 'Cause of Death', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer software', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Emission-Computed Tomography', 'Enrollment', 'Event', 'FDA approved', 'Failure', 'Fluorides', 'Freezing', 'Funding', 'Future', 'Goals', 'Heart', 'Histologic', 'Image', 'Image Analysis', 'Imaging Techniques', 'Inflammation', 'Institution', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardium', 'Noise', 'Outcome', 'Pathologic Processes', 'Patient risk', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Radiation', 'Recurrence', 'Reporting', 'Reproducibility', 'Research Personnel', 'Risk', 'Risk Assessment', 'Rupture', 'Scanning', 'Series', 'Signal Transduction', 'Sodium Fluoride', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tracer', 'Translating', 'United States Food and Drug Administration', 'Vascular blood supply', 'Work', 'X-Ray Computed Tomography', 'atherosclerotic plaque rupture', 'coronary computed tomography angiography', 'coronary plaque', 'coronary vasculature', 'cost', 'disorder risk', 'efficacy testing', 'experience', 'fluorodeoxyglucose positron emission tomography', 'heart motion', 'high risk', 'imaging study', 'improved', 'novel', 'novel strategies', 'novel therapeutics', 'patient stratification', 'prevent', 'prospective', 'respiratory', 'success', 'uptake', 'virtual']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2018,756791,0.017391526361552098
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9525301,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Modernization', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Prediction of Response to Therapy', 'Privatization', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissues', 'Tumor Burden', 'base', 'cancer biomarkers', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'clinical predictors', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'specific biomarkers', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2018,593292,-0.0031273751225334634
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9622047,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Biological Neural Networks', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2018,1057846,0.004999748394405727
"ClearScope Combined in vivo and ex vivo three‐dimensional (3D) whole‐brain imaging of non‐transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole‐brain datasets, the best approach is brain clearing followed by whole‐brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole‐brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo‐bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide‐spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state‐of‐the‐art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large‐scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,9559081,R44MH116827,"['Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biological Neural Networks', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Dimensions', 'Human', 'Image', 'Immersion Investigative Technique', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,556615,0.009793425068072186
"MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention Project Summary The Medical Image Computing and Computer Assisted Intervention (MICCAI) society is dedicated to the promotion, preservation, facilitation of research and education in the fields of medical image computing (MIC) and computer assisted interventions (CAI) including biomedical imaging and robotics; this is achieved through the organization and operation of regular international conferences of highest quality and publications which promote and foster the exchange and dissemination of advanced knowledge, expertise and experience in the field produced by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their roots and origin in three separate but related conferences beginning in early 1990s, the Visualization in Biomedical Computing (VBC), Computer Vision and Virtual Reality in Robotics and Medicine (CVRMed), and Medical Robotics and Computer Assisted Surgery (MRCAS), which merged into a single annual conference in 1998. MICCAI Conferences have defined a new scientific discipline over the years and have become the premier conference in the field with their proceedings having an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & image processing for medical imaging, computer-aided diagnosis, computer-assisted intervention & surgery, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, specific imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry. The main MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance) and several presented papers becoming landmark publications over the years reaching up to 2,000 citations. The conference series includes community-driven software challenges, workshops and tutorials just before and/or after the main conference. These satellite events focus in detail on the current status and advances in topics relevant to MICCAI and are very highly attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendance typically includes more than 45 countries, with strong student representation (~40%). The MICCAI 2018 Conference will be held in Granada, Spain in September 16th-20th, 2018. An innovative aspect of MICCAI 2018 is the initiation of a “Mentoring Program” to connect students and young investigators with established mentors from academia and industry. Along with the mission of “Women in MICCAI” committee, this proposal requests funds to initiate and ultimately sustain student travel awards to specifically enhance diversity in conference attendance, including women, underrepresented minorities, students with disabilities, and students from disadvantaged backgrounds, to present their work, providing them with a unique opportunity to reach an international audience for career development and collaborations. Project Narrative The MICCAI 2018 Conference will be held in Granada, Spain during September 16th-20th, 2018. The MICCAI conferences are the premier meeting in the medical image computing (MIC) and computer assisted intervention (CAI) communities, having introduced several landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students, focusing on enhancing diversity by supporting the participation of women, underrepresented minorities, students with disabilities, and from disadvantaged backgrounds, to present their work, providing them with an opportunity for visibility in an established international audience, foster professional development and collaborations.",MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention,9617533,R13CA225202,"['Academia', 'Address', 'American', 'Area', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Climate', 'Clinic', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Country', 'Development', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Grant', 'Imagery', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority', 'Mission', 'Occupations', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Physicians', 'Physiology', 'Plant Roots', 'Policies', 'Psychiatry', 'Publications', 'Publishing', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Support', 'Robotics', 'Scientist', 'Series', 'Sex Bias', 'Societies', 'Spain', 'Students', 'System', 'Translations', 'Travel', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'computer science', 'design', 'digital imaging', 'disabled students', 'disadvantaged student', 'experience', 'image processing', 'imaging system', 'improved', 'innovation', 'lecture notes', 'meetings', 'new technology', 'oncology', 'operation', 'peer', 'posters', 'preservation', 'programs', 'prototype', 'racial and ethnic', 'research and development', 'social', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NCI,UNIVERSITY OF PENNSYLVANIA,R13,2018,5000,-0.015467691643907973
"MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention Project Summary The Medical Image Computing and Computer Assisted Intervention (MICCAI) society is dedicated to the promotion, preservation, facilitation of research and education in the fields of medical image computing (MIC) and computer assisted interventions (CAI) including biomedical imaging and robotics; this is achieved through the organization and operation of regular international conferences of highest quality and publications which promote and foster the exchange and dissemination of advanced knowledge, expertise and experience in the field produced by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their roots and origin in three separate but related conferences beginning in early 1990s, the Visualization in Biomedical Computing (VBC), Computer Vision and Virtual Reality in Robotics and Medicine (CVRMed), and Medical Robotics and Computer Assisted Surgery (MRCAS), which merged into a single annual conference in 1998. MICCAI Conferences have defined a new scientific discipline over the years and have become the premier conference in the field with their proceedings having an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & image processing for medical imaging, computer-aided diagnosis, computer-assisted intervention & surgery, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, specific imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry. The main MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance) and several presented papers becoming landmark publications over the years reaching up to 2,000 citations. The conference series includes community-driven software challenges, workshops and tutorials just before and/or after the main conference. These satellite events focus in detail on the current status and advances in topics relevant to MICCAI and are very highly attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendance typically includes more than 45 countries, with strong student representation (~40%). The MICCAI 2018 Conference will be held in Granada, Spain in September 16th-20th, 2018. An innovative aspect of MICCAI 2018 is the initiation of a “Mentoring Program” to connect students and young investigators with established mentors from academia and industry. Along with the mission of “Women in MICCAI” committee, this proposal requests funds to initiate and ultimately sustain student travel awards to specifically enhance diversity in conference attendance, including women, underrepresented minorities, students with disabilities, and students from disadvantaged backgrounds, to present their work, providing them with a unique opportunity to reach an international audience for career development and collaborations. Project Narrative The MICCAI 2018 Conference will be held in Granada, Spain during September 16th-20th, 2018. The MICCAI conferences are the premier meeting in the medical image computing (MIC) and computer assisted intervention (CAI) communities, having introduced several landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students, focusing on enhancing diversity by supporting the participation of women, underrepresented minorities, students with disabilities, and from disadvantaged backgrounds, to present their work, providing them with an opportunity for visibility in an established international audience, foster professional development and collaborations.",MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention,9617533,R13CA225202,"['Academia', 'Address', 'American', 'Area', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Climate', 'Clinic', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Country', 'Development', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Grant', 'Imagery', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority', 'Mission', 'Occupations', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Physicians', 'Physiology', 'Plant Roots', 'Policies', 'Psychiatry', 'Publications', 'Publishing', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Support', 'Robotics', 'Scientist', 'Series', 'Sex Bias', 'Societies', 'Spain', 'Students', 'System', 'Translations', 'Travel', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'computer science', 'design', 'digital imaging', 'disabled students', 'disadvantaged student', 'experience', 'image processing', 'imaging system', 'improved', 'innovation', 'lecture notes', 'meetings', 'new technology', 'oncology', 'operation', 'peer', 'posters', 'preservation', 'programs', 'prototype', 'racial and ethnic', 'research and development', 'social', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NCI,UNIVERSITY OF PENNSYLVANIA,R13,2018,3000,-0.015467691643907973
"Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research PROJECT SUMMARY/ABSTRACT This proposal represents a vertical advancement in neighborhood effects research, producing for the first time, national neighborhood indicators of the built environment. Thus far, only local studies have been conducted due to the resource-intensive nature of site visits to conduct assessments of community features and also manual annotations of street images. With the recent advancement of computer vision and the emergence of massive sources of image data, we will leverage our team’s abilities to develop a data collection strategy utilizing geographic information systems to assemble a national collection of Google Street View images of all road intersections and street segments in the United States. We will utilize this data bank, and develop informatics algorithms to produce neighborhood summaries of built environment that have been theoretically and empirically identified to be important for health outcomes. After the creation of Neighborhood Looking Glass, we will conduct investigations into the impact of neighborhood environments on health utilizing medical records from hundreds of thousands of patients and accounting for predisposing characteristics in analyses. Our investigative team—comprised of experts in the field of epidemiology, computer vision, bioinformatics, and computer science—is uniquely suited to implement the study aims. Our Specific Aims are: 1) Develop informatics techniques to produce neighborhood quality indicators; 2) Measure the accuracy of data algorithms and construct an interactive geoportal for neighborhood data visualization and data sharing, 3) Utilize Neighborhood Looking Glass and a large collection of medical records from Intermountain Healthcare to investigate neighborhood influences on the risk of obesity and substance abuse. The epidemic rise in chronic health conditions is recent and as such suggests its cause is social, cultural, and constructed rather than purely biological. Thus, we have the possibility of intervening on the environment to better support health. Recent studies suggest that the current cohort of young adults may face historically high cardiovascular disease risk and chronic disease burden. Our substantive investigation of the impact of neighborhood factors on chronic conditions will contribute further to the understanding of contextual influences on the health of this cohort at the forefront of a chronic disease epidemic. Moreover, the dramatic rise in overdoses, accidental poisonings, and mental health issues contributing to premature mortality warrants further investigation into risk-inducing environmental factors for substance abuse. Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics. Results can be utilized to inform population-based strategies to reduce health disparities and improve health. Project Narrative/Relevance to Public Health The epidemic rise in obesity, related chronic diseases, and substance abuse in recent decades signal the importance of structural forces and social processes, but the dearth of data on contextual factors limits the investigation of multilevel effects on health. The development of the Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics with potential impact on health. Results from our project can be utilized to inform system-wide and local strategies to improve community health.",Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research,9499844,R01LM012849,"['Accounting', 'Alcohol or Other Drugs use', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Characteristics', 'Chronic', 'Chronic Disease', 'Cities', 'Collection', 'Communities', 'Community Health', 'Computer Vision Systems', 'Data', 'Data Collection', 'Data Sources', 'Development', 'Disease', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Family', 'Food', 'Food Access', 'Geographic Information Systems', 'Geography', 'Glass', 'Grant', 'Happiness', 'Health', 'Health Food', 'Health Personnel', 'Health Services Accessibility', 'Health behavior', 'Health care facility', 'Healthcare', 'Image', 'Individual', 'Informatics', 'Investigation', 'Label', 'Literature', 'Manuals', 'Measures', 'Medical Records', 'Mental Health', 'Methods', 'Nature', 'Neighborhoods', 'Obesity', 'Outcome', 'Overdose', 'Patients', 'Physical activity', 'Physical environment', 'Premature Mortality', 'Process', 'Public Health', 'Quality Indicator', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Signal Transduction', 'Site Visit', 'Social Environment', 'Source', 'Substance abuse problem', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Visit', 'built environment', 'burden of illness', 'cardiovascular disorder risk', 'cohort', 'computer science', 'contextual factors', 'cost', 'crowdsourcing', 'data management', 'data mining', 'data resource', 'data sharing', 'data visualization', 'data warehouse', 'density', 'health disparity', 'improved', 'land use', 'obesity risk', 'object recognition', 'physical conditioning', 'population based', 'social', 'social media', 'walkability', 'young adult']",NLM,"UNIV OF MARYLAND, COLLEGE PARK",R01,2018,355252,-0.008113509730077538
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9542210,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting', 'whole slide imaging']",NIAMS,UNIVERSITY OF FLORIDA,R01,2018,377571,0.05179957234559452
"Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner Project Summary/Abstract This application is for a shared instrumentation grant from the Light Microscope Imaging Facility at Case Western Reserve University (CWRU) School of Medicine (SOM) to acquire a fully automated, high-capacity, high- resolution Hamamatsu Nanozoomer S60 slide scanner that can accommodate both brightfield and fluorescence imaging in single-slide and double-slide formats. We also request MicroDimensions 3D reconstruction and alignment software packages for manipulating and analyzing the whole slide images produced with the scanner. We need to replace a scanner that is not functioning properly. Our well-established shared core facility supports NIH-funded investigators by giving them access to state-of-the-art microscopy technologies that enhance collaborative, multidisciplinary research. Acquisition of this instrument will have a high impact on the biomedical research at CWRU and expand the scope of our NIH-funded projects. Several projects have been identified that will utilize the scanner and its associated analyses programs. These include: the genetic mechanisms underlying skin fibrosis and cranial bone development (Atit); the mechanisms behind the lifelong functions of transcription factors in axonal growth and architecture (Deneris); deep-learning for histologic image predictors of various diseases (Madabhushi); the development of diagnostic probes to discriminate between glioma subtypes for screening and survival therapies (Brady-Kalnay); the role of progesterone receptors in the control of parturition and the development of therapies to prevent preterm birth (Messiano); the mechanisms by which breast cancer stem cells overcome metastatic latency leading to disease recurrence and the biomarkers that could potentially identify those tumors likely to undergo this process (Schiemann); and the significance of cholesterol-related proteins in brain and retinal function (Pikuleva). Many additional projects of minor users and others at CWRU are anticipated. All of the proposed projects are in need of a high-capacity automated scanner acquiring whole slide images so that analyses can be applied to tissues that cover hundreds of fields of view, rather than the single regions of interest that can be acquired on a standard microscope. Narrative This proposal seeks to acquire a new, state-of-the-art high-speed, high content digital slide scanner for high resolution cellular and biomarker identfcation across large tissue areas. The dual mode (fluorescence and brightfield) allows flexibility in marker visualization while the software allows the automated alignment of whole slide images for multi-stain analysis and 3d reconstruction of serial section for in-depth analysis of specimens. This equipment is essential for our NIH disease-related studies providing a profound positive impact on a wide range of public health areas.",Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner,9489976,S10OD024981,"['Architecture', 'Biological Markers', 'Biomedical Research', 'Birth', 'Bone Development', 'Brain', 'Cephalic', 'Cholesterol', 'Computer software', 'Core Facility', 'Development', 'Diagnostic', 'Disease', 'Enhancement Technology', 'Funding', 'Genetic', 'Glioma', 'Grant', 'Interdisciplinary Study', 'Light Microscope', 'Microscope', 'Microscopy', 'Minor', 'Premature Birth', 'Process', 'Progesterone Receptors', 'Proteins', 'Recurrence', 'Research Personnel', 'Resolution', 'Retinal', 'Role', 'Slide', 'Tissues', 'United States National Institutes of Health', 'Universities', 'axon growth', 'cancer stem cell', 'deep learning', 'digital', 'equipment acquisition', 'fluorescence imaging', 'histological image', 'imaging facilities', 'instrumentation', 'interest', 'malignant breast neoplasm', 'medical schools', 'prevent', 'programs', 'reconstruction', 'screening', 'skin fibrosis', 'therapy development', 'transcription factor', 'tumor', 'whole slide imaging']",OD,CASE WESTERN RESERVE UNIVERSITY,S10,2018,303390,-0.010499588130273093
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9517057,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Radiology Specialty', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Screening procedure', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'single photon emission computed tomography', 'skills', 'success', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2018,169609,0.020196330208896263
"DEVELOPMENT OF A RAPID METHOD FOR IMAGING REGIONAL VENTILATION IN SMALL ANIMALS W/O CONTRAST AGENTS The objective of this R01 application is to develop a rapid method for imaging regional ventilation and lung compliance in small animals without contrast agents. Much of our current understanding of the normal functioning of the lung and mechanisms of lung disease comes from small animal studies. However, lung function imaging in small animal models is technically challenging due to motion and the relatively small size of the lungs. Pulmonary function testing using plethysmography has been employed to assess lung function and injury with limited validity and utility, particularly in small animals. Additionally, only aggregate measures of functional performance are produced and no regional lung changes can be assessed. An improved imaging method that could provide spatially- and temporally-resolved information regarding ventilation would be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases. It would also facilitate drug discovery and efficacy studies aimed to mitigate respiratory pathology. The ideal method would provide quantitative regional functional information, be applicable to longitudinal studies (low radiation dose), and have a simple and affordable implementation that permits widespread use. Currently available imaging methods including micro-CT or MRI fall short in one or more of these requirements.  To address this need, we will establish and evaluate a novel, easy to implement, and highly effective X- ray phase-contrast (XPC) method for ventilation imaging in small animal models. The lung is ideally suited to XPC imaging because it is comprised mainly of air spaces separated by thin tissue structures. The air-tissue interfaces cause the X-ray beam to experience numerous and strong refractions that produce a distinctive texture in the intensity measured over the lungs known as speckle. Detailed information regarding the regional lung air volume (RLAV) distribution is encoded in the speckle. The benefits of exploiting lung speckle for detecting and monitoring lung function are numerous but remain entirely unexplored for benchtop imaging.  Our approach involves a high degree of technical innovation regarding image formation methods and will significantly extend the current boundaries of functional lung imaging in small animals. The proposed method, referred to as parametric XPC (P-XPC) imaging, will produce 2D parametric images that depict the projected RLAV distribution. When differential images are computed for any given two points in the breathing cycle, ventilation or lung compliance imaging will be achieved. Preliminary in vivo and computational studies have been conducted in support of the proposed research. The specific aims of the project are as follows. Aim 1: Develop P-XPC image formation methods for estimating the projected RLAV distribution; Aim 2: Optimize an XPC imaging system for P-XPC imaging. Aim 3: Evaluate the diagnostic capability of P-XPC imaging in two pre-clinical animal models of disease in vivo. The proposed research will result in a novel, easy to implement, and highly effective X-ray phase-contrast (XPC) method for functional lung imaging in small animal models. It will provide spatially- and temporally- resolved information regarding lung ventilation that will be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases.",DEVELOPMENT OF A RAPID METHOD FOR IMAGING REGIONAL VENTILATION IN SMALL ANIMALS W/O CONTRAST AGENTS,9474118,R01EB023045,"['Address', 'Air', 'Animal Disease Models', 'Animal Model', 'Animals', 'Breathing', 'Communities', 'Contrast Media', 'Diagnostic', 'Dose', 'Environmental air flow', 'Evaluation', 'Functional Imaging', 'Image', 'Imaging technology', 'Learning', 'Longitudinal Studies', 'Low Dose Radiation', 'Lung', 'Lung Compliance', 'Lung diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Monitor', 'Motion', 'Mus', 'Pathology', 'Performance', 'Phase', 'Physics', 'Physiology', 'Plethysmography', 'Process', 'Pulmonary Emphysema', 'Pulmonary function tests', 'Radiation', 'Research', 'Resolution', 'Resource Sharing', 'Respiratory physiology', 'Roentgen Rays', 'Scientist', 'Source', 'Structure', 'Supervision', 'System', 'Technical Degree', 'Techniques', 'Texture', 'Thinness', 'Time', 'Tissues', 'Translating', 'animal imaging', 'base', 'computer studies', 'contrast imaging', 'cost', 'detector', 'drug discovery', 'drug efficacy', 'efficacy study', 'experience', 'falls', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'learning strategy', 'lung imaging', 'lung injury', 'lung pressure', 'lung volume', 'microCT', 'mouse model', 'novel', 'parametric imaging', 'pre-clinical', 'pressure', 'rapid technique', 'respiratory']",NIBIB,WASHINGTON UNIVERSITY,R01,2018,408541,-0.007344899037082696
"Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms Project Summary This project will create and assess new optical imaging and computational technologies with the goal of improving the detection rates of precancerous, non-polypoid lesions during colonoscopy screening. Identifying and removing these subtle lesions is critical to improving the protective value of colonoscopy in reducing mortality from colorectal cancer. However, current approaches to non-polypoid lesion detection are largely unsuccessful because they are time-consuming and require specialized training (chromoendoscopy), or they start with poor image contrast (software analysis of conventional video). This project focuses on developing a novel technique, called quantitative topographic endoscopy (QTE), that optically measures colon surface properties via a modified commercial colonoscope. The key innovation in this proposal is to utilize structured illumination and build on concepts from computer vision and optical engineering to acquire high-resolution 3D images of the colon surface through a custom endoscope. The project will be implemented through three specific aims: (1) develop a miniaturized, quantitative, high-resolution topography system, (2) implement QTE in a modified commercial colonoscope ready for clinical testing, and (3) determine the validity of QTE in a phantom model and its clinical feasibility in a pilot human study. QTE systems developed in this project will be tested in tissue-mimicking phantoms with a goal of achieving better than 1-mm height sensitivity, in ex-vivo resected colon samples with a goal of accurately reconstructing surface shapes from a complex tissue, and in a pilot human study with the goal of obtaining surface topography non-polypoid lesions. Beyond increasing non-polypoid lesion detection rates, QTE has the potential to address other limitations of colonoscopy, including preventing missed polypoid lesions, classifying lesions for resect-and-discard strategies, and improving colonoscopy quality metrics. Additionally, the development of a QTE system that is approved for human studies will serve as a platform for future clinical assessment of other optical techniques such as spatial frequency domain imaging and speckle imaging in a variety of gastroenterology applications. Project Narrative Colorectal cancer is the second leading cause of cancer death in the United States. Screening colonoscopy can significantly reduce mortality from colorectal cancer but is limited by high miss rates for precancerous non- polypoid lesions. This project will develop new imaging and computational techniques for improving the detection rates of these lesions during colonoscopy screening.",Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms,9456285,R21EB024700,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'Biopsy', 'Caliber', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical assessments', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Color', 'Colorectal', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Custom', 'Data', 'Detection', 'Development', 'Dyes', 'Effectiveness', 'Elements', 'Endoscopes', 'Endoscopy', 'Engineering', 'Foundations', 'Frequencies', 'Future', 'Gastroenterology', 'Goals', 'Height', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Interobserver Variability', 'Knowledge', 'Large Intestine', 'Lesion', 'Light', 'Lighting', 'Malignant - descriptor', 'Maps', 'Measurement', 'Measures', 'Morphology', 'Motion', 'Mucous Membrane', 'Optics', 'Patients', 'Pilot Projects', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Premalignant', 'Procedures', 'Research', 'Research Proposals', 'Resected', 'Resolution', 'Sampling', 'Shapes', 'Source', 'Spatial\xa0Frequency\xa0Domain\xa0Imaging', 'Structure', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Image', 'Time', 'Tissues', 'Training', 'United States', 'adenoma', 'base', 'chromoscopy', 'colorectal cancer risk', 'computer aided detection', 'contrast imaging', 'human study', 'imaging system', 'improved', 'innovation', 'miniaturize', 'mortality', 'novel', 'optical imaging', 'phantom model', 'prevent', 'research clinical testing', 'routine screening', 'screening', 'vector']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,295916,-0.04422336545410892
"Fast and Robust Low-Dose X-Ray CT Image Reconstruction Abstract:  The use of CT scans has recently increased, for example, in virtual colonoscopy, CT cardiac screening, screening of the lung in smokers, whole-body CT in asymptomatic patients, and CT imaging of children. Shortening of the scanning time to around 1 second, eliminating the strict need for the subject to remain still or be sedated, is one of the main reasons for the large increase in the pediatric population. CT scans of children have been estimated to produce non-negligible increases in the probability of lifetime cancer mortality, leading to calls for the use of reduced current settings for CT scans of children. For these reasons, the CT industry has put in a lot of effort to develop low-dose CT. One active area of research is methods to reduce the radiation counts by applying adaptive collimation to block unnecessary x-ray photons. Another active area of research is the development of more robust image reconstruction algorithms that are less sensitive to noise for low-count data.  This grant proposal is focused on the second approach — development of fast and robust reconstruction algorithms. It is known that some iterative image reconstruction algorithms outperform the analytical filtered backprojection (FBP) algorithm in terms of producing less-noisy images with the same data set. One disadvantage of these iterative algorithms is their long computation time, making them impractical in a real- world CT reconstruction tasks. For this reason, the FBP algorithm is still the main work horse for CT applications.  The main goal of the proposed research is to develop fast and robust iterative-algorithms so that their computation time is at the same order of an analytic FBP algorithm, using experimental low-dose phantom, cadaver data, and low-dose cancer screen chest CT patient data to perform comparison studies. We will answer the question: When the fast and robust algorithms are used, how much can the CT dose be reduced while retaining the image quality of a standard-dose CT produced by the conventional FBP?  This R15 project provides Weber State University (WSU) computer engineering and computer science students with hands-on opportunities and experiences of performing real-world research in the field of healthcare. It will stimulate the interests of students so that they consider a career in biomedical and bioengineering field/industry. Narrative:  CT dose is currently a major concern for the general public. Low-dose CT is under development. The proposed research will focus on developing fast, robust and practical image reconstruction methods that are able to produce a standard CT image using a lower CT dose.",Fast and Robust Low-Dose X-Ray CT Image Reconstruction,9440734,R15EB024283,"['Algorithms', 'Applications Grants', 'Area', 'Biomedical Engineering', 'Cadaver', 'Cancer Patient', 'Cardiac', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Collimator', 'Computed Tomographic Colonography', 'Computer Hardware', 'Computer Simulation', 'Computers', 'Contracts', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Disadvantaged', 'Disease', 'Dose', 'Engineering', 'Environment', 'Equilibrium', 'Equus caballus', 'Evaluation', 'General Population', 'Goals', 'Healthcare', 'Human', 'Image', 'Industry', 'Inferior', 'Internships', 'Investigation', 'Learning', 'Lesion', 'Liver Cirrhosis', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Morphologic artifacts', 'Noise', 'Patients', 'Performance', 'Photons', 'Population', 'Preparation', 'Probability', 'Radiation', 'Radiation exposure', 'Research', 'Resolution', 'Roentgen Rays', 'Running', 'Scanning', 'Screening for cancer', 'Smoker', 'Structure', 'Students', 'Supervision', 'Time', 'Training', 'Universities', 'Utah', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'career', 'chest computed tomography', 'clinical application', 'computer science', 'data acquisition', 'design', 'digital imaging', 'experience', 'high risk', 'image reconstruction', 'improved', 'interest', 'low-dose spiral CT', 'lung cancer screening', 'mortality', 'parallel computer', 'professor', 'radiologist', 'reconstruction', 'screening', 'tomography', 'university student']",NIBIB,WEBER STATE UNIVERSITY,R15,2018,88321,-0.012086211469316158
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9679722,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Autistic Disorder', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2018,303226,0.0016420151957678634
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, image refers not only to biomedical images, but also to illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. We are seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. To meet these objectives, we use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers richer search results.   A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and the modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval are achieved in the following ways: (i) using image analysis; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. Additional steps include describing an image with visual features, automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.), and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed Open-i (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. The Open-i system enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 1,651,647 open access articles and 5,362,166  illustrations from the biomedical literature hosted at the National Library of Medicine's PubMed Central repository; including, over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays; 67,517 images from NLM History of Medicine collection; and about 2,064 orthopedic anatomy illustrations provided by Norris Medical Library, University of Southern California. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publisher's Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to search for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using a clinical image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. Open-i indexes all the text and illustrations in medical articles by features, both textual and image-based. Open-i also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and de-identified patient records, as well as the orthopedic and historical images. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first and perhaps only production-quality system of its kind in the biomedical domain, Open-i has enabled medical professionals and the public to access visual information from biomedical articles that are highly relevant to their query, as well as the ""take away"" messages of the articles. The quality of the information delivered by Open-i has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system placed first in the 2013 image retrieval evaluation that attracted participants from academia, industry and clinical settings. For the past year the site has attracted over 10,000 unique visitors daily (excluding bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. During the 2016 reporting period, the Open-i user interface was redesigned to provide equal quality of retrieval results for all types of devices used to access the site. n/a",Integrating image and text information for biomedical information retrieval,9787040,ZIALM010001,"['Academia', 'Anatomy', 'Bibliography', 'California', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Devices', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'History of Medicine', 'Hybrids', 'Image', 'Image Analysis', 'Indiana', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'Manuals', 'MeSH Thesaurus', 'Medical', 'Medical Libraries', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Orthopedics', 'Outcome', 'Participant', 'Patients', 'Performance', 'Physicians', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Visual', 'Work', 'base', 'bioimaging', 'clinical imaging', 'cluster computing', 'digital', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'multimodality', 'patient oriented', 'phrases', 'radiological imaging', 'repository', 'search engine', 'text searching', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2018,292180,-0.003449326757803978
"System-independent quantitative cardiac CT perfusion System-independent quantitative cardiac CT perfusion Summary BioInVision, Inc. and Case Western Reserve University researchers will develop software for quantitative anal- ysis of cardiac CT perfusion (CCTP), creating an important tool for evaluation of cardiovascular disease. With this product, cardiologists will be able to identify functional flow deficits in coronary artery territories. When one combines functional myocardial blood flow (MBF) with coronary anatomy from computed tomography angi- ography (CTA), it provides needed information on the physiologic significance of a stenosis. The CTA+CCTP combo could provide an ideal gateway exam for deciding whether to send a patient for percutaneous invasive coronary angiography and potential intervention (e.g., stenting). In addition, if flow is low and no stenosis is present, it will suggest microvascular disease, a very prevalent ailment of growing concern, especially among women and in diabetes. CT compares favorably to all other non-invasive cardiovascular imaging techniques (SPECT, PET, and MRI). It is available in many settings, including emergency departments. It provides both MBF and reliable coronary anatomy, not available in any other single modality. It has excellent resolution ena- bling detection of endocardial perfusion deficit, thought to be an early disease indicator that is impossible to assess with SPECT. CT is cheaper and has higher patient throughput than MRI or PET. With inclusion of MBF, CT would have an excellent opportunity to disrupt the diagnostic pathway leading to percutaneous intervention, a pathway now dominated by SPECT myocardial imaging, which includes zero information about coronary anatomy. To achieve reliable, accurate CT MBF measurements, we will invoke innovations to reduce beam hardening and to make reliable estimates of flow. Currently, CT perfusion is done on different CT machines with manufacturers’ proprietary software, using algorithms that can give erroneous MBFs. Applicable to any commercial scanner; our solution would harmonize measurements across acquisition systems providing trust- worthy, standardized measurements to clinicians, thereby improving management of cardiovascular patients. Narrative We will develop software to enable reliable evaluation of blood flow in heart tissue using CT imaging. With suc- cess, our project could lead to an improved gateway examination that could reduce unnecessary invasive cor- onary angiography, thereby reducing costs, patient discomfort, patient risk, and possibly unnecessary interven- tional therapies.",System-independent quantitative cardiac CT perfusion,9622204,R41HL144271,"['Accident and Emergency department', 'Affect', 'Algorithms', 'Anatomy', 'Angiography', 'Attention', 'Benchmarking', 'Blood Vessels', 'Blood flow', 'Calibration', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cause of Death', 'Chest Pain', 'Clinical', 'Clinical Data', 'Computer software', 'Confidence Intervals', 'Coronary', 'Coronary Angiography', 'Coronary artery', 'Cost Savings', 'Coupled', 'Data', 'Detection', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Electrocardiogram', 'Evaluation', 'Family suidae', 'Heart', 'Image', 'Imaging Techniques', 'Inferior', 'Intervention', 'Iodine', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measurement', 'Methods', 'Microvascular Dysfunction', 'Modality', 'Modeling', 'Morphologic artifacts', 'Myocardial', 'Myocardium', 'Obesity', 'Pathway interactions', 'Patient risk', 'Patients', 'Perfusion', 'Persons', 'Phase', 'Physiological', 'Physiology', 'Positron-Emission Tomography', 'Pre-Clinical Model', 'Prevalence', 'Quantitative Evaluations', 'Research', 'Research Personnel', 'Resolution', 'Source', 'Standardization', 'Stenosis', 'Stents', 'System', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Tissues', 'Trust', 'Universities', 'Woman', 'X-Ray Computed Tomography', 'blood flow measurement', 'cardiovascular imaging', 'cost', 'design', 'detector', 'digital', 'imaging system', 'improved', 'innovation', 'noninvasive diagnosis', 'perfusion imaging', 'pre-clinical', 'prototype', 'research and development', 'single photon emission computed tomography', 'software development', 'success', 'tool', 'virtual']",NHLBI,"BIOINVISION, INC.",R41,2018,224240,-0.011016901331999934
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9592308,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2018,113241,0.0038909702902889826
"New Approach to Quantitative Beta Amyloid Imaging Using PET Summary This project seeks to prove the commercial feasibility of a new approach to analyzing dynamic positron emission tomography (PET) data that would improve sensitivity, quantitative accuracy, and accessibility of imaging the biomarkers of Alzheimer's disease (AD). Recent progress in understanding the nature of neurodegenerative diseases — especially evidence that the onset of cognitive symptoms of AD can be mitigated —amplify the critical need of improved quantitative evaluation of AD biomarkers. Dynamic PET may be the most accurate modality capable of achieving this goal. However, current strategies of analyzing dynamic PET images either require complex acquisition protocols with invasive arterial blood sampling procedures or rely on accuracy-degrading approximations such as compartment modeling. We have developed Intelligent Dynamics-Driven Quantitative Diagnostics (IDDQD), a novel processing approach based on factor analysis of dynamic structures with partial clustering used to initiate the process. We have shown that an early version of IDDQD can extract blood and tissue tracer dynamics and the corresponding spatial distributions from 11C-PIB PET scans. SolvingDynamics Inc plans to offer a Research-as-a-Service data processing workflow that will apply IDDQD to dynamic brain PET datasets acquired by the customers, producing accurate quantitative tracer dynamics time-activity curves (TACs) and the distribution of the targeted tissues, including the AD biomarkers beta-amyloid and tau. Our proprietary algorithm does not require the tracer dynamics model to achieve steady state, so a shorter scan can be used to generate results of similar or better accuracy than those produced by current approaches, such as reference tissue- based methods. In this proposal, SolvingDynamics seeks to prove the feasibility of our proposed approach by comparing the diagnostics obtained using IDDQD analysis of dynamic PET data and those obtained from independent measurements. A subcontract group at Lawrence Berkeley National Laboratory has been conducting dynamic 11C-PIB PET studies for several years and has accumulated over 70 cases with PET data matched to both cognitive-memory tests and to post-mortem pathology studies. SolvingDynamics will retrospectively apply its analysis technique to these datasets and compare its computed tissue distributions to standardized uptake volume ratio (SUVR) and distribution volume ratio (DVR) data. A subset of 20 dynamic 11C-PIB PET datasets ranging in length from 15 to 90 minutes will also be analyzed in order to validate the feasibility of reducing the imaging time. In addition, similar studies aimed at reducing imaging time with IDDQD will be performed for 20 PET scans acquired using 18F-AV1451 tracer to image tau. PROJECT NARRATIVE Positron emission tomography image analysis methodology to be validated in this project aims to improve sensitivity and specificity of tissue analysis in dynamic positron emission tomography, improving diagnosis of Alzheimer's diseases and other neurodegenerative disorders. The main benefits are expected in medical research developing treatments for dementia and in clinical diagnosis, allowing early detection of the disease with less cost and reduced radiation dose to the patients.",New Approach to Quantitative Beta Amyloid Imaging Using PET,9557192,R43AG059500,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Amyloid', 'Amyloid beta-Protein', 'Autopsy', 'Benchmarking', 'Binding', 'Biological Markers', 'Blood', 'Blood specimen', 'Brain', 'Brain imaging', 'Cause of Death', 'Clinic', 'Clinical Research', 'Cognition', 'Cognitive', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Dementia', 'Diagnosis', 'Diagnostic', 'Disease', 'Dose', 'Drug or chemical Tissue Distribution', 'Early Diagnosis', 'Factor Analysis', 'Functional Imaging', 'Goals', 'Gold', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Injections', 'Kinetics', 'Laboratories', 'Length', 'Light', 'Machine Learning', 'Measurement', 'Measures', 'Medical Research', 'Memory', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurodegenerative Disorders', 'Onset of illness', 'Pathology', 'Patients', 'Phase', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Protocols documentation', 'Quantitative Evaluations', 'Radiation', 'Research', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Services', 'Small Business Innovation Research Grant', 'Spatial Distribution', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'amyloid imaging', 'base', 'biomarker evaluation', 'clinical Diagnosis', 'computerized data processing', 'cost', 'heuristics', 'human subject', 'imaging biomarker', 'improved', 'molecular imaging', 'neuropathology', 'neurophysiology', 'novel', 'novel strategies', 'prevent', 'prototype', 'quantitative imaging', 'radiotracer', 'tau Proteins', 'uptake']",NIA,"SOLVINGDYNAMICS, INC.",R43,2018,149871,-0.04340781174909356
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9449456,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2018,64155,0.01080629321577253
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9595780,R01EB025468,"['Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2018,670762,0.017422856912198446
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9749865,R01EB025468,"['Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2018,141623,0.017422856912198446
"Fully-automated lesion characterization in ultrawide-field retinal images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-automated lesion characterization in ultrawide-field retinal images,9559582,R43EY028081,"['Agreement', 'Algorithms', 'Anti-HIV Agents', 'Applications Grants', 'Architecture', 'Area', 'Biological', 'Blindness', 'Cataract', 'Categories', 'Characteristics', 'Clinical', 'Cloud Computing', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Engineering', 'Ensure', 'Exposure to', 'Exudate', 'Eye', 'Eye diseases', 'Eyelash', 'Gold', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Lasers', 'Lesion', 'Light', 'Manuals', 'Measures', 'Microaneurysm', 'Modality', 'Morphologic artifacts', 'Normalcy', 'Ophthalmoscopy', 'Output', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Receiver Operating Characteristics', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Spottings', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Vision', 'Work', 'base', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fovea centralis', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'operation', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'software development', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2018,216440,0.014221326840195793
"RetiVue DR, a point and shoot, non-mydriatic, widefield retinal camera for diabetic eye screening Project Summary Over the past two decades, diabetic retinopathy (DR) has become the leading cause of adult blindness in the US, affecting 40% of all diabetic patients and resulting in $500 million a year in direct medical costs. Vision loss due to DR is largely preventable and can be reduced by up to 90% with appropriate eye screening. However, in the US, less than 50% of diabetic patients receive a recommended yearly eye exam due to many factors that include lack of access to eye care professionals. Distributed tele-ophthalmic screening thru primary care clinics can potentially provide all diabetic patients cost- effective, yearly evaluations to detect DR and prevent vision loss. However, gold-standard sensitive detection of DR using standard retinal photography is complex and cumbersome process requiring up to 7 images per eye. This screening process cannot for all practical purposes be achieved without having highly trained ophthalmic photographers. RetiVue proposes to develop the RetiVue DR in collaboration with Olympus, to create the first handheld, non- mydriatic, 160 field of view, widefield DR screening camera. It will allow single photo capture of an area up to ten times greater than conventional fundus cameras, allowing sensitive detection of DR at its earliest time points. Full integration of RetiVue and Olympus hardware will enable the most advanced and highest image quality handheld retina camera on the market. Use of automated alignment, auto laser focus, and auto image capture will allow complex imaging of the retina to be performed simply by positioning the iris, requiring no user knowledge of retinal anatomy. We have established clinical proof of concept with our patented technology, but require several additional innovations in optical design, automated image recognition, and retinal image processing to enable a commercial device. We will for this proposal optimize our alignment system and laser based focusing system for widefield imaging, allowing automated alignment and focus to image the retina before eye movement occurs. We will develop a new method of widefield, non-mydriatic peripheral retinal imaging using multiple LED slit-beam projectors to allow rapid, segmental, sequential image capture of 90°, 120°, and 160° FOV on diabetic patients. Finally, we will create the most advanced retinal image processing algorithms to remove Purkinje haze which prevents conventional cameras from imaging beyond 45° FOV and enable seamless stitching of segmental peripheral retina images into a single widefield image. Project Narrative Diabetic retinopathy is a blinding eye disease that affects millions of people with diabetes and costs the US $500 million a year in medical costs. Loss of vision can be prevented if diabetic patients undergo yearly eye screening that examines the retina to detect this disease, but currently less than 50% of diabetics do so. At Re- tiVue LLC, we are designing the first easy to use handheld eye camera to allow primary care doctors to take DSLR quality pictures of the eye to look for diabetic retinopathy. Our eye camera will see 5 times more of the retina than any other handheld camera, ensuring that we find diabetic retinopathy when it first occurs. Earlier detection of diabetic retinopathy will give diabetic patients the best chance to keep their vision long term, and avoid unnecessary blindness.","RetiVue DR, a point and shoot, non-mydriatic, widefield retinal camera for diabetic eye screening",9564677,R44EY028484,"['Adult', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Americas', 'Anatomy', 'Animals', 'Area', 'Blindness', 'Caring', 'Clinic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Color', 'Complex', 'Custom', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Diagnostic Imaging', 'Direct Costs', 'Disease', 'Early Diagnosis', 'Electronics', 'Ensure', 'Evaluation', 'Eye', 'Eye Movements', 'Eye diseases', 'Fundus photography', 'Generations', 'Gold', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Iris', 'Knowledge', 'Lasers', 'Legal patent', 'Light', 'Lighting', 'Masks', 'Medical Care Costs', 'Methods', 'Modeling', 'Movement', 'Ophthalmic examination and evaluation', 'Optics', 'Patients', 'Peripheral', 'Phase', 'Photography', 'Physicians', 'Positioning Attribute', 'Predictive Value', 'Primary Health Care', 'Procedures', 'Process', 'Pupil', 'Resolution', 'Retina', 'Retinal', 'Sensitivity and Specificity', 'Specificity', 'Speed', 'Surface', 'System', 'TNFRSF10B gene', 'Technology', 'Time', 'Training', 'Ultraviolet Rays', 'Validation', 'Visible Radiation', 'Vision', 'base', 'compliance behavior', 'cost', 'cost effective', 'deep learning', 'design', 'detector', 'diabetic', 'diabetic patient', 'image processing', 'imager', 'improved', 'innovation', 'laptop', 'lens', 'novel', 'point of care', 'prevent', 'prototype', 'retinal imaging', 'sample fixation', 'screening', 'seal', 'sensor', 'success']",NEI,RETIVUE,R44,2018,847697,0.001738208251595475
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9547416,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anatomy', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathologic', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'clinical application', 'clinical imaging', 'clinical phenotype', 'clinical practice', 'cloud based', 'cluster computing', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'heart imaging', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'multidisciplinary', 'new technology', 'novel', 'open source', 'outreach', 'public health relevance', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,597688,0.03904125267400077
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9548627,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2018,573677,0.007782822129024382
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,9566167,K01DK110136,"['Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2018,154915,0.006105706688597255
"MalariaScreener: image analysis and machine learning for detecting malaria in blood   film The Lister Hill National Center for Biomedical Communications at NLM is developing a software called MalariaScreener, which can count parasite-infected and uninfected red blood cells, using automatic image analysis and machine learning algorithms. The software, which received an HHS Ventures Award, has been ported from MATLAB to Android smartphones by imaging scientists at NLM and University of Missouri. Running on a camera-equipped smartphone that is attached to a microscopes eyepiece by an adapter, the software screens the field of view for malaria parasites and reports the level of parasitemia to the microscopist. MalariaScreener first identifies red blood cells using segmentation methods such as watershed and level-sets. Then, it computes features that can detect the typical color and shape of parasites. A support vector machine performs the final classification into infected and uninfected cells based on the features computed. MalariaScreener has been trained with more than 200,000 blood cell images acquired from 150 malaria-infected and 50 uninfected patients, which have been annotated by an expert microscopist using a tailored online annotation tool. The encouraging performance of the MalariaScreener prototype in the lab has motivated preparations for testing the system at multiple sites in the field. After field-testing, the smartphone application will be made publicly available for download to other malaria screening sites in the world. With the feedback from expert microscopists, research will continue with implementing sophisticated cell segmentation techniques and deep learning methods to improve the system performance where needed. Another direction of future research is the automatic discrimination between different parasite species and their stage of development.  This year we expanded use of Deep Learning for classifying thin blood film cell images and have started implementing a cell classifier for smartphones based on deep learning. Several improvements have been made to our Android smartphone app, including improvements to the interface based on expert feedback and run-time improvements for the machine learning algorithms. For easier remote communication and diagnosis in telehealth applications, the app can now share captured images in a shared cloud folder. Furthermore, multilingual support for Chinese has been added as well as Bluetooth support for picture taking.   We have also started acquiring images of thick blood films, including manual annotations of parasites and white blood cells for machine training on this type of images. For further field testing of the app, we have reached out to sites in Thailand and Bangladesh, among others. Investigators interested in testing the app can download the app from the Google Play Store, where we have made it available for the sites participating in the testing. n/a",MalariaScreener: image analysis and machine learning for detecting malaria in blood   film,9554458,ZIALM010006,"['Africa', 'Algorithms', 'Alpha Cell', 'Android', 'Award', 'Bangladesh', 'Blood', 'Blood Cells', 'Cells', 'Cellular Phone', 'Cessation of life', 'Child', 'Childhood', 'Chinese People', 'Classification', 'Color', 'Communication', 'Computer software', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discrimination', 'Disease', 'Drug resistance', 'Erythrocytes', 'Feedback', 'Field Workers', 'Film', 'Goals', 'Image', 'Image Analysis', 'Learning', 'Leukocytes', 'Machine Learning', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Methods', 'Microscope', 'Microscopic', 'Missouri', 'Mosquito Control', 'Multilingualism', 'Parasitemia', 'Parasites', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Play', 'Preparation', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Shapes', 'Site', 'System', 'Techniques', 'Testing', 'Thailand', 'Thick', 'Thinness', 'Time', 'Training', 'Universities', 'Workload', 'annotation  system', 'base', 'cellular imaging', 'digital imaging', 'disability', 'experience', 'field study', 'fighting', 'global health', 'imaging scientist', 'improved', 'interest', 'learning strategy', 'light microscopy', 'malaria infection', 'mortality', 'prototype', 'screening', 'skills', 'telehealth', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2017,400234,-0.04140984754937412
"Image analysis and machine learning for pulmonary disease screening Our research toward the development of these algorithms has resulted in novel image analysis algorithms (graph cut, atlas based) that identify lung boundaries and delineate lung regions in the posteroanterior CXR. The research has also resulted in novel combinations of shape, edge and texture descriptors computed from pixels within the lung boundaries. These image descriptors are then used to train a supervised machine learning classifiers (e.g., SVM).   We have acquired 4 datasets for testing these algorithms and have made them publicly available for enabling scientific research on the topic. These datasets have been downloaded by over 250 researchers from academic and industrial research labs worldwide.   Performance of our lung segmentation algorithm has been shown to be 95% accurate. In addition, the classification accuracy for TB detection has been shown to be 84% which is measured as area under the receiver operating characteristic (ROC) curve. The curve measures the response of the classifier at various operating points and indicates the trade-off between sensitivity and specificity of its performance. Both results have been published in high quality archival journals.   The SVM model developed in our work is being beta-tested in the field to differentiate between normal CXR and those exhibiting lung diseases. The implemented system, which received an HHS Innovates Award, is installed in a truck equipped with a mobile x-ray unit and is deployed by a Kenyan-NGO (Academic Model for Providing Access to Healthcare, AMPATH) and is traveling through numerous sites in rural western Kenya, visiting scores of patients weekly. Research continues with acquiring digital CXR from the field for further training and testing of the algorithms, and the implementation of deep learning techniques (CNN) for fine-tuned classification of the CXR.   In FY2017 we upgraded the hardware on the truck to a fully Digital X-ray imaging (DR) system. The software was also upgraded to the next generation software with new hardware. The system can now communicate with the main PACS system in the hospital using communication over cellular modem. n/a",Image analysis and machine learning for pulmonary disease screening,9554456,ZIALM010004,"['AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Archives', 'Area', 'Atlases', 'Award', 'Classification', 'Communication', 'Comorbidity', 'Computer software', 'Country', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Digital X-Ray', 'Epidemic', 'Exhibits', 'Goals', 'Graph', 'Hospitals', 'Image', 'Image Analysis', 'Industrialization', 'Infection', 'Journals', 'Kenya', 'Learning', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Modeling', 'Modems', 'Patients', 'Performance', 'Process', 'Publishing', 'Pulmonary Tuberculosis', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Rural', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Supervision', 'System', 'Techniques', 'Testing', 'Texture', 'Thoracic Radiography', 'Training', 'Travel', 'Visit', 'Work', 'base', 'burden of illness', 'cost', 'digital', 'health care availability', 'imaging system', 'improved', 'innovation', 'mortality', 'next generation', 'novel', 'response', 'screening']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2017,303476,-0.009931568063995469
"Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes Abstract: Particle tracking (PT) is a powerful biophysical tool for elucidating molecular interactions, transport phenomena and rheological properties in complex biological environments. Unfortunately, PT remains a niche tool in life and physical sciences with a limited user base, in large part due to significant time and technical constraints in extracting accurate time-variant positional data from recorded movies. These constraints are exacerbated in experiments with low signal-to-noise ratios or substantial heterogeneity, as frequently encountered with nanoparticles and pathogens in biological fluids. Currently available software that attempts to automate the movie analysis process rely almost exclusively on assigning static image filters based on specific intensity, pixel size and signal-to-noise ratio thresholds. Unfortunately, when applied to actual experimental data with substantial spatial and temporal heterogeneity, the current software generally produces substantial numbers of false positives (i.e. tracking artifacts) or false negatives (i.e. missing actual traces), and frequently both. Frequent user intervention is thus required to ensure accurate tracking even when using sophisticated tracking software, markedly reducing experimental throughput and resulting in substantial user- to-user variations in analyzed data. The time required for accurate particle tracking analysis makes PT experiments exceedingly expensive compared to other commonly used experimental techniques in life sciences. These same tracking analysis limitations have effectively precluded investigators from undertaking more sophisticated 3D PT, even though the microscopy capability to obtain such movies is readily available and critical scientific insights can be gained from 3D PT. To circumvent the challenges with currently available particle tracking software, we have developed a new approach for particle identification and tracking, based on machine learning and convolutional neural networks (CNN). CNN is a type of feed-forward artificial neural network designed to process information in a layered network of connections that mimics the organization of real neural networks in the mammalian retina and visual cortex. Unlike most CNN imaging models that are trained to make predictions on static images, we have trained our CNN to input adjacent frames so that each prediction includes information from the past and future, thus effectively performing convolutions in both space and time to infer particle locations. Similar principles of image analysis are now being harnessed by developers of autonomous vehicle technologies to distinguish the motions of different objects on the road. We have applied our CNN tracking algorithm to a wide range of 2D movies capturing dynamic motions of nanoparticles, viruses and highly motile bacteria, achieving at least 30-fold time savings with virtually no need for human intervention while maintaining robust tracking performance (i.e. low false positive and low false negative rates). In this STTR proposal, we seek to focus on further optimization and testing of our neural network tracking platform for 2D PT, including the use of cloud computing (Aim 1), and extending our neural network tracker to enable accurate 3D PT (Aim 2). Our vision is to popularize PT as a research tool among researchers by minimizing the time and labor costs associated with PT analysis. Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a computational neural network that can recognize objects in much the same way as the human eye, and which consistently provided superior and truly automated tracking performance compared to current alternatives. This STTR will establish the feasibility of using our computational neural network for robust 2D and 3D particle tracking analysis.","Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes",9347679,R41GM123897,"['Adopted', 'Advanced Development', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Bacteria', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Classification', 'Cloud Computing', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diffuse', 'Ensure', 'Environment', 'Eye', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Link', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Performance', 'Phase', 'Photobleaching', 'Process', 'Property', 'Radial', 'Research', 'Research Personnel', 'Retina', 'Savings', 'Scientist', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Software Tools', 'Spottings', 'Students', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Virus', 'Vision', 'Visual Cortex', 'Work', 'base', 'biophysical tools', 'cell motility', 'cloud based', 'cost', 'design', 'experimental study', 'feeding', 'field study', 'graduate student', 'improved', 'insight', 'interest', 'macromolecule', 'movie', 'nanoparticle', 'novel strategies', 'particle', 'pathogen', 'physical science', 'response', 'spatiotemporal', 'submicron', 'terabyte', 'tool', 'virtual']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2017,224997,-0.0056287669375432725
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9322408,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,30900,-0.009299165570238523
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,0.0292746657047411
"A high-throughput imaging and classification system for fruit flies PROJECT SUMMARY / ABSTRACT In this Phase I SBIR application, FlySorter proposes to development a high throughput imaging and classification system to aid research with fruit flies, a widely-used model organism relevant to both basic science as well as studies in human health. The use of animal model systems is essential for research in almost all aspects of biology: genetics, development, neuroscience, disease, physiology, and beyond. The fruit fly – Drosophila melanogaster – is small and easy to care for, but is complex enough an organism to provide a wealth of information that directly relates to human biology and health. Over 75% of human diseases with a genetic basis (including depression, alcoholism, certain forms of cancer, and many more) are either present or have an analog in Drosophila. Modern genetic tools, such as CRISPR/cas9, allow the creation of transgenic flies that provide the opportunity to study diseases, pathways and systems that don’t exist naturally in Drosophila. With these advances, fruit flies are becoming more frequently subjects for drugs screens. For all the advances in the biological tools and techniques applicable to flies, however, the limiting factor in many experiments is the manual labor involved in a few common tasks: moving flies from vial to vial or other lab equipment; classifying and sorting flies by sex, eye color and other phenotypes; and collecting virgin female flies before they mate so that they can be used in controlled crosses, etc. FlySorter’s patent-pending fly dispensing mechanism can reliably deliver a single organism from a vial containing hundreds of awake flies, and our novel FlyPlate system allows storage of individual flies in custom 96 well plates. FlySorter’s robotic fly handling system, co-developed with the de Bivort Lab at Harvard, is capable of manipulating and transporting those individual flies between vial, 96 well plate, and experimental apparatus. The next piece of the automation puzzle to solve is high throughput imaging and classification. To accomplish this goal, FlySorter will: 1) complete a prototype automated image capture hardware system; 2) adapt state-of-the-art computer vision and machine learning algorithms for use on Drosophila; and 3) build a module that can physically sort the classified flies into different vials. Once integrated into the existing FlySorter product ecosystem, this imaging and classification module will greatly expand the kinds of experiments and screens that can be automated, allowing for the study of larger populations or a wider variety of flies, reducing the impact of human error, and freeing up valuable time for researchers. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are one of the most widely used model organisms in biology, for research in genetics, development, neuroscience, disease, and much more. One of the most common tasks in Drosophila labs is sorting flies by various markers and phenotypes using a microscope and paintbrush. FlySorter aims to build an automated system for sorting flies using high resolution digital cameras and modern computer vision algorithms, which will obviate the need for such tedious manual labor.",A high-throughput imaging and classification system for fruit flies,9408980,R43OD023302,"['Air', 'Alcoholism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Animals', 'Appearance', 'Automation', 'Basic Science', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Neural Networks', 'Biology', 'CRISPR/Cas technology', 'Caring', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Custom', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Pathway', 'Dorsal', 'Drosophila genus', 'Drosophila melanogaster', 'Ecosystem', 'Ensure', 'Eye', 'Eye Color', 'Female', 'Floor', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Head', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Legal patent', 'Lighting', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mechanics', 'Mental Depression', 'Methodology', 'Microscope', 'Modernization', 'Motor', 'Mutation', 'Names', 'Neurosciences', 'Obesity', 'Optics', 'Organism', 'Partner in relationship', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Preclinical Drug Evaluation', 'Pump', 'Research', 'Research Personnel', 'Resolution', 'Robot', 'Robotics', 'Sampling', 'Sclera', 'Shapes', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Standardization', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transgenic Organisms', 'Universities', 'Vial device', 'Walking', 'Work', 'analog', 'awake', 'base', 'depression model', 'digital', 'digital imaging', 'experimental study', 'fly', 'genetic strain', 'human disease', 'improved', 'interest', 'laboratory equipment', 'male', 'meter', 'novel', 'phenotypic biomarker', 'prevent', 'prototype', 'sex', 'tool', 'virtual']",OD,"FLYSORTER, LLC",R43,2017,225000,-0.006399823767708266
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9213309,R01EB008374,"['4D Imaging', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Pharmacology', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'clinical diagnostics', 'clinical predictors', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'serial imaging', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2017,451650,-0.019237302566677997
"Biomedical Image Analysis and Informatics The Biomedical Image Analysis and Services Section (BIRSS) is committed to providing computational and engineering expertise to a variety of clinical and biomedical informatics activities at NIH. Specifically, biomedical imaging research in PET, ultrasound, CT, MRI, microscopy, cancer research, and neural dysfunction have been supported extensively. To advance and empower scientific research in the NIH intramural program, CIT has developed and continues to enhance a sophisticated open source, platform-independent, n-dimensional, extensible image processing and visualization application. The MIPAV (Medical Image Processing Analysis and Visualization) (http://mipav.cit.nih.gov/) is an application that enables quantitative analysis and visualization of biomedical imaging modalities (from micro to macro) and is used by researchers at NIH and around the world. At NIH, MIPAV has been used to analyze anatomical structures in CT datasets, analysis of MRI datasets for NIMH, and has been used by NCI for the analysis of 2D and 3D microscopic samples.   In addition, BIRSS leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based system to support the collection and analysis of research studies and clinical trials, using a set of modular components that cover all stages of the research life cycle. And because BRICS is un-branded and not associated with a particular disease or organization, it can be efficiently custom-tailored for many research programs.  MIPAVs integrated set of biomedical imaging algorithms and its extensibility have been used by BIRSS to implement solutions to imaging problems in the NIH intramural research community dozens of times over.  To create custom workflows and solutions for intramural collaborators, BIRSS team members can build plug-ins that leverage the algorithms and tools in MIPAV to solve complex imaging research questions.  For example, BIRSS continues to develop a novel MIPAV plug-in as part of a collaboration with Dr. Hari Shroffs lab in the National Institute of Biomedical Imaging and Bioengineering (NIBIB) to untwist four-dimensional high-resolution microscopy images of the Caenorhabditis elegans nematode embryo throughout its development.  This plug-in used the image registration and visualization tools already developed by BIRSS for MIPAV, along with novel fiducial annotation and lattice warping tools, to allow the NIBIB researchers to annotate and regularize the C. elegans embryo data through its twitching phase of development, which has not previously been possible algorithmically.  This, in turn, allowed Dr. Shroffs group to investigate neurodevelopmental events in late embryogenesis and apply it to track the 3D positions of seam cell nuclei, neurons, and neurites in multiple elongating embryos. The detailed positional information obtained enabled NIBIB to develop a composite model showing movement of these cells and neurites in an 'average' worm embryo. The untwisting and cell tracking capabilities of this plug-in provides a foundation on which to catalog C. elegans neurodevelopment, allowing interrogation of developmental events in previously inaccessible periods of embryogenesis.  Accurate automatic organ segmentation is an important yet challenging task for medical image analysis.  Anatomical variability in shape and texture feature inhibits traditional segmentation methods from achieving high accuracies.    Machine learning has dominated the medical imaging research field in the past decade.  Initially, pioneer work with decent feature extraction and SVM based image classification achieves better results.  Later, learning based detection algorithm began to dominate the machine learning tools like boosting trees, random forest.   More recently the deep learning based Deep Convolutional Neural Networks (DCNNs) become the mainstream of the medical imaging research field for the past two years.   Using and enhancing the MIPAV application has allowed us to rapidly build the new machine learning component integral to the MIPAV software and is being used to support automated segmentation of the prostate.  BIRSS also leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based informatics system to support the collection and analysis of research studies and clinical trials. BRICS is un-branded and not associated with a particular disease or organization, therefore, it can be efficiently custom-tailored for many research programs. For example, in collaboration with the National Institute of Neurological Disorders and Stroke (NINDS), BIRSS has developed two informatics systems, using the BRICS system, in support of Traumatic Brain Injury (TBI)(http://fitbir.nih.gov/)research, the Parkinsons Disease Biomarker Program (PDBP) (http://pdbp.ninds.nih.gov/), as well as, collaborated with the National Eye Institute developed an informatics system for rare eye diseases, eyeGENE (https://eyegene.nih.gov/).  The TBI informatics system is called the Federal Interagency TBI Research (FITBIR) database to acknowledge the interagency participation and shared interests. FITBIR serves as a repository for TBI research, is supported by multiple federal agencies, and consolidates high quality, uniformly collected, and contemporary data that can be accessed and analyzed by scientific experts.  Over one million records have been uploaded to FITBIR thus far for 42,183 subjects enrolled in 85 different research studies. Currently there are 145 studies expected to contribute to FITBIR and the number of studies is growing every year. Within FITBIR are clinical outcome data and imaging data of which 36,000+ records are of imaging data (MRI, CT, PET and Diffusion) from 42,000+ individual subjects. A summary of the data can be found here: https://fitbir.nih.gov/content/submitted-data.  The goal of the PDBP, a BRICS system, is to support new and existing research and resource development promoting biomarker discovery for Parkinson's disease. Although our understanding of the biology and genetics associated with Parkinson's disease (PD) is advancing rapidly, gaps remain between promising laboratory discoveries and the realization of treatments that will cure or slow progression of PD. To address the needs of the PD community, NINDS has established the PDBP program focused on promoting the discovery of biomarker candidates for early detection and measurement of disease progression.  To date, the PDBP prospective consortium has 100% accrual at nine sites across the US with 1,536 enrolled subjects of which biorepository samples have been collected from 1,501 subjects. A summary of the data can be found here: https://pdbp.ninds.nih.gov/Data  The National Eye Institute (NEI) has also adopted the BRICS system to support The National Ophthalmic Disease Genotyping and Phenotyping Network (eyeGENE) (https://eyegene.nih.gov/). The eyeGENE project is a research venture created by NEI in response to promising scientific discoveries in genetics. eyeGENE aims to advance studies of eye diseases and their genetic causes by giving researchers access to DNA samples, clinical information, and patients looking to participate in research studies and clinical trials.  A summary of the data can be found here: https://eyegene.nih.gov/node/35. n/a",Biomedical Image Analysis and Informatics,9549704,ZIACT000272,"['Address', 'Adopted', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Biology', 'Biomedical Research', 'Caenorhabditis elegans', 'Catalogs', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Custom', 'DNA', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Embryo', 'Embryonic Development', 'Engineering', 'Enrollment', 'Event', 'Eye diseases', 'Foundations', 'Four-dimensional', 'Genetic', 'Genotype', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging problem', 'Individual', 'Informatics', 'Intramural Research', 'Intramural Research Program', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Measurement', 'Medical Imaging', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Nematoda', 'Neurites', 'Neuronal Dysfunction', 'Neurons', 'Online Systems', 'Organ', 'Outcome', 'Parkinson Disease', 'Patients', 'Phase', 'Phenotype', 'Plug-in', 'Positioning Attribute', 'Positron-Emission Tomography', 'Prostate', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resolution', 'Resource Development', 'Resources', 'Sampling', 'Services', 'Shapes', 'Site', 'Speed', 'System', 'Techniques', 'Texture', 'Time', 'Traumatic Brain Injury', 'Trees', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization software', 'Work', 'anticancer research', 'base', 'biobank', 'bioimaging', 'biomarker discovery', 'biomedical informatics', 'candidate marker', 'cell motility', 'clinical imaging', 'forest', 'high dimensionality', 'image processing', 'image registration', 'image visualization', 'imaging informatics', 'imaging modality', 'informatics infrastructure', 'interest', 'member', 'microscopic imaging', 'n-dimensional', 'neurodevelopment', 'novel', 'open source', 'platform-independent', 'programs', 'prospective', 'repository', 'research and development', 'research study', 'response', 'tool', 'web-based informatics']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2017,1007609,0.0242944270777338
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9315808,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Computing', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'image guided', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'public health relevance', 'quantitative imaging', 'response', 'task analysis', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2017,413289,0.048235464336763956
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris�n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris�n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9264531,R01EY023279,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Categories', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Morphology', 'Nerve Fibers', 'Ophthalmoscopes', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2017,339750,0.0035069763880461757
"Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET ﻿    DESCRIPTION (provided by applicant): Ischemic cardiomyopathy affects approximately 3 million people in the United States. This form of heart failure is the result of myocardial infarcton or severe coronary heart disease that reduces the viability and function of the heart. Ischemic cardiomyopathy is associated with poor long-term survival when patients with viable myocardium are not revascularized. By imaging myocardial blood flow and glucose metabolism and seeking flow-metabolism mismatches, positron emission tomography (PET) method has been established as the gold standard of assessing myocardial viability for selecting patients who can benefit most from surgical revascularization. Current PET method employs two separate static scans with two different radiotracers for generation of the flow-metabolism image pair. While the image of glucose metabolism is acquired using the most widely used radiotracer 18F- fluorodeoxyglucose (FDG), myocardial blood flow imaging with the radiotracer 13N-ammonia or rubidium-82 suffers from limited clinical availability. In addition, the imaging protoco of two separate imaging sessions is time consuming and resource intensive. As a result, myocardial viability via PET is currently under-utilized in clinic despite its high accuracy and th fast-growing installation of PET/CT scanners in the past decade. In this project, we propose to develop a novel PET method for myocardial viability assessment that only uses a single injection of FDG without the need of a flow- specific radiotracer. We hypothesize that myocardial blood flow can be derived from the quantitative kinetic parameters of dynamic FDG PET. We will develop a new multi-variable prediction model using statistical machine learning to predict myocardial blood flow from dynamic FDG PET data. We will also develop a shortened dynamic FDG PET protocol to improve practicality. This innovation will provide the flow-metabolism image pair for myocardial viability assessment in a clinically favorable time, cost and with reduced radiation dose. Success of this research will make PET assessment of myocardial viability more widely available in clinic with easier access, lower radiation dose, cheaper imaging cost and shorter clinical visit time as compared with conventional two-session protocols, thus improving our clinical practice of treating ischemic cardiomyopathy. PUBLIC HEALTH RELEVANCE: Positron emission tomography (PET) is a gold standard method for detecting viable myocardium to select which patients with ischemic cardiomyopathy to benefit most from surgical revascularization. Its use in clinic, however, is under-utilized because of the limited clinical availability of the radiotracers needed. This research aims to develop a novel PET imaging method for assessment of myocardial viability that can be easily accessed in clinic with reduced lower radiation dose and imaging cost without compromising imaging performance.",Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET,9251317,R21HL131385,"['Address', 'Affect', 'Algorithms', 'Ammonia', 'Blood', 'Blood Glucose', 'Blood flow', 'Cardiac', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Trials', 'Coronary heart disease', 'Cyclotrons', 'Data', 'Dependence', 'Dose', 'Echocardiography', 'Evaluation', 'Generations', 'Goals', 'Gold', 'Heart failure', 'Hour', 'Image', 'Injection of therapeutic agent', 'Investments', 'Kinetics', 'Low Dose Radiation', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial tissue', 'Myocardium', 'Noise', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Recruitment Activity', 'Research', 'Resolution', 'Resources', 'Rubidium', 'Scanning', 'Site', 'Testing', 'Time', 'Time Study', 'Tracer', 'United States', 'Visit', 'clinical practice', 'cost', 'experience', 'fluorodeoxyglucose', 'fluorodeoxyglucose positron emission tomography', 'glucose metabolism', 'glucose transport', 'heart function', 'image reconstruction', 'imaging modality', 'implantable device', 'improved', 'innovation', 'ischemic cardiomyopathy', 'mortality', 'novel', 'perfusion imaging', 'public health relevance', 'radiotracer', 'single photon emission computed tomography', 'success', 'uptake']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2017,195625,0.027147030686627563
"High Performance Automated System for Analysis of Fast Cardiac SPECT DESCRIPTION (provided by applicant): Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before a heart attack, and predict risk in millions of patients annually. This is currently limited by the need fo visual interpretation, which is highly variable and depends on the physician's experience. The long-term objective of this program is to improve the interpretation of this widely used heart imaging technique-achieving higher accuracy for disease detection than it is possible by the best attainable visual analysis. This proposal builds on our prior work in conventional myocardial MPS, and focuses on fast, low-radiation MPS imaging (fast-MPS) obtained by new high-efficiency scanners. Specifically, we aim to: 1) develop new image processing algorithms for a fully automated analysis of fast-MPS. The algorithms will include better heart muscle detection by training with correlated anatomical data and a novel approach for mapping the probability of abnormal perfusion for each location of the heart muscle; 2) enhance the diagnosis of heart disease from fast-MPS by machine- learning algorithms that integrate clinical data, stress test parameters, and quantitative image features; 3) demonstrate the clinical utility of the new algorithms applied to automatic canceling of the rest portion of the MPS scan, when not needed. The new system will be more accurate than the clinical expert analysis in the detection of obstructive coronary disease. By immediately indicating whether a stress scan is normal, the system will allow for the automatic cancellation of the rest imaging portion when it is not needed (estimated in over 60% of all MPS studies). Our research will demonstrate that the computer decision regarding rest-scan cancellation is safe for the patient, both from a diagnostic and prognostic standpoint. This will lead to a wide adoption of low-dose stress-only imaging for MPS studies, which would reduce the amount of radiation that patients are exposed to, and allow for significant healthcare savings. It will additionally lead to a paradigm shift in the practice of nuclear cardiology, which will ultimately result in better selection of patients who need intervention, and reduce the number of deaths due coronary artery disease. PUBLIC HEALTH RELEVANCE: Imaging of myocardial perfusion (heart muscle blood flow) at rest and stress allows physicians to detect disease and predict risk in millions of patients in the US each year, but it is currently limited by the need of visual interpretation, which is dependent on doctor's experience. The investigators propose to develop and validate an automated, highly-accurate and objective computer system which will outperform even experienced physicians in interpreting these images using latest generation scanners and novel machine learning computer tools. The computer will be able to better select patients needing treatment and automatically indicate the normal stress-scan immediately, and more accurately than physicians allowing automatic cancellation of the rest imaging, when not needed; this will result in large healthcare savings and reduced radiation to the patients.",High Performance Automated System for Analysis of Fast Cardiac SPECT,9282634,R01HL089765,"['Adoption', 'Algorithms', 'Anatomy', 'Blood', 'Blood flow', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Collimator', 'Complex', 'Computer Analysis', 'Computer Systems', 'Computer software', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Coupled', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Dose', 'Generations', 'Grant', 'Healthcare', 'Heart Diseases', 'Human', 'Image', 'Imaging Techniques', 'Industry', 'Intervention', 'Lead', 'Location', 'Machine Learning', 'Maps', 'Medical Imaging', 'Methods', 'Mitral Valve', 'Multicenter Studies', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Patient Selection', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Probability', 'Protocols documentation', 'Public Health', 'Radiation', 'Reader', 'Reading', 'Recovery', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Risk', 'Savings', 'Scanning', 'Site', 'Stress', 'Stress Tests', 'System', 'Systems Analysis', 'Techniques', 'Testing', 'Training', 'United States', 'Visual', 'Work', 'attenuation', 'base', 'cardiac single photon emission computed tomography', 'cardiovascular risk factor', 'clinical imaging', 'computer generated', 'cost', 'detector', 'diagnostic accuracy', 'experience', 'heart imaging', 'image processing', 'improved', 'novel', 'novel strategies', 'patient population', 'prognostic', 'programs', 'public health relevance', 'quantitative imaging', 'reconstruction', 'single photon emission computed tomography', 'solid state', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2017,600120,0.014591966304917312
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9197624,R01CA193730,"['Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modality', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'public health relevance', 'quality assurance', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2017,359444,-0.010717456739707604
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,56360,0.02229960032088547
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,25000,0.02229960032088547
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,454865,0.02229960032088547
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,100000,0.02229960032088547
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9315773,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Darkness', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2017,619539,0.012686012897553426
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9150601,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2017,326571,0.016505465945273818
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle. PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9355100,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Intuition', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Morphology', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscle function', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2017,391844,0.023849925105576625
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9268035,R01HL122484,"['3D ultrasound', '4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Discipline of Nuclear Medicine', 'Dose', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radiation exposure', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical imaging', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging approach', 'imaging modality', 'improved', 'individual patient', 'interest', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2017,770494,0.04630148028577662
"Area B:  Multi-Tracer Volumetric PET (MTV-PET) to Measure Tumor Glutamine and Glucose Metabolic Rates in a Single Imaging Session Precision oncology places an increased demand on cancer diagnostics to characterize tumors at the time of diagnosis. Tissue diagnostics for precision oncology increasingly rely on multi-valent assays to characterize cancer biology and identify therapeutic targets. The power of molecular imaging for cancer diagnosis has been well demonstrated by [18F]fluorodexoyglucose positron emission tomography (FDG PET/CT), widely used in clinical oncology. PET tracers targeted to facets of tumor biology now enable multi-valent molecular imaging to identify therapeutic targets. Early studies show that combined tracer studies, commonly FDG plus a target- specific tracer, are highly predictive of tumor response to targeted therapy. However, emissions from different PET tracers are indistinguishable to a PET scanner, requiring separate imaging sessions on separate days for multiple 18F-based tracers (~ 2 hour half-life) in the same patient. This limits the clinical practicality of multi-tracer PET, and fails to exploit the full power of multi-tracer PET to quantify tumor in vivo biology and biologic heterogeneity for highly variable process such as cancer metabolism. We will overcome this limitation by taking advantage of recent developments in volumetric PET scanners, fast reconstruction, and 4D image analysis methods from our laboratories to develop Multi-Tracer Volumetric PET (MTV-PET) to generate multi-valent, quantitative biologic parametric images for two or more tracers in a single session to guide precision oncology and translational cancer biology research. As such, our proposed technology development project addresses a need, described under Priority Area B for “new capabilities for advancing precise clinical diagnosis of cancer patients”. Using methods developed in our laboratories, we now propose to integrate and enhance these methodologies to develop and validate Multi-Tracer Volumetric PET (MTV-PET) to generate quantitative biologic parametric images for two or more tracers in a single session. We will develop and test this approach for simultaneous glucose and glutamine metabolism imaging, with the goal of guiding metabolism-targeted therapy such as inhibitors of glutaminase (GLS) and lactate dehydrogenase (LDH). The project will focus on the technology developments (largely computational) that enable multi-tracer imaging. Ongoing and separately funded work on clinical studies will acquire data from two separate imaging PET sessions using current technology and will provide data for method development. We will first optimize tracer dose timing, image reconstruction, and image time binning for dual tracer MTV-PET (Aim 1), followed by implementation and technical validation of image analysis using a mixture analysis approach (Aim 2). This will set the stage for technical validation of MTV-PET (Aim 3) and an exploratory aim (Aim 4) testing image analytics based on machine learning. Successful completion of our technology development will yield a new method for multi-tracer PET that would change the landscape for cancer imaging diagnostic biomarker and precision oncology research, consistent with goals of RFA-CA-17-023 Priority Area B. PROJECT NARRATIVE Our proposed technology development in response to RFA-CA-17-023 (Integration and Validation of Emerging Technologies to Accelerate Cancer Research) addresses a need for more precise diagnosis for precision oncology, under Priority Area B: “New capabilities for advancing precise clinical diagnosis of cancer patients”. We will advantage of recent developments in volumetric positron emission tomography (PET) scanners, fast reconstruction, and 4D image analysis to develop methods for multi-tracer PET with the goal of generating quantitative, multi-parametric whole-body images of specific aspects of cancer biology, including cancer metabolism as the focus of our proposed technology development projects. Successful completion of our proposed technology development will yield a clinically practical method for multi-tracer PET that would provide multi-valent, whole body molecular parametric images that would change the landscape for cancer imaging diagnostic biomarkers and precision oncology research, targeted to RFA-CA-17-023 Priority Area B.",Area B:  Multi-Tracer Volumetric PET (MTV-PET) to Measure Tumor Glutamine and Glucose Metabolic Rates in a Single Imaging Session,9483034,R33CA225310,"['4D Imaging', 'Address', 'Agreement', 'Algorithms', 'Area', 'Biological Assay', 'Biology', 'Breast Cancer Patient', 'Cancer Biology', 'Cancer Diagnostics', 'Cancer Patient', 'Clinical', 'Clinical Data', 'Clinical Oncology', 'Clinical Research', 'Cluster Analysis', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Emerging Technologies', 'Funding', 'Glucose', 'Glutaminase', 'Glutamine', 'Glycolysis', 'Goals', 'Half-Life', 'Heterogeneity', 'Hour', 'Human', 'Image', 'Image Analysis', 'Injection of therapeutic agent', 'Kinetics', 'Laboratories', 'Lactate Dehydrogenase', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Outcome', 'Patients', 'Phenotype', 'Positron-Emission Tomography', 'Process', 'Radiation exposure', 'Reference Standards', 'Research', 'Technology', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Tracer', 'Tumor Biology', 'Validation', 'Work', 'analytical method', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'clinical Diagnosis', 'cohort', 'diagnostic biomarker', 'genomic biomarker', 'glucose metabolism', 'high dimensionality', 'image reconstruction', 'imaging biomarker', 'in vivo', 'inhibitor/antagonist', 'malignant breast neoplasm', 'metabolic rate', 'method development', 'molecular imaging', 'novel', 'parametric imaging', 'personalized diagnostics', 'phenotypic biomarker', 'precision oncology', 'radiotracer', 'reconstruction', 'response', 'targeted treatment', 'technology development', 'therapeutic target', 'tumor', 'tumor heterogeneity', 'tumor metabolism', 'whole body imaging']",NCI,UNIVERSITY OF PENNSYLVANIA,R33,2017,1448329,-0.01768391900024578
"Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography PROJECT SUMMARY Integrated analysis of coronary anatomy and biology using 18F-fluoride PET and CT angiography Each year, 735,000 Americans have an acute myocardial infarction (heart attack), and approximately 120,000 die from it. Heart attacks occur most commonly due to rupture of atherosclerotic plaques in coronary arteries. Despite this, current diagnostic and treatment algorithms make no allowance for the assessment of disease activity and currently all patients with atherosclerosis are treated in a similar manner. This failure to differentiate stable from active disease may result in potentially unnecessary or insufficient therapies. In a breakthrough series of studies, our co-investigators discovered that positron emission tomography (PET) with 18F-sodium- fluoride (18F-NaF; an inexpensive and widely available tracer approved by Food and Drug Administration) can readily identify plaque rupture and increased coronary plaque activity. We propose to build further on this success, by addressing several important remaining limitations that prevent us from translating this technology to broad clinical use. The limitations include complicated and subjective image analysis, underutilization of the concomitant coronary computed tomography angiography (CTA) for plaque characterization, inability to utilize prior CTA for the analysis of 18F-NaF PET, lack of methods to integrate all available PET and CTA data and significant motion of the coronaries during the PET scan. We propose a multi-faceted approach to automate and improve coronary 18F-NaF PET imaging by full integration with CTA and correction for cardiac, respiratory, and patient motion. The overall goal of the proposal is to optimize the measurement of disease activity in coronary atherosclerosis using integrated 18F-NaF PET/CTA imaging, with the opportunity to validate this development against clinical outcome in a “real-world” multicenter patient study. For this work, we propose the following 3 specific aims: 1) to integrate quantification of CTA and PET image data 2) to develop new methods for simultaneous correction of cardiac, respiratory, and patient motion for coronary PET, and 3) to clinically evaluate new methods in a multicenter clinical trial (separately funded and already underway), further refining risk prediction for heart attacks with integrated PET+CTA risk score derived by machine learning. This work will lead to a robust and reproducible clinical method for stratification of patients for risk of heart attacks, with potential to be applied for the identification of patients who would most benefit from expensive, and potentially risky treatments. Our techniques could also be used in future clinical trials to test the efficacy of novel therapies. Moreover, the new analysis will be applicable to other PET tracers that may be developed to investigate other pathological processes in the coronary vasculature. The resulting software will be shared with clinical institutions performing coronary PET to facilitate standardization and automation of this novel plaque imaging technique. NARRATIVE A heart attack, a major cause of death, is most commonly caused by rupture of deposits in heart vessels, leading to sudden blockage of the blood flow in the vessels and disruption of blood supply to the heart muscle. Currently there is no reliable test to identify deposits at the highest risk of rupture, but in a recent scientific breakthrough, positron emission tomography has demonstrated capability to image disease activity inside these deposits, linked to their rupture; this technique, however, is currently hampered by lack of anatomical reference, image blurring due to heart motion, and variability of manual analysis. We propose to address these problems by developing automatic software that precisely integrates anatomical and biological information and virtually “freezes” vessel motion, validating this new approach in a large “real-world” multicenter patient study.",Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography,9382827,R01HL135557,"['Acute myocardial infarction', 'Address', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Area', 'Arterial Fatty Streak', 'Atherosclerosis', 'Automation', 'Binding', 'Biological', 'Biological Process', 'Biology', 'Blood flow', 'Breast Microcalcification', 'Cardiac', 'Cause of Death', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer software', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Enrollment', 'Event', 'FDA approved', 'Failure', 'Fluorides', 'Freezing', 'Funding', 'Future', 'Goals', 'Heart', 'Histologic', 'Image', 'Image Analysis', 'Imaging Techniques', 'Inflammation', 'Institution', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardium', 'Noise', 'Outcome', 'Pathologic Processes', 'Patient risk', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Radiation', 'Recurrence', 'Reporting', 'Reproducibility', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk stratification', 'Rupture', 'Scanning', 'Series', 'Signal Transduction', 'Sodium Fluoride', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tracer', 'Translating', 'United States Food and Drug Administration', 'Vascular blood supply', 'Work', 'X-Ray Computed Tomography', 'coronary computed tomography angiography', 'cost', 'disorder risk', 'efficacy testing', 'experience', 'fluorodeoxyglucose positron emission tomography', 'heart motion', 'high risk', 'imaging study', 'improved', 'novel', 'novel strategies', 'novel therapeutics', 'patient stratification', 'prevent', 'prospective', 'respiratory', 'success', 'uptake', 'virtual']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2017,771431,0.017391526361552098
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9324146,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Modernization', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Privatization', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissues', 'Tumor Burden', 'base', 'cancer biomarkers', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'clinical predictors', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'predictive of treatment response', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'specific biomarkers', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2017,487132,-0.0031273751225334634
"Software for OCT Analysis of Vascular Stents Software for OCT Analysis of Vascular Stents PI: Ronny Shalev, PhD, Dyad Medical Summary Dyad Medical, Inc. will create intravascular OCT (IVOCT) software for clinical, live time determination of stent apposition (OCTivat-live, the live time OCT image visualization and analysis tool) and for offline analysis of stent implantation (OCTivat-stent). Every year, 100s of thousands of patients in the US are treated with intra- vascular stents creating an opportunity for both solutions. Although advancements such as drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent design parameters include drug, material (bioresorbable vs metal), polymer composition, coatings to stimulate cell coverage, etc. To opti- mize designs, sensitive, in vivo assessments are needed for preclinical and clinical evaluations. Intravascular OCT (IVOCT) is the lone imaging modality with the resolution and contrast to meet this challenge. The Core Lab at CWRU is the premiere site in the world for manual analysis of IVOCT image data. A cardiologist analyst takes 6-16 hrs to analyze manually a single stent, and despite training and quality assurance measures, inter- analyst variability can limit the power to determine changes between stent designs. Building upon work at CWRU, we will develop advanced, highly automated software to greatly speed analysis, improve reproducibil- ity, increase accuracy, and harmonize analysis. Software will reduce costs by decreasing manual labor, and with improved reproducibility, possibly enable the use of historical data, eliminating cost of a control arm. Re- garding live time analysis, rather than manually reviewing >500 images in a pullback, with fast software, it will be possible to present the number and location of malapposed struts in 3D, providing instant feedback to phy- sicians on the need for additional dilatation with a larger balloon or higher pressure. In addition, we will auto- matically determine stent and vessel area along the length of the pullback, allowing us to compute stent ex- pansion and eccentricity, quantitative measures related to successful stent deployment, the most important de- terminant of outcome. IVOCT could also play a role at patient follow up. If a stent is well covered, then long- term anti-platelet therapy might be unnecessary, minimizing bleeding risk. If a stent has many uncovered struts, a therapeutic might prevent stent thrombosis or stimulate healing. Project Narrative: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies and improved deployment for improved treatment of vascular dis- ease.",Software for OCT Analysis of Vascular Stents,9407267,R43HL137500,"['Agreement', 'Algorithms', 'Area', 'Blinded', 'Blood Vessels', 'Cells', 'Classification', 'Clinical', 'Clinical Trials', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dilatation - action', 'Doctor of Philosophy', 'Feedback', 'Follow-Up Studies', 'Heart', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Institutes', 'International', 'Ions', 'Laboratories', 'Length', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Metals', 'Methods', 'Myocardial Ischemia', 'Needs Assessment', 'Outcome', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Polymers', 'Process', 'Reproducibility', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Services', 'Site', 'Speed', 'Stents', 'Surrogate Markers', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Variant', 'Vascular Diseases', 'Work', 'arm', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'image visualization', 'imaging modality', 'implantation', 'improved', 'in vivo', 'personalized diagnostics', 'preclinical evaluation', 'pressure', 'prevent', 'prototype', 'quality assurance', 'research clinical testing', 'restenosis', 'statistics', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,"DYAD MEDICAL, INC.",R43,2017,224744,0.012680081442968396
"DEVELOPMENT OF A RAPID METHOD FOR IMAGING REGIONAL VENTILATION IN SMALL ANIMALS W/O CONTRAST AGENTS The objective of this R01 application is to develop a rapid method for imaging regional ventilation and lung compliance in small animals without contrast agents. Much of our current understanding of the normal functioning of the lung and mechanisms of lung disease comes from small animal studies. However, lung function imaging in small animal models is technically challenging due to motion and the relatively small size of the lungs. Pulmonary function testing using plethysmography has been employed to assess lung function and injury with limited validity and utility, particularly in small animals. Additionally, only aggregate measures of functional performance are produced and no regional lung changes can be assessed. An improved imaging method that could provide spatially- and temporally-resolved information regarding ventilation would be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases. It would also facilitate drug discovery and efficacy studies aimed to mitigate respiratory pathology. The ideal method would provide quantitative regional functional information, be applicable to longitudinal studies (low radiation dose), and have a simple and affordable implementation that permits widespread use. Currently available imaging methods including micro-CT or MRI fall short in one or more of these requirements.  To address this need, we will establish and evaluate a novel, easy to implement, and highly effective X- ray phase-contrast (XPC) method for ventilation imaging in small animal models. The lung is ideally suited to XPC imaging because it is comprised mainly of air spaces separated by thin tissue structures. The air-tissue interfaces cause the X-ray beam to experience numerous and strong refractions that produce a distinctive texture in the intensity measured over the lungs known as speckle. Detailed information regarding the regional lung air volume (RLAV) distribution is encoded in the speckle. The benefits of exploiting lung speckle for detecting and monitoring lung function are numerous but remain entirely unexplored for benchtop imaging.  Our approach involves a high degree of technical innovation regarding image formation methods and will significantly extend the current boundaries of functional lung imaging in small animals. The proposed method, referred to as parametric XPC (P-XPC) imaging, will produce 2D parametric images that depict the projected RLAV distribution. When differential images are computed for any given two points in the breathing cycle, ventilation or lung compliance imaging will be achieved. Preliminary in vivo and computational studies have been conducted in support of the proposed research. The specific aims of the project are as follows. Aim 1: Develop P-XPC image formation methods for estimating the projected RLAV distribution; Aim 2: Optimize an XPC imaging system for P-XPC imaging. Aim 3: Evaluate the diagnostic capability of P-XPC imaging in two pre-clinical animal models of disease in vivo. The proposed research will result in a novel, easy to implement, and highly effective X-ray phase-contrast (XPC) method for functional lung imaging in small animal models. It will provide spatially- and temporally- resolved information regarding lung ventilation that will be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases.",DEVELOPMENT OF A RAPID METHOD FOR IMAGING REGIONAL VENTILATION IN SMALL ANIMALS W/O CONTRAST AGENTS,9309904,R01EB023045,"['Address', 'Air', 'Animal Disease Models', 'Animal Model', 'Animals', 'Breathing', 'Communities', 'Contrast Media', 'Development', 'Diagnostic', 'Dose', 'Environmental air flow', 'Evaluation', 'Functional Imaging', 'Image', 'Imaging technology', 'Learning', 'Longitudinal Studies', 'Lung', 'Lung Compliance', 'Lung diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Monitor', 'Motion', 'Mus', 'Pathology', 'Performance', 'Phase', 'Physics', 'Physiology', 'Plethysmography', 'Process', 'Pulmonary Emphysema', 'Pulmonary function tests', 'Radiation', 'Research', 'Resolution', 'Resource Sharing', 'Respiratory physiology', 'Roentgen Rays', 'Scientist', 'Source', 'Structure', 'Supervision', 'System', 'Technical Degree', 'Techniques', 'Texture', 'Thinness', 'Time', 'Tissues', 'Translating', 'animal imaging', 'base', 'computer studies', 'contrast imaging', 'cost', 'detector', 'drug discovery', 'drug efficacy', 'efficacy study', 'experience', 'falls', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'innovation', 'learning strategy', 'lung imaging', 'lung injury', 'lung pressure', 'lung volume', 'microCT', 'mouse model', 'novel', 'parametric imaging', 'pre-clinical', 'pressure', 'rapid technique', 'respiratory']",NIBIB,WASHINGTON UNIVERSITY,R01,2017,489676,-0.007344899037082696
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9316507,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2017,379732,0.05179957234559452
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers. PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9330810,UH2CA203710,"['Algorithms', 'Artificial Intelligence', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Classification', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Image Analysis', 'Institutes', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Nonprofit Organizations', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Specificity', 'Statistical Models', 'Students', 'Technology', 'Territoriality', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'fine art', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'virtual', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2017,320900,-0.009125501051804959
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9300962,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'success', 'tool', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2017,169609,0.020196330208896263
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,9194390,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Internet', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'analytical method', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'public health relevance', 'sample fixation', 'screening', 'tool', 'transmission process', 'virtual']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,611703,0.01374142401715393
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9212187,R01HL121226,"['Acute', 'Anatomy', 'Autopsy', 'Bayesian Modeling', 'Biomechanics', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Heart Ventricle', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Pharmacology', 'Phase', 'Physiology', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'perfusion imaging', 'public health relevance', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2017,768639,0.012116660210422812
"Statistical methods for large and complex databases of ultra-high-dimensional DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.",Statistical methods for large and complex databases of ultra-high-dimensional,9320865,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multicenter Studies', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'analytical tool', 'base', 'bioimaging', 'clinical practice', 'contrast enhanced', 'data visualization', 'design', 'high dimensionality', 'imaging Segmentation', 'imaging modality', 'imaging study', 'member', 'neuroimaging', 'next generation', 'open source', 'public health relevance', 'skills', 'spatiotemporal', 'study population', 'terabyte', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2017,347156,0.008295021665244493
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, image refers not only to biomedical images, but also to illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. We are seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. To meet these objectives, we use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers richer search results.   A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and the modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval are achieved in the following ways: (i) using image analysis; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. Additional steps include describing an image with visual features, automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.), and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed Open-i (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. The Open-i system enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 1.2 million open access articles and nearly 3.7 million illustrations from the biomedical literature hosted at the National Library of Medicine's PubMed Central repository; over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays; 67,517 images from NLM History of Medicine collection; and about 2,064 orthopedic anatomy illustrations provided by Norris Medical Library, University of Southern California. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publisher's Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to search for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using a clinical image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. Open-i indexes all the text and illustrations in medical articles by features, both textual and image-based. Open-i also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and de-identified patient records, as well as the orthopedic and historical images. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first and perhaps only production-quality system of its kind in the biomedical domain, Open-i has enabled medical professionals and the public to access visual information from biomedical articles that are highly relevant to their query, as well as the ""take away"" messages of the articles. The quality of the information delivered by Open-i has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system placed first in the 2013 image retrieval evaluation that attracted participants from academia, industry and clinical settings. For the past year the site has attracted over 10,000 unique visitors daily (excluding bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. During the FY2017, the Open-i suite of services was joined by MedPix https://medpix.nlm.nih.gov/home, a searchable online database of medical images, teaching cases and clinical topics, integrating images and textual metadata including over 19,000 patient case scenarios and nearly 54,000 images.  MedPix is organized by disease location (organ system), pathology category, patient profiles, and by image classification and captions. The collection is searchable by keywords, image types, authors, and many other search options.  In addition to searching and browsing images and cases, the MedPix website provides free AMA Category 1 CME credits online.   Registered users can submit interesting cases to Open-i, MedPix, or both using a dedicated Case Upload Server https://cup.nlm.nih.gov/login.   Additionally this year we explored or advanced algorithms for summarizing video, labeling images, panel segmentation, and visual question answering. n/a",Integrating image and text information for biomedical information retrieval,9554454,ZIALM010001,"['Academia', 'Algorithms', 'Anatomy', 'Bibliography', 'California', 'Categories', 'Classification', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Differential Diagnosis', 'Disease', 'Educational process of instructing', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'History of Medicine', 'Home environment', 'Hybrids', 'Image', 'Image Analysis', 'Indiana', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Label', 'Letters', 'Link', 'Literature', 'Location', 'MEDLINE', 'Manuals', 'MeSH Thesaurus', 'Medical', 'Medical Imaging', 'Medical Libraries', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Orthopedics', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Services', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Visual', 'Work', 'base', 'bioimaging', 'body system', 'clinical imaging', 'cluster computing', 'digital', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'multimodality', 'patient oriented', 'phrases', 'profiles in patients', 'radiological imaging', 'repository', 'search engine', 'text searching', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2017,317997,0.009221563668634108
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9244841,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2017,63883,0.01080629321577253
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study No abstract available Project Narrative This study will use computer image analysis techniques to improve our understanding of the causes of diagnostic errors during the interpretation of skin biopsy specimens, as well as seek ways to reduce such errors. As skin biopsies are one of the most common medical procedures performed in the U.S., the results of this study have important implications for patients as these tests are frequently used to guide important treatment recommendations for melanoma and surveillance recommendations for dysplastic nevi.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9666656,R01CA200690,[' '],NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2017,283866,-0.0015372191005172265
"Neuronal Network Analysis Tools for Large Calcium Imaging Datasets No abstract available Project Narrative Recently, we have shown that we can image 100s to 1000s of neurons concurrently in awake, behaving animals using wide-field calcium imaging. The goal of this research proposal is to develop scalable, robust analysis methods to analyze neuronal networks and sub-networks of this size and scale. These analysis methods will have the potential to connect our understanding of network function at the cellular level with network function at the whole-brain level.",Neuronal Network Analysis Tools for Large Calcium Imaging Datasets,9470517,F31NS105420,"['Address', 'Animals', 'Area', 'Back', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Brain region', 'Calcium', 'Calcium Spikes', 'Cells', 'Chemicals', 'Classification', 'Classification Scheme', 'Communities', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Detection', 'Foundations', 'Genetic', 'Genetic Markers', 'Goals', 'Hippocampus (Brain)', 'Image', 'Individual', 'Interneurons', 'Label', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Memory', 'Methods', 'Monitor', 'Mus', 'Neurons', 'Neurosciences', 'Parvalbumins', 'Pathway Analysis', 'Process', 'Reporting', 'Research Personnel', 'Research Proposals', 'Resolution', 'Rest', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Transgenic Mice', 'Work', 'awake', 'cell type', 'conditioning', 'experimental study', 'imaging modality', 'insight', 'interest', 'mouse model', 'network models', 'novel', 'response', 'tool']",NINDS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),F31,2017,30011,-0.005796057179221896
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9350173,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anatomy', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathologic', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical imaging', 'clinical phenotype', 'clinical practice', 'cloud based', 'cluster computing', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'multidisciplinary', 'new technology', 'novel', 'open source', 'outreach', 'public health relevance', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2017,597688,0.03904125267400077
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9341177,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2017,579791,0.007782822129024382
"MalariaScreener: image analysis and machine learning for detecting malaria in blood   film  The Lister Hill National Center for Biomedical Communications at NLM is developing a software called MalariaScreener, which can count parasite-infected and uninfected red blood cells, using automatic image analysis and machine learning algorithms. The software, which received an HHS Ventures Award, has been ported from MATLAB to Android smartphones by imaging scientists at NLM and University of Missouri. Running on a camera-equipped smartphone that is attached to a microscopes eyepiece by an adapter, the software screens the field of view for malaria parasites and reports the level of parasitemia to the microscopist. MalariaScreener first identifies red blood cells using segmentation methods such as watershed and level-sets. Then, it computes features that can detect the typical color and shape of parasites. A support vector machine performs the final classification into infected and uninfected cells based on the features computed. MalariaScreener has been trained with more than 200,000 blood cell images acquired from 150 malaria-infected and 50 uninfected patients, which have been annotated by an expert microscopist using a tailored online annotation tool. The encouraging performance of the MalariaScreener prototype in the lab has motivated preparations for testing the system at multiple sites in the field. After field-testing, the smartphone application will be made publicly available for download to other malaria screening sites in the world. With the feedback from expert microscopists, research will continue with implementing sophisticated cell segmentation techniques and deep learning methods to improve the system performance where needed. Another direction of future research is the automatic discrimination between different parasite species and their stage of development. n/a",MalariaScreener: image analysis and machine learning for detecting malaria in blood   film ,9358289,ZICLM010006,"['Africa', 'Algorithms', 'Android', 'Award', 'Blood', 'Blood Cells', 'Cells', 'Cellular Phone', 'Cessation of life', 'Child', 'Childhood', 'Classification', 'Color', 'Communication', 'Computer software', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discrimination', 'Disease', 'Drug resistance', 'Erythrocytes', 'Feedback', 'Field Workers', 'Film', 'Goals', 'Image', 'Image Analysis', 'Machine Learning', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Methods', 'Microscope', 'Microscopic', 'Missouri', 'Mosquito Control', 'Parasitemia', 'Parasites', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Preparation', 'Reporting', 'Research', 'Running', 'Scientist', 'Shapes', 'Site', 'Staging', 'System', 'Techniques', 'Testing', 'Training', 'Universities', 'Workload', 'base', 'cellular imaging', 'digital imaging', 'disability', 'experience', 'field study', 'fighting', 'global health', 'improved', 'learning strategy', 'light microscopy', 'malaria infection', 'mortality', 'prototype', 'screening', 'skills', 'therapy development', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIC,2016,342916,-0.11347913238989725
"Image analysis and machine learning for pulmonary disease screening Our research toward the development of these algorithms has resulted in novel image analysis algorithms (graph cut, atlas based) that identify lung boundaries and delineate lung regions in the posteroanterior CXR. The research has also resulted in novel combinations of shape, edge and texture descriptors computed from pixels within the lung boundaries. These image descriptors are then used to train a supervised machine learning classifiers (e.g., SVM).   We have acquired 4 datasets for testing these algorithms and have made them publicly available for enabling scientific research on the topic. These datasets have been downloaded by over 200 researchers from academic and industrial research labs worldwide.   Performance of our lung segmentation algorithm has been shown to be 95% accurate. In addition, the classification accuracy for TB detection has been shown to be 84% which is measured as area under the receiver operating characteristic (ROC) curve. The curve measures the response of the classifier at various operating points and indicates the trade-off between sensitivity and specificity of its performance. Both results have been published in high quality archival journals.   The SVM model developed in our work is being beta-tested in the field to differentiate between normal CXR and those exhibiting lung diseases. The implemented system, which received an HHS Innovates Award, is installed in a truck equipped with a mobile x-ray unit and is deployed by a Kenyan-NGO (Academic Model for Providing Access to Healthcare, AMPATH) and is traveling through numerous sites in rural western Kenya, visiting scores of patients weekly. Research continues with acquiring digital CXR from the field for further training and testing of the algorithms, and the implementation of deep learning techniques (CNN) for fine-tuned classification of the CXR. n/a",Image analysis and machine learning for pulmonary disease screening,9359856,ZIALM010004,"['AIDS/HIV problem', 'Algorithms', 'Area', 'Atlases', 'Award', 'Classification', 'Comorbidity', 'Country', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Epidemic', 'Exhibits', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Infection', 'Journals', 'Kenya', 'Learning', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Modeling', 'Patients', 'Performance', 'Process', 'Publishing', 'Pulmonary Tuberculosis', 'Receiver Operating Characteristics', 'Research', 'Research Personnel', 'Resources', 'Rural', 'Sensitivity and Specificity', 'Shapes', 'Site', 'System', 'Techniques', 'Testing', 'Texture', 'Thoracic Radiography', 'Training', 'Travel', 'Visit', 'Work', 'base', 'burden of illness', 'cost', 'digital', 'health care availability', 'improved', 'mortality', 'novel', 'response', 'screening']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2016,510292,-0.01614779658277172
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9174605,R01CA200690,"['Adult', 'Algorithms', 'Architecture', 'Area', 'Association Learning', 'Behavior', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Characteristics', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Event', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Property', 'Reference Standards', 'Research', 'Scanning', 'Skin', 'Slide', 'Specimen', 'Staging', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'visual tracking']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,408063,-0.009299165570238523
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing. PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8998947,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'improved outcome', 'neovascular', 'novel', 'programs', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2016,180061,0.008498623053718094
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9111923,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,539886,0.04288854545501288
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9324484,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,175692,0.04288854545501288
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9058040,R01EB008374,"['4D Imaging', 'Accounting', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Health', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2016,451650,-0.019237302566677997
"Biomedical Image Analysis and Informatics The Biomedical Image Analysis and Services Section (BIRSS) is committed to providing computational and engineering expertise to a variety of clinical and biomedical informatics activities at NIH. Specifically, biomedical imaging research in PET, ultrasound, CT, MRI, microscopy, cancer research, and neural dysfunction have been supported extensively. To advance and empower scientific research in the NIH intramural program, CIT has developed and continues to enhance a sophisticated open source, platform-independent, n-dimensional, extensible image processing and visualization application. The MIPAV (Medical Image Processing Analysis and Visualization) (http://mipav.cit.nih.gov/) is an application that enables quantitative analysis and visualization of biomedical imaging modalities (from micro to macro) and is used by researchers at NIH and around the world. At NIH, MIPAV has been used to analyze anatomical structures in CT datasets, analysis of MRI datasets for NIMH, and has been used by NCI for the analysis of 2D and 3D microscopic samples.   In addition, BIRSS leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based system to support the collection and analysis of research studies and clinical trials, using a set of modular components that cover all stages of the research life cycle. And because BRICS is un-branded and not associated with a particular disease or organization, it can be efficiently custom-tailored for many research programs.   MIPAVs integrated set of biomedical imaging algorithms and its extensibility have been used by BIRSS to implement solutions to imaging problems in the NIH intramural research community dozens of times over.  To create custom workflows and solutions for intramural collaborators, BIRSS team members can build plug-ins that leverage the algorithms and tools in MIPAV to solve complex imaging research questions.  For example, BIRSS has created a novel MIPAV plug-in as part of a collaboration with Dr. Hari Shroffs lab in the National Institute of Biomedical Imaging and Bioengineering (NIBIB) to untwist four-dimensional high-resolution microscopy images of the Caenorhabditis elegans nematode embryo throughout its development.  This plug-in used the image registration and visualization tools already developed by BIRSS for MIPAV, along with novel fiducial annotation and lattice warping tools, to allow the NIBIB researchers to annotate and regularize the C. elegans embryo data through its twitching phase of development, which has not previously been possible algorithmically.  This, in turn, allowed Dr. Shroffs group to investigate neurodevelopmental events in late embryogenesis and apply it to track the 3D positions of seam cell nuclei, neurons, and neurites in multiple elongating embryos. The detailed positional information obtained enabled NIBIB to develop a composite model showing movement of these cells and neurites in an 'average' worm embryo. The untwisting and cell tracking capabilities of this plug-in provides a foundation on which to catalog C. elegans neurodevelopment, allowing interrogation of developmental events in previously inaccessible periods of embryogenesis.  Accurate automatic organ segmentation is an important yet challenging task for medical image analysis.  Anatomical variability in shape and texture feature inhibits traditional segmentation methods from achieving high accuracies.    Machine learning has dominated the medical imaging research field in the past decade.  Initially, pioneer work with decent feature extraction and SVM based image classification achieves better results.  Later, learning based detection algorithm began to dominate the machine learning tools like boosting trees, random forest.   More recently the deep learning based Deep Convolutional Neural Networks (DCNNs) become the mainstream of the medical imaging research field for the past two years.   Using and enhancing the MIPAV application has allowed us to rapidly build the new machine learning component integral to the MIPAV software and is being used to support automated segmentation of the prostate.  BIRSS also leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based informatics system to support the collection and analysis of research studies and clinical trials. BRICS is un-branded and not associated with a particular disease or organization, therefore, it can be efficiently custom-tailored for many research programs. For example, in collaboration with the National Institute of Neurological Disorders and Stroke (NINDS), BIRSS has developed two informatics systems, using the BRICS system, in support of Traumatic Brain Injury (TBI)(http://fitbir.nih.gov/)research, the Parkinsons Disease Biomarker Program (PDBP) (http://pdbp.ninds.nih.gov/), as well as, collaborated with the National Eye Institute developed an informatics system for rare eye diseases, eyeGENE (https://eyegene.nih.gov/).  The TBI informatics system is called the Federal Interagency TBI Research (FITBIR) database to acknowledge the interagency participation and shared interests. FITBIR serves as a repository for TBI research, is supported by multiple federal agencies, and consolidates high quality, uniformly collected, and contemporary data that can be accessed and analyzed by scientific experts.  Over one million records have been uploaded to FITBIR thus far for 24,545 subjects enrolled in 45 different research studies. Currently there are 105 studies expected to contribute to FITBIR and the number of studies is growing every year. Within FITBIR are clinical outcome data and imaging data of which 34,883 records are of imaging data (MRI, CT, PET and Diffusion) from 2,616 individual subjects. Of that data, FITBIR contains 13,069 rows of imaging data from 1,794 individual subjects that are shared with users who have approved Data Access accounts. A summary of the data can be found here: https://fitbir.nih.gov/content/submitted-data.  The goal of the PDBP, a BRICS system, is to support new and existing research and resource development promoting biomarker discovery for Parkinson's disease. Although our understanding of the biology and genetics associated with Parkinson's disease (PD) is advancing rapidly, gaps remain between promising laboratory discoveries and the realization of treatments that will cure or slow progression of PD. To address the needs of the PD community, NINDS has established the PDBP program focused on promoting the discovery of biomarker candidates for early detection and measurement of disease progression.  To date, the PDBP prospective consortium has 100% accrual at nine sites across the US with 1,536 enrolled subjects of which biorepository samples have been collected from 1,501 subjects. The total number of unique biospecimens collected longitudinally across all sites totals 15,524. 	1,444 DNA samples 	3,854 RNA samples 	3,255 plasma samples 	2,934 serum samples 	787 CSF samples 	3,250 whole blood samples A summary of the data can be found here: https://pdbp.ninds.nih.gov/Data  The National Eye Institute (NEI) has also adopted the BRICS system to support The National Ophthalmic Disease Genotyping and Phenotyping Network (eyeGENE) (https://eyegene.nih.gov/). The eyeGENE project is a research venture created by NEI in response to promising scientific discoveries in genetics. eyeGENE aims to advance studies of eye diseases and their genetic causes by giving researchers access to DNA samples, clinical information, and patients looking to participate in research studies and clinical trials.  A summary of the data can be found here: https://eyegene.nih.gov/node/35. n/a",Biomedical Image Analysis and Informatics,9339938,ZIACT000272,"['Accounting', 'Address', 'Adopted', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Biology', 'Biomedical Research', 'Blood specimen', 'Caenorhabditis elegans', 'Cataloging', 'Catalogs', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Custom', 'DNA', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Embryo', 'Embryonic Development', 'Engineering', 'Enrollment', 'Event', 'Eye diseases', 'Foundations', 'Four-dimensional', 'Genetic', 'Genotype', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging problem', 'Individual', 'Informatics', 'Intramural Research', 'Intramural Research Program', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Measurement', 'Medical Imaging', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Nematoda', 'Neurites', 'Neuronal Dysfunction', 'Neurons', 'Online Systems', 'Organ', 'Outcome', 'Parkinson Disease', 'Patients', 'Phase', 'Phenotype', 'Plasma', 'Plug-in', 'Positioning Attribute', 'Positron-Emission Tomography', 'Prostate', 'RNA', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Support', 'Resolution', 'Resource Development', 'Resources', 'Sampling', 'Serum', 'Services', 'Shapes', 'Site', 'Speed', 'Staging', 'Structure', 'System', 'Techniques', 'Texture', 'Time', 'Traumatic Brain Injury', 'Trees', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization software', 'Whole Blood', 'Work', 'anticancer research', 'base', 'biobank', 'bioimaging', 'biomarker discovery', 'biomedical informatics', 'candidate marker', 'cell motility', 'data access', 'empowered', 'forest', 'image processing', 'image registration', 'image visualization', 'imaging informatics', 'imaging modality', 'informatics infrastructure', 'interest', 'member', 'microscopic imaging', 'n-dimensional', 'neurodevelopment', 'novel', 'open source', 'platform-independent', 'programs', 'prospective', 'repository', 'research and development', 'research study', 'response', 'tool', 'web-based informatics']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2016,847611,0.02476441651269586
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals. PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9137657,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Health', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'microscopic imaging', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2016,246750,-0.020971438520325424
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of available MR techniques and image contrast mechanisms that can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.         One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While our application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around application of support vector machine analysis and other types of low-dimensional multivariate analyses of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hyper surface.      An additional approach is the development of 1D and 2D relaxometery and related experimental approaches.  In these experiments, correlated data is obtained for two (or in some circumstances, 3) MR parameters simultaneously.  This permit characterization of water pools in the tissue.  This is an emerging methodology in MR, and we have successfully performed and published the first higher-dimensional approach using compressed sensing.       We are currently developing discriminant functions based on three metrics in both one variable and two variables.    These permit the translation of means and standard deviations to sensitivity and specificity of derived statistical tests.  These results are general and can be applied to a wide variety of medical diagnostic tests. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,9351980,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic tests', 'Diffusion', 'Exhibits', 'Goals', 'Hydration status', 'Imaging Techniques', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Probability', 'Publishing', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Statistical Data Interpretation', 'Surface', 'Testing', 'Tissues', 'Training', 'Translations', 'Validation', 'Water', 'Weight', 'Work', 'base', 'cartilage degradation', 'contrast imaging', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'research study', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2016,1247642,-0.025349285577498316
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9110984,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2016,412881,0.048235464336763956
"Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling ﻿    DESCRIPTION (provided by applicant): The quest for fast image acquisition speed has always been a perennial topic in the MRI community. To reduce the acquisition time for maximal spatial and temporal resolution, modern MRI protocols usually perform reduced acquisitions below the Nyquist rate. The reduced data is then used to reconstruct the image through advanced reconstruction techniques that leverage some prior information about the MRI system (e.g., parallel imaging) and/or MR signal (e.g., compressed sensing). Since such prior information is patient and system specific, recent techniques obtain the prior information using training data obtained through an empirical calibration procedure. All existing methods assume the prior models are linear. Since the intrinsic nonlinear relationship in the training data cannot be characterized in such simple models, the reconstruction is degraded by the inaccuracy of the prior information. Nonlinear learning from the training data have proven to be more powerful in machine learning because it is more general and includes the linear model as a special case. However, it is usually more challenging to learn the nonlinear models and even more challenging to incorporate the model in reconstruction due to the increased degree of freedom. We recently have introduced a novel concept of ""kernel"" in MR reconstruction to address the above challenges timely. Our preliminary results on parallel imaging and sparsity-constrained reconstruction demonstrate that the kernel-based algorithms improve the reconstruction quality over the original algorithms with linear prior models. Built upon our strong preliminary results, the objective of this application is to develop an innovative kernel-based framework for MR image reconstruction from undersampled data. This framework does not require explicit knowledge of nonlinear mapping (as in preliminary work) such that a broader family of nonlinear functions can be explored for different clinical applications. The proposed work is expected to advance the field of MR image reconstruction vertically. Specifically, the successful completion of the proposed project will result in a general framework leading to many new algorithms (including two developed in this project) for reconstruction from reduced acquisition. Therefore, virtually all of current clinical MRI could benefit from the improved resolution, image quality, and/or reduced acquisition times that the new framework will facilitate or the novel applications i may enable. PUBLIC HEALTH RELEVANCE: The proposed research is to develop a general framework and two specific new techniques to improve the spatial resolution and/or reduce the scan time in magnetic resonance imaging and evaluate the performance of the techniques for 3D parallel imaging and quantitative imaging in brain. The development of such novel fast imaging techniques may greatly enhance diagnosis of neurological disease. Therefore the project will potentially benefit numerous subjects and the healthcare system.",Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling,9119020,R21EB020861,"['Address', 'Algorithms', 'Brain', 'Calibration', 'Clinical', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Family', 'Freedom', 'Health', 'Healthcare Systems', 'Image', 'Imaging Techniques', 'Industry', 'Knowledge', 'Learning', 'Letters', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Modeling', 'Non-linear Models', 'Patients', 'Performance', 'Phase', 'Physics', 'Polynomial Models', 'Principal Component Analysis', 'Procedures', 'Protocols documentation', 'Qualifying', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Signal Transduction', 'Software Tools', 'Speed', 'System', 'Techniques', 'Time', 'Training', 'Weight', 'Work', 'base', 'clinical application', 'image reconstruction', 'improved', 'innovation', 'nervous system disorder', 'neuroimaging', 'novel', 'quantitative imaging', 'reconstruction', 'temporal measurement']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R21,2016,222652,0.03604950501330835
"High Performance Automated System for Analysis of Fast Cardiac SPECT DESCRIPTION (provided by applicant): Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before a heart attack, and predict risk in millions of patients annually. This is currently limited by the need fo visual interpretation, which is highly variable and depends on the physician's experience. The long-term objective of this program is to improve the interpretation of this widely used heart imaging technique-achieving higher accuracy for disease detection than it is possible by the best attainable visual analysis. This proposal builds on our prior work in conventional myocardial MPS, and focuses on fast, low-radiation MPS imaging (fast-MPS) obtained by new high-efficiency scanners. Specifically, we aim to: 1) develop new image processing algorithms for a fully automated analysis of fast-MPS. The algorithms will include better heart muscle detection by training with correlated anatomical data and a novel approach for mapping the probability of abnormal perfusion for each location of the heart muscle; 2) enhance the diagnosis of heart disease from fast-MPS by machine- learning algorithms that integrate clinical data, stress test parameters, and quantitative image features; 3) demonstrate the clinical utility of the new algorithms applied to automatic canceling of the rest portion of the MPS scan, when not needed. The new system will be more accurate than the clinical expert analysis in the detection of obstructive coronary disease. By immediately indicating whether a stress scan is normal, the system will allow for the automatic cancellation of the rest imaging portion when it is not needed (estimated in over 60% of all MPS studies). Our research will demonstrate that the computer decision regarding rest-scan cancellation is safe for the patient, both from a diagnostic and prognostic standpoint. This will lead to a wide adoption of low-dose stress-only imaging for MPS studies, which would reduce the amount of radiation that patients are exposed to, and allow for significant healthcare savings. It will additionally lead to a paradigm shift in the practice of nuclear cardiology, which will ultimately result in better selection of patients who need intervention, and reduce the number of deaths due coronary artery disease. PUBLIC HEALTH RELEVANCE: Imaging of myocardial perfusion (heart muscle blood flow) at rest and stress allows physicians to detect disease and predict risk in millions of patients in the US each year, but it is currently limited by the need of visual interpretation, which is dependent on doctor's experience. The investigators propose to develop and validate an automated, highly-accurate and objective computer system which will outperform even experienced physicians in interpreting these images using latest generation scanners and novel machine learning computer tools. The computer will be able to better select patients needing treatment and automatically indicate the normal stress-scan immediately, and more accurately than physicians allowing automatic cancellation of the rest imaging, when not needed; this will result in large healthcare savings and reduced radiation to the patients.",High Performance Automated System for Analysis of Fast Cardiac SPECT,9064178,R01HL089765,"['Adoption', 'Algorithms', 'Blood', 'Blood flow', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Systems', 'Computers', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Dose', 'Generations', 'Health', 'Healthcare', 'Heart Diseases', 'Image', 'Imaging Techniques', 'Intervention', 'Lead', 'Location', 'Machine Learning', 'Maps', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Patient Selection', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Probability', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Savings', 'Scanning', 'Stress', 'Stress Tests', 'System', 'Systems Analysis', 'Training', 'United States', 'Visual', 'Work', 'cardiac single photon emission computed tomography', 'experience', 'heart imaging', 'image processing', 'improved', 'novel', 'novel strategies', 'prognostic', 'programs', 'quantitative imaging', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2016,695446,0.014591966304917312
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9050682,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2016,339750,0.0035069763880461757
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment.         PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.            ",MRI-Based Radiation Therapy Treatment Planning,9026075,R01CA193730,"['Adopted', 'Adoption', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modality', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'public health relevance', 'quality assurance', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2016,362066,-0.010717456739707604
"Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET ﻿    DESCRIPTION (provided by applicant): Ischemic cardiomyopathy affects approximately 3 million people in the United States. This form of heart failure is the result of myocardial infarcton or severe coronary heart disease that reduces the viability and function of the heart. Ischemic cardiomyopathy is associated with poor long-term survival when patients with viable myocardium are not revascularized. By imaging myocardial blood flow and glucose metabolism and seeking flow-metabolism mismatches, positron emission tomography (PET) method has been established as the gold standard of assessing myocardial viability for selecting patients who can benefit most from surgical revascularization. Current PET method employs two separate static scans with two different radiotracers for generation of the flow-metabolism image pair. While the image of glucose metabolism is acquired using the most widely used radiotracer 18F- fluorodeoxyglucose (FDG), myocardial blood flow imaging with the radiotracer 13N-ammonia or rubidium-82 suffers from limited clinical availability. In addition, the imaging protoco of two separate imaging sessions is time consuming and resource intensive. As a result, myocardial viability via PET is currently under-utilized in clinic despite its high accuracy and th fast-growing installation of PET/CT scanners in the past decade. In this project, we propose to develop a novel PET method for myocardial viability assessment that only uses a single injection of FDG without the need of a flow- specific radiotracer. We hypothesize that myocardial blood flow can be derived from the quantitative kinetic parameters of dynamic FDG PET. We will develop a new multi-variable prediction model using statistical machine learning to predict myocardial blood flow from dynamic FDG PET data. We will also develop a shortened dynamic FDG PET protocol to improve practicality. This innovation will provide the flow-metabolism image pair for myocardial viability assessment in a clinically favorable time, cost and with reduced radiation dose. Success of this research will make PET assessment of myocardial viability more widely available in clinic with easier access, lower radiation dose, cheaper imaging cost and shorter clinical visit time as compared with conventional two-session protocols, thus improving our clinical practice of treating ischemic cardiomyopathy.         PUBLIC HEALTH RELEVANCE: Positron emission tomography (PET) is a gold standard method for detecting viable myocardium to select which patients with ischemic cardiomyopathy to benefit most from surgical revascularization. Its use in clinic, however, is under-utilized because of the limited clinical availability of the radiotracers needed. This research aims to develop a novel PET imaging method for assessment of myocardial viability that can be easily accessed in clinic with reduced lower radiation dose and imaging cost without compromising imaging performance.              ",Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET,9020059,R21HL131385,"['Address', 'Affect', 'Algorithms', 'Ammonia', 'Blood', 'Blood Glucose', 'Blood flow', 'Cardiac', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Trials', 'Coronary heart disease', 'Cyclotrons', 'Data', 'Dependence', 'Dose', 'Echocardiography', 'Evaluation', 'Generations', 'Goals', 'Gold', 'Heart failure', 'Hour', 'Image', 'Injection of therapeutic agent', 'Investments', 'Kinetics', 'Low Dose Radiation', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial tissue', 'Myocardium', 'Noise', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Perfusion', 'Physicians', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Recruitment Activity', 'Research', 'Resolution', 'Resources', 'Rubidium', 'Scanning', 'Site', 'Testing', 'Time', 'Tracer', 'United States', 'Visit', 'clinical practice', 'cost', 'experience', 'fluorodeoxyglucose', 'fluorodeoxyglucose positron emission tomography', 'glucose metabolism', 'glucose transport', 'heart function', 'image reconstruction', 'imaging modality', 'implantable device', 'improved', 'innovation', 'ischemic cardiomyopathy', 'mortality', 'novel', 'public health relevance', 'radiotracer', 'single photon emission computed tomography', 'success', 'uptake']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2016,234875,0.027147030686627563
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,677628,0.02229960032088547
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,100000,0.02229960032088547
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9108343,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Health', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2016,618809,0.012686012897553426
"Development And Applications Of The Open Microscopy Environment (OME) In recent years, we have focused on developing robust general image analysis methodology, culminating in our pattern recognition tool called WND-CHRM.  We have validated this pattern-recognition approach to biological image analysis using diverse imaging modalities ranging from fluorescence microscopy to X-rays of human knees, MRIs, and other imaging modalities.  We have also validated a range of  applications from scoring image-based assays to diagnosis of disease to prediction of future disease risk.  The specific applications of this approach are covered in reports AG000674-12 and AG000685-09.  A major effort recently has been to rewrite the WND-CHARM code-base to make it more modular, better organized, easier to use, and accessible with the Python scripting language.  A recent release of WND-CHARM 1.52 is available from our code repository (http://ome.grc.nia.nih.gov/wnd-charm/wndchrm-1.52.775.tar.gz).  This release focuses on streamlining access to image feature computing algorithms so that they are individually acessible by the name of the algorithm and any preceding image transforms.  The individual algorithms are also broken out behind a common interface so that new algorithms are easy to add. The image feature computing plan was previously hard-coded, but to make it more flexible, easier to modify, and responsive to ""on demand"" feature requests, it is now automatically assembled based on the requested features, taking account of their preceding image transform dependencies.   Spatially-resolved pattern analysis places an extreme burden on the performance of our software.  Instead of an entire image being considered at once, or split into a small number of tiles on a grid, to achieve spatial resolution, each image must be sampled thousands or millions of times.  In order to make this type of application practical, the computational strategy used in the software must be reconsidered.  Previously, all 3,000 low-level image features were calculated for each image sample, even when most of them were later found to be irrelevant to the classification problem because they lacked discrimination power.  The major change in strategy to enable spatially-resolved pattern recognition is to eliminate unnecessary calculations.  This requires an on-demand computing strategy for image features, which is a major architectural change in the wndchrm software.  Our current release makes use of this strategy, exposing a very simple to use API for specifying the specific features to be computed. An added benefit of this restructuring is that it is now very straightforward to add new image descriptors to this library. Because all of the existing descriptors use the same interface, they act as examples for future additions.  We have have also made the majority of the underlying C++ code accessible from the Python scripting language to make it easier to customize how WND-CHARM is used in new applications. It is now possible to compute on-demand features using the Python interface and perform further processing using mathematical, scientific, and machine learning libraries available for Python (numpy, scipy, Scikit-learn).  A major feature expanded in the past year is development and refinement of the sliding window classifier. This feature allows an entire image to be scanned systematically to look for the presence of patterns that the classifier has been previously trained to recognize, either by defining them manually, or with the use of automated segmentation methods.  A second, related feature is the ability to train a classifier to isolate objects of interest using a segmentation mask.  One or more binary images defining segmentation masks are automatically randomly sampled with a user-defined window size to define image-windows that are within the desired object, constitute a boundary, or are outside of the object of interest.  Subsequently, a new image is systematically scanned using a sliding-window classifier to define the boundary and/or interior of an object of interest.  In 2012, in collaboration with Jason Swedlow (University of Dundee, Scotland), a large international project sponsored by the Wellcome Trust was initiated to develop specific applications of the OME/OMERO system.  Our group's contribution to this project involves providing interfaces between OMERO and WND-CHARM to enable image comparisons in large, diverse image repositories.  The eventual goal is to use pattern recognition to annotate new images added to these collections automatically, based on previously annotated images and a large set of independent classifiers that opeerate autonomously in the background.  The primary design goal of a system like OME/OMERO is to provide scientists with easy ways of organizing and annotating their image collections.  The organizational structure of the images and their grouping by their annotations can also serve as the primary inputs for training pattern-recognition classifiers.  Because classifiers require little or no additional input from the user, the natural convergence of these two technologies represent a powerful new mode for maximizing the utility of large scale scientific and medical image databases.  Currently we have a functioning prototype that interacts with OMERO to read image data and annotations; use these for training a classifier; and return annotations derived from classification back to OMERO.  Substantial work remains to make this integrated system practical.  Currently, a developer-preview release is available, but it lacks the flexibility on the OMERO side to keep track of multiple, potentially conflicting classifications for images, as well as maintaining a flexible store of image feature sets.  Our current efforts are to implement a standardized feature store based on the widely used HDF data format, which can be used both standalone with WND-CHARM alone, and when using WND-CHARM together with the OME database. We are also populating this database with a large and diverse set of images from cell-based high-content screening assays, as well as their corresponding CHARM features. This will constitute a realistic test-case for computation, storage and retreival of images and their corresponding numerical image descriptors computed with our software.  Several efforts are under way to use parts of the OME Data Model in Pathology Informatics.  Pathology makes use of digital microscopy and the Pathology Informatics field is concerned with the standardized storage of both the digital image data as well as other systematic meta-data collected about these images.  The work resulting from my participation in several Pathology Informatics workshops has resulted in two publications this past year. n/a",Development And Applications Of The Open Microscopy Environment (OME),9341860,ZIAAG000671,"['Accounting', 'Address', 'Algorithms', 'Back', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer Analysis', 'Computer software', 'Computers', 'Conflict (Psychology)', 'Data', 'Databases', 'Dependency', 'Descriptor', 'Development', 'Discrimination', 'Educational workshop', 'Ensure', 'Environment', 'Fluorescence Microscopy', 'Future', 'Generic Drugs', 'Goals', 'Grouping', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Individual', 'Informatics', 'International', 'Knee', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Manuals', 'Masks', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Microscopy', 'Modality', 'Modeling', 'Names', 'Pathology', 'Pattern', 'Pattern Recognition', 'Performance', 'Process', 'Publications', 'Pythons', 'Reading', 'Reporting', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scanning', 'Scientist', 'Scotland', 'Semantics', 'Side', 'Slide', 'Specific qualifier value', 'Speed', 'System', 'Tars', 'Technology', 'Testing', 'Time', 'Training', 'Trust', 'Universities', 'Visual', 'Work', 'age related', 'application programming interface', 'base', 'cellular imaging', 'data format', 'data modeling', 'design', 'detector', 'digital', 'digital imaging', 'disease diagnosis', 'disorder risk', 'flexibility', 'imaging informatics', 'imaging modality', 'interest', 'medical specialties', 'open source', 'organizational structure', 'practical application', 'prototype', 'repository', 'screening', 'software development', 'targeted imaging', 'tool']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2016,374348,0.05981747370191041
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle.           PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.              ",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9047634,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Genetic', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'quantitative imaging', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2016,609726,0.023849925105576625
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9061011,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Health', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'individual patient', 'interest', 'predictive modeling', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2016,770494,0.04630148028577662
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9132190,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissue Survival', 'Tissues', 'Tumor Burden', 'base', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'quantitative imaging', 'repository', 'response', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2016,626891,-0.0031273751225334634
"Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle,9282051,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'muscular system', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,58482,0.0507477328126235
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9126405,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,316467,0.05179957234559452
"Pattern recognition in medical imaging Modern imaging systems far exceed the human eye in spatial and spectral resolution and in dynamic range, thus potentially allowing machine-based image pattern analysis systems to outperform manual image interpretation. In fact, recent work in pattern recognition has demonstrated that computers can equal or even surpass image classification and pattern analysis by human experts.  We have previously published work investigating the progression of osteoarthritis (OA) in the human population comprising the Baltimore Longitudinal Study of Aging (BLSA).  We were able to show that WND-CHARM (see AG000671-13) is able to diagnose the existence of OA in knee X-Rays with accuracies approaching that of a panel of highly trained radiologists.  We have subsequently published work that WND-CHARM can predict the future onset of radiologically detectable osteoarthritis in X-Rays that were scored as radiologically clear.  We were able to show that the development of moderate OA two decades in the future can be predicted with > 70% accuracy from X-Rays scored as free of OA by a panel of three radiologists.  Subsequently, we were able to further characterize OA progression and identify an early, slow period of change followed by rapid degeneration.   We are following up our knee X-ray studies with an MRI dataset obtained from the Osteoarthritis Initiative as well as experimental MRI samples imaged here at NIA through a collaboration with Dr. Richard Spencer (NIA/LCI). In a recently published study, we developed a technique using multivariate linear regression of image features derived from several types of MRI scans to construct a continuously variable cartilage quality score similar to an OARSI grade.  The OARSI grade is determined histologically, and involves an invasive procedure that is not amenable to early screening or tracking disease progress.  While MRI methods are non-invasive, they must first be correlated with histological grading schemes before they can be used in diagnosis or evaluating cartilage quality.  Our multivariate regression of image features from multimodal MRI scans produced a continuous score that was well correlated with the OARSI grade of the same samples (r > 0.65, p < 10-5).  Defining a continuous grading system based on a non-invasive procedure is a key element in evaluating osteoarthritis treatment strategies.  A follow-up study to this work is being re-submitted after review, where we evaluated our ability to predict development of OA in a high-risk co-hort derived from the Osteoarthritis Initiative (OAI) study.  Here we showed that our sensitivity, specificity and accuracy for predicting development of symptomatic OA from MR scans were 74%, 76% and 75%, respectively.  A recently completed study that is in the submission process involves abdominal CT scans.  The viscera, bone, subcutaneous and visceral fat in these scans has been segmented into separate image masks using the characteristic densities of these tissues on the Hounsfield scale. Our analysis of these image masks indicates that a strong aging signal is present in adipose tissues as well as in the unsegmented whole CT scans. These results are based on cross-validation of classifiers trained on a middle-age group (56-70) and an older group (81-99).  This is by far the largest image-based aging study done in humans, and it clearly shows that adipose tissue is one of the major factors in age-related changes occuring in the abdomen.  Another radiology project is in collaboration with Dr. Maria Knoll at the Johns Hopkins Bloomberg School of Public Health.  Here the goal is to diagnose viral vs., bacterial pneumonia in children using chest X-rays.  A rapid accurate diagnosis of the nature of this disease will dramatically improve outcomes for children in developing countries.  A standard set of chest X-rays is available from the World Health Organization that is well annotated, with each X-ray having beenn read by mmultiple expert radiologists forming a solid ground truth for training machine classifiers.  The major challenge posed by this set is the extreme variation in the physical size of the subjects due to the variation in their ages.  We have developed a strategy to compensate for this size variation by working with a student at JHSPH to manually annotate the X-rays with a set of fiducial marks that are anatomically comparable across the X-rays regardless of subject size.  Using these manually aligned regions of the lung, we have preliminary indications that such a diagnosis may be possible. We have also assembled a dataset where areas of the lung X-rays have been manually delineated and annotated. This dataset is being used to train an automated segmentation classifier as described in the report for AG000671-15.  A project recently begun involves analyzing fundus images collected by the National Eye Institute. The goal is two-fold: 1) Develop an automated scoring system for age-related macular degeneration (AMD), and use fundus images from SardiNIA for testing and validation using manual reads by our NEI collaborators.  2) Develop a set of numerical descriptors for segmented vasculature in fundus images, correlate them with cardiovascular traits measured in SardiNIA, and use them to determine genome-wide associations to these traits.  Currently, preliminary experiments have been able to automatically detect an AMD signal in NEI fundus images, and thuse preliminary findings are being refined.  We have some evidence that a new scale based on objective image similarity measures can be derived for scoring AMD. We have evaluated software for automated segmentation of fundus vasculature, and Dr. Nikita Orlov has developed several algorithms to analyze the vessicle segmentation masks for numerical descriptors of vasculature, including various tortuosity measurements, distributions of vessicle thickness, branching patterns, etc.  Our work in developing tools and expertise in analyzing images to obtain physiological insights that are not directly observable has recently been translated to non-image-based clinical data.  In this project, we used machine learning and the totality of the quantitative trait data collected in the SardiNIA study to ascertain each participant's age.  This predicted age was excpected to closely correlate to chronological age, but as it was based on broad physiological measurements, be more closely related to each participant's physiological age.  The ratio between physiological and chronological age can be viewed as a measure of aging rate, and we determined that this rate is largely preserved for each participant across multiple visits.  Moreover, we determined that 40% of the variation in aging rates is heritable, and by performing a GWAS showed that it is significantly associated with two genes related to telomere function.  We have been unable to replicate the GWAS results in the InChianti study, but we were able to reproducibly calculate aging rates from physiological data in that study as well. We were able to perform an internal validation using the SardiNIA study, and are now prepared this manuscript for publication.  The use of machine learning and pattern recognition to mine new insights from numerical clinical data has great potential, and we are actively pursuing this strategy with new projects.  In collaboration with Madhav Thambisetty and Kevin Becker, we are extending this approach to examine traits in BLSA participants that may be predictive of later diagnosis of Alzheimer's disease.  In a collaboration with Matt Oberdier and Majd AlGhatrif (LCS) we are applying these tools to analyze data from blood flow and pressure sensors to act as markers of cardiovascular state in rats. n/a",Pattern recognition in medical imaging,9341862,ZIAAG000685,"['Abdomen', 'Adipose tissue', 'Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Area', 'Bacterial Pneumonia', 'Baltimore', 'Biopsy', 'Blood Pressure', 'Blood flow', 'Cardiovascular system', 'Cartilage', 'Characteristics', 'Child', 'Classification', 'Clinical Data', 'Collaborations', 'Collection', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Degenerative polyarthritis', 'Descriptor', 'Developing Countries', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Eye', 'Fatty acid glycerol esters', 'Fundus', 'Future', 'Genes', 'Goals', 'Hematoxylin and Eosin Staining Method', 'Histologic', 'Homeostasis', 'Human', 'Image', 'Image Analysis', 'Indium', 'Knee', 'Lead', 'Life', 'Linear Regressions', 'Longitudinal Studies', 'Lung', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Manuscripts', 'Masks', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Mining', 'Morphology', 'National Eye Institute', 'Nature', 'Participant', 'Pattern', 'Pattern Recognition', 'Physiological', 'Pneumonia', 'Population', 'Procedures', 'Process', 'Public Health Schools', 'Publications', 'Publishing', 'Radiology Specialty', 'Rattus', 'Reading', 'Reporting', 'Resolution', 'Roentgen Rays', 'Sampling', 'Sardinia', 'Scanning', 'Scheme', 'Sensitivity and Specificity', 'Signal Transduction', 'Solid', 'Staining method', 'Stains', 'Students', 'Study Section', 'System', 'Systems Analysis', 'Techniques', 'Testing', 'Thick', 'Thoracic Radiography', 'Time', 'Tissues', 'Training', 'Translating', 'Validation', 'Variant', 'Viral', 'Viscera', 'Visceral', 'Visit', 'Work', 'World Health Organization', 'X-Ray Computed Tomography', 'abdominal CT', 'accurate diagnosis', 'age group', 'age related', 'base', 'bone', 'clinical Diagnosis', 'clinically relevant', 'density', 'follow-up', 'functional decline', 'genome wide association study', 'high risk', 'human disease', 'imaging system', 'improved outcome', 'insight', 'middle age', 'outcome forecast', 'predictive marker', 'radiologist', 'research study', 'screening', 'sensor', 'subcutaneous', 'telomere', 'tool', 'trait', 'treatment strategy', 'tumor progression']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2016,377295,0.017456753929794667
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9132242,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Health', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2016,169609,0.020196330208896263
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,9097737,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Surrogate Markers', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'preclinical trial', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2016,447440,-0.006168876280915534
"Statistical methods for large and complex databases of ultra-high-dimensional DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.",Statistical methods for large and complex databases of ultra-high-dimensional,9115248,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multicenter Studies', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'contrast enhanced', 'data visualization', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'skills', 'study population', 'terabyte', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2016,347156,0.008295021665244493
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9002898,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2016,776460,0.012116660210422812
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8970690,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,624643,0.01374142401715393
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, image refers not only to biomedical images, but also to illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. We are seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. To meet these objectives, we use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers richer search results.   A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and the modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval are achieved in the following ways: (i) using image analysis; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. Additional steps include describing an image with visual features, automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.), and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed Open-iSM (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. The Open-i system enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 1.2 million open access articles and nearly 3.7 million illustrations from the biomedical literature hosted at the National Library of Medicine's PubMed Central  repository; over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays; 67,517 images from NLM History of Medicine collection; and about 2,064 orthopedic anatomy illustrations provided by Norris Medical Library, University of Southern California. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publisher's Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to search for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using a clinical image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. Open-i indexes all the text and illustrations in medical articles by features, both textual and image-based. Open-i also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and de-identified patient records, as well as the orthopedic and historical images. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first and perhaps only production-quality system of its kind in the biomedical domain, Open-i has enabled medical professionals and the public to access visual information from biomedical articles that are highly relevant to their query, as well as the ""take away"" messages of the articles. The quality of the information delivered by Open-i has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system placed first in the 2013 image retrieval evaluation that attracted participants from academia, industry and clinical settings. For the past year the site has attracted over 8,000 unique visitors daily (excluding bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. During the 2016 reporting period, the Open-i user interface was redesigned to provide equal quality of retrieval results for all types of devices used to access the site. n/a",Integrating image and text information for biomedical information retrieval,9359855,ZIALM010001,"['Academia', 'Anatomy', 'California', 'Chest', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Devices', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'History of Medicine', 'Hybrids', 'Image', 'Image Analysis', 'Indiana', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Medical', 'Medical Libraries', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Orthopedics', 'Outcome', 'Participant', 'Patients', 'Performance', 'Physicians', 'Process', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Visual', 'Work', 'abstracting', 'base', 'bioimaging', 'cluster computing', 'digital', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'meetings', 'patient oriented', 'phrases', 'repository', 'search engine', 'text searching', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2016,530704,-0.003658194635329485
"Clinical Evaluation of Lung Motion Tracker for Improved Diagnosis and Treatment ﻿    DESCRIPTION (provided by applicant): In dynamic image-guided radiotherapy for lung cancer, one of the major tasks is to provide the dynamic images and tumor shapes that reflect the patient's real-time anatomy as the roadmap for guiding the delivery of radiation beams. One fundamental question for these applications is how to estimate such dynamic images, as well location and shape changes of tumor using available sensors to capture the respiratory motion. This proposal focuses on solving such a lung motion tracking problem by using our newly proposed high- dimensional surface to lung motion prediction model and considering the difference of each individuals, such as gender, size, and respiratory pattern. Specifically, we wil optimize the statistical models that capture the motion distribution from training samples and the nonlinear prediction model for accurate lung motion tracking and conduct extensive evaluation for the lung motion tracking system developed to validate its feasibility in clinic practice. Our goal is to develop an efficient, effective and robust lung motion tracking system for dynamic image guidance of the radiotherapy procedures. After this clinical data validation, such a technique can also be applied to image-guided intervention. PUBLIC HEALTH RELEVANCE: Lung motion tracking is essential for dynamic image-guided radiotherapy for lung cancer. We propose to estimate the dynamic lung motion for patient using the high-dimensional chest surface motion. Due individual variability (patient size, gender, and different respiratory patterns), in this proposal, we will optimize the newly proposed lung motion tracking by considering practical patient variability and evaluate the performance of the proposed system with a large number of dataset collected from radiotherapy planning.",Clinical Evaluation of Lung Motion Tracker for Improved Diagnosis and Treatment,9050674,R03EB018977,"['Abdomen', 'Adult', 'Algorithms', 'Anatomy', 'Biological Models', 'Breathing', 'Cancer Etiology', 'Cancer Patient', 'Cessation of life', 'Chest', 'Clinic', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Data Set', 'Diagnosis', 'Early Diagnosis', 'Evaluation', 'Gender', 'Goals', 'Health', 'Image', 'Individual', 'Joints', 'Least-Squares Analysis', 'Left', 'Location', 'Lung', 'Lung Neoplasms', 'Machine Learning', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Obesity', 'Optics', 'Patients', 'Pattern', 'Performance', 'Phase', 'Principal Component Analysis', 'Procedures', 'Radiation', 'Radiation therapy', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Respiration', 'Sampling', 'Shapes', 'Signal Transduction', 'Statistical Models', 'Surface', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Tumor Volume', 'United States', 'Validation', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer imaging', 'cancer radiation therapy', 'clinical practice', 'dynamic system', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'image reconstruction', 'imaging Segmentation', 'imaging biomarker', 'improved', 'individual patient', 'male', 'new technology', 'open source', 'optical imaging', 'prediction algorithm', 'real time model', 'research clinical testing', 'respiratory', 'sensor', 'tumor']",NIBIB,METHODIST HOSPITAL RESEARCH INSTITUTE,R03,2016,79750,-0.019549458178019945
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9044803,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Health', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2016,63620,0.01080629321577253
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Prediction of IPF Progression Using Imaging Patterns,9122467,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'Health', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary Fibrosis', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'data archive', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'individual patient', 'insight', 'interstitial', 'novel', 'novel therapeutics', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2016,107290,0.007740973244649574
"Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Abstract: Advances in imaging technology offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to various large-scale imaging studies, i.e., ADNI, for discovering AD-related imaging biomarkers. In these imaging studies, image registration plays a key role in reducing the confounding inter-subject variability and also enhancing the statistical power of identifying abnormalities related to AD. However, automated processing of large-scale imaging data, i.e., involving anything from hundreds to thousands of 3D brain images, is not trivial and requires dedicated computational tools. The goal of this project is to develop a series of novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going large-scale imaging study, an efficient incremental groupwise registration method will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. Our key idea is to break down the complex groupwise registration problem into hierarchical sets of small- scale registration tasks that can be solved easily, thus making the large-scale registration more manageable and fast. Specifically, 1) for fast initialization of large-scale groupwise registration of brain images, we will develop in Aim 1 a hierarchical learning-based landmark detection algorithm, based on random forest regression, to detect salient anatomical landmarks and then jointly align all images with detected landmarks. Since all images are distributed in a complex manifold and also the registration of similar images is much faster and more accurate, we propose to first build a graph to link each image only with similar images, and then formulate groupwise registration as dynamic graph shrinkage. This avoids direct registration of each image to the group-mean image as done in the conventional methods, thus improving both speed and accuracy. 2) To significantly speed up and also improve this single-layer graph-based groupwise registration, we will further develop in Aim 2 a deep multi-layer groupwise registration by simultaneous layer-by-layer graph construction and layer-wise registration. 3) Finally, to significantly increase both the speed and accuracy of registration for new images acquired from on-going large-scale imaging study, we will develop in Aim 3 a novel incremental groupwise registration method to reuse previous registration results of existing images for guiding registration of new images. Specifically, each new image can be quickly registered to the common space of existing images by finding its most similar existing image(s). Accordingly, all new and existing images will become similar in the common space and then can be quickly updated for their overall groupwise registration. All computational tools developed will be made freely available to the research community, for accelerating the imaging study of Alzheimer's disease. Narrative Description of Project Modern imaging techniques offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to increasing number of large-scale imaging studies, including ADNI. However, the overwhelmingly big data poses new challenges to researchers in automated data processing. Thus, modern computational tools are expected to be able to handle the vast amount of data within a manageable time frame. In light of this, we aim to solve this large-scale spatial registration problem – a critical step directly related to accuracy and precision of imaging biomarkers to be discovered for AD. In particular, we will develop novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going study, an efficient incremental groupwise registration will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. The development of these advanced computational tools will eventually benefit for discovery of new imaging biomarkers for AD.",Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease,9240850,RF1AG053867,"['Advanced Development', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appearance', 'Automatic Data Processing', 'Big Data', 'Brain', 'Brain imaging', 'Communities', 'Complex', 'Computer software', 'Data', 'Detection', 'Documentation', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Imaging technology', 'Learning', 'Light', 'Link', 'Mainstreaming', 'Methods', 'Play', 'Process', 'Research', 'Research Personnel', 'Resources', 'Running', 'Series', 'Speed', 'Subgroup', 'Time', 'Update', 'Work', 'abstracting', 'base', 'computerized tools', 'cost', 'empowered', 'forest', 'image guided', 'image registration', 'imaging biomarker', 'improved', 'neuroimaging', 'novel', 'rapid technique']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,RF1,2016,2485857,-0.003657502943343712
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers.         PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1        ",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9076876,UH2CA203710,"['Algorithms', 'Arts', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Code', 'Collaborations', 'Color', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Institutes', 'Intelligence', 'Lead', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Statistical Models', 'Students', 'Technology', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2016,320900,-0.009125501051804959
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9119513,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention Studies', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2016,597688,0.03904125267400077
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9145647,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2016,605366,0.007782822129024382
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications DESCRIPTION (provided by applicant): In this small business innovations research (SBIR) project we present EyeArt, a retinal image analysis tool for automated diabetic retinopathy (DR) screenings with high diag- nostic efficacy. With its interface to EyePACS, a license-free, scalable telemedicine plat- form, EyeArt will aid the expansion of DR screening and help bridge the exponentially growing disparity between the number of diabetic patients and the number of eye-care providers. Research suggests that the Latino population in general are genetically predisposed to develop diabetes. Their vulnerability to vision loss due to diabetic retinopathy is further compounded by factors such as lack of access to ophthalmology clinicians, lack of insurance, and lack of education. According to the Department of Health Services (DHS) in Los Angeles County (LAC) the situation for diabetics is particularly grim, with current wait times upwards of 6-9 months for retinal examinations for retinopathy screening. This can lead to treatment delays and progression towards irreversible vision loss. To help reduce risk of vision loss in this diabetic population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritizatin of ophthalmologist appointments, and aid in triage of high-risk patients. Our phase I prototype automatic DR screening tool has already shown great potential by beating current academic and commercial DR screening ap- proaches on large public retinal datasets. Going forward, we will build on our approach and further develop innovative, customized algorithms for critical low-level image processing steps, while leveraging on recent advances in computer vision, and machine learning areas for high-level, inference steps to produce a clinical grade DR screening tool. Our lesion localization and screening engine will be functionally integrated with EyePACS to further drive the expansion of screening, particularly benefiting under- resourced screening programs like the LAC-DHS safety net and its large Hispanic diabetic population. PUBLIC HEALTH RELEVANCE: EyeArt - an automated retinal image analysis tool will help in triaging patients in need of expert care and thus reduce the cost of diabetic retinopathy (DR) screening, while leading to an expansion of screening in primary care centers through its easily accessible telemedicine interface. This increased access to DR care will help prevent vision loss due to diabetes complications in vulnerable disparity populations such as Latinos who do not get screened due to socio-economic factors. To make an immediate impact we are collaborating with Los Angeles County Department of Health Services (LAC-DHS) to deploy our system, following clinical validation, in their under-resourced safety net teleretinal screening setup whic caters to large disparity populations of LA County.",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8891422,R44EB013585,"['Adult', 'Age', 'Agreement', 'Algorithms', 'Appointment', 'Area', 'Background Diabetic Retinopathy', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Clinical effectiveness', 'Color', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Consult', 'County', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Dimensions', 'Economic Factors', 'Economically Deprived Population', 'Education', 'Engineering', 'Evaluation', 'Eye', 'Faculty', 'Fundus', 'Goals', 'Gold', 'Health', 'Health Services', 'Hispanics', 'Image', 'Image Analysis', 'Industry', 'Institutes', 'Insurance', 'International', 'Latino', 'Lead', 'Learning', 'Lesion', 'Licensing', 'Los Angeles', 'Machine Learning', 'Marketing', 'Measures', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patient Triage', 'Patients', 'Pattern Recognition', 'Phase', 'Population', 'Predictive Value', 'Primary Health Care', 'Process', 'Protocols documentation', 'Provider', 'ROC Curve', 'Reader', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Project Grants', 'Resolution', 'Retinal', 'Retinal Diseases', 'Risk', 'Sensitivity and Specificity', 'Severities', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Surveys', 'System', 'Telemedicine', 'Testing', 'Texture', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Work', 'base', 'bioimaging', 'clinical care', 'cloud based', 'computerized', 'cost', 'design', 'diabetic', 'diabetic patient', 'experience', 'high risk', 'image processing', 'innovation', 'prevent', 'programs', 'prototype', 'safety net', 'screening', 'socioeconomics', 'success', 'tool', 'usability']",NIBIB,"EYENUK, INC.",R44,2015,394177,-0.0015800849786248871
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing.         PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.                ",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8826350,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'neovascular', 'novel', 'programs', 'public health relevance', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2015,215393,0.008498623053718094
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,8910751,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,589523,0.04288854545501288
"4D Software Tools for Longitudinal Prediction of Brain Disease     DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders.          PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.            ",4D Software Tools for Longitudinal Prediction of Brain Disease,8814543,R01EB008374,"['4D Imaging', 'Accounting', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'mild cognitive impairment', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2015,477101,-0.019237302566677997
"Image analysis for high-throughput C. elegans infection and metabolism assays DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute. PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8786567,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression Profile', 'Gene Expression Profiling', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'imaging platform', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,309263,0.008214299187041777
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals.         PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.            ",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9053610,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Microscopic', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'public health relevance', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2015,239361,-0.020971438520325424
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of available MR techniques and image contrast mechanisms that can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.         One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While our application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around development of support vector machine analysis of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hypersurface.      We are currently developing discriminant functions based on three metrics in both one variable and two variables.    These permit the translation of means and standard deviations to sensitivity and specificity of derived statistical tests. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,9147369,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Goals', 'Hydration status', 'Imaging Techniques', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Probability', 'Process', 'Relative (related person)', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Testing', 'Tissues', 'Training', 'Translations', 'Validation', 'Weight', 'Work', 'articular cartilage', 'base', 'cartilage degradation', 'contrast imaging', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2015,768909,-0.02176123156831503
"Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling ﻿    DESCRIPTION (provided by applicant): The quest for fast image acquisition speed has always been a perennial topic in the MRI community. To reduce the acquisition time for maximal spatial and temporal resolution, modern MRI protocols usually perform reduced acquisitions below the Nyquist rate. The reduced data is then used to reconstruct the image through advanced reconstruction techniques that leverage some prior information about the MRI system (e.g., parallel imaging) and/or MR signal (e.g., compressed sensing). Since such prior information is patient and system specific, recent techniques obtain the prior information using training data obtained through an empirical calibration procedure. All existing methods assume the prior models are linear. Since the intrinsic nonlinear relationship in the training data cannot be characterized in such simple models, the reconstruction is degraded by the inaccuracy of the prior information. Nonlinear learning from the training data have proven to be more powerful in machine learning because it is more general and includes the linear model as a special case. However, it is usually more challenging to learn the nonlinear models and even more challenging to incorporate the model in reconstruction due to the increased degree of freedom. We recently have introduced a novel concept of ""kernel"" in MR reconstruction to address the above challenges timely. Our preliminary results on parallel imaging and sparsity-constrained reconstruction demonstrate that the kernel-based algorithms improve the reconstruction quality over the original algorithms with linear prior models. Built upon our strong preliminary results, the objective of this application is to develop an innovative kernel-based framework for MR image reconstruction from undersampled data. This framework does not require explicit knowledge of nonlinear mapping (as in preliminary work) such that a broader family of nonlinear functions can be explored for different clinical applications. The proposed work is expected to advance the field of MR image reconstruction vertically. Specifically, the successful completion of the proposed project will result in a general framework leading to many new algorithms (including two developed in this project) for reconstruction from reduced acquisition. Therefore, virtually all of current clinical MRI could benefit from the improved resolution, image quality, and/or reduced acquisition times that the new framework will facilitate or the novel applications i may enable.         PUBLIC HEALTH RELEVANCE: The proposed research is to develop a general framework and two specific new techniques to improve the spatial resolution and/or reduce the scan time in magnetic resonance imaging and evaluate the performance of the techniques for 3D parallel imaging and quantitative imaging in brain. The development of such novel fast imaging techniques may greatly enhance diagnosis of neurological disease. Therefore the project will potentially benefit numerous subjects and the healthcare system.            ",Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling,8953102,R21EB020861,"['Address', 'Algorithms', 'Brain', 'Calibration', 'Clinical', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Family', 'Freedom', 'Healthcare Systems', 'Image', 'Imaging Techniques', 'Industry', 'Knowledge', 'Learning', 'Letters', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Modeling', 'Non-linear Models', 'Patients', 'Performance', 'Phase', 'Physics', 'Principal Component Analysis', 'Procedures', 'Protocols documentation', 'Qualifying', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Signal Transduction', 'Software Tools', 'Speed', 'System', 'Techniques', 'Time', 'Training', 'Weight', 'Work', 'base', 'clinical application', 'image reconstruction', 'improved', 'innovation', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'quantitative imaging', 'reconstruction', 'temporal measurement']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R21,2015,180330,0.03604950501330835
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,8902139,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2015,405249,0.048235464336763956
"High Performance Automated System for Analysis of Fast Cardiac SPECT DESCRIPTION (provided by applicant): Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before a heart attack, and predict risk in millions of patients annually. This is currently limited by the need fo visual interpretation, which is highly variable and depends on the physician's experience. The long-term objective of this program is to improve the interpretation of this widely used heart imaging technique-achieving higher accuracy for disease detection than it is possible by the best attainable visual analysis. This proposal builds on our prior work in conventional myocardial MPS, and focuses on fast, low-radiation MPS imaging (fast-MPS) obtained by new high-efficiency scanners. Specifically, we aim to: 1) develop new image processing algorithms for a fully automated analysis of fast-MPS. The algorithms will include better heart muscle detection by training with correlated anatomical data and a novel approach for mapping the probability of abnormal perfusion for each location of the heart muscle; 2) enhance the diagnosis of heart disease from fast-MPS by machine- learning algorithms that integrate clinical data, stress test parameters, and quantitative image features; 3) demonstrate the clinical utility of the new algorithms applied to automatic canceling of the rest portion of the MPS scan, when not needed. The new system will be more accurate than the clinical expert analysis in the detection of obstructive coronary disease. By immediately indicating whether a stress scan is normal, the system will allow for the automatic cancellation of the rest imaging portion when it is not needed (estimated in over 60% of all MPS studies). Our research will demonstrate that the computer decision regarding rest-scan cancellation is safe for the patient, both from a diagnostic and prognostic standpoint. This will lead to a wide adoption of low-dose stress-only imaging for MPS studies, which would reduce the amount of radiation that patients are exposed to, and allow for significant healthcare savings. It will additionally lead to a paradigm shift in the practice of nuclear cardiology, which will ultimately result in better selection of patients who need intervention, and reduce the number of deaths due coronary artery disease. PUBLIC HEALTH RELEVANCE: Imaging of myocardial perfusion (heart muscle blood flow) at rest and stress allows physicians to detect disease and predict risk in millions of patients in the US each year, but it is currently limited by the need of visual interpretation, which is dependent on doctor's experience. The investigators propose to develop and validate an automated, highly-accurate and objective computer system which will outperform even experienced physicians in interpreting these images using latest generation scanners and novel machine learning computer tools. The computer will be able to better select patients needing treatment and automatically indicate the normal stress-scan immediately, and more accurately than physicians allowing automatic cancellation of the rest imaging, when not needed; this will result in large healthcare savings and reduced radiation to the patients.",High Performance Automated System for Analysis of Fast Cardiac SPECT,8906912,R01HL089765,"['Adoption', 'Algorithms', 'Blood', 'Blood flow', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Systems', 'Computers', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Dose', 'Generations', 'Health', 'Healthcare', 'Heart Diseases', 'Image', 'Imaging Techniques', 'Intervention', 'Lead', 'Location', 'Machine Learning', 'Maps', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Patient Selection', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Probability', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Savings', 'Scanning', 'Stress', 'Stress Tests', 'System', 'Systems Analysis', 'Training', 'United States', 'Visual', 'Work', 'cardiac single photon emission computed tomography', 'experience', 'heart imaging', 'image processing', 'improved', 'novel', 'novel strategies', 'prognostic', 'programs', 'quantitative imaging', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2015,685014,0.014591966304917312
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8842639,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2015,332955,0.0035069763880461757
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact).         PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.            ",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,8946754,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2015,658985,0.012686012897553426
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8852613,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,213115,0.03662215286454506
"Cloud-computer-aided diagnostic imaging decision support system DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer. Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.",Cloud-computer-aided diagnostic imaging decision support system,8848046,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'accurate diagnosis', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2015,361050,-0.03695537992623735
"Cloud-computer-aided diagnostic imaging decision support system DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer. Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.",Cloud-computer-aided diagnostic imaging decision support system,9050240,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'accurate diagnosis', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2015,227070,-0.03695537992623735
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics.         PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.            ",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9072725,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disadvantaged', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Population', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'Solutions', 'Staging', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2015,299984,0.016505465945273818
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice.         PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.                ","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",8960049,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissue Survival', 'Tissues', 'Tumor Burden', 'base', 'cancer genomics', 'cancer imaging', 'cancer therapy', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'statistics', 'success', 'tool', 'transcriptome sequencing', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2015,652612,-0.0031273751225334634
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,8842707,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Health', 'Heart', 'Heart Diseases', 'Image', 'Individual', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'interest', 'predictive modeling', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2015,758935,0.04630148028577662
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics. n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8792208,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2015,248295,0.015456565673140138
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8922953,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2015,314327,0.05179957234559452
"Pattern recognition in medical imaging Modern imaging systems far exceed the human eye in spatial and spectral resolution and in dynamic range, thus potentially allowing machine-based image pattern analysis systems to outperform manual image interpretation. In fact, recent work in pattern recognition has demonstrated that computers can equal or even surpass image classification and pattern analysis by human experts.  We have previously published work investigating the progression of osteoarthritis (OA) in the human population comprising the Baltimore Longitudinal Study of Aging (BLSA).  We were able to show that WND-CHARM (see AG000671-13) is able to diagnose the existence of OA in knee X-Rays with accuracies approaching that of a panel of highly trained radiologists.  We have subsequently published work that WND-CHARM can predict the future onset of radiologically detectable osteoarthritis in X-Rays that were scored as radiologically clear.  We were able to show that the development of moderate OA two decades in the future can be predicted with > 70% accuracy from X-Rays scored as free of OA by a panel of three radiologists.  Subsequently, we were able to further characterize OA progression and identify an early, slow period of change followed by rapid degeneration.   We are following up our knee X-ray studies with an MRI dataset obtained from the Osteoarthritis Initiative as well as experimental MRI samples imaged here at NIA through a collaboration with Dr. Richard Spencer (NIA/LCI). In a recently published study, we developed a technique using multivariate linear regression of image features derived from several types of MRI scans to construct a continuously variable cartilage quality score similar to an OARSI grade.  The OARSI grade is determined histologically, and involves an invasive procedure that is not amenable to early screening or tracking disease progress.  While MRI methods are non-invasive, they must first be correlated with histological grading schemes before they can be used in diagnosis or evaluating cartilage quality.  We analyzed samples from cadavers that were imaged using several MRI modalities as well as scored histologically using the OARSI scale.  Standard classification experiments using single MRI scans of degraded vs. non-degraded cartilage as determined by OARSI had accuracies > 80%, which are substantially higher than published reports correlating scores derived from MRI images with OARSI grades.  Our multivariate regression of image features from multimodal MRI scans produced a continuous score that was well correlated with the OARSI grade of the same samples (r > 0.65, p < 10-5).  Defining a continuous grading system based on a non-invasive procedure is a key element in evaluating osteoarthritis treatment strategies.  A recently completed study being prepared for publication involves abdominal CT scans.  The viscera, bone, subcutaneous and visceral fat in these scans has been segmented into separate image masks using the characteristic densities of these tissues on the Hounsfield scale. Our analysis of these image masks indicates that a strong aging signal is present in adipose tissues as well as in the unsegmented whole CT scans. These results are based on cross-validation of classifiers trained on a middle-age group (56-70) and an older group (81-99).  This is by far the largest image-based aging study done in humans, and it clearly shows that adipose tissue is one of the major factors in age-related changes occuring in the abdomen.  Another radiology project is in collaboration with Dr. Maria Knoll at the Johns Hopkins Bloomberg School of Public Health.  Here the goal is to diagnose viral vs., bacterial pneumonia in children using chest X-rays.  A rapid accurate diagnosis of the nature of this disease will dramatically improve outcomes for children in developing countries.  A standard set of chest X-rays is available from the World Health Organization that is well annotated, with each X-ray having beenn read by mmultiple expert radiologists forming a solid ground truth for training machine classifiers.  The major challenge posed by this set is the extreme variation in the physical size of the subjects due to the variation in their ages.  We have developed a strategy to compensate for this size variation by working with a student at JHSPH to manually annotate the X-rays with a set of fiducial marks that are anatomically comparable across the X-rays regardless of subject size.  Using these manually aligned regions of the lung, we have preliminary indications that such a diagnosis may be possible. We are currently assembling a completed manually annotated set from the WHO, as well as a different set of X-rays that has recently become available through JHSPH.  A project recently begun involves analyzing fundus images collected by the National Eye Institute. The goal is two-fold: 1) Develop an automated scoring system for age-related macular degeneration (AMD), and use fundus images from SardiNIA for testing and validation using manual reads by our NEI collaborators.  2) Develop a set of numerical descriptors for segmented vasculature in fundus images, correlate them with cardiovascular traits measured in SardiNIA, and use them to determine genome-wide associations to these traits.  Currently, preliminary experiments have been able to automatically detect an AMD signal in NEI fundus images, and thuse preliminary findings are being refined.  Additionally, software has been identified to automatically segment vasculature from fundus images.  Our work in developing tools and expertise in analyzing images to obtain physiological insights that are not directly observable has recently been translated to non-image-based clinical data.  In this project, we used machine learning and the totality of the quantitative trait data collected in the SardiNIA study to ascertain each participant's age.  This predicted age was excpected to closely correlate to chronological age, but as it was based on broad physiological measurements, be more closely related to each participant's physiological age.  The ratio between physiological and chronological age can be viewed as a measure of aging rate, and we determined that this rate is largely preserved for each participant across multiple visits.  Moreover, we determined that 40% of the variation in aging rates is heritable, and by performing a GWAS showed that it is significantly associated with two genes related to telomere function.  This study is currently being prepared for publication.  The use of machine learning and pattern recognition to mine new insights from numerical clinical data has great potential, and we are actively pursuing this strategy with new projects.  In collaboration with Madhav Thambisetty and Kevin Becker, we are extending this approach to examine traits in BLSA participants that may be predictive of later diagnosis of Alzheimer's disease.  In a collaboration with Matt Oberdier and Majd AlGhatrif (LCS) we are applying these tools to analyze data from blood flow and pressure sensors to act as markers of cardiovascular state in rats. n/a",Pattern recognition in medical imaging,9147320,ZIAAG000685,"['Abdomen', 'Adipose tissue', 'Age', 'Age related macular degeneration', 'Aging', 'Alzheimer&apos', 's Disease', 'Bacterial Pneumonia', 'Baltimore', 'Biological Markers', 'Biopsy', 'Blood Pressure', 'Blood flow', 'Cadaver', 'Cardiovascular system', 'Cartilage', 'Characteristics', 'Child', 'Classification', 'Clinical Data', 'Collaborations', 'Collection', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Degenerative polyarthritis', 'Descriptor', 'Developing Countries', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Eye', 'Fatty acid glycerol esters', 'Fundus', 'Future', 'Genes', 'Goals', 'Hematoxylin and Eosin Staining Method', 'Histologic', 'Homeostasis', 'Human', 'Image', 'Image Analysis', 'Indium', 'Knee', 'Lead', 'Life', 'Linear Regressions', 'Longitudinal Studies', 'Lung', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Masks', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Mining', 'Modality', 'Morphology', 'National Eye Institute', 'Nature', 'Outcome', 'Participant', 'Pattern', 'Pattern Recognition', 'Physiological', 'Pneumonia', 'Population', 'Procedures', 'Public Health Schools', 'Publications', 'Publishing', 'Radiology Specialty', 'Rattus', 'Reading', 'Reporting', 'Resolution', 'Roentgen Rays', 'Sampling', 'Sardinia', 'Scanning', 'Scheme', 'Signal Transduction', 'Solid', 'Staining method', 'Stains', 'Students', 'Study Section', 'System', 'Systems Analysis', 'Techniques', 'Testing', 'Thoracic Radiography', 'Time', 'Tissues', 'Training', 'Translating', 'Validation', 'Variant', 'Viral', 'Viscera', 'Visceral', 'Visit', 'Work', 'World Health Organization', 'X-Ray Computed Tomography', 'abdominal CT', 'accurate diagnosis', 'age group', 'age related', 'base', 'bone', 'clinical Diagnosis', 'clinically relevant', 'density', 'functional decline', 'genome wide association study', 'human disease', 'imaging system', 'improved', 'insight', 'middle age', 'outcome forecast', 'radiologist', 'research study', 'screening', 'sensor', 'subcutaneous', 'telomere', 'tool', 'trait', 'treatment strategy', 'tumor progression']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2015,334462,0.02125125876361294
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging.         PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.                ",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,8968015,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2015,169609,0.020196330208896263
"Development And Applications Of The Open Microscopy Environment (OME) In recent years, we have focused on developing robust general image analysis methodology, culminating in our pattern recognition tool called WND-CHRM.  We have validated this pattern-recognition approach to biological image analysis using diverse imaging modalities ranging from fluorescence microscopy to X-rays of human knees, MRIs, and other imaging modalities.  We have also validated a range of  applications from scoring image-based assays to diagnosis of disease to prediction of future disease risk.  The specific applications of this approach are covered in reports AG000674-10 and AG000685-07.  A major effort recently has been to rewrite the WND-CHARM code-base to make it more modular, better organized, easier to use, and accessible with the Python scripting language.  A recent release of WND-CHARM 1.52 is available from our code repository (http://ome.grc.nia.nih.gov/wnd-charm/wndchrm-1.52.775.tar.gz).  This release focuses on streamlining access to image feature computing algorithms so that they are individually acessible by the name of the algorithm and any preceding image transforms.  The individual algorithms are also broken out behind a common interface so that new algorithms are easy to add. The image feature computing plan was previously hard-coded, but to make it more flexible, easier to modify, and responsive to ""on demand"" feature requests, it is now automatically assembled based on the requested features, taking account of their preceding image transform dependencies.   Whole-image analysis has proven very useful, but it is not always possible to compare whole images to each other.  Examples of relatively homogenous images are those of cultured cells, or tissues like muscle, liver, and certain types of tumors.  Our work on human knee X-Rays (see AG000685-07) was the first application where a certain degree of pre-processing was necessary to align images of different subjects to compare them to each other.  In this case, we simply found the center of the knee joint in each image and extracted a fixed radius around this center for all patients.  A much more complicated alignment problem exists in images with complex anatomy.  Possibly the most extreme example of this are stained sections of brain tissue.  A solution to the alignment problem would allow the use of generalized pattern recognition to address morphological differences in an anatomical context.  Spatially-resolved pattern analysis places an extreme burden on the performance of our software.  Instead of an entire image being considered at once, or split into a small number of tiles on a grid, to achieve spatial resolution, each image must be sampled thousands or millions of times.  In order to make this type of application practical, the computational strategy used in the software must be reconsidered.  Previously, all 3,000 low-level image features were calculated for each image sample, even when most of them were later found to be irrelevant to the classification problem because they lacked discrimination power.  The major change in strategy to enable spatially-resolved pattern recognition is to eliminate unnecessary calculations.  This requires an on-demand computing strategy for image features, which is a major architectural goal for the wndchrm software.  Our current release makes use of this strategy, exposing a very simple to use API for specifying the specific features to be computed.  We have have also made the majority of the underlying C++ code accessible from the Python scripting language to make it easier to customize how WND-CHARM is used in new applications. It is now possible to compute on-demand features using the Python interface and perform further processing using mathematical and scientific computing libraries available for Python (numpy, scipy).  A major feature expanded in the past year is the ""file of files"" interface.  Previously this was simply a spreadsheet of individdual single-plane tiff files and the classes they belong to.  Now, this interface allows the use of multi-dimensional (5D) image files to construct classification experiments, as well as allowing the combination of multiple image planes into extended multi-plane feature sets.  An example of multi-plane feature sets is in the use of separate Hematoxylin and Eosin channels of the same image to compute a compound set of image descriptors.  Other examples include combining multiple planes from a 3D experiment.  These experiments previously required specialized code, but can now be accomplished simply by editing a ""file of files"" spreadsheet. The Python-related software is publicly available on our new public code repository (https://github.com/wnd-charm/wnd-charm).  In 2012, in collaboration with Jason Swedlow (University of Dundee, Scotland), a large international project sponsored by the Wellcome Trust was initiated to develop specific applications of the OME/OMERO system.  Our group's contribution to this project involves providing interfaces between OMERO and WND-CHARM to enable image comparisons in large, diverse image repositories.  The eventual goal is to use pattern recognition to annotate new images added to these collections automatically, based on previously annotated images and a large set of independent classifiers that opeerate autonomously in the background.  The primary design goal of a system like OME/OMERO is to provide scientists with easy ways of organizing and annotating their image collections.  The organizational structure of the images and their grouping by their annotations can also serve as the primary inputs for training pattern-recognition classifiers.  Because classifiers require little or no additional input from the user, the natural convergence of these two technologies represent a powerful new mode for maximizing the utility of large scale scientific and medical image databases.  Currently we have a functioning prototype that interacts with OMERO to read image data and annotations; use these for training a classifier; and return annotations derived from classification back to OMERO.  Substantial work remains to make this integrated system practical.  Currently, a developer-preview release is available, but it lacks the flexibility on the OMERO side to keep track of multiple, potentially conflicting classifications for images, as well as maintaining a flexible store of image feature sets.  Our current efforts are to implement a standardized feature store based on the widely used HDF data format, which can be used both standalone with WND-CHARM alone, and when using WND-CHARM together with the OME database. n/a",Development And Applications Of The Open Microscopy Environment (OME),9147317,ZIAAG000671,"['Accounting', 'Address', 'Algorithms', 'Anatomy', 'Back', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Classification', 'Code', 'Collaborations', 'Collection', 'Complex', 'Computer software', 'Computers', 'Conflict (Psychology)', 'Cultured Cells', 'Data', 'Databases', 'Dependency', 'Descriptor', 'Development', 'Discrimination', 'Ensure', 'Environment', 'Fluorescence Microscopy', 'Future', 'Generic Drugs', 'Goals', 'Grouping', 'Hematoxylin and Eosin Staining Method', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Individual', 'Informatics', 'International', 'Knee', 'Knee joint', 'Language', 'Libraries', 'Liver', 'Machine Learning', 'Manuals', 'Mathematical Computing', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Microscopy', 'Modality', 'Modeling', 'Muscle', 'Names', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Process', 'Pythons', 'Radial', 'Reading', 'Reporting', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scientist', 'Scotland', 'Semantics', 'Side', 'Solutions', 'Specific qualifier value', 'Speed', 'Staining method', 'Stains', 'System', 'Tars', 'Technology', 'Time', 'Tissues', 'Training', 'Trust', 'Universities', 'Visual', 'Work', 'age related', 'base', 'brain tissue', 'data format', 'data modeling', 'design', 'detector', 'digital', 'disease diagnosis', 'disorder risk', 'flexibility', 'imaging informatics', 'imaging modality', 'medical specialties', 'open source', 'organizational structure', 'practical application', 'programs', 'prototype', 'repository', 'research study', 'scientific computing', 'software development', 'targeted imaging', 'tool', 'tumor']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2015,331966,0.05792201491877305
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8885879,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2015,457216,-0.006168876280915534
"Clinical Evaluation of Lung Motion Tracker for Improved Diagnosis and Treatment ﻿    DESCRIPTION (provided by applicant): In dynamic image-guided radiotherapy for lung cancer, one of the major tasks is to provide the dynamic images and tumor shapes that reflect the patient's real-time anatomy as the roadmap for guiding the delivery of radiation beams. One fundamental question for these applications is how to estimate such dynamic images, as well location and shape changes of tumor using available sensors to capture the respiratory motion. This proposal focuses on solving such a lung motion tracking problem by using our newly proposed high- dimensional surface to lung motion prediction model and considering the difference of each individuals, such as gender, size, and respiratory pattern. Specifically, we wil optimize the statistical models that capture the motion distribution from training samples and the nonlinear prediction model for accurate lung motion tracking and conduct extensive evaluation for the lung motion tracking system developed to validate its feasibility in clinic practice. Our goal is to develop an efficient, effective and robust lung motion tracking system for dynamic image guidance of the radiotherapy procedures. After this clinical data validation, such a technique can also be applied to image-guided intervention.         PUBLIC HEALTH RELEVANCE: Lung motion tracking is essential for dynamic image-guided radiotherapy for lung cancer. We propose to estimate the dynamic lung motion for patient using the high-dimensional chest surface motion. Due individual variability (patient size, gender, and different respiratory patterns), in this proposal, we will optimize the newly proposed lung motion tracking by considering practical patient variability and evaluate the performance of the proposed system with a large number of dataset collected from radiotherapy planning.            ",Clinical Evaluation of Lung Motion Tracker for Improved Diagnosis and Treatment,8893187,R03EB018977,"['Abdomen', 'Adult', 'Algorithms', 'Anatomy', 'Biological Models', 'Breathing', 'Cancer Etiology', 'Cancer Patient', 'Cessation of life', 'Chest', 'Clinic', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Data Set', 'Diagnosis', 'Early Diagnosis', 'Evaluation', 'Gender', 'Goals', 'Image', 'Individual', 'Joints', 'Least-Squares Analysis', 'Left', 'Location', 'Lung', 'Lung Neoplasms', 'Machine Learning', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Obesity', 'Optics', 'Patients', 'Pattern', 'Performance', 'Phase', 'Principal Component Analysis', 'Procedures', 'Radiation', 'Radiation therapy', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Respiration', 'Sampling', 'Shapes', 'Signal Transduction', 'Statistical Models', 'Surface', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Tumor Volume', 'United States', 'Validation', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer imaging', 'cancer radiation therapy', 'clinical practice', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'image reconstruction', 'imaging Segmentation', 'improved', 'male', 'new technology', 'open source', 'optical imaging', 'public health relevance', 'real time model', 'research clinical testing', 'respiratory', 'sensor', 'tumor']",NIBIB,METHODIST HOSPITAL RESEARCH INSTITUTE,R03,2015,79750,-0.019549458178019945
"Statistical methods for large and complex databases of ultra-high-dimensional DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.",Statistical methods for large and complex databases of ultra-high-dimensional,8890255,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multicenter Studies', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Population Study', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Solutions', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'contrast enhanced', 'data visualization', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'skills', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2015,347156,0.008295021665244493
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, an image includes not only biomedical images, but also illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. We are seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. To meet these objectives, we use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers a richer search.   Taking the retrieval of biomedical literature a step further, our goal is to find information relevant to a patient's case from the literature and then link it to the patients health record. The case is first represented in structured form using both text and image features, and then literature and EHR databases are searched for similar cases.  A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval objectives are achieved in the following ways: (i) using image analysis; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. Additional steps include describing an image with visual features, automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.), and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed OpenI (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. OpenI is a novel system that enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 733,000 open access articles and nearly 2.3 million illustrations from the biomedical literature hosted at the National Library of Medicine's PubMed Central repository; over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays; and about 600 orthopedic anatomy illustrations provided by Norris Medical Library, University of Southern California. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publisher's Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to the problem of searching for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using the (clinical) image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. OpenI indexes all the text and illustrations in medical articles by features, both textual and image-based. OpenI also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and deidentified patient records. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first production-quality system of its kind in the biomedical domain, OpenI has enabled medical professionals and the public to access visual information from biomedical articles that are highly relevant to their query, as well as the ""take away"" messages of the articles. The quality of the information delivered by OpenI has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system placed first in 2013 image retrieval evaluation that attracted participants from academia, industry and clinical settings. For the past year the site has attracted over 7,000 unique visitors daily (excluding bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. During the 2015 reporting period, the Open-I user interface was redesigned to provide equal quality of retrieval results for all types of devices used to access the site. n/a",Integrating image and text information for biomedical information retrieval,9160922,ZIALM010001,"['Academia', 'Anatomy', 'California', 'Chest', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Devices', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'Hybrids', 'Image', 'Image Analysis', 'Indiana', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Medical', 'Medical Libraries', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Orthopedics', 'Outcome', 'Participant', 'Patients', 'Performance', 'Physicians', 'Process', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Visual', 'Work', 'abstracting', 'base', 'bioimaging', 'cluster computing', 'digital', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'meetings', 'novel', 'patient oriented', 'phrases', 'repository', 'text searching', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2015,484333,-0.013104690740240411
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8771432,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,639475,0.01374142401715393
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8807942,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2015,767996,0.012116660210422812
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2).          PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.                 ",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,8854343,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Minority', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2015,63363,0.01080629321577253
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression.         PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.            ",Prediction of IPF Progression Using Imaging Patterns,8956609,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'insight', 'interstitial', 'novel', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'public health relevance', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2015,107290,0.007740973244649574
"Quantitative Image Analysis Techniques for Optic Nerve Disease DESCRIPTION (provided by applicant): Disorders of the optic nerve (ON) account for a significant percentage of the 20 most impactful ophthalmological conditions. Collectively, diseases of the ON are the number one cause of irreversible blindness worldwide, and present serious public health concerns in the U.S. Consider, for example, that glaucoma impacts more than three million Americans and costs the U.S. economy almost $3 billion per year. Optic neuritis (i.e., inflammatory demyelination of the ON) is the initial symptom in ~25% of all multipl sclerosis (MS) cases (which impacts over 400 thousand Americans and introduces societal health care costs of nearly $30 billion per year). Nearly two thirds of MS patients will experience episodes of optic neuritis in their lifetimes, and 40-60% of patients have visual defects localized to the ON. These disorders irreversibly damage the ON. Even so, damage to axons in the ON is progressive, defined by a window of opportunity for treatment between loss of function and actual degeneration. The potential for recovery exists because there are treatments that can help prevent progression if administered during this window of opportunity. Yet, we do not have effective means to assess who is in the window and who will benefit from treatment. We propose to translate computational imaging methods from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. These efforts will improve prognostic accuracy, lead to better understanding of patient responses, and enhance targeted interventions. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not.  The overall goal of this research is to provide a foundation for image analysis of the ON and its relationships with pathological disorders. We will build upon recent advances in robust medical image computing to segment the ON in clinical CT and MRI acquisitions, develop registration procedures to establish intra- and inter-subject correspondence, and bring together information from the multi-modal battery of imaging studies that are typically used in clinical care (aim 1). With these new methods, we will address the exploratory hypothesis that quantitative use of clinical imaging data can increase prognostic accuracy (aim 2). We note that aim 2 is particularly exploratory and in line with the high- risk/high-reward aspect of this mechanism; many studies have shown that baseline imaging does not conclusively predict long term outcome or treatment response. We hypothesize that this may be because early findings are related to edema and inflammation rather than cellular damage per se. Once this exploratory phase is complete, we will pursue promising prognostic biomarkers using more detailed condition staging criteria and including more than two longitudinal time points in the analysis. Ultimately, these efforts will improve assessment ON disease and, in turn, patient care. PUBLIC HEALTH RELEVANCE:  We propose to translate medical imaging computing procedures from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not more effectively than traditional pre-interventional measures.",Quantitative Image Analysis Techniques for Optic Nerve Disease,8774908,R21EY024036,"['Accounting', 'Acute', 'Address', 'Adrenal Cortex Hormones', 'Affect', 'Aftercare', 'Age', 'Algorithms', 'American', 'Area', 'Axon', 'Biological Markers', 'Blindness', 'Brain', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Communities', 'Data', 'Defect', 'Demyelinations', 'Diagnostic', 'Disease', 'Edema', 'Eye', 'Foundations', 'Gap Junctions', 'Glaucoma', 'Goals', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Inflammatory', 'Interferons', 'Intervention', 'Intracranial Hypertension', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Modality', 'Multiple Sclerosis', 'Myelin', 'Nerve Tissue', 'Neurologic', 'Nutritional', 'Operative Surgical Procedures', 'Optic Disk', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Neuritis', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Prognostic Marker', 'Property', 'Protective Agents', 'Public Health', 'Publishing', 'Recovery', 'Recurrence', 'Relapse', 'Research', 'Resource Sharing', 'Resources', 'Scanning', 'Sclerosis', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Swelling', 'Symptoms', 'Tars', 'Techniques', 'Thyroid Diseases', 'Time', 'Training', 'Translating', 'Treatment outcome', 'Tweens', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical care', 'clinical practice', 'clinical sequencing', 'computerized tools', 'contrast imaging', 'cost', 'direct application', 'experience', 'high reward', 'high risk', 'image processing', 'imaging modality', 'improved', 'innovation', 'loss of function', 'nerve decompression', 'neuroimaging', 'optic nerve disorder', 'outcome forecast', 'pressure', 'prevent', 'prognostic', 'prognostic value', 'quantitative imaging', 'response', 'standard of care', 'success', 'thyroid associated ophthalmopathies', 'tool', 'treatment response', 'vector']",NEI,VANDERBILT UNIVERSITY,R21,2015,185147,0.005810299226675904
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,8887334,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2015,591379,0.03904125267400077
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8919113,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'imaging software', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'targeted imaging', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,341788,0.05551060013187785
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities.         PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.                ","Pathology Image Informatics Platform for visualization, analysis and management",8970326,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2015,606305,0.007782822129024382
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8699686,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'E-learning', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2014,142837,0.011948472898020647
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8699686,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'E-learning', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2014,1,0.011948472898020647
"Automated retinopathy of prematurity classification using machine learning     DESCRIPTION (provided by applicant): The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH-funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi-disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing.         PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.",Automated retinopathy of prematurity classification using machine learning,8723225,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2014,198905,0.01895673796086787
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications  Abstract In this small business innovations research (SBIR) project we present EyeArt, a retinal image analysis tool for automated diabetic retinopathy (DR) screenings with high diag- nostic efficacy. With its interface to EyePACS, a license-free, scalable telemedicine plat- form, EyeArt will aid the expansion of DR screening and help bridge the exponentially growing disparity between the number of diabetic patients and the number of eye-care providers. Research suggests that the Latino population in general are genetically predisposed to develop diabetes. Their vulnerability to vision loss due to diabetic retinopathy is further compounded by factors such as lack of access to ophthalmology clinicians, lack of in- surance, and lack of education. According to the Department of Health Services (DHS) in Los Angeles County (LAC) the situation for diabetics is particularly grim, with current wait times upwards of 6-9 months for retinal examinations for retinopathy screening. This can lead to treatment delays and progression towards irreversible vision loss. To help reduce risk of vision loss in this diabetic population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and aid in triage of high-risk patients. Our phase I prototype automatic DR screening tool has already shown great potential by beating current academic and commercial DR screening ap- proaches on large public retinal datasets. Going forward, we will build on our approach and further develop innovative, customized algorithms for critical low-level image pro- cessing steps, while leveraging on recent advances in computer vision, and machine learning areas for high-level, inference steps to produce a clinical grade DR screening tool. Our lesion localization and screening engine will be functionally integrated with EyePACS to further drive the expansion of screening, particularly benefiting under- resourced screening programs like the LAC-DHS safety net and its large Hispanic dia- betic population. PUBLIC HEALTH RELEVANCE: EyeArt - an automated retinal image analysis tool will help in triaging patients in need of expert care and thus reduce the cost of diabetic retinopathy (DR) screening, while leading to an expansion of screening in primary care centers through its easily accessible telemedicine interface. This increased access to DR care will help prevent vision loss due to diabetes complications in vulnerable disparity populations such as Latinos who do not get screened due to socio-economic factors. To make an immediate impact we are collaborating with Los Angeles County Department of Health Services (LAC-DHS) to deploy our system, following clinical validation, in their under-resourced safety net teleretinal screening setup whic caters to large disparity populations of LA County.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8740363,R44EB013585,"['Adult', 'Age', 'Agreement', 'Algorithms', 'Appointment', 'Area', 'Background Diabetic Retinopathy', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Clinical effectiveness', 'Color', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Consult', 'County', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Dimensions', 'Economic Factors', 'Economically Deprived Population', 'Education', 'Engineering', 'Evaluation', 'Eye', 'Faculty', 'Fundus', 'Goals', 'Gold', 'Health', 'Health Services', 'Hispanics', 'Image', 'Image Analysis', 'Industry', 'Institutes', 'Insurance', 'International', 'Latino', 'Lead', 'Learning', 'Lesion', 'Licensing', 'Los Angeles', 'Machine Learning', 'Marketing', 'Measures', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patient Triage', 'Patients', 'Pattern Recognition', 'Phase', 'Population', 'Predictive Value', 'Primary Health Care', 'Process', 'Protocols documentation', 'Provider', 'ROC Curve', 'Reader', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Project Grants', 'Resolution', 'Retinal', 'Retinal Diseases', 'Risk', 'Sensitivity and Specificity', 'Severities', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Surveys', 'System', 'Telemedicine', 'Testing', 'Texture', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Work', 'base', 'bioimaging', 'clinical care', 'cloud based', 'computerized', 'cost', 'design', 'diabetic', 'diabetic patient', 'experience', 'high risk', 'image processing', 'innovation', 'prevent', 'programs', 'prototype', 'public health relevance', 'safety net', 'screening', 'socioeconomics', 'success', 'tool', 'usability']",NIBIB,"EYENUK, INC.",R44,2014,394542,-0.0018142178912624832
"Continued Development of CellProfiler Cell Image Analysis Software     DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology.         PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.            ",Continued Development of CellProfiler Cell Image Analysis Software,8761195,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'public health relevance', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,522488,0.04288854545501288
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8600293,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,310129,0.008214299187041777
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of available MR techniques and image contrast mechanisms that can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.         One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While our application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around development of support vector machine analysis of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hypersurface.      We are currently developing discriminant functions based on three metrics in both one variable and two variables.    These permit the translation of means and standard deviations to sensitivity and specificity of derived statistical tests. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,8931615,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Goals', 'Hydration status', 'Imaging Techniques', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metric', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Probability', 'Process', 'Relative (related person)', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Testing', 'Tissues', 'Training', 'Translations', 'Validation', 'Weight', 'Work', 'articular cartilage', 'base', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2014,944170,-0.02176123156831503
"Graph-Based Medical Image Segmentation in 3D and 4D     DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care.         PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.            ",Graph-Based Medical Image Segmentation in 3D and 4D,8759436,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'public health relevance', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2014,395708,0.048235464336763956
"High Performance Automated System for Analysis of Fast Cardiac SPECT     DESCRIPTION (provided by applicant): Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before a heart attack, and predict risk in millions of patients annually. This is currently limited by the need fo visual interpretation, which is highly variable and depends on the physician's experience. The long-term objective of this program is to improve the interpretation of this widely used heart imaging technique-achieving higher accuracy for disease detection than it is possible by the best attainable visual analysis. This proposal builds on our prior work in conventional myocardial MPS, and focuses on fast, low-radiation MPS imaging (fast-MPS) obtained by new high-efficiency scanners. Specifically, we aim to: 1) develop new image processing algorithms for a fully automated analysis of fast-MPS. The algorithms will include better heart muscle detection by training with correlated anatomical data and a novel approach for mapping the probability of abnormal perfusion for each location of the heart muscle; 2) enhance the diagnosis of heart disease from fast-MPS by machine- learning algorithms that integrate clinical data, stress test parameters, and quantitative image features; 3) demonstrate the clinical utility of the new algorithms applied to automatic canceling of the rest portion of the MPS scan, when not needed. The new system will be more accurate than the clinical expert analysis in the detection of obstructive coronary disease. By immediately indicating whether a stress scan is normal, the system will allow for the automatic cancellation of the rest imaging portion when it is not needed (estimated in over 60% of all MPS studies). Our research will demonstrate that the computer decision regarding rest-scan cancellation is safe for the patient, both from a diagnostic and prognostic standpoint. This will lead to a wide adoption of low-dose stress-only imaging for MPS studies, which would reduce the amount of radiation that patients are exposed to, and allow for significant healthcare savings. It will additionally lead to a paradigm shift in the practice of nuclear cardiology, which will ultimately result in better selection of patients who need intervention, and reduce the number of deaths due coronary artery disease.         PUBLIC HEALTH RELEVANCE: Imaging of myocardial perfusion (heart muscle blood flow) at rest and stress allows physicians to detect disease and predict risk in millions of patients in the US each year, but it is currently limited by the need of visual interpretation, which is dependent on doctor's experience. The investigators propose to develop and validate an automated, highly-accurate and objective computer system which will outperform even experienced physicians in interpreting these images using latest generation scanners and novel machine learning computer tools. The computer will be able to better select patients needing treatment and automatically indicate the normal stress-scan immediately, and more accurately than physicians allowing automatic cancellation of the rest imaging, when not needed; this will result in large healthcare savings and reduced radiation to the patients.            ",High Performance Automated System for Analysis of Fast Cardiac SPECT,8762268,R01HL089765,"['Adoption', 'Algorithms', 'Blood', 'Blood flow', 'Cardiac', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Systems', 'Computers', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Dose', 'Generations', 'Healthcare', 'Heart Diseases', 'Image', 'Imaging Techniques', 'Intervention', 'Lead', 'Location', 'Machine Learning', 'Maps', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Patient Selection', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Probability', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Savings', 'Scanning', 'Stress', 'Stress Tests', 'System', 'Systems Analysis', 'Training', 'United States', 'Visual', 'Work', 'experience', 'heart imaging', 'image processing', 'improved', 'novel', 'novel strategies', 'prognostic', 'programs', 'public health relevance', 'single photon emission computed tomography', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2014,653934,0.014591966304917312
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8653848,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2014,436094,-0.004293519968457697
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8652462,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2014,332955,0.0035069763880461757
"Mobile App for Diabetic Retinopathy Screening using Cellphone Retinal Camera     DESCRIPTION (provided by applicant): In this SBIR project, we present EyeApp, a smartphone-based end-to-end point-of- care diabetic retinopathy diagnostic device comprising of a smartphone-attachable retinal imaging camera and validated software application enabling fully-automated screening of diabetic retinopathy (DR). DR is the leading cause of new-onset blindness in working-age adults in the industrialized world today. Studies show that in 90% of the cases vision loss can be prevented if DR is diagnosed at an early stage.  Recommended annual screening is expected to significantly improve outcome for diabetic patients, but even in the developed world, majority of the diabetics do not regularly have the annual screening due to several limiting factors. To make things worse, the current cost of screening all diabetics to detect those with early DR is very high because: (a) most patients will have normal exams (thus, causing inefficient use of specialist's time), (b) retinal imaging equipment is very expensive, and (c) trained technicians must operate the imaging equipment. In this project we address these critical limitations by employing cellphone retinal camera attachment, the Ocular CellScope, developed by our collaborators at UCB/UCSF, which simply attaches to an iPhone, doesn't need a trained technician to operate, will obtain wide-field images, and will cost several orders of mag- nitude less than the current tabletop retinal imaging cameras. Diabetic patients can attach the camera to their smartphones and with some assistance (untrained friend, spouse, or nurse) obtain retinal video for each eye using an app residing on the same phone. This app guides the image capture to ensure that best quality frames are obtained, and also ensure all areas of the eye are imaged enabling wide-field imaging. EyeApp's validated algorithms output a near-instant DR screening recommendation score. EyeApp is con- ceptualized as a culmination of over three years of research and development at Eyenuk (on computerized DR screening) and at UCB/UCSF (on smartphone retinal camera) that has already produced functional prototypes of critical technology modules. This phase I project focusses on seamless integration of these proven modules (the camera hardware and the diagnostic software) via several novel ideas.         PUBLIC HEALTH RELEVANCE: EyeApp, a smartphone-based end-to-end point-of-care diabetic retinopathy diagnostic device, will truly enable diabetic retinopathy screening at massive scale, which is necessary and urgent - since the world diabetic population is estimated to be a staggering 371 million, and is projected to grow to over half a billion by 2030. EyeApp will operate in and end-to-end fashion, from retinal imaging to diagnostic screening, all without needing a trained operator. It will cost orders of magnitude less than conventional retinal cameras, and will simply attach to a smartphone, thus greatly reducing the cost and expanding the availability of screening to vast underserved population in the US and the world.            ",Mobile App for Diabetic Retinopathy Screening using Cellphone Retinal Camera,8782362,R43EY024848,"['Address', 'Adult', 'Age', 'Agreement', 'Algorithms', 'Architecture', 'Area', 'Back', 'Biomedical Engineering', 'Blindness', 'Chairperson', 'Color', 'Computer Vision Systems', 'Computer software', 'Descriptor', 'Detection', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Elements', 'Ensure', 'Equipment', 'Eye', 'Foundations', 'Friends', 'Fundus', 'Goals', 'Gold', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Leadership', 'Lesion', 'Machine Learning', 'Marketing', 'Measures', 'Monitor', 'Nurses', 'Ophthalmology', 'Optics', 'Outcome', 'Output', 'Patients', 'Pattern Recognition', 'Phase', 'Population', 'Process', 'Public Health', 'ROC Curve', 'Recommendation', 'Research', 'Resolution', 'Retinal', 'Retinal Diseases', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Solid', 'Specialist', 'Spouses', 'Staging', 'Surveys', 'System', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Washington', 'Work', 'base', 'clinical care', 'cloud based', 'cluster computing', 'commercialization', 'computerized', 'cost', 'design', 'diabetic', 'diabetic patient', 'experience', 'glucose monitor', 'image processing', 'improved', 'interest', 'longitudinal analysis', 'member', 'mobile application', 'novel', 'point of care', 'prevent', 'professor', 'prototype', 'public health relevance', 'research and development', 'screening', 'statistics', 'success', 'tool']",NEI,"EYENUK, INC.",R43,2014,217002,-0.003298599608381593
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8664845,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,214609,0.03662215286454506
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.          Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8657936,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2014,350219,-0.03695537992623735
"Segmentation and volumetric quantification of thalamic nuclei for assessing MS     DESCRIPTION (provided by applicant): The thalamus plays a key role in integrating sensory information for further processing in the basal ganglia and cortex. In multiple sclerosis (MS), long thought to be primarily a white matter disease, it has recently been shown that cognitive decline is more strongly related to thalamic volume than to white matter magnetic resonance image (MRI) lesion load. Since the thalamus is made up of nuclei having specific physical connections within the brain, it may be possible to relate physical changes in thalamic nuclei caused by MS to specific cognitive, behavioral, or disease subtype differences. This grant proposes to develop an automated method and associated software tool to carry out thalamic nuclei parcellation using MRI. Specifically, it is proposed to: 1) optimize the computation of thalamic features from anatomical and diffusion MRI; 2) develop an integrated, multi-nuclear thalamus segmentation algorithm; 3) optimize the algorithm parameters using manual delineations; and 4) carry out a pilot study using an existing MRI database comprising 99 normal controls and 226 MS patients. The work builds on previous methods that exploit topology and connectivity in order to improve segmentation robustness. The primary innovation is to provide a coordinated multi-object approach that integrates intensity information from T1-weighted MRI with orientation information and connectivity information obtained from diffusion MRI. Primary diffusion directions will be mapped to a five- dimensional space in order to cluster nuclei by diffusion orientation and use this information in the parcellation algorithm. A machine learning approach applied to manual delineations will be used to learn boundary-specific properties that will be used to carry out a joint parcellation approach. The algorithm will be designed for conventional three tesla clinical MRI and will be validated using high-resolution, high signal-to-noise ratio seven tesla MRI on 15 subjects scanned contemporaneously with their three tesla scans. The pilot study will use 822 scans of 305 participants, and will examine longitudinal stability of the algorithm and a cross-sectional univariate statistical analysis relatng thalamic nuclei (or nuclear groups) volumes to various clinical measures including disease subtype, disease duration, visual acuity, and two standard MS composite disability scores. An exploratory principal component analysis of multiple thalamic nuclear volumes will be carried out to look for patterns of atrophy and their relationships to various clinical measures. The algorithm will be made publicly available as open source code on the NITRC website so that the entire neuroscience community will be able to use the algorithm to study other diseases or modify and extend it for other applications.         PUBLIC HEALTH RELEVANCE: The project will develop software for the automatic segmentation and measurement of thalamic nuclei, which are thought to be affected by multiple sclerosis (MS). With this software applied to clinical magnetic resonance scans, the size of the thalamus and its nuclei will be available as biomarkers to track both the progression of MS and the success of its treatment. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.            ",Segmentation and volumetric quantification of thalamic nuclei for assessing MS,8656167,R21NS082891,"['Address', 'Affect', 'Algorithms', 'Anterior', 'Atrophic', 'Basal Ganglia', 'Behavioral', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Categories', 'Cessation of life', 'Chronic', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Communities', 'Computer software', 'Cues', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Epilepsy', 'Equilibrium', 'Fiber', 'Functional disorder', 'Grant', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Investigation', 'Joints', 'Label', 'Language', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Moods', 'Motor', 'Movement', 'Multiple Sclerosis', 'Neurosciences', 'Noise', 'Nuclear', 'Parkinson Disease', 'Participant', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Pilot Projects', 'Play', 'Population', 'Primary Progressive Multiple Sclerosis', 'Principal Component Analysis', 'Process', 'Property', 'Relapse', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Running', 'Scanning', 'Sensory', 'Signal Transduction', 'Software Tools', 'Solvents', 'Source Code', 'Surface', 'Symptoms', 'Techniques', 'Testing', 'Thalamic Diseases', 'Thalamic structure', 'Tremor', 'Visual Acuity', 'Weight', 'White Matter Disease', 'Work', 'Writing', 'base', 'cohort', 'design', 'disability', 'disorder subtype', 'experience', 'falls', 'gray matter', 'illness length', 'improved', 'innovation', 'neuroimaging', 'novel', 'open source', 'programs', 'public health relevance', 'software development', 'success', 'web site', 'white matter']",NINDS,JOHNS HOPKINS UNIVERSITY,R21,2014,228293,0.0013935574013950935
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging     DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient.         PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.            ",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,8674683,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Individual', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging modality', 'improved', 'interest', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2014,782871,0.04630148028577662
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8631080,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2014,250003,0.015456565673140138
"HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/ This proposal describes enhancements to Viocare’s Mobile Food Intake Visual and Voice Recognizer (FIVR)  System, a novel combination of innovative technologies including computer vision and speech recognition to  measure dietary intake using a mobile phone. FIVR uses a mobile phone’s camera to capture a short video  of foods to be consumed, which is then verbally-annotated on the mobile phone by the user. These video  and audio files are processed through a real-time backend server speech and image recognition engine for  food recognition and portion size measurement. This project will extend FIVR’s capabilities to analyze more  foods, enhance the analysis and reporting tools, expand system support tools, and develop interfaces to a  diverse set of clinical and research systems. A final evaluation of the FIVR system will be conducted at The  Ohio State University to assess the usability and accuracy of food intake tracking with a group of 100 freeliving  subjects, comparing 4 days of FIVR food intake data to 4 days of 24 hour recalls collected using  ASA24 data. The resulting FIVR product will be a unique food intake tracker that combines selfadministration,  automation (vision), and backend coding to collect food intake records to generate a detailed  nutritional analysis. n/a","HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/",8947304,61201400054C,"['Architecture', 'Automation', 'Car Phone', 'Clinical Research', 'Code', 'Collection', 'Computer Vision Systems', 'Computerized Medical Record', 'Data', 'Databases', 'Diet', 'Dietary intake', 'Eating', 'Evaluation', 'Food', 'Health', 'Hour', 'Image', 'Individual', 'Location', 'Measurement', 'Measures', 'Methods', 'Nutritional', 'Ohio', 'Output', 'Patients', 'Performance', 'Procedures', 'Process', 'Records', 'Reporting', 'Research Personnel', 'Speech', 'Support System', 'System', 'Systems Analysis', 'Time', 'Universities', 'Vision', 'Visual', 'Voice', 'innovative technologies', 'mobile application', 'novel', 'speech recognition', 'tool', 'usability']",NCI,"VIOCARE, INC.",N44,2014,1000000,-0.020484948614982904
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus     DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community.         PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.            ",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8761698,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'prognostic', 'public health relevance', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2014,314327,0.05179957234559452
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8652454,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2014,195709,0.010612631721812702
"Development And Applications Of The Open Microscopy Environment (OME) In recent years, we've focused on the OME analysis system and developing robust general image analysis methodology, culminating in our pattern recognition tool called WND-CHRM.  We have validated this pattern-recognition approach to biological image analysis using diverse imaging modalities ranging from fluorescence microscopy to X-rays of human knees.  We have also validated a range of  applications from scoring image-based assays to diagnosis of disease to prediction of future disease risk.  The specific applications of this approach are covered in reports AG000674-10 and AG000685-07.  A major effort recently has been to rewrite the WND-CHARM code-base to make it more modular, better organized, easier to use, and accessible with the Python scripting language.  A recent release of WND-CHARM 1.50 is available from our code repository (https://code.google.com/p/wnd-charm/), with significant speed improvements as well as several bug fixes.  Most recently, a significant effort was made to integrate WND-CHARM with OMERO, resulting in a developer preview release of the integrated project in August 2014.  Additionally, the Bisque development team at UC-Santa Barbara in BS Manjunath's group has been able to use our revamped code for image feature calculation in their own open-source software project. Efforts are to ongoing to finish reorganizing the WND-CHARM codebase.  Whole-image analysis has proven very useful, but it is not always possible to compare whole images to each other.  Examples of relatively homogenous images are those of cultured cells, or tissues like muscle, liver, and certain types of tumors.  Our work on human knee X-Rays (see AG000685-07) was the first application where a certain degree of pre-processing was necessary to align images of different subjects to compare them to each other.  In this case, we simply found the center of the knee joint in each image and extracted a fixed radius around this center for all patients.  A much more complicated alignment problem exists in images with complex anatomy.  Possibly the most extreme example of this are stained sections of brain tissue.  A solution to the alignment problem would allow the use of generalized pattern recognition to address morphological differences in an anatomical context.  Spatially-resolved pattern analysis places an extreme burden on the performance of our software.  Instead of an entire image being considered at once, or split into a small number of tiles on a grid, to achieve spatial resolution, each image must be sampled thousands or millions of times.  In order to make this type of application practical, the computational strategy used in the software must be reconsidered.  Previously, all 3,000 low-level image features were calculated for each image sample, even when most of them were later found to be irrelevant to the classification problem because they lacked discrimination power.  The major change in strategy to enable spatially-resolved pattern recognition is to eliminate unnecessary calculations.  This requires an on-demand computing strategy for image features, which is a major architectural goal for the wndchrm software.  Our current release makes use of this strategy, exposing a very simple to use API for specifying the specific features to be computed.  We have have also made the majority of the underlying C++ code accessible from the Python scripting language to make it easier to customize how WND-CHARM is used in new applications. It is now possible to compute on-demand features using the Python interface and perform further processing using mathematical and scientific computing libraries available for Python (numpy, scipy). The Python-related software is publicly available on our public code repository (https://github.com/wnd-charm/wnd-charm).  In 2012, in collaboration with Jason Swedlow (University of Dundee, Scotland), a large international project sponsored by the Wellcome Trust was initiated to develop specific applications of the OME/OMERO system.  Our group's contribution to this project involves providing interfaces between OMERO and WND-CHARM to enable image comparisons in large, diverse image repositories.  The eventual goal is to use pattern recognition to annotate new images added to these collections automatically, based on previously annotated images and a large set of independent classifiers that opeerate autonomously in the background.  The primary design goal of a system like OME/OMERO is to provide scientists with easy ways of organizing and annotating their image collections.  The organizational structure of the images and their grouping by their annotations can also serve as the primary inputs for training pattern-recognition classifiers.  Because classifiers require little or no additional input from the user, the natural convergence of these two technologies represent a powerful new mode for maximizing the utility of large scale scientific and medical image databases.  Currently we have a functioning prototype that interacts with OMERO to read image data and annotations; use these for training a classifier; and return annotations derived from classification back to OMERO.  Substantial work remains to make this integrated system practical.  The current developer-preview release lacks flexibility on the OMERO side to keep track of multiple, potentially conflicting classifications for images, as well as maintain a flexible store of image feature sets.  Additionally, both the OMERO and the Python-WND-CHARM software packages need better support for sub-image regions (ROIs) and systematic image tiling schemes.  Despite these limitations, the released software is capable of training a classifier and using it to classify previously unseen images. n/a",Development And Applications Of The Open Microscopy Environment (OME),8931562,ZIAAG000671,"['Address', 'Algorithms', 'Anatomy', 'Back', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Classification', 'Code', 'Collaborations', 'Collection', 'Complex', 'Computer software', 'Computers', 'Conflict (Psychology)', 'Cultured Cells', 'Data', 'Databases', 'Development', 'Discrimination', 'Ensure', 'Environment', 'Fluorescence Microscopy', 'Future', 'Generic Drugs', 'Goals', 'Grouping', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Informatics', 'International', 'Knee', 'Knee joint', 'Language', 'Libraries', 'Liver', 'Machine Learning', 'Manuals', 'Mathematical Computing', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Microscopy', 'Modality', 'Modeling', 'Muscle', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Process', 'Pythons', 'Radial', 'Reading', 'Reporting', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scheme', 'Scientist', 'Scotland', 'Semantics', 'Side', 'Solutions', 'Specific qualifier value', 'Speed', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Technology', 'Time', 'Tissues', 'Training', 'Trust', 'Universities', 'Visual', 'Work', 'age related', 'base', 'brain tissue', 'data modeling', 'design', 'detector', 'digital', 'disease diagnosis', 'disorder risk', 'flexibility', 'imaging informatics', 'imaging modality', 'medical specialties', 'open source', 'organizational structure', 'practical application', 'programs', 'prototype', 'repository', 'scientific computing', 'software development', 'tool', 'tumor']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2014,331245,0.05453313129933712
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8724992,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2014,402534,-0.006168876280915534
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, an image includes not only biomedical images, but also illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. The project objectives may be formulated as seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. The approaches to meeting these objectives use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers a richer search.   Taking the retrieval of biomedical literature a step further, within the first objective our goal is to find information relevant to a patient's case from the literature and then link it to the patients health record. The case is first represented in structured form using both text and image features, and then literature and EHR databases are searched for similar cases.  A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval objectives are achieved in the following ways: (i) using image analysis; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. Additional steps include describing an image with visual features, automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.), and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed OpenI (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. OpenI is a novel system that enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 733,000 open access articles and nearly 2.3 million illustrations from the biomedical literature hosted at the National Library of Medicine's PubMed Central repository and over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publishers Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to the problem of searching for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using the (clinical) image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. OpenI indexes all the text and illustrations in medical articles by features, both textual and image-based. OpenI also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and deidentified patient records. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first production-quality system of its kind in the biomedical domain, OpenI has enabled medical professionals and the public access to visual information from biomedical articles that are highly relevant to their query, as well as the take away messages of the articles. The quality of the information delivered by OpenI has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system placed first in 2013 image retrieval evaluation that attracted participants from academia, industry and clinical settings. For the past year the site has grown to attract over 41,000 unique visitors (including bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. n/a",Integrating image and text information for biomedical information retrieval,8943231,ZIALM010001,"['Academia', 'Chest', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'Hybrids', 'Image', 'Image Analysis', 'Indiana', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Medical', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Physicians', 'Process', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Visual', 'Work', 'abstracting', 'base', 'bioimaging', 'cluster computing', 'digital', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'meetings', 'novel', 'patient oriented', 'phrases', 'repository', 'text searching', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2014,572530,-0.012595644767501997
"Statistical methods for large and complex databases of ultra-high-dimensional     DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences.         PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.                ",Statistical methods for large and complex databases of ultra-high-dimensional,8738735,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Population Study', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Solutions', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'public health relevance', 'skills', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2014,343683,0.008295021665244493
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8601692,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,623127,0.01374142401715393
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography  Project Summary/Abstract  Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induced stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quan- titative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational im- age analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentiallly between rest and stress - that will identify my- ocardial tissue at-risk after dobutamine-induced stress. This work will involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to hu- mans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.            ",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8614454,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Frequencies', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Radio', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'novel', 'novel strategies', 'public health relevance', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2014,819740,0.009118818808243051
"Quantitative Image Analysis Techniques for Optic Nerve Disease  PROJECT SUMMARY/ABSTRACT  Disorders of the optic nerve (ON) account for a significant percentage of the 20 most impactful ophthalmological conditions. Collectively, diseases of the ON are the number one cause of irreversible blindness worldwide, and present serious public health concerns in the U.S. Consider, for example, that glaucoma impacts more than three million Ameri- cans and costs the U.S. economy almost $3 billion per year. Optic neuritis (i.e., inflammatory demyelination of the ON) is the initial symptom in ~25% of all multiple sclerosis (MS) cases (which impacts over 400 thousand Americans and intro- duces societal health care costs of nearly $30 billion per year). Nearly two thirds of MS patients will experience episodes of optic neuritis in their lifetimes, and 40-60% of patients have visual defects localized to the ON. These disorders irre- versibly damage the ON. Even so, damage to axons in the ON is progressive, defined by a window of opportunity for treatment between loss of function and actual degeneration. The potential for recovery exists because there are treatments that can help prevent progression if administered during this window of opportunity. Yet, we do not have effective means to assess who is in the window and who will benefit from treatment.  We propose to translate computational imaging methods from the neuroimaging community to provide ro- bust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. These efforts will improve prognostic accuracy, lead to better understanding of patient responses, and enhance targeted interven- tions. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not.  The overall goal of this research is to provide a foundation for image analysis of the ON and its relationships with pathological disorders. We will build upon recent advances in robust medical image computing to segment the ON in clinical CT and MRI acquisitions, develop registration procedures to establish intra- and inter-subject correspondence, and bring together information from the multi-modal battery of imaging studies that are typically used in clinical care (aim 1). With these new methods, we will address the exploratory hypothesis that quantitative use of clinical imaging data can increase prognostic accuracy (aim 2). We note that aim 2 is particularly exploratory and in line with the high- risk/high-reward aspect of this mechanism; many studies have shown that baseline imaging does not conclusively pre- dict long term outcome or treatment response. We hypothesize that this may be because early findings are related to edema and inflammation rather than cellular damage per se. Once this exploratory phase is complete, we will pursue promising prognostic biomarkers using more detailed condition staging criteria and including more than two longitudinal time points in the analysis. Ultimately, these efforts will improve assessment ON disease and, in turn, patient care. PUBLIC HEALTH RELEVANCE:  We propose to translate medical imaging computing procedures from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not more effectively than traditional pre-interventional measures.                ",Quantitative Image Analysis Techniques for Optic Nerve Disease,8620598,R21EY024036,"['Accounting', 'Acute', 'Address', 'Adrenal Cortex Hormones', 'Affect', 'Aftercare', 'Age', 'Algorithms', 'American', 'Area', 'Axon', 'Biological Markers', 'Blindness', 'Brain', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Communities', 'Data', 'Defect', 'Demyelinations', 'Diagnostic', 'Disease', 'Edema', 'Eye', 'Foundations', 'Gap Junctions', 'Glaucoma', 'Goals', 'Health Care Costs', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Inflammatory', 'Interferons', 'Intervention', 'Intracranial Hypertension', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Modality', 'Multiple Sclerosis', 'Myelin', 'Nerve Tissue', 'Neurologic', 'Nutritional', 'Operative Surgical Procedures', 'Optic Disk', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Neuritis', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Prognostic Marker', 'Property', 'Protective Agents', 'Public Health', 'Publishing', 'Recovery', 'Recurrence', 'Relapse', 'Research', 'Resource Sharing', 'Resources', 'Scanning', 'Sclerosis', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Swelling', 'Symptoms', 'Tars', 'Techniques', 'Thyroid Diseases', 'Time', 'Training', 'Translating', 'Treatment outcome', 'Tweens', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical care', 'clinical practice', 'computerized tools', 'cost', 'direct application', 'experience', 'high reward', 'high risk', 'image processing', 'imaging modality', 'improved', 'innovation', 'loss of function', 'nerve decompression', 'neuroimaging', 'optic nerve disorder', 'outcome forecast', 'pressure', 'prevent', 'prognostic', 'public health relevance', 'response', 'standard of care', 'success', 'thyroid associated ophthalmopathies', 'tool', 'treatment response', 'vector']",NEI,VANDERBILT UNIVERSITY,R21,2014,225089,0.006084824843594695
"Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters    DESCRIPTION (provided by applicant): Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance to detect PCa; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project is highly significant because it addresses a major health problem in the United States and other developed countries. The project will overcome the current inability of established clinical-imaging method to image PCa reliably by combining the capabilities of advanced ultrasound (US) and magnetic-resonance (MR) techniques in a clinically effective manner. The proposed approach will exploit the sensitivity of US to mechanical properties of tissue on a microscopic scale with the sensitivity of MR to chemical constituents of tissue and its ability to sense blood distribution. Each of these modalities senses different and independent properties of tissue and has shown encouraging potential for improved imaging of PCa when used alone; combining parameters derived from each modality can provide far superior sensitivity and specificity for PCa. We will combine US and MR parameters using advanced classifiers such as artificial neural networks and support-vector machines. These classifiers already have produced ROC-curve areas of 0.91 for advanced US methods, and the MR methods have demonstrated equivalent ROC-curve areas in many studies. We will embody the combined capabilities in specifications for a prototype imaging system that can generate prostate tissue-typing images (TTIs) in real-time for targeting biopsies or planning treatment in the operating room or in an off-line setting. The latest Logiq E9 instrument currently being produced by GE already has a capability for fusing previously obtained MR images with US images in real time, which provides an existing framework for combining US and MR parameters and generating real-time TTIs. Successfully generating reliable prostate TTIs based on combined US and MR parameters will represent a quantum advance in PCa management by enabling significant improvements in the diagnosis and treatment of PCa.        Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.         ",Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters,8677765,R01CA140772,"['Ablation', 'Achievement', 'Acoustics', 'Address', 'Adverse effects', 'Area', 'Atlas of Cancer Mortality in the United States', 'Biological Neural Networks', 'Biopsy', 'Biopsy Specimen', 'Bladder', 'Blood', 'Blood Vessels', 'Chemicals', 'Classification', 'Clinical', 'Cryosurgery', 'Data', 'Data Analyses', 'Databases', 'Developed Countries', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Disease regression', 'Drug Formulations', 'Engineering', 'Frequencies', 'Generations', 'Gland', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Israel', 'Lead', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Mechanics', 'Medical center', 'Metabolic', 'Methods', 'Microscopic', 'Modality', 'Monitor', 'Morphologic artifacts', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nerve', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Perfusion', 'Process', 'Property', 'Prostate', 'Prostate Cancer therapy', 'Prostate-Specific Antigen', 'Prostatectomy', 'Quantitative Evaluations', 'ROC Curve', 'Radio', 'Radiosurgery', 'Rectum', 'Research', 'Research Institute', 'Resolution', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Signal Transduction', 'Specimen', 'Spectrum Analysis', 'Staging', 'Structure of base of prostate', 'Surface', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Universities', 'Urethra', 'Ursidae Family', 'base', 'blind', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'computer aided detection', 'computerized', 'cost', 'experience', 'high risk', 'image registration', 'imaging modality', 'improved', 'instrument', 'instrumentation', 'interest', 'lymph nodes', 'novel', 'outcome forecast', 'prototype', 'quantitative ultrasound', 'quantum', 'response', 'standard care', 'tool', 'treatment planning', 'tumor']",NCI,RIVERSIDE RESEARCH INSTITUTE,R01,2014,553498,-0.018564177680512536
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,8761531,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Build-it', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2014,611476,0.03904125267400077
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8737899,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,335356,0.05551060013187785
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8522756,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2013,150000,0.011948472898020647
"Automated retinopathy of prematurity classification using machine learning  Project Summary/Abstract The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH- funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi- disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing. PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.                 ",Automated retinopathy of prematurity classification using machine learning,8445584,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2013,283543,0.019082252210251942
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,1,0.0257248060880638
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,199466,0.0257248060880638
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8402395,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,301051,0.008214299187041777
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8522304,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2013,216041,0.03663359618523319
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of available MR techniques and image contrast mechanisms that can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.         One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While our application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around development of support vector machine analysis of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hypersurface.      We are currently developing discriminant functions based on three metrics in both one variable and two variables.    These permit the translation of means and standard deviations to sensitivity and specificity of derived statistical tests. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,8736644,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Goals', 'Hydration status', 'Imaging Techniques', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metric', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Probability', 'Process', 'Relative (related person)', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Testing', 'Tissues', 'Training', 'Translations', 'Validation', 'Weight', 'Work', 'articular cartilage', 'base', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2013,571335,-0.02176123156831503
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.03935701524700623
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8461069,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,425454,-0.004293519968457697
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8477880,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2013,339750,0.0035069763880461757
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.          Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8494421,R01CA166816,"['Adoption', 'American Cancer Society', 'Belief', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2013,339387,-0.03695537992623735
"Automatic 3D Quantification of Synapse Distribution in Complex Dendritic Arbor     DESCRIPTION (provided by applicant): The subcellular distribution of synapses is critical for the assembly, function, and plasticity of the nervous system and plays a role in its disorders. Underlying molecular mechanisms, however, remain largely unknown. While advanced multidimensional images, in conjunction with single-cell genetic techniques, have afforded an unprecedented opportunity to understand synapse development at a new level, there is a knowledge gap in our capacity to effectively quantify subcellular synapses from large quantities of three-dimensional images. This is a significant problem and has hampered large-scale studies of the molecular mechanisms of synapse development, especially in neurons with complex arbor-such as Purkinje cells in mammals and lobula plate tangential cells (LPTC) in Drosophila-where existing approaches do not yield complete or robust synapse quantification for the entire dendritic tree and do not scale to efficient genetic screening. The objective of thi project is to bridge this gap by providing tools for quantitative investigation of subcellular synapse distribution and its molecular mechanisms using three-dimensional microscopy images. Specifically, our highly cross- disciplinary team will pursue two aims: (1) Develop automatic algorithms to analyze and quantify synapse distribution in the entire dendritic tree of neurons with complex arbor. Holistic and objective description of synapse density will enable automatic detection of mutant patterns. (2) Develop automatic algorithms to analyze and quantify synapse distribution in different parts of the entire dendritic tree of neurons with complex arbor. Efficient quantification at distinct subcellular locations will assist discovery of novel regulators for different subcellular parts. As a test case, we will use synapse distribution n Drosophila LPTC neurons, which are amenable to both genome-wide genetic screens and genetic manipulations with single-neuron resolution. We will develop reliable methods to characterize the density of inhibitory GABAergic and excitatory cholinergic synapses from three-dimensional fluorescence confocal images. Our algorithms will lead to the next level of mechanistic understanding that controls the subcellular distribution of inhibitory and excitatory synapses, and enable a wide range of quantitative analyses for other types of neurons with similar complexity. Powerful multichannel co-analysis and machine learning approaches will be used to improve synapse detection and subcellular compartment extraction for overcoming challenges in 3D confocal image, including staining artifacts and anisotropic resolution. Algorithms will be developed using a model-guided methodology that emphasizes efficiency for large volume 3D images during genetic screening. Pattern-recognition methods will be used to speed up proofreading of the synapse quantification results. A novel ordering strategy will be adapted for neurons of complex dendritic arbor to quantify subcellular synapses in a functionally meaningful way. The project will produce a set of open-source, extensible tools for automatic synapse quantification and proofreading, with friendly graphical-user interfaces, to serve the neuroscience community.         PUBLIC HEALTH RELEVANCE: The underlying molecular mechanisms for the subcellular distribution of synapses remain largely unknown, which hinders the discovery of novel therapies for many neurological disorders. By developing new, efficient automatic algorithms and open-source tools for quantifying synapses in neurons, this research intends to advance the capacity to effectively analyze large quantities of three-dimensional neuronal images, especially those of complex dendritic arbor. The work will impact public health by enabling a better understanding of disease mechanisms, which is the critical first step toward new treatments, and supports NIH's goal to advance understanding of fundamental biology to uncover the causes of specific diseases.            ",Automatic 3D Quantification of Synapse Distribution in Complex Dendritic Arbor,8574710,R15MH099569,"['Academic Research Enhancement Awards', 'Algorithms', 'Area', 'Biology', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Data', 'Dendrites', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Excitatory Synapse', 'Fluorescence', 'Generations', 'Genetic', 'Genetic Screening', 'Genetic Techniques', 'Goals', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'Inhibitory Synapse', 'Investigation', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Mammals', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Play', 'Public Health', 'Purkinje Cells', 'Pyramidal Cells', 'Research', 'Resolution', 'Role', 'Speed', 'Staging', 'Staining method', 'Stains', 'Surface', 'Synapses', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Trees', 'Variant', 'Work', 'base', 'cholinergic synapse', 'density', 'falls', 'genetic manipulation', 'genome-wide', 'graduate student', 'graphical user interface', 'high throughput technology', 'improved', 'in vivo', 'innovation', 'interdisciplinary approach', 'mutant', 'nervous system disorder', 'novel', 'open source', 'public health relevance', 'tool', 'undergraduate student', 'user-friendly']",NIMH,NORTHERN ILLINOIS UNIVERSITY,R15,2013,461165,0.0037263374960444825
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8599843,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,224942,0.03662215286454506
"Segmentation and volumetric quantification of thalamic nuclei for assessing MS     DESCRIPTION (provided by applicant): The thalamus plays a key role in integrating sensory information for further processing in the basal ganglia and cortex. In multiple sclerosis (MS), long thought to be primarily a white matter disease, it has recently been shown that cognitive decline is more strongly related to thalamic volume than to white matter magnetic resonance image (MRI) lesion load. Since the thalamus is made up of nuclei having specific physical connections within the brain, it may be possible to relate physical changes in thalamic nuclei caused by MS to specific cognitive, behavioral, or disease subtype differences. This grant proposes to develop an automated method and associated software tool to carry out thalamic nuclei parcellation using MRI. Specifically, it is proposed to: 1) optimize the computation of thalamic features from anatomical and diffusion MRI; 2) develop an integrated, multi-nuclear thalamus segmentation algorithm; 3) optimize the algorithm parameters using manual delineations; and 4) carry out a pilot study using an existing MRI database comprising 99 normal controls and 226 MS patients. The work builds on previous methods that exploit topology and connectivity in order to improve segmentation robustness. The primary innovation is to provide a coordinated multi-object approach that integrates intensity information from T1-weighted MRI with orientation information and connectivity information obtained from diffusion MRI. Primary diffusion directions will be mapped to a five- dimensional space in order to cluster nuclei by diffusion orientation and use this information in the parcellation algorithm. A machine learning approach applied to manual delineations will be used to learn boundary-specific properties that will be used to carry out a joint parcellation approach. The algorithm will be designed for conventional three tesla clinical MRI and will be validated using high-resolution, high signal-to-noise ratio seven tesla MRI on 15 subjects scanned contemporaneously with their three tesla scans. The pilot study will use 822 scans of 305 participants, and will examine longitudinal stability of the algorithm and a cross-sectional univariate statistical analysis relatng thalamic nuclei (or nuclear groups) volumes to various clinical measures including disease subtype, disease duration, visual acuity, and two standard MS composite disability scores. An exploratory principal component analysis of multiple thalamic nuclear volumes will be carried out to look for patterns of atrophy and their relationships to various clinical measures. The algorithm will be made publicly available as open source code on the NITRC website so that the entire neuroscience community will be able to use the algorithm to study other diseases or modify and extend it for other applications.         PUBLIC HEALTH RELEVANCE: The project will develop software for the automatic segmentation and measurement of thalamic nuclei, which are thought to be affected by multiple sclerosis (MS). With this software applied to clinical magnetic resonance scans, the size of the thalamus and its nuclei will be available as biomarkers to track both the progression of MS and the success of its treatment. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.            ",Segmentation and volumetric quantification of thalamic nuclei for assessing MS,8583135,R21NS082891,"['Address', 'Affect', 'Algorithms', 'Anterior', 'Atrophic', 'Basal Ganglia', 'Behavioral', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Categories', 'Cessation of life', 'Chronic', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Communities', 'Computer software', 'Cues', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Epilepsy', 'Equilibrium', 'Fiber', 'Functional disorder', 'Grant', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Investigation', 'Joints', 'Label', 'Language', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Moods', 'Motor', 'Movement', 'Multiple Sclerosis', 'Neurosciences', 'Noise', 'Nuclear', 'Parkinson Disease', 'Participant', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Pilot Projects', 'Play', 'Population', 'Primary Progressive Multiple Sclerosis', 'Principal Component Analysis', 'Process', 'Property', 'Relapse', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Running', 'Scanning', 'Sensory', 'Signal Transduction', 'Software Tools', 'Solvents', 'Source Code', 'Surface', 'Symptoms', 'Techniques', 'Testing', 'Thalamic Diseases', 'Thalamic structure', 'Tremor', 'Visual Acuity', 'Weight', 'White Matter Disease', 'Work', 'Writing', 'base', 'cohort', 'design', 'disability', 'disorder subtype', 'experience', 'falls', 'gray matter', 'illness length', 'improved', 'innovation', 'neuroimaging', 'novel', 'open source', 'programs', 'public health relevance', 'software development', 'success', 'web site', 'white matter']",NINDS,JOHNS HOPKINS UNIVERSITY,R21,2013,196835,0.0013935574013950935
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8599834,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2013,249999,0.015456565673140138
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,8541012,R01EB012070,"['Agreement', 'Algorithms', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'image processing', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIVERSITY OF HOUSTON,R01,2013,361799,-0.03221075848364982
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8472102,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Computers', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2013,200000,0.010612631721812702
"Development And Applications Of The Open Microscopy Environment (OME) In recent years, we've focused on the OME analysis system and developing robust general image analysis methodology, culminating in our pattern recognition tool called WND-CHRM.  We have validated this pattern-recognition approach to biological image analysis using diverse imaging modalities ranging from fluorescence microscopy to X-rays of human knees.  We have also validated a range of  applications from scoring image-based assays to diagnosis of disease to prediction of future disease risk.  The specific applications of this approach are covered in reports AG000674-09 and AG000685-06.  A major effort in the previous year has been to rewrite the WND-CHRM code-base to make it more modular, better organized, easier to use, and accessible with the Python scripting language.  A recent release of WND-CHRM 1.50 is available from our code repository (https://code.google.com/p/wnd-charm/).  Whole-image analysis has proven very useful, but it is not always possible to compare whole images to each other.  Examples of relatively homogenous images are those of cultured cells, or tissues like muscle, liver, and certain types of tumors.  Our work on human knee X-Rays (see AG000685-06) was the first application where a certain degree of pre-processing was necessary to align images of different subjects to compare them to each other.  In this case, we simply found the center of the knee joint in each image and extracted a fixed radius around this center for all patients.  A much more complicated alignment problem exists in images with complex anatomy.  Possibly the most extreme example of this are stained sections of brain tissue.  A solution to the alignment problem would allow the use of generalized pattern recognition to address morphological differences in an anatomical context.  The general approach to the alignment problem involves an initial training step where comparable anatomy is manually identified in several subjects by generating fiducial marks or regions of interest (ROIs).  These ROIs are used to train a classifier to automatically identify the target tissue by systematically scanning images with overlapping ROIs and generating an anatomical map for each image.  These maps would in turn be used to isolate target tissue and generate new ROIs that can be subsequently analyzed by experiment-specific classifiers as before.  In many cases the identification of ROIs for subsequent analysis can be accomplished with traditional image segmentation techniques.  However, for a great many image problems, including those of interest to our group, contrast is limiting and traditional segmentation is error prone. Analogous to our success with whole-image pattern recognition, the proposed work aims to identify target tissues automatically by manual training of classifiers based on general algorithms, rather than by developing specific segmentation algorithms for each imaging problem.  Spatially-resolved pattern analysis places an extreme burden on the performance of our software.  Instead of an entire image being considered at once, or split into a small number of tiles on a grid, to achieve spatial resolution, each image must be sampled thousands or millions of times.  In order to make this type of application practical, the computational strategy used in the software must be reconsidered.  Previously, all 3,000 low-level image features were calculated for each image sample, even when most of them were later found to be irrelevant to the classification problem because they lacked discrimination power.  The major change in strategy to enable spatially-resolved pattern recognition is to eliminate unnecessary calculations.  This requires an on-demand computing strategy for image features, which is a major architectural goal for the wndchrm software.  Our current release addresses the architectural issues necessary for this strategy, and the overlaying code to make use of this architecture is currently in development.  We have have also made the majority of the underlying C++ code accessible from the Python scripting language to make it easier to customize how WND-CHARM is used in new applications. It is now possible to compute on-demand features using the Python interface and perform further processing using mathematical and scientific computing libraries available for Python (numpy, scipy). The Python-related software is publicly available under the ""pychrm"" branch on our public code repository (http://code.google.com/p/wnd-charm/).  In 2012, in collaboration with Jason Swedlow (University of Dundee, Scotland), a large international project sponsored by the Wellcome Trust was initiated to develop specific applications of the OME/OMERO system.  Our group's contribution to this project involves providing interfaces between OMERO and WND-CHARM to enable image comparisons in large, diverse image repositories.  The eventual goal is to use pattern recognition to annotate new images added to these collections automatically, based on previously annotated images and a large set of independent classifiers that opeerate autonomously in the background.  The primary design goal of a system like OME/OMERO is to provide scientists with easy ways of organizing and annotating their image collections.  The organizational structure of the images and their grouping by their annotations can also serve as the primary inputs for training pattern-recognition classifiers.  Because classifiers require little or no additional input from the user, the natural convergence of these two technologies represent a powerful new mode for maximizing the utility of large scale scientific and medical image databases.  Currently we have a functioning prototype that interacts with OMERO to read image data and annotations; use these for training a classifier; and return annotations derived from classification back to OMERO.  Substantial work remains to make this integrated system practical.  The Python interface needs to be restructured to parallel the restructuring in the underlying implementation of WND-CHARM in the C++ language.  The OMERO system needs to be made more flexible to accommodate the types of annotations possible with WND-CHARM, as well as to store the computationally expensive image features so that they can be reused by different classifiers.  We are working closely with members of Dr. Swedlow's group to merge these two projects into a practical, general-use system. n/a",Development And Applications Of The Open Microscopy Environment (OME),8736587,ZIAAG000671,"['Address', 'Algorithms', 'Anatomy', 'Architecture', 'Back', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Classification', 'Code', 'Collaborations', 'Collection', 'Complex', 'Computer software', 'Computers', 'Cultured Cells', 'Data', 'Databases', 'Development', 'Discrimination', 'Ensure', 'Environment', 'Fluorescence Microscopy', 'Future', 'Generic Drugs', 'Goals', 'Grouping', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Informatics', 'International', 'Knee', 'Knee joint', 'Language', 'Libraries', 'Liver', 'Machine Learning', 'Manuals', 'Maps', 'Mathematical Computing', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Microscopy', 'Modality', 'Modeling', 'Muscle', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Process', 'Pythons', 'Radial', 'Reading', 'Reporting', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scanning', 'Scientist', 'Scotland', 'Semantics', 'Solutions', 'Speed', 'Staining method', 'Stains', 'Step training', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Trust', 'Universities', 'Visual', 'Work', 'age related', 'base', 'brain tissue', 'data modeling', 'design', 'detector', 'digital', 'disease diagnosis', 'disorder risk', 'flexibility', 'imaging Segmentation', 'imaging informatics', 'imaging modality', 'interest', 'medical specialties', 'member', 'open source', 'organizational structure', 'practical application', 'programs', 'prototype', 'repository', 'research study', 'scientific computing', 'software development', 'success', 'tool', 'tumor']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2013,329208,0.03423612709496663
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.            ",In vivo Characterization of Stents using Intravascular OCT Imaging,8529140,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2013,412883,-0.006168876280915534
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, an image includes not only biomedical images, but also illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. The project objectives may be formulated as seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. The approaches to meeting these objectives use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers a richer search.   Taking the retrieval of biomedical literature a step further, within the first objective our goal is to find information relevant to a patients case from the literature and then link it to the patients health record. The case is first represented in structured form using both text and image features, and then literature and EHR databases are searched for similar cases.  A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval objectives are achieved in the following ways: (i) using image analysis; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. Additional steps include describing an image with visual features, automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.), and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed OpenI (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. OpenI is a novel system that enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of approximately 450,000 open access articles and nearly 1.3 million illustrations from the biomedical literature hosted at the National Library of Medicines PubMed Central repository. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publishers Web site. A user may search by text words, as well as by query images. Using this framework we explore alternative approaches to the problem of searching for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using the (clinical) image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. OpenI indexes all the text and illustrations in medical articles by features, both textual and image-based. OpenI also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and deidentified patient records. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first production-quality system of its kind in the biomedical domain, OpenI has enabled medical professionals and the public access to visual information from biomedical articles that are highly relevant to their query, as well as the take away messages of the articles. The quality of the information delivered by OpenI has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system placed first in 2013 image retrieval evaluation that attracted participants from academia, industry and clinical settings. For the past year the site has grown to attract over 20,000 unique visitors daily and is able to support searches of vast multimedia collections. n/a",Integrating image and text information for biomedical information retrieval,8746742,ZIALM010001,"['Academia', 'Chest', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'Hybrids', 'Image', 'Image Analysis', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Medical', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Physicians', 'Process', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Visual', 'Work', 'abstracting', 'base', 'bioimaging', 'cluster computing', 'digital', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'meetings', 'novel', 'patient oriented', 'phrases', 'repository', 'text searching', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2013,659631,-0.01478321968546842
"Statistical methods for large and complex databases of ultra-high-dimensional  Abstract Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.                ",Statistical methods for large and complex databases of ultra-high-dimensional,8614974,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Population Study', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Solutions', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'public health relevance', 'skills', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2013,373406,0.00779525265031234
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8420220,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,682340,0.01374142401715393
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.        The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8383103,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2013,222916,-0.004878205061622173
"Real-Time MRI Motion Correction System    DESCRIPTION (provided by applicant):  MOTIVATION - Motion remains one of the most frequent contributors to image artifacts in MR studies.  The motion susceptibility of MRI is well-known and has spawned a number of elegant navigation techniques.  These methods, however, are tailored to specific MR acquisitions that require modified k-space trajectories or the acquisition of additional MR data, and most are unable to correct certain types of motion, for example, through-plane motion.  Moreover, motion correction has been focused on specific families of sequences, but no generally applicable approach currently exists.  Certain patient populations, such as pediatric or geriatric patients, are more likely to move than others.  In pediatric imaging, anesthesia is used to control motion, adding substantially to exam costs and patient risks.  A sequence-independent, autonomous and prospective motion correction system could greatly improve image quality for a wide spectrum of MR examinations.  For pediatric imaging, in particular, we anticipate reduced reliance on anesthesia to control patient motion.  AIMS - We will be focusing on three independent specific aims (carried out in parallel and completed within 4 years), with corresponding subaims that we believe are important for establishing the technical/scientific merit and to demonstrate the feasibility of the proposed R&D efforts for our real-time adaptive motion correction approach.  Specifically, these aims are:  (1) to develop and evaluate a coil-mounted MR-compatible tracking device for routine clinical use; (2) to integrate pose tracking into real-time MRI; and (3) to validate our real-time motion correction system in volunteers and patients.  METHODS -In Aim 1 we will improve the methods for computer-vision-based pose estimation inside an MR scanner and build an MR-compatible coil-mounted pose tracker that can be used in clinical routine examinations.  In Aim 2 we will focus on reducing the latency between pose changes happening and the MR scanner reacting to these pose changes, and on building a software library for the MR pulse sequence development that allows one to implement real-time motion correction into all MR pulse sequences.  In Aim 3 we will perform a thorough evaluation of our system on 60 volunteers (30 adults and 30 children) and 120 patients (80 adults and 40 children).  SIGNIFICANCE - The impact of our technology has several facets.  First, it will improve patient care by reducing the number of MR images with compromised quality because of motion artifacts.  Especially because of the increasing reliance on MR Images as a primary means of diagnosis, this will reduce the number of misdiagnoses.  Secondly, this technology will help to lower the high national spending on imaging by dramatically improving the efficiency of MRI scanners.  Finally, it will improve patient comfort by reducing the need for repeat sequences, as well as reduce the necessity of sedation aimed at keeping the patient still.  Overall, this technology will have a significant impact on MRI both in clinical practice and basic science research.       PUBLIC HEALTH RELEVANCE:  Synopsis Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually.  This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time.  The project leverages on previous work from an R21 project in which a prototype system was successfully built.  Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.            ",Real-Time MRI Motion Correction System,8533777,R01EB011654,"['Address', 'Adopted', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Articular Range of Motion', 'Base Sequence', 'Basic Science', 'Brain', 'Callback', 'Child', 'Childhood', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer software', 'Data', 'Detection', 'Development', 'Device Safety', 'Devices', 'Diagnosis', 'Disease', 'Economic Burden', 'Educational workshop', 'Elderly', 'Electronics', 'Enrollment', 'Environment', 'Evaluation', 'Family', 'Financial compensation', 'Goals', 'Grant', 'Head', 'Healthcare Systems', 'High Prevalence', 'Image', 'Individual', 'Lead', 'Libraries', 'Magnetic Resonance Imaging', 'Methods', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Noise', 'Optics', 'Patient Care', 'Patients', 'Physiologic pulse', 'Positioning Attribute', 'Predisposition', 'Procedures', 'Protocols documentation', 'Reliance', 'Research', 'Research Project Grants', 'Resolution', 'Risk', 'Safety', 'Scanning', 'Scheme', 'Sedation procedure', 'Signal Transduction', 'Societies', 'Solutions', 'Speed', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Update', 'Vision', 'Well in self', 'Work', 'aging population', 'analog', 'base', 'body system', 'clinical practice', 'comparative', 'cost', 'data sharing', 'design', 'detector', 'digital', 'human subject', 'image processing', 'improved', 'innovation', 'lens', 'meetings', 'novel marker', 'optical imaging', 'patient population', 'peer', 'programs', 'prospective', 'prototype', 'public health relevance', 'research and development', 'research clinical testing', 'research study', 'tool', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2013,568465,0.024167373965159993
"Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters    DESCRIPTION (provided by applicant): Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance to detect PCa; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project is highly significant because it addresses a major health problem in the United States and other developed countries. The project will overcome the current inability of established clinical-imaging method to image PCa reliably by combining the capabilities of advanced ultrasound (US) and magnetic-resonance (MR) techniques in a clinically effective manner. The proposed approach will exploit the sensitivity of US to mechanical properties of tissue on a microscopic scale with the sensitivity of MR to chemical constituents of tissue and its ability to sense blood distribution. Each of these modalities senses different and independent properties of tissue and has shown encouraging potential for improved imaging of PCa when used alone; combining parameters derived from each modality can provide far superior sensitivity and specificity for PCa. We will combine US and MR parameters using advanced classifiers such as artificial neural networks and support-vector machines. These classifiers already have produced ROC-curve areas of 0.91 for advanced US methods, and the MR methods have demonstrated equivalent ROC-curve areas in many studies. We will embody the combined capabilities in specifications for a prototype imaging system that can generate prostate tissue-typing images (TTIs) in real-time for targeting biopsies or planning treatment in the operating room or in an off-line setting. The latest Logiq E9 instrument currently being produced by GE already has a capability for fusing previously obtained MR images with US images in real time, which provides an existing framework for combining US and MR parameters and generating real-time TTIs. Successfully generating reliable prostate TTIs based on combined US and MR parameters will represent a quantum advance in PCa management by enabling significant improvements in the diagnosis and treatment of PCa.       PUBLIC HEALTH RELEVANCE: Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.         ",Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters,8478061,R01CA140772,"['Ablation', 'Achievement', 'Acoustics', 'Address', 'Adverse effects', 'Area', 'Atlas of Cancer Mortality in the United States', 'Biological Neural Networks', 'Biopsy', 'Biopsy Specimen', 'Bladder', 'Blood', 'Blood Vessels', 'Chemicals', 'Classification', 'Clinical', 'Cryosurgery', 'Data', 'Data Analyses', 'Databases', 'Developed Countries', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Disease regression', 'Drug Formulations', 'Engineering', 'Frequencies', 'Generations', 'Gland', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Israel', 'Lead', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Mechanics', 'Medical center', 'Metabolic', 'Methods', 'Microscopic', 'Modality', 'Monitor', 'Morphologic artifacts', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nerve', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Perfusion', 'Process', 'Property', 'Prostate', 'Prostate Cancer therapy', 'Prostate-Specific Antigen', 'Prostatectomy', 'Quantitative Evaluations', 'ROC Curve', 'Radio', 'Radiosurgery', 'Rectum', 'Research', 'Research Institute', 'Resolution', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Signal Transduction', 'Specimen', 'Spectrum Analysis', 'Staging', 'Structure of base of prostate', 'Surface', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Universities', 'Urethra', 'Ursidae Family', 'base', 'blind', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'computer aided detection', 'computerized', 'cost', 'experience', 'high risk', 'image registration', 'imaging modality', 'improved', 'instrument', 'instrumentation', 'interest', 'lymph nodes', 'novel', 'outcome forecast', 'prototype', 'quantitative ultrasound', 'quantum', 'response', 'standard care', 'tool', 'treatment planning', 'tumor']",NCI,RIVERSIDE RESEARCH INSTITUTE,R01,2013,525013,-0.018329258945855992
"Spatially Accurate Deformable Image Registration for Thoracic C Applications    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.    Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.      ",Spatially Accurate Deformable Image Registration for Thoracic C Applications,8558551,DP2OD007044,"['4D Imaging', 'Aftercare', 'Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computers', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Malignant neoplasm of lung', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Patients', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Validation', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'imaging modality', 'lung injury', 'novel', 'public health relevance', 'pulmonary function', 'small airways disease', 'treatment planning']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2013,201518,0.003000115994780725
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data.  PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.          ",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,8520329,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Health', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'NMR Spectroscopy', 'Negative Staining', 'Neighborhoods', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2013,301072,-0.02296349915593097
"Multimodal image registration by proxy image synthesis No abstract available PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8614480,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,343798,0.04108053235408323
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, an image includes not only biomedical images, but also illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. The project objectives may be formulated as seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. The approaches to meeting these objectives use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers a richer search.   Taking the retrieval of biomedical literature a step further, within the first objective our goal is to find information relevant to a patients case from the literature and then link it to the patients health record. The case is first represented in structured form using both text and image features, and then literature and EHR databases are searched for similar cases.  A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval objectives can be achieved in the following ways: (i) using imageanalysis alone; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. One approach is to compute image similarity, the traditional CBIR task of finding images that are overall visually similar to a query image, using machine learning classifiers (e.g., Support Vector Machine) and fusion of class probabilities. These classifiers are trained on a variety of image features such as wavelets, edge histograms and those recommended by the MPEG-7 committee. Additional steps include describing an image by automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.) and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed OpenI (Open ""eye""), a hybrid system combining text-based searching with an image similarity engine. Using this framework we explore alternative approaches to the problem of searching for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using the (clinical) image of a given patient, and then linking the image to relevant information found by using visual and text features;  (iii) merging the results of independent text and image searches; and (iv) starting a multimodal search that combines text and image features.  The project development is demonstrated through the OpenI (pronounced open eye) system (available at http://openi.nlm.nih.gov). OpenI is a novel system that enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from a collection of 250,000 open access articles and nearly 1 million illustrations from the biomedical literature hosted at the National Library of Medicines PubMed Centralrepository. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publishers Web site. A user may search by text words, as well as by query images. OpenI indexes all the text and illustrations in medical articles by features, both textual and image-based. To compute these features efficiently, the system is built on a high performance distributed computing platform using virtual machine and private cloud infrastructure.  As the first production-quality system of its kind in the biomedical domain, OpenI has enabled medical professionals and the public access to visual information from biomedical articles that are highly relevant to their query, as well as the take away messages of the articles. The quality of the information delivered by OpenI has been evaluated in international competitions, in which the system consistently ranks among the best. For example, the system demonstrated the best retrieval results and placed third in image type classification in the 2012 medical image retrieval evaluation that attracted participants from academia, industry and clinical settings. After just a few months of its public release in February the site is now visited by 3,000 unique visitors daily and is able to support searches of vast multimedia collections. n/a",Integrating image and text information for biomedical information retrieval,8558113,ZIALM010001,"['Academia', 'Classification', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Development', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'Hybrids', 'Image', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'Machine Learning', 'MeSH Thesaurus', 'Medical', 'Medical Imaging', 'MedlinePlus', 'Metadata', 'Methods', 'Modality', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Physicians', 'Probability', 'Process', 'Production', 'PubMed', 'Research Infrastructure', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Training', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Visit', 'Visual', 'Work', 'abstracting', 'base', 'bioimaging', 'cluster computing', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'meetings', 'monomethoxypolyethylene glycol', 'novel', 'patient oriented', 'phrases', 'text searching', 'tool', 'virtual', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2012,677001,-0.008062448825144791
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.        PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.              Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8266132,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2012,199915,0.023864050450331003
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8323502,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2012,234509,0.03663359618523319
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Public Health Relevance/Narrative Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8208036,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,311786,0.015283684527455325
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of available MR techniques and image contrast mechanisms that can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.         One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While our application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around development of support vector machine analysis of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hypersurface. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,8552506,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Goals', 'Hydration status', 'Imaging Techniques', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metric', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Probability', 'Process', 'Relative (related person)', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Tissues', 'Training', 'Validation', 'Weight', 'Work', 'articular cartilage', 'base', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2012,650977,-0.02280465319400394
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.0394432229513386
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8259135,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'public health relevance', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,445075,-0.004293519968457697
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.        PUBLIC HEALTH RELEVANCE: Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                  Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8276007,R01CA166816,"['Adoption', 'American Cancer Society', 'Belief', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2012,361569,-0.04218427716613109
"Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging DESCRIPTION (provided by applicant): Dementia represents a major public health problem which will grow significantly with the aging of our society. Recently, multiple pieces of converging clinical and neuropathological data indicate that dementia is typically a multi-factorial process. This evolution in thinking about the biology of dementia comes at a time when the most significant recent development in dementia imaging has been the introduction of amyloid plaque labeling compounds; the most widely studied at this point is Pittsburgh Compound - B (PiB). A central principle underlying this renewal is this. Amyloid imaging is unquestionably a major advance. However, since the biology of dementia is more complex than brain amyloidosis alone, imaging of dementia is more complex than brain amyloid imaging alone. Our primary goal in this renewal is to use various imaging modalities to identify different mechanisms underlying dementia. This is the first resubmission of a competitive renewal of AG11378. We have revised the grant in accordance with each point raised in the critique and we believe this has resulted in a much stronger application. Each of the five aims is cast to answer variations on the questions: What is the contribution of specific imaging-based proxies of pathology to clinical/cognitive decline? When in the course of the disease do these relationships hold true? For whom is this true? Where in the brain are the relevant pathologies expressed? Principle outcome measures will be clinical and psychometric decline over time which we will use as indicators of disease progression. Our predictor variables will include various imaging modalities which will serve as proxies for specific pathologic mechanisms underlying dementia. PiB will serve as a measure of plaque burden and we will use various Magnetic Resonance Imaging (MRI) modalities to assess cerebro- vascular disease, tissue loss, tissue perfusion, diffusion, neuronal integrity, and inflammation. Features that distinguish this renewal from past cycles of AG11378 include a mechanistic focus, multi- modality imaging including multiple MRI modalities as well as PET amyloid imaging, MR imaging now at 3T, inclusion of both amnestic and non-amnestic MCI, and voxel-based analytic methods including an exciting new computational approach which employs a support vector machine algorithm to provide diagnosis in individual subjects. In addition, subjects will now be recruited from a new population-based study of aging and dementia, which differentiates this renewal from past cycles as well as from most dementia imaging studies which recruit from referral practices and thus risk sampling bias. Previous cycles of this grant have contributed significantly to recognition of the utility of imaging in dementia. An active debate is currently underway about revising clinical criteria for AD, specifically whether imaging and fluid biomarker information should be included among the criteria. Results from this renewal grant will inform this debate about multiple time dependent mechanisms leading to dementia that are accessible in living subjects through imaging. PUBLIC HEALTH RELEVANCE: Identifying Mechanisms of Dementia: Role for MRI in the Era of Molecular Imaging (AG11378) Dementia is a leading public health problem now and will have an increasingly serious impact on public health as the number of elderly individuals increase. Dementia has many possible underlying causes and several different causes are at work in most elderly demented subjects. In this grant, we will use modern brain imaging to identify specific mechanisms underlying progression to dementia.",Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging,8292033,R01AG011378,"['6-hydroxybenzothiazole', 'Abbreviations', 'Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease Pathway', 'Amyloid deposition', 'Amyloidosis', 'Anatomy', 'Anisotropy', 'Applications Grants', 'Attenuated', 'Autopsy', 'Base of the Brain', 'Binding', 'Biological Markers', 'Biology', 'Biostatistical Methods', 'Brain', 'Brain Mapping', 'Brain imaging', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Clinical Pathology', 'Cognition', 'Cognitive', 'Complex', 'Correlation Studies', 'Critiques', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Elderly', 'Enrollment', 'Epidemiologic Studies', 'Event', 'Evolution', 'Future', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Inflammation', 'Inositol', 'Label', 'Life', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measures', 'Memory', 'Methods', 'Metric', 'Modality', 'Modeling', 'N-acetylaspartate', 'Neurofibrillary Tangles', 'Neurons', 'Outcome', 'Outcome Measure', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Perfusion', 'Pittsburgh Compound-B', 'Population', 'Positron-Emission Tomography', 'Process', 'Proxy', 'Psychometrics', 'Public Health', 'Recovery', 'Recruitment Activity', 'Relative (related person)', 'Resolution', 'Risk', 'Role', 'Sampling', 'Sampling Biases', 'Scheme', 'Senile Plaques', 'Severity of illness', 'Societies', 'Spin Labels', 'Staging', 'Study Subject', 'Symptoms', 'Synapses', 'Syndrome', 'Text', 'Thinking', 'Time', 'Tissues', 'Variant', 'Vascular Diseases', 'Work', 'amyloid imaging', 'base', 'clinical Diagnosis', 'cohort', 'imaging modality', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular imaging', 'morphometry', 'neuroimaging', 'population based', 'primary outcome', 'tool']",NIA,MAYO CLINIC ROCHESTER,R01,2012,934653,-0.031041979167451425
"OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN This proposal describes plans to enhance Viocare¿s Mobile Food Intake Visual and Voice Recognizer (FIVR) System. FIVR, an active Genes, Environment and Health Initiative (GEI) project, is a novel combination of innovative technologies including computer vision and speech recognition to measure dietary intake using a mobile phone. Version 1 of FIVR uses a mobile phone¿s embedded camera to capture a short video of food to be consumed. The food to be eaten is annotated verbally on the mobile phone by the user. These video and audio files are sent to a backend server for real-time food recognition and portion size measurement through speech recognition and image analysis. This project will develop specifications to extend FIVR¿s capabilities to standardize, store, and analyze more diverse food images, such as 3D photos; to collect other food data; to enhance the analysis tools; and for interfaces to a variety of clinical/research systems. The FIVR Version 2 functional prototype will be developed to use 3D dietary images as input. A final evaluation of the FIVR V2 prototype will be conducted to assess the accuracy and feasibility of the 3D image diet capture with a group of 9 subjects in a controlled feeding study. n/a","OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN",8554263,61201200042C,"['Car Phone', 'Clinical Research', 'Computer Vision Systems', 'Data', 'Diet', 'Dietary intake', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Food', 'Genes', 'Health', 'Image', 'Image Analysis', 'Measurement', 'Measures', 'Phase', 'Reporting', 'Small Business Innovation Research Grant', 'System', 'Three-Dimensional Image', 'Time', 'Visual', 'Voice', 'feeding', 'innovative technologies', 'novel', 'prototype', 'speech recognition', 'tool']",NCI,"VIOCARE, INC.",N43,2012,200000,-0.015374254175315552
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,8323998,R01EB012070,"['Agreement', 'Algorithms', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'image processing', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIVERSITY OF HOUSTON,R01,2012,406394,-0.03221075848364982
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8234040,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2012,424407,0.026770635898351307
"Development And Applications Of The Open Microscopy Environment (OME) In recent years, we've focused on the OME analysis system and developing robust general image analysis methodology, culminating in our pattern recognition tool called WND-CHRM.  We have validated this pattern-recognition approach to biological image analysis using diverse imaging modalities ranging from fluorescence microscopy to X-rays of human knees.  We have also validated a range of  applications from scoring image-based assays to diagnosis of disease to prediction of future disease risk.  The specific applications of this approach are covered in reports AG000674-07 and AG000685-04.  A major effort in the previous year has been to expand the functionality of WND-CHRM into real-time image-comparison assays as well as analysis of anatomically-defined patterns.  A major effort is underway to rewrite the WND-CHRM code-base to make it more modular, better organized, easier to use, and accessible with the Python scripting language.  WND-CHARM is a generalized pattern-recognition algorithm that can be used to analyze any type of image.  Unlike most approaches to image processing in current use, this method relies on training a machine classifier to automatically recognize differences between training image classes (i.e. controls), rather than relying on an a-priori model of what is being imaged.  This approach has been demonstrated to be effective at discerning differences even when they cannot be easily perceived manually.  The output of a trained machine classifier is qualitative: for a given test image, it reports the most similar training class.  In a scientific setting, it is often not sufficient to know what class an image belongs to, but how similar it is to the given training classes.  An example is a quantitative imaging assay where the set of training image-classes comprise a standard curve, and the classifier's task is to arrive at a continuous score by interpolating between the defined classes.  This type of classification can be called an ""ordered-class problem"".  There also exist a set of problems where the classes have no inherent order, and instead of an interpolated continuous score, the desired output is a measure of the similarity between classes.  A familiar visualization of classes that have varying degrees of similarity to each other is a dendrogram for example, a phylogenetic tree representing evolutionary distance.  This type of classification can be called a ""class-similarity problem"".  The current implementation of WND-CHARM addresses both of these quantitative imaging problems automatically.  In addition to reporting the qualitative class assignment, it reports a continuous value if the class names can be interpreted numerically, and it computes pair-wise similarities between all of the classes.  If a dendrogram visualization package is installed on the system (PHYLIP), it automatically generates a dendrogram based on the pair-wise class-distance matrix.  This type of visualization has proven useful as an independent validation for ordered-class problems, since a well-ordered set of classes will produce a linear or elongated dendrogram without major branch-points.  The program that implements the WND-CHRM algorithm (called wndchrm), has been made publicly available on Google Code (http://wnd-charm.googlecode.com/).  A major release of the code (version 1.31) covering the areas discussed above has been made available on the project's site, as well as the Python code that is still under development.  This release represents a first pass at reorganizing the code-base by making it more self-consistent and reliable without major architectural changes.  It also represents a substantial effort in validation, testing and resolution of bugs.  The site provides an interface for reporting bugs and requesting new features, and we have made extensive use of this facility within our own group.  This continues to be visited multiple times per day, and the software source code has been downloaded several hundred times from multiple sites around the world.  Whole-image analysis has proven very useful, but it is not always possible to compare whole images to each other.  Examples of relatively homogenous images are those of cultured cells, or tissues like muscle, liver, and certain types of tumors.  Our work on human knee X-Rays was the first application where a certain degree of pre-processing was necessary to make images of different subjects comparable to each other.  In this case, we simply found the center of the knee joint in each image and extracted a fixed radius around this center for all patients.  A much more complicated alignment problem exists in images with complex anatomy.  Possibly the most extreme example of this are stained sections of brain tissue.  A solution to the alignment problem would allow the use of generalized pattern recognition to address morphological differences in an anatomical context.  For example, what areas of the brain correlate with cognitive decline or age?  What is the degree of overlap between these areas?  Spatially-resolved pattern analysis places an extreme burden on the performance of our software.  Instead of an entire image being considered at once, or split into a small number of tiles on a grid, to achieve spatial resolution, each image must be sampled thousands or millions of times.  In order to make this type of application practical, the computational strategy used in the software must be reconsidered.  Previously, all 3,000 low-level image features were calculated for each image sample, even when most of them were later found to be irrelevant to the classification problem because they lacked discrimination power.  The major change in strategy to enable spatially-resolved pattern recognition is to eliminate unnecessary calculations.  This requires an on-demand computing strategy for image features, which is a major architectural goal for the wndchrm software. Recently, we have wrapped the C++ classes defined by wndchrm to make them accessible from Python.  Python is a scripting language that is seeing increasing use in high-performance computing for manipulating large datasets.  Currently, there is an operational prototype of this software that can compute image features on-demand. The software is publicly available under the ""pychrm"" branch on our public code repository (http://code.google.com/p/wnd-charm/).  Current efforts are underway to parallelize the execution of this code at a deeper level than is currently done in order to take better advantage of modern CPUs with multiple cores.  The majority of our software-development efforts recently have been dedicated to the WND-CHRM analysis tool.  With the addition of quantitative and spatially-resolved pattern analysis, it represents a substantial portion of what is possible with image analysis without a-priori models.  Meanwhile, the OMERO project has matured under the guidance of Jason Swedlow, and is now a good, stable and usable implementation of the image and meta-data management concepts within OME.  OMERO provides interface libraries for Python, which will facilitate its integration with pychrm. In the coming year, we plan a substantial effort of integration of WND-CHRM and OMERO. n/a",Development And Applications Of The Open Microscopy Environment (OME),8552437,ZIAAG000671,"['Address', 'Algorithms', 'Anatomy', 'Area', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Classification', 'Code', 'Cognitive aging', 'Collection', 'Complex', 'Computer software', 'Computers', 'Cultured Cells', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Discrimination', 'Ensure', 'Environment', 'Fluorescence Microscopy', 'Future', 'Generic Drugs', 'Genomics', 'Goals', 'High Performance Computing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging problem', 'Impaired cognition', 'Informatics', 'Knee', 'Knee joint', 'Language', 'Libraries', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Microscopy', 'Mining', 'Modality', 'Modeling', 'Muscle', 'Names', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phylogenetic Analysis', 'Process', 'Pythons', 'Radial', 'Reporting', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Semantics', 'Site', 'Solutions', 'Source Code', 'Speed', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Trees', 'Validation', 'Visit', 'Visual', 'Work', 'age related', 'base', 'brain tissue', 'data management', 'data mining', 'data modeling', 'detector', 'digital', 'disease diagnosis', 'disorder risk', 'flexibility', 'image processing', 'imaging informatics', 'imaging modality', 'medical specialties', 'open source', 'practical application', 'programs', 'prototype', 'repository', 'software development', 'tool', 'tumor']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2012,456779,0.03779755125290995
"Molecular Pathology Research for Cancer Diagnostics and Biomarkers In this project research is conducted to characterize and develop new animal models of human disease and to develop the means to better characterize a model's relevance for human disease, addressing critical barriers to research progress.  Additional aims include the the development of new research technologies for the evaluation and application of disease biomarkers.  Progress was made in developing cancer diagnostics and in research resources useful in developing and characterizing new models of human cancer.  This research project included developing capabilities in molecular diagnostics for cancer models, developing methods for automated morphmetric image analysis of cancer specimens for quantitative pathology, investigating the role of S100 in cancer, developing new methods in mass spectrometry for limited tissue such as biopsies or model animals, and effects of Ras oncogene activation.     Continued advances and applications in developing quality assurance methods for tissue biobanking were also made.  Biorepository supported translational research depends upon high-quality, well-annotated specimens.  Histopathology assessment contributes insight into how representative lesions are for research objectives.  Feasibility of documenting histological proportions of tumor and stroma was studied in an effort to enhance information regarding biorepository tissue heterogeneity. Unique spatial-spectral image analysis algorithms were developed for applying automated pattern recognition morphometric image analysis to quantify histologic tumor and non-tumor tissue areas in biospecimen tissue sections.  Successfully acquired measurements for lymphomas, osteosarcomas and melanomas were extended to include additional progress in developing and validating algorithms for cancers of the blood and vascular tissues, lung, and connective mesenchymal tissues (soft tissue sarcoma).  Quantitative image analysis automation is anticipated to minimize variability associated with routine biorepository pathologic evaluations and enhance biomarker discovery by helping to guide the selection of study-appropriate specimens. Pattern recognition image analysis (PRIA) is artificial intelligence automation technology that has the capacity to significantly impact the work that pathologists do when applied to histopathology.  To what degree computer-assisted diagnostic pattern recognition image analysis agrees with accepted histopathology approaches has not been clearly established.  Digitally scanned histomorphological whole-slide images from two sources served for evaluation of a commercially available pattern recognition image analysis platform, to address diagnostic agreement achievable.  Substantial agreement, lacking significant constant or proportional errors, between pattern recognition image analysis and manual morphometric image segmentation was obtained for pulmonary metastatic cancer areas (Passing/Bablok regression).  Bland-Altman analysis indicated heteroscedastic measurements and tendency toward increasing variance with increasing tumor burden, but no significant trend in mean bias. The average between-methods percent tumor content difference was -0.64. Analysis of between-methods measurement differences relative to the percent tumor magnitude revealed that method disagreement had an impact primarily in the smallest measurements (tumor burden 0.988, indicating high reproducibility for both methods, yet pattern recognition image analysis reproducibility was superior (C.V.: PRIA = 7.4, manual = 17.1). Evaluation of pattern recognition image analysis on morphologically complex teratomas led to diagnostic agreement with pathologist assessments of pluripotency on subsets of teratomas. Accommodation of the diversity of teratoma histologic features frequently resulted in detrimental trade-offs, increasing pattern recognition image analysis error elsewhere in images.  Pattern recognition image analysis error was nonrandom and influenced by variations in histomorphology. File-size limitations encountered while training algorithms and consequences of spectral image processing dominance contributed to diagnostic inaccuracies experienced for some teratomas.  Pattern recognition image analysis appeared better suited for tissues with limited phenotypic diversity. Technical improvements may enhance diagnostic agreement, and consistent pathologist input will benefit further development and application of pattern recognition image analysis.Quantitative image analysis pathology was employed to study chloride intracellular channel (CLIC) 4.  CLIC 4 is a member of a redox-regulated, metamorphic multifunctional protein family, first characterized as intracellular chloride channels. Current knowledge indicates that CLICs participate in signaling, cytoskeleton integrity and differentiation functions of multiple tissues.  Image analysis algorithms were developed and applied to obtain evidence of nuclear localization and quantitation results supporting the indication that CLIC4 suppresses the growth of squamous cancers, that reduced CLIC4 expression and nuclear residence detected in cancer cells is associated with the altered redox state of tumor cells, and the absence of detectable nuclear CLIC4 in cancers contributes to TGF-beta resistance and enhances tumor development.In vivo image analysis provided further means to document enhanced CD8 T cell-mediated therapeutic efficacy using a combination regimen of murine IL-15 administered with an agonistic anti-CD40 Ab (FGK4.5), which led to increased IL-15Ralpha expression on dendritic cells (DCs), as well as other cell types, in a syngeneic established TRAMP-C2 tumor model. IL-15 has potential as an immunotherapeutic agent for cancer treatment because it is a critical factor for the proliferation and activation of NK and CD8(+) T cells.  Anti-CD40-mediated augmented IL-15Ralpha expression was critical in IL-15-associated sustained remissions observed in TRAMP-C2 tumor-bearing mice receiving combination therapy.The significant materials, equipment or methods in this project include use of recombinant DNA technology, in vitro cell culture, DNA sequence analysis, immunodiagnostics, molecular imaging, morphometrics, computer assisted image analysis, optical imaging, mass spectrometry, molecular pathology, and veterinary medical diagnosis. n/a",Molecular Pathology Research for Cancer Diagnostics and Biomarkers,8554087,ZICBC010953,"['Address', 'Agreement', 'Algorithms', 'Animal Model', 'Applied Research', 'Area', 'Artificial Intelligence', 'Automated Pattern Recognition', 'Automation', 'Biological Markers', 'Biological Models', 'Biopsy', 'Blood Vessels', 'CD8B1 gene', 'CLIC4 gene', 'Cancer Diagnostics', 'Cancer Model', 'Cell Culture Techniques', 'Cells', 'Chloride Channels', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Comprehension', 'Computer Assisted', 'Computer-Assisted Image Analysis', 'Cytoskeleton', 'DNA Sequence Analysis', 'Dendritic Cells', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease remission', 'Disseminated Malignant Neoplasm', 'Equipment', 'Evaluation', 'Genetic Engineering', 'Growth', 'Harvest', 'Hematopoietic Neoplasms', 'Heterogeneity', 'Histologic', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Immunological Diagnosis', 'Immunotherapeutic agent', 'In Vitro', 'Interleukin-15', 'Investigation', 'Knowledge', 'Laboratories', 'Lesion', 'Lung', 'Lymphoma', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measurement', 'Mediating', 'Medical', 'Medicine', 'Mesenchymal', 'Methods', 'Microdissection', 'Modality', 'Modeling', 'Molecular', 'Molecular Analysis', 'Mus', 'Nuclear', 'Oncogene Activation', 'Optical Instrument', 'Oxidation-Reduction', 'Pathologic', 'Pathologist', 'Pathology', 'Pattern Recognition', 'Phenotype', 'Protein Family', 'Reagent', 'Regimen', 'Relative (related person)', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resistance', 'Resources', 'Role', 'Scanning', 'Signal Transduction', 'Slide', 'Source', 'Specimen', 'Structure of parenchyma of lung', 'T-Lymphocyte', 'TNFRSF5 gene', 'Techniques', 'Technology', 'Teratoma', 'Tissue Preservation', 'Tissue Procurements', 'Tissues', 'Training', 'Transforming Growth Factor beta', 'Translational Research', 'Treatment Efficacy', 'Tumor Burden', 'Tumor Tissue', 'Ultrasonography', 'Variant', 'Work', 'X-Ray Computed Tomography', 'biobank', 'cancer cell', 'cancer therapy', 'cell type', 'data acquisition', 'design', 'digital', 'experience', 'human CLIC4 protein', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'in vivo', 'insight', 'instrument', 'interest', 'melanoma', 'member', 'molecular imaging', 'molecular pathology', 'neoplastic cell', 'optical imaging', 'osteosarcoma', 'pluripotency', 'pre-clinical', 'quality assurance', 'ras Oncogene', 'residence', 'sarcoma', 'soft tissue', 'systems research', 'technology development', 'tool', 'trend', 'tumor']",NCI,DIVISION OF BASIC SCIENCES - NCI,ZIC,2012,1239425,-0.03134424238348504
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.      PUBLIC HEALTH RELEVANCE: The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.           The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8227796,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2012,197444,-0.0010940192887262659
"Real-Time MRI Motion Correction System    DESCRIPTION (provided by applicant):  MOTIVATION - Motion remains one of the most frequent contributors to image artifacts in MR studies.  The motion susceptibility of MRI is well-known and has spawned a number of elegant navigation techniques.  These methods, however, are tailored to specific MR acquisitions that require modified k-space trajectories or the acquisition of additional MR data, and most are unable to correct certain types of motion, for example, through-plane motion.  Moreover, motion correction has been focused on specific families of sequences, but no generally applicable approach currently exists.  Certain patient populations, such as pediatric or geriatric patients, are more likely to move than others.  In pediatric imaging, anesthesia is used to control motion, adding substantially to exam costs and patient risks.  A sequence-independent, autonomous and prospective motion correction system could greatly improve image quality for a wide spectrum of MR examinations.  For pediatric imaging, in particular, we anticipate reduced reliance on anesthesia to control patient motion.  AIMS - We will be focusing on three independent specific aims (carried out in parallel and completed within 4 years), with corresponding subaims that we believe are important for establishing the technical/scientific merit and to demonstrate the feasibility of the proposed R&D efforts for our real-time adaptive motion correction approach.  Specifically, these aims are:  (1) to develop and evaluate a coil-mounted MR-compatible tracking device for routine clinical use; (2) to integrate pose tracking into real-time MRI; and (3) to validate our real-time motion correction system in volunteers and patients.  METHODS -In Aim 1 we will improve the methods for computer-vision-based pose estimation inside an MR scanner and build an MR-compatible coil-mounted pose tracker that can be used in clinical routine examinations.  In Aim 2 we will focus on reducing the latency between pose changes happening and the MR scanner reacting to these pose changes, and on building a software library for the MR pulse sequence development that allows one to implement real-time motion correction into all MR pulse sequences.  In Aim 3 we will perform a thorough evaluation of our system on 60 volunteers (30 adults and 30 children) and 120 patients (80 adults and 40 children).  SIGNIFICANCE - The impact of our technology has several facets.  First, it will improve patient care by reducing the number of MR images with compromised quality because of motion artifacts.  Especially because of the increasing reliance on MR Images as a primary means of diagnosis, this will reduce the number of misdiagnoses.  Secondly, this technology will help to lower the high national spending on imaging by dramatically improving the efficiency of MRI scanners.  Finally, it will improve patient comfort by reducing the need for repeat sequences, as well as reduce the necessity of sedation aimed at keeping the patient still.  Overall, this technology will have a significant impact on MRI both in clinical practice and basic science research.      PUBLIC HEALTH RELEVANCE:  Synopsis Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually.  This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time.  The project leverages on previous work from an R21 project in which a prototype system was successfully built.  Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.              Synopsis  Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually. This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time. The project leverages on previous work from an R21 project in which a prototype system was successfully built. Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.",Real-Time MRI Motion Correction System,8323818,R01EB011654,"['Address', 'Adopted', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Articular Range of Motion', 'Base Sequence', 'Basic Science', 'Brain', 'Callback', 'Child', 'Childhood', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer software', 'Data', 'Detection', 'Development', 'Device Safety', 'Devices', 'Diagnosis', 'Disease', 'Economic Burden', 'Educational workshop', 'Elderly', 'Electronics', 'Enrollment', 'Environment', 'Evaluation', 'Family', 'Financial compensation', 'Goals', 'Grant', 'Head', 'Healthcare Systems', 'High Prevalence', 'Image', 'Individual', 'Lead', 'Libraries', 'Magnetic Resonance Imaging', 'Methods', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Noise', 'Optics', 'Patient Care', 'Patients', 'Physiologic pulse', 'Positioning Attribute', 'Predisposition', 'Procedures', 'Protocols documentation', 'Reliance', 'Research', 'Research Project Grants', 'Resolution', 'Risk', 'Safety', 'Scanning', 'Scheme', 'Sedation procedure', 'Signal Transduction', 'Societies', 'Solutions', 'Speed', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Update', 'Vision', 'Well in self', 'Work', 'aging population', 'analog', 'base', 'body system', 'clinical practice', 'comparative', 'cost', 'data sharing', 'design', 'detector', 'digital', 'human subject', 'image processing', 'improved', 'innovation', 'lens', 'meetings', 'novel marker', 'optical imaging', 'patient population', 'peer', 'programs', 'prospective', 'prototype', 'public health relevance', 'research and development', 'research clinical testing', 'research study', 'tool', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2012,592538,0.025469477573441122
"Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters    DESCRIPTION (provided by applicant): Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance to detect PCa; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project is highly significant because it addresses a major health problem in the United States and other developed countries. The project will overcome the current inability of established clinical-imaging method to image PCa reliably by combining the capabilities of advanced ultrasound (US) and magnetic-resonance (MR) techniques in a clinically effective manner. The proposed approach will exploit the sensitivity of US to mechanical properties of tissue on a microscopic scale with the sensitivity of MR to chemical constituents of tissue and its ability to sense blood distribution. Each of these modalities senses different and independent properties of tissue and has shown encouraging potential for improved imaging of PCa when used alone; combining parameters derived from each modality can provide far superior sensitivity and specificity for PCa. We will combine US and MR parameters using advanced classifiers such as artificial neural networks and support-vector machines. These classifiers already have produced ROC-curve areas of 0.91 for advanced US methods, and the MR methods have demonstrated equivalent ROC-curve areas in many studies. We will embody the combined capabilities in specifications for a prototype imaging system that can generate prostate tissue-typing images (TTIs) in real-time for targeting biopsies or planning treatment in the operating room or in an off-line setting. The latest Logiq E9 instrument currently being produced by GE already has a capability for fusing previously obtained MR images with US images in real time, which provides an existing framework for combining US and MR parameters and generating real-time TTIs. Successfully generating reliable prostate TTIs based on combined US and MR parameters will represent a quantum advance in PCa management by enabling significant improvements in the diagnosis and treatment of PCa.      PUBLIC HEALTH RELEVANCE: Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.           Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.",Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters,8293146,R01CA140772,"['Ablation', 'Achievement', 'Acoustics', 'Address', 'Adverse effects', 'Area', 'Atlas of Cancer Mortality in the United States', 'Biological Neural Networks', 'Biopsy', 'Biopsy Specimen', 'Bladder', 'Blood', 'Blood Vessels', 'Chemicals', 'Classification', 'Clinical', 'Cryosurgery', 'Data', 'Data Analyses', 'Databases', 'Developed Countries', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Disease regression', 'Drug Formulations', 'Engineering', 'Frequencies', 'Generations', 'Gland', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Israel', 'Lead', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Mechanics', 'Medical center', 'Metabolic', 'Methods', 'Microscopic', 'Modality', 'Monitor', 'Morphologic artifacts', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nerve', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Perfusion', 'Process', 'Property', 'Prostate', 'Prostate Cancer therapy', 'Prostate-Specific Antigen', 'Prostatectomy', 'Quantitative Evaluations', 'ROC Curve', 'Radio', 'Radiosurgery', 'Rectum', 'Research', 'Research Institute', 'Resolution', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Signal Transduction', 'Specimen', 'Spectrum Analysis', 'Staging', 'Structure of base of prostate', 'Surface', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Universities', 'Urethra', 'Ursidae Family', 'base', 'blind', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'computer aided detection', 'computerized', 'cost', 'experience', 'high risk', 'image registration', 'imaging modality', 'improved', 'instrument', 'instrumentation', 'interest', 'lymph nodes', 'novel', 'outcome forecast', 'prototype', 'quantitative ultrasound', 'quantum', 'response', 'standard care', 'tool', 'treatment planning', 'tumor']",NCI,RIVERSIDE RESEARCH INSTITUTE,R01,2012,582054,-0.014414008307465368
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis  Project Summary All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This proposal takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.  Project Narrative This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8300746,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2012,151744,0.01643299934634294
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,8281471,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Health', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'NMR Spectroscopy', 'Negative Staining', 'Neighborhoods', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2012,272755,-0.02296349915593097
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, an image includes not only biomedical images, but also illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. The project objectives may be formulated as seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. The approaches to meeting these objectives use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers a richer search.   Taking the retrieval of biomedical literature a step further, within the first objective our goal is to find information relevant to a patients case from the literature and then link it to the patients health record. The case is first represented in structured form using both text and image features, and then literature and EHR databases are searched for similar cases.  A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   Automatic image annotation and retrieval objectives can be achieved in the following ways: (i) using image analysis alone; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. One approach is to compute image similarity, the traditional CBIR task of finding images that are overall visually similar to a query image, using machine learning classifiers (e.g., Support Vector Machine) and fusion of class probabilities. These classifiers are trained on a variety of image features such as wavelets, edge histograms and those recommended by the MPEG-7 committee. Additional steps include describing an image by automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.) and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed OpenI (Open ""eye""), a hybrid system combining text-based searching with an image similarity engine. Using this framework we explore alternative approaches to the problem of searching for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using the (clinical) image of a given patient, and then linking the image to relevant information found by using visual and text features;  (iii) merging the results of independent text and image searches; and (iv) starting a multimodal search that combines text and image features.  In an international evaluation our approaches were shown to be among the best in image type classification,  image retrieval using only visual features, ad hoc retrieval, and medical case retrieval among over a dozen teams from around the world, including several from the industry. n/a",Integrating image and text information for biomedical information retrieval,8344956,ZIALM010001,"['Classification', 'Clinical', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Differential Diagnosis', 'Electronic Health Record', 'Elements', 'Evaluation', 'Eye', 'Goals', 'Graph', 'Hybrids', 'Image', 'Image Analysis', 'Industry', 'Information Retrieval', 'International', 'Journals', 'Letters', 'Link', 'Literature', 'MEDLINE', 'Machine Learning', 'MeSH Thesaurus', 'Medical', 'Metadata', 'Methods', 'Modality', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patients', 'Physicians', 'Probability', 'Process', 'Retrieval', 'Roentgen Rays', 'Semantics', 'Shapes', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Training', 'Ultrasonography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Visual', 'Work', 'abstracting', 'base', 'bioimaging', 'health record', 'image processing', 'imaging modality', 'improved', 'indexing', 'interest', 'journal article', 'meetings', 'monomethoxypolyethylene glycol', 'patient oriented', 'phrases', 'text searching', 'tool', 'visual search']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2011,621974,0.007485189026452244
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8299311,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2011,239426,0.03663359618523319
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8022635,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,304318,0.015292950474833929
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of available MR techniques and image contrast mechanisms, which can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.        One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While our application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around development of support vector machine analysis of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hypersurface. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,8335963,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Goals', 'Hydration status', 'Imaging Techniques', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metric', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Probability', 'Process', 'Relative (related person)', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Tissues', 'Training', 'Validation', 'Weight', 'Work', 'articular cartilage', 'base', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2011,521842,-0.02280465319400394
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.0394432229513386
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8163481,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,459174,-0.004293519968457697
"PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY    DESCRIPTION (provided by applicant): Well trained, experienced gastroenterologists in academic and high volume settings can reliably recognize 97% of pathologies in Capsule Endoscopy (CE) video. However, community physicians and infrequent users may miss up to 20%. The end goal of our proposed new line of research is to develop clinical software that provides automatic decision support to physicians who are trying to declare that a patient is pathology free or has a certain disease process. The risk for the physician - and their patients - is that of a less than optimal clinical outcome due to:  1) missing a lesion/pathology in the video and putting the patient at risk of developing a more serious condition over time, or  2) mistakenly ""identifying"" a pathology that is not present and thus subjecting the patient to unnecessary further diagnostic or surgical procedures.  The research aims in this proposal will enable Ikona to create a pathology prioritization image processing module. Implementing modern machine learning techniques such as Support Vector Machines (SVM) and Adaboost methodologies together with proprietary image feature analysis, this technology will assign a probability metric to every frame in the image sequence for specific pathology (lesions, ulcers, bleeding, etc) and the major landmarks in the GI tract (ileo-cecal valve, pyloric valve etc.). Filtering and sorting endoscopy image data will be done such that the images with the highest probability of containing pathology will be presented to the reviewer first.  This pathology prioritized sequencing is not intended to replace the clinician in the workflow, but rather to allow the clinician to focus more time on frames with a higher potential of containing pathology. Often times, clinically significant pathology may only be present in a single frame. A single ""pathological"" frame in the middle of a 50,000 frame sequence can easily be overlooked by a novice reviewer or a reviewer whose attention is temporarily distracted. With our proposed pathology prioritization, that single pathological frame will be identified and sorted near the beginning of the image sequence thus greatly increasing the likelihood of detection by the reviewer.  Specifically for Phase I, we plan to investigate and develop different algorithms for classifying image frames and recognizing pathological and normal frames, and, algorithms for ranking frames by severity of pathology. Following the implementation of a working prototype, we will further test the clinical utility of these algorithms with human clinical capsule endoscopy videos.      PUBLIC HEALTH RELEVANCE: Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.           Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.         ",PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY,8057895,R43DK091083,"['Affect', 'Algorithms', 'American', 'Attention', 'Blood', 'Categories', 'Classification', 'Classification Scheme', 'Clinical', 'Community Physician', 'Computer software', 'Crohn&apos', 's disease', 'Data', 'Data Set', 'Databases', 'Deformity', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Endoscopy', 'Evaluation', 'Family', 'Fatigue', 'Gastroenterologist', 'Gastrointestinal tract structure', 'Goals', 'Hemorrhage', 'Hour', 'Human', 'Image', 'Imagery', 'Lesion', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Metric', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Phase', 'Physicians', 'Polyps', 'Population', 'Probability', 'Procedures', 'Process', 'Readability', 'Reader', 'Reading', 'Research', 'Risk', 'Risk Reduction', 'Severities', 'Small Intestines', 'Sorting - Cell Movement', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'Ulcer', 'Work', 'base', 'capsule', 'clinically relevant', 'clinically significant', 'cost', 'experience', 'gastrointestinal', 'image processing', 'improved', 'innovation', 'interest', 'prospective', 'prototype', 'tumor']",NIDDK,IKONA MEDICAL CORPORATION,R43,2011,176778,0.01989958020052338
"Digital image analysis for quantitative and qualitative assessment of pig islets    DESCRIPTION (provided by applicant): The demonstration by the Edmonton group that human islet transplantation can be successfully used to manage adult type 1 diabetes patients with refractory hypoglycemia has led to increased funding of clinical trials and further research to extend the scope of this therapy by using porcine islets in place of human islets. Significant advances have been made in improving immunosuppression treatment regimens so that results obtained from treating adult diabetic patients with human islet transplants are similar to those obtained after pancreas transplantation. The major hurdle to move this therapy from clinical research to routine clinical practice is to improve the yield and quality of islets recovered from human or porcine pancreas. Presently, there are no standardized methods that can accurately assess the number or quality of islets that are used in the islet transplantation procedures so that results between laboratories can be objectively evaluated. This grant is focused on developing a robust, islet image analysis software to objectively analyze the number and quality of porcine islets recovered from the pancreas. The two major aims of the project are first to develop an improved image analysis software program that will provide a standardized measurement of the number and mass of porcine islets in a cell preparation. And second, enhance the capabilities of the software program by correlating the image signatures of each porcine islet to an artificial category. Porcine islets of similar size will be handpicked and sorted into three categories based on the shape, border, integrity, or uniformity of dithizone staining. The first software enhancement will find those features in the images that can be used to distinguish the different categories of islets. The second enhancement will assess the feasibility of using machine learning methods to correlate these features with data recovered from the images but also other discrete or continuous variables that are used to characterize the porcine islet preparations. If successful, the ability to use a rapid and objective image analysis methodology will improve the assessment of the number and quality of islets within and between laboratories; correlate image features with success of transplantation as measured by graft survival and insulin independence; and improve the islet isolation methods to achieve favorable islet image scores that are determined by retrospective analysis. The ability of a commercial firm focused on improving islet yields by focusing on tissue dissociation with a leading academic laboratory that has sophisticated expertise in developing software algorithms from microscopic images provides a fresh approach to a difficult medical that needs to be resolved to realize the full potential of islet transplantation to treat adult type 1 diabetic patients.      PUBLIC HEALTH RELEVANCE: An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.           An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.         ",Digital image analysis for quantitative and qualitative assessment of pig islets,8058009,R43DK091103,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Biochemical', 'Biological', 'Biological Assay', 'Caliber', 'Categories', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computer Assisted', 'Computer software', 'Data', 'Data Collection', 'Development', 'Dissociation', 'Dithizone', 'Drops', 'Enzymes', 'Family suidae', 'Feasibility Studies', 'Funding', 'Genetic', 'Glucose', 'Graft Survival', 'Grant', 'Human', 'Hypoglycemia', 'Image', 'Image Analysis', 'Immunosuppression', 'In Vitro', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Islet Cell', 'Islets of Langerhans Transplantation', 'Laboratories', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modification', 'Optics', 'Organ', 'Outcome', 'Pancreas', 'Pancreas Transplantation', 'Pathway interactions', 'Patients', 'Pattern Recognition', 'Pattern Recognition Systems', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Portal vein structure', 'Predictive Value', 'Preparation', 'Procedures', 'Proteomics', 'Protocols documentation', 'Recovery', 'Refractory', 'Reporting', 'Research', 'Sampling', 'Sampling Errors', 'Scientist', 'Screening procedure', 'Shapes', 'Sorting - Cell Movement', 'Staining method', 'Stains', 'Standardization', 'Statistical Models', 'Stress', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Time', 'Tissues', 'Transplantation', 'Treatment Protocols', 'base', 'cell preparation', 'clinical practice', 'diabetic patient', 'digital', 'digital imaging', 'improved', 'indexing', 'innovation', 'islet', 'programs', 'software development', 'standardize measure', 'success', 'tool', 'type I diabetic']",NIDDK,"VITACYTE, LLC",R43,2011,232329,0.03931567919470384
"Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging Dementia represents a major public health problem which will grow significantly with the aging of our society. Recently, multiple pieces of converging clinical and neuropathological data indicate that dementia is typically a multi-factorial process. This evolution in thinking about the biology of dementia comes at a time when the most significant recent development in dementia imaging has been the introduction of amyloid plaque labeling compounds; the most widely studied at this point is Pittsburgh Compound - B (PiB). A central principle underlying this renewal is this. Amyloid imaging is unquestionably a major advance. However, since the biology of dementia is more complex than brain amyloidosis alone, imaging of dementia is more complex than brain amyloid imaging alone. Our primary goal in this renewal is to use various imaging modalities to identify different mechanisms underlying dementia. This is the first resubmission of a competitive renewal of AG11378. We have revised the grant in accordance with each point raised in the critique and we believe this has resulted in a much stronger application. Each of the five aims is cast to answer variations on the questions: What is the contribution of specific imaging-based proxies of pathology to clinical/cognitive decline? When in the course of the disease do these relationships hold true? For whom is this true? Where in the brain are the relevant pathologies expressed? Principle outcome measures will be clinical and psychometric decline over time which we will use as indicators of disease progression. Our predictor variables will include various imaging modalities which will serve as proxies for specific pathologic mechanisms underlying dementia. PiB will serve as a measure of plaque burden and we will use various Magnetic Resonance Imaging (MRI) modalities to assess cerebro- vascular disease, tissue loss, tissue perfusion, diffusion, neuronal integrity, and inflammation. Features that distinguish this renewal from past cycles of AG11378 include a mechanistic focus, multi- modality imaging including multiple MRI modalities as well as PET amyloid imaging, MR imaging now at 3T, inclusion of both amnestic and non-amnestic MCI, and voxel-based analytic methods including an exciting new computational approach which employs a support vector machine algorithm to provide diagnosis in individual subjects. In addition, subjects will now be recruited from a new population-based study of aging and dementia, which differentiates this renewal from past cycles as well as from most dementia imaging studies which recruit from referral practices and thus risk sampling bias. Previous cycles of this grant have contributed significantly to recognition of the utility of imaging in dementia. An active debate is currently underway about revising clinical criteria for AD, specifically whether imaging and fluid biomarker information should be included among the criteria. Results from this renewal grant will inform this debate about multiple time dependent mechanisms leading to dementia that are accessible in living subjects through imaging. PUBLIC HEALTH RELEVANCE: Identifying Mechanisms of Dementia: Role for MRI in the Era of Molecular Imaging (AG11378) Dementia is a leading public health problem now and will have an increasingly serious impact on public health as the number of elderly individuals increase. Dementia has many possible underlying causes and several different causes are at work in most elderly demented subjects. In this grant, we will use modern brain imaging to identify specific mechanisms underlying progression to dementia. n/a",Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging,8117482,R01AG011378,"['6-hydroxybenzothiazole', 'Abbreviations', 'Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease Pathway', 'Amyloid deposition', 'Amyloidosis', 'Anatomy', 'Anisotropy', 'Applications Grants', 'Attenuated', 'Autopsy', 'Base of the Brain', 'Binding', 'Biological Markers', 'Biology', 'Biostatistical Methods', 'Brain', 'Brain Mapping', 'Brain imaging', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Clinical Pathology', 'Cognition', 'Cognitive', 'Complex', 'Correlation Studies', 'Critiques', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Elderly', 'Enrollment', 'Epidemiologic Studies', 'Event', 'Evolution', 'Future', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Inflammation', 'Inositol', 'Label', 'Life', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measures', 'Memory', 'Methods', 'Metric', 'Modality', 'Modeling', 'N-acetylaspartate', 'Neurofibrillary Tangles', 'Neurons', 'Outcome', 'Outcome Measure', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Perfusion', 'Pittsburgh Compound-B', 'Population', 'Positron-Emission Tomography', 'Process', 'Proxy', 'Psychometrics', 'Public Health', 'Recovery', 'Recruitment Activity', 'Relative (related person)', 'Resolution', 'Risk', 'Role', 'Sampling', 'Sampling Biases', 'Scheme', 'Senile Plaques', 'Severity of illness', 'Societies', 'Spin Labels', 'Staging', 'Study Subject', 'Symptoms', 'Synapses', 'Syndrome', 'Text', 'Thinking', 'Time', 'Tissues', 'Variant', 'Vascular Diseases', 'Work', 'amyloid imaging', 'base', 'clinical Diagnosis', 'cohort', 'imaging modality', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular imaging', 'morphometry', 'neuroimaging', 'population based', 'primary outcome', 'tool']",NIA,MAYO CLINIC ROCHESTER,R01,2011,968365,-0.031469944618231216
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,8135352,R01EB012070,"['Agreement', 'Algorithms', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'image processing', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2011,29247,-0.03221075848364982
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8037095,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2011,417204,0.026770635898351307
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,8143297,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'animal tissue', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2011,132786,-0.0262196829063859
"Development And Applications Of The Open Microscopy Environment (OME) In recent years, we've focused on the OME analysis system and developing robust general image analysis methodology, culminating in our pattern recognition tool called WND-CHRM.  We have validated this pattern-recognition approach to biological image analysis using diverse imaging modalities ranging from fluorescence microscopy to X-rays of human knees.  We have also validated a range of  applications from scoring image-based assays to diagnosis of disease to prediction of future disease risk.  The specific applications of this approach are covered in reports AG000674-07 and AG000685-04.  A major effort in the previous year has been to expand the functionality of WND-CHRM into quantitative image-comparison assays as well as spatial pattern analysis.  A major effort was also undertaken to rewrite the WND-CHRM code-base to make it more modular, better organized and easier to use.  WND-CHARM is a generalized pattern-recognition algorithm that can be used to analyze any type of image.  Unlike most approaches to image processing in current use, this method relies on training a machine classifier to automatically recognize differences between training image classes (i.e. controls), rather than relying on an a-priori model of what is being imaged.  This approach has been demonstrated to be effective at discerning differences even when they cannot be easily perceived manually.  The output of a trained machine classifier is qualitative: for a given test image, it reports the class of training images that the test image is most similar to.  In a scientific setting, it is often not sufficient to know what class an image belongs to, but how similar it is to the given training classes.  An example is a quantitative imaging assay where the set of training image-classes comprise a standard curve, and the classifier's task is to arrive at a continuous score by interpolating between the defined classes.  This type of classification can be called an ""ordered-class problem"".  There also exist a set of problems where the classes do not have an inherent order, and instead of an interpolated continuous score, the desired output is a measure of the similarity between classes.  A familiar visualization of classes that have varying degrees of similarity to each other is a dendrogram, or for example, a phylogenetic tree representing evolutionary distance.  This type of classification can be called a ""class-similarity problem"".  The current implementation of WND-CHARM addresses both of these quantitative imaging problems automatically.  In addition to reporting the qualitative class assignment, it reports a continuous value if the class names can be interpreted numerically, and it computes pair-wise similarities between all of the classes.  If a dendrogram visualization package is installed on the system (PHYLIP), it automatically generates a dendrogram based on the pair-wise class-distance matrix.  This type of visualization has proven useful as an independent validation for ordered-class problems, since a well-ordered set of classes will produce a linear, or elongated dendrogram without major branch-points.  The program that implements the WND-CHRM algorithm (called wndchrm), has been made publicly available on Google Code (http://wnd-charm.googlecode.com/).  A major release of the code (version 1.31), covering the areas discussed above has been made available on the project's site as well.  This version represents a first pass at reorganizing the code-base by making it more self-consistent and reliable without major architectural changes.  It also represents a substantial effort in validation, testing and resolution of bugs.  The site provides an interface for reporting bugs and requesting new features, and we have made extensive use of this facility within our own group.  Although the site has only been active since February 2011, it is visited an average of 30 times per week, and the software has been downloaded over 100 times.  The visits represent 59 countries, though nearly half of the visits are from the US.  Whole-image analysis has proven very useful, but it is not always possible to compare whole images to each other.  Examples of relatively homogenous images are those of cultured cells, or tissues like muscle, liver, and certain types of tumors.  Our work on human knee X-Rays was the first application where a certain degree of pre-processing was necessary to make images of different subjects comparable to each other.  In this case, we simply found the center of the knee joint in each image, and extracted a fixed radius around this center for all patients.  A much more complicated alignment problem exists in images with complex anatomy.  Possibly the most extreme example of this are stained sections of brain tissue.  A solution to the alignment problem would allow the use of generalized pattern recognition to address morphological differences in an anatomical context.  For example, what areas of the brain correlate with cognitive decline or age?  What is the degree of overlap between these areas?  Spatially-resolved pattern analysis places an extreme burden on the performance of our software.  Instead of an entire image being considered at once, or split into a small number of tiles on a grid, to achieve spatial resolution, each image must be sampled thousands or millions of times.  In order to make this type of application practical, the computational strategy used in the software must be reconsidered.  Previously, all of the 3,000 low-level image features were calculated for each image sample, even when most of them were later found to be irrelevant to the classification problem because they lacked discrimination power.  The major change in strategy to enable spatially-resolved pattern recognition is to eliminate unnecessary calculations.  This requires an on-demand computing strategy for image features, which is a major architectural goal of the wndchrm rewrite.  Incremental improvements in performance are also expected from making more extensive use of optimized libraries, which also helps to reduce the burden of code that our group has to maintain.  Lastly, a better-managed mechanism for maintaining the results of image-feature computation is necessary when the volume is increased by several orders of magnitude.  We are adopting SQLlite for this task, which is a common solution to high-volume/low-complexity database needs.  Currently, these various efforts are maintained in separate branches in our Google Code software repository, and we will merge them as they become more mature.  The majority of our software-development efforts recently have been dedicated to the WND-CHRM analysis tool.  With the addition of quantitative and spatially-resolved pattern analysis, it represents a substantial portion of what is possible with image analysis without a-priori models.  Meanwhile, the OMERO project has matured under the guidance of Jason Swedlow, and is now a good, stable and usable implementation of the image and meta-data management concepts within OME.  In the coming year, we will begin a substantial effort of integrating our ideas from developing WND-CHRM into the original concepts developed for OME.  Together with Jason Swedlow, we have applied for and received funding from the Wellcome Trust to bring these two projects together, and we will begin these efforts in the coming year. n/a",Development And Applications Of The Open Microscopy Environment (OME),8336690,ZICAG000671,"['Address', 'Adopted', 'Algorithms', 'Anatomy', 'Area', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Classification', 'Code', 'Cognitive aging', 'Collection', 'Complex', 'Computer software', 'Computers', 'Country', 'Cultured Cells', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Discrimination', 'Ensure', 'Environment', 'Fluorescence Microscopy', 'Funding', 'Future', 'Generic Drugs', 'Genomics', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging problem', 'Impaired cognition', 'Informatics', 'Knee', 'Knee joint', 'Libraries', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Microscopy', 'Mining', 'Modality', 'Modeling', 'Muscle', 'Names', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phylogenetic Analysis', 'Process', 'Radial', 'Reporting', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Semantics', 'Site', 'Solutions', 'Speed', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Trees', 'Trust', 'Validation', 'Visit', 'Visual', 'Work', 'age related', 'base', 'brain tissue', 'data management', 'data mining', 'data modeling', 'detector', 'digital', 'disease diagnosis', 'disorder risk', 'flexibility', 'image processing', 'imaging informatics', 'imaging modality', 'medical specialties', 'open source', 'practical application', 'programs', 'software development', 'software repository', 'tool', 'tumor']",NIA,NATIONAL INSTITUTE ON AGING,ZIC,2011,353738,0.03894813164160447
"Real-Time MRI Motion Correction System    DESCRIPTION (provided by applicant):  MOTIVATION - Motion remains one of the most frequent contributors to image artifacts in MR studies.  The motion susceptibility of MRI is well-known and has spawned a number of elegant navigation techniques.  These methods, however, are tailored to specific MR acquisitions that require modified k-space trajectories or the acquisition of additional MR data, and most are unable to correct certain types of motion, for example, through-plane motion.  Moreover, motion correction has been focused on specific families of sequences, but no generally applicable approach currently exists.  Certain patient populations, such as pediatric or geriatric patients, are more likely to move than others.  In pediatric imaging, anesthesia is used to control motion, adding substantially to exam costs and patient risks.  A sequence-independent, autonomous and prospective motion correction system could greatly improve image quality for a wide spectrum of MR examinations.  For pediatric imaging, in particular, we anticipate reduced reliance on anesthesia to control patient motion.  AIMS - We will be focusing on three independent specific aims (carried out in parallel and completed within 4 years), with corresponding subaims that we believe are important for establishing the technical/scientific merit and to demonstrate the feasibility of the proposed R&D efforts for our real-time adaptive motion correction approach.  Specifically, these aims are:  (1) to develop and evaluate a coil-mounted MR-compatible tracking device for routine clinical use; (2) to integrate pose tracking into real-time MRI; and (3) to validate our real-time motion correction system in volunteers and patients.  METHODS -In Aim 1 we will improve the methods for computer-vision-based pose estimation inside an MR scanner and build an MR-compatible coil-mounted pose tracker that can be used in clinical routine examinations.  In Aim 2 we will focus on reducing the latency between pose changes happening and the MR scanner reacting to these pose changes, and on building a software library for the MR pulse sequence development that allows one to implement real-time motion correction into all MR pulse sequences.  In Aim 3 we will perform a thorough evaluation of our system on 60 volunteers (30 adults and 30 children) and 120 patients (80 adults and 40 children).  SIGNIFICANCE - The impact of our technology has several facets.  First, it will improve patient care by reducing the number of MR images with compromised quality because of motion artifacts.  Especially because of the increasing reliance on MR Images as a primary means of diagnosis, this will reduce the number of misdiagnoses.  Secondly, this technology will help to lower the high national spending on imaging by dramatically improving the efficiency of MRI scanners.  Finally, it will improve patient comfort by reducing the need for repeat sequences, as well as reduce the necessity of sedation aimed at keeping the patient still.  Overall, this technology will have a significant impact on MRI both in clinical practice and basic science research.      PUBLIC HEALTH RELEVANCE:  Synopsis Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually.  This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time.  The project leverages on previous work from an R21 project in which a prototype system was successfully built.  Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.              Synopsis  Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually. This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time. The project leverages on previous work from an R21 project in which a prototype system was successfully built. Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.",Real-Time MRI Motion Correction System,8141396,R01EB011654,"['Address', 'Adopted', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Articular Range of Motion', 'Base Sequence', 'Basic Science', 'Brain', 'Callback', 'Child', 'Childhood', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer software', 'Data', 'Detection', 'Development', 'Device Safety', 'Devices', 'Diagnosis', 'Disease', 'Economic Burden', 'Educational workshop', 'Elderly', 'Electronics', 'Enrollment', 'Environment', 'Evaluation', 'Family', 'Financial compensation', 'Goals', 'Grant', 'Head', 'Healthcare Systems', 'High Prevalence', 'Image', 'Individual', 'Lead', 'Libraries', 'Magnetic Resonance Imaging', 'Methods', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Noise', 'Optics', 'Patient Care', 'Patients', 'Physiologic pulse', 'Positioning Attribute', 'Predisposition', 'Procedures', 'Protocols documentation', 'Reliance', 'Research', 'Research Project Grants', 'Resolution', 'Risk', 'Safety', 'Scanning', 'Scheme', 'Sedation procedure', 'Signal Transduction', 'Societies', 'Solutions', 'Speed', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Update', 'Vision', 'Well in self', 'Work', 'aging population', 'analog', 'base', 'body system', 'clinical practice', 'comparative', 'cost', 'data sharing', 'design', 'detector', 'digital', 'human subject', 'image processing', 'improved', 'innovation', 'lens', 'meetings', 'novel marker', 'optical imaging', 'patient population', 'peer', 'programs', 'prospective', 'prototype', 'public health relevance', 'research and development', 'research clinical testing', 'research study', 'tool', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2011,540015,0.025469477573441122
"Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters    DESCRIPTION (provided by applicant): Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance to detect PCa; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project is highly significant because it addresses a major health problem in the United States and other developed countries. The project will overcome the current inability of established clinical-imaging method to image PCa reliably by combining the capabilities of advanced ultrasound (US) and magnetic-resonance (MR) techniques in a clinically effective manner. The proposed approach will exploit the sensitivity of US to mechanical properties of tissue on a microscopic scale with the sensitivity of MR to chemical constituents of tissue and its ability to sense blood distribution. Each of these modalities senses different and independent properties of tissue and has shown encouraging potential for improved imaging of PCa when used alone; combining parameters derived from each modality can provide far superior sensitivity and specificity for PCa. We will combine US and MR parameters using advanced classifiers such as artificial neural networks and support-vector machines. These classifiers already have produced ROC-curve areas of 0.91 for advanced US methods, and the MR methods have demonstrated equivalent ROC-curve areas in many studies. We will embody the combined capabilities in specifications for a prototype imaging system that can generate prostate tissue-typing images (TTIs) in real-time for targeting biopsies or planning treatment in the operating room or in an off-line setting. The latest Logiq E9 instrument currently being produced by GE already has a capability for fusing previously obtained MR images with US images in real time, which provides an existing framework for combining US and MR parameters and generating real-time TTIs. Successfully generating reliable prostate TTIs based on combined US and MR parameters will represent a quantum advance in PCa management by enabling significant improvements in the diagnosis and treatment of PCa.      PUBLIC HEALTH RELEVANCE: Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.           Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.",Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters,8123232,R01CA140772,"['Ablation', 'Achievement', 'Acoustics', 'Address', 'Adverse effects', 'Area', 'Atlas of Cancer Mortality in the United States', 'Biological Neural Networks', 'Biopsy', 'Biopsy Specimen', 'Bladder', 'Blood', 'Blood Vessels', 'Chemicals', 'Classification', 'Clinical', 'Computer Assisted', 'Cryosurgery', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Developed Countries', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Disease regression', 'Drug Formulations', 'Engineering', 'Frequencies', 'Generations', 'Gland', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Israel', 'Lead', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Mechanics', 'Medical center', 'Metabolic', 'Methods', 'Microscopic', 'Modality', 'Monitor', 'Morphologic artifacts', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nerve', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Perfusion', 'Process', 'Property', 'Prostate', 'Prostate Cancer therapy', 'Prostate-Specific Antigen', 'Prostatectomy', 'Quantitative Evaluations', 'ROC Curve', 'Radio', 'Radiosurgery', 'Rectum', 'Research', 'Research Institute', 'Resolution', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Signal Transduction', 'Specimen', 'Spectrum Analysis', 'Staging', 'Structure of base of prostate', 'Surface', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Universities', 'Urethra', 'Ursidae Family', 'base', 'blind', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'computerized', 'cost', 'experience', 'high risk', 'image registration', 'imaging modality', 'improved', 'instrument', 'instrumentation', 'interest', 'lymph nodes', 'novel', 'outcome forecast', 'prototype', 'quantitative ultrasound', 'quantum', 'response', 'standard care', 'tool', 'treatment planning', 'tumor']",NCI,RIVERSIDE RESEARCH INSTITUTE,R01,2011,639137,-0.014414008307465368
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,8077991,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2011,192348,-0.010894706233885817
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,8098196,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Health', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'NMR Spectroscopy', 'Negative Staining', 'Neighborhoods', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2011,311172,-0.02296349915593097
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis    DESCRIPTION (provided by applicant): All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This application takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.      PUBLIC HEALTH RELEVANCE: This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.           This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.         ",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8192056,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2011,148255,0.009699298549535025
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7921476,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2010,110591,0.03663359618523319
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.03935701524700623
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7845601,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,TULANE UNIVERSITY OF LOUISIANA,R21,2010,186306,0.02680482650913043
"Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging Dementia represents a major public health problem which will grow significantly with the aging of our society. Recently, multiple pieces of converging clinical and neuropathological data indicate that dementia is typically a multi-factorial process. This evolution in thinking about the biology of dementia comes at a time when the most significant recent development in dementia imaging has been the introduction of amyloid plaque labeling compounds; the most widely studied at this point is Pittsburgh Compound - B (PiB). A central principle underlying this renewal is this. Amyloid imaging is unquestionably a major advance. However, since the biology of dementia is more complex than brain amyloidosis alone, imaging of dementia is more complex than brain amyloid imaging alone. Our primary goal in this renewal is to use various imaging modalities to identify different mechanisms underlying dementia. This is the first resubmission of a competitive renewal of AG11378. We have revised the grant in accordance with each point raised in the critique and we believe this has resulted in a much stronger application. Each of the five aims is cast to answer variations on the questions: What is the contribution of specific imaging-based proxies of pathology to clinical/cognitive decline? When in the course of the disease do these relationships hold true? For whom is this true? Where in the brain are the relevant pathologies expressed? Principle outcome measures will be clinical and psychometric decline over time which we will use as indicators of disease progression. Our predictor variables will include various imaging modalities which will serve as proxies for specific pathologic mechanisms underlying dementia. PiB will serve as a measure of plaque burden and we will use various Magnetic Resonance Imaging (MRI) modalities to assess cerebro- vascular disease, tissue loss, tissue perfusion, diffusion, neuronal integrity, and inflammation. Features that distinguish this renewal from past cycles of AG11378 include a mechanistic focus, multi- modality imaging including multiple MRI modalities as well as PET amyloid imaging, MR imaging now at 3T, inclusion of both amnestic and non-amnestic MCI, and voxel-based analytic methods including an exciting new computational approach which employs a support vector machine algorithm to provide diagnosis in individual subjects. In addition, subjects will now be recruited from a new population-based study of aging and dementia, which differentiates this renewal from past cycles as well as from most dementia imaging studies which recruit from referral practices and thus risk sampling bias. Previous cycles of this grant have contributed significantly to recognition of the utility of imaging in dementia. An active debate is currently underway about revising clinical criteria for AD, specifically whether imaging and fluid biomarker information should be included among the criteria. Results from this renewal grant will inform this debate about multiple time dependent mechanisms leading to dementia that are accessible in living subjects through imaging. PUBLIC HEALTH RELEVANCE: Identifying Mechanisms of Dementia: Role for MRI in the Era of Molecular Imaging (AG11378) Dementia is a leading public health problem now and will have an increasingly serious impact on public health as the number of elderly individuals increase. Dementia has many possible underlying causes and several different causes are at work in most elderly demented subjects. In this grant, we will use modern brain imaging to identify specific mechanisms underlying progression to dementia. n/a",Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging,7894558,R01AG011378,"['6-hydroxybenzothiazole', 'Abbreviations', 'Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease Pathway', 'Amyloid deposition', 'Amyloidosis', 'Anatomy', 'Anisotropy', 'Applications Grants', 'Attenuated', 'Autopsy', 'Base of the Brain', 'Binding', 'Biological Markers', 'Biology', 'Biostatistical Methods', 'Brain', 'Brain Mapping', 'Brain imaging', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Clinical Pathology', 'Cognition', 'Cognitive', 'Complex', 'Correlation Studies', 'Critiques', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Elderly', 'Enrollment', 'Epidemiologic Studies', 'Event', 'Evolution', 'Future', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Inflammation', 'Inositol', 'Knowledge', 'Label', 'Life', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measures', 'Memory', 'Methods', 'Metric', 'Modality', 'Modeling', 'N-acetylaspartate', 'Neurofibrillary Tangles', 'Neurons', 'Outcome', 'Outcome Measure', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Perfusion', 'Pittsburgh Compound-B', 'Population', 'Positron-Emission Tomography', 'Process', 'Proxy', 'Psychometrics', 'Public Health', 'Recovery', 'Recruitment Activity', 'Relative (related person)', 'Resolution', 'Risk', 'Role', 'Sampling', 'Sampling Biases', 'Scheme', 'Senile Plaques', 'Severity of illness', 'Societies', 'Spin Labels', 'Staging', 'Study Subject', 'Symptoms', 'Synapses', 'Syndrome', 'Text', 'Thinking', 'Time', 'Tissues', 'Variant', 'Vascular Diseases', 'Work', 'amyloid imaging', 'base', 'clinical Diagnosis', 'cohort', 'imaging modality', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular imaging', 'morphometry', 'neuroimaging', 'population based', 'primary outcome', 'public health relevance', 'tool']",NIA,MAYO CLINIC ROCHESTER,R01,2010,1034999,-0.031469944618231216
"Integrating image and text information for biomedical information retrieval  The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, an image includes not only biomedical images, but also illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. The project objectives out  may be formulated as seeking better ways to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. The approaches to meeting these objectives use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions), (ii) image features, such as color, shape, size, etc., and, if available, (iii) annotation markers within figures such as arrows, letters or symbols that are extracted from the image and correlated with concepts in the caption. These annotation markers can help isolate regions of interest (ROI) in images, the ROI being useful for improving the relevance of the figures retrieved. It is hypothesized that augmenting conventional search results with relevant images offers a richer search.   Taking the retrieval of biomedical literature a step further, within the first objective our goal is to find information relevant to a patients case from the literature and then link it to the patients health record. The case is first represented in structured form using both text and image features, and then literature and EHR databases are searched for similar cases.  A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems (for example, VisualDx) that use only text driven menus. Such menu driven systems guide a physician to describe a patient and then present a set of images from which a clinician can select the ones most similar to the patients, and access relevant information manually linked to the images.   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine.  This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and modality of the image).  In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.     Automatic image annotation and retrieval objectives can be achieved in the following ways: (i) using image analysis alone; (ii) by indexing the text assigned to images; and (iii) using a combination of image and text analysis. One approach is to compute image similarity, the traditional CBIR task of finding images that are overall visually similar to a query image, using machine learning classifiers (e.g., Support Vector Machine) and fusion of class probabilities. These classifiers are trained on a variety of image features such as wavelets, edge histograms and those recommended by the MPEG-7 committee. Additional steps include describing an image by automatically detecting its modality (for example, CT, MR, X-ray, ultrasound, etc.) and generating a visual ontology, i.e., concepts assigned to image patches. Elements from the visual ontology are called visual keywords and are used to find images with similar concepts.   To evaluate and demonstrate our techniques, we have developed the Image and Text Search Engine (ITSE), a hybrid system combining phrase-based searching with CEBs image similarity engine. Using this framework we explore alternative approaches to the problem of searching for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using the (clinical) image of a given patient, and then linking the image to relevant information found by using visual and text features; and, (iii) merging the results of independent text and image searches.  In an international evaluation our approaches were shown to be the best in two of three categories (image retrieval using only visual features, and medical case retrieval) and in the top four for ad-hoc biomedical information retrieval among over a dozen teams from around the world, including several from the industry. n/a",Integrating image and text information for biomedical information retrieval ,8158052,ZIALM010001,"['Image', 'Information Retrieval', 'Text']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2010,492812,0.0023071714186165796
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,7948792,R01EB012070,"['Agreement', 'Algorithms', 'Arts', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Computer Systems Development', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2010,546827,-0.03221075848364982
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7769507,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2010,420313,0.026770635898351307
"Spatially Accurate Deformable Image Registration for Thoracic CT Application    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.   Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.       n/a",Spatially Accurate Deformable Image Registration for Thoracic CT Application,7980382,DP2OD007044,"['Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computer Vision Systems', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'pulmonary function', 'small airways disease']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2010,1645038,0.0007987706039971308
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7941984,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2010,303186,-0.0262196829063859
"High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI    DESCRIPTION (provided by applicant):  Understanding normal and abnormal patterns of brain development in fetuses and neonates is a key factor in early detection of developmental disorders. This project proposal seeks to develop and refine novel magnetic resonance image reconstruction and analysis methodology to allow, for the first time, the mapping of in-utero fetal brain development. One of the most common abnormalities detected by clinical imaging of the developing fetal brain is ventriculomegaly, which, despite the absence of other clinical or imaging findings, is associated with neurodevelopmental disabilities in infancy and childhood in up to 50% of cases. Although ultrasound allows diagnosis of the condition, it has not been able to distinguish those fetus that will have poor neurological outcome from those with normal outcome. Recent developments in fast magnetic resonance imaging have permitted the use of MRI to study the fetal anatomy and this technique is now being routinely used at a small number of sites around the world including UCSF. However, MR imaging of the fetal brain is still challenging because of imaging distortions caused by motion of the fetus within the mother and by artifacts caused by the surrounding maternal anatomy. Higher resolution or 3D acquisitions are not possible because of motion of the fetus during the acquisition time^ required. The current clinical 2D slice data individually provide limited resolution and contrast and, most importantly, often contain severe motion corruption between slices. This project is motivated by the observation that it is possible to apply computer vision and image processing techniques to correct relative motion between the multiple stacks of low resolution fetal slices, and create a single volumetric image with high isotropic 3D resolution and consistent geometry. Such higher resolution images provide structure that may be analyzed using computational morphometric techniques that can detect subtle focal differences in the pattern of tissue volume, location and surface folding. This project will combine such powerful techniques with extensive fetal and neonatal imaging experience at UCSF, allowing direct clinical application of the methodology to study morphologic aberrations associated with ventriculomegaly and to correlate these with clinical outcome. The ability to apply these computational techniques to in-utero data will provide an entirely new view of the developing brain, which promises to shed new light on early developmental problems both in fetuses and premature neonates.           n/a",High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI,7904306,R01NS055064,"['Anatomy', 'Automobile Driving', 'Brain', 'Brain Mapping', 'Childhood', 'Clinic', 'Clinical', 'Computational Technique', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Evolution', 'Fetus', 'Gestational Age', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Infant Development', 'Investigation', 'Knowledge', 'Lesion', 'Light', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Mothers', 'Motion', 'Neonatal', 'Neurodevelopmental Disability', 'Neurological outcome', 'Outcome', 'Pattern', 'Premature Infant', 'Prematurity of fetus', 'Relative (related person)', 'Research Personnel', 'Resolution', 'Site', 'Slice', 'Staging', 'Statistical Models', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'brain tissue', 'clinical Diagnosis', 'clinical application', 'developmental disease', 'experience', 'fetal', 'follow-up', 'gray matter', 'image processing', 'image reconstruction', 'improved', 'in utero', 'infancy', 'insight', 'neonate', 'novel', 'premature', 'programs', 'reconstruction', 'tool', 'two-dimensional']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2010,48929,0.008574484874814756
"Real-Time MRI Motion Correction System    DESCRIPTION (provided by applicant):  MOTIVATION - Motion remains one of the most frequent contributors to image artifacts in MR studies.  The motion susceptibility of MRI is well-known and has spawned a number of elegant navigation techniques.  These methods, however, are tailored to specific MR acquisitions that require modified k-space trajectories or the acquisition of additional MR data, and most are unable to correct certain types of motion, for example, through-plane motion.  Moreover, motion correction has been focused on specific families of sequences, but no generally applicable approach currently exists.  Certain patient populations, such as pediatric or geriatric patients, are more likely to move than others.  In pediatric imaging, anesthesia is used to control motion, adding substantially to exam costs and patient risks.  A sequence-independent, autonomous and prospective motion correction system could greatly improve image quality for a wide spectrum of MR examinations.  For pediatric imaging, in particular, we anticipate reduced reliance on anesthesia to control patient motion.  AIMS - We will be focusing on three independent specific aims (carried out in parallel and completed within 4 years), with corresponding subaims that we believe are important for establishing the technical/scientific merit and to demonstrate the feasibility of the proposed R&D efforts for our real-time adaptive motion correction approach.  Specifically, these aims are:  (1) to develop and evaluate a coil-mounted MR-compatible tracking device for routine clinical use; (2) to integrate pose tracking into real-time MRI; and (3) to validate our real-time motion correction system in volunteers and patients.  METHODS -In Aim 1 we will improve the methods for computer-vision-based pose estimation inside an MR scanner and build an MR-compatible coil-mounted pose tracker that can be used in clinical routine examinations.  In Aim 2 we will focus on reducing the latency between pose changes happening and the MR scanner reacting to these pose changes, and on building a software library for the MR pulse sequence development that allows one to implement real-time motion correction into all MR pulse sequences.  In Aim 3 we will perform a thorough evaluation of our system on 60 volunteers (30 adults and 30 children) and 120 patients (80 adults and 40 children).  SIGNIFICANCE - The impact of our technology has several facets.  First, it will improve patient care by reducing the number of MR images with compromised quality because of motion artifacts.  Especially because of the increasing reliance on MR Images as a primary means of diagnosis, this will reduce the number of misdiagnoses.  Secondly, this technology will help to lower the high national spending on imaging by dramatically improving the efficiency of MRI scanners.  Finally, it will improve patient comfort by reducing the need for repeat sequences, as well as reduce the necessity of sedation aimed at keeping the patient still.  Overall, this technology will have a significant impact on MRI both in clinical practice and basic science research.      PUBLIC HEALTH RELEVANCE:  Synopsis Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually.  This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time.  The project leverages on previous work from an R21 project in which a prototype system was successfully built.  Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.              Synopsis  Patient motion during an MRI exam can result in major degradation of image quality and decreased efficiency in a large portion of the 40 million MRI procedures performed annually. This is not only of increasing concern due to the aging population and its associated diseases, but also in children and patients who are simply too sick to remain still during an exam.  This proposal aims to build an optical tracking system and methods to adapt MRI pulse sequences to changes in patient pose in real time. The project leverages on previous work from an R21 project in which a prototype system was successfully built. Specifically, the aims are to (i) introduce innovative improvements to the existing prototype, making the system suitable for use in clinical routine, (ii) modify the optical tracking system to be compatible with multiple MR sequences, and (iii) perform clinical evaluation.  Our real-time technique is a unique and innovative solution that will improve MRI image quality and thus patient care, and will address the escalating burden of imaging costs on the health care system.",Real-Time MRI Motion Correction System,7987431,R01EB011654,"['Address', 'Adopted', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Articular Range of Motion', 'Base Sequence', 'Basic Science', 'Brain', 'Child', 'Childhood', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer software', 'Data', 'Detection', 'Development', 'Device Safety', 'Devices', 'Diagnosis', 'Disease', 'Economic Burden', 'Educational workshop', 'Elderly', 'Electronics', 'Enrollment', 'Environment', 'Evaluation', 'Family', 'Financial compensation', 'Goals', 'Grant', 'Head', 'Healthcare Systems', 'High Prevalence', 'Image', 'Individual', 'Lead', 'Libraries', 'Magnetic Resonance Imaging', 'Methods', 'Morphologic artifacts', 'Motion', 'Motivation', 'Neurologic', 'Noise', 'Optics', 'Patient Care', 'Patients', 'Physiologic pulse', 'Positioning Attribute', 'Predisposition', 'Procedures', 'Protocols documentation', 'Reliance', 'Research', 'Research Project Grants', 'Resolution', 'Risk', 'Safety', 'Scanning', 'Scheme', 'Sedation procedure', 'Signal Transduction', 'Societies', 'Solutions', 'Speed', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Update', 'Vision', 'Well in self', 'Work', 'aging population', 'analog', 'base', 'body system', 'clinical practice', 'comparative', 'cost', 'data sharing', 'design', 'detector', 'digital', 'human subject', 'image processing', 'improved', 'innovation', 'lens', 'meetings', 'novel marker', 'optical imaging', 'patient population', 'peer', 'programs', 'prospective', 'prototype', 'public health relevance', 'research and development', 'research clinical testing', 'research study', 'tool', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2010,695908,0.025469477573441122
"Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters    DESCRIPTION (provided by applicant): Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance to detect PCa; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project is highly significant because it addresses a major health problem in the United States and other developed countries. The project will overcome the current inability of established clinical-imaging method to image PCa reliably by combining the capabilities of advanced ultrasound (US) and magnetic-resonance (MR) techniques in a clinically effective manner. The proposed approach will exploit the sensitivity of US to mechanical properties of tissue on a microscopic scale with the sensitivity of MR to chemical constituents of tissue and its ability to sense blood distribution. Each of these modalities senses different and independent properties of tissue and has shown encouraging potential for improved imaging of PCa when used alone; combining parameters derived from each modality can provide far superior sensitivity and specificity for PCa. We will combine US and MR parameters using advanced classifiers such as artificial neural networks and support-vector machines. These classifiers already have produced ROC-curve areas of 0.91 for advanced US methods, and the MR methods have demonstrated equivalent ROC-curve areas in many studies. We will embody the combined capabilities in specifications for a prototype imaging system that can generate prostate tissue-typing images (TTIs) in real-time for targeting biopsies or planning treatment in the operating room or in an off-line setting. The latest Logiq E9 instrument currently being produced by GE already has a capability for fusing previously obtained MR images with US images in real time, which provides an existing framework for combining US and MR parameters and generating real-time TTIs. Successfully generating reliable prostate TTIs based on combined US and MR parameters will represent a quantum advance in PCa management by enabling significant improvements in the diagnosis and treatment of PCa.      PUBLIC HEALTH RELEVANCE: Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.           Riverside Research Institute, Beth Israel Deaconess Medical Center, Rutgers University, and the General Electric Corporation propose to undertake an Academic-Industrial Partnership study to improve prostate- cancer (PCA) imaging markedly and thereby improve prostate-biopsy guidance; enhance monitoring, surveillance, and treatment of PCa; and enable planning and execution of focal PCa therapy. The project will combine attributes of advanced ultrasound and magnetic-resonance techniques and embody them in a prototype imaging system capable of generating novel tissue-type images that reliably depict PCa in real-time.",Prostate-cancer Imaging by Combined Ultrasound and Magnetic-resonance Parameters,7989004,R01CA140772,"['Ablation', 'Achievement', 'Acoustics', 'Address', 'Adverse effects', 'Area', 'Atlas of Cancer Mortality in the United States', 'Biological Neural Networks', 'Biopsy', 'Biopsy Specimen', 'Bladder', 'Blood', 'Blood Vessels', 'Chemicals', 'Classification', 'Clinical', 'Computer Assisted', 'Cryosurgery', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Developed Countries', 'Development', 'Diagnosis', 'Diffusion', 'Disease', 'Disease Progression', 'Drug Formulations', 'Engineering', 'Frequencies', 'Generations', 'Gland', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Israel', 'Lead', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Mechanics', 'Medical center', 'Metabolic', 'Methods', 'Microscopic', 'Modality', 'Monitor', 'Morphologic artifacts', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nerve', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Perfusion', 'Process', 'Property', 'Prostate', 'Prostate Cancer therapy', 'Prostate-Specific Antigen', 'Prostatectomy', 'Quantitative Evaluations', 'ROC Curve', 'Radio', 'Radiosurgery', 'Rectum', 'Research', 'Research Institute', 'Resolution', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Signal Transduction', 'Specimen', 'Spectrum Analysis', 'Staging', 'Structure of base of prostate', 'Surface', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Universities', 'Urethra', 'Ursidae Family', 'base', 'blind', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'computerized', 'cost', 'experience', 'high risk', 'image registration', 'imaging modality', 'improved', 'instrument', 'instrumentation', 'interest', 'lymph nodes', 'novel', 'outcome forecast', 'prototype', 'public health relevance', 'quantitative ultrasound', 'quantum', 'response', 'standard care', 'tool', 'treatment planning', 'tumor']",NCI,RIVERSIDE RESEARCH INSTITUTE,R01,2010,723266,-0.014414008307465368
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,7896281,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2010,163457,-0.010894706233885817
"Computational Photography Project for Pill Identification (C3PI) In a national effort to promote patient safety, the National Library of Medicine (NLM) proposes to create a comprehensive, public digital image inventory of the nation's commercial prescription solid dose medications. The primary intention of this effort is create a test data collection for the advancement of automatic pharmaceutical identification through computer analysis from photographic data. NLM expects to promote computer-based image research applied to the domain of content-based information retrieval (CBIR) of solid-dose pharmaceuticals, and anticipates the need for generating a test environment, including variations of photographs of the same drug or sample under different environments. n/a",Computational Photography Project for Pill Identification (C3PI),8174192,76201000698P,"['Algorithms', 'Collection', 'Color', 'Computer Analysis', 'Computer Vision Systems', 'Computers', 'Data', 'Data Collection', 'Dose', 'Environment', 'Equipment', 'Equipment and supply inventories', 'Image', 'Imagery', 'Information Retrieval', 'Intention', 'Measurement', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Photography', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Solid', 'Structure', 'Surface Properties', 'Testing', 'Text', 'United States National Library of Medicine', 'Variant', 'base', 'digital imaging', 'patient safety', 'pill']",NLM,"MEDICOS CONSULTANTS, LLC",N03,2010,500000,-0.0013074313332715143
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of MR techniques and image contrast mechanisms available which can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.        One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While out application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.        Current work is centered around development of support vector machine analysis of degraded cartilage.  We find that this SVM approach may have significant advantages, in particular through a minimization of the over-training potential that occurs when developing a model with a training set for use on validation samples.  In addition, the SVM, like the Gaussian clustering approach, lends itself to a graded assessment of cartilage degradation.  This is through a sigmoidal probability function of the distance of a sample in parameter space from the decision hypersurface. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,8148342,ZIAAG000922,"['Cartilage', 'Characteristics', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Fibrinogen', 'Goals', 'Hydration status', 'Magnetic Resonance Imaging', 'Preparation', 'Process', 'Sensitivity and Specificity', 'Validation', 'base', 'improved', 'in vivo']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2010,513704,-0.02280465319400394
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8136874,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,125017,0.017181425347300768
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8143048,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,76123,0.017181425347300768
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7876805,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,676574,0.017181425347300768
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,7901378,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'Muscle Rigidity', 'NMR Spectroscopy', 'Negative Staining', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'public health relevance', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2010,273363,-0.02296349915593097
"High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI    DESCRIPTION (provided by applicant):  Understanding normal and abnormal patterns of brain development in fetuses and neonates is a key factor in early detection of developmental disorders. This project proposal seeks to develop and refine novel magnetic resonance image reconstruction and analysis methodology to allow, for the first time, the mapping of in-utero fetal brain development. One of the most common abnormalities detected by clinical imaging of the developing fetal brain is ventriculomegaly, which, despite the absence of other clinical or imaging findings, is associated with neurodevelopmental disabilities in infancy and childhood in up to 50% of cases. Although ultrasound allows diagnosis of the condition, it has not been able to distinguish those fetus that will have poor neurological outcome from those with normal outcome. Recent developments in fast magnetic resonance imaging have permitted the use of MRI to study the fetal anatomy and this technique is now being routinely used at a small number of sites around the world including UCSF. However, MR imaging of the fetal brain is still challenging because of imaging distortions caused by motion of the fetus within the mother and by artifacts caused by the surrounding maternal anatomy. Higher resolution or 3D acquisitions are not possible because of motion of the fetus during the acquisition time^ required. The current clinical 2D slice data individually provide limited resolution and contrast and, most importantly, often contain severe motion corruption between slices. This project is motivated by the observation that it is possible to apply computer vision and image processing techniques to correct relative motion between the multiple stacks of low resolution fetal slices, and create a single volumetric image with high isotropic 3D resolution and consistent geometry. Such higher resolution images provide structure that may be analyzed using computational morphometric techniques that can detect subtle focal differences in the pattern of tissue volume, location and surface folding. This project will combine such powerful techniques with extensive fetal and neonatal imaging experience at UCSF, allowing direct clinical application of the methodology to study morphologic aberrations associated with ventriculomegaly and to correlate these with clinical outcome. The ability to apply these computational techniques to in-utero data will provide an entirely new view of the developing brain, which promises to shed new light on early developmental problems both in fetuses and premature neonates.           n/a",High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI,8287830,R01NS055064,[' '],NINDS,UNIVERSITY OF WASHINGTON,R01,2010,223596,0.008574484874814756
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7560409,R01NS051826,"['Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Back', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Disease', 'Disease Progression', 'Evaluation', 'Fetal Growth Retardation', 'Goals', 'Gold', 'Human', 'Image', 'Imagery', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Modeling', 'Neonatal', 'Normal Range', 'Operative Surgical Procedures', 'Patients', 'Population', 'Population Study', 'Process', 'Research', 'Schizophrenia', 'Shapes', 'Statistical Distributions', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'base', 'computer studies', 'disease classification', 'feeding', 'improved', 'neonate', 'nervous system disorder', 'normal aging', 'novel', 'shape analysis', 'tool']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2009,280500,-0.001015016704282184
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7739714,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2009,104963,0.03663359618523319
"Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage MRI is increasingly used to assess cartilage, with the overall goal of relating noninvasive measurements to the actual biophysical status of the tissue.  There are a variety of MR techniques and image contrast mechanisms available which can be evaluated in terms of their ability to characterize tissue status, both in experimental preparations and in the clinical setting:  T2 is sensitive to tissue hydration, collagen content, and collagen orientation with respect to the main magnetic field; diffusion (D) is sensitive to macromolecular content and hydration; T1 is sensitive primarily to PG content, as is the dGEMRIC index.  Magnetization transfer (MT) studies primarily reflect collagen content.  Heteronuclear studies have also been performed, with the Na+ signal intensity being sensitive to local PG content.   All of these measurements exhibit utility in certain circumstances.  However, all are of limited specificity, with a large overlap observed between values measured in normal cartilage and e.g. degraded cartilage, or between different regions of cartilage.        Parameter combinations can be more specific than single parameters; a variety of multi-parametric approaches have been applied, particularly to image segmentation.  A robust approach is k-means clustering.  In our application, cluster centroids are calculated based on a scatterplot with respect to measured parameters.  A data point is then assigned to the cluster with the closer centroid.  There will be a certain number of misclassifications with real, imperfectly clustered, data, but the analysis is expected to be substantially more accurate than univariate classifications.        One factor determining the success of the algorithm is the degree of independence of the measured parameters, so that careful selection of these is essential.  Similarly, clustering can be performed with any number of independent outcome variables; the two-parameter case was illustrated above. These outcome variables can also be derived from entirely different modalities, such as use of MRI in conjunction with FT-IRIS outcome measures.  A further extension of the basic k-means clustering algorithm is fuzzy k-means, where tissue is designated as belonging to a particular cluster to a specified degree.  This is of particular utility when the dataset does not break into defined clusters, as in cartilage analysis.  An additional extension of the basic algorithm removes the requirement for pre-defining the number of clusters within the data.  This may not be required in experimental situations in which the goal is to distinguish two discrete groups, such as normal and degraded cartilage.  However, it may be very useful in realistic situations with more subtle gradations of tissue quality.  Finally, we note that different distance metrics may be applied, permitting relative weighting of the outcome measures.      We have tried multiple approaches to this problem, with the best results to date resulting from a cluster analysis based on parameterized cluster shapes, sizes, and orientations.        Additional analysis has demonstrated that under severe degradation, the conventional univariate analysis based on comparison of sample values with category means provides reasonable sensitivity and specificity.  However, with more subtle degradation, we have found that model-based classification using Gaussian clusters is substantially more effective for classification. The probabalistic nature of this analysis lends itself readily to fuzzy clustering as well. While out application has been to cartilage degradation, the approach is much more general and may be useful in materials classification in general with magnetic resonance.  Further ongoing work is centered around development of support vector machine analysis of degraded cartilage. n/a",Improving Sensitivity and Specificity of Parametric MRI Assessment of Cartilage,7964089,ZIAAG000922,"['Algorithms', 'Cartilage', 'Categories', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Collagen', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion', 'Exhibits', 'Fibrinogen', 'Goals', 'Hydration status', 'Imaging Techniques', 'Iris', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metric', 'Modality', 'Modeling', 'Multivariate Analysis', 'Nature', 'Outcome', 'Outcome Measure', 'Preparation', 'Process', 'Relative (related person)', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Specific qualifier value', 'Specificity', 'Tissues', 'Weight', 'Work', 'articular cartilage', 'base', 'imaging Segmentation', 'improved', 'in vivo', 'indexing', 'magnetic field', 'progesterone 11-hemisuccinate-(2-iodohistamine)', 'success']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2009,404073,-0.023710784682616216
"AUTOMATIC QUANTITATIVE CT IMAGING OF PERICARDIAL FAT: A NOVEL ISCHEMIA PREDICTOR    DESCRIPTION (provided by applicant): Every year, 1 million people in the US will experience a heart attack or sudden cardiac death. A large percentage of these patients have no prior symptoms of any kind but suffer from silent heart disease (ischemia), which may cause a heart attack at any time. Currently there is no reliable screening method to identify people who may have silent heart disease and therefore are at risk of ""heart attack"".       We seek to extract additional data from a non-invasive Computed Tomography (CT) scan of the heart (commonly used in most imaging centers), which will better identify patients who are ""vulnerable"" to sudden heart attack. These images are acquired without contrast agents, as a common screening test for measuring coronary calcium, another clinical marker of coronary artery disease. We will prove that additional information about cardiovascular risk can be obtained by quantifying pericardial fat surrounding the heart in these cardiac CT images. Although this information exists in the cardiac CT scans acquired today, it is ignored in clinical practice because currently there are no tools to measure it automatically and reliably, and no information regarding its significance for a given patient.       We will develop fully automated, accurate, new computer software for quantitation of pericardial fat from cardiac CT images acquired for routine assessment of coronary calcium. We plan to achieve complete automation and accuracy, by applying a combination of robust and effective algorithms in machine learning with anatomical knowledge. We aim to prove that the developed automatic software will be as accurate, and more reproducible than experienced imaging physicians in quantifying pericardial fat, and will accomplish the measurement in a fraction of the time. Such software could be immediately made available worldwide to standard imaging workstations. For the first time, this will allow its use as a standard practical imaging tool for cardiovascular risk assessment, without requiring additional time, imaging or radiation risk to the patient.       We will also show that this new quantitative information has important additional value compared to other clinical cardiovascular risk factors and information from blood samples (such as cholesterol, glucose and CRP), and the amount of calcium in the patient's coronary arteries seen on CT scans, and establish its significance in the prediction of silent heart disease.      PUBLIC HEALTH RELEVANCE: This new research will allow accurate prediction of who might be more likely to have heart disease which may ultimately cause a heart attack. It will allow doctors to identify patients for whom appropriate treatment could be prescribed to avoid a heart attack, or more extensive testing, could be recommended, to confirm or rule out heart disease.          n/a",AUTOMATIC QUANTITATIVE CT IMAGING OF PERICARDIAL FAT: A NOVEL ISCHEMIA PREDICTOR,7588839,R21EB006829,"['Abdomen', 'Algorithms', 'Automation', 'Biochemical', 'Blood specimen', 'C-reactive protein', 'Calcium', 'Cardiac', 'Cholesterol', 'Clinical', 'Clinical Markers', 'Computational algorithm', 'Computer software', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Development', 'Diagnostic', 'Evaluation', 'Fatty acid glycerol esters', 'Glucose', 'Goals', 'Heart', 'Heart Diseases', 'Image', 'Imaging Device', 'Ischemia', 'Knowledge', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Myocardial Infarction', 'Patients', 'Pericardial body location', 'Physicians', 'Predictive Value', 'Radiation', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Scanning', 'Screening procedure', 'Symptoms', 'Testing', 'Time', 'Visceral', 'X-Ray Computed Tomography', 'base', 'cardiovascular risk factor', 'clinical practice', 'experience', 'heart imaging', 'indexing', 'novel', 'public health relevance', 'sudden cardiac death', 'tool', 'waist circumference']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R21,2009,196375,0.007506705609661426
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7641582,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Classification', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,UNIVERSITY OF MISSOURI KANSAS CITY,R21,2009,219972,0.02680482650913043
"Instrumentation and Bioengineering Development and Application Development of unique instrumentation using novel approaches is, in many instances, necessary to the success of biomedical research. Areas of emphasis within our group are summarized below.  In collaboration with Dr. Richard Hendler, NHLBI, a modified version of a high speed optical multichannel spectrometer, developed previously, has been enhanced in terms of temporal and signal amplitude resolution. The kinetics of the bacteriorhodopsin (BR) photocycle, initiated with a synchronized laser pulse (532nm, 7ns), are being studied using an optical system that follows the spectral changes associated with the transient intermediates of the photocycle. Complete spectra from approximately 400nm to 700nm are collected with less than 10 microsecond resolution, permitting extraction, though single value decomposition analysis, of the role of the intermediates. These studies support the view that the BR photocycle consists of two parallel cycles instead of a single photocycle favored by other groups. To adapt to the next phase of this project, which entails collecting infrared data, a collaboration has been established with the National Institute of Standards and Technology (NIST). The optical system has been relocated to the Center for Advanced Research in Biology of which NIST is a member.  The realigned system incorporates both the high-speed multichannel analyzer and the infrared spectrometer that has permitted capturing a parallel data set of infrared spectral data.  Combined optical and spectral kinetic data studies will allow characterization of the structural information for each step in the photocycle.  Our ultimate goal is to apply the same approaches to time-resolved X-ray diffraction using BR membrane crystals thus obtaining structural information at the atomic level to visualize protein conformational changes resulting from the electrogenic movement of protons across the membrane.  To capture the necessary spectral information across the complete visible spectrum with time resolution under 200ns, an optical instrument has been designed to accommodate a charge-coupled device (CCD) camera, an image intensifier that are attached to a spectrograph. The dispersed spectrographic data is positioned on two rows of the CCDs photon detector (1048 rows of 512 pixels) thus enabling collection of spectra of 524 wavelengths at 512 different points in time.  To record points that are staggered in time to account for the different lifetimes of the BR photocycle intermediates a time gated image intensifier  will be integrated into the instrument.  Time synchronization is achieved through custom electonic hardware and software developed by CIT colleagues.  This year we have demonstrated the capability to collect spectral data from sample volumes of 12nl.  To achieve this required fabrication of a custom cell incorporating fiber optic technology to carry monitoring light to the sample and deliver through a 200 micron fiber the spectral information to the spectrograph.  In lieu of the laser photolysis, we were able to initiate the photocycle through 532 nm carried by a 600 micron fiber.  To simulate the laser pulse, a 100 micron pinhole in a wheel rotating at 100 Hz was placed in the fiber optic path using a microscope objective to focus the 5W laser beam through the pinhole.  A complete description of the results is presented in Dr. Hendler's annual report.  In collaboration with Dr. Janine Smith, NEI, an ocular imaging system for measuring dry eye severity has being developed and is undergoing evaluation for clinical use. The method uses the Oxford Scheme for grading ocular staining in dry eyes using various dyes. The software that processes the ocular images will be tested in the clinic in conjunction with a slit bio-microscope. The image analysis uses a support vector machine algorithm from statistical learning theory. Based on the clinical feedback a subsequent instrument development may be necessary to improve image capture that will enable image enhancement, and the correction of imaging defects. This system will enhance image quality by minimizing the potential effects of eye movement, glare, vignetting, lens distortion, noise, and non-uniform eye lighting. System and monitor calibration techniques for color management and white balance will be developed. It is anticipated that further improvement to image quality would be obtained by standardizing  the instillation and timing of dye administration to account for time dilution of dye staining. A database will be developed for storing patient information and history, and to save patient images. Both the instrument and software will be initiated using a semi-automated system with the goal of future development as a fully automatic system.  In collaboration with Drs. Dietrich Haubenberger and Mark Hallett, NINDS, a system has been designed for a wireless sensor to be placed on the wrist of Parkinson's disease patients to analyze limb motion.  Initial assembly has taken place.  It will measure intensity, frequency and duration of tremors due to Parkinsons disease. The system will use a Shimmer mote platform consisting of a microcontroller, transceiver and sensors. n/a",Instrumentation and Bioengineering Development and Application,7967869,ZIAEB000011,"['Accounting', 'Algorithms', 'Annual Reports', 'Area', 'Bacteriorhodopsins', 'Biology', 'Biomedical Engineering', 'Biomedical Research', 'Calibration', 'Cells', 'Clinic', 'Clinical', 'Collaborations', 'Collection', 'Color', 'Computer software', 'Custom', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Device or Instrument Development', 'Discipline', 'Dyes', 'Engineering', 'Equilibrium', 'Eye', 'Eye Movements', 'Feedback', 'Fiber', 'Fiber Optics', 'Frequencies', 'Future', 'Glare', 'Goals', 'Image', 'Image Analysis', 'Image Enhancement', 'Institutes', 'Intramural Research Program', 'Kinetics', 'Laboratories', 'Lasers', 'Light', 'Lighting', 'Limb structure', 'Machine Learning', 'Measures', 'Membrane', 'Methods', 'Microscope', 'Mission', 'Monitor', 'Motion', 'Movement', 'National Heart, Lung, and Blood Institute', 'National Institute of Neurological Disorders and Stroke', 'Noise', 'Optical Instrument', 'Optics', 'Parkinson Disease', 'Patients', 'Phase', 'Photons', 'Physiologic pulse', 'Positioning Attribute', 'Process', 'Proteins', 'Protons', 'Recording of previous events', 'Research', 'Resolution', 'Role', 'Sampling', 'Scheme', 'Scientist', 'Severities', 'Signal Transduction', 'Simulate', 'Speed', 'Staining method', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tremor', 'United States National Institutes of Health', 'Wireless Technology', 'Wrist', 'X ray diffraction analysis', 'X-Ray Diffraction', 'base', 'charge coupled device camera', 'design', 'detector', 'eye dryness', 'improved', 'instrument', 'instrumentation', 'lens', 'member', 'novel strategies', 'photolysis', 'physical science', 'research clinical testing', 'sensor', 'software development', 'success', 'theories']",NIBIB,NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING,ZIA,2009,146101,0.018313426117712406
"Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging    DESCRIPTION (provided by applicant): Dementia represents a major public health problem which will grow significantly with the aging of our society. Recently, multiple pieces of converging clinical and neuropathological data indicate that dementia is typically a multi-factorial process. This evolution in thinking about the biology of dementia comes at a time when the most significant recent development in dementia imaging has been the introduction of amyloid plaque labeling compounds; the most widely studied at this point is Pittsburgh Compound - B (PiB). A central principle underlying this renewal is this. Amyloid imaging is unquestionably a major advance. However, since the biology of dementia is more complex than brain amyloidosis alone, imaging of dementia is more complex than brain amyloid imaging alone. Our primary goal in this renewal is to use various imaging modalities to identify different mechanisms underlying dementia. This is the first resubmission of a competitive renewal of AG11378. We have revised the grant in accordance with each point raised in the critique and we believe this has resulted in a much stronger application. Each of the five aims is cast to answer variations on the questions: What is the contribution of specific imaging-based proxies of pathology to clinical/cognitive decline? When in the course of the disease do these relationships hold true? For whom is this true? Where in the brain are the relevant pathologies expressed? Principle outcome measures will be clinical and psychometric decline over time which we will use as indicators of disease progression. Our predictor variables will include various imaging modalities which will serve as proxies for specific pathologic mechanisms underlying dementia. PiB will serve as a measure of plaque burden and we will use various Magnetic Resonance Imaging (MRI) modalities to assess cerebro- vascular disease, tissue loss, tissue perfusion, diffusion, neuronal integrity, and inflammation. Features that distinguish this renewal from past cycles of AG11378 include a mechanistic focus, multi- modality imaging including multiple MRI modalities as well as PET amyloid imaging, MR imaging now at 3T, inclusion of both amnestic and non-amnestic MCI, and voxel-based analytic methods including an exciting new computational approach which employs a support vector machine algorithm to provide diagnosis in individual subjects. In addition, subjects will now be recruited from a new population-based study of aging and dementia, which differentiates this renewal from past cycles as well as from most dementia imaging studies which recruit from referral practices and thus risk sampling bias. Previous cycles of this grant have contributed significantly to recognition of the utility of imaging in dementia. An active debate is currently underway about revising clinical criteria for AD, specifically whether imaging and fluid biomarker information should be included among the criteria. Results from this renewal grant will inform this debate about multiple time dependent mechanisms leading to dementia that are accessible in living subjects through imaging. PUBLIC HEALTH RELEVANCE: Identifying Mechanisms of Dementia: Role for MRI in the Era of Molecular Imaging (AG11378) Dementia is a leading public health problem now and will have an increasingly serious impact on public health as the number of elderly individuals increase. Dementia has many possible underlying causes and several different causes are at work in most elderly demented subjects. In this grant, we will use modern brain imaging to identify specific mechanisms underlying progression to dementia.          n/a",Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging,7919029,R01AG011378,"['6-hydroxybenzothiazole', 'Abbreviations', 'Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease Pathway', 'Amyloid deposition', 'Amyloidosis', 'Anatomy', 'Anisotropy', 'Applications Grants', 'Attenuated', 'Autopsy', 'Base of the Brain', 'Binding', 'Biological Markers', 'Biology', 'Biostatistical Methods', 'Brain', 'Brain Mapping', 'Brain imaging', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Clinical Pathology', 'Cognition', 'Cognitive', 'Complex', 'Correlation Studies', 'Critiques', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Elderly', 'Enrollment', 'Epidemiologic Studies', 'Event', 'Evolution', 'Future', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Inflammation', 'Inositol', 'Knowledge', 'Label', 'Life', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measures', 'Memory', 'Methods', 'Metric', 'Modality', 'Modeling', 'N-acetylaspartate', 'Neurofibrillary Tangles', 'Neurons', 'Outcome', 'Outcome Measure', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Perfusion', 'Pittsburgh Compound-B', 'Population', 'Positron-Emission Tomography', 'Process', 'Proxy', 'Psychometrics', 'Public Health', 'Recovery', 'Recruitment Activity', 'Relative (related person)', 'Resolution', 'Risk', 'Role', 'Sampling', 'Sampling Biases', 'Scheme', 'Senile Plaques', 'Severity of illness', 'Societies', 'Spin Labels', 'Staging', 'Study Subject', 'Symptoms', 'Synapses', 'Syndrome', 'Text', 'Thinking', 'Time', 'Tissues', 'Variant', 'Vascular Diseases', 'Work', 'amyloid imaging', 'base', 'clinical Diagnosis', 'cohort', 'imaging modality', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular imaging', 'morphometry', 'neuroimaging', 'population based', 'primary outcome', 'public health relevance', 'tool']",NIA,MAYO CLINIC ROCHESTER,R01,2009,237227,-0.031041979167451425
"Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging DESCRIPTION (provided by applicant): Dementia represents a major public health problem which will grow significantly with the aging of our society. Recently, multiple pieces of converging clinical and neuropathological data indicate that dementia is typically a multi-factorial process. This evolution in thinking about the biology of dementia comes at a time when the most significant recent development in dementia imaging has been the introduction of amyloid plaque labeling compounds; the most widely studied at this point is Pittsburgh Compound - B (PiB). A central principle underlying this renewal is this. Amyloid imaging is unquestionably a major advance. However, since the biology of dementia is more complex than brain amyloidosis alone, imaging of dementia is more complex than brain amyloid imaging alone. Our primary goal in this renewal is to use various imaging modalities to identify different mechanisms underlying dementia. This is the first resubmission of a competitive renewal of AG11378. We have revised the grant in accordance with each point raised in the critique and we believe this has resulted in a much stronger application. Each of the five aims is cast to answer variations on the questions: What is the contribution of specific imaging-based proxies of pathology to clinical/cognitive decline? When in the course of the disease do these relationships hold true? For whom is this true? Where in the brain are the relevant pathologies expressed? Principle outcome measures will be clinical and psychometric decline over time which we will use as indicators of disease progression. Our predictor variables will include various imaging modalities which will serve as proxies for specific pathologic mechanisms underlying dementia. PiB will serve as a measure of plaque burden and we will use various Magnetic Resonance Imaging (MRI) modalities to assess cerebro- vascular disease, tissue loss, tissue perfusion, diffusion, neuronal integrity, and inflammation. Features that distinguish this renewal from past cycles of AG11378 include a mechanistic focus, multi- modality imaging including multiple MRI modalities as well as PET amyloid imaging, MR imaging now at 3T, inclusion of both amnestic and non-amnestic MCI, and voxel-based analytic methods including an exciting new computational approach which employs a support vector machine algorithm to provide diagnosis in individual subjects. In addition, subjects will now be recruited from a new population-based study of aging and dementia, which differentiates this renewal from past cycles as well as from most dementia imaging studies which recruit from referral practices and thus risk sampling bias. Previous cycles of this grant have contributed significantly to recognition of the utility of imaging in dementia. An active debate is currently underway about revising clinical criteria for AD, specifically whether imaging and fluid biomarker information should be included among the criteria. Results from this renewal grant will inform this debate about multiple time dependent mechanisms leading to dementia that are accessible in living subjects through imaging. PUBLIC HEALTH RELEVANCE: Identifying Mechanisms of Dementia: Role for MRI in the Era of Molecular Imaging (AG11378) Dementia is a leading public health problem now and will have an increasingly serious impact on public health as the number of elderly individuals increase. Dementia has many possible underlying causes and several different causes are at work in most elderly demented subjects. In this grant, we will use modern brain imaging to identify specific mechanisms underlying progression to dementia. n/a",Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging,7683735,R01AG011378,"['6-hydroxybenzothiazole', 'Abbreviations', 'Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease Pathway', 'Amyloid deposition', 'Amyloidosis', 'Anatomy', 'Anisotropy', 'Applications Grants', 'Attenuated', 'Autopsy', 'Base of the Brain', 'Binding', 'Biological Markers', 'Biology', 'Biostatistical Methods', 'Brain', 'Brain Mapping', 'Brain imaging', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Clinical Pathology', 'Cognition', 'Cognitive', 'Complex', 'Correlation Studies', 'Critiques', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Elderly', 'Enrollment', 'Epidemiologic Studies', 'Event', 'Evolution', 'Future', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Inflammation', 'Inositol', 'Knowledge', 'Label', 'Life', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measures', 'Memory', 'Methods', 'Metric', 'Modality', 'Modeling', 'N-acetylaspartate', 'Neurofibrillary Tangles', 'Neurons', 'Outcome', 'Outcome Measure', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Perfusion', 'Pittsburgh Compound-B', 'Population', 'Positron-Emission Tomography', 'Process', 'Proxy', 'Psychometrics', 'Public Health', 'Recovery', 'Recruitment Activity', 'Relative (related person)', 'Resolution', 'Risk', 'Role', 'Sampling', 'Sampling Biases', 'Scheme', 'Senile Plaques', 'Severity of illness', 'Societies', 'Spin Labels', 'Staging', 'Study Subject', 'Symptoms', 'Synapses', 'Syndrome', 'Text', 'Thinking', 'Time', 'Tissues', 'Variant', 'Vascular Diseases', 'Work', 'amyloid imaging', 'base', 'clinical Diagnosis', 'cohort', 'imaging modality', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular imaging', 'morphometry', 'neuroimaging', 'population based', 'primary outcome', 'public health relevance', 'tool']",NIA,MAYO CLINIC ROCHESTER,R01,2009,1043699,-0.031041979167451425
"Accurate detection of chromosomal abnormalities with multi-color image processing    DESCRIPTION (provided by applicant): The combination of high resolution assays in genomics with microscopic imaging has been used for the detection of complex chromosomal rearrangements, a significant but difficult problem in prenatal and postnatal diagnosis, birth defect detection and cancer research. As a recently developed molecular cytogenetic technique, multiplex fluorescence in situ hybridization (M-FISH) imaging has provided rapid and high resolution detection of chromosomal abnormalities associated with cancer and genetic disorders. However, the technique is currently limited to research use and only serves as an adjunct tool to the G-banding based monochromatic chromosomal karyotyping in a clinical laboratory. A primary barrier of the technique is the lower classification accuracy when classifying chromosomes from multi-color microscopic imaging data. Therefore, the goal of this R15 project is to develop innovative multi-spectral image processing and machine learning techniques for M-FISH image analysis so that chromosomal rearrangement detection can be made more reproducible, robust, and faster, thereby significantly increasing the ability and efficacy of this newly developed cellular imaging technique. Our proposed approaches such as multiscale feature extraction, nonlinear manifold analysis and adaptive fuzzy clustering are able to target specific features of multi-spectral imaging data, promising a significant improvement over the current techniques. In order to validate the technique and bring it into clinical use, we will partner with a clinical geneticist, Dr. Merlin Butler, and a cytogeneticist, Dr. Diane Persons both at Kansas University Medical Center. In addition, we will collaborate with an industrial scientist, Dr. Kenneth Castleman, who is the pioneer in developing and commercializing cytogenetic imaging products. Through our interdisciplinary research and collaboration, we will accomplish the following specific aims: 1) develop image normalization approaches to improve the acquisition of multi-color FISH images; 2) develop multiscale dimension analysis to extract features from multi-color images; 3) design adaptive fuzzy clustering and incorporate contextual information to improve the pixel-wise classification of chromosomes; and 4) validate computational approaches with clinical testing in collaboration with medical and industrial partners. This research project will also enhance our research infrastructure in biomedical image informatics and provide undergraduate and graduate students opportunities to touch the frontier of molecular and cellular imaging by participating in the proposed research activities. PUBLIC HEALTH RELEVANCE: Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.           Project Narrative Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.",Accurate detection of chromosomal abnormalities with multi-color image processing,7727717,R15GM088802,"['Academic Medical Centers', 'Academic Research Enhancement Awards', 'Address', 'Algorithms', 'Biological Assay', 'Cells', 'Chromosomal Rearrangement', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 4', 'Cities', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Color', 'Communities', 'Complex', 'Computational Technique', 'Congenital Abnormality', 'Cytogenetic Analysis', 'Cytogenetics', 'DNA Sequence Rearrangement', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Engineering', 'Environment', 'Figs - dietary', 'Fluorescent in Situ Hybridization', 'G-Banding', 'Genetic', 'Genomics', 'Goals', 'Health Benefit', 'Hereditary Disease', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging problem', 'Interdisciplinary Study', 'Kansas', 'Karyotype', 'Karyotype determination procedure', 'Laboratories', 'Learning', 'Machine Learning', 'Masks', 'Medical', 'Methods', 'Microscopic', 'Missouri', 'Molecular Probes', 'Neurofibromin 2', 'Patients', 'Persons', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Project Grants', 'Resolution', 'Resources', 'Schools', 'Scientist', 'Signal Transduction', 'Spectral Karyotyping', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Training', 'United States National Institutes of Health', 'Universities', 'anticancer research', 'assay development', 'base', 'bioimaging', 'cancer diagnosis', 'cancer genetics', 'cellular imaging', 'clinical application', 'clinical effect', 'design', 'experience', 'frontier', 'graduate student', 'high throughput screening', 'image processing', 'imaging informatics', 'improved', 'innovation', 'leukemia', 'meetings', 'molecular/cellular imaging', 'multidisciplinary', 'novel', 'postnatal', 'prenatal', 'prevent', 'programs', 'public health relevance', 'research clinical testing', 'response', 'tool']",NIGMS,UNIVERSITY OF MISSOURI KANSAS CITY,R15,2009,229519,0.012335349575509753
"Technology Development for 3D Electron Microscopy Several new technologies have been developed from our work over the last couple of    years. In a collaboration with GATAN Inc., we reported the development of a novel,    multi-specimen imaging system for high-throughput transmission electron microscopy that    circumvents time-consuming steps involved in manual specimen loading. This cartridge-based    loading system, called the Gatling, permits the sequential examination of as many as 100    specimens in the microscope for room temperature electron microscopy using mechanisms for    rapid and automated specimen exchange. This is now available commercially under the trade name    Select 100. We anticipate that the availability of this accessory will greatly accelerate the    speed of data acquisition for a variety of applications in biology, materials science and    nanotechnology that require rapid screening and image analysis of multiple specimens. We have    developed a complete framework for alignment, classification, and averaging of volumes derived    by electron tomography that is computationally efficient and effectively accounts for the    missing wedge that is inherent to limited angle electron tomography. Modeling the missing data    as a multiplying mask in reciprocal space we have shown that the effect of the missing wedge    can be accounted for seamlessly in all alignment and classification operations. We solve the    alignment problem using the convolution theorem in harmonic analysis, thus eliminating the    need for approaches that require exhaustive angular search, and adopt an iterative approach to    alignment and classification that does not require the use of external references. We also    demonstrated that our method could be successfully applied for 3D classification and averaging    of phantom volumes as well as experimentally obtained tomograms of GroEL where the outcomes of    the analysis can be quantitatively compared against the expected results. The development of    these tools proved to be critical for our successful effort in determining the structure of    trimeric HIV-1 envelope glycoproteins. Another area of focus has been on image processing and    segmentation. Previous studies using nonlinear anisotropic methods, wavelet based methods and    filtering have already demonstrated the value of image denoising in various 2D and 3D    datasets. The existing methods usually consider clean data (or assume that clean data is    available) and artificially add different types of noise to the clean data and then denoise    the noisy data assuming that the statistics of noise is known using various algorithms. We    have investigated the use of transform-domain denoising techniques and feature extraction to    improve quantitative interpretation of cryo electron tomograms of viruses and cells. In our    approach, we have used four metrics for analysis including the Kullback-Leibler (KL) distance    based GOF test, Fourier ring correlation and single-image SNR to iteratively obtain the    optimal denoising algorithm for a given 3D volume. Using these methods, we showed that    denoising, when used with care is an enormously powerful tool for the automated interpretation    of complex 3D data sets at high throughput. In continued developments for automated image    analysis, we have developed a machine-learning tool for automatic texton-based joint    classification and segmentation of mitochondria in MNT-1 cells imaged using ion-abrasion    scanning electron microscopy (IA-SEM). For diagnosing signatures that may be unique to    cellular states, automatic tools with minimal user intervention need to be developed for    high-throughput data mining and analysis of these large volume data sets (typically    2GB/cell). Challenges for developing such a tool in 3D electron microscopy arise in particular    due to low contrast and low signal-to-noise ratios (SNR). Our approach is based on block-wise    classification of images into a trained list of regions. Classification is performed using a    k-nearest neighbor (k-NN) classifier, support vector machines (SVMs), adaptive boosting    (AdaBoost) and histogram matching using an NN classifier. In addition, we study the    computational complexity vs. segmentation accuracy tradeoff of these classifiers. Segmentation    results demonstrate that our approach using minimal training data performs close to    semi-automatic methods using the variational level-set method and manual segmentation by an    experienced user. We apply the method to investigate quantitative parameters such as volume of    the cytoplasm occupied by mitochondria, differences between the surface area of inner and    outer membranes and mean mitochondrial width that are representative quantities that may have    relevance to distinguishing cancer cells from normal cells. Chemical definition of complex    protein assemblies is integral to interpreting 3D structure. We have explored a general    approach for the determination of absolute amounts and the relative stoichiometry of proteins    in a mixture using fluorescence and mass spectrometry. We engineered a gene to express green    fluorescent protein (GFP) with a synthetic fusion protein (GABGFP) in Escherichia coli to    function as a spectroscopic standard for the quantification of an analogous stable    isotope-labeled, non-fluorescent fusion protein (GAB*) and for the quantification and    stoichiometric analysis of purified transducin, a heterotrimeric G-protein complex. Using our    approach, the stoichiometry of the three transducin subunits was measured to be 1:1.1:1.15    over a 5-fold range of labeled internal standard with a relative standard deviation of 9%.    Fusing a unique genetically coded spectroscopic signal element with concatenated proteotypic    peptides provides a powerful method to accurately quantify and determine the relative    stoichiometry of multiple proteins present in complexes or mixtures that cannot be readily    assessed using classical gravimetric, enzymatic, or antibody-based technologies. Over the last    year, we also took delivery of the first FEI Titan Krios automated electron microscope    installed in the US. The work on this microscope has been conducted under the auspices of a    collaboration between NCI and FEI Company aimed at advancing the throughput, level of    automation and resolution of 3D electron microscopy. This microscope is integral and essential    to our ongoing efforts at determining the structure of HIV envelope glycoproteins and    structure of the bacterial apparatus for chemotaxis. n/a",Technology Development for 3D Electron Microscopy,7965729,ZIABC010826,"['Accounting', 'Adopted', 'Algorithms', 'Antibodies', 'Area', 'Automation', 'Biology', 'Cancer Biology', 'Caring', 'Cells', 'Chemicals', 'Chemotaxis', 'Chimeric Proteins', 'Classification', 'Code', 'Collaborations', 'Complex', 'Cytoplasm', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Elements', 'Engineering', 'Escherichia coli', 'Fluorescence', 'Foundations', 'Genes', 'Glycoproteins', 'Government Agencies', 'Green Fluorescent Proteins', 'HIV', 'HIV-1', 'Heterotrimeric GTP-Binding Proteins', 'Housing', 'Image', 'Image Analysis', 'Imaging technology', 'Industry', 'Intervention', 'Ions', 'Joints', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Masks', 'Mass Spectrum Analysis', 'Measures', 'Membrane', 'Methods', 'Metric', 'Microscope', 'Mitochondria', 'Modeling', 'Molecular', 'Names', 'Nanotechnology', 'Noise', 'Normal Cell', 'Operative Surgical Procedures', 'Outcome', 'Peptides', 'Proteins', 'Relative (related person)', 'Reporting', 'Resolution', 'Scanning Electron Microscopy', 'Science', 'Screening procedure', 'Signal Transduction', 'Specimen', 'Speed', 'Stable Isotope Labeling', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Tissues', 'Titan', 'Tomogram', 'Training', 'Transducin', 'Transmission Electron Microscopy', 'Virus', 'Width', 'Work', 'base', 'cancer cell', 'cellular imaging', 'computer studies', 'data acquisition', 'data mining', 'electron tomography', 'experience', 'glycoprotein structure', 'image processing', 'improved', 'new technology', 'novel', 'protein complex', 'statistics', 'stoichiometry', 'technology development', 'three dimensional structure', 'tool', 'tool development']",NCI,DIVISION OF BASIC SCIENCES - NCI,ZIA,2009,1052305,-0.022776802570479843
"Development And Applications Of The Open Microscopy Environment (OME) In previous years, we've re-written the OME analysis system to make it more robust and efficient (1), added an internationalization layer that includes a complete translation of both the user interface and the underlying semantic framework into Spanish, and have contributed to our collaborations that have further refined OME's user interface, as well as its underlying infrastructure (6).  However, the bulk of the work in this project this year has been the validation of the WND-CHARM pattern recognition algorithm we have worked on for several years.  WND-CHARM is a generalized pattern-recognition algorithm that can be used to analyze any type of image.  We have validated the accuracy and generality of this approach using standard benchmark suites used for pattern recognition by the machine vision community, including face recognition, object recognition, and other non-biological classification problems (2).  Due to the lack of biologically and medically oriented machine-vision benchmarks, we have developed our own benchmark suite to foster interest by the wider machine vision community.  This comprises over 20 GB of image data spanning 11 different biological imaging problems, ranging from sub-cellular organelle identification to image-based screening, to medical diagnosis. Different imaging modalities are also represented including fluorescence microscopy, differential-interference contrast, phase-contrast and H&E stained brightfield.  This image collection and benchmark has been made freely available to the public (http://ome.grc.nia.nih.gov/iicbu2008) (5).  One of the WND-CHARM validations we performed resulted from an image dataset we used in our medical imaging project (AG000685-02: Pattern recognition in medical imaging).  Here we were able to use knee X-Rays for biometric identification, which is the first example we are aware of that used internal tissue structures to identify individuals (3).  While WND-CHARM is not yet fully integrated with OME, we published the source-code for this utility as well as a ""field manual"" for its practical applications to imaging problems (4).  In the coming year, we plan to test integrations of WND-CHARM with our existing OME platform as well as the OMERO platform being developed in Dr. Swedlow's lab in Dundee, Scotland.  WND-CHARM is very computationally intensive and places enormous demands on an image informatics framework to supply it with images to analyze as well as consume and organize its outputs.  The relative performance of these two systems will be critical for determining which of the two platforms to use in integration. n/a",Development And Applications Of The Open Microscopy Environment (OME),7969905,ZICAG000671,"['Address', 'Algorithms', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Biometry', 'Blast Cell', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Ensure', 'Environment', 'Face', 'Fluorescence Microscopy', 'Fostering', 'Generic Drugs', 'Genomics', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Individual', 'Informatics', 'Knee', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Microscopy', 'Mining', 'Modality', 'Modeling', 'Organelles', 'Output', 'Pattern Recognition', 'Performance', 'Phase', 'Process', 'Publishing', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Resolution', 'Roentgen Rays', 'Scotland', 'Screening procedure', 'Semantics', 'Source Code', 'Speed', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Analysis', 'Technology', 'Testing', 'Tissues', 'Training', 'Translations', 'Validation', 'Vision', 'Visual', 'Work', 'Writing', 'base', 'data mining', 'data modeling', 'detector', 'digital', 'flexibility', 'imaging informatics', 'imaging modality', 'interest', 'medical specialties', 'object recognition', 'open source', 'practical application', 'programs', 'software development']",NIA,NATIONAL INSTITUTE ON AGING,ZIC,2009,361575,0.02170234195581442
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7837005,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,229517,0.026770635898351307
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7585774,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,411032,0.026770635898351307
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7677970,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'skeletal', 'standard measure', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2009,15000,0.0070012151614109825
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7677970,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'skeletal', 'standard measure', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2009,189454,0.0070012151614109825
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7884780,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'skeletal', 'standard measure', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2009,100000,0.0070012151614109825
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of  computer scientists, software engineers, and medical investigators who develop computational tools for the  analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure  and environment for the development of computational algorithms and open source technologies, and then  oversee the training and dissemination of these tools to the medical research community. This world-class  software and development environment serves as a foundation for accelerating the development and  deployment of computational tools that are readily accessible to the medical research community. The team  combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state  of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed,  open-source environment) to enable computational examination of both basic neurosience and neurologicat  disorders. In developing this infrastructure resource, the team will significantly expand upon proven open  systems technology and platforms. The driving biological projects will come initially from the study of  schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open  systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures  and connectivity patterns in the brain, derangements of which have long been thought to play a role in the  etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range  of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially  including microscopic, genomic, and other image data. It will apply to image data from individual  )atients,and to studies executed across large poplulations. The data will be taken from subjects across a  Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7915998,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Genomics', 'Goals', 'Healthcare', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2009,3720664,0.023706321325150742
"High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI    DESCRIPTION (provided by applicant):  Understanding normal and abnormal patterns of brain development in fetuses and neonates is a key factor in early detection of developmental disorders. This project proposal seeks to develop and refine novel magnetic resonance image reconstruction and analysis methodology to allow, for the first time, the mapping of in-utero fetal brain development. One of the most common abnormalities detected by clinical imaging of the developing fetal brain is ventriculomegaly, which, despite the absence of other clinical or imaging findings, is associated with neurodevelopmental disabilities in infancy and childhood in up to 50% of cases. Although ultrasound allows diagnosis of the condition, it has not been able to distinguish those fetus that will have poor neurological outcome from those with normal outcome. Recent developments in fast magnetic resonance imaging have permitted the use of MRI to study the fetal anatomy and this technique is now being routinely used at a small number of sites around the world including UCSF. However, MR imaging of the fetal brain is still challenging because of imaging distortions caused by motion of the fetus within the mother and by artifacts caused by the surrounding maternal anatomy. Higher resolution or 3D acquisitions are not possible because of motion of the fetus during the acquisition time^ required. The current clinical 2D slice data individually provide limited resolution and contrast and, most importantly, often contain severe motion corruption between slices. This project is motivated by the observation that it is possible to apply computer vision and image processing techniques to correct relative motion between the multiple stacks of low resolution fetal slices, and create a single volumetric image with high isotropic 3D resolution and consistent geometry. Such higher resolution images provide structure that may be analyzed using computational morphometric techniques that can detect subtle focal differences in the pattern of tissue volume, location and surface folding. This project will combine such powerful techniques with extensive fetal and neonatal imaging experience at UCSF, allowing direct clinical application of the methodology to study morphologic aberrations associated with ventriculomegaly and to correlate these with clinical outcome. The ability to apply these computational techniques to in-utero data will provide an entirely new view of the developing brain, which promises to shed new light on early developmental problems both in fetuses and premature neonates.           n/a",High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI,7668441,R01NS055064,"['Anatomy', 'Automobile Driving', 'Brain', 'Brain Mapping', 'Childhood', 'Clinic', 'Clinical', 'Computational Technique', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Evolution', 'Fetus', 'Gestational Age', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Infant Development', 'Investigation', 'Knowledge', 'Lesion', 'Light', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Mothers', 'Motion', 'Neonatal', 'Neurodevelopmental Disability', 'Neurological outcome', 'Outcome', 'Pattern', 'Premature Infant', 'Prematurity of fetus', 'Relative (related person)', 'Research Personnel', 'Resolution', 'Site', 'Slice', 'Staging', 'Statistical Models', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'brain tissue', 'clinical Diagnosis', 'clinical application', 'developmental disease', 'experience', 'fetal', 'follow-up', 'gray matter', 'image processing', 'image reconstruction', 'improved', 'in utero', 'infancy', 'insight', 'neonate', 'novel', 'premature', 'programs', 'reconstruction', 'tool', 'two-dimensional']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2009,275279,0.008574484874814756
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7804332,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2009,363247,-0.0262196829063859
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,0.023266717349781457
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7915039,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,168580,0.017181425347300768
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7643324,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,815277,0.017181425347300768
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,7787325,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'Muscle Rigidity', 'NMR Spectroscopy', 'Negative Staining', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'public health relevance', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2009,293039,-0.02296349915593097
"Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S    DESCRIPTION (provided by applicant): Magnetic Resonance imaging (MRI) is a powerful imaging tool but many important clinical applications are limited by long scan times and/or poor SNR. This proposal aims to improve the speed of MRI without losing SNR, through a Bayesian inference approach. Improvement in scan speed can enable new time-critical clinical and diagnostic MR applications, like cardiac imaging, time-resolved 4D coronary angiography, high-resolution volumetric brain imaging, dynamic contrast enhanced imaging, etc. A Bayesian framework for the reconstruction of raw MR data from multiple coils in parallel will be developed. This framework makes it possible to reduce the time taken during scanning multiple times by reducing the sampling rate of raw MR data. Our method will be generally applicable to most MR imaging modalities, targets and sampling schemes. Our method will then be validated and tested on the specific clinical application of volumetric structural brain imaging, which is an important procedure for the detection and diagnosis of neurodegenerative diseases, tumors, white matter lesions, measuring brain atrophy and hippocampal subfields, etc. The main goal of this project is to create a set of computational tools to perform the reconstruction of accelerated MRI data on arbitrary imaging targets, modalities and acquisition schemes, including random sampling schemes. Design of models to capture prior spatial information about images will be undertaken. Finally, the method will be validated on structural brain data in terms of metrics like SNR, partial voluming, test- retest repeatability, and the performance of subsequent processing steps like image segmentation. PUBLIC HEALTH RELEVANCE: This project has the potential to make clinical MR imaging much faster than currently possible. This will make many time-critical clinical applications of MRI more feasible, for instance real-time MRI of the heart. The resolving power of MRI to image finer, clinically interesting anatomical features will also increase, making more reliable diagnosis possible.          n/a",Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S,7688029,R21EB008138,"['Acceleration', 'Address', 'Algorithms', 'Anatomy', 'Brain', 'Brain Diseases', 'Brain imaging', 'Breathing', 'Cardiac', 'Clinical', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Coronary Angiography', 'Data', 'Data Quality', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Drug Formulations', 'Future', 'Generic Drugs', 'Goals', 'Graph', 'Heart', 'Hippocampus (Brain)', 'Image', 'Imaging Device', 'Imaging Techniques', 'Knowledge', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Metric', 'Modality', 'Modification', 'Morphologic artifacts', 'Motion', 'Neurodegenerative Disorders', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Problem Solving', 'Procedures', 'Process', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Validation', 'Weight', 'Work', 'base', 'cerebral atrophy', 'clinical application', 'combinatorial', 'computerized data processing', 'computerized tools', 'design', 'expectation', 'heart motion', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'in vivo', 'interest', 'model design', 'nervous system disorder', 'public health relevance', 'reconstruction', 'simulation', 'tumor', 'white matter']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R21,2009,211250,0.012065660617013137
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7351765,R01NS051826,"['Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomy', 'Area', 'Back', 'Class', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Diffuse Pattern', 'Disease', 'Disease Progression', 'Evaluation', 'Fetal Growth Retardation', 'Goals', 'Gold', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Intuition', 'Knowledge', 'Learning', 'Localized', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Research', 'Methods', 'Modeling', 'Morphology', 'Neonatal', 'Neuroanatomy', 'Normal Range', 'Operative Surgical Procedures', 'Pathology', 'Patients', 'Population', 'Population Study', 'Process', 'Range', 'Research', 'Schizophrenia', 'Shapes', 'Standards of Weights and Measures', 'Statistical Distributions', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'computer studies', 'desire', 'disease classification', 'feeding', 'imaging Segmentation', 'improved', 'neonate', 'nervous system disorder', 'neurosurgery', 'normal aging', 'novel', 'shape analysis', 'tool']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2008,281588,-0.001015016704282184
"AUTOMATIC QUANTITATIVE CT IMAGING OF PERICARDIAL FAT: A NOVEL ISCHEMIA PREDICTOR    DESCRIPTION (provided by applicant): Every year, 1 million people in the US will experience a heart attack or sudden cardiac death. A large percentage of these patients have no prior symptoms of any kind but suffer from silent heart disease (ischemia), which may cause a heart attack at any time. Currently there is no reliable screening method to identify people who may have silent heart disease and therefore are at risk of ""heart attack"".       We seek to extract additional data from a non-invasive Computed Tomography (CT) scan of the heart (commonly used in most imaging centers), which will better identify patients who are ""vulnerable"" to sudden heart attack. These images are acquired without contrast agents, as a common screening test for measuring coronary calcium, another clinical marker of coronary artery disease. We will prove that additional information about cardiovascular risk can be obtained by quantifying pericardial fat surrounding the heart in these cardiac CT images. Although this information exists in the cardiac CT scans acquired today, it is ignored in clinical practice because currently there are no tools to measure it automatically and reliably, and no information regarding its significance for a given patient.       We will develop fully automated, accurate, new computer software for quantitation of pericardial fat from cardiac CT images acquired for routine assessment of coronary calcium. We plan to achieve complete automation and accuracy, by applying a combination of robust and effective algorithms in machine learning with anatomical knowledge. We aim to prove that the developed automatic software will be as accurate, and more reproducible than experienced imaging physicians in quantifying pericardial fat, and will accomplish the measurement in a fraction of the time. Such software could be immediately made available worldwide to standard imaging workstations. For the first time, this will allow its use as a standard practical imaging tool for cardiovascular risk assessment, without requiring additional time, imaging or radiation risk to the patient.       We will also show that this new quantitative information has important additional value compared to other clinical cardiovascular risk factors and information from blood samples (such as cholesterol, glucose and CRP), and the amount of calcium in the patient's coronary arteries seen on CT scans, and establish its significance in the prediction of silent heart disease.      PUBLIC HEALTH RELEVANCE: This new research will allow accurate prediction of who might be more likely to have heart disease which may ultimately cause a heart attack. It will allow doctors to identify patients for whom appropriate treatment could be prescribed to avoid a heart attack, or more extensive testing, could be recommended, to confirm or rule out heart disease.          n/a",AUTOMATIC QUANTITATIVE CT IMAGING OF PERICARDIAL FAT: A NOVEL ISCHEMIA PREDICTOR,7470355,R21EB006829,"['Abdomen', 'Algorithms', 'Automation', 'Biochemical', 'Blood specimen', 'C-reactive protein', 'Calcium', 'Cardiac', 'Cholesterol', 'Clinical', 'Clinical Markers', 'Computational algorithm', 'Computer software', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Development', 'Diagnostic', 'Evaluation', 'Fatty acid glycerol esters', 'Glucose', 'Goals', 'Heart', 'Heart Diseases', 'Image', 'Imaging Device', 'Invasive', 'Ischemia', 'Knowledge', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Myocardial Infarction', 'Patients', 'Pericardial body location', 'Physicians', 'Predictive Value', 'Public Health', 'Radiation', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Scanning', 'Score', 'Screening procedure', 'Standards of Weights and Measures', 'Symptoms', 'Testing', 'Time', 'Today', 'Visceral', 'X-Ray Computed Tomography', 'base', 'cardiovascular risk factor', 'cysteine rich protein', 'experience', 'heart imaging', 'human FAT protein', 'indexing', 'novel', 'sudden cardiac death', 'tool', 'waist circumference']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R21,2008,245025,0.007506705609661426
"Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging    DESCRIPTION (provided by applicant): Dementia represents a major public health problem which will grow significantly with the aging of our society. Recently, multiple pieces of converging clinical and neuropathological data indicate that dementia is typically a multi-factorial process. This evolution in thinking about the biology of dementia comes at a time when the most significant recent development in dementia imaging has been the introduction of amyloid plaque labeling compounds; the most widely studied at this point is Pittsburgh Compound - B (PiB). A central principle underlying this renewal is this. Amyloid imaging is unquestionably a major advance. However, since the biology of dementia is more complex than brain amyloidosis alone, imaging of dementia is more complex than brain amyloid imaging alone. Our primary goal in this renewal is to use various imaging modalities to identify different mechanisms underlying dementia. This is the first resubmission of a competitive renewal of AG11378. We have revised the grant in accordance with each point raised in the critique and we believe this has resulted in a much stronger application. Each of the five aims is cast to answer variations on the questions: What is the contribution of specific imaging-based proxies of pathology to clinical/cognitive decline? When in the course of the disease do these relationships hold true? For whom is this true? Where in the brain are the relevant pathologies expressed? Principle outcome measures will be clinical and psychometric decline over time which we will use as indicators of disease progression. Our predictor variables will include various imaging modalities which will serve as proxies for specific pathologic mechanisms underlying dementia. PiB will serve as a measure of plaque burden and we will use various Magnetic Resonance Imaging (MRI) modalities to assess cerebro- vascular disease, tissue loss, tissue perfusion, diffusion, neuronal integrity, and inflammation. Features that distinguish this renewal from past cycles of AG11378 include a mechanistic focus, multi- modality imaging including multiple MRI modalities as well as PET amyloid imaging, MR imaging now at 3T, inclusion of both amnestic and non-amnestic MCI, and voxel-based analytic methods including an exciting new computational approach which employs a support vector machine algorithm to provide diagnosis in individual subjects. In addition, subjects will now be recruited from a new population-based study of aging and dementia, which differentiates this renewal from past cycles as well as from most dementia imaging studies which recruit from referral practices and thus risk sampling bias. Previous cycles of this grant have contributed significantly to recognition of the utility of imaging in dementia. An active debate is currently underway about revising clinical criteria for AD, specifically whether imaging and fluid biomarker information should be included among the criteria. Results from this renewal grant will inform this debate about multiple time dependent mechanisms leading to dementia that are accessible in living subjects through imaging. PUBLIC HEALTH RELEVANCE: Identifying Mechanisms of Dementia: Role for MRI in the Era of Molecular Imaging (AG11378) Dementia is a leading public health problem now and will have an increasingly serious impact on public health as the number of elderly individuals increase. Dementia has many possible underlying causes and several different causes are at work in most elderly demented subjects. In this grant, we will use modern brain imaging to identify specific mechanisms underlying progression to dementia.          n/a",Identifying Mechanisms of Dementia:  Role for MRI in the Era of Molecular Imaging,7522303,R01AG011378,"['6-hydroxybenzothiazole', 'Abbreviations', 'Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease Pathway', 'Amyloid deposition', 'Amyloidosis', 'Anatomy', 'Anisotropy', 'Appendix', 'Applications Grants', 'Attenuated', 'Autopsy', 'Base of the Brain', 'Binding', 'Biological Markers', 'Biology', 'Biostatistical Methods', 'Brain', 'Brain Mapping', 'Brain imaging', 'Cerebrovascular Circulation', 'Chromosome Pairing', 'Classification', 'Clinic', 'Clinical', 'Clinical Pathology', 'Cognition', 'Cognitive', 'Complex', 'Correlation Studies', 'Critiques', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Disease Progression', 'Elderly', 'Enrollment', 'Epidemiologic Studies', 'Event', 'Evolution', 'Future', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Inflammation', 'Inositol', 'Knowledge', 'Label', 'Life', 'Liquid substance', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Maps', 'Measures', 'Memory', 'Methods', 'Metric', 'Modality', 'Modeling', 'N-acetylaspartate', 'Neurofibrillary Tangles', 'Neurons', 'Numbers', 'Outcome', 'Outcome Measure', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Perfusion', 'Pittsburgh Compound-B', 'Population', 'Positron-Emission Tomography', 'Process', 'Proxy', 'Psychometrics', 'Public Health', 'Purpose', 'Recovery', 'Recruitment Activity', 'Relative (related person)', 'Resolution', 'Risk', 'Role', 'Sampling', 'Sampling Biases', 'Scheme', 'Senile Plaques', 'Severity of illness', 'Societies', 'Spin Labels', 'Staging', 'Study Subject', 'Symptoms', 'Synapses', 'Syndrome', 'Text', 'Thinking', 'Time', 'Tissues', 'Variant', 'Vascular Diseases', 'Work', 'amyloid imaging', 'base', 'clinical Diagnosis', 'cohort', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular imaging', 'morphometry', 'neuroimaging', 'tool']",NIA,MAYO CLINIC ROCHESTER,R01,2008,868308,-0.031041979167451425
"Instrumentation and Bioengineering Development and Application Development of unique instrumentation using novel approaches is, in many instances, necessary to the success of biomedical research. Areas of emphasis within our group are summarized below.  A digital video, EEG imaging system with seizure detection for multiple small animals, has been developed  initially in collaboration with NINDS detects and record sseizures of small animals by monitoring their EEGs together with documenting the animals' accompanying behavior via video recording. The instrumentation consists of animal cages, swivel connectors connected to the head of each animal, EEG analog amplifiers, computer control with movie maker and graphics hardware, and software detection of spikes and seizure patterns. The system has been assembled and will visually display and record EEG data along with video of multiple small animals. The instrument has been tested on small animals and modifications have been made to the mechanical apparatus to allow for more flexible animal movement. Through consultation with the National Naval Medical Center, a system based on the same principles will be developed for research purposes. An e laser flash photolysis apparatus was developed in collaboration with Dr. Fred Friedman, NCI, and Dr. Stanley Smith (University of Mississippi)to measure the kinetics of carbon monoxide (CO) binding to cytochromes P450 in liver microsomes from rats treated with various drugs and carcinogens. Since numerous forms of P450 contribute to the overall reaction, a difference kinetic method was used to distinguish the kinetic behavior of individual P450s. This method entails analysis of the difference between the kinetic profiles in the absence and presence of a specific P450 effector, and successfully yielded kinetic parameters for individual P450s involved in drug and carcinogen metabolism. Specifically, various polycyclic hydrocarbons differentially accelerated CO binding to the P450 1A1, which metabolizes these carcinogens in a size- and shape-dependent manner. Wavelet analysis and maximum entropy  software tools  will be  evaluated to  determine if a signal processing enhancement of the data, results.  Wavelet analysis allows selection of critical short time scale regions, which cannot be performed using fast Fourier transform analysis, where high frequency information predominates and provides information on the early events associated with the cytochrome P450 binding kinetics. Additionally, use of the maximum entropy technique will improve the probability distribution of the data.  In collaboration with Dr. Steven Stanhope, NICHD, a time reaction reflex movement system has been  duplicated to test a person's reaction time in attempting to follow a laser beam directed at the floor. Signals generated in a computer system change the position of the light and indicate when a particular light stimulus is activated and deactivated. The computer correlates signals from force plates in the floor with foot placement.   In collaboration with Dr. Richard Hendler, NHLBI, a modified version of a high speed optical multichannel spectrometer, developed previously, has been enhanced in terms of temporal and signal amplitude resolution. The kinetics of the bacteriorhodopsin (BR) photocycle, initiated with a synchronized laser pulse (532nm, 7ns), is being studied using an optical system that follows the spectral changes associated with the transient intermediates of the photocycle. Complete spectra from approximately 400nm to 700nm are collected with less than 10 microsecond resolution, permitting extraction, though single value decomposition analysis, of the role of the intermediates. These studies support the view that the BR photocycle consists of two parallel cycles instead of a single photocycle favored by other groups. To adapt to the next phase of this project, which entails collecting infrared data, a collaboration has been established with the National Institute of Standards and Technology. The optical system has been realigned to incorporate both the high-speed multichannel analyzer and the infrared spectrometer  Combined optical and spectral kinetic data studies will allow characterization of the structural information for each step in the photocycle.. Our ultimate goal is to apply the same approaches to time-resolved X-ray diffraction using BR membrane crystals thus obtaining structural information at the atomic level to visualize protein conformational changes resulting from the electrogenic movement of protons across the membrane.  To capture the necessary spectral information, an optical instrument has been designed to accommodate a charge-coupled device (CCD) camera with an attached spectrograph. The CCDs photon detector contains 1024 rows of 512 pixels thus enabling collection of spectra of 512 wavelengths at different points in time.  To record points that are staggered in time to account for the different lifetimes of the BR photocycle intermediates a time gated image intensifier will be integrated into the instrument.  In collaboration with Dr. Janine Smith, NEI, an ocular imaging system for measuring dry eye severity has being developed and is undergoing evaluation for clinical use. The method uses the Oxford Scheme for grading ocular staining in dry eyes using various dyes. The software that processes the ocular images will be tested in the clinic in conjunction with a slit bio-microscope. The image analysis uses a support vector machine algorithm from statistical learning theory. Based on the clinical feedback a subsequent instrument development may be necessary to improve image capture that will enable image enhancement, and the correction of imaging defects. This system will enhance image quality by minimizing the potential effects of eye movement, glare, vignetting, lens distortion, noise, and non-uniform eye lighting. System and monitor calibration techniques for color management and white balance will be developed. It is anticipated that further improvement to image quality would be obtained by standardizing  the instillation and timing of dye administration to account for time dilution of dye staining. A database will be developed for storing patient information and history, and to save patient images. Both the instrument and software will be initiated using a semi-automated system with the goal of future development as a fully automatic system. n/a",Instrumentation and Bioengineering Development and Application,7734357,Z01EB000011,"['Accounting', 'Algorithms', 'Amplifiers', 'Animals', 'Area', 'Bacteriorhodopsins', 'Behavior', 'Binding', 'Biomedical Engineering', 'Biomedical Research', 'Calibration', 'Carbon Monoxide', 'Carcinogen Metabolism', 'Carcinogens', 'Clinic', 'Clinical', 'Collaborations', 'Collection', 'Color', 'Computer Systems', 'Computer software', 'Computers', 'Consultations', 'Cytochrome P450', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Device or Instrument Development', 'Discipline', 'Dyes', 'Electroencephalography', 'Engineering', 'Entropy', 'Equilibrium', 'Event', 'Eye', 'Eye Movements', 'Feedback', 'Floor', 'Fourier Transform', 'Frequencies', 'Future', 'Glare', 'Goals', 'Head', 'Image', 'Image Analysis', 'Image Enhancement', 'Individual', 'Institutes', 'Intramural Research Program', 'Kinetics', 'Laboratories', 'Lasers', 'Light', 'Lighting', 'Liver Microsomes', 'Machine Learning', 'Measures', 'Mechanics', 'Medical center', 'Membrane', 'Methods', 'Microscope', 'Mission', 'Mississippi', 'Modification', 'Monitor', 'Movement', 'National Institute of Child Health and Human Development', 'Noise', 'Optical Instrument', 'Optics', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Photons', 'Physiologic pulse', 'Placement', 'Polycyclic Hydrocarbons', 'Positioning Attribute', 'Probability', 'Process', 'Proteins', 'Protons', 'Pulse taking', 'Purpose', 'Range', 'Rattus', 'Reaction', 'Reaction Time', 'Recording of previous events', 'Reflex action', 'Research', 'Resolution', 'Role', 'Scheme', 'Scientist', 'Seizures', 'Severities', 'Shapes', 'Signal Transduction', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'Stimulus', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Video Recording', 'X ray diffraction analysis', 'X-Ray Diffraction', 'analog', 'base', 'charge coupled device camera', 'computerized data processing', 'design', 'detector', 'digital', 'eye dryness', 'flash photolysis', 'foot', 'improved', 'instrument', 'instrumentation', 'lens', 'movie', 'novel strategies', 'physical science', 'research clinical testing', 'size', 'success', 'theories']",NIBIB,NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING,Z01,2008,115047,0.002213478318048328
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7480255,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2008,89733,-0.0053064129268631105
"Technology Development for 3D Electron Microscopy In a collaboration with GATAN Inc., we have reported the development of a novel,       multi-specimen imaging system for high-throughput transmission electron microscopy that       circumvents time-consuming steps involved in manual specimen loading. This cartridge-based       loading system, called the Gatling, permits the sequential examination of as many as 100       specimens in the microscope for room temperature electron microscopy using mechanisms for       rapid and automated specimen exchange. The software for the operation of the Gatling and       automated data acquisition has been implemented in an updated version of our in-house program       AutoEM. In the current implementation of the system, the time required to deliver 95 specimens       into the microscope and collect overview images from each is about 13 hours. Regions of       interest are identified from a low magnification atlas generation from each specimen and an       unlimited number of higher magnifications images can be subsequently acquired from these       regions using fully automated data acquisition procedures that can be controlled from a remote       interface. We anticipate that the availability of the Gatling will greatly accelerate the       speed of data acquisition for a variety of applications in biology, materials science and       nanotechnology that require rapid screening and image analysis of multiple specimens. (see       Lefman et al (2007) for more details) Strategies for the determination of 3D structures of       biological macromolecules using electron crystallography and single particle electron       microscopy utilize powerful tools for the averaging of information obtained from 2D projection       images of structurally homogeneous specimens. In contrast, electron tomographic approaches       have often been used to study the 3D structures of heterogeneous, one-of-a-kind objects such       as whole cells where image averaging strategies are not applicable. Complex entities such as       cells and viruses, nevertheless, contain multiple copies of numerous macromolecules that can       individually be subjected to 3D averaging. We have deeloped a complete framework for       alignment, classification, and averaging of volumes derived by electron tomography that is       computationally efficient and effectively accounts for the missing wedge that is inherent to       limited angle electron tomography. Modeling the missing data as a multiplying mask in       reciprocal space we have shown that the effect of the missing wedge can be accounted for       seamlessly in all alignment and classification operations. We solve the alignment problem       using the convolution theorem in harmonic analysis, thus eliminating the need for approaches       that require exhaustive angular search, and adopt an iterative approach to alignment and       classification that does not require the use of external references. We also demonstrated that       our method could be successfully applied for 3D classification and averaging of phantom       volumes as well as experimentally obtained tomograms of GroEL where the outcomes of the       analysis can be quantitatively compared against the expected results. (see Bartesaghi et al       (2008) for more details) Another area of focus has been on image processing and segmentation.       Previous studies using nonlinear anisotropic methods, wavelet based methods and filtering have       already demonstrated the value of image denoising in various 2D and 3D datasets. The existing       methods usually consider clean data (or assume that clean data is available) and artificially       add different types of noise to the clean data and then denoise the noisy data assuming that       the statistics of noise is known using various algorithms. We have investigated the use of       transform-domain denoising techniques and feature extraction to improve quantitative       interpretation of cryo electron tomograms of viruses and cells. In our approach, we have used       four metrics for analysis including the Kullback-Leibler (KL) distance based GOF test, Fourier       ring correlation and single-image SNR to iteratively obtain the optimal denoising algorithm       for a given 3D volume. Using these methods, we show that denoising, when used with care is an       enormously powerful tool for the automated interpretation of complex 3D data sets at high       throughput. (see Narasimha, Aganj et al (2008) for more details). In continued developments       for automated image analysis, we have developed a machine-learning tool for automatic       texton-based joint classification and segmentation of mitochondria in MNT-1 cells imaged using       ion-abrasion scanning electron microscopy (IA-SEM). For diagnosing signatures that may be       unique to cellular states, automatic tools with minimal user intervention need to be developed       for high-throughput data mining and analysis of these large volume data sets (typically        2GB/cell). Challenges for developing such a tool in 3D electron microscopy arise in particular       due to low contrast and low signal-to-noise ratios (SNR). Our approach is based on block-wise       classification of images into a trained list of regions. Classification is performed using a       k-nearest neighbor (k-NN) classifier, support vector machines (SVMs), adaptive boosting       (AdaBoost) and histogram matching using an NN classifier. In addition, we study the       computational complexity vs. segmentation accuracy tradeoff of these classifiers. Segmentation       results demonstrate that our approach using minimal training data performs close to       semi-automatic methods using the variational level-set method and manual segmentation by an       experienced user. We apply the method to investigate quantitative parameters such as volume of       the cytoplasm occupied by mitochondria, differences between the surface area of inner and       outer membranes and mean mitochondrial width that are representative quantities that may have       relevance to distinguishing cancer cells from normal cells. (see Narasimha, Ouyang et al       (2008) for more details). Chemical definition of complex protein assemblies is integral to       interpreting 3D structure. We have explored a general approach for the determination of       absolute amounts and the relative stoichiometry of proteins in a mixture using fluorescence       and mass spectrometry. We engineered a gene to express green fluorescent protein (GFP) with a       synthetic fusion protein (GABGFP) in Escherichia coli to function as a spectroscopic standard       for the quantification of an analogous stable isotope-labeled, non-fluorescent fusion protein       (GAB*) and for the quantification and stoichiometric analysis of purified transducin, a       heterotrimeric G-protein complex. Using our approach, the stoichiometry of the three       transducin subunits was measured to be 1:1.1:1.15 over a 5-fold range of labeled internal       standard with a relative standard deviation of 9%. Fusing a unique genetically coded       spectroscopic signal element with concatenated proteotypic peptides provides a powerful method       to accurately quantify and determine the relative stoichiometry of multiple proteins present       in complexes or mixtures that cannot be readily assessed using classical gravimetric,       enzymatic, or antibody-based technologies. (see Nanavati et al (2008) for more details). n/a",Technology Development for 3D Electron Microscopy,7733260,Z01BC010826,"['Accounting', 'Adopted', 'Algorithms', 'Antibodies', 'Area', 'Atlases', 'Bacteria', 'Biological', 'Biological Process', 'Biology', 'Cancer Biology', 'Caring', 'Cells', 'Chemicals', 'Chemotaxis', 'Chimeric Proteins', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'Cytoplasm', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Electron Microscopy', 'Electrons', 'Elements', 'Engineering', 'Escherichia coli', 'Fluorescence', 'Foundations', 'Generations', 'Genes', 'Goals', 'Government Agencies', 'Green Fluorescent Proteins', 'HIV', 'Heterotrimeric GTP-Binding Proteins', 'Hour', 'Housing', 'Image', 'Image Analysis', 'Imaging technology', 'Industry', 'Intervention', 'Ions', 'Joints', 'Label', 'Laboratories', 'Light', 'Machine Learning', 'Manuals', 'Masks', 'Mass Spectrum Analysis', 'Measures', 'Medicine', 'Membrane', 'Methods', 'Metric', 'Microscope', 'Mitochondria', 'Modeling', 'Molecular', 'Nanotechnology', 'Noise', 'None or Not Applicable', 'Normal Cell', 'Nucleic Acids', 'Numbers', 'Operative Surgical Procedures', 'Organelles', 'Outcome', 'Peptides', 'Procedures', 'Proteins', 'Range', 'Relative (related person)', 'Reporting', 'Resolution', 'Roentgen Rays', 'Scanning Electron Microscopy', 'Science', 'Screening procedure', 'Signal Transduction', 'Specimen', 'Speed', 'Stable Isotope Labeling', 'Standards of Weights and Measures', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Tissues', 'Tomogram', 'Training', 'Transducin', 'Transmission Electron Microscopy', 'Update', 'Virus', 'Width', 'Work', 'base', 'cancer cell', 'cellular imaging', 'computer studies', 'data acquisition', 'data mining', 'electron crystallography', 'electron tomography', 'experience', 'image processing', 'improved', 'interest', 'macromolecule', 'novel', 'particle', 'programs', 'size', 'statistics', 'stoichiometry', 'technology development', 'three dimensional structure', 'tool']",NCI,DIVISION OF BASIC SCIENCES - NCI,Z01,2008,587287,-0.0018147519804819125
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7496032,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2008,189850,0.010110972157437663
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7355521,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Class', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Pliability', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Score', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'desire', 'experience', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2008,431744,0.026770635898351307
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7495057,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Body measure procedure', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Skeletal system', 'Standards of Weights and Measures', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'size', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2008,15000,0.0070012151614109825
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7495057,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Body measure procedure', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Skeletal system', 'Standards of Weights and Measures', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'size', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2008,189397,0.0070012151614109825
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neurosience and neurologicat disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual )atients,and to studies executed across large poplulations. The data will be taken from subjects across a Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7688808,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Class', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Future', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Link', 'Localized', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Property', 'Purpose', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Services', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Textiles', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,100000,0.023706321325150742
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neurosience and neurologicat disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual )atients,and to studies executed across large poplulations. The data will be taken from subjects across a Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7688368,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Class', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Future', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Link', 'Localized', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Purpose', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Services', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Textiles', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,50000,0.023706321325150742
"High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI    DESCRIPTION (provided by applicant):  Understanding normal and abnormal patterns of brain development in fetuses and neonates is a key factor in early detection of developmental disorders. This project proposal seeks to develop and refine novel magnetic resonance image reconstruction and analysis methodology to allow, for the first time, the mapping of in-utero fetal brain development. One of the most common abnormalities detected by clinical imaging of the developing fetal brain is ventriculomegaly, which, despite the absence of other clinical or imaging findings, is associated with neurodevelopmental disabilities in infancy and childhood in up to 50% of cases. Although ultrasound allows diagnosis of the condition, it has not been able to distinguish those fetus that will have poor neurological outcome from those with normal outcome. Recent developments in fast magnetic resonance imaging have permitted the use of MRI to study the fetal anatomy and this technique is now being routinely used at a small number of sites around the world including UCSF. However, MR imaging of the fetal brain is still challenging because of imaging distortions caused by motion of the fetus within the mother and by artifacts caused by the surrounding maternal anatomy. Higher resolution or 3D acquisitions are not possible because of motion of the fetus during the acquisition time^ required. The current clinical 2D slice data individually provide limited resolution and contrast and, most importantly, often contain severe motion corruption between slices. This project is motivated by the observation that it is possible to apply computer vision and image processing techniques to correct relative motion between the multiple stacks of low resolution fetal slices, and create a single volumetric image with high isotropic 3D resolution and consistent geometry. Such higher resolution images provide structure that may be analyzed using computational morphometric techniques that can detect subtle focal differences in the pattern of tissue volume, location and surface folding. This project will combine such powerful techniques with extensive fetal and neonatal imaging experience at UCSF, allowing direct clinical application of the methodology to study morphologic aberrations associated with ventriculomegaly and to correlate these with clinical outcome. The ability to apply these computational techniques to in-utero data will provide an entirely new view of the developing brain, which promises to shed new light on early developmental problems both in fetuses and premature neonates.           n/a",High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI,7469332,R01NS055064,"['Anatomy', 'Automobile Driving', 'Brain', 'Brain Mapping', 'Childhood', 'Clinic', 'Clinical', 'Computational Technique', 'Computer Vision Systems', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Evolution', 'Fetus', 'Gestational Age', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant Development', 'Investigation', 'Knowledge', 'Lesion', 'Light', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Mothers', 'Motion', 'Neonatal', 'Neurodevelopmental Disability', 'Neurological outcome', 'Numbers', 'Outcome', 'Pattern', 'Premature Infant', 'Range', 'Relative (related person)', 'Research Personnel', 'Resolution', 'Site', 'Slice', 'Staging', 'Statistical Models', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'brain tissue', 'clinical Diagnosis', 'clinical application', 'developmental disease', 'experience', 'fetal', 'follow-up', 'gray matter', 'image processing', 'image reconstruction', 'improved', 'in utero', 'infancy', 'insight', 'neonate', 'novel', 'programs', 'reconstruction', 'tool', 'two-dimensional']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2008,275279,0.008574484874814756
"In-vivo optical molecular imaging with Dynamic Contrast Enhancement (DyCE)    DESCRIPTION (provided by applicant): Fluorescence-based molecular Imaging in small animals is having a major impact on drug development and disease research. However, a significant challenge to imaging targeted fluorescent markers in vivo remains: unless the labeled regions are located superficially; localization, quantitation and host organ identification are impeded by the effects of light scattering and absorption. Orthotopic tumor and disease models are increasingly preferred over less biologically relevant subcutaneous xenografts. In such studies, substantial difficulties are encountered in longitudinal studies where animals are growing and are positioned differently for each measurement. We believe that a single imaging advance could address many of these issues, and advance the utility of in-vivo molecular imaging: an exact anatomical co-registration technique that does not rely on multimodal techniques. This proposal describes dynamic molecular imaging (DMI), an approach that can provide co-registered anatomical information by exploiting in-vivo pharmacokinetics of dyes in small animals in a simple and inexpensive way. We demonstrate that by acquiring a time-series of optical images during injection of an inert dye, we can repeatably and accurately delineate the major internal organs of mice using optical imaging alone. This is possible because each major organ is ""illuminated"" by the kinetics of dye passing through it in such a manner as to make it distinguishable from other structures. Spatiotemporal analysis can exploit these characteristic time courses to allow the body-surface representation of each organ to be visualized. These in- vivo anatomical maps can be overlaid onto simultaneously acquired images of a targeted molecular probe (detected and distinguished from the mapping dye via multispectral imaging techniques, if necessary) to significantly aid in identification of the probe's anatomical and physical location. Using CRi's existing and prototype 2D, ""2.5D"" and true 3D multispectral mouse imaging systems, we propose to test and refine a DMI approach. Based on our findings to date, we will examine and exploit in-vivo pharmacokinetics of the near-infrared dye, indocyanine green, to generate delineated surface projections of individual organs. Co-registering this surface map with surface projections of detected targeted labels will allow the targeted probe's 3D spatial location to be inferred. This information can further be used to improve quantitative accuracy in longitudinal molecular imaging studies of deep targets.           n/a",In-vivo optical molecular imaging with Dynamic Contrast Enhancement (DyCE),7485551,R43EB008627,"['Address', 'Adoption', 'Algorithms', 'Anatomy', 'Animals', 'Automatic Data Processing', 'Back', 'Basic Science', 'Body Surface', 'Bolus Infusion', 'Characteristics', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Contrast Media', 'Data', 'Data Display', 'Depth', 'Detection', 'Development', 'Disease', 'Disease model', 'Drug Kinetics', 'Dyes', 'Fluorescence', 'General Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Indocyanine Green', 'Injection of therapeutic agent', 'Kinetics', 'Label', 'Legal patent', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Massachusetts', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Probes', 'Mus', 'Nature', 'Optics', 'Organ', 'Paper', 'Performance', 'Physiological', 'Positioning Attribute', 'Protocols documentation', 'Purpose', 'Range', 'Research', 'Research Personnel', 'Retrieval', 'Series', 'Signal Transduction', 'Small Animal Imaging Systems', 'Software Tools', 'Solutions', 'Source', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'Tissues', 'Validation', 'Variant', 'Virginia', 'Visualization software', 'X-Ray Computed Tomography', 'Xenograft procedure', 'absorption', 'base', 'blind', 'data acquisition', 'drug development', 'drug discovery', 'experience', 'hemodynamics', 'image reconstruction', 'improved', 'in vivo', 'instrumentation', 'light scattering', 'longitudinal animal study', 'millimeter', 'molecular imaging', 'novel strategies', 'optical imaging', 'photonics', 'prototype', 'response', 'spatiotemporal', 'subcutaneous', 'tumor']",NIBIB,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R43,2008,167462,-8.502174602820988e-05
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,0.023266717349781457
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7479786,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,3534631,0.023745863431005598
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7479786,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,186033,0.023745863431005598
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7665248,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,80289,0.017181425347300768
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7489821,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,1042528,0.017181425347300768
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7467385,U24RR021382,[' '],NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2008,5140823,0.011568916796495491
"Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S    DESCRIPTION (provided by applicant): Magnetic Resonance imaging (MRI) is a powerful imaging tool but many important clinical applications are limited by long scan times and/or poor SNR. This proposal aims to improve the speed of MRI without losing SNR, through a Bayesian inference approach. Improvement in scan speed can enable new time-critical clinical and diagnostic MR applications, like cardiac imaging, time-resolved 4D coronary angiography, high-resolution volumetric brain imaging, dynamic contrast enhanced imaging, etc. A Bayesian framework for the reconstruction of raw MR data from multiple coils in parallel will be developed. This framework makes it possible to reduce the time taken during scanning multiple times by reducing the sampling rate of raw MR data. Our method will be generally applicable to most MR imaging modalities, targets and sampling schemes. Our method will then be validated and tested on the specific clinical application of volumetric structural brain imaging, which is an important procedure for the detection and diagnosis of neurodegenerative diseases, tumors, white matter lesions, measuring brain atrophy and hippocampal subfields, etc. The main goal of this project is to create a set of computational tools to perform the reconstruction of accelerated MRI data on arbitrary imaging targets, modalities and acquisition schemes, including random sampling schemes. Design of models to capture prior spatial information about images will be undertaken. Finally, the method will be validated on structural brain data in terms of metrics like SNR, partial voluming, test- retest repeatability, and the performance of subsequent processing steps like image segmentation. PUBLIC HEALTH RELEVANCE: This project has the potential to make clinical MR imaging much faster than currently possible. This will make many time-critical clinical applications of MRI more feasible, for instance real-time MRI of the heart. The resolving power of MRI to image finer, clinically interesting anatomical features will also increase, making more reliable diagnosis possible.          n/a",Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S,7528771,R21EB008138,"['Acceleration', 'Address', 'Algorithms', 'Anatomy', 'Blur', 'Brain', 'Brain Diseases', 'Brain imaging', 'Breathing', 'Cardiac', 'Class', 'Clinical', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Condition', 'Coronary Angiography', 'Data', 'Data Quality', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Drug Formulations', 'Future', 'Generic Drugs', 'Goals', 'Graph', 'Heart', 'Hippocampus (Brain)', 'Image', 'Imaging Device', 'Imaging Techniques', 'Knowledge', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Metric', 'Modality', 'Modification', 'Morphologic artifacts', 'Motion', 'Neurodegenerative Disorders', 'Noise', 'Numbers', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Problem Solving', 'Procedures', 'Process', 'Public Health', 'Pulse taking', 'Purpose', 'Range', 'Rate', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Validation', 'Weight', 'Work', 'base', 'cerebral atrophy', 'clinical application', 'combinatorial', 'computerized data processing', 'computerized tools', 'design', 'expectation', 'heart motion', 'image reconstruction', 'imaging Segmentation', 'improved', 'in vivo', 'interest', 'model design', 'nervous system disorder', 'reconstruction', 'simulation', 'tumor', 'white matter']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R21,2008,252375,0.012065660617013137
"Development and Dissemination of Robust Brain MRI Measurement Tools    DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: This application responds to RFA: PAR-07-249, ""Collaborations with National Centers for Biomedical Computing"". The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods. The project will collaborate with the National Alliance for Medical Image Computing (NA-MIC) to develop the software using the NA-MIC Software Engineering Process, leverage the NA-MIC engineering infrastructure, and integrate this software into the 3D Slicer, a well-architected application environment being developed in NA-MIC. The particular software package will include both a brain image registration and warping algorithm, called HAMMER, and an algorithm for the segmentation of white matter lesions (WMLs), which can arise from a variety of pathologies including vascular pathology and multiple sclerosis. HAMMER received 2006 Best Paper Award from IEEE Signal Processing Society. HAMMER has been successfully applied to many large clinical research studies and clinical trials involving over 5,000 MR brain images and has been downloaded by 318 users from 102 institutions in over 20 countries. The WML segmentation algorithm has been successfully applied to ""Action to Control Cardiovascular Risk in Diabetes-Memory in Diabetes"" (ACCORD-MIND) sub- study, with data acquired from 4 centers on 650 patients over a period of 8 years. Designing an easy-to-use, robust software package for these two algorithms and incorporating it into the 3D Slicer will benefit a large community of end-users that need access to advanced image analysis methods in various neuroimaging studies. To increase the robustness of the algorithms to the highly variable quality and characteristics of clinical image data, further algorithm development is necessary. To increase ease of use by non-experts in computer analysis methods and integrate this software into the Slicer platform, significant software engineering efforts are planned. Three aims will be investigated. The first aim is to further develop and extend novel image analysis methods aiming at improving the robustness and performance of HAMMER registration and WML segmentation algorithms, so that they can be easily applied to various clinical research studies. The second and third aims are to design separate software modules for these two algorithms, and to incorporate them into the 3D Slicer. These two modules will be designed (1) with consistent cross-platform interactive and scripted interfaces, (2) allowing end-users to interactively explore the suitable parameters for their data, (3) enabling developers to add new functions. The robustness of these two modules will be extensively tested and improved by both software engineering tools and various clinical research data (acquired from different centers). The final software will be freely available in both source code and pre-compiled programs. PUBLIC HEALTH REVELANCE: The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods.          n/a",Development and Dissemination of Robust Brain MRI Measurement Tools,7556497,R01EB006733,"['Academia', 'Address', 'Adopted', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Arts', 'Attention', 'Automobile Driving', 'Award', 'Behavioral', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Budgets', 'California', 'Characteristics', 'Child', 'Class', 'Clinical', 'Clinical Data', 'Clinical Engineering', 'Clinical Research', 'Clinical Trials', 'Cocaine', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Communities', 'Compatible', 'Complex', 'Computational algorithm', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computers', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Documentation', 'Educational Materials', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'General Hospitals', 'Genetic', 'Genomics', 'Goals', 'Government', 'Hand', 'Head', 'Health', 'Healthcare', 'Heavy Drinking', 'Hemoglobin', 'Histocompatibility Testing', 'Hormonal', 'Hospitals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Industry', 'Information Technology', 'Institutes', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Lesion', 'Licensing', 'Life', 'Localized', 'Longitudinal Studies', 'Los Angeles', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Memory', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Mind', 'Modality', 'Modeling', 'Molecular Abnormality', 'Morphology', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Center for Research Resources', 'Nature', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'North Carolina', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Paper', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Philosophy', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Production', 'Property', 'Protocols documentation', 'Psychiatry', 'Public Health', 'Publications', 'Purpose', 'Radiology Specialty', 'Range', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Secure', 'Series', 'Services', 'Simulate', 'Site', 'Societies', 'Software Engineering', 'Software Tools', 'Source', 'Source Code', 'Spatial Distribution', 'Speed', 'Structure', 'System', 'Talents', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'USA Georgia', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Upper arm', 'Ursidae Family', 'Utah', 'Visible Radiation', 'Vision', 'Vision research', 'Western Asia Georgia', 'Woman', 'Women&apos', 's Health', 'Work', 'abstracting', 'base', 'bioimaging', 'biomedical scientist', 'cardiovascular risk factor', 'computerized data processing', 'computerized tools', 'cost', 'design', 'disability', 'egg', 'endophenotype', 'experience', 'follow-up', 'human disease', 'image registration', 'improved', 'innovation', 'mathematical model', 'medical schools', 'member', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'open source', 'outreach program', 'portability', 'professor', 'programs', 'receptor', 'repository', 'research and development', 'research study', 'scripting interface', 'software development', 'tool', 'usability', 'user-friendly', 'vector', 'vision development', 'water diffusion', 'web-enabled', 'white matter']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2008,402999,0.027973163232534477
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7186695,R01NS051826,"['Accounting', 'Adult', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomic structures', 'Anatomy', 'Area', 'Atlases', 'Back', 'Biomechanics', 'Boston', 'Brain', 'Caring', 'Class', 'Classification', 'Clinical assessments', 'Clutterings', 'Collaborations', 'Competence', 'Computer Simulation', 'Computer Vision Systems', 'Computing Methodologies', 'Corpus Callosum', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diffuse Pattern', 'Discipline of obstetrics', 'Disease', 'Disease Progression', 'Effectiveness', 'Effectiveness of Interventions', 'Electroencephalography', 'Elements', 'Ensure', 'Evaluation', 'Evolution', 'Fetal Growth Retardation', 'General Hospitals', 'Genetic Markers', 'Goals', 'Gold', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Incidence', 'Individual', 'Infant', 'Intervention', 'Intuition', 'Invasive', 'Knowledge', 'Label', 'Learning', 'Learning Disabilities', 'Link', 'Localized', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Motivation', 'Neonatal', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Noise', 'Normal Range', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Pediatric Hospitals', 'Population', 'Population Characteristics', 'Population Study', 'Positioning Attribute', 'Premature Infant', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Property', 'Psyche structure', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Resolution', 'Rest', 'Role', 'Scanning', 'Schizophrenia', 'Shapes', 'Site', 'Specificity', 'Staging', 'Standards of Weights and Measures', 'Statistical Distributions', 'Statistical Models', 'Statistical Study', 'Statistically Significant', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Tweens', 'Universities', 'Validation', 'Variant', 'Washington', 'Woman', 'base', 'cohort', 'computer studies', 'computerized tools', 'desire', 'deviant', 'disease classification', 'expectation', 'feeding', 'healthy aging', 'imaging Segmentation', 'improved', 'instrument', 'interest', 'mortality', 'neonate', 'nervous system disorder', 'neuroimaging', 'neurosurgery', 'normal aging', 'novel', 'programs', 'radiologist', 'reconstruction', 'relating to nervous system', 'research clinical testing', 'response', 'shape analysis', 'statistics', 'tool', 'tumor']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2007,282619,-0.001015016704282184
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,7278340,R44CA088684,"['Acute leukemia', 'Antibodies', 'Area', 'Aspirate substance', 'Biopsy Specimen', 'Blast Cell', 'Bone Marrow', 'Bone marrow biopsy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Color', 'Compatible', 'Computer software', 'Count', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Disease', 'Dysmyelopoietic Syndromes', 'Ensure', 'Equipment', 'Evaluation', 'Evaluation Reports', 'Event', 'Experimental Designs', 'Florida', 'Fluorescence', 'Funding', 'Future', 'Generations', 'Goals', 'Grant', 'Hematopathology', 'Histology', 'Image', 'Image Analysis', 'Immunophenotyping', 'Label', 'Laboratories', 'Legal patent', 'Light', 'Lighting', 'Machine Learning', 'Malignant - descriptor', 'Manuals', 'Mechanics', 'Medical Device', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Morphology', 'Myelodysplastic/Myeloproliferative Disease', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Procedures', 'Protocols documentation', 'Public Health Schools', 'Purpose', 'Qualifying', 'Range', 'Reagent', 'Reporting', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Side', 'Slide', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Software Validation', 'Source', 'Speed', 'Staging', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'System', 'Testing', 'Therapeutic', 'Time', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Washington', 'Work', 'base', 'cellular imaging', 'design', 'experience', 'innovation', 'instrument', 'instrumentation', 'leukemia', 'light microscopy', 'novel', 'programs', 'research study', 'response', 'software development']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2007,1006481,-0.012164287096536117
"Instrumentation and Bioengineering Development and Application Development of unique instrumentation using novel approaches is, in many instances, necessary to the success of biomedical research.  Areas of emphasis within our group are summarized below.  A digital video, EEG imaging system with seizure detection for multiple small animals, being developed in collaboration with Drs. Michael Rogawski and Maciej Gasior NINDS, will detect and record seizures of small animals by monitoring their EEGs together with documenting the animals' accompanying behavior via video recording.  The instrumentation consists of animal cages, swivel connectors connected to the head of each animal, EEG analog amplifiers, computer control with movie maker and graphics hardware, and software detection of spikes and seizure patterns.  The system has been assembled and will visually display and record EEG data along with video of multiple small animals.  The instrument has been tested on small animals and modifications have been made to the mechanical apparatus to allow for more flexible animal movement.  The system will continue to be updated as the latest software changes become available.   A laser flash photolysis apparatus was developed in collaboration with Dr. Fred Friedman, NCI, to measure the kinetics of carbon monoxide (CO) binding to cytochromes P450 in liver microsomes from rats treated with various drugs and carcinogens.  Since numerous forms of P450 contribute to the overall reaction, a difference kinetic method was used to distinguish the kinetic behavior of individual P450s.  This method entails analysis of the difference between the kinetic profiles in the absence and presence of a specific P450 effector, and successfully yielded kinetic parameters for individual P450s involved in drug and carcinogen metabolism.  Specifically, various polycyclic hydrocarbons differentially accelerated CO binding to the P450 1A1, which metabolizes these carcinogens in a size- and shape-dependent manner.  Wavelet analysis allows selection of critical short time scale regions where high frequency information predominates and provides information on the early events associated with the cytochrome P450 binding kinetics.    In collaboration with Dr. Brian Brooks, CC, an eye movement system is being developed for use with patients who are unable to understand commands, such as infants, or patients with below-average verbalization or language barriers.  Stimuli, such as sound, light, or motion of objects cause eye movements toward the stimuli. The unit has been installed, tested and used on patients in an ophthalmic testing laboratory.  In collaboration with Dr. Steven Stanhope and Shih-Chiao Tseng, CC, a time reaction reflex movement system is being developed to test a person's reaction time in attempting to follow a laser beam directed at the floor.   Signals generated in a computer system change the position of the light and indicate when a particular light stimulus is activated and deactivated.  The computer correlates signals from force plates in the floor with foot placement.  The system has been completed and is ready for initial patient testing.   In collaboration with Dr. Richard Hendler, NHLBI, a modified version of a high speed optical multichannel spectrometer, developed previously, has been enhanced in terms of temporal and signal amplitude resolution.  The kinetics of the bacteriorhodopsin photocycle, initiated with a synchronized laser pulse (532nm, 7ns), is being studied using an optical system that follows the spectral changes associated with the transient intermediates of the photocycle.  Complete spectra from approximately 400nm to 700nm are collected with less than 10 microsecond resolution, permitting extraction, though single value decomposition analysis, of the role of the intermediates.  To adapt to the next phase of this project, which entails collecting infrared data, a collaboration has been established with the National Institute of Standards and Technology.  The optical system has been realigned to incorporate both the high-speed multichannel analyzer and the infrared spectrometer.  In collaboration with Dr. Janine Smith, NEI, an ocular imaging system for measuring dry eye severity is being developed.  The method uses the Oxford Scheme for grading ocular staining in dry eyes using various dyes.  The software for ocular image analysis is complete and will be tested in the clinic in conjuction with a slit biomicroscope.  The image analysis uses a support vector machine (SVM) algorithm from statistical learning theory.  An ocular instrument will be developed for improving image capture, image enhancement, and the correction of imaging defects.  It is intended that the system will enhance image quality by minimizing the potential effects of eye movement, glare, vignetting, lens distortion, noise, and non-uniform eye lighting.  System and monitor calibration techniques for color management and white balance will be developed.  Instillation and timing of dye administration will be controlled to account for time dilution of dye staining.  A database will be developed for storing patient information and history, and to save patient images.  Both the instrument and software will be initiated using a semi-automated system with the goal of future development as a fully automatic system. n/a",Instrumentation and Bioengineering Development and Application,7593815,Z01EB000011,"['Accounting', 'Algorithms', 'Amplifiers', 'Animals', 'Area', 'Bacteriorhodopsins', 'Behavior', 'Binding', 'Biomedical Engineering', 'Biomedical Research', 'Calibration', 'Carbon Monoxide', 'Carcinogen Metabolism', 'Carcinogens', 'Clinic', 'Collaborations', 'Color', 'Computer Systems', 'Computer software', 'Computers', 'Cytochrome P450', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Discipline', 'Dyes', 'Electroencephalography', 'Engineering', 'Equilibrium', 'Event', 'Eye', 'Eye Movements', 'Floor', 'Frequencies', 'Future', 'Glare', 'Goals', 'Head', 'Image', 'Image Analysis', 'Image Enhancement', 'Individual', 'Infant', 'Institutes', 'Intramural Research Program', 'Kinetics', 'Laboratories', 'Language', 'Lasers', 'Light', 'Lighting', 'Liver Microsomes', 'Machine Learning', 'Measures', 'Mechanics', 'Methods', 'Mission', 'Modification', 'Monitor', 'Movement', 'Noise', 'Optics', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Physiologic pulse', 'Placement', 'Polycyclic Hydrocarbons', 'Positioning Attribute', 'Pulse taking', 'Range', 'Rattus', 'Reaction', 'Reaction Time', 'Recording of previous events', 'Reflex action', 'Resolution', 'Role', 'Scheme', 'Scientist', 'Seizures', 'Severities', 'Shapes', 'Signal Transduction', 'Speed', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'Stimulus', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Update', 'Video Recording', 'analog', 'digital', 'eye dryness', 'flash photolysis', 'foot', 'improved', 'instrument', 'instrumentation', 'lens', 'movie', 'novel strategies', 'object motion', 'physical science', 'size', 'sound', 'success', 'theories']",NIBIB,NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING,Z01,2007,53800,-0.02891554421722967
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,7272822,R01EB002247,"['Address', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Body of uterus', 'Cancer Patient', 'Caregivers', 'Chronic', 'Chronic Disease', 'Clinical', 'Communication', 'Communities', 'Condition', 'Consultations', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Health Personnel', 'Healthcare', 'Image', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Metric', 'Modeling', 'Musculoskeletal', 'Musculoskeletal Pain', 'Natural Language Processing', 'Neurologic', 'Oncologist', 'Optics', 'Patients', 'Performance', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Process', 'Quality of Care', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Infrastructure', 'Slice', 'Specialist', 'Structure', 'Surgeon', 'System', 'Techniques', 'Technology', 'Teleconsultations', 'Telemedicine', 'Testing', 'Time', 'Upper arm', 'Work', 'base', 'chemotherapy', 'data mining', 'diagnostic accuracy', 'health care quality', 'image registration', 'improved', 'interest', 'knowledge base', 'medical specialties', 'novel', 'research clinical testing', 'size', 'telehealth']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,394864,-0.016031712460069902
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7298516,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2007,88539,-0.0053064129268631105
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7362843,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2007,235138,0.010110972157437663
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7337256,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Body measure procedure', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Skeletal system', 'Standards of Weights and Measures', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'size', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2007,15000,0.0070012151614109825
"Validation and Evaluation of a Portable Body Scanner for Determination of Obesity    DESCRIPTION (provided by applicant):       Obesity has reached epidemic levels in the U.S., with 66% of adults overweight and 32% of adults obese. The research uses the new technique of three-dimensional  (3 D) photonic scanning to create and validate an instrument that  rapidly  assesses  obesity  in  clinical  and  field  settings.  The  first  aim  is  to develop a portable computer vision system of body imaging for 3 D surface imaging of the human body. The hardware system is designed from off-the- shelf components such as digital cameras, projectors, and personal computer. Algorithms for the 3D data are being developed and refined for calculation and system calibration for a small instrument. The second aim is to develop algorithms for surface reconstruction from 3D data in order to define a proper surface representation and to reconstruct a 3D model of the human body from incomplete and noisy data. The third aim begins the human measurement testing in 120 adults. Aim 3 is to estimate the size and shape of the reconstructed human body by a portable body imager and compare to current methods that assess obesity. Anthropometric parameters will be computed by a 3 second body scan via imaging and then compared to other methods of obesity assessment including BMI, waist circumference, sagittal abdominal diameter, bioimpedence, hydrodensitometry, dual energy X-ray absorptiometry, and air displacement plethysmography. The final aim is to validate body imaging as an indicator of central obesity (fat in the abdominal region, as opposed to subcutaneous depots) in a subset of 60 subjects because it is the abdominal fat that is most associated with health risks such as diabetes. Abdominal fat tissue as detected by magnetic resonance imaging scans will be compared to that calculated from 3 D body imaging. In sum, the non-contact, noninvasive nature of this new portable body scanner will produce a quick, inexpensive and objective measure of body size and type of obesity.             n/a",Validation and Evaluation of a Portable Body Scanner for Determination of Obesity,7337256,R21DK081206,"['3-Dimensional', 'Abdomen', 'Adult', 'Air', 'Algorithms', 'Area', 'Body Image', 'Body Size', 'Body fat', 'Body measure procedure', 'Caliber', 'Calibration', 'Central obesity', 'Clinical', 'Computer Vision Systems', 'Data', 'Diabetes Mellitus', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Evaluation', 'Fatty acid glycerol esters', 'Goals', 'Health', 'Height', 'Human', 'Human body', 'Image', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Obesity', 'Overweight', 'Personal Computers', 'Plethysmography', 'Population Study', 'Research', 'Risk', 'Scanning', 'Shapes', 'Skeletal system', 'Standards of Weights and Measures', 'Sum', 'Surface', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Tissues', 'Use of New Techniques', 'Validation', 'abdominal fat', 'design', 'digital', 'indexing', 'instrument', 'photonics', 'reconstruction', 'size', 'subcutaneous', 'three-dimensional modeling', 'waist circumference']",NIDDK,"UNIVERSITY OF TEXAS, AUSTIN",R21,2007,183318,0.0070012151614109825
"High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI    DESCRIPTION (provided by applicant):  Understanding normal and abnormal patterns of brain development in fetuses and neonates is a key factor in early detection of developmental disorders. This project proposal seeks to develop and refine novel magnetic resonance image reconstruction and analysis methodology to allow, for the first time, the mapping of in-utero fetal brain development. One of the most common abnormalities detected by clinical imaging of the developing fetal brain is ventriculomegaly, which, despite the absence of other clinical or imaging findings, is associated with neurodevelopmental disabilities in infancy and childhood in up to 50% of cases. Although ultrasound allows diagnosis of the condition, it has not been able to distinguish those fetus that will have poor neurological outcome from those with normal outcome. Recent developments in fast magnetic resonance imaging have permitted the use of MRI to study the fetal anatomy and this technique is now being routinely used at a small number of sites around the world including UCSF. However, MR imaging of the fetal brain is still challenging because of imaging distortions caused by motion of the fetus within the mother and by artifacts caused by the surrounding maternal anatomy. Higher resolution or 3D acquisitions are not possible because of motion of the fetus during the acquisition time^ required. The current clinical 2D slice data individually provide limited resolution and contrast and, most importantly, often contain severe motion corruption between slices. This project is motivated by the observation that it is possible to apply computer vision and image processing techniques to correct relative motion between the multiple stacks of low resolution fetal slices, and create a single volumetric image with high isotropic 3D resolution and consistent geometry. Such higher resolution images provide structure that may be analyzed using computational morphometric techniques that can detect subtle focal differences in the pattern of tissue volume, location and surface folding. This project will combine such powerful techniques with extensive fetal and neonatal imaging experience at UCSF, allowing direct clinical application of the methodology to study morphologic aberrations associated with ventriculomegaly and to correlate these with clinical outcome. The ability to apply these computational techniques to in-utero data will provide an entirely new view of the developing brain, which promises to shed new light on early developmental problems both in fetuses and premature neonates.           n/a",High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI,7241562,R01NS055064,"['Anatomy', 'Automobile Driving', 'Brain', 'Brain Mapping', 'Childhood', 'Clinic', 'Clinical', 'Computational Technique', 'Computer Vision Systems', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Dimensions', 'Early Diagnosis', 'Evolution', 'Fetus', 'Gestational Age', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant Development', 'Investigation', 'Knowledge', 'Lesion', 'Light', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Mothers', 'Motion', 'Neonatal', 'Neurodevelopmental Disability', 'Neurological outcome', 'Numbers', 'Outcome', 'Pattern', 'Premature Infant', 'Range', 'Relative (related person)', 'Research Personnel', 'Resolution', 'Site', 'Slice', 'Staging', 'Statistical Models', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'brain tissue', 'clinical Diagnosis', 'clinical application', 'developmental disease', 'experience', 'fetal', 'follow-up', 'gray matter', 'image processing', 'image reconstruction', 'improved', 'in utero', 'infancy', 'insight', 'neonate', 'novel', 'programs', 'reconstruction', 'tool', 'two-dimensional']",NINDS,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,R01,2007,275279,0.008574484874814756
"Automatic Detection of Critical Dermoscopy Features for Melanoma Diagnosis    DESCRIPTION (provided by applicant): Malignant melanoma, with an estimated growth in incidence of about 6% per year for decades, causes considerable loss of life. Yet melanoma can be easily cured if detected early. Digital dermoscopy has shown promise for more accurate detection, particularly at an early stage. Recent conferences have highlighted a general agreement on definition of dermoscopic features and moderate agreement on the most useful structural features. Automatic detection of these specific structures that are critical for early diagnosis and are used in various dermoscopic diagnostic algorithms would be desirable. Yet little work has been published on automatic detection of any specific dermoscopic structures. Although specific colors figure prominently in the definition of the most critical dermoscopic structures, little work has been done on finding the specific regions or region combinations in the color space where colors are located, particularly with reference to the surrounding skin. The work in Phase I and after Phase I successfully segmented the border within 5% of the range of the dermatologists' borders, found several highly accurate dermoscopy features, and brought mean diagnostic accuracy on difficult early lesions to a high level. This proposal seeks to develop a digital dermosocopy system by 1) comparing classifiers 2) testing border accuracy and modifying segmentation if needed 3) developing an algorithm that uses a three-dimensional representation of a probability density function to specify single and paired melanoma colors via cluster methods and fuzzy logic techniques 4) identifying critical structural features including brown globules, abrupt border cutoff, granularity, regression, and pigment asymmetry with high accuracy 5) developing a clinical interface for acquisition of images within the clinic 6) testing the new algorithms in six dermatology clinics including two pigmented lesion clinics with both EpiLight and DermLite II Pro dermoscopy images taken in the clinic. Key features of the research include dermatopathology confirmation of specific structures and the use of relative color analysis. If successful, software will be marketed to the growing number of dermatologists with digital dermoscopy capability. The commercial software package will be ready for marketing as a diagnostic adjunct for digital camera dermoscopy attachments. Malignant melanoma, with an estimated growth in incidence of about 6% per year for decades, causes considerable loss of life. Melanoma can be easily cured if detected early, and this project seeks to develop a digital dermoscopy device that can detect very early melanomas. The project goal is to develop inexpensive melanoma detection software and test it in multiple dermatology clinics.          n/a",Automatic Detection of Critical Dermoscopy Features for Melanoma Diagnosis,7284886,R44CA101639,"['Agreement', 'Algorithms', 'Am 80', 'Amelanotic Melanoma', 'American', 'Architecture', 'Area', 'Benign', 'Biological', 'Biological Neural Networks', 'Biopsy', 'Blood Vessels', 'Borderline Lesion', 'Boxing', 'Calibration', 'Characteristics', 'Cicatrix', 'Class', 'Classification', 'Clinic', 'Clinical', 'Code', 'Color', 'Computer software', 'Computer-Assisted Image Analysis', 'Count', 'Decision Trees', 'Dermatologist', 'Dermatology', 'Dermoscopy', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease regression', 'Dysplastic Nevus', 'Early Diagnosis', 'Effectiveness', 'Equipment', 'Evaluation', 'Excision', 'Fuzzy Logic', 'Goals', 'Government', 'Growth', 'Hair', 'Hair Removal', 'Head', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Incidence', 'Lentigo', 'Lesion', 'Life', 'Lighting', 'Location', 'Machine Learning', 'Manuals', 'Marketing', 'Measures', 'Methods', 'N(delta)-acetylornithine, -isomer', 'N-dodecanoylglutamic acid, -isomer, sodium salt', 'Noise', 'Numbers', 'Odds Ratio', 'Pattern', 'Peripheral', 'Persons', 'Phase', 'Phase I Clinical Trials', 'Physicians', 'Pigments', 'Precancerous melanosis', 'Probability', 'Process', 'Published Comment', 'Publishing', 'Purpose', 'ROC Curve', 'Radial', 'Range', 'Rate', 'Relative (related person)', 'Reporting', 'Research', 'Risk', 'Score', 'Series', 'Skin', 'Software Tools', 'Source', 'Specificity', 'Staging', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'To specify', 'Training', 'Work', 'alpha-difluoromethyl-DOPA, -isomer', 'alpha-methylornithine dihydrochloride, -isomer', 'base', 'density', 'diagnostic accuracy', 'digital', 'experience', 'improved', 'indexing', 'melanoma', 'reconstruction', 'software development', 'software systems', 'statistics', 'symposium', 'tool development', 'vector']",NCI,STOECKER & ASSOCIATES,R44,2007,494442,-0.014214902965396545
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7494181,U54EB005149,"['Address', 'Affect', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Appearance', 'Area', 'Atlases', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Cells', 'Characteristics', 'Clinical', 'Clinical Data', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Complex', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Coupling', 'Data', 'Data Correlations', 'Data Sources', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Elements', 'Ensure', 'Epilepsy', 'Feedback', 'Fiber', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imagery', 'Imaging Techniques', 'Individual', 'Knowledge', 'Life', 'Link', 'Localized', 'Location', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modification', 'Morphology', 'Multiple Sclerosis', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Organ', 'Other Imaging Modalities', 'Output', 'Participant', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Range', 'Recording of previous events', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Schizophrenia', 'Science', 'Services', 'Shapes', 'Software Engineering', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Distributions', 'Structure', 'Syndrome', 'System', 'Systems Analysis', 'Techniques', 'Testing', 'Textiles', 'Time', 'Tissues', 'Today', 'USA Georgia', 'Utah', 'Visible Radiation', 'Vision', 'Western Asia Georgia', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'design', 'disability', 'experience', 'image registration', 'insight', 'interest', 'mathematical model', 'neuroimaging', 'novel', 'prenatal', 'research study', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion', 'white matter']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2007,87500,0.023745863431005598
"National Alliance for Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (NAMIC)(RMI),7271955,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2007,3888915,0.023988043748670643
"Mobile Food Intake Visualization and Voice Recognize (FIVR) Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives. n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7490204,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,3000,0.016896238522445664
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7340845,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,1039742,0.017181425347300768
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7253351,U24RR021382,[' '],NCRR,MASSACHUSETTS GENERAL HOSP,U24,2007,5123449,0.011568916796495491
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7015019,R01NS051826,"['Alzheimer&apos', 's disease', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain morphology', 'human data', 'image enhancement', 'image guided surgery /therapy', 'magnetic resonance imaging', 'mathematical model', 'prenatal growth disorder']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2006,289590,-0.001015016704282184
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,7115855,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,396341,-0.016031712460069902
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,7096660,R44CA088684,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biopsy', 'blood cell count', 'bone marrow', 'bone marrow exam', 'cell morphology', 'cell population study', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'flow cytometry', 'hematopoietic stem cells', 'high throughput technology', 'histopathology', 'human tissue', 'image enhancement', 'immunocytochemistry', 'leukemia', 'light emission', 'light microscopy', 'lighting', 'molecular /cellular imaging', 'neoplasm /cancer diagnosis', 'spectrometry']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2006,1029373,-0.012164287096536117
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7104243,U54EB005149,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'bioinformatics', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2006,3809481,0.023745863431005598
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7104243,U54EB005149,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'bioinformatics', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2006,195300,0.023745863431005598
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6985366,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2006,183324,0.021590453018666092
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7078667,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2006,5010926,0.011568916796495491
"High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI    DESCRIPTION (provided by applicant):  Understanding normal and abnormal patterns of brain development in fetuses and neonates is a key factor in early detection of developmental disorders. This project proposal seeks to develop and refine novel magnetic resonance image reconstruction and analysis methodology to allow, for the first time, the mapping of in-utero fetal brain development. One of the most common abnormalities detected by clinical imaging of the developing fetal brain is ventriculomegaly, which, despite the absence of other clinical or imaging findings, is associated with neurodevelopmental disabilities in infancy and childhood in up to 50% of cases. Although ultrasound allows diagnosis of the condition, it has not been able to distinguish those fetus that will have poor neurological outcome from those with normal outcome. Recent developments in fast magnetic resonance imaging have permitted the use of MRI to study the fetal anatomy and this technique is now being routinely used at a small number of sites around the world including UCSF. However, MR imaging of the fetal brain is still challenging because of imaging distortions caused by motion of the fetus within the mother and by artifacts caused by the surrounding maternal anatomy. Higher resolution or 3D acquisitions are not possible because of motion of the fetus during the acquisition time^ required. The current clinical 2D slice data individually provide limited resolution and contrast and, most importantly, often contain severe motion corruption between slices. This project is motivated by the observation that it is possible to apply computer vision and image processing techniques to correct relative motion between the multiple stacks of low resolution fetal slices, and create a single volumetric image with high isotropic 3D resolution and consistent geometry. Such higher resolution images provide structure that may be analyzed using computational morphometric techniques that can detect subtle focal differences in the pattern of tissue volume, location and surface folding. This project will combine such powerful techniques with extensive fetal and neonatal imaging experience at UCSF, allowing direct clinical application of the methodology to study morphologic aberrations associated with ventriculomegaly and to correlate these with clinical outcome. The ability to apply these computational techniques to in-utero data will provide an entirely new view of the developing brain, which promises to shed new light on early developmental problems both in fetuses and premature neonates.           n/a",High Resolution In-Utero Mapping of Fetal Brain Development from Combined MRI,7148587,R01NS055064,"['brain', 'clinical research', 'embryo /fetus']",NINDS,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,R01,2006,274794,0.008574484874814756
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,6916728,R01NS051826,"['Alzheimer&apos', 's disease', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain morphology', 'human data', 'image enhancement', 'image guided surgery /therapy', 'magnetic resonance imaging', 'mathematical model', 'prenatal growth disorder']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2005,292728,-0.001015016704282184
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6944025,R13CA093819,"['artificial intelligence', 'computer human interaction', 'videotape /videodisc', 'workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2005,5000,0.010205458085198486
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6951380,R44HL071470,"['artificial intelligence', 'atherosclerotic plaque', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical automation', 'cardiovascular disorder diagnosis', 'clinical research', 'diagnosis design /evaluation', 'human data', 'image processing', 'informatics', 'magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R44,2005,374972,0.015234914431633367
"Reconstruction Hardware for Real-Time Moving Tabel MRI    DESCRIPTION (provided by applicant):    The overall goal of this project is to design and integrate instrumentation allowing the next generation of real-time image formation in MRI. The motivation comes from an existing project for forming MR images during continuous motion of the patient table. When applied to peripheral MR angiography the target is the formation of a moving table angiogram in which the table motion is precisely matched to the transit of the contrast bolus through the patient. However, implementation of this requires that a number of mathematical processes be done at high speed, including: (i) time-resolved 3D MRI of an extended field of view (FOV); (ii) determination of localized time-dependent parameters such as bolus arrival time and bolus velocity; (iii) variable ordering of phase encodings over the course of an MRI scan, allowing optimized local resolution; (iv) gradient warping correction for MR acquisition done using a moving patient table; (v) multi-coil reconstruction using the SENSE technique, allowing improved lateral resolution for a given acquisition time; (vi) MR acquisition done using a variable table velocity When implemented, these methods will allow the formation of peripheral MR angiograms with optimized, patient-specific table motion, maximum efficiency, and high spatial resolution. Specific aims are: 1. Construction of the Next Generation Real-Time Image MR Reconstruction System. The funding will allow the construction of a system enabling the real-time performance of the mathematical algorithms which perform the above processes. System design will allow the data acquisition and reconstruction to be modified in real time. 2. Incorporation of the New System into the Project of Moving Table MRA. Once the hardware is integrated into a useable system it will be interfaced to a clinical MRI scanner at Mayo and used in the formation of peripheral contrast-enhanced MR angiograms using continuous motion of the patient table through the scanner gantry.         n/a",Reconstruction Hardware for Real-Time Moving Tabel MRI,6890990,R33EB004281,"['angiography', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'clinical research', 'computer program /software', 'human subject', 'image processing', 'magnetic resonance imaging', 'mathematics', 'physics', 'technology /technique development', 'time resolved data']",NIBIB,MAYO CLINIC,R33,2005,330397,0.023317435129979074
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6951446,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2005,318350,0.031495363023625565
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6935840,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2005,399984,-0.017566062891122627
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6948251,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,399327,-0.016031712460069902
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,6938339,R44CA088684,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biopsy', 'blood cell count', 'bone marrow', 'bone marrow exam', 'cell morphology', 'cell population study', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'flow cytometry', 'hematopoietic stem cells', 'high throughput technology', 'histopathology', 'human tissue', 'image enhancement', 'immunocytochemistry', 'leukemia', 'light emission', 'light microscopy', 'lighting', 'molecular /cellular imaging', 'neoplasm /cancer diagnosis', 'spectrometry']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2005,1000582,-0.012164287096536117
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),6950028,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2005,3800000,0.023745863431005598
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),6950028,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2005,200000,0.023745863431005598
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6850297,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2005,172385,0.021590453018666092
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,6952714,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2005,5013536,0.011568916796495491
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6793307,R13CA093819,"['artificial intelligence', 'computer human interaction', 'videotape /videodisc', 'workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2004,5000,0.010205458085198486
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6833334,R44HL071470,"['artificial intelligence', 'atherosclerotic plaque', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical automation', 'cardiovascular disorder diagnosis', 'clinical research', 'diagnosis design /evaluation', 'human data', 'image processing', 'informatics', 'magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R44,2004,374972,0.015234914431633367
"Sub-millimeter Simultaneous SPECT-CT for Imaging    DESCRIPTION (provided by applicant):    We are proposing to develop a single, bench-top animal scanner that will acquire both functional SPECT images and anatomical CT images with sub-millimeter spatial resolution for both imaging modalities. The sub-mm SPECT-CT will provide a technique for noninvasive functional imaging in mice for a wide range of applications, including the development of new radio-pharmaceuticals, assessment of new therapeutic approaches, and investigation of fundamental biological processes in transgenic and knockout mice. This would allow investigators to perform serial imaging studies in the same animal at multiple time points to investigate tumor growth, tissue pathology, the effects of therapy, and the mechanism of action of new diagnostic agents. The system will have wide applicability and significant impact in research that uses small animals to advance our understanding of human disease processes. During phase I we successfully completed all proposed feasibility studies to demonstrate SPECT/CT with gamma performance of 1.3mm intrinsic spatial resolution, E range from 30keV to 350keV, and,deltaE/E=12% at 140keV and - 100mu m CT capability from a 50xS0mm CMOS based digital x-ray detector. In addition, we acquired outstanding dual SPECT-CT images of euthanized mice. During the phase II project we will complete the integration of the high-resolution SPECT and transmission CT subsystems and develop all necessary hardware and software. The result will be a fully functional dual-modality prototype scanner for anatomical and quantitative metabolic imaging of small animals.         n/a",Sub-millimeter Simultaneous SPECT-CT for Imaging,6773880,R44RR016393,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computed axial tomography', 'computer system design /evaluation', 'image processing', 'laboratory mouse', 'noninvasive diagnosis', 'single photon emission computed tomography', 'technology /technique development', 'whole body imaging /scanning']",NCRR,"PHOTON IMAGING, INC.",R44,2004,368960,0.003920257521119878
"Reconstruction Hardware for Real-Time Moving Table MRI    DESCRIPTION (provided by applicant):    The overall goal of this project is to design and integrate instrumentation allowing the next generation of real-time image formation in MRI. The motivation comes from an existing project for forming MR images during continuous motion of the patient table. When applied to peripheral MR angiography the target is the formation of a moving table angiogram in which the table motion is precisely matched to the transit of the contrast bolus through the patient. However, implementation of this requires that a number of mathematical processes be done at high speed, including: (i) time-resolved 3D MRI of an extended field of view (FOV); (ii) determination of localized time-dependent parameters such as bolus arrival time and bolus velocity; (iii) variable ordering of phase encodings over the course of an MRI scan, allowing optimized local resolution; (iv) gradient warping correction for MR acquisition done using a moving patient table; (v) multi-coil reconstruction using the SENSE technique, allowing improved lateral resolution for a given acquisition time; (vi) MR acquisition done using a variable table velocity When implemented, these methods will allow the formation of peripheral MR angiograms with optimized, patient-specific table motion, maximum efficiency, and high spatial resolution. Specific aims are: 1. Construction of the Next Generation Real-Time Image MR Reconstruction System. The funding will allow the construction of a system enabling the real-time performance of the mathematical algorithms which perform the above processes. System design will allow the data acquisition and reconstruction to be modified in real time. 2. Incorporation of the New System into the Project of Moving Table MRA. Once the hardware is integrated into a useable system it will be interfaced to a clinical MRI scanner at Mayo and used in the formation of peripheral contrast-enhanced MR angiograms using continuous motion of the patient table through the scanner gantry.         n/a",Reconstruction Hardware for Real-Time Moving Table MRI,6783945,R33EB004281,"['angiography', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'clinical research', 'computer program /software', 'human subject', 'image processing', 'magnetic resonance imaging', 'mathematics', 'physics', 'technology /technique development', 'time resolved data']",NIBIB,MAYO CLINIC,R33,2004,361371,0.023317435129979074
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6833120,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2004,427818,0.031495363023625565
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6752819,R44EY013038,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'charge coupled device camera', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'diabetic retinopathy', 'digital imaging', 'human subject', 'image processing', 'ophthalmoscopy', 'thermodynamics']",NEI,KESTREL CORPORATION,R44,2004,340158,0.010898896819692302
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6834860,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2004,350214,-0.017566062891122627
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6802269,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,387825,-0.016031712460069902
"National Alliance for Medical Imaging Computing (RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (RMI),6847712,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2004,100000,0.023988043748670643
"National Alliance for Medical Imaging Computing (RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (RMI),6847712,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2004,3625000,0.023988043748670643
"National Alliance for Medical Imaging Computing (RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (RMI),6847712,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2004,200000,0.023988043748670643
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,6909355,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2004,3821536,0.011568916796495491
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6644867,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2003,5000,0.010205458085198486
"Vector Quantization for Image Pattern Recognition    DESCRIPTION (provided by applicant):    This Phase-I SBIR application addresses the increasingly significant challenges faced by pathologists and clinicians in manually inspecting microscope slides. Microscopic inspection suffers from being labor-intensive, subjective, expensive and limited by the need for physical access to the glass slide specimen of interest. The obstacle to automated microscopic inspection has been the inability to efficiently digitize entire microscope specimens at high resolutions. Aperio has developed the ScanScope (R), a novel microscope slide scanner that makes it practical - for the first time - to rapidly create virtual microscope slides at high resolutions. Virtual slides set the stage for automating microscopic inspection using automated pattern recognition. This research aims to adapt and optimize Aperio's existing and novel algorithms for vector quantization (VQ) to the problem of automatic pattern recognition in virtual slides. VQ is a general mathematical technique for encoding bitstreams using a vocabulary. The primary aim is to demonstrate the feasibility of using VQ for pattern recognition in a practical and well-characterized application: automatically finding virtually all micrometastasis clusters in cytology specimens. This proposed research represents a first attempt to automate pattern recognition in virtual slides using VQ.         n/a",Vector Quantization for Image Pattern Recognition,6695147,R43EB001617,"['artificial intelligence', ' automated data processing', ' bioimaging /biomedical imaging', ' cell line', ' computer system design /evaluation', ' cytology', ' digital imaging', ' high throughput technology', ' metastasis', ' microscopy', ' nomenclature']",NIBIB,"APERIO TECHNOLOGIES, INC.",R43,2003,97269,0.00282347159518794
"MicroSeer, Analysis software for microscopy imagery  DESCRIPTION (provided by applicant): This project will create new pattern recognition software to improve the analysis and interpretation of in vivo  biomedical imagery. Currently, researchers can get remarkably detailed images of living cells and their  constituent proteins using molecular genetic and microscopy-based approaches in conjunction with  sophisticated microscopy hardware. Available image analysis techniques and software, however, lag behind  the power of this new imaging equipment to visualize the microscopic world.  This phase I SBIR project will apply existing technology in spatial analysis of satellite image data to microscopy data, create new statistical techniques specific to the study of spatial association of proteins in  cells, and create software that implements these statistics for use in the analysis of spatial association timeslice in vivo biomedical imagery.   n/a","MicroSeer, Analysis software for microscopy imagery",6581125,R43EB000575,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' image processing', ' statistics /biometry', ' structural biology']",NIBIB,BIOMEDWARE,R43,2003,177261,0.006365044526841385
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6643700,R43HL071470,"['artificial intelligence', ' atherosclerotic plaque', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical automation', ' cardiovascular disorder diagnosis', ' diagnosis design /evaluation', ' human data', ' image processing', ' magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R43,2003,99850,0.015234914431633367
"Sub-millimeter Simultaneous SPECT-CT for Imaging    DESCRIPTION (provided by applicant):    We are proposing to develop a single, bench-top animal scanner that will acquire both functional SPECT images and anatomical CT images with sub-millimeter spatial resolution for both imaging modalities. The sub-mm SPECT-CT will provide a technique for noninvasive functional imaging in mice for a wide range of applications, including the development of new radio-pharmaceuticals, assessment of new therapeutic approaches, and investigation of fundamental biological processes in transgenic and knockout mice. This would allow investigators to perform serial imaging studies in the same animal at multiple time points to investigate tumor growth, tissue pathology, the effects of therapy, and the mechanism of action of new diagnostic agents. The system will have wide applicability and significant impact in research that uses small animals to advance our understanding of human disease processes. During phase I we successfully completed all proposed feasibility studies to demonstrate SPECT/CT with gamma performance of 1.3mm intrinsic spatial resolution, E range from 30keV to 350keV, and,deltaE/E=12% at 140keV and - 100mu m CT capability from a 50xS0mm CMOS based digital x-ray detector. In addition, we acquired outstanding dual SPECT-CT images of euthanized mice. During the phase II project we will complete the integration of the high-resolution SPECT and transmission CT subsystems and develop all necessary hardware and software. The result will be a fully functional dual-modality prototype scanner for anatomical and quantitative metabolic imaging of small animals.         n/a",Sub-millimeter Simultaneous SPECT-CT for Imaging,6693866,R44RR016393,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computed axial tomography', ' computer system design /evaluation', ' image processing', ' laboratory mouse', ' noninvasive diagnosis', ' single photon emission computed tomography', ' technology /technique development', ' whole body imaging /scanning']",NCRR,"PHOTON IMAGING, INC.",R44,2003,379863,0.003920257521119878
"Rapid Cancer-Treatment Efficacy Monitoring System DESCRIPTION (provided by applicant): Evaluating cancer therapy efficacy by studying symptomatic improvement in patient condition is a popular practice due to the lack of rapid, reliable and robust quantitative evaluation protocols for routine clinical measurement of cancer therapy efficacy. Reducing time required for arriving at decisions and reducing cost without compromising accuracy could provide potentially improved treatments especially for patients with advanced leukemia of various types. This proposal focuses on rapid quantitative assessment of cancer treatment efficacy for leukemia. The proposed approach is based on quantifying apoptosis (programmed cell death) and has been shown to be one of the most reliable and one of the earliest indicators for assessing anticancer efficacy of a drug. Several other techniques are available to detect apoptosis (Agarose gel electrophoresis, Caspase-3, TUNEL assay, Morphological estimation, Annexin V assays etc). However, these techniques are inaccurate, expensive or time consuming.      A recently developed a two stage DNA diffusion assay holds promise to be an accurate, relatively inexpensive and rapid methodology for quantitative apoptosis measurement via the apoptotic index. The two stages are:(1) slide preparation and microscopy imaging, which requires approximately 1.5 hrs and (2) image analysis, which is tedious, and takes approximately 2 hours of additional intensive manual labor leading to errors in categorization of the cells. We propose to fully automate the second stage with the goal to minimize manual effort and there by reduce the human errors. This would also make the procedure more reproducible. Phase I work will involve: (1) segmentation and classification algorithm development for automatic apoptotic index calculation, and (2) characterizing the algorithm performance by inducing apoptosis in leukemia cells in culture using known apoptosis inducing agents. n/a",Rapid Cancer-Treatment Efficacy Monitoring System,6643057,R43CA101292,"['apoptosis', ' artificial intelligence', ' automated health care system', ' bioimaging /biomedical imaging', ' biomedical automation', ' computer program /software', ' fluorescence microscopy', ' image processing', ' leukemia', ' patient care management', ' prognosis', ' technology /technique development', ' tissue /cell culture']",NCI,INSIGHTFUL CORPORATION,R43,2003,99644,-0.01790085917681932
"Vessel Segmentation/Registration from Ultrasound Images    DESCRIPTION (provided by applicant):    Ultrasound is widely used for imaging of blood vessels as it is non-invasive, real-time, and relatively inexpensive. This proposal focuses on segmentation of abdominal aortic aneurysms (AAA) from ultrasound images with extension to other vascular imaging applications in the long term. Reliable quantitative evaluation of AAAs plays a pivotal role in diagnoses and frequent follow-up studies needed to avoid life-threatening rupture. These studies require vessel segmentation (for size analysis) and registration between serial studies (for monitoring the progression of the disease before and/or after vascular repair). AAA evaluation is routinely carried out for both high-risk patient populations and those treated with endovascular repair. Currently, AAA management is primarily based on measurements from two-dimensional (2-D) slices in CT scans. AAA monitoring and follow-up could be improved by 1) measurement from 3-D reconstructions, and 2) use of ultrasound imaging to minimize radiation exposure and reduce costs. 3-D ultrasound reconstructions provide accuracy comparable to that of CT. However, large inter-observer variability and long processing times preclude routine clinical use of 3-D image information. This research aims to develop software solutions for improved ultrasound-based AAA monitoring and other vascular diseases (in the long term). The tools used will be based on advanced image segmentation and registration algorithms involving curvature-driven image processing techniques and deformable models. The goal of the Phase I study is to establish feasibility of the proposed methods by demonstrating an improvement in the repeatability and accuracy of measurements and reduction in delineation time.         n/a",Vessel Segmentation/Registration from Ultrasound Images,6641019,R43HL069540,"['abdomen', ' aorta aneurysm', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' gastrointestinal circulation disorder', ' gastrointestinal imaging /visualization', ' human data', ' mathematics', ' three dimensional imaging /topography']",NHLBI,INSIGHTFUL CORPORATION,R43,2003,99621,0.029324840016921948
"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",Automated Quantitation of 3D Echocardiograms,6622226,R44HL059054,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' echocardiography', ' heart disorder diagnosis', ' heart ventricle', ' human subject', ' image processing', ' papillary muscles', ' pericardium']",NHLBI,"QUANTIGRAPHICS, INC.",R44,2003,244092,0.0026420921423836287
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6583366,R44EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' human subject', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R44,2003,431799,0.010898896819692302
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by investigator):  The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47% to 58% of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy, with 8% stating that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side-effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better-informed treatment decisions, and facilitate coping when it occurs.         n/a",Computer Imaging to Diminish Alopecia Distress,6586963,R43CA099873,"['alopecia', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted patient care', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' coping', ' desensitization psychotherapy', ' drug adverse effect', ' female', ' imaging /visualization /scanning', ' psychological aspect of cancer', ' quality of life', "" women's health""]",NCI,"BARRON ASSOCIATES, INC.",R43,2003,99973,-0.017713777863209244
"Novel Methods for Automated Key Image Selection    DESCRIPTION (provided by the applicant):  Significant new knowledge about human behavior and the brain has come to light in recent years, due in part to rapid technical developments in imaging. As the role of imaging becomes increasingly important in neurosciences, effective methods for managing and retrieving images will become even more critical; without such advances, further progress will be hindered. The goal of this proposal is the automated summarization of large imaging sets. Image summarization proffers a method to compress imaging studies by selecting only pertinent image slices that objectively document a patient's condition; as such, its applications include multimedia electronic medical records, telemedicine, and teaching files. In Phase I, development is focused on a customizable brain atlas used for registering patient imaging studies in order to select key images. This phase addresses selection of images from ""normal"" studies and studies with only subtle morphological changes, as typical of most patients with psychiatric disorders. Automatic techniques for customizing the atlas to imaging study acquisition parameters are developed, in addition to registration methods for mapping the atlas to the patient's original study. Building from this initial work, Phase II expands to encompass selection of images from ""abnormal"" studies that exhibit gross morphological changes through principle component analysis, further customization of the atlas for different age groups (e.g., pediatric), and incorporation of structured data entry (SDE) and natural language processing (NLP) of medical reports to help guide automatic selection of key images. The resultant product will be a fully automated software system that can select relevant images from any imaging study. Initial evaluation in Phase I will examine the performance of the contrast customizable atlas and summarization/relevant slice selection, as compared to human experts.         n/a",Novel Methods for Automated Key Image Selection,6583176,R43MH065764,"['archives', ' biomedical automation', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' human data', ' image processing', ' method development']",NIMH,MEDAXIS CORPORATION,R43,2003,93365,0.038741232378876604
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6725819,R01EB002247,"['anatomy', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer assisted patient care', ' computer data analysis', ' computer graphics /printing', ' computer system design /evaluation', ' diagnosis quality /standard', ' health care quality', ' health care referral /consultation', ' human data', ' image enhancement', ' image processing', ' magnetic resonance imaging', ' musculoskeletal disorder', ' nervous system disorder', ' statistics /biometry', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,383268,-0.016031712460069902
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6636516,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2003,374063,-0.0029273505490505836
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6522796,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2002,5000,0.010205458085198486
"Ultrasonic Registration of Knee Anatomy to MRI Images  DESCRIPTION (provided by applicant): The proposed research will investigate the feasibility of using intra-operative ultrasound (US) images to noninvasively register the bone surfaces of the knee to preoperative magnetic resonance (MR) images. A surgical navigation system, KneeNav, is being developed by CASurgica for intraoperatively planning the proper location of ligament attachment sites and drill tunnel locations and then guiding the surgeon to execute the plan. Despite agreement on the correct points of insertion, great variability exists in tunnel placement among surgeons and the rate of misplaced tunnels in ACL reconstruction surgery has been reported to be between 10-40 percent. Malpositioning of the bone tunnels is the main reason for revision surgery. The proposed research would increase the accuracy of the procedure versus current videoscopic techniques or versus competitive image guidance systems. The research plan is to establish a ""gold standard"" for registration accuracy using reconstructed CT scans, point-based surface matching algorithms, and optical tracking. Reconstructed MR models will be substituted for CT models and the accuracy reassessed. The US probe will then be calibrated and US surface collection will then be substituted for point based collection and the accuracy reassessed. Finally, registration of US directly to MR without reconstruction will be assessed.  PROPOSED COMMERCIAL APPLICATION: Not Available. n/a",Ultrasonic Registration of Knee Anatomy to MRI Images,6550304,R41AR049104,"['artificial intelligence', ' bioimaging /biomedical imaging', ' bone imaging /visualization /scanning', ' computed axial tomography', ' computer program /software', ' knee', ' magnetic resonance imaging', ' orthopedics', ' surgery material /equipment']",NIAMS,"CASURGICA, INC.",R41,2002,99995,0.004183250917181055
"Reliable and Robust ECG Gating Signal for MR Imaging The focus of this project is to develop and evaluate a noel and reliable system for ECG triggering during cardiac MR imaging. Understanding the mechanism of heart failure and cardiomyopathy using MRI requires reliable and robust ECG gating (or triggering). To provide effective ECG gating, the first specific aim of this Phase I project is to design and develop an ECG lead system and concomitant signal processing methodology to allow for improved ECG detection with the magnetic. Our preliminary data describing our optimal vector signal set approach , coupled with a dual derivative ECG detections scheme, appear to be effective in reliably detecting the ECG during MR imaging. An improved ECG trigger will provide cardiac MRI imaging without the artifacts of cardiac and respiratory motion. Our second specific aim is to design and develop a wireless (telemetry) infrared (IR) system for ECG trigger transmission to eliminate the need for either wiring or a fiber optic cable during MRI examinations. Additionally preliminary data demonstrates the capability of our IR telemetry system to transmit the ECG in laboratory tests. Our optimal telemetry system will also mitigate against many of the artifacts involved in the development of an effective MRI ECG trigger. During Phase I we will demonstrate the feasibility of our system by evaluating system performance in 20 human subjects undergoing cardiac MR imaging. We believe our approach should provide a reliable and robust ECG gated trigger with minimal delay from the onset of the R-wave. Such a trigger would minimize blurring artifacts from cardiac and respiratory motion and improve MR tagging studies. Should our phase I project be successful, we would develop a real-time implementation of the entire system in an expanded Phase II biomedical engineering and extended clinical study. A successful Phase I and II project would likely receive commercial backing from a major MRI instrument manufacturer. PROPOSED COMMERCIAL APPLICATIONS: Potential Commercial applications: Cardiac magnetic resonance imaging (MRI) is one of the most promising areas of MRI technology. There is a large potential commercial opportunity to develop a reliable and effective method to provide a real-time ECG gating and an infrared (IR) ECG telemetry link. n/a",Reliable and Robust ECG Gating Signal for MR Imaging,6486301,R43HL066791,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' bronchomotion', ' clinical research', ' electrocardiography', ' heart imaging /visualization /scanning', ' human subject', ' magnetic resonance imaging', ' optics', ' telemetry']",NHLBI,"PERINATRONICS MEDICAL SYSTEMS, INC.",R43,2002,335218,0.014396609097162375
"Advaced Cross-Correlator Development of a general purpose ultrasound cross-correlator module that is proposed for a) blood flow estimation in one, two and three dimensions b) blood flow estimation in an overlapped mode for use in high frequency small vessels c) coded excitation deconvolution d) A-Mode tissue characteristic correlation quantification The module would be capable of accepting Digitized RF data at rates up to 4o million 12 bit samples per second from a beamformer and returning the Sum of the Products (SOP) of multiple selectable ranges of up to 48 samples with a theoretical accuracy of 1/128th of a sample in the range dimension and a dynamic range of 36 bits in the intensity dimension at the rate of the input data. Multiple results based upon the SOP would also be output. The chosen algorithms would be loaded through a Firewire interface to a personal computer (PC) in a sub second rates. The correlator modules would output its results again through the Firewire interface into the PC for further image optimization and viewing. Initially the module would be tested with the company's Beamformer but efforts would be made to offer a universal interface so researchers could utilize the computing power of the correlator on other instruments. It is also intended to make available the parameters of the algorithms for researchers to use this tool for further developments. PROPOSED COMMERCIAL APPLICATIONS: This proposed tool would be applicable in the research then clinical evaluation of true three-dimensional real time blood flow in the major vessels of the body down to the capillary vessels and in tissue flow as in angiogenesis. The correlator potentially will be used in improving he dynamic range, and quality of ultrasonic imaging. A possible application to be investigated is the correlators potential for recognizing tissue characteristics in real time. n/a",Advaced Cross-Correlator,6479214,R43CA096018,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' digital imaging', ' phantom model', ' radiowave radiation', ' ultrasound blood flow measurement']",NCI,WINPROBE CORPORATION,R43,2002,127797,-0.028078128560909552
"Multiresolution Autofocusing for Automated Cytogenetics The goal of this project is to develop innovative digital microscope autofocusing techniques for automated cytogenetics applications.  We propose a novel multi-resolution image analysis approach to focus measurement and detection, based on the recently developed mathematical theory of wavelet transform.  In comparison to currently available single-resolution techniques, the proposed method overcomes their fundamental limitations and promises considerably more accurate, reliable and faster means to compute and determine in-focus image position for image acquisition.  This will significantly increase the ability and efficacy of automated scanning microscope instruments for clinical and cancer cytogenetics applications. In Phase 1 we will investigate the feasibility of the proposed method based on its utilization in fluorescence microscopy.  We will develop and implement the algorithm and software for multi-resolution focus function computation and in-focus position determination.  We will test and evaluate the new method against the current best-performing algorithms by comparing (1) Accuracy; (2)  Range; (3)  Insensitivity to other parameters; and (4)  Speed. If the new approach achieves superior performance, in Phase 2 the technique will be further developed and extended to bright-field microscopy applications.  When fully developed, the new technology will be made available to Applied Imaging (AIC) for integration into the PowerGene cytogenetics automation products. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new techniques are developed and qualified for routine application, they will be made available to AIC for incorporation into the PowerGene product line of cytogenetics automation equipment, both in new systems sold and as an upgrade to existing systems already in use in cytogenetics labs, thus commercializing the technology quickly. n/a",Multiresolution Autofocusing for Automated Cytogenetics,6443502,R43RR016817,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' cytogenetics', ' digital imaging', ' fluorescence microscopy', ' fluorescent in situ hybridization', ' human data', ' image enhancement', ' image processing', ' mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R43,2002,91727,0.022135390142357658
"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",Automated Quantitation of 3D Echocardiograms,6443269,R44HL059054,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' echocardiography', ' heart disorder diagnosis', ' heart ventricle', ' human subject', ' image processing', ' papillary muscles', ' pericardium']",NHLBI,"QUANTIGRAPHICS, INC.",R44,2002,255191,0.0026420921423836287
"Deployment Framework for Medical Imaging Applications DESCRIPTION (provided by applicant): There are many reasons for the relatively slow proliferation of advanced medical image processing methods but a significant reason is the present paradigm for providing access: most applications are still tied to proprietary software and hardware environments that carry significant up-front costs. The ultimate intent of this work is leverage commodity computing technologies to develop an open, extensible framework for deploying medical image processing applications in the heterogeneous, networked computing environment of today. The framework will provide clinicians and researchers access to state-of-the-art image processing applications regardless of their particular computing platform or locally available computing resources connecting them with federated database resources, with high-end computing resources, or even with their colleagues in a peer-to-peer computing environment. The aims for Phase I of this project are: (1) Demonstrate that the framework provides access to image processing applications to an extent that is largely independent of local computing resources. (2) Demonstrate that the framework is general in that the same components can be reused for deploying a wide variety of medical imaging applications. (3) Demonstrate that the framework is customizable both by third-party developers and by end-users allowing power-users to both create and deploy new applications. Work in Phase II will extend the framework and develop two-demonstration applications--computer aided diagnosis (CAD) for mammography and multimodality image fusion. The ultimate goal is to obtain key partnerships and the private equity investment necessary for commercialization, which will proceed by launching revenue-generating versions of the CAD and image fusion applications. n/a",Deployment Framework for Medical Imaging Applications,6494576,R44EB000149,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computed axial tomography', ' computer assisted diagnosis', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' human data', ' image processing', ' mammography', ' mathematics', ' positron emission tomography', ' telemedicine']",NIBIB,"FRONTIER MEDICAL, LLC",R44,2002,143577,0.00435366270367294
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6520333,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2002,363261,-0.0029273505490505836
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6421360,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2001,5000,0.010205458085198486
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6376544,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2001,373949,0.011619301168608567
"Simulation Algorithms for Spatial Pattern Recognition   DESCRIPTION (provided by applicant): A new generation of satellites is imaging       the earth's surface with unprecedented spatial and spectral resolution. With         the ability to identify local features related to environmental exposures, this      high-resolution imagery is gong to revolutionize health risk assessment. The         realization of this potential depends critically on our ability to recognize         spatial patterns on these large images. This project will develop fast spatial       null models for use in statistical pattern recognition, and will accomplish 4        aims.                                                                                                                                                                     (1) Implement fast simulation algorithms conditioned on properties of the data,      and on spatial functions;                                                            (2) Assess project feasibility by evaluating the performance of these                algorithms on existing high-resolution, hyperspectral imagery;                       (3) Implement the simulation algorithms in 2 commercial spatial analysis             software packages;                                                                   (4) Apply the software and methods to demonstrate the approach and unique            benefits for risk assessment.                                                                                                                                             The phase 1 research will address the first two aims; aims three and four will       be accomplished in phase 2 once feasibility is demonstrated. The technologic         and scientific innovations from this project are expected to greatly enhance         our ability to extract knowledge from high resolution imagery.                       PROPOSED COMMERCIAL APPLICATION:  The imminent launch of over a dozen satellites capable of high-resolution imagery is giving  health researchers powerful new data for relating environmental features to health   outcomes, but existing software packages cannot undertake spatial analysis of these  extraordinarly large data sets.   The fast simulation algorithms from this research will  be incorporated into 2 commercial software packages, providing advanced spatial  analysis for large imagery.                                                                                     n/a",Simulation Algorithms for Spatial Pattern Recognition,6401389,R43CA092807,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' image processing', ' imaging /visualization /scanning', ' statistics /biometry']",NCI,BIOMEDWARE,R43,2001,170490,-0.004718698177141467
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6445973,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2001,354009,0.010292710394488407
"Shearography for Non-Invasive Dental Health Evaluation   DESCRIPTION: Optical holography has been applied to non-invasive clinical            diagnosis and monitoring of Dental and oral/facial pathology, but has been           sharply limited in its usefulness by its requirements of high laser coherence.       absolute stability of setup. and wet processing of holograms. Physical Optics        Corporation (POC) proposes to develop a shearographic micro-optic camera as a        novel means of non-invasive Dental evaluation and characterization based on          shearing speckle interferometry, miniature camera imaging, and proprietary           neural network image processing. The innovation in this concept is the use of        shearography to avoid the need for high stability, high temporal coherence, and      wet processing. Nearfield shearography will have high spatial resolution, and        the neural network will perform real-time data processing and display.                                                                                                    The unique high resolution. real-time operation. low cost. and miniaturization       will make this device attractive to a large commercial market in Dental and          clinical applications.                                                                                                                                                    In Phase 1. POC will develop a miniature shearographic micro-optic camera            (SMOC) with fiber light delivery. a micro-CCD imaging component. and neural          network. It will be capable of distinguishing among tooth enamel, cementum,           dentine, pulp, and soft tissue.                                                      PROPOSED COMMERCIAL APPLICATION:  This compact, low-cost, high resolution non-invasive shearography device will represent a  technological breakthrough not only for oral diagnostics but also for biomedical imaging in  general.  Because of its high resolution, real-time operation, and immunity to vibration, it will  also have wide applications beyond the medical field, particularly for industrial diagnostics.  High-strength aerospace composite material evaluation and testing as well as weld and pipe  defect inspection are areas where it will be particularly welcome.                                                                                     n/a",Shearography for Non-Invasive Dental Health Evaluation,6404393,R43DE014307,"['artificial intelligence', ' bioimaging /biomedical imaging', ' dental disorder diagnosis', ' diagnosis design /evaluation', ' fiber optics', ' image processing', ' interferometry', ' lasers', ' noninvasive diagnosis', ' oral health', ' video recording system']",NIDCR,PHYSICAL OPTICS CORPORATION,R43,2001,100000,-0.009289202525873579
"MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING   A low-cost, high-resolution, high-contrast color digital camera optimized        for ophthalmology will be demonstrated. The maximum entropy camera         will be tested for its effectiveness in meeting the image quality requirements       for telemedicine and for remote screening of pre-proliferative and                   proliferative diabetic retinopathy. The proposed device exploits recent              technological advances in high sensitivity CCD cameras and digital signal            processing electronics. Today's low cost 8-bit CCD cameras do not have the           dynamic range to image the human retina, which is characterized by regions of        high reflectivity (20-40 percent), such as the optic disc, and very low              reflectivity (<2 percent), such as the macula and fovea. Existing digital            cameras used in ophthalmology are not designed to deal with the high dynamic         range and do not consider the special re-saturated characteristics of the            retina. The proposed device will be shown to offer significant improvement over      existing digital color cameras by addressing each of the deficiencies                mentioned.                                                                           PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING,6292349,R43EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R43,2001,107706,0.0075427189491405425
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6376842,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2001,607399,-0.03791389199165506
"INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE This application is a request for support of the July 2001 meeting on Information Processing in Medical Imaging (IPMI'01) to be held on the campus of the University of California, Davis. During 16 previous meetings, this biennial workshop-style conference has traditionally concentrated on the latest advancements in the acquisition, processing, analysis, display, and perception of medical images. At the 2001 meeting, we intend to continue this tradition while encouraging contributions from young investigators, specifically advanced graduate students, postdoctoral fellows, and junior faculty. The emphasis is on applied mathematical techniques in computer vision, microimaging techniques, and information technology. Advances reported at this meeting are especially important in the study of neurological disorders, cardiovascular disease and cancer, although applications in the area of functional genomics, orthopedics and soft tissue biomechanics are also represented. The conference attracts researchers from a broad range of disciplines, particularly computer scientists, neuroscientists, electrical engineers, cardiologists, mathematicians, oncologists, and physicists. All share an interest in improving the quality of health care through the extraction and presentation of diagnostic information from medical image data. Approximately 130 individuals will be invited to attend; there will be approximately 25-30 speakers and 25-30 poster presentations. Papers are accepted based on peer review by a 25 member scientific committee of 15-20 page manuscripts. Selected papers will be published in proceedings that will be available at the conference.  n/a",INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE,6231502,R13RR015416,"['bioimaging /biomedical imaging', ' biomechanics', ' cardiovascular disorder', ' computer data analysis', ' diagnosis design /evaluation', ' functional /structural genomics', ' image processing', ' informatics', ' mathematics', ' meeting /conference /symposium', ' neoplasm /cancer', ' nervous system disorder', ' orthopedics']",NCRR,UNIVERSITY OF CALIFORNIA DAVIS,R13,2001,5000,0.00760400492449939
"INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE This application is a request for support of the July 2001 meeting on Information Processing in Medical Imaging (IPMI'01) to be held on the campus of the University of California, Davis. During 16 previous meetings, this biennial workshop-style conference has traditionally concentrated on the latest advancements in the acquisition, processing, analysis, display, and perception of medical images. At the 2001 meeting, we intend to continue this tradition while encouraging contributions from young investigators, specifically advanced graduate students, postdoctoral fellows, and junior faculty. The emphasis is on applied mathematical techniques in computer vision, microimaging techniques, and information technology. Advances reported at this meeting are especially important in the study of neurological disorders, cardiovascular disease and cancer, although applications in the area of functional genomics, orthopedics and soft tissue biomechanics are also represented. The conference attracts researchers from a broad range of disciplines, particularly computer scientists, neuroscientists, electrical engineers, cardiologists, mathematicians, oncologists, and physicists. All share an interest in improving the quality of health care through the extraction and presentation of diagnostic information from medical image data. Approximately 130 individuals will be invited to attend; there will be approximately 25-30 speakers and 25-30 poster presentations. Papers are accepted based on peer review by a 25 member scientific committee of 15-20 page manuscripts. Selected papers will be published in proceedings that will be available at the conference.  n/a",INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE,6231502,R13RR015416,"['bioimaging /biomedical imaging', ' biomechanics', ' cardiovascular disorder', ' computer data analysis', ' diagnosis design /evaluation', ' functional /structural genomics', ' image processing', ' informatics', ' mathematics', ' meeting /conference /symposium', ' neoplasm /cancer', ' nervous system disorder', ' orthopedics']",NCRR,UNIVERSITY OF CALIFORNIA DAVIS,R13,2001,5000,0.00760400492449939
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6484619,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2001,337739,-0.0029273505490505836
"METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES DESCRIPTION (Adapted from Applicant's Abstract):  The aim of this proposal       is to further develop and validate algorithms for analysis of SPAMM MR           cardiac images based on novel spline methods.  MRI is unique in its ability      to non-invasively and selectively alter tissue magnetization, and create         tagged patterns within the deforming tissue such as the heart muscle.  The       resulting pattern defines a time-varying curvilinear coordinate system on        the underlying tissue, allowing for precise and quantitative measurement of      tissue motion and deformation.  The investigators are developing two             frameworks for analysis of SPAMM tagged images, both of these aimed at           providing a more automated and reproducible approach to analysis of SPAMM        data, as well as providing dense 3-D displacement information at all points      within the LV myocardium.  The investigators propose to (a) further develop      and extend our analyses techniques.  The extensions considered will all be       related and based on currently developed computer vision-based techniques        for regional LV wall motion analysis, that operates either on a sequence of      SA slice stacks or on a time sequence of single slice.  (b) The                  investigators will validate the motion tracking methods by comparing ""true""      and algorithm-estimated motion trajectories:  1) on dense field of points        derived from 3-D tagged computer models of objects that simulate the moving      LV, 2) on dense field of points derived from Finite Element Model                simulations of the constitutive equations of LV deformations (once again tag     planes will be superimposed on the time course of simulated geometries), 3)      on selected points in the LV myocardium of the in vivo heart using a porcine     model.  Here, ""true"" motion will be determined by tracking implanted image       distinguishable markers.  (c) The investigators will test whether regions of     postmortem myocardial injury imply similar-sized and locate regions of           altered deformations (as measured by parameters developed in (a)).  The          algorithm-derived LV function assessment based on the analysis of in vivo        tagged MRI sequences will be compared with postmortem myocardial injury          assessment determined by myocardial staining techniques.  The validated          parameters will also be use to examine the time-course of change in the          ischemic areas of the chronic animal models.                                      n/a",METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES,6389619,R01HL057628,"['bioimaging /biomedical imaging', ' cardiography', ' clinical research', ' computer data analysis', ' computer simulation', ' diagnosis design /evaluation', ' heart motion', ' histopathology', ' human subject', ' image processing', ' magnetic resonance imaging', ' myocardial ischemia /hypoxia', ' swine']",NHLBI,BARNES-JEWISH HOSPITAL,R01,2001,122402,-0.01563632804790492
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6211037,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2000,416478,0.011619301168608567
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6210821,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2000,395990,0.010292710394488407
"MICRO-OPTICS-BASED DIGITAL ALLERGEN COUNTER The current pollen identification and counting method based on microscopic visual examination is very time consuming and labor intensive. More importantly, it is very ""subjective"" and not truly scientific. Intelligent Optical Systems, Inc. proposes to develop a portable digital allergen counter (DAC) to accurately and reliably count and identify airborne pollen grains and fungal spores. The proposed DAC combines a micro-image scanner, a high-speed video chip, an allergen morphology data bank, and a built-in image processor into an integrated and automated pollen counter. The DAC will rapidly identify and quantify pollen, grains and spores. By making it much easier to collect allergen information in multiple locations, the proposed device will reduce morbidity by providing improved warnings on days with high pollen counts. The specific aims of the Phase I project are to design and construct optical image scanner suitable for allergen detection, identify the morphology of several types of pollen, grains, and spores, integrate the DAC system and test and evaluate the system feasibility. In Phase II, an engineering prototype of a portable instrument will be built and field-validated with real-world samples. We will also expand its capability to increase the pollen types of interest. PROPOSED COMMERCIAL APPLICATIONS: A compact, simple, and easy-to-use digital allergen counting system that can monitor indoor or outdoor air quality that will minimize people's overexposure to allergens.  This device is for aerobiological research that could be beneficial for public health, medical pharmaceutical and engineering applications. Universities, physicians, public health organizations, National Allergy Bureau (NAB) stations, and private air sampling consultants will  purchase the device.  n/a",MICRO-OPTICS-BASED DIGITAL ALLERGEN COUNTER,6211164,R43HL064459,"['air sampling /monitoring', ' allergens', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' computer program /software', ' computer system design /evaluation', ' image processing', ' monitoring device', ' optics', ' particle counter', ' pollen']",NHLBI,"INTELLIGENT OPTICAL SYSTEMS, INC.",R43,2000,99995,-0.014719160396084195
"IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY DESCRIPTION:  The research and development of teleradiology and telemedicine     systems has progressed through many technical and clinical endeavors.  When      dealing with large volume image transmission and storage, image data             compression is an outstanding issue in medical applications to which current     techniques were not designed to address.  The technical objectives of this       project are to develop optimized error-free as well as error-controllable        methods for medical image compression based on wavelet transform and             associated methods.  In this project, we employ both advanced artificial         intelligent and compression techniques to achieve these goals.                                                                                                    Our recent research outcomes include:  (a) development of a mathematics          approach to unify prediction, subband, and wavelet transforms, (b)               development of convolution neural network training methods to obtain             optimized wavelet kernel, (c) development of a data splitting technique to       improve edge accuracy and to provide error-control methods, and (d)              development of an integer implementation method for all wavelet transforms,      etc.  Based on the above technical advances, we propose to use integer form      of an adaptive (optimized) wavelets in conjunction with newly developed          coding methods such as ""partitioning in hierarchical trees"" (PHT) for            lossless compression.  For error-controllable approaches, we propose to use      adaptive wavelets coupled with optimized neural network prediction methods       in this study.  Since lossless compression is a part of the error -              controllable method, both systems can be implemented in the same scheme          which is a breakthrough approach in the field.  We will compare the              compression results (i.e., compression ratio and speed) of the proposed          compression methods with those of the current wavelet techniques using the       embedded zero-tree coding method.  At the end of the project, we will            deliver a software package for the radiological society.  Hence, the             evaluation for various clinical applications using the proposed methods can      be performed by the investigators.                                                                                                                                As the field of telemedicine is rapidly growing, we believe that development     of a dedicated compression module for economical storage and fast                communication of patient data (particularly for patient images) is               necessary.  This project is designed to address the related technical issues     with a strong clinical consideration.                                             n/a",IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY,6173899,R01CA079139,"['artificial intelligence', ' bioimaging /biomedical imaging', ' charge coupled device camera', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' human data', ' image processing', ' radiology', ' telemedicine']",NCI,GEORGETOWN UNIVERSITY,R01,2000,176034,0.019965343165721815
"DEVELOPMENT OF A KNOWLEDGE-BASED IMAGE REPORTING SYSTEM We have constructed a prototype structured reporting system that replaces conventional dictation and transcription for medical image reporting. Key design features include reporting speed, generation of graphical reports, structured storage of imaging findings, and the use of existing lexicons. Pilot timing data suggest that a radiologist using our system can generate a report more rapidly than with conventional reporting methods or speech recognition systems. Support is sought to refine the prototype, and to conduct feasibility testing. The specific aims are (1) to augment and refine a hierarchical test lexicon of imaging terms (2) to develop methods for the representation and reporting of imaging findings and their logical relationships, (3) to evaluate the system's performance on clinical imaging reports, and (4) to assess the completeness of existing lexicons for imaging. The project is supported by a Technical Advisory Committee comprised of experts in key methodological areas. A successful Phase I will lead (in Phase II) to testing of the approach for cross-sectional imaging, to adoption, augmentation, and use of an existing lexicon, to construction of real-time decision support techniques based on the knowledge base of imaging findings generated by the system, and to system evaluation in a clinical setting. PROPOSED COMMERCIAL APPLICATIONS: Our structured reporting system is appealing to radiologists because it speeds up the reporting process compared to conventional dictation/transcription or speech recognition. In addition, the system eliminates the costs, delays, inaccuracies, and other organizational problems associated with transcription services, thereby improving patient care. Therefore, time-efficient, speech-augmented structured reporting systems will likely capture a significant segment of the $1.2 billion annual market for radiology transcription services.  n/a",DEVELOPMENT OF A KNOWLEDGE-BASED IMAGE REPORTING SYSTEM,6073984,R43LM006837,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted medical decision making', ' computer system design /evaluation', ' data management', ' imaging /visualization /scanning', ' information systems', ' vocabulary', ' vocabulary development for information system']",NLM,"EDICT SYSTEMS, INC.",R43,2000,98563,-0.010832924710334054
"WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS This project aims to develop and commercialize significantly improved software for digital enhancement of the detail of chromosome banding patterns in microscopic images. These investigators have developed an innovative technique for this application, based upon wavelet transforms and multiresolution image analysis. Used with modern computerized chromosome analysis the proposed technique promises significantly improved enhancement of chromosome banding patterns and more effective visual detection of subtle rearrangements. This will help clinicians and researchers detect previously invisible or sub-visible band pattern alterations in conventional and high resolution banding. It will significantly increase the ability of automated instruments to assist the evaluation of chromosome alterations in clinical samples and in normal and neoplastic mammalian cells. During Phase I we implemented and tested three wavelet transforms with desirable mathematical properties. We developed a prototype multiresolution image processing system for chromosome enhancement. We obtained extremely encouraging results, strongly suggesting that these techniques offer considerably improved enhancement capability over conventional methods. and clearly demonstrating the feasibility of this approach. In Phase II we will complete the implementation and refinement of the software. We will implement several wavelet design approaches and evaluate many wavelet transform basis function sets that potentially can bring out relevant detail in chromosome banding patterns. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new enhancement techniques are developed and qualified for routine application, they will be incorporated into PSII's PowerGene products, both in new systems sold and as an upgrade to existing systems.  n/a",WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS,6181715,R44HD033658,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' chromosome aberrations', ' chromosomes', ' computer data analysis', ' computer program /software', ' computer simulation', ' cytogenetics', ' digital imaging', ' image enhancement', ' image processing', ' molecular dynamics']",NICHD,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2000,260552,0.01389115847613041
COMPUTER AIDED CARDIAC MEASUREMENT The objective of the proposed research is to develop a method for providing fast and accurate measurements of volume and ejection fraction from 3D echo images. Our Computer Aided Measurement System will reconstruct the LV endocardium using a few user selected points on oriented echocardiographic images together with prior shape and size knowledge. The Specific Aims for Phase I are: 1. To improve the accuracy of quantitative echo while minimizing manual labor. 2. To improve the ease of use of the prototype system for application in a clinical setting. 3. To expand the catalog representing our knowledge base by acquiring additional large volume and abnormally shaped LV's in order to enhance fitting accuracy for atypical shapes. Previously described methods of analyzing echocardiograms in 3D require so much manual labor that this modality has been limited to research applications. The advantages of our proposed approach are that it makes the superior accuracy and reproducibility of 3D echo available for clinical practice. Furthermore this process will be applicable to other imaging modalities. PROPOSED COMMERCIAL APPLICATIONS: This research will lead to products which can be sold to echocardiography system manufacturers and end users. The products will provide accurate and convenient value measurements.  n/a,COMPUTER AIDED CARDIAC MEASUREMENT,6211201,R43HL065827,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' echocardiography', ' heart dimension /size', ' heart disorder diagnosis', ' human data', ' image processing', ' measurement']",NHLBI,"QUANTIGRAPHICS, INC.",R43,2000,100000,0.007931070628455456
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,6185220,R01LM006326,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,2000,117821,0.0006513361552284372
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,6185220,R01LM006326,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,2000,16337,0.0006513361552284372
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6173999,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2000,563099,-0.03791389199165506
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6193019,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2000,478050,-0.0029273505490505836
"METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES DESCRIPTION (Adapted from Applicant's Abstract):  The aim of this proposal       is to further develop and validate algorithms for analysis of SPAMM MR           cardiac images based on novel spline methods.  MRI is unique in its ability      to non-invasively and selectively alter tissue magnetization, and create         tagged patterns within the deforming tissue such as the heart muscle.  The       resulting pattern defines a time-varying curvilinear coordinate system on        the underlying tissue, allowing for precise and quantitative measurement of      tissue motion and deformation.  The investigators are developing two             frameworks for analysis of SPAMM tagged images, both of these aimed at           providing a more automated and reproducible approach to analysis of SPAMM        data, as well as providing dense 3-D displacement information at all points      within the LV myocardium.  The investigators propose to (a) further develop      and extend our analyses techniques.  The extensions considered will all be       related and based on currently developed computer vision-based techniques        for regional LV wall motion analysis, that operates either on a sequence of      SA slice stacks or on a time sequence of single slice.  (b) The                  investigators will validate the motion tracking methods by comparing ""true""      and algorithm-estimated motion trajectories:  1) on dense field of points        derived from 3-D tagged computer models of objects that simulate the moving      LV, 2) on dense field of points derived from Finite Element Model                simulations of the constitutive equations of LV deformations (once again tag     planes will be superimposed on the time course of simulated geometries), 3)      on selected points in the LV myocardium of the in vivo heart using a porcine     model.  Here, ""true"" motion will be determined by tracking implanted image       distinguishable markers.  (c) The investigators will test whether regions of     postmortem myocardial injury imply similar-sized and locate regions of           altered deformations (as measured by parameters developed in (a)).  The          algorithm-derived LV function assessment based on the analysis of in vivo        tagged MRI sequences will be compared with postmortem myocardial injury          assessment determined by myocardial staining techniques.  The validated          parameters will also be use to examine the time-course of change in the          ischemic areas of the chronic animal models.                                      n/a",METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES,6184044,R01HL057628,"['bioimaging /biomedical imaging', ' cardiography', ' clinical research', ' computer data analysis', ' computer simulation', ' diagnosis design /evaluation', ' heart motion', ' histopathology', ' human subject', ' image processing', ' magnetic resonance imaging', ' myocardial ischemia /hypoxia', ' swine']",NHLBI,BARNES-JEWISH HOSPITAL,R01,2000,119129,-0.01563632804790492
"Machine Learning and artificial intelligence algorithms for smartphone-based malaria screening and diagnostics Data scientists with machine learning and artificial intelligence expertise at NLM have developed new intelligent methods to screen for malaria. Particularly, scientists used deep learning methods to detect and count infected red blood cells and parasites. Deep learning is a family of machine learning methods based on artificial neural networks. The scientists adapted these methods to take account of the specific features of blood smear images, in particular the relatively small size of parasites.   Algorithms were developed for both thin and thick smears, which are the two types of bloods smears used by experts in the field to diagnose malaria. The networks can detect blood cells in thin smears and classify them into infected and uninfected cells. They can also detect parasites in thick smears, thus covering the full screening spectrum in practice. Proven algorithms were then transformed for use on on Android smartphones. This required research into designing new and smaller network structures that can cope with the lower hardware specifications of smartphones in terms of processing units and memory. The resulting system is the first smartphone application for malaria screening that can process both thin and thick smears using deep learning. The application has an integrated image upload function to upload images to a cloud storage for further processing or archiving, and supports multiple languages. The software is publicly available in the Google Play Store (NLM MalariaScreener), where researchers can download it for testing or contributing training data. Future efforts plan to make the modularized source code publicly available to promote greater worldwide use. Field testing continues with collaborations with several sites worldwide: viz., Thailand, Bangladesh, Kenya, Uganda, Pakistan, Thailand, and Mali. The goal is to test the stability of the app in different environments, under different imaging parameters, and to verify the high correlation of the algorithmic output with expert counts, as in the practical experiments published. Researchers are also in contact with FIND (www.finddx.org), a non-profit organization driving innovation in the development and delivery of diagnostics, to test the app in the field and make improvements. Several suggested advances have been already implemented..   To train the mobile smartphone application for thin and thick smears, scientists used annotated images sets. For thick smears, they acquired about 3000 images from 200 patients at a hospital in Chittagong, Bangladesh, including 85,000 malaria parasites, which an expert all annotated manually. They collected a similarly-sized dataset for thin smears. Both thin and thick smear images were acquired for Plasmodium falciparum, which is the deadliest parasite species causing malaria in humans. In this fiscal year, researchers acquired similar data with Plasmodium vivax, which is another common malaria parasite species, in both thin and thick smears. Using this data, researchers have started training of deep learning networks for detecting and discriminating parasite species, which is an important clinical decision in practice. CEB will make all acquired data publicly available over time so that other researchers can train and test their algorithm. As a first step, researchers made more than 1800 thick smear images from 150 patients with Plasmodium falciparum infections available in conjunction with a publication.  In terms of methods, NLM researchers developed a custom-made segmentation technique to extract red blood cells from a blood smear image for classification, arguing that the relatively small size of red blood cells compared to the image dimensions can be a problem for other techniques. Researchers also implemented a multi-class classifier than can detect infected and uninfected red blood cells as well as white blood cells, in an attempt to avoid detecting white blood cells in a separate preprocessing step. Other methods developed include an augmentation method to add new instances of objects, such as infected cells, into an image to generate larger, and balanced training data. This method can be used as a pre-processing step for segmentation and object detection networks (for example, Faster R-CNN, Mask R-CNN, or YOLO). n/a",Machine Learning and artificial intelligence algorithms for smartphone-based malaria screening and diagnostics,10268074,ZIALM010006,"['Africa South of the Sahara', 'Algorithms', 'Android', 'Archives', 'Artificial Intelligence', 'Asia', 'Automobile Driving', 'Bangladesh', 'Bite', 'Blood', 'Blood Cells', 'Blood Screening', 'Cells', 'Cellular Phone', 'Cessation of life', 'Classification', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Culicidae', 'Custom', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Disease Vectors', 'Drug resistance', 'Environment', 'Erythrocytes', 'Family', 'Female', 'Field Workers', 'Film', 'Future', 'Goals', 'Hospitals', 'Human', 'Image', 'Immigrant', 'Infection', 'Intelligence', 'Kenya', 'Language', 'Learning', 'Leukocytes', 'Light Microscope', 'Machine Learning', 'Malaria', 'Mali', 'Manuals', 'Masks', 'Memory', 'Methods', 'Microscope', 'Modernization', 'Nonprofit Organizations', 'Output', 'Pakistan', 'Parasites', 'Patients', 'Persons', 'Plasmodium falciparum', 'Plasmodium vivax', 'Play', 'Process', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Running', 'Scientist', 'Severity of illness', 'Site', 'Source Code', 'Standardization', 'Structure', 'System', 'Techniques', 'Testing', 'Thailand', 'Thick', 'Thinness', 'Time', 'Training', 'Uganda', 'United States', 'Work', 'artificial neural network', 'base', 'cloud storage', 'deep learning', 'design', 'digital imaging', 'disorder control', 'drug testing', 'early screening', 'experience', 'experimental study', 'field study', 'fighting', 'global health', 'innovation', 'intelligent algorithm', 'learning network', 'learning strategy', 'machine learning method', 'malaria transmission', 'novel vaccines', 'portability', 'resistant strain', 'screening', 'smartphone Application', 'stability testing', 'vector control']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2020,488287,-0.11724139263171342
"TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH Developing artificial intelligence technology for medical imaging applications requires training models on large and diverse datasets.  Currently, aggregation of large data repositories, including radiology and pathology images, is limited by concerns around patient privacy.  In order to successfully share medical images, an institution must be able to quickly and accurately de-identify large numbers of images in batches.  This process is currently manual and time-consuming. We propose a pipeline to remove PHI from both radiology DICOM images and pathology whole slide images by leveraging machine learning, natural language processing, and compartmentalized workflow techniques to significantly reduce the human intervention needed to anonymize medical images.  In addition to examining header data in the images, we will use optical character recognition and computer vision algorithms to detect text in any location or orientation in the image, then automatically record and subsequently purge these regions. These techniques will be configured to work on a variety of image types (CT, MRI, radiograph, etc) and cover multiple OEM vendors for both radiology and pathology images. This phase I statement of work will construct the software tools, methods, and datasets necessary to facilitate a phase II where the complex algorithms needed for autonomous deidentification will be developed.  This phase II processing will be referred to throughout this document as the workflow. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH,10274086,5N91020C00023,"['Algorithms', 'Artificial Intelligence', 'Complex', 'Computer Vision Systems', 'Consumption', 'Contracts', 'Data', 'Data Set', 'Digital Imaging and Communications in Medicine', 'Elements', 'Excision', 'Head', 'Human', 'Image', 'Ingestion', 'Institution', 'Intervention', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Medical Imaging', 'Medical Technology', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology', 'Phase', 'Process', 'Radiology Specialty', 'Research', 'Sampling', 'Slide', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Vendor', 'Work', 'cancer imaging', 'data ingestion', 'data warehouse', 'file format', 'optical character recognition', 'pathology imaging', 'patient privacy', 'purge', 'radiological imaging', 'whole slide imaging']",NCI,"BIODATA CONSORTIUM, LLC",N43,2020,386526,0.05068718185756718
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,-0.0016517571768203075
"Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study PROJECT SUMMARY Road traffic injuries are a major contributor to the burden of disease globally with nearly 1.3 million deaths globally and as many as 50 million injured annually with pedestrians and cyclists in low and middle-income countries (LMICs) among the most affected. Road infrastructure of the built environment (e.g., sidewalks), neighborhood design (e.g., street connectivity) and urban development (e.g., urban sprawl) are key determinants of the risk of pedestrian injuries. In LMICs, poor road infrastructure and neighborhood design are acknowledged as being important contributors to rising numbers of road traffic injuries and deaths, but there are few studies systematically identifying and quantifying what specific features of the built environment are contributing to motor vehicle collisions in these settings. Within LMIC cities, there are often large disparities where infrastructure is improved that reflect socioeconomic characteristics, leading to health inequities in road traffic injury. The paucity of georeferenced data on the built environment in LMICs has made research on road traffic injuries more difficult, though recent advances in computer vision and image analysis combined with Big Data of publicly available, georeferenced, images of roads worldwide (e.g., Google Street View, GSV) can help overcome the paucity of data and the cost and time limitations of collecting and analyzing data on the built environment in LMICs. Automated image analysis has largely been made possible via deep learning, a subfield of artificial intelligence and machine learning and relies on training neural networks to detect and label specific objects within images. These methods can drastically reduce the barriers to citywide built environment and traffic safety research in LMIC cities, thus substantially increasing research capacity and generalizability. My career goal is to become an independent investigator in global urban health with a focus on road safety and the built environment in LMICs. I propose undertaking research and training in deep learning methods applied to public health in the setting of Bogota, Colombia: 1) Develop neural networks to create a database of BE features of the road infrastructure from image data and to create neighborhood typologies from those features; 2) Assess the association between neighborhood-level BE features and typologies and pedestrian collisions and fatalities and road safety perceptions; 3) Assess the association of neighborhood social environment characteristics with pedestrian collision and fatalities, perceptions, and BE features and typologies. I am seeking additional training in 1) developing competency in deep learning methods applied to public health; 2) creating neighborhood indictors and typologies of health and the built environment; 3) applying Bayesian spatiotemporal models to understand how neighborhood characteristics and typologies influence health; 4) develop skills in multi-country collaboration, grant writing and overseeing research projects in LMICs. PROJECT NARRATIVE Roads and neighborhoods with a built environment that support safe and active transportation are a major priority in low- and middle-income countries (LMICs) due to 90% of road traffic deaths occurring in these locations, especially to pedestrians and other vulnerable road users, yet data on key built environment features at a large scale are not always readily available in these settings. My career goal is to improve population health by examining the effects of the built environment and transportation on health through the adoption and use of methods that can leverage Big Data sources and answer complex, multilevel research questions by overcoming the lack of built environment data in LMICs. The proposed research uses deep learning and advanced statistical methods to create a citywide dataset of built and social environment features in Bogota, Colombia that will provide crucial data to answer questions of their impact on pedestrian injuries and deaths, as well as assessing the presence of health inequities in their distribution and that will lay the groundwork to expand these efforts to more cities in Latin America and other LMICs.","Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study",10123391,K01TW011782,"['Adopted', 'Adoption', 'Affect', 'Artificial Intelligence', 'Big Data', 'Cessation of life', 'Characteristics', 'Cities', 'Classification', 'Collaborations', 'Colombia', 'Competence', 'Complex', 'Computer Vision Systems', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Discipline', 'Education', 'Future', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Injury', 'Label', 'Latin America', 'Lead', 'Location', 'Machine Learning', 'Mathematics', 'Mentors', 'Methods', 'Modeling', 'Neighborhoods', 'Perception', 'Persons', 'Public Health', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Risk', 'Safety', 'Social Environment', 'Statistical Methods', 'Time', 'Training', 'Transportation', 'Typology', 'Urban Developments', 'Urban Health', 'Vehicle crash', 'Writing', 'automated image analysis', 'built environment', 'burden of illness', 'career', 'career development', 'computer science', 'cost', 'data infrastructure', 'deep learning', 'design', 'digital imaging', 'experience', 'high risk', 'improved', 'injured', 'learning strategy', 'low and middle-income countries', 'neighborhood association', 'neural network', 'pedestrian injury', 'population health', 'skills', 'social', 'socioeconomics', 'spatiotemporal', 'virtual']",FIC,DREXEL UNIVERSITY,K01,2020,138024,-0.0025050285482807132
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,-0.0016517571768203075
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,9955253,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Comparative Effectiveness Research', 'Computer Models', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'algorithm development', 'artificial neural network', 'automated segmentation', 'base', 'clinical decision-making', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'fall injury', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'secondary outcome', 'segmentation algorithm', 'skills', 'standard of care', 'support vector machine', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2020,186183,0.008548418236402195
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10019459,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2020,291252,-0.0008068280014990528
"Ophthalmic Image analysis and machine learning for eye disease detection Glaucoma: In a collaboration with the National Eye Institute (NEI), we developed a two-step automatic method to segment optic disc and cup from fundus images using deep learning and ensemble learning. First, a Mask R-CNN deep learning algorithm is adapted to estimate region of interest (ROI) from the fundus image. Next, two ensemble learning models having fully connected neural networks (FCNs) with a U-Net architecture are used for the segmentation of optic disc and cup from the ROI. Each ensemble learning model is composed of three FCNs, where each FCN uses a different size of ROI as its input to collect different spatial information. Raw ROIs are used as inputs for the optic disc segmentation model and masked ROIs are used as inputs for the cup segmentation model. We evaluate performance of our proposed EL method using four datasets and ten-fold cross validation. The proposed method results in 0.9303 Jaccard Index and 0.9635 Dice Coefficient in optic disc segmentation, and 0.8096 Jaccard Index and 0.8915 Dice Coefficient in cup segmentation, respectively and is better than other state-of-the-art methods.  AMD: Ophthalmologists use Optical Coherence Tomography (OCT) as one of key modalities to diagnose AMD and decide whether to perform anti-VEGF therapy since it provides cross-section of patients retina layers. Unfortunately, it is a tedious and time-consuming work. In our work we automatically categorize OCT images into four categories (Choroidal neovascularization (CNV), Diabetic macular edema (DME), Drusen, and Normal) using deep learning and ensemble learning methods. Several Convolutional Neural Networks (CNNs) are adapted for the classification. To standardize training and test images, Fully Convolutional Networks (FCN) is applied to remove noise and a projection method is used to adjust tilted retina layers in the images. We train several CNNs and implement an ensemble learning model based on CNNs to further improve the performance. Among the CNNs, ResNet152 shows the best results with 0.9810 accuracy, 0.9810 sensitivity, and 0.9937 specificity, and the ensemble learning based on three ResNet152 shows 0.989 accuracy, 0.989 sensitivity, and 0.996 specificity.  Uveitis: Following last years effort next steps are to improve segmentation accuracy by using more FA images and different FCN models. Toward this goal, we are annotating images to traing machine learning classifiers and image processing algorithms. n/a",Ophthalmic Image analysis and machine learning for eye disease detection,10268079,ZIALM010015,"['Affect', 'Age related macular degeneration', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Blindness', 'Blood Vessels', 'Caliber', 'Categories', 'Choroidal Neovascularization', 'Classification', 'Collaborations', 'Consumption', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drusen', 'Early Diagnosis', 'Early treatment', 'Exhibits', 'Extravasation', 'Exudative age-related macular degeneration', 'Eye', 'Eye diseases', 'Family', 'Fluorescein Angiography', 'Glaucoma', 'Goals', 'Image', 'Image Analysis', 'Inflammation', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Modeling', 'National Eye Institute', 'Nerve Fibers', 'Neural Network Simulation', 'Noise', 'Ophthalmologist', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Patients', 'Performance', 'Pigments', 'Rare Diseases', 'Retina', 'Retinal Neovascularization', 'Severities', 'Severity of illness', 'Specificity', 'Standardization', 'Testing', 'Time', 'Tissues', 'Training', 'Uveitis', 'Validation', 'Variant', 'Work', 'base', 'bevacizumab', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'diabetic', 'disease diagnosis', 'fundus imaging', 'geographic atrophy', 'image processing', 'improved', 'indexing', 'interest', 'learning classifier', 'learning strategy', 'macula', 'macular edema', 'neural network', 'optic cup', 'pressure']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2020,548436,0.010342341521464165
"Development of COVID-19 Imaging Tools with Artificial Intelligence This will be piloted in the NIH Intramural Research Program, and will eventually include opportunity for research purposes to uploading of DICOM CT images with an immediate output result of % likelihood COVID on chest CT scans. NIH CC and NCI have been among the first to gather multi-national data and develop freeware public AI solutions based on COVID CTs for both academic and commercial developer use. A uniform and validated imaging biomarker solution for use for a clinical trial setting should expedite the pathway towards drug discovery and early validation or response signals. The NIH team is working with commercial and academic partners to assess quantification tools for COVID metrics. NIH models can detect COVID-19 and differentiate from H1N1 influenza, fungal, or bacterial pneumonias as well as cancer, normal lungs, and other entities with high performance. Ongoing work will attempt to identify and flag CT cases for immediate radiologist review, thus flagging and encouraging isolation, PCR testing, and contact tracing for high suspicion and or asymptomatic cases. Other models may predict the later need for critical care therapies based upon an initial CT scan early on, at the initial point of care. The ability to standardize the quantification of CT responses would enable critical cross-platform comparisons among drug combinations and therapeutic approaches, which is vital, given the likely necessity for combination therapies across classes or drug plus supportive therapy pathways. It has also been shown that pre-symptomatic CT AI can track disease in a predictable fashion, and that this disease dynamic curve is recapitulated in a non-human primate model of COVID-19. Prior work with extramural partners has demonstrated that federated learning can overcome shortcomings in unbalanced source data for imaging AI, and that the application of a specific federated learning technique can overcome the gap, thus showing that the data does not need to be shared in order to build quality AI models from medical imaging. BACKGROUND / SIGNIFICANCE: CT image processing and deep learning models provide quantifiable metrics to serve as a noninvasive biomarker for pulmonary involvement. Correlation with a variety of clinically relevant metadata may enable the use of CT AI during outbreaks to identify CT biomarker features for clinical trials in COVID-19. This effort will cross link with numerous campus efforts, including preclinical NIAID efforts and clinical validation trials for image processing for classification and characterization in COVID-19. A multi-national dataset in COVID-19 is being collected and curated to build public models for COVID-19 classification and quantification and has verified that asymptomatic viral shedding may co-exist in the presence of a positive CT scan with analysis of thousands of CT scans from 4 nations. The validation of CT as a targeted epidemiological tool could potentially augment PCR and antibody testing in specific limited scenarios, given that peak infectivity may be pre-symptomatic. GOALS: Facilitate validation of a standardized tool for establishment of public deep learning models for quantification and standard response criteria metrics for characterization of COVID-19 clinical trials. HYPOTHESIS: CT imaging data aggregation and artificial intelligence will inform and expedite clinical and preclinical studies of COVID-19. SPECIFIC AIMS: Develop, validate, and translate tools for automated and standardized CT assessment and quantification of COVID-19 disease with deep learning methodologies for use during clinical trials. n/a",Development of COVID-19 Imaging Tools with Artificial Intelligence,10262554,ZIABC011936,"['Antibodies', 'Artificial Intelligence', 'Bacterial Pneumonia', 'Biological Markers', 'COVID-19', 'Chest', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Combined Modality Therapy', 'Communicable Diseases', 'Communities', 'Contact Tracing', 'Critical Care', 'Data', 'Data Aggregation', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Disease', 'Disease Outbreaks', 'Drug Combinations', 'Epidemiology', 'Extramural Activities', 'Goals', 'Image', 'Imaging Device', 'Immunology', 'Industry', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Intramural Research Program', 'Laboratories', 'Learning', 'Lung', 'Malignant Neoplasms', 'Medical Imaging', 'Metadata', 'Methodology', 'Modeling', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Outcome Measure', 'Output', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Pneumonia', 'Research', 'Resource Allocation', 'Seasons', 'Signal Transduction', 'Source', 'Standardization', 'Supportive care', 'Techniques', 'Testing', 'Therapeutic', 'Translating', 'United States National Institutes of Health', 'Validation', 'Viral Pneumonia', 'Virus Shedding', 'Work', 'X-Ray Computed Tomography', 'base', 'chest computed tomography', 'clinically relevant', 'coronavirus disease', 'crosslink', 'cytokine', 'deep learning', 'disease phenotype', 'drug discovery', 'flu', 'fungal pneumonia', 'image processing', 'imaging biomarker', 'influenza pneumonia', 'large datasets', 'model building', 'nonhuman primate', 'pandemic disease', 'point of care', 'pre-clinical', 'preclinical study', 'radiologist', 'response', 'success', 'tool']",NCI,DIVISION OF BASIC SCIENCES - NCI,ZIA,2020,290557,-0.014533662543223061
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,0.02706498683620171
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,9972588,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,318155,0.008908628446092711
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9913520,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'algorithm training', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,235027,0.01549491960747274
"Advancing artificial intelligence algorithms for cervical cancer diagnostics We continued research in generalizing the outcome from landmark paper describing a breakthrough two-stage Convolutional Neural Network (CNN) based deep learning algorithm, called automated visual evaluation (AVE) of the acetowhitened cervix, that  outperformed standard screening tests (clinician interpretation of the same cervical images, Pap smears, and even HPV testing) in predicting cumulative risk of precancer/cancer.   We demonstrated that the AVE algorithm depends on good quality images where quality is a combination of optimal lighting, adequate framing of the cervix, absent any occluding artefacts (e.g., swab, speculum, unrelated anatomy, etc.), and sharp focus. We have developed algorithms that identify landmarks on the cervical images and also determine if an image is a usable cervix image or not. We also showed that the algorithm is generally resilient to geographic variety in mobile phone images, but sensitive to the phone make and model.   Cytology / Pap smear analysis is the non-inferiority test for AVE. We creating a novel deep learning algorithm-based cytology image classifier for whole-slide images. We worked on a small deidentified dataset of liquid pap-smear slides from Beckton-Dickinson that came from a joint study they participated in with NCI. Our deep learning algorithm operated on cytologist marked high-sensitive regions on the whole slide image; i.e. those that contained high likelihood of abnormal cells, to detect and segment nuclei and classify them as one of several abnormal categories. For this we transferred knowledge from another cervical cytology slide dataset which only provided truth as individual segmented cells.   Other cervicographic images, we also continued efforts toward furthering prior work in deep learning-based classification of histopathology images. We continue to develop a novel algorithm that localizes epithelial region of interest on the image to which prior work in image classification can then be applied. In prior efforts, the region of interest was manually marked. We also developed algorithms that generated synthesized images based on images already seen to further train and improve classifier performance. n/a",Advancing artificial intelligence algorithms for cervical cancer diagnostics,10268078,ZIALM010014,"['Abnormal Cell', 'Acetic Acids', 'Algorithms', 'Anatomy', 'Artificial Intelligence', 'Cancer Diagnostics', 'Cancer Etiology', 'Car Phone', 'Categories', 'Cell Nucleus', 'Cells', 'Cellular Phone', 'Cervical', 'Cervix Uteri', 'Classification', 'Cytology', 'Cytology Histology', 'Data Set', 'Epithelial', 'Epithelium', 'Etiology', 'Geography', 'Goals', 'Health', 'Histopathology', 'Human Papilloma Virus Vaccination', 'Human Papillomavirus', 'Image', 'Image Analysis', 'Individual', 'International', 'Joints', 'Knowledge', 'Lesion', 'Lighting', 'Liquid substance', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Methods', 'Modeling', 'Morphologic artifacts', 'Outcome', 'Pap smear', 'Paper', 'Performance', 'Prevention', 'Research', 'Resources', 'Risk', 'Slide', 'Speculums', 'Swab', 'Telephone', 'Testing', 'Tissue imaging', 'Training', 'Visual', 'Work', 'authority', 'automated visual evaluation', 'base', 'cervical biopsy', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'improved', 'intelligent algorithm', 'interest', 'mortality', 'novel', 'premalignant', 'prevent', 'screening', 'screening program', 'whole slide imaging']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2020,862442,0.04512857186084266
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,9867431,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,806128,0.019396985281832074
"Advancing Ulcerative Colitis Monitoring with Deep Learning Models Project Summary/Abstract The number of practicing pathologists around the world is expected to decrease by as much as 30% over the next two decades, with some of the world’s poorest countries having a ratio of only one pathologist to many hundreds of thousands of people. At the same time, the diagnostic caseload that requires their expertise in clinical trials and hospital settings will continue to grow. The digitization of pathology data, coupled with the use of machine learning techniques for analyzing and scoring the data, provides exciting opportunities to make the field of pathology more efficient and scalable, even as the workforce continues to evolve. Deep learning in particular provides the potential to enhance the interpretation of medical images by improving the detection of image-based biomarkers for a broad range of diseases. Image interpretation plays an important role in patient eligibility and endpoint determination during the course of clinical trials. For patients with ulcerative colitis, the development of trained and reliable algorithms that can help pathologists identify disease progression and response to treatment in a timely and effective manner can provide benefit in two important ways. First, it will help to ensure that the most appropriate score for histological disease severity is being assigned to each image using the Robarts Histopathology Index (RHI) or similar grading scale. Second, it will support a triage process by which images known to contain non- healthy tissues can be prioritized for earlier assessment. Through a unique partnership between Azavea, a geospatial technology and machine learning firm, and Robarts, a clinical trials organization, the proposed research will begin to address these needs by developing deep learning algorithms for histopathology digital image analysis, testing them on machine-readable annotations of medical imagery from previous clinical studies, and exposing them through a metadata- searchable interface that will enable the images to be categorized and quickly accessed by pathologists and others to support reader training and increase communication between multiple readers and sites. In so doing, it will not only help streamline the evaluation of new ulcerative colitis treatments that rely heavily on the image interpretation process, but also provide the foundation for the identification of additional components present in other gastrointestinal disease indications in the future. Project Narrative The proposed research will contribute critical new insights on the reliability, sensitivity, and practicality of machine learning to support gastrointestinal disease detection and evaluation in a clinical trials setting. In pathology, where manual interpretation of images using a microscope has remained relatively unchanged for decades, machine learning provides particular potential to improve the speed and accuracy of diagnoses by reducing the subjectivity that is often inherent in the process.",Advancing Ulcerative Colitis Monitoring with Deep Learning Models,10081185,R43EB030441,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Catalogs', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer software', 'Country', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Eligibility Determination', 'Endoscopy', 'Endpoint Determination', 'Ensure', 'Evaluation', 'Foundations', 'Future', 'Gastrointestinal Diseases', 'Histologic', 'Histology', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Learning Skill', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Metadata', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Output', 'Pathologist', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Predictive Value', 'Process', 'Publications', 'Readability', 'Reader', 'Reporting', 'Research', 'Role', 'Series', 'Services', 'Severity of illness', 'Site', 'Software Design', 'Speed', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Triage', 'Ulcerative Colitis', 'Validation', 'base', 'deep learning', 'deep learning algorithm', 'diagnostic accuracy', 'digital imaging', 'gastrointestinal', 'imaging biomarker', 'imaging detection', 'improved', 'indexing', 'insight', 'instrument', 'learning network', 'prototype', 'software development', 'tool', 'treatment response']",NIBIB,"AZAVEA, INC",R43,2020,150000,0.02538112176886293
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,9895214,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2020,235500,-0.012735765766966747
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning.",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,10140491,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis ', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'software infrastructure', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2020,742405,0.021928632926054455
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9997914,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,498014,0.0466276648488818
"TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT This Fast Track SBIR aims to implement comprehensive image anonymization within an enterprise imaging informatics platform built on XNAT.  Our vision is for this platform to provide large healthcare enterprises with tools to generate secure research databases at scale that mirror their clinical image archives.  These databases would then provide local academic and industry collaborators with a rich resource for clinical research and development of AI-powered applications. Thus, our proposed anonymization services are designed to be scalable, risk-based, and verifiable. The platform's AI-powered image anonymization will include automated detection of PHI using a deep learning based natural language processing engine and automated detection of PHI in image content using a convolutational neural network.  The anonymization services will be integrated into Radiologics enterprise and clinical trial XNAT products. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT,10274066,5N91020C00025,"['Clinical Research', 'Clinical Trials', 'Computer software', 'Contracts', 'Data', 'Database Management Systems', 'Databases', 'Detection', 'Healthcare', 'Image', 'Industry Collaboration', 'Intelligence', 'Natural Language Processing', 'Phase', 'Radiology Specialty', 'Research', 'Resources', 'Risk', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Vision', 'base', 'clinical imaging', 'deep learning', 'design', 'image archival system', 'imaging informatics', 'neural network', 'prototype', 'research and development', 'tool']",NCI,"RADIOLOGICS, INC.",N43,2020,399691,0.026199612144735814
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9976466,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'neural network classifier', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,385010,-0.009299165570238523
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,-0.01386160807016534
"Clinical Development and Evaluation of a Deep Learning Approach to Improve Diagnostic Accuracy PROJECT SUMMARY Introduction: PhotoniCare, Inc. is a medical device company developing the TOMi Scope, a handheld, optical imaging device for improved diagnosis of middle ear health. The purpose of this proposal is to establish and evaluate a machine learning approach to facilitate both: (1) ease and reliability of quality data capture in a pediatric population from users with a range of otscopy expertise, and; (2) assist interpretation of the TOMi Scope’s correlated otoscopy and depth-resolved images in order to enable improved diagnostic accuracy and, ultimately, effective management. Significance: Ear infections affect 93% of all children, yet they are one of the most poorly diagnosed (~50% accuracy) and managed diseases in all of medicine, resulting in high antimicrobial over-prescription and resistance development. Correctly identifying the absence or presence/type of middle ear effusion (MEE; fluid) through the non-transparent eardrum is critical to accurate diagnosis, and the limited current diagnostic tools suffer poor diagnostic adoption (7-38% reported use) and accuracy (50-70%) due to inherent subjectivity and dependence on user expertise. Therefore, there is a clear and unmet need for superior, objective screening, starting with a definitive yet easily and reliably usable diagnostic tool for this extremely prevalent yet poorly managed disease. Hypothesis: Applying a machine learning approach to TOMi Scope imaging guidance and diagnostic classification will facilitate both: 1) ease-of-use and reliable quality data collection improvement, and 2) accurate detection of the presence or absence of MEE, as well as classification of the type of infection, regardless of user experience. Specific Aims: (1) Collect labeled TOMi Scope data (otoscopy and depth-scan images) from 268 patients at pediatric offices affiliated with UPMC Children’s Hospital of Pittsburgh, (2) Achieve reliable usability of the TOMi Scope by guiding image capture using TOMi-net, a deep learning model, (3) Develop a multimodal deep learning model to provide diagnostic assistance using TOMi Scope otoscopy and depth-scan data. Commercial Opportunity: The TOMi Scope will provide physicians with a superior user experience and new, objective information, enabling better decision-making for antibiotic prescription and surgical intervention. This has the potential to impact the standard of care for ~1B children worldwide that experience ear infections, representing a multi-billion-dollar commercial opportunity. PROJECT NARRATIVE Ear infections (otitis media) are highly prevalent in the pediatric population and represent a significant clinical challenge due to the limitations of the gold-standard diagnostic tools, resulting in high antimicrobial prescription and consequent resistance development. Accurate detection and classification of effusion (fluid) in the middle ear is a critical element for this diagnosis, and for making informed medical treatment decisions, particularly regarding antibiotic stewardship. The long-term goal of this work is to reduce antibiotic resistance and healthcare costs through improving patient outcomes by addressing the low diagnostic accuracy and user experience issues of current subjective methods, with a novel, non-invasive imaging tool capable of quantitative depth-resolved measurements to not only visualize the underlying infection behind the eardrum, but also, with automated machine learning image analysis algorithms, minimize user experience dependence and variability.",Clinical Development and Evaluation of a Deep Learning Approach to Improve Diagnostic Accuracy,10156035,R44DC017422,"['Acute', 'Address', 'Adoption', 'Affect', 'Algorithmic Analysis', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Appointment', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials Unit', 'Collection', 'Custom', 'Data', 'Data Collection', 'Decision Making', 'Dependence', 'Detection', 'Development', 'Development Plans', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Elements', 'External auditory canal', 'Feedback', 'Focus Groups', 'Goals', 'Gold', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Imaging Device', 'Infection', 'Label', 'Light', 'Liquid substance', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Medical center', 'Medicine', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Otitis Media', 'Otitis Media with Effusion', 'Otoscopy', 'Patient-Focused Outcomes', 'Patients', 'Pediatric Hospitals', 'Pediatrics', 'Phase', 'Physicians', 'Population', 'Prevalence', 'Primary Health Care', 'Recording of previous events', 'Reporting', 'Resistance development', 'Scanning', 'Schedule', 'Surface', 'Surveys', 'Testing', 'Time', 'Training', 'Tympanic membrane', 'Universities', 'Work', 'accurate diagnosis', 'antimicrobial', 'bacterial resistance', 'clinical development', 'clinically relevant', 'convolutional neural network', 'deep learning', 'diagnostic accuracy', 'ear infection', 'effusion', 'electronic data capture system', 'experience', 'hearing impairment', 'image guided', 'improved', 'middle ear', 'middle ear fluid', 'multimodality', 'non-invasive imaging', 'novel', 'optical imaging', 'prevent', 'recruit', 'research clinical testing', 'screening', 'standard of care', 'tool', 'usability']",NIDCD,"PHOTONICARE, INC.",R44,2020,1136886,-0.018240892951271792
"Support for New Bioinformatics Methods Development New bioinformatics method development support includes, image analysis for glyphosate toxicity where deep-learning based image processing tmethods were used to discriminate between normal, stressed and cell-death conditions of HepaRG cells and primary hepatocytes; Evidence tagging protocols were develop for evidence mapping for the OHAT group;  an evaluation of existing tagging methods was performed currently available in the SWIFT-Review program; Machine Learning methods were used for Document tagging activity exploring alternative to the keyword-based tagging strategy currently used in SWIFT-Review. n/a",Support for New Bioinformatics Methods Development,10281443,73201700001C,"['Bioinformatics', 'Cell Death', 'Cells', 'Chemical Exposure', 'Chemicals', 'Contractor', 'DNA Sequence', 'Development', 'Evaluation', 'Genes', 'Hepatocyte', 'Image Analysis', 'Measures', 'Methods', 'Output', 'Program Reviews', 'Programming Languages', 'Protocols documentation', 'Sampling', 'Series', 'Specific qualifier value', 'Stress', 'Toxic effect', 'base', 'bioinformatics tool', 'deep learning', 'differential expression', 'glyphosate', 'image processing', 'machine learning method', 'method development', 'programs', 'transcriptomics']",NIEHS,"SCIOME, LLC",N01,2020,210270,0.01020539494521971
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,9943875,R01EY031331,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,341800,-0.008103745442089461
"Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis,9934128,R00AR070902,"['3-Dimensional', 'Algorithms', 'Atlases', 'Award', 'Big Data', 'Big Data Methods', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Differences', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'Visualization', 'algorithm development', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'deep learning', 'design', 'epidemiology study', 'experience', 'feature extraction', 'heterogenous data', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'multidimensional data', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R00,2020,249000,-0.04463332201629907
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10048436,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Oxygen', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data sharing', 'data warehouse', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'tool']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2020,274883,0.016471980698302916
"Cardiac CT Deblooming PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the most common type of heart disease, killing over 370,000 Americans annu- ally2. Cardiac CT is a safe, accurate, non-invasive method widely employed for diagnosis of CAD and planning therapeutic interventions. With the current CT technology, calcium blooming artifacts severely limit the accuracy of coronary stenosis assessment. Similarly, stent blooming artifacts lead to overestimation of in-stent restenosis. As a result, many coronary CT angiography (CCTA) scans are non-diagnostic and result in patients receiving costly and invasive coronary angiography (ICA) procedures.  Based on extensive feasibility results, the goal of this project is to use deep learning innovations to fundamen- tally eliminate blooming artifacts without costly redesign of the CT hardware. A consortium between GE Re- search, Rensselaer Polytechnic Institute and Weill Cornell Medicine will develop dedicated imaging protocols and machine learning methods to avoid or minimize blooming artifacts and evaluate the clinical impact of the proposed solutions. In Aim 1, the CT scan protocol will be optimized and paired with deep learning reconstruc- tion and post-processing algorithms to generate high-resolution CT images and prevent blooming artifacts. In Aim 2, image-domain and raw-data-domain deep learning processing algorithms will be developed to correct for residual blooming. After successful demonstration of the proposed methods on phantom scans and emulated clinical datasets, in Aim 3 the proposed CT methods will be clinically demonstrated and optimized based on 100 patients with coronary artery disease, using intravascular ultrasound as the ground-truth reference.  At the end of the project, we will have demonstrated and publicly disseminated a systematic methodology to essentially remove blooming artifacts in cardiac CT without a costly hardware upgrade. This will be another suc- cess of deep learning, enabling accurate coronary stenosis assessment and eliminating many unnecessary diag- nostic catheterizations. PROJECT NARRATIVE Blooming artifacts severely limit the accuracy of coronary stenosis assessment with cardiac CT, leading to un- necessary invasive coronary angiography procedures. The goal of this project is to eliminate blooming artifacts without costly redesign of the CT hardware, but based on optimized scan protocols and deep-learning-based image reconstruction and post-processing techniques. The proposed CT methods will be clinically demonstrated and optimized based on CT scans of 100 patients with coronary artery disease and using intravascular ultrasound as the ground-truth reference.",Cardiac CT Deblooming,9943684,R01HL151561,"['Address', 'Algorithms', 'American', 'Angiography', 'Area', 'Attenuated', 'Calcium', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Collaborations', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Data Set', 'Diagnosis', 'Goals', 'Heart', 'Heart Diseases', 'High Resolution Computed Tomography', 'Hospitals', 'Image', 'In Vitro', 'Institutes', 'Lead', 'Measurement', 'Medicine', 'Metals', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'New York', 'Noise', 'Outcome', 'Patients', 'Physics', 'Plant Roots', 'Presbyterian Church', 'Prevention', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Scanning', 'Speed', 'Stenosis', 'Stents', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Training', 'Ultrasonography', 'Validation', 'X-Ray Computed Tomography', 'base', 'calcification', 'cohort', 'cost', 'deep learning', 'deep learning algorithm', 'diagnostic catheterization', 'image reconstruction', 'improved', 'in silico', 'in vivo', 'innovation', 'learning network', 'machine learning method', 'man', 'microCT', 'mortality', 'prevent', 'reconstruction', 'recruit', 'restenosis', 'simulation', 'success', 'temporal measurement', 'virtual', 'virtual reality simulation']",NHLBI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,R01,2020,900092,-0.04225276057790514
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,10193990,R33AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Models', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'automated segmentation', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'feature extraction', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'large datasets', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R33,2020,403748,0.02979488515340594
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9927625,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,458900,0.021797551589761995
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9928429,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'algorithm training', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'segmentation algorithm', 'software infrastructure', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2020,195000,0.022684123783079886
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,9973462,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,342970,0.0018183939285354713
"Gadgetron Global Network and Intelligence Computing: Clinical Imaging Application Development and Software Infrastructure The past FY of 2019-2020 was successful for Gadgetron AI R&D. More AI applications were developed and deployed to clinical practice. Data from 50K patients were collected and stored at NHLBI. Gadgetron AI was on international news and our research in clinical imaging AI was published at top journals. I listed a few after this report.  . Develop AI feedback and patient history interface software, so Gadgetron will be an unique platform to curate imaging data, patient record and clinical feedback. With these three key ingredients, we plan to move into disease diagnosis and automated analysis fields (e.g. to predict cardiac outcome and classify whether a patient should receive intervention procedure).  . Develop complete AI powered CMR analysis solution and deploy them to hospitals for daily usage, including cine, LGE, perfusion, T1/T2/T2* mapping, fat water imaging etc. The motivation here is to extract patient specific imaging information with full automation. These info will be used with patient history and cohort trained disease model.  . Develop precision imaging on MR scanner for major cardiac disease. The target is to develop a patient specific model to predict a) whether a patient should receive intervention surgery or not; b) whether a patient will have cardiac events down the road. The technical route to achieve these are: 1) free-breathing CMR imaging; 2) AI derived imaging information and biomarkers; 3) Patient history and record received in Gadgetron; 4) Make prediction using cohort model with info from step 1-3.   List of selected publications:  Landmark detection in Cardiac Magnetic Resonance Imaging Using A Convolutional Neural Network. Hui Xue, Jessica Artico, Marianna Fontana, James C Moon, Rhodri H Davies, Peter Kellman. arXiv:2008.06142 eess.IV (under review).  Automated Inline Analysis of Myocardial Perfusion MRI with Deep Learning. Hui Xue, Rhodri Davies, Louis AE Brown, Kristopher D Knott, Tushar Kotecha, Marianna Fontana, Sven Plein, James C Moon, Peter Kellman. Radiology: Artificial Intelligence (In Press). arXiv:1911.00625 q-bio.QM.  COVID-19: Myocardial injury in survivors. Daniel S. Knight , Tushar Kotecha , Yousuf Razvi , Liza Chacko , James T. Brown , Paramjit S. Jeetley , James Goldring , Michael Jacobs , Lucy E. Lamb , Rupert Negus , Anthony Wolff , James C. Moon , Hui Xue , Peter Kellman , Niket Patel , and Marianna Fontana. Circulation, https://doi.org/10.1161/CIRCULATIONAHA.120.049252  Automated detection of left ventricle in arterial input function images for inline perfusion mapping using deep learning: A study of 15,000 patients. Hui Xue, Ethan Tseng, Kristopher D Knott, Tushar Kotecha, Louise Brown, Sven Plein, Marianna Fontana, James C Moon, Peter Kellman. Magnetic Resonance in Medicine, Volume84, Issue 5, November 2020, Pages 2788-2800.  The prognostic significance of quantitative myocardial perfusion: an artificial intelligencebased approach using perfusion mapping. Kristopher D Knott, Andreas Seraphim, Joao B Augusto, Hui Xue, Liza Chacko, Nay Aung, Steffen E Petersen, Jackie A Cooper, Charlotte Manisty, Anish N Bhuva, Tushar Kotecha, Christos V Bourantas, Rhodri H Davies, Louise AE Brown, Sven Plein, Marianna Fontana, Peter Kellman, James C Moon. Circulation. 2020;141:12821291.  Media press:  https://www.newscientist.com/article/2224403-an-ai-doctor-is-analysing-heart-scans-in-dozens-of-hospitals/#ixzz6VfVSiMrH  https://www.beckershospitalreview.com/artificial-intelligence/ai-measures-blood-flow-in-real-time-predicting-heart-attack-and-stroke-study-finds.html  https://time.com/5784090/ai-heart-attack-stroke/ n/a",Gadgetron Global Network and Intelligence Computing: Clinical Imaging Application Development and Software Infrastructure,10265879,ZIAHL006214,"['Artificial Intelligence', 'Automation', 'Biological Markers', 'Blood Circulation', 'Blood flow', 'Breathing', 'COVID-19', 'Cardiac', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Computer software', 'Cooperative Research and Development Agreement', 'Data', 'Data Analyses', 'Data Reporting', 'Detection', 'Development', 'Disease model', 'Event', 'Fatty acid glycerol esters', 'Feedback', 'Goals', 'Heart Diseases', 'Hospitals', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging technology', 'Industrialization', 'Intelligence', 'International', 'Intervention', 'Journals', 'Lead', 'Left ventricular structure', 'Life Cycle Stages', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Medicine', 'Modeling', 'Moon', 'Motivation', 'Myocardial Infarction', 'Myocardial perfusion', 'National Heart, Lung, and Blood Institute', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Perfusion', 'Procedures', 'Publications', 'Publishing', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Route', 'Scanning', 'Site', 'Speed', 'Stroke', 'Survivors', 'Time', 'Training', 'Water', 'automated analysis', 'base', 'clinical imaging', 'clinical practice', 'cohort', 'computational platform', 'convolutional neural network', 'data acquisition', 'data curation', 'deep learning', 'disease diagnosis', 'heart imaging', 'image reconstruction', 'imaging modality', 'imaging system', 'improved', 'myocardial injury', 'news', 'open source', 'prognostic significance', 'research and development', 'software infrastructure']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIA,2020,767068,0.013734561075190554
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9973167,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2020,383601,0.009788876519051607
"Biomedical Image Analysis and Informatics The Biomedical Image Analysis and Services Section (BIRSS) is committed to providing computational and engineering expertise to a variety of clinical and biomedical informatics activities at NIH. Specifically, biomedical imaging research in PET, ultrasound, CT, MRI, microscopy, cancer research, and neural dysfunction have been supported extensively. To advance and empower scientific research in the NIH intramural program, CIT has developed and continues to enhance a sophisticated open source, platform-independent, n-dimensional, extensible image processing and visualization application. The MIPAV (Medical Image Processing Analysis and Visualization) (http://mipav.cit.nih.gov/) is an application that enables quantitative analysis and visualization of biomedical imaging modalities (from micro to macro) and is used by researchers at NIH and around the world. At NIH, MIPAV has been used to analyze anatomical structures in CT datasets, analysis of MRI datasets for NIMH, and has been used by NCI for the analysis of 2D and 3D microscopic samples.   In addition, BIRSS leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based system to support the collection and analysis of research studies and clinical trials, using a set of modular components that cover all stages of the research life cycle. And because BRICS is un-branded and not associated with a particular disease or organization, it can be efficiently custom-tailored for many research programs.  MIPAV's integrated set of biomedical imaging algorithms and its extensibility have been used by BIRSS to implement many solutions to imaging problems in the NIH intramural research community.  To create custom workflows and solutions for intramural collaborators, BIRSS team members can build plug-ins that leverage the algorithms and tools in MIPAV to solve complex imaging research questions.  For example, BIRSS continues to develop a novel MIPAV plug-in as part of a collaboration with Dr. Hari Shroffs lab in the National Institute of Biomedical Imaging and Bioengineering (NIBIB) to untwist four-dimensional high-resolution microscopy images of the Caenorhabditis elegans nematode embryo throughout its development.  This plug-in used the image registration and visualization tools already developed by BIRSS for MIPAV, along with novel fiducial annotation and lattice warping tools, to allow the NIBIB researchers to annotate and regularize the C. elegans embryo data through its twitching phase of development, which has not previously been possible algorithmically.  This, in turn, allowed Dr. Shroffs group to investigate neurodevelopmental events in late embryogenesis and apply it to track the 3D positions of seam cell nuclei, neurons, and neurites in multiple elongating embryos. The detailed positional information obtained enabled NIBIB to develop a composite model showing movement of these cells and neurites in an 'average' worm embryo. The untwisting and cell tracking capabilities of this plug-in provides a foundation on which to catalog C. elegans neurodevelopment, allowing interrogation of developmental events in previously inaccessible periods of embryogenesis.  Accurate automatic organ segmentation is an important yet challenging task for medical image analysis.  Anatomical variability in shape and texture feature inhibits traditional segmentation methods from achieving high accuracies.    Machine learning has dominated the medical imaging research field in the past decade.  Initially, pioneer work with decent feature extraction and SVM based image classification achieves better results.  Later, learning based detection algorithm began to dominate the machine learning tools like boosting trees, random forest.   More recently the deep learning based Deep Convolutional Neural Networks (DCNNs) become the mainstream of the medical imaging research field.   Using and enhancing the MIPAV application has allowed us to rapidly build the new machine learning component integral to the MIPAV software and is being used to support automated segmentation of the prostate.  BIRSS also leads the development of the Biomedical Research Informatics Computing System (BRICS) (http://brics.cit.nih.gov/) which is a collaborative and extensible web-based informatics system to support the collection and analysis of research studies and clinical trials. BRICS is un-branded and not associated with a particular disease or organization, therefore, it can be efficiently custom-tailored for many research programs. For example, in collaboration with the National Institute of Neurological Disorders and Stroke (NINDS), BIRSS has developed two informatics systems, using the BRICS system, in support of Traumatic Brain Injury (TBI)(http://fitbir.nih.gov/)research, the Parkinsons Disease Biomarker Program (PDBP) (http://pdbp.ninds.nih.gov/), as well as, collaborated with the National Eye Institute developed an informatics system for rare eye diseases, eyeGENE (https://eyegene.nih.gov/).  The TBI informatics system is called the Federal Interagency TBI Research (FITBIR) database to acknowledge the interagency participation and shared interests. FITBIR serves as a repository for TBI research, is supported by multiple federal agencies, and consolidates high quality, uniformly collected, and contemporary data that can be accessed and analyzed by scientific experts.  Over one million records have been uploaded to FITBIR thus far for 68,00 subjects enrolled in 105 different research studies. Currently there are 145 studies expected to contribute to FITBIR and the number of studies is growing every year. Within FITBIR are clinical outcome data and imaging data of which 100,000+ records are of imaging data (MRI, CT, PET and Diffusion). A summary of the data can be found here: https://fitbir.nih.gov/content/submitted-data.  The goal of the PDBP, a BRICS system, is to support new and existing research and resource development promoting biomarker discovery for Parkinson's disease. Although our understanding of the biology and genetics associated with Parkinson's disease (PD) is advancing rapidly, gaps remain between promising laboratory discoveries and the realization of treatments that will cure or slow progression of PD. To address the needs of the PD community, NINDS has established the PDBP program focused on promoting the discovery of biomarker candidates for early detection and measurement of disease progression.  To date, the PDBP prospective consortium has 100% accrual at nine sites across the US with more than 1,600 enrolled subjects of which biorepository samples have been collected from 1,501 subjects. A summary of the data can be found here: https://pdbp.ninds.nih.gov/Data  The National Eye Institute (NEI) has also adopted the BRICS system to support The National Ophthalmic Disease Genotyping and Phenotyping Network (eyeGENE) (https://eyegene.nih.gov/). The eyeGENE project is a research venture created by NEI in response to promising scientific discoveries in genetics. eyeGENE aims to advance studies of eye diseases and their genetic causes by giving researchers access to DNA samples, clinical information, and patients looking to participate in research studies and clinical trials.  A summary of the data can be found here: https://eyegene.nih.gov/node/35. n/a",Biomedical Image Analysis and Informatics,10250039,ZIACT000272,"['3-Dimensional', 'Address', 'Adopted', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biology', 'Biomedical Research', 'Caenorhabditis elegans', 'Catalogs', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Custom', 'DNA', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Embryo', 'Embryonic Development', 'Engineering', 'Enrollment', 'Event', 'Eye diseases', 'Foundations', 'Four-dimensional', 'Genetic', 'Genotype', 'Goals', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging problem', 'Informatics', 'Infrastructure', 'Intramural Research', 'Intramural Research Program', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Measurement', 'Medical Imaging', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Nematoda', 'Neurites', 'Neuronal Dysfunction', 'Neurons', 'Online Systems', 'Organ', 'Outcome', 'Parkinson Disease', 'Patients', 'Phase', 'Phenotype', 'Plug-in', 'Positioning Attribute', 'Positron-Emission Tomography', 'Prostate', 'Records', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resolution', 'Resource Development', 'Resources', 'Sampling', 'Services', 'Shapes', 'Site', 'Speed', 'System', 'Techniques', 'Texture', 'Traumatic Brain Injury', 'Trees', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'anticancer research', 'automated segmentation', 'base', 'biobank', 'bioimaging', 'biomarker discovery', 'biomedical informatics', 'candidate marker', 'cell motility', 'clinical imaging', 'convolutional neural network', 'deep learning', 'feature extraction', 'high dimensionality', 'image processing', 'image registration', 'image visualization', 'imaging informatics', 'imaging modality', 'informatics infrastructure', 'interest', 'member', 'microscopic imaging', 'n-dimensional', 'neurodevelopment', 'novel', 'open source', 'platform-independent', 'programs', 'prospective', 'random forest', 'repository', 'research and development', 'research study', 'response', 'tool', 'web-based informatics']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2020,1421478,0.023825311918774378
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10040835,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2020,113350,0.03572894837363082
"Society for Magnetic Resonance Angiography (SMRA) 32nd Annual International Conference Project Summary The objective of the 32nd Annual Workshop on Magnetic Resonance Angiography is to provide a forum for basic scientists, clinician scientists, clinical staff, and industry interested in MR angiography techniques to exchange ideas and share the latest research and clinical developments. The Workshop is the annual meeting of the Society for Magnetic Resonance Angiography (SMRA). At this meeting, emerging techniques and exciting new applications to visualize the vascular system, measure and display blood flow and improve patient outcomes will be presented. MR angiography is an important clinical tool that is applied to millions of patients annually and accounts for an estimated 10% of all MR procedures. Recent advances in time-resolved imaging, low-contrast and non-contrast imaging, novel contrast agents, post-processing and display techniques, flow measurements and flow visualization, artificial intelligence, as well other innovations, continue to make MRA a dynamic, cutting-edge area of interest for scientific investigation. A major goal of this SMRA Workshop is to provide scientists, clinicians, and particularly trainees with diverse background with the opportunity to build connections, pool their knowledge, and educate each other in order to accelerate the refinement of MRA technology and critically how to apply it in clinical practice. Topics for the MRA Workshop will include: vascular disease mechanisms, vessel wall and plaque imaging, quantification of blood flow dynamics, applications of artificial intelligence (AI) and deep learning, MRA of the brain, heart, abdomen, and extremities; contrast agents, cardiac MR, assessment of cardiac structure and function, clinical study design, new MRA techniques, MRI of implanted devices, technology assessment, comparing MRI with other imaging modalities, values added by MRA, and critically translating advanced MRA techniques into day-to-day clinical practice. The 3-day workshop will be preceded by an informative one-day educational program that will include both fundamental and advanced lectures from international experts in the field. These topics and educational objectives of the 32nd Annual Workshop on Magnetic Resonance Angiography are directly related to the NHLBI mission to provide global leadership for research, training, and education to promote the prevention and treatment of heart and blood diseases. The scientific presentations will include new discoveries about the causes of disease and as such contribute to the translation of basic discoveries into clinical practice. In addition, the proposed educational activities as well as discussion among participants will foster training and mentoring of emerging scientists and physicians. In this context, the workshop will support a collaborative research infrastructure, including participants from academic institutions and industry. Project Narrative This proposed “32nd Annual Workshop on Magnetic Resonance Angiography” will provide a forum in which researchers and clinicians interested in MRA can build connections, pool their knowledge, and educate students and fellow scientists in order to further develop MRA technology and translate it into clinical practice.",Society for Magnetic Resonance Angiography (SMRA) 32nd Annual International Conference,10071098,R13HL154799,"['Abdomen', 'Angiography', 'Area', 'Artificial Intelligence', 'Award', 'Biology', 'Blood flow', 'Brain', 'Cardiac', 'Catheters', 'Clinical', 'Clinical Research', 'Contrast Media', 'Development', 'Diagnostic Imaging', 'Disease', 'Education', 'Educational Activities', 'Educational workshop', 'Engineering', 'Female', 'Fertilization', 'Fostering', 'Funding', 'Genetics and Medicine', 'Goals', 'Growth', 'Heart', 'Heart Diseases', 'Hematological Disease', 'Image', 'Industry', 'Institution', 'International', 'Investigation', 'Ionizing radiation', 'Knowledge', 'Leadership', 'Limb structure', 'Los Angeles', 'Magnetic Resonance', 'Magnetic Resonance Angiography', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Mentors', 'Mission', 'Modality', 'Morphologic artifacts', 'National Heart, Lung, and Blood Institute', 'Oral', 'Organ', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Physics', 'Postdoctoral Fellow', 'Prevention', 'Procedures', 'Protocols documentation', 'Publications', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Training', 'Rest', 'Safety', 'Scientist', 'Series', 'Societies', 'Standardization', 'Structure', 'Students', 'Techniques', 'Technology', 'Technology Assessment', 'Time', 'Tissue Viability', 'Training', 'Training and Education', 'Translating', 'Translational Research', 'Translations', 'Travel', 'Underrepresented Minority', 'Vascular Diseases', 'Vascular System', 'Venous', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'clinical application', 'clinical development', 'clinical practice', 'computer science', 'cost', 'deep learning', 'imaging modality', 'implantable device', 'improved', 'innovation', 'interest', 'lectures', 'meetings', 'novel', 'posters', 'programs', 'research and development', 'success', 'supportive environment', 'symposium', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R13,2020,20000,0.004649431852391711
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,0.02656844330173737
"Adaptive Optics Retinal Imaging By the time diseases of the retina are detected, serious damage has often already been done. An advanced optical imaging instrument utilizing adaptive optics can be used to directly visualize the cellular structure of the retina in the living human eye. Adaptive optics is a technology for measuring and correcting the optical imperfections in the human eye. When adaptive optics is combined with an imaging platform, highly detailed images of the human retina can be acquired. Our research utilizes this technology to image cells in patients eyes through the Adaptive Optics Clinic within the NIH Clinical Center.  Processing of adaptive optics is highly time-consuming and labor intensive. Currently, there are very few publicly-available tools for handling of adaptive optics data. We have been actively developing novel computational tools incorporating artificial intelligence-based methods such as deep learning for the computer aided analysis of adaptive optics imaging data. This represents an important step towards quantitative assessment of the health and status of cells in the living human eye. We have developed several innovative approaches in the past year, including novel ways to use generative adversarial networks for synthesizing or improving adaptive optics images for efficient and accurate analyses. We continue to make software tools publicly-available through the NEI Commons. Progress towards these projects has been facilitated by ongoing collaborations with NIH, CIT, and NEI IT.  We are actively developing and implementing new technologies for improving our state-of-the-art, custom-built adaptive optics instrument in the NEI eye clinic with the overarching goal of augmenting the translational research capabilities at the NIH Clinical Center. Through collaboration with Drs. Hammer and Liu at the FDA, we have implemented state-of-the-art adaptive optics optical coherence tomography-based approaches for visualizing the 3-D cellular architecture of the human eye, especially of the retinal pigment epithelium. Together with other scanning-based fluorescence and reflectance-based imaging techniques pioneered in recent years, we are actively evaluating the clinical utility of multimodal adaptive optics imaging for the purposes of detecting subclinical cellular changes in the retina to better understand the progression and cellular nature of diseases in the eye.  Through collaboration with Drs. Huryn, Zein, Brooks, Hufnagel, Jeffrey, Magone, Chew, Keenan, Wong, Cukras, and Wiley, we continue to explore how the outer retinal layers are affected by both rare genetic eye diseases as well as other retinal diseases. Translation of our technology and tools from engineering into an active clinic is underway and represents an important step towards more sensitive methods to monitor the status and progression of disease at the cellular level in patients. n/a",Adaptive Optics Retinal Imaging,10253789,ZIAEY000544,"['3-Dimensional', 'Affect', 'Architecture', 'Artificial Intelligence', 'Cells', 'Cellular Structures', 'Clinic', 'Clinical', 'Collaborations', 'Computer Assisted', 'Consumption', 'Custom', 'Data', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Eye', 'Eye diseases', 'Fluorescence', 'Functional disorder', 'Genetic', 'Goals', 'Health Status', 'Human', 'Imaging Device', 'Imaging Techniques', 'Light', 'Measures', 'Methods', 'Microscopic', 'Monitor', 'Nature', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Research', 'Retina', 'Retinal Diseases', 'Role', 'Scanning', 'Software Tools', 'Structure', 'Structure of retinal pigment epithelium', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Zein', 'adaptive optics', 'base', 'cellular imaging', 'clinical center', 'computerized tools', 'deep learning', 'health assessment', 'healthy volunteer', 'human imaging', 'imaging platform', 'improved', 'innovation', 'instrument', 'multimodality', 'new technology', 'novel', 'optical imaging', 'retinal imaging', 'tool']",NEI,NATIONAL EYE INSTITUTE,ZIA,2020,2339906,-0.017987701372051936
"Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking PROJECT SUMMARY  Quantitative magnetic resonance imaging (MRI) measures tissue parameters such as T1, T2, T2*, and diffusion to detect subtle differences in tissue states (such as microstructure, diffuse fibrosis, edema, hemorrhage, and iron content) from neurological, oncological, and cardiovascular diseases. Because each parameter offers complementary tissue information, multiparameter mapping is very promising for risk assessment, early detection, accurate staging, and treatment monitoring of disease. However, quantitative MRI is typically very time consuming and difficult to perform. Each parameter is typically measured from its own series of images, so measuring multiple parameters leads to long, inefficient scanning sessions. Furthermore, cardiac and breathing motion creates misalignment between images, causing additional problems.  The standard approach to motion is to either remove it (e.g., ask the patient to hold their breath) or to synchronize image acquisition with it (e.g., using electrocardiography (ECG) to monitor cardiac motion). This approach makes scan times even longer, limits imaging to patients who can repeatedly perform long breath holds (which is difficult for aging or weak patients) and who have predictable cardiac motion (which is not true of patients with cardiac arrhythmias). Furthermore, these methods are often unreliable and difficult to perform.  This project is to develop and validate a new technology, MR Multitasking, to perform multiple simultaneous measurements in a single, push-button scan that is both comfortable for patients and simple for technologists to perform. MR Multitasking redesigns quantitative MRI around the concept of images as functions of many time dimensions, each corresponding to a different dynamic process (e.g., motion, T1, T2, T2*, and diffusion), and then uses mathematical models called low-rank tensors to perform fast, multidimensional imaging. This allows continuous acquisition of imaging data even while the subject is moving, providing motion-resolved parameter maps without breath holding or motion synchronization. We will scan healthy subjects, liver patients, prostate cancer patients, and cardiovascular patients to develop and validate this technology and use artificial intelligence to quickly reconstruct images from the collected data. The resulting tool will be applicable to any organ system, offering clinicians and investigators a valuable tool to answer a wide range of biomedical questions. PROJECT NARRATIVE  This project is to develop and validate a one-stop, push-button solution for comprehensive, motion- resolved quantitative magnetic resonance imaging (MRI). This will be accomplished by cultivating a new technology, MR Multitasking, which can measure multiple tissue biomarkers in a single scan, even in moving organs. The resulting technology will be applicable to any organ system, offering clinicians and investigators a valuable tool to diagnose, monitor, and study a wide range of diseases.","Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking",9886248,R01EB028146,"['Address', 'Aging', 'Algorithms', 'Arrhythmia', 'Artificial Intelligence', 'Blood flow', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Collection', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diffuse', 'Diffusion', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Electrocardiogram', 'Fibrosis', 'Hemorrhage', 'Image', 'Iron', 'Joints', 'Lead', 'Lipids', 'Liver', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetism', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Nature', 'Neurologic', 'Organ', 'Patients', 'Physiological', 'Positioning Attribute', 'Predisposition', 'Process', 'Property', 'Recovery', 'Reproducibility', 'Research', 'Research Personnel', 'Respiration', 'Risk Assessment', 'Scanning', 'Series', 'Signal Transduction', 'Source', 'Staging', 'System', 'Technology', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Validation', 'body system', 'deep learning', 'heart motion', 'image reconstruction', 'magnetic field', 'magnetohydrodynamic', 'mathematical model', 'multitask', 'new technology', 'prospective', 'quantitative imaging', 'reconstruction', 'respiratory', 'time use', 'tissue biomarkers', 'tool']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R01,2020,628575,-0.010816521038933843
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10018827,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2020,394824,-0.01708535014846615
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9970413,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,497020,0.021097612853143155
"Machine Learning and Deformable Model-based 4D Characterization of Cardiac Dyssynchrony from MRI Summary/Abstract In the presence of diseases such as ischemic heart disease (IHD), cardiac dyssynchrony deteriorates cardiac function and often cannot be treated effectively. However, while imaging methods such as cardiovascular magnetic resonance (CMR) can provide high quality images of the moving heart, conventional clinical quantitative analysis of cardiac function is largely limited to global function analysis of the left ventricle (LV), with only qualitative and subjective characterization of regional function. An obstacle to better quantification of regional function is the complex 3D structure and motion of the heart wall, which has typically necessitated time-consuming user-guided processing of the images to carry out the associated 3D-motion analysis.  Recent advances in machine-learning (ML) approaches for image analysis are promising as new means to speed up the processing of cardiac images, as well as to analyze the underlying regional motion patterns. However, current Deep ML (DML) approaches to image analysis largely function as “black boxes”, without clear indications of which features contribute most to the analysis results, thus limiting their clinical utility. In the initial funded period of this research project, we have been developing integrated approaches to the segmentation, 3D reconstruction, and analysis of CMR data, with application to the evaluation of cardiac dyssynchrony. Today, treatment of dyssynchrony in HF with cardiac resynchronization therapy (CRT) leads to improvement in only ~2/3 patients selected with conventional criteria (usually by electrocardiogram [ECG]). Our initial results show encouraging results of correlation between MRI evaluation of dyssynchrony and cardiac resynchronization therapy (CRT) outcomes. In the new proposed research, we will further develop these methods, with the goal of automating the cardiac analysis methods. This will include the introduction of new ML-based methods, which will incorporate information on the specific cardiac motion factors that lead to classification of different disease states in dyssynchrony. Our Hypothesis is that by using these new ML-based methods for cardiac motion analysis, we will discover and evaluate significant quantitative correlations between different cardiac dyssynchrony motion patterns and CRT outcomes. Also, late-gadolinium enhancement (LGE) provides images for infarction visualization. Incorporation of tissue characterization into the motion-pattern analysis could lead to increased understanding of how infarcted areas affect regional motion in concert with dyssynchrony. The unearthing of these findings will allow us to validate them in future clinical studies. The project will also disseminate our novel, coupled DML and model-based methodology for quantifying and classifying cardiac motion in diseases affecting regional wall motion. Other research groups can then apply our tools to specifically study dyssynchrony, as well as other cardiac diseases affecting LV motion. Project Narrative A significant proportion of patients with heart failure and cardiac dyssynchrony fail to positively respond to cardiac resynchronization therapy (CRT), as the current clinical selection criteria do not take into account regional cardiac function. We will develop improved methods for 4D-analysis and -visualization of both global and regional cardiac function from cardiovascular magnetic resonance (CMR) data, including novel deep learning methods that will provide additional information on the salient features that contribute most to characterization of cardiac dyssynchrony. These new methods will be applied to the analysis of CMR data from both a stratified sample of normal subjects and patients with cardiac dyssynchrony (with and without infarction), with correlation with therapeutic results following CRT, potentially leading to improved clinical guidelines and clinical outcomes, as well as increased understanding of cardiac physiology and pathophysiology.",Machine Learning and Deformable Model-based 4D Characterization of Cardiac Dyssynchrony from MRI,10052934,R01HL127661,"['3-Dimensional', 'Affect', 'Area', 'Attention', 'Automation', 'Cardiac', 'Cardiovascular Physiology', 'Cardiovascular system', 'Classification', 'Clinical', 'Clinical Research', 'Complex', 'Consumption', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'EKG QRS Complex', 'Echocardiography', 'Electrocardiogram', 'Evaluation', 'Functional disorder', 'Funding', 'Future', 'Gadolinium', 'Goals', 'Guidelines', 'Heart', 'Heart Diseases', 'Heart failure', 'Image', 'Image Analysis', 'Image Enhancement', 'Infarction', 'Ischemia', 'Lead', 'Left ventricular structure', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial Ischemia', 'Outcome', 'Output', 'Patient Selection', 'Patients', 'Pattern', 'Performance', 'Physiology', 'Prospective Studies', 'Pump', 'Research', 'Research Project Grants', 'Resolution', 'Sampling', 'Schedule', 'Selection Criteria', 'Speed', 'Sweden', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Treatment outcome', 'Universities', 'Visualization', 'Width', 'base', 'cardiac resynchronization therapy', 'deep learning', 'effective therapy', 'heart function', 'heart imaging', 'heart motion', 'image processing', 'imaging approach', 'imaging modality', 'improved', 'improved outcome', 'learning strategy', 'machine learning method', 'novel', 'patient subsets', 'reconstruction', 'response', 'spatiotemporal', 'success', 'therapy outcome', 'three dimensional structure', 'tool']",NHLBI,"RUTGERS, THE STATE UNIV OF N.J.",R01,2020,763531,0.01978402008574841
"International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020 Project summary  The Medical Image Computing and Computer Assisted Interventions (MICCAI) society is dedicated to the promotion, preservation and facilitation of research and education in the fields of medical image computing and computer assisted interventions, including biomedical imaging and robotics. This aim is achieved through the organization and operation of regular international conferences of the highest quality, and publications that promote and foster the exchange and dissemination of advanced knowledge, expertise and experience by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their origin in three separate but related conferences beginning in early 1990s--Visualization in Biomedical Computing, Computer Vision and Virtual Reality in Robotics and Medicine, and Medical Robotics and Computer Assisted Surgery--, which merged into a single annual conference in 1998. MICCAI Conferences have defined new scientific disciplines over the years and have become the premier meeting in the field. The conference proceedings have an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & medical image processing, computer-aided diagnosis, interventions & surgery, machine learning in medical imaging, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry.  The MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance). Selected presented papers became landmark publications over the years with up to 2,000 citations. The conference series includes satellite events like community-driven software challenges, workshops and tutorials just before and/or after the main conference. These events focus on the current status and advances in topics relevant to MICCAI and are very well attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendees are typically from over 45 countries, with strong student representation (>40%). The MICCAI 2020 Conference will be held in Lima, Peru in October 4th-8th, 2020. Since 2018, a Mentorship Program to connect students and young investigators with established mentors from academia and industry is also part of the conference. Along with the Mentorship Program and mission of the “Women in MICCAI” Committee, this proposal requests funds to support student and early investigator travel awards to enhance diversity in conference attendance (including women, underrepresented minorities, students with disabilities, and people from disadvantaged backgrounds) and provide minority groups with a unique opportunity to reach an international audience for career development and collaborations. Project narrative The Medical Image Computing and Computer Assisted Intervention (MICCAI) 2020 Conference will be held in Lima, Peru, October 4th-8th, 2020. MICCAI is the premier meeting in the medical image computing and computer assisted intervention communities, having introduced landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students and early investigators to present their work at MICCAI 2020--with focus on minority groups and underrepresented populations--providing them with an opportunity to attend the meeting, foster professional development and identify collaborations in an established international community.",International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020,10070479,R13EB030422,"['Academia', 'Academy', 'American', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Costs and Benefits', 'Country', 'Development', 'Disabled Persons', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority Groups', 'Mission', 'Oncology', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Peru', 'Physicians', 'Physiology', 'Policies', 'Postdoctoral Fellow', 'Psychiatry', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Robotics', 'Role', 'Scientist', 'Series', 'Societies', 'Students', 'Training', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Populations', 'United States National Institutes of Health', 'Visualization', 'Woman', 'Women&apos', 's Group', 'Work', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'community organizations', 'cost', 'disabled students', 'early-career faculty', 'experience', 'graduate student', 'image guided', 'image processing', 'imaging system', 'innovation', 'interest', 'meetings', 'operation', 'posters', 'preservation', 'programs', 'racial and ethnic', 'robotic system', 'social', 'student participation', 'success', 'supportive environment', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NIBIB,CHILDREN'S RESEARCH INSTITUTE,R13,2020,9850,-0.007864831219229748
"Data-driven Head Motion Correction in PET Imaging Using Deep Learning Project Summary Positron-emission tomography (PET) is an imaging modality that allows clinicians and researchers to study the physiological or pathological processes of the human body, and in particular the brain via the use of specific tracers. For brain PET imaging, patient head movement during scanning presents a challenge for accurate PET image reconstruction and subsequent quantitative analysis. Problems due to head motion are exacerbated by the long duration of the scans, with scan times commonly over one hour. Furthermore, some PET studies specifically involve subjects that either have trouble staying still due to psychological variations, e.g. patients with neurodegenerative disorders such as Alzheimer's disease and Parkinson's disease, or psychological variations, e.g. subjects with anxiety disorders, or are required to participate in tasks that involve movement, e.g. smoking cigarettes while scanning. In brain scans, the average head motion can vary from 7 mm in clinical scans to triple this amount for longer research scans. Quantitatively, a 5 mm head motion can produce biases of up to ~35% in regional intensities and ∼15% in volume of distribution estimates, which could much larger than the difference observed in regional intensities or binding potential that distinguish different demographic groups being studied. The ability to track and correct head motion, therefore, would be of high utility in both clinical and research PET studies. In the past, many motion correction methods have been proposed. However, except for hardware-based approaches, there has been no method that can track frequent head motion on-the-fly during the PET acquisition. Hardware-based approaches are not readily available for clinical translation or used by other research facilities due to highly-customized software/hardware setup. To address this challenge, we propose to develop a data-driven methodology using deep learning to track and estimate rigid head motion using PET raw data, and incorporate both tracer type and time as conditional variables into this deep neural network design in order to handle diverse PET tracer types and their dynamic behavior. Overall, these solutions will provide for a data-driven motion estimation methodology to improve the quality of PET imaging. Specifically, we will start with the development and testing of our methodology for rigid head motion estimation using single-tracer PET raw data. Then we will perform evaluation of our multi-tracer motion estimation methodology applied to real PET data with a diverse range of tracers. Finally, in the exploratory phase, we will integrate time-of-flight information into deep learning-based motion prediction. The significance of this proposal is that it will allow for improved quality of PET imaging in real time and potentially allow for its use in clinical PET systems that do not have special motion tracking hardware. This work will serve as a first step towards developing data-driven motion estimation algorithms for full body PET imaging. The innovation lies in the development of what is a data-driven solution to the problem of real time motion estimation. Project Narrative Positron-emission tomography (PET) imaging of the brain is a highly useful tool for biomedical research and clinical practice. Head motion during scanning degrades PET image quality and introduces image artifacts. We propose to develop new data-driven methods, based on PET raw data, to estimate head motion using deep learning, which can be used for real time motion estimation in PET imaging.",Data-driven Head Motion Correction in PET Imaging Using Deep Learning,9877261,R21EB028954,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anxiety Disorders', 'Behavior', 'Binding', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain scan', 'Cigarette', 'Clinical', 'Clinical Research', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Development', 'Devices', 'Effect Modifiers (Epidemiology)', 'Evaluation', 'Event', 'Funding', 'Gold', 'Head', 'Head Movements', 'Hour', 'Human', 'Human body', 'Image', 'Individual', 'Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Movement', 'Neurodegenerative Disorders', 'Parkinson Disease', 'Pathologic Processes', 'Patients', 'Performance', 'Phase', 'Physiological Processes', 'Positron-Emission Tomography', 'Research', 'Research Personnel', 'Scanning', 'Smoking', 'Synapses', 'System', 'Testing', 'Time', 'Tracer', 'Training', 'Variant', 'Work', 'base', 'clinical practice', 'clinical translation', 'deep learning', 'deep neural network', 'density', 'design', 'effectiveness evaluation', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'interest', 'neural network', 'novel', 'psychologic', 'reconstruction', 'research facility', 'simulation', 'statistics', 'tool']",NIBIB,YALE UNIVERSITY,R21,2020,243150,0.02528158117912105
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,9972122,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,193784,0.027960340039870187
"Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT PROJECT SUMMARY Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before heart attacks occur and is currently used to predict risk in millions of patients annually. Under the current grant, we have established a unique collaborative multicenter registry including over 23,000 imaging datasets (REFINE SPECT) with both prognostic (major adverse cardiovascular events) and diagnostic (invasive catheterization) outcomes. Using this registry, we have demonstrated that a combination of MPS image analysis and artificial intelligence (AI) tools achieved superior predictive performance compared to visual assessment by experienced readers or current state-of-the-art quantitative techniques. In the renewal, we plan to expand REFINE SPECT with now-available enhanced datasets (adding CT and myocardial blood flow information) and leverage latest AI advances to provide a personalized decision support tool for patient-specific cardiovascular risk assessment and estimation of benefit from revascularization following MPS. The overall aim is to optimize the clinical capabilities of MPS in risk prediction and treatment guidance by integrating all available imaging and clinical data with state-of-the-art AI methods. For this work, we propose the following 3 specific aims: (1) To expand and enhance our REFINE SPECT registry including CT and MPS flow data, (2) To develop fully automated techniques for all MPS and CT image analysis, (3) To apply explainable deep learning time-to-event AI models for optimal prediction of MACE and benefit from revascularization from all image and clinical data. This work will result in an immediately deployable clinical tool, which will optimally predict risk of adverse events and establish the relative benefits from specific therapies, beyond what is possible by subjective visual analysis and mental integration of all imaging (MPS, CT, flow), and clinical data by physicians. Such quantitative integrative methods are not yet available, leaving the current practice for assessing risk and recommending therapy highly subjective. The precise quantitative results will be presented to clinicians in easy to understand terms (e.g., % risk per year, or relative risk of one therapy vs. the alternative) for a specific patient. Additionally, our methods to make AI conclusions more tangible will improve adoption of this technology. All results will be derived fully automatically thus eliminating any variability. Our approach will fit into current MPS practice and will be immediately translatable to clinics worldwide. Most importantly, this research will allow patients to benefit from increased precision and accuracy in risk assessment, thereby optimizing the use of imaging in guiding patient management decisions and ultimately improving outcomes. PROJECT NARRATIVE Myocardial perfusion imaging with SPECT is often used to predict who is at risk of heart attack and should undergo treatment such as coronary bypass or stenting; however, physicians read images visually and report results with wide variability. With the latest artificial intelligence tools and new types of imaging (including CT and fast SPECT scans), the investigators propose to develop and validate an automated clinical tool to optimize risk prediction and objectively establish the relative benefit of a specific therapy. This new tool will consider all available patient images and other relevant information to provide a personalized explanation and precise calculation of risk and potential benefits from therapy for each patient.",Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT,9888240,R01HL089765,"['Adoption', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blood', 'Blood flow', 'Calcium', 'Cardiovascular system', 'Catheterization', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'Country', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Event', 'Grant', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Injections', 'International', 'Joints', 'Maps', 'Measures', 'Methods', 'Modeling', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Outcome', 'Patient imaging', 'Patients', 'Perception', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Positron-Emission Tomography', 'Psyche structure', 'Public Health', 'Reader', 'Recommendation', 'Registries', 'Relative Risks', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scanning', 'Site', 'Statistical Models', 'Stents', 'Stress', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Visual', 'Work', 'X-Ray Computed Tomography', 'adverse event risk', 'attenuation', 'cardiovascular risk factor', 'clinically relevant', 'deep learning', 'experience', 'improved', 'improved outcome', 'multidisciplinary', 'next generation', 'non-invasive imaging', 'novel', 'perfusion imaging', 'personalized decision', 'prognostic', 'radiotracer', 'relating to nervous system', 'single photon emission computed tomography', 'support tools', 'time use', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2020,808131,0.015037172488313464
"Machine learning for fast motion compensated quantitative abdominal DCE-MRI Project Summary: Functional imaging with dynamic contrast-enhanced MRI (DCE-MRI) provides important physiological markers of permeability, perfusion and glomerular filtration rate (GFR), a measure of kidney function, without exposing patients to ionizing radiation. DCE-MR images are at the same time used for evaluation of anatomy. Functional markers from DCE-MRI, if computed accurately, would play a critical role in diagnosing and assessing the progression of a number of pediatric diseases including those compromising kidney function, liver diseases, tumors, and Crohn's disease. One of the most important applications of DCE-MRI is assessing kidney function (GFR) in hydronephrosis patients with obstruction. In the absence of GFR information, children who stand to benefit from immediate surgical reconstruction might be overlooked or delayed in receiving treatment, and those who might benefit from a more conservative approach (i.e., “watchful waiting”) might receive an unnecessary surgical intervention. While the current reference standard, nuclear renography (MAG3), yields some useful diagnostic information, it is slow, provides low resolution, does not offer anatomic detail, and delivers potentially harmful ionizing radiation. There is a clinical need for accurate computation of quantitative functional markers. Unfortunately, current methods of DCE-MRI in neonates and children are less than optimal, and therefore, DCE-MRI is underutilized in clinical practice. The technical challenges include insufficient temporal resolution to capture fast arterial input function (AIF) dynamics (which are required for accurate computation of quantitative markers), unavoidable respiratory motion and bulk motion (which reduce image quality and significantly lower the accuracy of parameter estimates), and a lack of robust, fast, automated post processing techniques for accurate computation of markers. Thus, there is an urgent, unmet need to develop a motion-compensated, high spatiotemporal resolution DCE-MRI method addressing these challenges. The primary objective of this exploratory, three-year study, is three-fold: first, to develop and evaluate a new bulk and respiratory motion-compensated, high spatiotemporal resolution DCE-MRI technique for accurate estimation of functional markers; second, to further improve the robustness and speed of DCE-MRI using a fast, deep learning (DL) technique with integrated temporal prior for the reconstruction of motion-compensated, higher quality, high temporal resolution images; and third, to develop an automatic quantitative analysis pipeline including segmentation and tracer kinetic model-fitting using DL techniques for fast, robust and accurate quantification of functional markers. The successful completion of these aims will provide new, clinically important abdominal imaging capabilities, with real-time, motion-compensated image reconstruction and reliable real-time parameter estimation from high temporal and spatial resolution DCE-MRI. This work will extend the usefulness of DCE-MRI to pediatric patients who are unable to remain still in the scanner, and eliminate the need for repeated scans and sedation in infants. ! ! Project Narrative: This project addresses the need to develop advanced methods of magnetic resonance imaging (MRI) to provide new, clinically important abdominal imaging capabilities, with real-time, motion-compensated image reconstruction and reliable real-time estimation of clinically important quantitative imaging markers from high temporal and spatial resolution DCE-MRI. These markers will be used to evaluate the extent of several disorders and would play a critical role in diagnosing and assessing the progression of a number of pediatric diseases including those compromising kidney function, liver diseases, tumors, and Crohn's disease. This work will extend the usefulness of DCE-MRI to pediatric patients who are unable to remain still in the scanner, and eliminate the need of repeated scans, sedation and anesthesia when imaging newborns with congenital abnormalities such as congenital hydronephrosis, which if left untreated, can result in permanent damage to the child's kidneys.",Machine learning for fast motion compensated quantitative abdominal DCE-MRI,9957672,R21EB029627,"['Abdomen', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Anesthesia procedures', 'Breathing', 'Child', 'Childhood', 'Clinical', 'Congenital Abnormality', 'Crohn&apos', 's disease', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Financial compensation', 'Functional Imaging', 'Glomerular Filtration Rate', 'Hydronephrosis', 'Image', 'Imaging Techniques', 'Infant', 'Ionizing radiation', 'Kidney', 'Lead', 'Left', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Newborn Infant', 'Nuclear', 'Obstruction', 'Operative Surgical Procedures', 'Organ', 'Patient observation', 'Patients', 'Performance', 'Perfusion', 'Permeability', 'Physiological', 'Play', 'Reference Standards', 'Renal function', 'Resolution', 'Role', 'Scanning', 'Sedation procedure', 'Series', 'Signal Transduction', 'Speed', 'Techniques', 'Time', 'Tracer', 'Ureteropelvic junction obstruction', 'Work', 'analysis pipeline', 'anxious', 'base', 'bulk motion', 'clinical decision-making', 'clinical practice', 'contrast enhanced', 'deep learning', 'image reconstruction', 'imaging biomarker', 'imaging capabilities', 'imaging modality', 'improved', 'kinetic model', 'neonate', 'neural network architecture', 'pediatric patients', 'quantitative imaging', 'radiologist', 'real-time images', 'reconstruction', 'recursive neural network', 'respiratory', 'spatiotemporal', 'temporal measurement', 'time use', 'tumor']",NIBIB,BOSTON CHILDREN'S HOSPITAL,R21,2020,708000,0.005505710974944081
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9929633,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2020,1011405,-0.0010840053068292325
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10027477,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2020,360287,-0.023952897615806188
"Development of a prototype software for automated PET/CT interpretation and reporting in thoracic cancer Abstract. In cancer, body-wide FDG-PET/CT is a prime modality for diagnosis, staging, and treatment assessment. Despite its paramount importance to enable precision medicine in cancer, no method is currently available for automated disease burden estimation and standardized reporting on PET/CT images regionally and globally in anatomic organs and lymph node zones within a body region or body-wide. Automated production- mode body-wide/ body-region-wide disease measurement with standardized reporting will foster cancer research discovery and will be of great interest to oncologists, radiologists/ nuclear medicine physicians, Medicare and private health insurers, and pharmaceutical companies that conduct clinical trials of new cancer therapeutics and currently rely on manual methods of response assessment. The overarching goal of this Phase I project is, therefore, to develop, validate, and demonstrate a prototype software for disease measurement and reporting via FDG-PET/CT in the above manner in one body region, namely thorax, based on innovative algorithms that are generalizable body-wide. The project has two aims: Aim 1: Develop, implement, and validate algorithms for disease burden estimation in thoracic cancer via FDG-PET/CT. Aim 2: Develop and demonstrate a prototype software implementing the above algorithms for disease measurement and reporting. Aim 1 will be accomplished in 3 stages: Tasks 1, 2: PET/CT image data sets which are radiologically near normal for the thoracic body region will be gathered from existing whole-body scans of 100 patients. In these data sets, 7 key anatomic organs and 5 key lymph node zones in the thorax will be delineated under expert guidance. These data will be used to build population fuzzy anatomy models following our established Automatic Anatomy Recognition (AAR) methodology. An additional 100 whole-body PET/CT scans of patients with different types of cancer will be gathered to test our methods. Using available commercial clinical software, the PET uptake properties of lesions in organs and diseased lymph nodes in lymph node zones will be measured manually and used as reference ground truth of disease burden. Task 3: Deep learning (DL) algorithms anatomically guided by AAR will be developed to very accurately localize (but not delineate) organs and lymph node zones in PET/CT images using the models. Task 4: Novel methods based on fuzzy principles will be developed to automatically tag and quantify pathological regions (without explicitly delineating them) within located organs and nodal zones, and the accuracy of disease measurement will be evaluated (Task 5). Aim 2 will be accomplished by incorporating the disease measurement methodology into a prototype software named AAR-DQ (Tasks 6, 7) based on our earlier software platform CAVASS. AAR-DQ will report disease burden in a hierarchical manner – (i) at the body-region level; (ii) at each organ/ lymph node zone level; (ii) at each lesion/ lymph node level. Expected milestones. Aim 1: AAR-DQ disease measurement not to deviate more than 10% from clinical ground truth measurement. Aim 2: Disease measurement/ reporting in under 5 minutes per patient PET/CT study. Automated production-mode body-wide/ body-region-wide disease measurement has numerous potential applications in cancer and other diseases and has considerable commercial potential. The overarching goal of this Phase I STTR project is to develop, validate, and demonstrate a prototype software for disease measurement and reporting via FDG-PET/CT in the above manner in one body region, namely thorax, based on innovative algorithms that are generalizable body-wide.",Development of a prototype software for automated PET/CT interpretation and reporting in thoracic cancer,10076938,R41CA236492,"['Abbreviations', 'Abdomen', 'Algorithms', 'Anatomy', 'Artificial Intelligence', 'Body Burden', 'Body Regions', 'Cancer Patient', 'Chest', 'Clinical', 'Communication', 'Computer software', 'Conduct Clinical Trials', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discipline of Nuclear Medicine', 'Disease', 'Distant', 'Fostering', 'Geography', 'Glycolysis', 'Goals', 'Head and neck structure', 'Health', 'Image', 'Image Analysis', 'Insurance Carriers', 'Knowledge', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Medicare', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Monitor', 'Names', 'Nodal', 'Normalcy', 'Oncologist', 'Organ', 'PET/CT scan', 'Pathologic', 'Patient-Focused Outcomes', 'Patients', 'Pelvis', 'Pharmacologic Substance', 'Phase', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Privatization', 'Production', 'Property', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research Personnel', 'Sampling Biases', 'Scanning', 'Small Business Technology Transfer Research', 'Staging', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Training', 'X-Ray Computed Tomography', 'algorithm training', 'anticancer research', 'base', 'burden of illness', 'cancer diagnosis', 'cancer type', 'deep learning', 'deep learning algorithm', 'evidence based guidelines', 'fluorodeoxyglucose positron emission tomography', 'imaging modality', 'improved', 'innovation', 'interest', 'learning strategy', 'lymph nodes', 'lymphoid organ', 'model building', 'novel', 'object recognition', 'outcome forecast', 'payment', 'precision medicine', 'prototype', 'radiologist', 'response', 'software development', 'treatment response', 'uptake', 'whole body imaging']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R41,2020,252131,-0.021973942837242102
"Leveraging Neural Imaging for Automated Neonatal Infection Diagnosis PROJECT SUMMARY/ABSTRACT Post-infectious hydrocephalus (PIH) is a leading cause of neonate mortality in the developing world, but there are limited resources in place for appropriately diagnosing and monitoring the infections that lead to hydrocephalus. There is often a lack of personnel and laboratory resources available for the gathering and processing of lumbar puncture and blood cultures, which are the gold-standard for diagnosing the infectious agents at play in sepsis and PIH. In order to overcome this obstacle, CSF and blood samples were taken from a cohort of septic neonates in Mbale, Uganda, as well as a cohort of neonates and infants who had already progressed to PIH. Cranial ultrasounds (CrUS) were taken from the cohort of septic neonates, and head CT scans were gathered from the PIH cohort. This proposal hypothesizes that the pathogens determined from RNA and DNA sequencing of the blood and CSF samples can be used to train supervised machine learning algorithms to recognize imaging phenotypes characteristic of the underlying pathogen. Therefore, PIH can be prevented by providing pathogen-specific diagnosis and targeted treatment recommendations at the bedside for septic neonates using CrUS. Furthermore, surgical treatment success for PIH can be optimized using CT for the purpose of identifying the underlying pathogen and providing management plan recommendations. This project provides an ideal training environment for a fellow interested in pediatric neurosurgery with a research emphasis on engineering and machine learning applied to image analysis. The interdisciplinary and global nature of the project encourages development of a collaborative and innovative research approach. The home institution of Penn State provides multiple clinical opportunities for growth in pediatric neurosurgery, the MD/PhD program is supportive of truly translational research efforts, and the sponsor and co-sponsor are more than adequately prepared to provide all aspects of training mentorship necessary to accomplish the aims of this project and develop a well-rounded physician-scientist. PROJECT NARRATIVE Post-infectious hydrocephalus is a devastating condition with a global impact, but diagnostic options and available treatment plans are limited in the developing world in particular. This project aims to design machine learning algorithms that leverage cranial ultrasound and head CT for the diagnosis of pathogen-specific sepsis and hydrocephalus in neonates, and propose treatment paradigms based on the diagnostic output.",Leveraging Neural Imaging for Automated Neonatal Infection Diagnosis,10066656,F30HD102120,"['Africa', 'Africa South of the Sahara', 'Anti-Bacterial Agents', 'Antiviral Agents', 'Artificial Intelligence', 'Blood', 'Blood specimen', 'Brain', 'Caregivers', 'Cauterize', 'Central Nervous System Infections', 'Cephalic', 'Cerebrospinal Fluid', 'Cessation of life', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Cognitive', 'Communicable Diseases', 'Coupled', 'DNA sequencing', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Management', 'Doctor of Philosophy', 'Endocrine', 'Engineering', 'Environment', 'Evaluation', 'Failure', 'Functional disorder', 'Goals', 'Gold', 'Growth', 'Head', 'Healthcare Systems', 'Home environment', 'Human Resources', 'Hydrocephalus', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Infant', 'Infection', 'Infectious Agent', 'Institution', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Mentorship', 'Microbiology', 'Monitor', 'Nature', 'Neonatal', 'Nervous system structure', 'Neuraxis', 'Operative Surgical Procedures', 'Output', 'Pathogenicity', 'Pathologic', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Play', 'Prevention', 'Procedures', 'Protocols documentation', 'Recommendation', 'Research', 'Resources', 'Sampling', 'Scientist', 'Secondary to', 'Sepsis', 'Shunt Device', 'Spinal Puncture', 'Structure of choroid plexus', 'Survivors', 'Technology', 'Time', 'Training', 'Translational Research', 'Uganda', 'Ultrasonography', 'Ventriculostomy', 'Work', 'X-Ray Computed Tomography', 'base', 'cerebrospinal fluid flow', 'cohesion', 'cohort', 'design', 'diagnosis standard', 'disease classification', 'genome sequencing', 'hands-on learning', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'machine learning algorithm', 'mortality', 'neonatal infection', 'neonatal sepsis', 'neonate', 'neurosurgery', 'non-invasive imaging', 'optimal treatments', 'pathogen', 'prevent', 'programs', 'relating to nervous system', 'septic', 'success', 'supervised learning', 'targeted treatment', 'transcriptome sequencing', 'treatment planning', 'treatment strategy']",NICHD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,F30,2020,32183,-0.07726711494885158
"AI platform for microscopy image restoration and virtual staining AI Platform for Microscopy Image Restoration and Virtual Staining Project Summary:  Fluorescence microscopy has enabled many major discoveries in biomedical sciences. Despite the rapid advancements in optics, lasers, probes, cameras and novel techniques, major factors such as spatial and temporal resolution, light exposure, signal-to-noise, depth of penetration and probe spectra continue to limit the types of experiments that are possible. Deep learning (DL) algorithms are well suited for image-based problems like SNR/super-resolution restoration and virtual staining, which have great enabling potentials for microscopy experiments. Previously impossible experiments could be realized such as achieving high signal-to-noise and/or spatial-temporal resolution without photobleaching/phototoxicity; simultaneously observing many image channels without interfering with native processes, etc. This could pave the way for a quantum leap forward in microscopy-based discoveries that elucidate biological functions and the mechanisms of disorders, and enable new diagnostics and therapies for human diseases.  However, these new methods have not been widely translated to new microscopy experiments. The delay is due to several practical hurdles and challenges such as required expertise, computing and trust. In order to accelerate the adoption of DL in microscopy, novel AI platform tailored for biologists are needed for training, applying and validating DL models and outputs.  The present project aims to develop an AI platform for microscopy image restoration and virtual staining called AI for Restoring and Staining (AIRS) platform. With our collaborator, Dr. Hari Shroff (National Institute of Biomedical Imaging and Bioengineering) we have successfully created DL models for SNR restoration, super-resolution restoration and virtual staining for a variety of imaging conditions and organelles in our preliminary studies. The AIRS platform intends to (1)provide a comprehensive suite of validated DL models for microscopy restoration and virtual staining applications including SNR restoration, super-resolution restoration, spatial deconvolution, spectral unmixing, prediction of 3d from 2d images, organelle virtual staining and analysis; (2)provide plug and play for common microscopy experiments; (3)provide semi-automatic update training to tailor DL models to match advanced microscopy experiments; (4)provide user friendly support for new DL model training for pioneering microscopy experiments; (5)provide confidence scores to assess the output results by a DL model, (6) provide DL models that avoid image artifact (hallucination) and allow continuous learning and evolution; (7) and be able to access the required computing infrastructure and database connection. Project Narrative Deep learning (DL) algorithms have great enabling potentials for microscopy experiments. Previously impossible experiments could now be realized. This could pave the way for a quantum leap forward in microscopy-based discoveries.  Powered by deep learning and DRVision innovations and collaborating with Dr. Hari Shroff and 7 additional labs, this project aims to create an AI platform for microscopy image restorations and virtual staining called AI for restoring and staining (AIRS). The tool will be integrated with DRVision’s flagship product Aivia for commercialization to accelerate the adoption of DL in microscopy.",AI platform for microscopy image restoration and virtual staining,9909318,U44GM136091,"['3-Dimensional', 'Active Learning', 'Adoption', 'Artificial Intelligence', 'Biological Process', 'Data', 'Databases', 'Disease', 'Evaluation', 'Evolution', 'Feedback', 'Fluorescence Microscopy', 'Government', 'Hallucinations', 'Image', 'Infrastructure', 'Lasers', 'Libraries', 'Light', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'National Institute of Biomedical Imaging and Bioengineering', 'Noise', 'Optics', 'Organelles', 'Output', 'Penetration', 'Performance', 'Persons', 'Phase', 'Photobleaching', 'Phototoxicity', 'Play', 'Process', 'Resolution', 'Science', 'Signal Transduction', 'Stains', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Translating', 'Trust', 'Update', 'Validation', 'base', 'commercialization', 'deep learning', 'deep learning algorithm', 'experience', 'experimental study', 'human disease', 'improved', 'innovation', 'learning progression', 'microscopic imaging', 'novel', 'novel diagnostics', 'novel therapeutics', 'prototype', 'quantum', 'restoration', 'temporal measurement', 'tool', 'usability', 'user-friendly', 'virtual']",NIGMS,"DRVISION TECHNOLOGIES, LLC",U44,2020,172359,0.0085034185059523
"Integrating image and text information for biomedical information retrieval The search for relevant and actionable information is key to achieving clinical and research goals in biomedicine. Biomedical information exists in different forms: as text and illustrations in journal articles and other documents, in images stored in databases, and as patients cases in electronic health records. In the context of this work, image refers not only to biomedical images, but also to illustrations, charts, graphs, and other visual material appearing in biomedical journals, electronic health records, and other relevant databases. We are developing better approaches to retrieve information from these entities, by moving beyond conventional text-based searching to combining both text and visual features in search queries. To meet these objectives, we use a combination of techniques and tools from the fields of Information Retrieval (IR), Content-Based Image Retrieval (CBIR), and Natural Language Processing (NLP).   The first objective is to improve the retrieval of biomedical literature by targeting the visual content in articles, a rich source of information not typically exploited by conventional bibliographic or full-text databases. We index these figures (including illustrations and images) using (i) text in captions and where they are mentioned in the body of the article (mentions). In FY2020, we established that recently available deep learning features help finding relevant images better than the traditional image features, such as color and texture. We have accordingly updated these features for image searches.   A second objective is to find semantically similar images in image databases, an important step in differential diagnosis. We explore approaches that automatically combine image and text features in contrast to visual decision support systems that use only text driven menus. To support this research, we maintain the MedPix database (https://medpix.nlm.nih.gov/home) that contains and continues accepting medical cases submitted by radiologists through the case upload server (https://cup.nlm.nih.gov/login).   Our methods use text and image features extracted from relevant components in a document, database, or case description to achieve our objectives. For the document retrieval task, we rely on the U.S. National Library of Medicine (NLM) developed search engine. This is a phrase-based search engine with NLMs Unified Medical Language System (UMLS) based term and concept query expansion and probabilistic relevancy ranking that exploits document structure. Optimizing these features, we create structured representations of every full-text document and all its figures. These structured documents presented to the user as search results include typical fields found in MEDLINE citations (e.g., titles, abstracts and MeSH terms), the figures in the original documents, and image-specific fields extracted from the original documents (such as captions segmented into parts pertaining to each pane in a multi-panel image, ROI described in each caption, and the modality of the image). In addition, patient-oriented outcomes extracted from the abstracts are provided to the user.   To evaluate and demonstrate our techniques, we have developed Open-i (pronounced open eye, available at http://openi.nlm.nih.gov), a hybrid system combining text-based searching with an image similarity engine. The Open-i system enables users to search for and retrieve citations that are enriched with relevant images and bottom line (or take away) statements extracted from the Open Access subset of the PubMed Central repository maintained by the National Library of Medicine (NLM); as well as over 8,000 radiology images and 4,000 radiology examination reports from the Indiana University collection of chest x-rays; 67,517 images from NLM History of Medicine collection; and about 2,064 orthopedic anatomy illustrations provided by Norris Medical Library, University of Southern California. Each enriched citation is linked to PubMed Central, PubMed, MedlinePlus as well as to the article itself at the publisher's Web site. A user may search by text words and by query images. Using this framework we explore alternative approaches to search for information using a combination of visual and text features: (i) starting a text-based search of an image database, and refining the search using image features; (ii) starting a visual search using a clinical image of a given patient, and then linking the image to relevant information found by using visual and text features; (iii) starting a multimodal search that combines text and image features. Open-i indexes all the text and illustrations in medical articles by features, both textual and image-based. Open-i also indexes a collection of 8000 digital chest x-rays and accompanying radiology reports with an aim to provide easy access to publicly available and de-identified patient records, as well as the orthopedic and historical images. To compute text and image features efficiently, the system is built on a high performance distributed computing platform. As the first and perhaps only production-quality system of its kind in the biomedical domain, Open-i has enabled medical professionals and the public to access visual information from biomedical articles that are highly relevant to their query, as well as the ""take away"" messages of the articles. The quality of the information delivered by Open-i has been evaluated in international competitions, in which the system consistently ranks among the best. For the past years the site has attracted over 10,000 unique visitors daily (excluding bots) with 690,000 hits daily and is able to support searches of vast multimedia collections. During the 2020 reporting period, the Open-i user interface was updated to provide equal quality of retrieval results for all types of devices used to access the site.   Using images from Open-i and MedPix, we have created several collections of clinically relevant question-answer pairs pertaining to images and used the collections in the biomedical VQA challenges, which we co-organized within the international ImageCLEF evaluations. n/a",Integrating image and text information for biomedical information retrieval,10269684,ZIALM010001,"['Anatomy', 'Bibliography', 'California', 'Clinical Research', 'Collection', 'Color', 'Databases', 'Decision Support Systems', 'Devices', 'Differential Diagnosis', 'Electronic Health Record', 'Evaluation', 'Eye', 'Goals', 'Graph', 'History of Medicine', 'Home environment', 'Hybrids', 'Image', 'Indiana', 'Information Retrieval', 'International', 'Journals', 'Knowledge', 'Link', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Medical', 'Medical Libraries', 'MedlinePlus', 'Methods', 'Multimedia', 'Natural Language Processing', 'Orthopedics', 'Outcome', 'Patients', 'Performance', 'Production', 'PubMed', 'Radiology Specialty', 'Records', 'Reporting', 'Research Support', 'Resources', 'Retrieval', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Texture', 'Thoracic Radiography', 'Unified Medical Language System', 'United States National Library of Medicine', 'Universities', 'Update', 'Visual', 'Work', 'base', 'bioimaging', 'clinical imaging', 'clinically relevant', 'cluster computing', 'computational platform', 'deep learning', 'digital', 'imaging modality', 'improved', 'indexing', 'journal article', 'multimodality', 'patient oriented', 'phrases', 'radiological imaging', 'radiologist', 'repository', 'search engine', 'tool', 'visual information', 'visual search', 'web site']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2020,621320,-0.00939369879382688
"Optimization of diagnostic accuracy, radiation dose, and patient throughput for cardiac SPECT via advanced and clinically practical cardiac-respiratory motion correction and deep learning Single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) is widely used to detect and evaluate coronary artery disease. The goal of this project is to reduce the radiation dose and/or scan time of SPECT MPI by a combined factor of 16x, while maintaining or increasing diagnostic accuracy. This would enable SPECT MPI to be performed, e.g., with 4x reduced radiation dose and 4x shorter scan time (~2.5 minutes) than typical protocols. Radiation dose in SPECT MPI has been recognized as an important issue, accounting for ~25% of all radiation exposure to patients in medical imaging. Dose reduction particularly addresses the increased prevalence of obese patients (who receive higher dose) and younger cardiac patients (whose radiation risk is higher due to longer life expectancy). Reduction in scan time would improve comfort for elderly and infirm cardiac patients, while mitigating body-motion image artifacts and reducing healthcare costs by increasing clinical throughput. We will reduce dose and scan time through innovative image reconstruction methods that involve little or no cost and require no additional patient setup steps. We will employ new respiratory and cardiac motion compensation to reduce image artifacts, as well as new deep learning techniques, which will be used for both respiratory-signal estimation and high-performance denoising. We will methodically optimize these techniques and then validate our algorithms in multicenter clinical reader studies. SA1: Develop clinically practical respiratory motion surrogates for low-count studies. T1: Perfect data- driven respiratory surrogate estimation; T2: Optimize data-driven surrogate estimation at reduced counts; T3: Develop and clinically validate depth-sensing cameras for respiratory and body-motion surrogate estimation; T4: Generalization of data-driven surrogate estimation to SPECT systems not having a CT. SA2: Develop deep-learning reconstruction methods and optimize for diagnostic accuracy and dose/scan time. T1: Post-reconstruction DL denoising algorithms for 3D perfusion images for reduced-count and standard- count studies; T2: DL denoising algorithms for 4D cardiac-gated studies; T3: 4D reconstruction with embedded DL denoising, cardiac motion estimation and correction; and T4: DL reconstruction methods with both RMC and CMC, with projection data binned using respiratory surrogate signals derived in SA1. SA3: Perform multicenter clinical reader studies (6 clinicians, 3 institutions) to validate the new algorithms and compare to current clinically-available methods based on diagnostic performance and repeatability in assessing both perfusion and wall motion defects. T1: In comparison to baseline clinical reconstruction, evaluate added benefit of: a) including attenuation and scatter correction, and b) additionally including RMC; T2: Validate DL for improvement of perfusion and function (wall motion) task performance at full-count levels; and T3: Validate DL for improvement of task performance at reduced counts. PROJECT NARRATIVE In this project we will employ new methods of image reconstruction and processing to reduce radiation dose and scan time in cardiac SPECT imaging, which is used 15-20 million times per year to evaluate coronary artery disease. Dose reduction is important because cardiac SPECT accounts for ~25% of all radiation exposure to the public due to medical imaging; reducing scan time would make SPECT more comfortable for elderly and infirm cardiac patients, while mitigating image artifacts, as well as and reducing healthcare costs by allowing more patients to be scanned per day. Our goal will be to achieve a combined 16x reduction in dose and scan time while maintaining or improving diagnostic accuracy, thereby permitting a 4x reduction in dose while reducing scan time from ~10 minutes to ~2.5 minutes.","Optimization of diagnostic accuracy, radiation dose, and patient throughput for cardiac SPECT via advanced and clinically practical cardiac-respiratory motion correction and deep learning",10072432,R01HL154687,"['3-Dimensional', '4D Imaging', 'Accounting', 'Address', 'Advocate', 'Algorithms', 'American', 'Cardiac', 'Clinic', 'Clinical', 'Computer software', 'Coronary Arteriosclerosis', 'Data', 'Defect', 'Development', 'Diagnostic', 'Disease', 'Dose', 'Effectiveness', 'Elderly', 'Electromagnetic Energy', 'Exposure to', 'Financial compensation', 'Functional Imaging', 'Goals', 'Health Care Costs', 'Image', 'Imaging Techniques', 'Institution', 'Left Ventricular Function', 'Life Expectancy', 'Measures', 'Mechanics', 'Medical Imaging', 'Methods', 'Modality', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Play', 'Population', 'Prevalence', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation exposure', 'Reader', 'Recommendation', 'Resolution', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Societies', 'System', 'Task Performances', 'Techniques', 'Technology', 'Time', 'Translating', 'Validation', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'cardiac single photon emission computed tomography', 'clinical care', 'cost', 'deep learning', 'denoising', 'denoising deep learning', 'diagnosis evaluation', 'diagnostic accuracy', 'heart motion', 'hemodynamics', 'image processing', 'image reconstruction', 'imaging modality', 'imaging system', 'improved', 'innovation', 'perfusion imaging', 'preservation', 'prognostic', 'quantum', 'radiation risk', 'radiologist', 'reconstruction', 'respiratory', 'single photon emission computed tomography', 'tool', 'visual tracking']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2020,786840,0.019242378301817964
"Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment Project Summary More than 20,000 hematopoietic stem cell transplants (including bone marrow transplants) are performed in the U.S. each year to cure a range of diseases ranging from leukemias to sickle cell anemia to autoimmune deficiencies in children. Unfortunately, most long-term non-relapse survivors will die of chronic graft-versus-host disease (cGVHD), which remains a disease of steadily increasing incidence and profound unmet need. A fundamental barrier in cGVHD management and research is a lack of sensitive and objective assessment tools that permit objective and reproducible measures of disease severity and progression. Skin is the most commonly affected organ in cGVHD and automated techniques capable of measuring precisely the surface area of involved skin in photographs may provide the tools necessary for effectively evaluating patient progress. We propose to (1) create the data set necessary to develop machine learning-based methods for the automatic analysis of cGVHD images, and (2) implement and evaluate these methods. Project Narrative  Chronic graft-versus-host disease (cGVHD) is a lethal disease that affects most long-term hematopoietic stem cell transplant (including bone marrow transplants) recipients. Skin images are used to assess disease severity and progression but the technology required to quantitatively and reproducibly analyze these images is lacking. This project aims at developing and evaluating this technology.",Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment,9864040,R21AR074589,"['3-Dimensional', 'Achievement', 'Affect', 'Agreement', 'Allogenic', 'Area', 'Assessment tool', 'Autoimmune Process', 'Body Surface', 'Bone Marrow Transplantation', 'Characteristics', 'Child', 'Circumscribed Lesion', 'Clinic', 'Clinical', 'Clinical Research', 'Cutaneous', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dermatologic', 'Dermatologist', 'Disease', 'Disease Management', 'Disease Progression', 'Documentation', 'Erythema', 'Exanthema', 'Future', 'Goals', 'Hematologic Neoplasms', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic System', 'Human', 'Image', 'Incidence', 'Industry', 'Institution', 'Label', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methods', 'Morbidity - disease rate', 'Organ', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Protocols documentation', 'Psoriasis', 'Reaction', 'Reproducibility', 'Research', 'Resources', 'Role', 'Scanning', 'Severities', 'Severity of illness', 'Sickle Cell Anemia', 'Site', 'Skin', 'Skin Cancer', 'Standardization', 'Surface', 'Survivors', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-dimensional analysis', 'Time', 'Transplant Recipients', 'Visit', 'Vitiligo', 'automated analysis', 'base', 'cancer imaging', 'chronic graft versus host disease', 'data warehouse', 'deep learning', 'deep neural network', 'digital', 'graft vs host disease', 'high risk', 'image processing', 'improved', 'interdisciplinary approach', 'learning strategy', 'leukemia', 'machine vision', 'mortality', 'network architecture', 'neural network architecture', 'novel therapeutics', 'patient subsets', 'prototype', 'repository', 'response', 'skin disorder', 'skin lesion', 'stereoscopic', 'success', 'tool']",NIAMS,VANDERBILT UNIVERSITY,R21,2020,201692,-0.008549514267606773
"2021 International Workshop on Pulmonary Imaging SUMMARY This application requests funding to support the 2021 International Workshop on Pulmonary Imaging, a three- day meeting to be held from February 25-27, 2021, which will be the seventh of its kind hosted by the University of Pennsylvania. The requested funds will primarily be used to cover travel and lodging for junior researchers who will be presenting at the workshop: undergraduate, graduate and junior faculty. Some funds may also be allocated to help pay for live webcasting and publication costs related to workshop materials. As with previous meetings, we intend to stream each session of the meeting in real-time, allowing those who are interested in the proceedings but unable to attend in person to access them online for free. As mortalities associated with pulmonary disease continue to rise worldwide, innovative imaging techniques capable of both diagnosing and helping to treat these pathologies are becoming an increasingly important. As a field, pulmonary imaging currently encompasses a wider range of techniques for the structural, functional and molecular assessment of lung disorders than at any time in its history. What is more, these techniques are being developed and optimized by researchers across an increasingly diverse set of fields such as biology, chemistry, physics, engineering, computer science and medicine. Given the field's rapidly-evolving nature, the existence of a regular forum in which scientists and clinicians can communicate their ideas with each other is of the utmost importance. Given the absence of other scientific meetings with a similarly focused agenda, our previous workshops have succeeded in providing just such a forum—allowing a diverse group of pulmonary imaging researchers to come together for the kind of rigorous, collaborative exchange that can continue to advance the field. The specific aims of the proposed workshop are as follows: (1) host a one-day workshop on pulmonary inflammation; (2) inform the pulmonary imaging community of the latest advances in structural, functional and molecular lung imaging; (3) explore the use of pulmonary imaging to evaluate therapeutic response, the inherent obstacles to doing so, and strategies to overcome them; (4) investigate new approaches for integrating deep learning and pulmonary imaging techniques to more accurately diagnose and phenotype disease and predict injury progression; (5) broadcast the entire workshop live online, thereby enabling interested parties not in attendance to access the proceedings in real-time, free of charge. Based on the uniformly positive feedback in response to our one-day boot camp on pulmonary physiology prior to the 2019 workshop, we intend to hold another boot camp before the 2021 meeting, this time focused on pulmonary inflammation. This boot camp will consist of ~5 longer presentations (approximately 1 hour each) on topics related to this central theme, with significant time devoted to question and answer after each, and a final discussion panel aimed at synthesizing the most important issues covered over the course of the day. In addition to this exciting addition to the format, the 2021 workshop will again seek a more equitable balance between functional, structural and molecular imaging approaches to pulmonary disease across the invited talks, while also continuing to expand our recent focus on the topics of imaging assessments of treatment response and the integration of imaging techniques with machine learning. Finally, the 2021 workshop add a session on bridging the gap between current clinical practice and innovative imaging technologies. NARRATIVE This application requests funding to support the 2021 International Workshop on Pulmonary Imaging at the University of Pennsylvania. This recurring workshop provides a necessary and valuable opportunity for researchers working in the fields of functional, structural, and molecular imaging technique development for assessing lung diseases such as lung cancer, COPD, IPF and ARDS to come together in order to discuss and share their work. The full workshop proceedings will be streamed live online, allowing those unable to attend in person the opportunity to both watch and participate in the meeting.",2021 International Workshop on Pulmonary Imaging,10070932,R13HL154586,"['Address', 'Adult Respiratory Distress Syndrome', 'Anatomy', 'Biology', 'Characteristics', 'Charge', 'Chemistry', 'Chronic Obstructive Airway Disease', 'Classification Scheme', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Educational workshop', 'Engineering', 'Equilibrium', 'Faculty', 'Feedback', 'Functional Imaging', 'Funding', 'Future', 'Gases', 'Heart', 'Hour', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury', 'International', 'Learning', 'Location', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant neoplasm of lung', 'Medicine', 'Molecular', 'Movement', 'Nature', 'Pathology', 'Pennsylvania', 'Persons', 'Phenotype', 'Physics', 'Physiology', 'Positron-Emission Tomography', 'Process', 'Protons', 'Public Health', 'Publications', 'Pulmonary Inflammation', 'Pulmonology', 'Radiology Specialty', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Scientist', 'Stream', 'Structure', 'Techniques', 'Time', 'Travel', 'Treatment Efficacy', 'Universities', 'Update', 'Work', 'accurate diagnosis', 'base', 'clinical practice', 'computer science', 'cost', 'deep learning', 'density', 'disease phenotype', 'graduate student', 'imaging approach', 'imaging biomarker', 'imaging modality', 'improved', 'innovation', 'interest', 'lung imaging', 'meetings', 'molecular imaging', 'mortality', 'non-invasive imaging', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'technique development', 'treatment response', 'undergraduate student']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R13,2020,29805,-0.00241880527628886
"An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic ABSTRACT More than 20 million patients suffer from age-related macular degeneration, diabetic retinopathy, or glaucoma. These degenerative eye diseases develop over decades, and their prevalence is increasing. Retinal imaging technologies such as optical coherence tomography and adaptive optics ophthalmoscopy are essential tools in the investigation and management of eye disease. New quantitative biomarkers derived from these and other imaging modalities are critical to the clinical translation of emerging ophthalmic innovations. However, biomarker development in the era of artificial intelligence requires large volumes of annotated images and transparent, reproducible processes, which places new demands on the management of living subjects research, data sharing, and algorithm development. Unfortunately, current software platforms are not effective in integrating these data in a manner that meets specific requirements in ophthalmology, Our goal in this Direct-to-Phase II SBIR, consistent with objectives of the NIH Strategic Plan for Data Science, is to create an integrated platform (PaaS) for the collection, curation, analysis, and sharing of ocular images and data. We will extend the capabilities of systems developed by the Advanced Ocular Imaging Program (AOIP), Medical College of Wisconsin (MCW), which include: (a) LATTICE - a software solution that reduces costs, reduces errors, and improves communications in the management of living-subjects research; (b) MOSAIC - an image processing platform and algorithm library with traditional and AI-trained algorithms; and (c) The AOIP Image Bank - a Repository that houses images and data on 1578 fully-consent human research subjects. To create the integrative platform, we will address four aims: (a) Extend LATTICE to meet the workflow requirements of academic and sponsored research in local and multisite environments, including the extensible direct integration of data relevant to ocular studies; (b) Design and implement a hybrid (local + cloud) REPOSITORY architecture, data schema, knowledge ontology, and query architecture for Owners and Readers of data.; (c) Integrate and demonstrate LATTICE, REPOSITORY and MOSAIC into a continuous ocular science workflow and (d) integrate and demonstrate Lattice, Repository and Mosaic into a continuous ocular science workflow. Our Integrated Translational Imaging platform will enable ophthalmic innovators to translate sight-saving insights and interventions to the clinic faster, with less frustration, and greater confidence. Our proposal fills an important technology gap in the field of ophthalmic data science and biomarker development. While the number and type of imaging devices continues to grow, the tools to develop and deploy new biomarkers and clinical endpoints using these exquisite imaging devices has not kept pace. With this program we will enable a new generation of image-driven innovation to find its way to the clinic. Project Narrative With more than 20 million patients suffering from age-related macular degeneration, diabetic retinopathy, or glaucoma, it is crucial to develop non-invasive biomarkers as early predictors of eye disease and reliable tests of the safety and efficacy of new preventative and restorative therapies. To meet the unmet need for rapid access and analysis of ophthalmic research data for the discovery of these biomarkers, we will create an integrated platform (PaaS) for the collection, curation, sharing, and analysis of ocular images and data. If we meet our objectives, our platform will reduce the cost of clinical research and increase the speed of translating critical research insights to saving the sight of millions of patients.",An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic,9908389,R44EY031198,"['Address', 'Age related macular degeneration', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Collection', 'Communication', 'Computer software', 'Consent', 'Data', 'Data Discovery', 'Data Science', 'Diabetic Retinopathy', 'Docking', 'Economics', 'Environment', 'Eye diseases', 'Foundations', 'Frustration', 'Funding', 'Glaucoma', 'Goals', 'Housing', 'Human Subject Research', 'Hybrids', 'Image', 'Imaging Device', 'Imaging technology', 'Influentials', 'Intervention', 'Investigation', 'Knowledge', 'Libraries', 'Mosaicism', 'Ontology', 'Ophthalmology', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Phase', 'Policies', 'Prevalence', 'Process', 'Reader', 'Research', 'Research Subjects', 'Savings', 'Science', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Translating', 'Translations', 'United States National Institutes of Health', 'Validation', 'Vision', 'Wisconsin', 'adaptive optics', 'algorithm development', 'algorithm training', 'application programming interface', 'biomarker development', 'biomarker discovery', 'clinical translation', 'cost', 'data access', 'data exchange', 'data integration', 'data sharing', 'data warehouse', 'deep learning', 'design', 'efficacy testing', 'experience', 'fighting', 'image processing', 'image reconstruction', 'imaging modality', 'imaging platform', 'imaging program', 'improved', 'innovation', 'insight', 'medical schools', 'microsystems', 'ocular imaging', 'process repeatability', 'programs', 'repository', 'retinal imaging', 'safety testing', 'software systems', 'structured data', 'tool', 'verification and validation', 'vision science']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R44,2020,743347,-0.02868343683645906
"Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks PROJECT SUMMARY The long-term goal of this project is to improve the care of patients with laryngeal disorders through development of automated diagnostic support for in-office flexible laryngoscopy. To accomplish this goal, we propose developing neural network-based algorithms to detect and classify structural laryngeal lesions in laryngoscopy images. An automated diagnostic tool for in-office laryngoscopy such as we propose will have several benefits: (1) It will improve access to care for patients with symptoms of laryngeal dysfunction living in communities with limited otolaryngology resources, (2) It will improve early detection of laryngeal cancers potentially reducing the morbidity of treatment, and (3) It will prove a valuable teaching tool for students and residents first learning to interpret laryngoscopic exams. Flexible laryngoscopy is a common in-office procedure performed by otolaryngologists to evaluate the upper aerodigestive tract in patients with symptoms of laryngeal dysfunction. Subtle differences in the appearance of laryngeal lesions enable otolaryngologists to differentiate benign lesions from suspected malignant ones. The expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training and therefore laryngoscopy is largely only performed in subspecialty otolaryngology clinics. The primary objective of this project is to develop neural network-based algorithms to detect and classify structural laryngeal lesions. Our hypothesis is that these algorithms can be trained using a large dataset of laryngeal images to accurately detect and classify structural laryngeal lesions on flexible laryngoscopic exam. To test this hypothesis, we propose the following aims: (1) Generate a dataset of high-quality, labeled endoscopic laryngeal images corresponding to normal and structural lesions of the larynx, (2) Develop a location-aware anchor-based reasoning neural network for accurate detection of laryngeal lesions, and (3) Develop an adaptive network model for classification of structural laryngeal pathologies including papilloma, polyp, leukoplakia and suspected malignancy. With expertise in the diagnosis and treatment of laryngeal disorders and computer vision, including object detection and classification, our multidisciplinary team is uniquely qualified to complete this project. PROJECT NARRATIVE We propose to revolutionize in-office laryngoscopy through development of a deep neural network-based automated detection and classification system for diagnosis of structural diseases of the larynx. Currently, flexible laryngoscopy is only performed by expert subspecialists with years of experience because developing the expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training. Through development of deep neural network-based algorithms to detect and classify laryngeal lesions on in- office laryngoscopy, we will improve access to care for patients living in communities without subspecialty otolaryngology care and will develop an important teaching tool for clinicians learning to interpret laryngoscopic exams.",Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks,10043172,R03CA253212,"['Aerodigestive Tract', 'Algorithms', 'Anesthesia procedures', 'Appearance', 'Architecture', 'Awareness', 'Benign', 'Caring', 'Categories', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Collaborations', 'Colonic Polyps', 'Colonoscopy', 'Communities', 'Computer Vision Systems', 'Custom', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Distal', 'Drops', 'Early Diagnosis', 'Educational process of instructing', 'Ensure', 'Fellowship', 'Functional disorder', 'Gastroesophageal reflux disease', 'Goals', 'Health Services Accessibility', 'Hoarseness', 'Image', 'Improve Access', 'Infection', 'Label', 'Laryngeal Diseases', 'Laryngoscopes', 'Laryngoscopy', 'Larynx', 'Learning', 'Lesion', 'Leukoplakia', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of larynx', 'Manuals', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Network-based', 'Normal Range', 'Otolaryngologist', 'Otolaryngology', 'Papilloma', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Pilot Projects', 'Plug-in', 'Polyps', 'Positioning Attribute', 'Procedures', 'Recurrence', 'Resources', 'Sampling', 'Semantics', 'Structure', 'Students', 'Symptoms', 'System', 'Technical Expertise', 'Testing', 'Training', 'Vision research', 'Work', 'base', 'classification algorithm', 'cost', 'deep neural network', 'detector', 'digital', 'experience', 'feature extraction', 'flexibility', 'improved', 'large datasets', 'learning algorithm', 'multidisciplinary', 'network models', 'neural network', 'tool']",NCI,UNIVERSITY OF KANSAS MEDICAL CENTER,R03,2020,154375,-0.03532858356050874
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9997917,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Infrastructure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'feature detection', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'patient health information', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2020,1339073,0.014043397962715838
"IEEE Medical Imaging Conference Abstract  The IEEE Medical Imaging Conference (MIC) is the leading international scientific meeting bringing together a broad community interested in the physics, engineering and mathematical aspects of medical imaging, with special emphasis on nuclear medicine and multi-modal systems. The MIC runs in conjunction with the IEEE Nuclear Science Symposium (NSS) and the Workshop on Room Temperature Semiconductor X-ray and Gamma-ray Detectors (RTSD).  The purpose of the MIC is to disseminate and foster new research in physics and bio-engineering methods in medical imaging. While the traditional topics of primary interest are related to nuclear medicine techniques such as positron emission tomography (PET) and single photon emission computerized tomography (SPECT), increasing space will be also given to recently evolving imaging modalities such as X-ray, CT, optical, MR, with special emphasis on their multi-modal combination with nuclear medical imaging. Recently there has also been additional interest in employing deep learning and AI to enhance the field medical imaging. The conference provides a well-established forum of scientific exchange and dialogue between researchers in academia, industry, and government as well as education of the public, with special emphasis on young generations. This is reflected by the large spectrum of educational refresher sessions and short courses. One of the major objectives of the conference is the education of young investigators, and therefore this NIH R13 proposal seeks $10,000 in funding for each of the next three years to provide 20 trainee grants of $500 each to partially cover costs of MIC conference registration, housing and/or short course fees for graduate students and postdoctoral fellows based at US institutions.  We anticipate that the main impact of this grant program will be to increase attendance of students and postdocs at the 2020 meeting, especially those typically underrepresented, as well as to support their participation in educational activities. It is important to bring young generations, especially women, minorities, and those with disabilities, into the medical imaging field, where they could become main actors in the coming years. They will attend plenary and oral presentations given by many of the world leaders in the nuclear medical imaging instrumentation, image processing, and quantitative analysis fields. Moreover, they will be given the unique opportunity of direct personal interaction through the short courses and dedicated poster presentations. In turn their work will be exposed to the other participants for critical evaluation, constructive suggestions and dissemination. Furthermore, many of these trainees will likely continue in this field, thereby contributing to advancing technology with high societal relevance as being increasingly used in the clinical management of disease and therapeutic interventions. Narrative  The IEEE Medical Imaging Conference (MIC) has the purpose to disseminate and foster new research in physics and bio-engineering methods in medical imaging. The conference covers a variety of medical imaging topics including quantitative imaging, PET/SPECT techniques, image reconstruction, imaging in radiation therapy, portable imaging, multi-modality systems, new medical imaging technologies, CT/MR/optical/ultrasound, parametric/kinetic image modeling, and signal/image processing and modeling. One of the major objectives of the conference is the education and encouragement of young investigators, and therefore this NIH R13 proposal seeks funding to provide twenty grants for each of the next three years to graduate students and postdoctoral fellows based at US institutions to partially cover costs of MIC conference registration and short course fees.",IEEE Medical Imaging Conference,10071524,R13EB030423,"['Academia', 'Animals', 'Area', 'Artificial Intelligence', 'Attention', 'Award', 'Biological', 'Biomedical Engineering', 'Brain', 'Clinical Management', 'Collaborations', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'Detection', 'Development', 'Diagnosis', 'Disabled Persons', 'Discipline of Nuclear Medicine', 'Disease Management', 'Education', 'Educational Activities', 'Educational workshop', 'Emission-Computed Tomography', 'Engineering', 'Evaluation', 'Exposure to', 'Fees', 'Fostering', 'Funding', 'Gamma Rays', 'Generations', 'Government', 'Grant', 'Housing', 'Image', 'Image Analysis', 'Imaging technology', 'Industrialization', 'Industry', 'Institution', 'International', 'Italy', 'Japan', 'Joints', 'Kinetics', 'Lead', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Care Costs', 'Medical Imaging', 'Medical Technology', 'Methods', 'Minority', 'Modeling', 'Modernization', 'Monitor', 'Multimodal Imaging', 'Nuclear', 'Optics', 'Oral', 'Participant', 'Photons', 'Physics', 'Positron-Emission Tomography', 'Postdoctoral Fellow', 'Radiation therapy', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Roentgen Rays', 'Running', 'Scientist', 'Semiconductors', 'Signal Transduction', 'Students', 'Suggestion', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic Intervention', 'Time', 'Tracer', 'Translations', 'Ultrasonography', 'Underrepresented Groups', 'United States National Institutes of Health', 'Woman', 'Work', 'base', 'clinical imaging', 'clinical practice', 'cost', 'deep learning', 'design', 'detector', 'disability', 'graduate student', 'image processing', 'image reconstruction', 'imaging modality', 'innovation', 'instrumentation', 'interest', 'kinetic model', 'meetings', 'member', 'models and simulation', 'multidisciplinary', 'multimodality', 'nanoparticle', 'novel', 'nuclear science', 'parametric imaging', 'portability', 'posters', 'programs', 'public education', 'quantitative imaging', 'radiation detector', 'reconstruction', 'signal processing', 'statistics', 'symposium', 'theranostics']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R13,2020,10000,0.0004821290647095576
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9989186,R44MH118815,"['3-Dimensional', 'Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'stem cells', 'treatment strategy', 'two-dimensional', 'usability', 'virtual environment', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,749716,0.028597522278036542
"SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring This project aims to develop an interpretable, physician-in-the-loop AI-aided software that accurately delineates glioma boundaries in MRIs, computes volumetric curves, and statistically quantifies the tumor growth in longitudinal studies. The current clinical practice of visually analyzing and manually contouring tumors is subjective, time-consuming, and often inconsistent. The novelty of MRIMath's explainable, trustworthy, and physician-in-the-loop AI system is multi-fold. First, we introduce a multi-scale feature extraction framework using the inception modules in contracting and expanding paths of the U-Net image segmentation neural network architecture. Second, we propose a new loss function based on the modified Dice similarity coefficient. Third, we train and test the AI system using two learning regimes: learning to segment intra-tumoral structures and learning to segment glioma sub-regions. Finally, we produce heat maps to visualize the features extracted by the AI, thus offering physicians a view of AI's attention patterns and activation maps that were triggered during AI's decision-making. An intuitive and interactive User Interface will allow the physician to review contouring results, make adjustments and approve contours, visualize AI's explanations and volumetric measurements, and finally review the results of the statistical analysis. Any modifications made by the physician will be used later to re-train AI. n/a","SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269837,5N91020C00049,"['Artificial Intelligence', 'Attention', 'Computer software', 'Consumption', 'Contracts', 'Data', 'Data Sources', 'Decision Making', 'Diagnosis', 'Glioma', 'Human', 'Intuition', 'Learning', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measurement', 'Modality', 'Modification', 'Monitor', 'Pattern', 'Phase', 'Physicians', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'TimeLine', 'Training', 'base', 'cancer imaging', 'cancer prevention', 'clinical practice', 'design', 'feature extraction', 'imaging Segmentation', 'imaging software', 'imaging system', 'loss of function', 'neural network architecture', 'prototype', 'tumor', 'tumor growth', 'usability']",NCI,"MRIMATH, LLC",N43,2020,400000,-0.02343924956487479
"Multi-modal and Extreme PET/MRI Reconstruction Methods Project Summary / Abstract  Hybrid PET/MRI systems are very advantageous for a variety of clinical applications by combining the soft tissue contrast of MRI with the functional and metabolic information of PET. These systems have found success for oncology studies, particularly in head and abdomen/pelvis, as well as for epilepsy, neurological diseases, heart disease, and pediatrics for dose reduction. However, the PET resolution and SNR is typically worse than MRI, and suffers from the loss of feature and data due to motion as well. PET/MRI systems offer the potential to create more accurate, higher resolution PET reconstructions, including correction of artifacts, motion, and im- proved localization, by performing synergistic reconstructions that leverage the simultaneous data acquisition. In particular, this fellowship proposes to develop novel physics-constrained machine learning models for informa- tion sharing between PET and MRI for enhanced spatial localization, estimation of attenuation and activity, and motion. We propose to develop a deep maximum-likelihood estimation of attenuation and activity (MLAA) that can compensate for artifacts and improve PET reconstruction accuracy. We also propose a motion-enhanced joint PET/MRI reconstruction to capture arbitrary motions and reduce dose requirements for chest and abdomen studies. Together, these models aim to improve the PET spatio-temporal resolution, SNR, and quantiﬁcation for a broad range of clinical applications, and will be evaluated for cancer assessment in the pelvis, liver, and lung.  This fellowship will be performed in the Department of Radiology and Biomedical Imaging at UCSF under the guidance of Prof. Peder Larson, who leads a research program on advanced imaging methods development, and Dr. Thomas Hope, a radiologist and nuclear medicine physician who leads multiple PET/MRI projects. The Department is one of the leading centers in biomedical imaging research, and has been at the forefront on translating PET/MRI systems into clinical practice. The UCSF PET/MRI scanner has dedicated research time, which is also available on other MRI and PET/CT research systems, and extensive computational resources to support the proposed project. The applicant, Dr. Abhejit Rajagopal, has a background in computational imaging and machine learning, will be jointly mentored by this engineer/physician team. He will be trained to become a biomedical imaging scientist by participating in formal coursework on medical imaging systems, training on the PET/MRI system, grant writing, and performing clinical research, supporting his development into a creative, independent biomedical researcher. Project Narrative  Hybrid positron emission tomography (PET) and magnetic resonance imagery (MRI) imaging systems cur- rently aid in diagnosis and prognosis of numerous types of cancer and disease, but are not always precise enough to accurately measure and track a patient’s response to therapy, particularly in organs and tissue that are sub- ject to motion. There is an unrealized potential here to synergistically combine complimentary PET-MRI data to dramatically improve the spatial resolution and SNR of PET, as well as to create motion-resolved 4D (x,y,z,t) imagery by combining information across modalities and time-frames to combat severe undersampling. These methods will be evaluated in human studies of cancer to capture ﬁne structure and micro-features on moving organs (e.g. lung nodules, liver metastases), ultimately aiding in quantitative characterization of disease.",Multi-modal and Extreme PET/MRI Reconstruction Methods,10069132,F32EB030411,"['3-Dimensional', 'Abdomen', 'Address', 'Affect', 'Algorithms', 'Attention', 'Chest', 'Childhood', 'Clinical', 'Clinical Research', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discipline of Nuclear Medicine', 'Disease', 'Dose', 'Engineering', 'Epilepsy', 'FOLH1 gene', 'Fellowship', 'Financial compensation', 'Goals', 'Grant', 'Head', 'Head and Neck Cancer', 'Heart Diseases', 'Human', 'Hybrids', 'Image', 'Imagery', 'Implant', 'Joint repair', 'Joints', 'Learning', 'Liver', 'Lung', 'Lung nodule', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Female Reproductive System Neoplasm', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Medical Imaging', 'Mentors', 'Metabolic', 'Metals', 'Metastatic Neoplasm to the Liver', 'Methods', 'Modality', 'Modeling', 'Morphologic artifacts', 'Motion', 'Neurodegenerative Disorders', 'Oncology', 'Organ', 'Output', 'Patients', 'Pediatrics', 'Pelvis', 'Performance', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Scanning', 'Signal Transduction', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Tracer', 'Training', 'Translating', 'Writing', 'attenuation', 'bioimaging', 'bone', 'cancer type', 'clinical application', 'clinical practice', 'combat', 'computing resources', 'data acquisition', 'deep learning', 'heart imaging', 'high resolution imaging', 'imaging modality', 'imaging scientist', 'imaging system', 'improved', 'information model', 'lung imaging', 'method development', 'multimodality', 'nervous system disorder', 'neuro-oncology', 'novel', 'outcome forecast', 'patient response', 'programs', 'radiological imaging', 'radiologist', 'reconstruction', 'respiratory', 'soft tissue', 'spatiotemporal', 'success', 'systems research', 'uptake']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2020,69426,0.008645266960467845
"An Integrated CT-based Image-Guided Neurosurgical System An Integrated CT-based Image-Guided Neurosurgical System In this SBIR Phase IIb proposal Xoran intends to commercialize a compact and affordable, yet highly- functional, system to provide real time image updates and navigation guidance in support of minimally invasive cranial and spinal neurosurgical procedures. The effort builds on previously developed compact and portable flat-panel Computed Tomography (CT) technology which has been commercialized for hard tissue applications, and incorporates work done in earlier phases of this project to generate viable high- quality images of the soft tissue structures in the brain. Intraoperatively obtained images tightly integrated into an onboard surgical navigation will provide updated instrument localization using next generation electromagnetic tool tip guidance. Workflow optimizations become possible when the imaging and guidance are one device, including fast local image updates, automatic image-to-world registration, as well as speed and simplicity of use. The project includes expansion of the system capabilities to facilitate precise minimally-invasive surgical removal of tumors in both the head and spine. It incorporates a machine-learning based deep neural network method for image finalization to allow high quality, low radiation image updates. The three-year project involves meeting technical milestones of system development including imaging capability, registration, navigation accuracy, speed, workflow, radiation dose considerations and cost. Clinical evaluations will take place at University of Michigan, and a team of consulting physicians has been assembled for oversight, input and feedback. Narrative / Relevance to Public Health Minimally invasive surgical procedures have many benefits to public health including reducing the medical risks and costs associated with brain cancer and spine surgery. However such procedures are often time consuming and technically difficult as the surgeon is unable to directly visualize the area of the operation. In this project, an intraoperative surgical system is developed with onboard imaging capability in order to enable minimally invasive surgeries to be performed more safely and completely, by providing hi-resolution imaging of the brain and spine while the surgeon operates.",An Integrated CT-based Image-Guided Neurosurgical System,10017876,R44CA112966,"['3-Dimensional', 'Address', 'Agreement', 'American', 'Anatomy', 'Animals', 'Area', 'Benefits and Risks', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Businesses', 'Caliber', 'Cancer Etiology', 'Canis familiaris', 'Capital', 'Central Nervous System Neoplasms', 'Cephalic', 'Cessation of life', 'Clinic', 'Clinical', 'Computed Tomography Scanners', 'Consensus', 'Consult', 'Consumption', 'Data', 'Devices', 'Diagnosis', 'Dose', 'Electromagnetics', 'Environment', 'Evaluation', 'Excision', 'Feedback', 'Fluoroscopy', 'Funding', 'Goals', 'Head', 'Image', 'Image-Guided Surgery', 'Institutional Review Boards', 'Investments', 'Licensing', 'Machine Learning', 'Malignant neoplasm of brain', 'Mediation', 'Medical', 'Medical Imaging', 'Metals', 'Metastatic Neoplasm to the Bone', 'Michigan', 'Minimally Invasive Surgical Procedures', 'Monitor', 'Navigation System', 'Neoplasm Metastasis', 'Neurosurgeon', 'Neurosurgical Procedures', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Pennsylvania', 'Phase', 'Physicians', 'Pituitary Neoplasms', 'Positioning Attribute', 'Procedures', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Resolution', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Spinal', 'Spine surgery', 'Structure', 'Surgeon', 'Survival Rate', 'System', 'Systems Development', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Update', 'Vertebral column', 'Veterinary Medicine', 'Veterinary Schools', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer site', 'cancer surgery', 'commercial application', 'cost', 'cranium', 'deep neural network', 'human subject', 'image guided', 'image reconstruction', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'instrument', 'interest', 'meetings', 'minimally invasive', 'neurosurgery', 'next generation', 'operation', 'point of care', 'portability', 'real-time images', 'research clinical testing', 'soft tissue', 'spine bone structure', 'tool', 'tumor', 'validation studies']",NCI,"XORAN TECHNOLOGIES, LLC",R44,2020,1279629,0.010175229520902447
"Deviceless and Autonomous Prospective Cardiac CT Triggering PROJECT SUMMARY/ABSTRACT Coronary heart disease (CHD) is the leading cause of death worldwide. An estimated 3.8 million men and 3.4 million women die each year from CHD. Cardiac CT is a safe, accurate, non-invasive imaging modality used for diagnosing CHD and for planning therapeutic interventions. Cardiac CT exams are still challenging to perform due to the beating heart and the need to carefully time the scan based on cardiac phase and based on when the peak iodine contrast enhancement is reached. The overall exam duration and the complexity of performing these exams (contrasted with limited reimbursement levels) have limited patient access to cardiac CT to academic hospitals and specialized cardiac imaging centers. As compared to other CT exams, cardiac CT exams require additional patient preparation time, additional CT scans to track the bolus, and additional contrast agent to avoid missing the peak enhancement.  The goal of this project is to develop a smart cardiac CT scanner that autonomously determines the optimal scan time interval without ECG, traditional bolus tracking or timing bolus. Initial results show that it is possible to extract cardiac gating information from a few CT projection measurements prior to the diagnostic CT scan, without reconstruction. This is made possible by an innovative combination of fast X-ray tube pulsing and deep learning raw data analysis. This project builds on GE Research's experience with cardiac CT technologies, deep learning algorithms and X-ray tube physics, as well as the strong clinical cardiac CT expertise at the University of California San Diego.  The outcome of this project will be a clinical feasibility study of the autonomous triggering approach, which has the potential to simplify and increase patient access to cardiac CT, while reducing exam time, reducing con- trast agent volume, and ensuring robust image quality. PROJECT NARRATIVE The goal of this project is to develop a smart cardiac CT scanner that autonomously determines the optimal scan time interval without ECG, traditional bolus tracking or timing bolus. The result will be a patient-friendly and technologist-friendly cardiac CT exam with reduced exam time, minimal contrast agent volume and radia- tion dose, and robust image quality.",Deviceless and Autonomous Prospective Cardiac CT Triggering,10029731,R01HL153250,"['Algorithms', 'Anatomy', 'Angiography', 'Bolus Infusion', 'California', 'Cardiac', 'Cause of Death', 'Clinical', 'Contrast Media', 'Coronary', 'Coronary heart disease', 'Data', 'Data Analyses', 'Diagnosis', 'Diagnostic', 'Electrocardiogram', 'Ensure', 'Feasibility Studies', 'Financial compensation', 'Goals', 'Heart', 'Hospitals', 'Image', 'Institutional Review Boards', 'Iodine', 'Measurement', 'Morphology', 'Motion', 'Myocardial', 'Outcome', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physics', 'Physiologic pulse', 'Preparation', 'Prospective Studies', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Roentgen Rays', 'Rotation', 'Scanning', 'System', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Time', 'Training', 'Translating', 'Tube', 'Universities', 'Woman', 'X-Ray Computed Tomography', 'algorithm development', 'base', 'contrast enhanced', 'deep learning', 'deep learning algorithm', 'experience', 'heart imaging', 'image reconstruction', 'imaging modality', 'innovation', 'men', 'non-invasive imaging', 'prospective', 'reconstruction', 'standard of care', 'temporal measurement', 'time interval']",NHLBI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,R01,2020,1060608,-0.008973906243641689
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",9850968,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,442592,0.006014142363428086
"Quantitative MRI of Multiple Sclerosis - Resubmission - 1 Project Summary  In this project, we propose a novel T1 and T2 quantification method that generates quantitative T1 or T2 maps from weighted MR images. Magnetic resonance imaging (MRI) is commonly used as a tool to diagnose Multiple Sclerosis (MS) and track lesional changes over time. Because MRI has various contrasts that display different information about the underlying tissue microstructure and physiology, it can potentially be used as a tool to predict MS disease progression and even disability. However, there is no known measure derived from MR images of MS that correlates well with clinical disability as described by the Expanded Disability Status Score (EDSS). Previous efforts to correlate MRI features and EDSS have included calculating total lesion load on T1- and T2-weighted images, measuring the variations in the magnetic transfer ration of normal-appearing brain tissues, and calculating cerebral atrophy, each with a varying level of success. Yet, there has been little study of the evolution of relaxation times of the lesions over time and how it relates to disability. Because changes in the T1 (spin-lattice) and T2 (spin-spin) relaxation times of a tissue can reflect pathological changes in that tissue over time, quantitative T1 and T2 maps derived from MR images may be more indicative of microscopic changes that manifest as disability in MS patients.  The specific aims of this proposal are: (1) develop and validate novel T1 and T2 quantification method on spin-echo MR images, (2) extend the novel quantification method to common MS imaging sequences, and (3) apply the novel quantification method to MS datasets to predict EDSS using machine learning. Aim 1 will involve the validation of the quantification pipeline on both T1- and T2-weighted spin-echo MR images in vivo, resulting in a range of acceptable parameters for the novel quantification method. Aim 2 will extend the quantification pipeline to include commonly used and more complicated MS imaging sequences, again resulting in a range of acceptable parameters for the quantification method. Aim 3 will use the quantification pipeline to compare machine learning algorithms with and without quantification to determine the added value of quantification in the imaging of MS. Additionally, Aim 3 will result in a predictive machine learning model utilizing multiple imaging contrasts for the prediction of disability in MS. These results will provide a more thorough understanding of the role of MR quantification in the evaluation of neurological diseases, such as MS, and will offer a scientific foundation to extend the use of MR quantification as a potential imaging biomarker for other diseases and pathologies. Project Narrative The proposed research aims to develop and validate a T1 and T2 quantification method using internal reference values derived from T1- or T2-weighted MR images. This method will be applied to weighted images of patients who have been diagnosed Multiple Sclerosis and input into various classification algorithms to determine which method is most predictive of worsening clinical disability as described by the Expanded Disability Status Score. By doing this, we will determine the impact of this novel quantification method as a tool for both the analysis of patients with Multiple Sclerosis as well as a tool for the normalization of big MR datasets before being input into machine learning algorithms.",Quantitative MRI of Multiple Sclerosis - Resubmission - 1,10154293,F31NS118930,"['Affect', 'Age-Years', 'Attenuated', 'Axon', 'Brain', 'Cerebrospinal Fluid', 'Clinical', 'Coupled', 'Data', 'Data Set', 'Demyelinations', 'Dependence', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Ensure', 'Equation', 'Evaluation', 'Evolution', 'Fatty acid glycerol esters', 'Foundations', 'Frequencies', 'Image', 'Inflammation', 'Investigation', 'Learning', 'Lesion', 'Liquid substance', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Medical', 'Methods', 'Microscopic', 'Modeling', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Neuraxis', 'Pathologic', 'Pathology', 'Patient imaging', 'Patients', 'Physiology', 'Population', 'Prediction of Response to Therapy', 'Predictive Value', 'Process', 'ROC Curve', 'Recovery', 'Reference Values', 'Relaxation', 'Research', 'Role', 'Scanning', 'Signal Transduction', 'T2 weighted imaging', 'Techniques', 'Time', 'Tissues', 'United States', 'Validation', 'Variant', 'brain tissue', 'cerebral atrophy', 'classification algorithm', 'contrast enhanced', 'contrast imaging', 'data harmonization', 'digital', 'disability', 'gray matter', 'healthy volunteer', 'imaging biomarker', 'improved', 'in vivo', 'in vivo imaging', 'longitudinal dataset', 'machine learning algorithm', 'multiple sclerosis patient', 'nervous system disorder', 'novel', 'predictive modeling', 'prospective', 'simulation', 'subcutaneous', 'success', 'tool', 'treatment response', 'white matter']",NINDS,UNIVERSITY OF CHICAGO,F31,2020,45520,0.0008602627337660014
"Optimizing Acquisition and Reconstruction of Under-sampled MRI for Signal Detection PROJECT SUMMARY Magnetic resonance imaging (MRI) is a versatile imaging modality that suffers from slow acquisition times which is a challenge for both time sensitive applications and for patient throughput. Accelerating MRI would benefit patients both by reducing the time they need to be in the scanner and in reducing the cost of healthcare. This project is part of a larger scientific effort to accelerate MRI while maintaining the diagnostic quality. Acceleration, even by a factor of two would result in a major advance for public health. Two of the current approaches to accelerate MRI rely on collecting less data (under-sampling) and constrained or deep learning reconstruction. These approaches can lead to images with diagnostic quality with significant under-sampling but may suffer from artifacts which are hard to characterize. Specifically, this project will optimize the performance of constrained reconstruction and deep learning on detecting subtle lesions in acquiring and reconstructing under-sampled MRI. To carry out this optimization, we will first develop the methods required for detection of lesions by machine and human observer models. Then the models will be validated by psychophysical studies where humans perform the detection task. In the first aim of this project, we will optimize constrained reconstruction based on the ideal linear observer. We will consider under-sampled acquisition strategies in 2D MRI including one and two dimensional subsampling methods with constrained reconstruction using both wavelet and total variation constraints. We will perform simulations using anatomical backgrounds both for lesions which match the prior information of the constraints and those which do not to better understand how choices in acquisition and reconstruction affect ideal detection. While the ideal linear observer approximates the best possible detection, typically the signal detection is carried out by a human. In the second aim, we will optimize constrained reconstruction using human observer models and validate the models using human observer studies. A recent approach to reconstruction of under- sampled images is based on deep learning. In the third aim, this work will optimize deep learning reconstruction based on ideal and human observers. Due to the complexity of the deep learning approach, having this task-based approach to optimization is particularly relevant. This project will optimize a network using signal detection to better understand how training and architecture choices in the neural network affect detection of lesions which are not included in training images. This research project will help to strengthen the research environment at Manhattan College by involving students in biomedical research incorporating applied mathematics, statistics and data science. PROJECT NARRATIVE Magnetic resonance imaging (MRI) is a versatile imaging modality that suffers from slow acquisition times which is a challenge for both time sensitive applications and for patient throughput. Accelerating MRI would benefit patients and improve public health both by reducing the time they need to be in the scanner and in reducing the cost of healthcare. This project would advance a larger scientific effort to accelerate MRI while maintaining the diagnostic quality by optimizing the performance of constrained reconstruction and deep learning on detecting subtle lesions in accelerated MRI.",Optimizing Acquisition and Reconstruction of Under-sampled MRI for Signal Detection,9880534,R15EB029172,"['Acceleration', 'Affect', 'Anatomy', 'Architecture', 'Biomedical Research', 'Collaborations', 'Data', 'Data Science', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Evaluation', 'Gaussian model', 'Grant', 'Health Care Costs', 'Human', 'Image', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Mathematics', 'Methods', 'Modeling', 'Morphologic artifacts', 'Patients', 'Performance', 'Positron-Emission Tomography', 'Psychophysics', 'Public Health', 'Research', 'Research Project Grants', 'Resolution', 'Sampling', 'Signal Transduction', 'Students', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'college', 'deep learning', 'density', 'flexibility', 'imaging modality', 'improved', 'insight', 'neural network', 'neural network architecture', 'predictive modeling', 'reconstruction', 'simulation', 'single photon emission computed tomography', 'statistics', 'two-dimensional']",NIBIB,MANHATTAN COLLEGE,R15,2020,395210,0.005212784295672752
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),9996604,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'data streams', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'open source', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2020,1198860,0.033045775848745094
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9926311,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Comparative Effectiveness Research', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'cost', 'deep learning', 'diagnosis standard', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2020,348620,0.007853820925514648
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",9890853,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2020,795348,0.014485816699720001
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10016301,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2020,396286,0.044724220549096146
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10010814,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2020,819293,0.029284358182998533
"Next-Generation Ultrasound Localization Microscopy Project Summary/Abstract Abnormal alterations of tissue microcirculation are often associated with early stage of tissue pathology. Detection and characterization of these early microvascular abnormalities can greatly benefit clinical diagnosis and treatment monitoring as well as facilitating the creation of new therapies to counter disease development. For decades, there has been a longstanding quest for the development of a clinical imaging modality that can noninvasively and directly image such tissue microvascular variations. To date, however, such an imaging method remains elusive due to the fundamental compromise between imaging spatial resolution and depth penetration. Therefore, the long-term objective of this project is to fulfill this unmet clinical need by developing the next-generation ultrasound localization microscopy (ULM), which is an ultrasound-based imaging technique that can directly assess structural and functional tissue microvasculature in vivo in humans at a clinically relevant depth. Different from other imaging modalities, ULM is not limited by the resolution-penetration compromise: ULM can noninvasively image capillary-scale microvessels at several centimeters depth and quantitatively measure their blood flow speed (as low as 1 mm/s). Such combination of deep imaging penetration and exquisite spatial resolution and the unique functionality of measuring small vessel blood flow speed make ULM a promising technique for many clinical applications including cancer and cardiovascular diseases. At present, however, ULM is not ready for clinical use due to several key technical limitations: 1) ULM data acquisition is very slow (tens of seconds with breath holding); 2) ULM post-processing is very expensive computationally (several hours to generate a single 2D ULM image); 3) ULM is difficult to be extended to 3D imaging (which is important for comprehensive evaluation of tissue microvasculature such as in cancer applications). These limitations largely forbids ULM from being effectively used in the clinic to provide useful microvascular biomarkers. In this proposal, we will concentrate on addressing these technical barriers and transform ULM to a truly useful clinical imaging tool. Our approach synergistically combines deep learning (DL), parallel computing, and ultrafast 3D ultrasound imaging to fundamentally shorten ULM data acquisition time, substantially accelerate ULM post-processing, and enhance ULM to 3D imaging. Our first aim will develop and validate DL-based ULM data processing algorithms that would enable real-time 4D morphometric ULM and fast 3D quantitative ULM. Our method uniquely collects real labeled optical imaging data on a chicken embryo microvessel model for DL training. Our second aim will focus on realizing 3D-ULM on a 2D row-column-addressing transducer with ultrafast 3D plane wave imaging. We will develop a DL-based beamforming technique to enable high-fidelity 3D microbubble imaging for robust 3D-ULM. Our final aim will focus on validating the in vivo performance of the newly developed 3D-ULM imaging techniques on a mouse tumor model. We will be collaborating with world-renowned experts in deep learning, optical imaging, and comparative medicine at the University of Illinois to accomplish these aims of the proposal. Project Narrative Imaging-based detection and characterization of abnormal tissue microvascular variations is clinically significant for diagnosis, treatment evaluation, and therapy development in many pathologies such as cancer, cardiovascular diseases, inflammation, and neurodegenerative diseases. At present, there is no viable noninvasive imaging tool that can fulfill this important clinical need. To fill this gap, we propose to develop a new ultrasound-based super-resolution microvessel imaging technique that can directly and quantitatively assess the structure and the function of tissue microcirculation in vivo in humans.",Next-Generation Ultrasound Localization Microscopy,10039725,R21EB030072,"['3-Dimensional', '3D ultrasound', '4T1', 'Address', 'Adopted', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Biological Markers', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Breast Carcinoma', 'Cardiovascular Diseases', 'Chickens', 'Clinic', 'Clinical', 'Clinical Treatment', 'Complex', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Evaluation', 'Goals', 'Health', 'Hour', 'Human', 'Illinois', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging Techniques', 'Incentives', 'Inflammation', 'Knowledge', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medicine', 'Metabolic', 'Methods', 'Microbubbles', 'Microcirculation', 'Microscopy', 'Modality', 'Modeling', 'Modification', 'Monitor', 'Morphologic artifacts', 'Mus', 'Neurodegenerative Disorders', 'Noise', 'Nutrient', 'Organ', 'Oxygen', 'Pathogenesis', 'Pathology', 'Patients', 'Penetration', 'Performance', 'Property', 'Provider', 'Resolution', 'Series', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Transducers', 'Transportation', 'Ultrasonic Transducer', 'Ultrasonography', 'Universities', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically relevant', 'clinically significant', 'comparative', 'computerized data processing', 'cost', 'data acquisition', 'deep learning', 'deep neural network', 'hemodynamics', 'imaging detection', 'imaging modality', 'in vivo', 'in vivo imaging', 'innovation', 'instrumentation', 'microCT', 'microscopic imaging', 'next generation', 'non-invasive imaging', 'novel', 'novel therapeutics', 'optical imaging', 'parallel computer', 'performance tests', 'quantitative ultrasound', 'real-time images', 'therapy development', 'tool', 'tumor', 'two photon microscopy']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565346,-0.0422738832496974
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,10241562,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Visualization', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2020,2500,0.004999748394405727
"Fast motion-robust fetal neuroimaging with MRI PROJECT SUMMARY/ABSTRACT Fetal-brain magnetic resonance imaging (MRI) has become an invaluable tool for studying the early development of the brain and can resolve diagnostic ambiguities that may remain after routine ultrasound exams. Unfortunately, high levels of fetal and maternal motion (1) limit fetal MRI to rapid two-dimensional (2D) sequences and frequently introduce dramatic artifacts such as (2) image misorientation relative to the standard sagittal, coronal, axial planes needed for clinical assessment and (3) partial to complete signal loss. These factors lead to the inefficient practice of repeating ~30 s stack-of-slices acquisitions until motion-free images have been obtained. Throughout the session, technologists manually adjust the orientation of scans in response to motion, and about 38% of datasets are typically discarded. Thus, subject motion is the fundamental impediment to reaping the full benefits of MRI for answering clinical and investigational questions in the fetus. The overarching goal of this project is to overcome the challenges posed by motion by exploiting innovations in deep learning, which have enabled image-analysis algorithms with unprecedented speed and reliability. We propose to integrate these into the MRI acquisition pipeline to unlock the potential of fetal MRI. We will develop practical pulse-sequence technology for automated and dynamically motion-corrected fetal neuroimaging without the need for external hardware or calibration. We hypothesize that this will radically improve the quality and success rates of clinical and research studies, while dramatically reducing patient discomfort and cost. We propose as Aim 1 to eradicate (2) the vulnerability of acquisitions to image-brain misorientation with rapid, automated prescription of standard anatomical planes. In Aim 2, we propose to address (3) motion during the scan with real-time correction of fetal-head motion. An anatomical stack-of-slices acquisition will be interleaved with volumetric navigators. These will be used to measure motion as it happens in the scanner and to adaptively update the slice tilt/position. We propose as Aim 3 to develop a 3D radial sequence and estimate motion between subsets of radial spokes for real-time self-navigation. Adaptively updating the orientation of spokes and selectively re-acquiring corrupted subsets at the end of the scan will enable 3D imaging of the fetal brain (1). Since the applicant has a physics background, the proposed training program at MIT and HMS will focus on deep learning and fetal development/neuroscience during the K99 phase to develop the skills needed for transitioning to independence in the R00 phase. The applicant’s goal is to become a fetal image acquisition and analysis scientist acting as bridge between deep learning, MRI and clinical fetal-imaging applications to shift the boundaries of what is currently possible with state-of-the-art technology. Fulfilling the research aims will promote this, as it will result in a practical framework for automation and motion correction, applicable to a wide variety of fetal neuroimaging sequences. PROJECT NARRATIVE Subject motion is the fundamental impediment to reaping the full benefits of fetal-brain magnetic resonance imaging, as it frequently produces images with dramatic artifacts. The goal of this project is to exploit innovations in deep learning and integrate them into the acquisition pipeline to overcome the challenges posed by motion in fetal neuroimaging studies. This will be achieved by using fast, automated scan prescription of standard anatomical planes and by adaptively updating the acquisition as motion happens in the scanner, based on sub-second navigator scans interleaved with the imaging sequence.",Fast motion-robust fetal neuroimaging with MRI,9950474,K99HD101553,"['3-Dimensional', 'Address', 'Algorithmic Analysis', 'Amniotic Fluid', 'Anatomy', 'Automation', 'Brain', 'Brain imaging', 'Calibration', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Data Set', 'Development', 'Diagnostic', 'Echo-Planar Imaging', 'Fetal Development', 'Fetus', 'Geometry', 'Goals', 'Head', 'Image', 'Individual', 'Label', 'Lead', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Masks', 'Measures', 'Morphologic artifacts', 'Motion', 'Neurosciences', 'Patients', 'Phase', 'Physics', 'Physiologic pulse', 'Population', 'Positioning Attribute', 'Radial', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Sampling', 'Scanning', 'Scientist', 'Signal Transduction', 'Slice', 'Speed', 'Technology', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Training Programs', 'Translating', 'Ultrasonography', 'Update', 'Work', 'base', 'clinical investigation', 'convolutional neural network', 'cost', 'deep learning', 'echo detection', 'experience', 'fetal', 'image archival system', 'improved', 'innovation', 'interest', 'neuroimaging', 'novel', 'prospective', 'radiologist', 'reconstruction', 'repaired', 'research study', 'response', 'skills', 'success', 'tool', 'two-dimensional']",NICHD,MASSACHUSETTS GENERAL HOSPITAL,K99,2020,108601,0.023924622558218093
"Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction Nuclear medicine imaging in children has been shown to have significant clinical value across all organ systems. In providing this significant benefit it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that of adults, owing to their higher tissue sensitivity and longer potential lifespan. The governing principle of this project will be to minimize radiation dose while methodically ensuring that lesion detection performance is fully preserved. This will be accomplished by using validations based on both numerical and physician observers measuring performance in tasks that emulate those performed clinically. We will employ two approaches in tandem to enable lowering dose while maintaining performance. First, we will use advanced image reconstruction and processing techniques. Corrections for various forms of image quality degradation will be incorporated in the reconstruction, and deep learning (DL) will be used for post-reconstruction denoising. Second, we will develop methods to correct for both body and respiratory motion, which degrade diagnostic accuracy. Correcting for body and respiratory motion will allow dose to be reduced without loss of image quality and will also offer a technological alternative to using sedation or even general anesthesia to minimize motion when imaging children. For this investigation we have selected 99mTc-labeled dimercaptosuccinic acid (DMSA) renal imaging as a testbed to demonstrate our approaches. Damage to the renal cortex resulting from infection of the kidneys is a critical issue in children, including newborns and toddlers. DMSA SPECT is the “gold-standard” in the evaluation of pyelonephritis and renal scarring post- infection. The concepts we will demonstrate for reduction of radiation dose and correction of motion with DMSA will be translatable to other SPECT (and PET) studies in pediatric imaging and beyond.  Our Specific Aims are: 1. Establish infrastructure for investigating and evaluating advanced reconstruction and motion correction; 2. Determine the extent of radiation dose reduction to pediatric patients through improved reconstruction and DL denoising while maintaining optimal full-dose lesion detection accuracy; 3. Develop data-driven and depth-sensing camera methods for body and respiratory motion estimation and correction; and 4. Conduct numerical and physician observer studies to validate the level of dose reduction enabled by DL denoising and motion correction. Narrative  In nuclear medicine imaging, it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that in adults, owing to their higher tissue sensitivity and longer potential lifespan. Correcting for body and respiratory motion occurring during imaging will improve the quality of the formed three-dimensional images of the patient by reducing blurring and image artifacts and offer a technological alternative to using sedation or even general anesthesia to reduce motion when imaging children, which can bear health risks of its own. We propose an advanced reconstruction methodology which would enable reduction in the amount of activity administered and compensate for patient motion during imaging.",Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction,9914572,R01EB029315,"['3-Dimensional', 'Adult', 'Algorithms', 'American', 'Area', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'DMSA', 'Data', 'Databases', 'Detection', 'Development', 'Discipline of Nuclear Medicine', 'Dose', 'Enhancing Lesion', 'Ensure', 'European', 'Evaluation', 'Freedom', 'Gaussian model', 'General Anesthesia', 'Gold', 'Guidelines', 'Health', 'Hybrids', 'Image', 'Imaging problem', 'Infection', 'Infrastructure', 'Investigation', 'Kidney', 'Label', 'Lesion', 'Longevity', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Morphologic artifacts', 'Motion', 'Newborn Infant', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Pyelonephritis', 'ROC Curve', 'Radiation Dose Unit', 'Respiration', 'Risk', 'Scheme', 'Sedation procedure', 'Societies', 'Statistical Study', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Tissues', 'Toddler', 'Ursidae Family', 'Validation', 'base', 'body system', 'cardiac single photon emission computed tomography', 'clinically significant', 'deep learning', 'denoising', 'denoising deep learning', 'diagnostic accuracy', 'image processing', 'image reconstruction', 'improved', 'innovation', 'kidney cortex', 'kidney infection', 'molecular imaging', 'pediatric patients', 'preservation', 'reconstruction', 'renal scarring', 'respiratory', 'response', 'single photon emission computed tomography']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,773763,0.015238949401607811
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10011054,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2020,1159612,0.016420818792651802
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9910382,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2020,510157,0.02022255949284849
"ClearScope Combined in vivo and ex vivo three-dimensional (3D) whole-brain imaging of non-transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole-brain datasets, the best approach is brain clearing followed by whole-brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole-brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo-bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide-spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state-of-the-art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,10019728,R44MH116827,"['3-Dimensional', 'Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Confocal Microscopy', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Human', 'Image', 'Immersion', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'multiphoton microscopy', 'neural network', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,1313060,0.009793425068072186
"Development of advanced cardiac SPECT imaging technologies Project Abstract Single Photon Emission Computed Tomography (SPECT) continues to play a critical role in the diagnosis and management of coronary artery disease (CAD). While conventional SPECT scanners using parallel-hole collimators are still the foundation of cardiac SPECT, recently our field observed an exciting growth of new developments of dedicated cardiac scanners. Such dedicated scanners, such as the GE Alcyone 530/570c systems and the D-SPECT systems both with CZT detectors, typically have multiple detectors collecting photons emitted from the heart simultaneously, leading to dramatically improved sensitivity (2-5 X). In addition, the GE systems use pinhole collimators and can achieve much higher resolution. These dedicated scanners opened doors to new applications with significant clinical impact, including ultra-low-dose imaging, absolute quantification of myocardial blood flow (MBF) and coronary flow reserve (CFR), high resolution molecular imaging, multi-isotope imaging, motion correction, and many more. Most of these new applications are uniquely achievable only using dedicated scanners. While the dedicated cardiac SPECT systems can improve clinical practice and lead to numerous new clinical applications, such systems are far from being optimized to fully realize their great potentials. In this grant, we propose to systematically develop and optimize innovative imaging technologies for the GE 530/570c systems to further improve its clinical efficacy in a variety of significant ways. In Aim 1, we will develop and optimize methods for static cardiac SPECT imaging. We will develop various deep learning methods and investigate approaches to increase angular sampling to reduce noise, and improve resolution and quantitative accuracy. In Aim 2, we will develop and validate methods for dynamic SPECT imaging, particularly involving direct parametric image reconstruction. In Aim 3, we will develop and validate methods for dual-isotope SPECT. Monte Carso simulation and deep learning based methods will be developed for tracers with different spatial distributions and fast kinetics. In all three aims, large animal studies and human subject data will be used for optimization and validation. Narrative The success of imaging technology developments proposed in this grant will substantially improve the image quality, reduce patient dose, expand the applications of cardiac SPECT from mainly static imaging to dynamic imaging, and establish multi-isotope clinical imaging.",Development of advanced cardiac SPECT imaging technologies,10064473,R01HL154345,"['Address', 'Advanced Development', 'Algorithms', 'Amyloidosis', 'Anatomy', 'Animals', 'Blood flow', 'Cardiac', 'Charge', 'Clinical', 'Collimator', 'Computed Tomography Scanners', 'Coronary', 'Coronary Arteriosclerosis', 'DCNU', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dose', 'Event', 'Foundations', 'Gold', 'Grant', 'Heart', 'Human', 'Hybrids', 'Image', 'Imaging technology', 'Infarction', 'Isotopes', 'Kidney', 'Kinetics', 'Lead', 'Maps', 'Methods', 'Microspheres', 'Molecular Target', 'Monte Carlo Method', 'Motion', 'Myocardial', 'Myopathy', 'Noise', 'Patients', 'Perfusion', 'Photons', 'Play', 'Positioning Attribute', 'Positron-Emission Tomography', 'Radiation Dose Unit', 'Resolution', 'Role', 'Sampling', 'Spatial Distribution', 'Study Subject', 'System', 'Tail', 'Toxic effect', 'Tracer', 'Training', 'Validation', 'animal data', 'attenuation', 'base', 'cardiac single photon emission computed tomography', 'clinical application', 'clinical efficacy', 'clinical imaging', 'clinical practice', 'contrast enhanced', 'convolutional neural network', 'deep learning', 'detector', 'human subject', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'new growth', 'parametric imaging', 'prospective', 'reconstruction', 'respiratory', 'simulation', 'single photon emission computed tomography', 'success', 'technology development']",NHLBI,YALE UNIVERSITY,R01,2020,806926,0.0202558109880488
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9823881,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2020,401916,0.020958841551139588
"Osteoarthritis: Quantitative Evaluation of Whole Joint Disease with MRI Project Summary Osteoarthritis (OA) is an enormous clinical problem and worldwide cause of disability. Development of new therapies for OA is hampered by a lack of sensitive imaging tests that respond to changes in disease status. Recently FDA and CE approved clinical knee 7T MRI has the potential to add sensitivity and specificity to advanced MRI biomarkers of OA progression. This project will compare changes seen at 3T and 7T across two different vendors systems and assess the potential for 7T MRI to improve our ability to study and develop new disease- modifying therapies. This study will enhance future studies and clinical exams at 7T and can be used to improve routine 3T MRI though machine learning reconstruction and enhanced understanding of OA disease mechanisms. Understanding the relative strengths of 3T and 7T MRI in this important clinical application is critical to developing new disease-modifying treatments for patients with OA. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for development of disease-modifying treatments. This work aims to develop novel 3D imaging approaches using 3T and 7T magnetic resonance imaging (MRI), to quantitatively assess joint health across different tissues in osteoarthritis.",Osteoarthritis: Quantitative Evaluation of Whole Joint Disease with MRI,10071340,R01EB002524,"['Address', 'Affect', 'Biochemical', 'Biomechanics', 'Cartilage', 'Chemicals', 'Clinical', 'Degenerative polyarthritis', 'Detection', 'Development', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Disease', 'Ensure', 'Environment', 'Evaluation', 'Extracellular Matrix', 'Funding', 'Future', 'GAG Gene', 'Health', 'Human', 'Hydroxyl Radical', 'Image', 'Imaging Techniques', 'Imaging technology', 'Joints', 'Knee', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meniscus structure of joint', 'Methodology', 'Methods', 'Morphology', 'Musculoskeletal', 'Orthopedics', 'Patients', 'Pharmacologic Substance', 'Population', 'Proteoglycan', 'Quality of life', 'Quantitative Evaluations', 'Replacement Arthroplasty', 'Research', 'Resolution', 'Roentgen Rays', 'Scanning', 'Sensitivity and Specificity', 'Site', 'Specificity', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Treatment Efficacy', 'Vendor', 'Work', 'arthropathies', 'clinical application', 'clinical examination', 'clinical imaging', 'clinically significant', 'cost', 'design', 'disability', 'efficacy trial', 'imaging approach', 'imaging detection', 'imaging modality', 'imaging system', 'improved', 'innovation', 'magnetic resonance imaging biomarker', 'mechanical properties', 'molecular marker', 'novel', 'novel therapeutics', 'patient population', 'quantitative imaging', 'rapid technique', 'reconstruction', 'soft tissue', 'tool', 'treatment strategy']",NIBIB,STANFORD UNIVERSITY,R01,2020,612595,-0.0015742430242736056
"Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research PROJECT SUMMARY/ABSTRACT This proposal represents a vertical advancement in neighborhood effects research, producing for the first time, national neighborhood indicators of the built environment. Thus far, only local studies have been conducted due to the resource-intensive nature of site visits to conduct assessments of community features and also manual annotations of street images. With the recent advancement of computer vision and the emergence of massive sources of image data, we will leverage our team’s abilities to develop a data collection strategy utilizing geographic information systems to assemble a national collection of Google Street View images of all road intersections and street segments in the United States. We will utilize this data bank, and develop informatics algorithms to produce neighborhood summaries of built environment that have been theoretically and empirically identified to be important for health outcomes. After the creation of Neighborhood Looking Glass, we will conduct investigations into the impact of neighborhood environments on health utilizing medical records from hundreds of thousands of patients and accounting for predisposing characteristics in analyses. Our investigative team—comprised of experts in the field of epidemiology, computer vision, bioinformatics, and computer science—is uniquely suited to implement the study aims. Our Specific Aims are: 1) Develop informatics techniques to produce neighborhood quality indicators; 2) Measure the accuracy of data algorithms and construct an interactive geoportal for neighborhood data visualization and data sharing, 3) Utilize Neighborhood Looking Glass and a large collection of medical records from Intermountain Healthcare to investigate neighborhood influences on the risk of obesity and substance abuse. The epidemic rise in chronic health conditions is recent and as such suggests its cause is social, cultural, and constructed rather than purely biological. Thus, we have the possibility of intervening on the environment to better support health. Recent studies suggest that the current cohort of young adults may face historically high cardiovascular disease risk and chronic disease burden. Our substantive investigation of the impact of neighborhood factors on chronic conditions will contribute further to the understanding of contextual influences on the health of this cohort at the forefront of a chronic disease epidemic. Moreover, the dramatic rise in overdoses, accidental poisonings, and mental health issues contributing to premature mortality warrants further investigation into risk-inducing environmental factors for substance abuse. Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics. Results can be utilized to inform population-based strategies to reduce health disparities and improve health. Project Narrative/Relevance to Public Health The epidemic rise in obesity, related chronic diseases, and substance abuse in recent decades signal the importance of structural forces and social processes, but the dearth of data on contextual factors limits the investigation of multilevel effects on health. The development of the Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics with potential impact on health. Results from our project can be utilized to inform system-wide and local strategies to improve community health.",Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research,9979947,R01LM012849,"['Accounting', 'Alcohol or Other Drugs use', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Chronic', 'Chronic Disease', 'Cities', 'Collection', 'Communities', 'Community Health', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Collection', 'Data Sources', 'Development', 'Disease', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Family', 'Food', 'Food Access', 'Geographic Information Systems', 'Geography', 'Glass', 'Grant', 'Happiness', 'Health', 'Health Food', 'Health Personnel', 'Health behavior', 'Health care facility', 'Healthcare', 'Image', 'Individual', 'Informatics', 'Investigation', 'Label', 'Literature', 'Manuals', 'Measures', 'Medical Records', 'Mental Health', 'Methods', 'Nature', 'Neighborhoods', 'Obesity', 'Outcome', 'Overdose', 'Patients', 'Physical activity', 'Physical environment', 'Premature Mortality', 'Process', 'Public Health', 'Quality Indicator', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Signal Transduction', 'Site Visit', 'Social Environment', 'Social Processes', 'Source', 'Structure', 'Substance abuse problem', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Visit', 'built environment', 'burden of illness', 'cardiovascular disorder risk', 'cohort', 'computer science', 'contextual factors', 'convolutional neural network', 'cost', 'crowdsourcing', 'data management', 'data mining', 'data resource', 'data sharing', 'data visualization', 'data warehouse', 'density', 'health care availability', 'health disparity', 'improved', 'land use', 'obesity risk', 'object recognition', 'physical conditioning', 'population based', 'social', 'social media', 'walkability', 'young adult']",NLM,"UNIV OF MARYLAND, COLLEGE PARK",R01,2020,329703,-0.008113509730077538
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,9885175,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Body mass index', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Individual', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2020,590183,0.013519094534140123
"Opera Phenix High-Content Imaging System for Drug Discovery PROJECT SUMMARY The University of Pittsburgh Drug Discovery Institute (UPDDI) is requesting funds to purchase the Perkin Elmer OPERA PHENIX high speed, high resolution spinning disk confocal High-Content Screening (HCS) device. The Opera Phenix will replace two Molecular Devices ImageXpress Ultra high content readers purchased in 2008, which are critical to multiple NIH-, DoD-, and Foundation-funded projects at the University of Pittsburgh, but are no longer supported by the manufacturer and have been decommissioned. We have determined that one Opera Phenix instrument can replace the two IXUs. The Phenix is a third generation HCS instrument that will be essential to satisfy the diverse needs of users that the UPDDI serves. No comparable instruments exist at the University of Pittsburgh, the University of Pittsburgh Medical Center, and Carnegie Mellon University. Over the last decade, HCS has become a standard in the pharmaceutical industry for target identification, phenotypic screening, as well as toxicology, and in academia for large-scale biological studies, where cell-by- cell quantitation is critical. The UPDDI has been an academic pioneer in the application of HCS and serves an extensive number of collaborators across campus that require and rely on HCS, ranging from neurodegeneration, organ regeneration, cancer, liver diseases, organotypic model development, and traumatic brain injury. Our diverse user groups’ needs emphasize discovery models of physiological relevance and high complexity, and therefore require fast, high resolution 2D, 3D, and kinetic imaging and maximum flexibility in image analysis. The large number of HCS users working in the UPDDI further demands a fast system to permit effective sharing of instrument time, and an integrated database with off-site user access to perform off- line analysis. Key requirements for an HCS imager therefore are superior speed in acquiring z-series of images at high resolution of thick specimens in aqueous matrices, mature yet flexible image algorithms, and seamless integration of instrument software with system, public,and custom-developed UPDDI databases. The only instrument that meets all of these criteria is the Opera Phenix because it has 1) fast laser-based illumination and the ability to acquire multiple channels simultaneously 2) water immersion objectives that eliminate non-matching refractive indices, which limit spherical aberrations of air and oil objectives at longer working distances and require adjustment of correction collars depending on imaging depth; 3) a powerful suite of user-friendly yet flexible image analysis routines including a 3D module, advanced texture and morphology analysis, and intuitive and user-friendly machine learning; and 4) the ability to perform seamless “adaptive high-resolution imaging”, i.e., pre-scanning a large area at low magnification, followed by automated “on-the- fly” switching to higher magnification to acquire high resolution images of user-defined regions of interest. The Opera Phenix is the only instrument on the market that is capable of fulfilling the demands of the University of Pittsburgh’s diverse drug discovery community. PROJECT NARRATIVE Modern drug discovery increasingly demands better and more disease relevant models and the ability to analyze them. High-content screening (HCS) has become indispensable in the analysis of such models as it permits the analysis of cells, their constituents, and interactions in their proper biological context. The third generation HCS instrument, Opera Phenix, produces the quality and quantity of data from cells, tissues and experimental animals that are required for computational and systems biological investigations, while at the same time providing the throughput needed for automated screening.",Opera Phenix High-Content Imaging System for Drug Discovery,9935240,S10OD028450,"['3-Dimensional', 'Academia', 'Air', 'Algorithms', 'Area', 'Biological', 'Cells', 'Communities', 'Computer software', 'Custom', 'Databases', 'Devices', 'Drug Industry', 'Foundations', 'Funding', 'Generations', 'Image', 'Image Analysis', 'Immersion', 'Institutes', 'Intuition', 'Kinetics', 'Lasers', 'Lighting', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical center', 'Molecular', 'Morphology', 'Nerve Degeneration', 'Oils', 'Phenotype', 'Reader', 'Refractive Indices', 'Resolution', 'Scanning', 'Series', 'Site', 'Specimen', 'Speed', 'System', 'Texture', 'Thick', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Universities', 'Water', 'aqueous', 'base', 'drug discovery', 'flexibility', 'high resolution imaging', 'imager', 'imaging system', 'instrument', 'interest', 'model development', 'organ regeneration', 'physiologic model', 'screening', 'user-friendly']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2020,1010594,-0.005378822108795551
"NICHD Microscopy and Imaging Core Facility COVID pandemic  Like most research units on campus, the MIC was severely impacted by COVID-19. The facility was deemed a non-essential unit and was shut down from March 9 to June 22, 2020. The MIC then operated under phase A re-opening guidelines with a 2-user limit from June 22 until July 19, 2020. As of this writing we are still under phase B reopening with a 4-user limit. With severe limitations on personal interactions to reduce the risks of exposure, hands-on training and in-person support has been curtailed since the start of the pandemic. For the same reason, the yearly MIC-organized workshop on microscopy was cancelled in 2020. The staff was involved in the BIOC35 (ex-FAES35) microscopy course that happened online. Likewise, there was no on-site equipment demonstration after March 2020. Although the staff made maximum use of teleworking, the scientific output of the MIC was understandably reduced compared to 2019.    Light microscopy  The MIC is equipped with six confocal microscopes, each optimized for certain applications: 1) A Zeiss LSM 710 inverted for high-resolution confocal imaging. 2) A Zeiss LSM 780 with a spectral detector 3) A Nikon Spinning Disk / Total Internal Reflection Fluorescence (TIRF) hybrid microscope for high-speed confocal imaging or recording of membrane-bound events in live cells (TIRF). 4) A Zeiss LSM 880 2-photon confocal for thick tissues and live animals. 5) A Zeiss 800 optimized for advanced tiling experiments and, 6) A Zeiss 880 AiryScan with higher spatial resolution.  Several conventional (wide-field) light microscopes provides imaging modalities such as transmission (visible stains), large-scale tiling of tissue slices, high-speed phase contrast and DIC, and large specimens. High-end computer workstations with imaging software (Zeiss Zen, Nikon Element, Bitplane Imaris, SVI Hyugens and ImageJ) are also available.  After an initial orientation where their project is researched by the staff and the best approach is decided upon, users receives hands-on training on the equipment and / or software best suited to their goals, followed by continuous support when required. Once image acquisition is complete, the staff devise solutions and train users on how to extract usable data from their images.   Image processing based on neural-networks (Artificial Intelligence or AI) is fast becoming a very powerful tool for image restoration, segmentation and resolution improvement. The MIC has been actively looking at AI-powered solutions for image restoration and segmentation. The Nikon NIS-AI suite, an advanced software for noise removal and segmentation not possible with conventional methods, was purchased and is now available in the core.   Electron microscopy  The electron microscopy branch of the facility processes specimens from start to finish: fixation, embedding, semi-thin and ultra-thin sectioning, staining and imaging on the JEOL 1400 transmission electron microscope. Because of the labor involved, the volume is necessarily smaller than the light microscopy branch where end users do their own processing. In the past 12 months, Mr. Dye processed a total of 145 samples for morphology studies.  Tissue preparation  Mrs. Holtzclaw provided sample processing training and services for light and electron microscopy. 13 users were trained in-person in rodent perfusion, cryopreservation, cryosectioning, immunofluorescence and tissue clearing. With the assistance of Mrs. Felsen, Mrs. Holtzclaw also dedicated a significant amount of time to bring RNAScope methodologies to the Core, allowing users to conduct investigations in the histology suite. NICHD users include Drs. Balla, Basser, Bezrukov, Buonanno, Chernomordik, Crouch, Fields, Hoffman, Klein, Le Pichon, McBain, Pfeifer, Porter, Sackett, Shi, Stojilkovic and Stopfer. She also provided assisted the laboratories of Drs. Holmgren, Roche, Youle and Ward (NINDS); Plenz (NIMH) and Sidransky (NHGRI).  A collaboration with the laboratory of Dr. Richard Youle to study the accumulation of ubiquitinated protein aggregates in brain and liver of a TAX1BP1 knock-out mouse was completed. A developmental rat pineal study, in collaboration with Dr. David Klein, was initiated with plans to probe samples using the RNAScope methodology.  Mrs. Holtzclaw is also working with the McBain Lab to ascertain, via RNAscope , the expression of a potassium channel subunit in human PV interneurons.   Publications  Since its inception in 2004, the work carried out in the MIC has been included in more than 200 publications. For a complete list, head to: https://science.nichd.nih.gov/confluence/display/mic/Publications n/a",NICHD Microscopy and Imaging Core Facility,10266647,ZICHD008874,"['Animals', 'Area', 'Artificial Intelligence', 'Brain', 'COVID-19', 'Calendar', 'Cells', 'Charge', 'Collaborations', 'Communities', 'Computer Workstations', 'Computer software', 'Core Facility', 'Cryopreservation', 'Cryoultramicrotomy', 'Data', 'Development', 'Dyes', 'Educational workshop', 'Electron Microscope', 'Electron Microscopy', 'Elements', 'Environment', 'Equipment', 'Event', 'Excision', 'Floor', 'Fluorescence', 'Goals', 'Guidelines', 'Head', 'Histology', 'Hour', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Device', 'Immunofluorescence Immunologic', 'Institutes', 'Interneurons', 'Investigation', 'Knockout Mice', 'LIF gene', 'Laboratories', 'Light Microscope', 'Liver', 'Membrane', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Microtomy', 'Mission', 'Morphology', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'Noise', 'Output', 'Perfusion', 'Persons', 'Phase', 'Potassium Channel', 'Preparation', 'Process', 'Publications', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Resource Sharing', 'Resources', 'Risk', 'Rodent', 'Sampling', 'Science', 'Services', 'Site', 'Slice', 'Specimen', 'Speed', 'Stains', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Transmission Electron Microscopy', 'Work', 'Writing', 'base', 'confocal imaging', 'coronavirus disease', 'detector', 'experimental study', 'high end computer', 'image processing', 'imaging facilities', 'imaging modality', 'imaging software', 'light microscopy', 'microscopic imaging', 'neural network', 'pandemic disease', 'protein aggregation', 'restoration', 'sample fixation', 'telework', 'tissue preparation', 'transmission process', 'two-photon', 'ward']",NICHD,EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT,ZIC,2020,1306241,-0.01271540212443277
"8th International CEST workshop (CEST2020) Project Summary/Abstract The 8th International Workshop of chemical exchange saturation transfer (CEST) MRI in November 2020 (CEST2020) brings together an international community of experts in CEST imaging. CEST MRI has gained tremendous interest from the research community, and many leading institutions have joined forces to optimize CEST MRI and develop new applications in a host of diseases including acute stroke, epilepsy, and, most importantly, tumor imaging. Recently, machine learning and neuron networks have been explored for CEST imaging. The CEST 2020 forges research and learning opportunities for students and young researchers in a dedicated forum unmatched by other meetings. CEST 2020 is being organized by Phillip Zhe Sun, Ph.D. (Emory University), in conjunction with the CEST Workshop steering committee of well- established scholars in the CEST MRI field. It will run November 8-11, 2020, at the Emory Conference Center Hotel located on the Emory University campus in Atlanta, Georgia. The goal is to bring together researchers from varying backgrounds and clinicians from related disciplines and to provide a forum for communication among these multi-disciplinary groups. The workshop will feature a blend of plenary sessions, invited scientific presentations, manuscripts, poster presentations, and panel discussions. The meeting will provide all participants the opportunity to present and learn emerging applications of CEST imaging. Emory University researchers have contributed to the development of the CEST MRI field, from the theory, experimental optimization, and quantification. Members well established in the CEST MRI field including Dr. Peter van Zijl, Dr. Dean Sherry, Dr. John Gore, Dr. Marty Pagel, and Dr. Reddy Ravinder, will attend and present their work. This creates an outstanding intellectual enrichment opportunity not just for well-established investigators but also for students, postdocs and junior faculty as they enter into this exciting field of MRI research. The primary goal is to create opportunities and offer supportive mentoring at this formative stage in the trainee's career to enhance their research potential and the likelihood of success. We will have two plenary sessions, two poster sessions, and two power pitch sessions, in which the goal is to share the state of the art CEST research and engage newcomers to the field. Also, we will select 3-4 oral presentations for each scientific session from submitted abstracts to promote the rising stars in the field and provide our feedback on their work, strength, and, most importantly, areas to improve. This grant will support students, postdocs and junior faculty to participate in the CEST2020 Workshop. Project Narrative The 8th Biennial International CEST workshop (CEST 2020) will focus on the technical development of CEST imaging and clinical applications in a broad spectrum of diseases. The goal is to bring together MRI researchers from varying backgrounds and clinicians from related disciplines, educate newcomers to the CEST MRI field, and provide a forum for communication among these multi-disciplinary groups. The CEST workshop is the only conference that is held for this particular area of Imaging Science.",8th International CEST workshop (CEST2020),10070772,R13EB030424,"['Area', 'Brain Neoplasms', 'Chemicals', 'Clinic', 'Communication', 'Communities', 'Contrast Media', 'Development', 'Diagnosis', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Epilepsy', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Growth', 'Image', 'Image Analysis', 'Imaging technology', 'Institution', 'International', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuscripts', 'Mathematics', 'Mentors', 'Myocardial Infarction', 'Neurologist', 'Neurons', 'Oncologist', 'Oral', 'Participant', 'Patients', 'Physicians', 'Physics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Running', 'Science', 'Students', 'The Sun', 'Universities', 'Work', 'acute stroke', 'cancer imaging', 'career', 'clinical Diagnosis', 'clinical application', 'computerized data processing', 'experience', 'field theory', 'image processing', 'improved', 'in vivo evaluation', 'interest', 'meetings', 'member', 'multidisciplinary', 'posters', 'pre-clinical research', 'signal processing', 'success', 'symposium', 'theories', 'ward']",NIBIB,EMORY UNIVERSITY,R13,2020,10000,-0.019401189745896365
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,9855767,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2020,1835520,0.020937293699518817
"Generation of parametric images for FDG PET using dual-time-point scans Project Summary/Abstract Positron emission tomography combined with computed tomography (PET/CT) using the radiolabeled tracer 2- deoxy-2-(18F)fluoro-D-glucose (FDG) has become a standard imaging tool for cancer patient management. The semi-quantitative parameter standardized uptake value (SUV) is routinely used in clinical for tumor uptake quantification, which is computed on the static PET image acquired at a certain time (typically 60 min) post tracer injection for a short interval (typically 5-15 min). However, the quantification accuracy of SUV from a single PET scan suffers from the variabilities of tracer plasma clearance and acquisition start time. The dual- time-point FDG PET imaging has been intensively investigated and used in both clinical and research studies, typically one scan at 60 min and the other at 120 min, showing the potential to enhance the diagnostic accuracy of FDG PET by differentiating malignancy from inflammation and normal tissue. However, the current clinical dual-time-point FDG PET studies use the relative SUV change between two scans as the quantification index, which cannot eliminate the variations in tracer plasma clearance. Meanwhile, the dual-time-point protocol has not been optimized and standardized currently, leading to conflicting results. The fully-quantitative parameter, tracer net uptake rate constant Ki, is the most accurate parameter to quantify FDG PET, which is calculated using dynamic imaging with compartmental modeling. Ki is independent on the plasma clearance or acquisition start time. However, the long and complex acquisition protocol (typically at least 60 min), which requires dynamic scanning and sequential arterial blood sampling (or image-derived blood activity) used as input function from the time of injection, limits its application in clinical practice. Meanwhile, generation of the parametric Ki image, which can provide additional heterogeneity information for FDG PET, is challenging clinically using voxel-by-voxel compartmental modeling due to the computational cost and being sensitive to noise using non-linear least squares. The graphical Patlak plot, can be used for simplified Ki calculation and Ki image generation by voxel-by-voxel fitting. However, it still needs dynamic scanning starting from 15-30 min after injection and input function from the time of injection. The aims of this proposal are 1) to optimize the dual-time-point protocol for accurate Ki quantification using Patlak plot without the need for individual patient's input function, and 2) to generate high-quality low-noise dual-time-point Ki images using novel techniques based on deep learning. Upon the success of this project, our proposed approach can obtain reliable tumor Ki quantification and parametric Ki image ""for free"" without adding any additional complexity on the existing dual- time-point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology. We expect the translation of this approach to clinical investigation to be fast, as this is a post-processing approach and is based on data already acquired using clinically used protocol without imposing additional burden to technologists. Project Narrative For FDG PET imaging, we propose to develop a novel and simple approach of quantifying tumor Ki and generating parametric Ki image ""for free"" without adding any additional complexity on the existing dual-time- point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology.",Generation of parametric images for FDG PET using dual-time-point scans,9896329,R03EB027864,"['Blood', 'Blood specimen', 'Cancer Patient', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Generations', 'Glucose', 'Heterogeneity', 'Image', 'Imaging Device', 'Inflammation', 'Injections', 'Label', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Noise', 'Normal tissue morphology', 'Oncology', 'Patients', 'Plasma', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation exposure', 'Radiolabeled', 'Scanning', 'Standardization', 'Techniques', 'Time', 'Tracer', 'Training', 'Translations', 'Variant', 'X-Ray Computed Tomography', 'attenuation', 'base', 'clinical investigation', 'clinical practice', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'diagnostic accuracy', 'image reconstruction', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'parametric imaging', 'population based', 'research study', 'simulation', 'success', 'tumor', 'uptake']",NIBIB,YALE UNIVERSITY,R03,2020,80375,0.0017459179644341094
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9843490,R01CA193730,"['3-Dimensional', 'Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation Dose Unit', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'primary endpoint', 'public health relevance', 'quality assurance', 'radiation delivery', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2020,354198,-0.010717456739707604
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,10019348,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2020,314388,-0.010916534529304085
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10023935,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2020,256578,0.002067356577915763
"In vivo Macroscopic Fluorescence Lifetime Molecular Optical Imaging In vivo Macroscopic Fluorescence Lifetime Molecular Optical Imaging ABSTRACT There is still great need in better characterizing new targeted therapies in vivo, especially prior to clinical translation. In this regard, preclinical molecular imaging is a central tool in the targeted drug development pipeline. However, there is still a lack of integrated imaging platforms that can enable longitudinal (multiple time points) and spatially-resolved monitoring of complex fingerprints including molecular, metabolic and functional signatures in the same tumor/subject. This new integrated multiplexing imaging platform will play a crucial role in the development of the next generation of targeted drugs and elucidating (multi-) drug resistance mechanisms. Recently, we have demonstrated the unique capabilities of optical imaging in quantifying receptor-target engagement in live subjects by leveraging fluorescence lifetime. This outstanding achievement was realized thanks to the combination of instrumental, algorithmic and biochemical innovations to enable, for the first time, whole-body time-resolved optical imaging based on structured light for 2D or 3D Förster resonance energy transfer (FRET) imaging in live subjects. Herein, we will further impact the field of optical preclinical imaging and drug delivery assessment by 1) integrating a cutting-edge high-resolution, time-resolved SPAD array imager for improved photon collection efficiency, spatial resolution, and portability; 2) we will harness the latest developments in Deep Learning (DL) for ultra-fast, quantitative, but fitting/iterative inverse solver-free image formation, in both 2D and 3D providing image formation/processing solutions to facilitate multiplexed imaging; 3) we will implement new functionalities in our imaging platform to enable the concurrent longitudinal imaging of multiple clinically relevant target-receptor interactions (e.g. HER receptor family members involved in many cancers) as well as metabolic and functional status across the whole-tumor region in live intact animals. NARRATIVE Following an ever increased focus on personalized medicine, there is a continuing need to develop preclinical molecular imaging modalities to guide the development and optimization of targeted therapies. This research program will combine novel time-resolved cameras as well as deep learning techniques to broaden the impact of macroscopic lifetime imaging with the overarching goal to facilitate multiplexed imaging for a comprehensive assessment of cellular delivery efficacy of multiple clinically relevant drugs (e.g. HER receptor family members involved in many cancers) as well as drug response via metabolic and functional status across the whole-tumor region in live intact animals.",In vivo Macroscopic Fluorescence Lifetime Molecular Optical Imaging,9997447,R01CA250636,"['3-Dimensional', 'Achievement', 'Algorithms', 'Animals', 'Biochemical', 'Biological', 'Biological Assay', 'Blood Vessels', 'Cancer Biology', 'Cells', 'Collection', 'Complex', 'Data', 'Detection', 'Development', 'Drug Delivery Systems', 'Drug Targeting', 'ERBB2 gene', 'Electronics', 'Epidermal Growth Factor Receptor', 'Family member', 'Fingerprint', 'Fluorescence', 'Fluorescence Microscopy', 'Fluorescence Resonance Energy Transfer', 'Foundations', 'Functional Imaging', 'Goals', 'Hemoglobin', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging ligands', 'Immunohistochemistry', 'Light', 'Longitudinal Studies', 'Malignant Neoplasms', 'Mammary Neoplasms', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Molecular', 'Molecular Probes', 'Molecular Target', 'Monitor', 'Multi-Drug Resistance', 'Optical Tomography', 'Optics', 'Oxygen', 'Penetration', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physiological', 'Play', 'Reporter Genes', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Side', 'Signal Transduction', 'Structure', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'base', 'bioimaging', 'clinical translation', 'clinically relevant', 'cost effective', 'deep learning', 'design', 'detector', 'drug development', 'drug efficacy', 'fluorescence lifetime imaging', 'functional status', 'imager', 'imaging agent', 'imaging modality', 'imaging platform', 'imaging study', 'improved', 'in vivo', 'innovation', 'metabolic imaging', 'molecular imaging', 'multiplexed imaging', 'new technology', 'new therapeutic target', 'next generation', 'novel', 'optical imaging', 'personalized medicine', 'portability', 'pre-clinical', 'preclinical imaging', 'preclinical study', 'programs', 'quantitative imaging', 'receptor', 'resistance mechanism', 'response', 'serial imaging', 'targeted treatment', 'technological innovation', 'tomography', 'tool', 'treatment response', 'tumor', 'tumor xenograft', 'user-friendly']",NCI,RENSSELAER POLYTECHNIC INSTITUTE,R01,2020,637634,-0.006418498056550907
"Gadolinium Free Cardiac MR Imaging of Scar and Fibrosis Cardiovascular disease continues to be the leading cause of morbidity and mortality in the United States. Magnetic resonance imaging (MRI) of scarred or fibrotic heart tissue plays a major diagnostic and prognostic role in patients with coronary heart disease (CHD) or non-ischemic cardiomyopathy (NICM). Cardiac MRI is a non-invasive, multifaceted imaging modality and is the clinical gold standard for scar and fibrotic cardiac tissue imaging with use of gadolinium-based contrast injection. However, administration of such gadolinium-based contrast agents (GBCA) prolongs the scan time, increases scan cost, and is contra-indicated in patients with impaired kidney function? a highly prevalent comorbidity in CHD patients. Until recently, GBCA was presumed to be safe in patients with normal kidney function; however, there are emerging data on long-term GBCA retention in the body. We aim to develop two complimentary approaches to reduce GBCA use in myocardial, or cardiac muscle, scar imaging. Initially, we will develop a quantitative risk-benefit model to identify NICM patients with a low chance of having scarred myocardium. Concurrently, we will develop a GBCA-free cardiac MR myocardial tissue probe platform based on AI (MyoProbe.ai) to quantify scarred regions of the heart. To accomplish this, we will develop and evaluate an individualized, patient-specific scar prediction model to reduce GBCA use in NICM patients with different etiologies by training the model to learn to identify whether the patient is likely to have scarring based on non-contrast images. If it is unlikely that a patient has scarring, contrast administration can be avoided. To develop and evaluate MyoProbe.ai for GBCA-free quantification of myocardial scar in CHD patients, we will use AI to integrate signal intensity and heart motion data from MRI images to accurately locate and quantify scar tissue. This information can then be used by cardiologists to diagnose and treat the patient. We will rigorously validate our risk-benefit model and AI myocardial probe platform using retrospectively and prospectively collected cardiac MRI images from multiple healthcare centers, MRI vendors, and magnetic field strengths. Our dataset will include different types of NICM and CHD patient populations to ensure that our work is applicable to patients with many different types of NICM and CHD. Cardiac magnetic resonance imaging (MRI) of scarred/fibrotic heart tissue with gadolinium- based contrast agents (GBCA) plays a major diagnostic and prognostic role in patients with coronary heart disease (CHD) or non-ischemic cardiomyopathy (NICM). However, administration of GBCAs prolongs the scan time, increases scan cost, contaminates surface and drinking water, is retained in the body long-term, and is contra-indicated in patients with impaired renal function– a highly prevalent comorbidity in CHD patients. The goal of our study is to reduce or eliminate GBCA use in cardiac MR scar imaging using artificial intelligence (AI) by concurrently developing a quantitative model to identify NICM patients with a low likelihood of scarring and a GBCA-free cardiac MR AI platform to quantify scar tissue.",Gadolinium Free Cardiac MR Imaging of Scar and Fibrosis,10072898,R01HL154744,"['Adopted', 'Algorithms', 'Artificial Intelligence', 'Benefits and Risks', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Chronic Kidney Failure', 'Cicatrix', 'Clinical', 'Contrast Media', 'Coronary heart disease', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Ensure', 'Etiology', 'Fibrosis', 'Fostering', 'Gadolinium', 'General Population', 'Goals', 'Gold', 'Growth', 'Healthcare', 'Heart', 'Heterogeneity', 'Hypertrophic Cardiomyopathy', 'Image', 'Imaging Techniques', 'Impaired Renal Function', 'Impairment', 'Injections', 'Ischemia', 'Kidney', 'Learning', 'Location', 'Magnetic Resonance Imaging', 'Maps', 'Modeling', 'Morbidity - disease rate', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial tissue', 'Myocardium', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Protocols documentation', 'Reference Standards', 'Relaxation', 'Renal function', 'Research', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Surface', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'United States', 'Validation', 'Vendor', 'Work', 'base', 'clinical application', 'clinical practice', 'comorbidity', 'coronary fibrosis', 'cost', 'deep learning', 'drinking water', 'heart imaging', 'heart motion', 'imaging modality', 'improved', 'individual patient', 'magnetic field', 'mortality', 'non-invasive imaging', 'novel', 'patient population', 'patient safety', 'predictive modeling', 'prognostic', 'prospective', 'radiomics']",NHLBI,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2020,946194,-0.026802294713313902
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,9997783,R01AR074492,"['3-Dimensional', 'Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Canes', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Extracellular Matrix', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Societies', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'flexibility', 'gait examination', 'gait rehabilitation', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'kinetic model', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2020,435694,-0.03000952742075383
"Computational and Statistical Framework to Model Tissue Shape and Mechanics PROJECT SUMMARY  The morphologic and mechanical characteristics of a tissue are fundamental to understanding the development, homeostasis, and pathology of the human body. During the previous period of funding, we developed statistical shape modeling (SSM) methods and applied these to the study of structural hip disease. We also developed the initial framework to integrate SSM with finite element (FE) analysis to enable the study of shape and mechanics together. If incorporated into clinical practice, SSM and FE analysis could identify features of the anatomy likely responsible for injury, remodeling, or repair. Geometry needed for SSM and FE models is typically generated by segmentation of volumetric imaging data. This step can be painstakingly slow, error prone, and cost prohibitive, which hampers clinical application of these computational techniques. We have created a deep machine learning algorithm ‘DeepSSM’ that uses a convolutional neural network to establish the correspondence model directly from unsegmented images. In Aim 1 we will apply DepSSM to improve clinical understanding of structural hip disease by characterizing differences in anatomy between symptomatic and asymptomatic individuals; these morphometric comparisons will identify anatomic features most telling of disease, thereby guiding improvements in diagnosis. Computational advancements have simplified the process to generate patient-specific FE models, enabling clinically focused research. However, there is no framework to collectively visualize, compare, and interpret (i.e., post-process) results from multiple FE models. Currently, inter-subject comparisons require oversimplifications such as averaging results over subjectively defined regions. In Aim 2 we will develop new post-processing methods to collectively visualize, interpret and statistically analyze FE results across multiple subjects and study groups. We will map FE results to synthetic anatomies representing statistically meaningful distributions using the correspondence model. Statistical parametric mapping will be applied to preserve anatomic detail through statistical testing. We will use our published FE models of hip joint mechanics as the test system. Finally, volumetric images provide a wealth of information that is delivered to physicians in a familiar format. Yet, tools are not available to interpret model data with clinical findings from volumetric images. In Aim 3, we will develop methods that evaluate relationships between shape, mechanics, and clinical findings gleaned from imaging through integrated statistical tests and semi-automatic medical image annotation tools that utilize standard ontologies. Quantitative CT and MRI images of the hip, which estimate bone density and cartilage ultrastructure, respectively, will be evaluated as test datasets. To impart broad impact, we will disseminate our methods to the community as open source software that will call core functionality provided by existing, open source software that has a large user base (FEBio, ShapeWorks). PROJECT NARRATIVE The proposed technology will provide the methodologies necessary to increase the clinical acceptance and applicability of computer models. These models measure three-dimensional tissue shape and estimate tissue mechanics, providing information that cannot be measured conventionally. We will implement these methods into software that can be used by the public free-of-charge.",Computational and Statistical Framework to Model Tissue Shape and Mechanics,9972694,R01EB016701,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anatomy', 'Architecture', 'Bone Density', 'Cardiology', 'Cartilage', 'Characteristics', 'Charge', 'Clinical', 'Communities', 'Computational Technique', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Finite Element Analysis', 'Foundations', 'Funding', 'Geometry', 'Glean', 'Grooming', 'Hip Joint', 'Hip region structure', 'Homeostasis', 'Human Pathology', 'Human body', 'Image', 'Individual', 'Injury', 'Intuition', 'Libraries', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Neurology', 'Ontology', 'Orthopedics', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Procedures', 'Process', 'Publishing', 'Quantitative Evaluations', 'Research', 'Resources', 'Scheme', 'Shapes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Validation', 'X-Ray Computed Tomography', 'annotation  system', 'base', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data modeling', 'disease diagnosis', 'improved', 'in vivo', 'machine learning algorithm', 'novel', 'open source', 'predictive modeling', 'preservation', 'relating to nervous system', 'repaired', 'shape analysis', 'simulation', 'three-dimensional modeling', 'tool']",NIBIB,UNIVERSITY OF UTAH,R01,2020,563658,-0.02331937861755905
"Novel Algorithms for Reducing Radiation Dose of CT Perfusion Project Summary/Abstract X-ray computed tomography (CT) has been increasingly used in medical diagnosis, currently reaching more than 100 million CT scans every year in the US. The increasing use of CT has sparked concern over the effects of radiation dose on patients. It is estimated that every 2000 CT scans will cause one future cancer, i.e., 50,000 cases of future cancers from 100 million CT scans every year. CT brain perfusion (CTP) is a widely used imaging technique for the evaluation of hemodynamic changes in stroke and cerebrovascular disorders. However, CTP involves high radiation dose for patients as the CTP scan is repeated on the order of 40 times at the same anatomical location, in order to capture the full passage of the contrast bolus. Several techniques have been applied for radiation dose reduction in CTP scans, including reduction of tube current and tube voltage, as well as the use of noise reduction techniques such as iterative reconstruction (IR). However, the resultant radiation dose of existing CTP scans is still significantly higher than that of a standard head CT scan. The application of IR techniques in CTP is very limited due to the high complexity and computational burden for processing multiple CTP images that impairs clinical workflow. During the Phase 1 STTR project, we introduced a novel low dose CTP imaging method based on the k-space weighted image contrast (KWIC) reconstruction algorithm. We performed thorough evaluation in both a CTP phantom and clinical CTP datasets, and demonstrated that the KWIC algorithm is able to reduce the radiation dose of existing CTP techniques by 75% without affecting the image quality and accuracy of quantification (i.e., Milestone of Phase 1 STTR). However, the original KWIC algorithm requires rapid-switching pulsed X-ray at pre-specified rotation angles – a hardware capability yet to be implemented by commercial CT vendors. In order to address this limitation, we recently introduced a variant of the KWIC algorithm termed k-space weighted image average (KWIA) that preserves high spatial and temporal resolutions as well as image quality of low dose CTP data (~75% dose reduction) to be comparable to those of standard CTP scans. Most importantly, KWIA does not require modification of existing CT hardware and is computationally simple and fast, therefore has a low barrier for market penetration. The purpose of the Phase 2 STTR project is to further optimize and validate the KWIA algorithm for reducing radiation dose of CTP scans by ~75% while preserving the image quality and quantification accuracy in CTP phantom, clinical CTP data and animal studies. We will further develop innovative deep-learning (DL) based algorithms to address potential motion and other artifacts in KWIA, and commercialize the developed algorithms by collaborating with CT vendors. Relevance to Public Health More than 100 million CT scans are performed every year in the US, estimated to cause 50,000 cases of future cancers. This project will develop, evaluate and commercialize novel CT imaging technologies that reduce the radiation dose of existing CT perfusion techniques by ~75% without compromising imaging speed or quality.",Novel Algorithms for Reducing Radiation Dose of CT Perfusion,10006737,R44EB024438,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American Heart Association', 'Anatomy', 'Angiography', 'Animals', 'Bolus Infusion', 'Brain', 'Brain Neoplasms', 'Cerebrovascular Disorders', 'Clinical', 'Collaborations', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Head', 'Heart', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Infarction', 'Location', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical', 'Methods', 'Modification', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Organ', 'Patients', 'Pattern', 'Penetration', 'Perfusion', 'Phase', 'Physiologic pulse', 'Public Health', 'Radiation Dose Unit', 'Reperfusion Therapy', 'Roentgen Rays', 'Rotation', 'Scanning', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specific qualifier value', 'Speed', 'Stroke', 'Techniques', 'Technology', 'Time', 'Traumatic Brain Injury', 'Tube', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'acute stroke', 'base', 'brain tissue', 'contrast imaging', 'deep learning', 'denoising', 'hemodynamics', 'imaging modality', 'innovation', 'low dose computed tomography', 'novel', 'perfusion imaging', 'preservation', 'radiation effect', 'reconstruction', 'temporal measurement', 'voltage']",NIBIB,"HURA IMAGING, INC",R44,2020,820709,-0.0006372624514623771
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,9860776,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2020,649717,0.013638791266078273
"Enabling Kinematic Joint Profiling Using MRI Project Summary We propose a technical feasibility study seeking to develop methods for quantitative kinematic proﬁling of moving joints using magnetic resonance imaging (MRI). In the context of this study, a kinematic proﬁle is deﬁned as a collection of joint characteristics computed and tracked during the course of movement. This project is motivated by the hypothesis that such proﬁling of moving joints can highlight dysfunction, treatment progress, and point towards favorable (or unfavorable) surgical interventions. At a high level, it is envisioned that the proposed kinematic proﬁles could ﬁt into clinical management workﬂows much in the same way as blood biomarker panels.  While kinematic imaging of joints can be performed using plain-ﬁlm (PF) X-ray, computed tomography (CT), and ultrasound (US) methods, MRI is the gold-standard for advanced orthopedic assessment and is an appealing option for accessory kinematic analysis. A set of relatively fast kinematic proﬁling acquisitions could feasibly be added to routine orthopedic MRI exams, thereby providing optimal diagnostic imaging in both static and kinematic contexts within a single visit.  Though several preliminary studies have hinted at the potential diagnostic value of kinematic imaging data, such data is difﬁcult to interpret and cannot easily be quantiﬁed or captured in clinical records. In this study, we seek to establish fundamental methods that can provide simple and easily digestible kinematic imaging reports with data acquired in a short scan interval using conventional clinical MRI equipment.  As a preliminary feasibility investigation of these methods, kinematic imaging of the wrist will be studied. Dysfunction of the scaphoid and lunate bones in the wrist is a well-studied kinematic problem of diagnostic signiﬁcance. Novel 4D zero-echo-time MRI of the wrist will be used to capture the kinematic imaging using for proﬁling of the scaphoid-lunate mechanics during two established wrist movement patterns.  The goal of this project is to establish and demonstrate methodological components required for MRI kinematic proﬁling. Data collection on a modest-sized cohort of 100 healthy control subjects is proposed for this purpose. Novel MRI pulse-sequence and post-processing development components are introduced and tasked for analysis of this normative data. Using the acquired MRI data, kinematic parameters for each dynamic dataset will be extracted and curated into a multi-parametric proﬁle for each subject.  Aim 2 of the study proposes the use of external sensor motion capture methods to validate the MRI-based kinematic parameter measurements on 50% of the study cohort.  Finally, Aim 3 of the study seeks to use machine-learning clustering approaches to develop a kinematic proﬁle normalization procedure using the acquired control dataset. Such normalization is a crucial milestone in the translation of kinematic proﬁling to the clinic and will establish a baseline for future translational studies of symptomatic cohorts. Project Narrative We seek to develop and demonstrate fundamental methods in quantitative kinematic proﬁling using clinical diagnostic imaging equipment. This technical development project is constructed under the hypothesis that such proﬁling of moving joints can highlight dysfunction, treatment progress, and point towards favorable (or unfavorable) surgical interventions. Using currently available advanced magnetic resonance imaging technology, data collected from a controlled subject cohort will be used to develop and test the proposed kinematic proﬁling technology on the moving wrist.",Enabling Kinematic Joint Profiling Using MRI,9893679,R21AR075327,"['3-Dimensional', 'Age', 'Algorithms', 'Anatomy', 'Biological Process', 'Biomechanics', 'Blood', 'Blood flow', 'Cardiovascular system', 'Cartilage', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Equipment', 'Feasibility Studies', 'Film', 'Functional Imaging', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Gold', 'Hand', 'Image', 'Imaging technology', 'Investigation', 'Joints', 'Ligaments', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Orthopedics', 'Patient risk', 'Patients', 'Pattern', 'Physiologic pulse', 'Physiological', 'Population Control', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Protocols documentation', 'Records', 'Reporting', 'Resolution', 'Rest', 'Rewards', 'Roentgen Rays', 'Scanning', 'Scaphoid bone', 'Semilunar Bone', 'Series', 'Structure', 'Surgeon', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Ultrasonography', 'Upper Extremity', 'Visit', 'Work', 'Wrist', 'Wrist joint', 'X-Ray Computed Tomography', 'base', 'biomarker panel', 'blood perfusion', 'bone', 'clinical diagnostics', 'clinical practice', 'cohort', 'heart function', 'high resolution imaging', 'human subject', 'image registration', 'imaging Segmentation', 'imaging modality', 'interest', 'joint mobilization', 'kinematics', 'motion sensor', 'novel', 'radiologist', 'soft tissue', 'task analysis', 'tool', 'translational study', 'volunteer', 'water diffusion']",NIAMS,MEDICAL COLLEGE OF WISCONSIN,R21,2020,214720,0.008467106412993726
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,9877188,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2020,265345,0.012543792574520672
"Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients Esophageal adenocarcinoma (EAC) is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. Barrett’s esophagus (BE) confers elevated risk for progression to EAC. Patients diagnosed with BE undergo periodic surveillance endoscopy with biopsies to detect dysplasia which can be treated by endoscopic eradication with radiofrequency ablation before it progresses to EAC. However, the majority of diagnosed EAC patients have not had prior screening endoscopy and present with advanced lesions that limit treatment options and result in poorer survival. The development of a rapid, low cost, well tolerated, non-endoscopic BE screening technique that can be performed in unsedated patients at points of care outside the endoscopy suite would improve BE detection and reduce EAC morbidity and mortality. Our program is a multidisciplinary collaboration among investigators at the Massachusetts Institute Technology and Veteran Affairs Boston Healthcare System / Harvard Medical School that integrates novel optical imaging and software design, preclinical studies in swine, clinical studies in patients, and advanced image processing / machine learning. Aim 1 will develop an omniview tethered capsule technology that generates a map of the esophageal mucosa over a multi-centimeter length of esophagus and a series of wide angle forward views to aid navigation as the capsule is swallowed or retracted. The images will resemble endoscopic white light or narrow band imaging, but will not suffer from perspective distortion present in standard endoscopic or video capsule images. This will facilitate development of automated BE detection algorithms as well as enhance their sensitivity and specificity. This aim will also perform imaging studies in swine as a translational step toward clinical studies. Aim 2 will determine reader sensitivity and specificity for BE detection versus standard endoscopy / biopsy and prepare data for developing automated BE detection. Patients undergoing screening as well as with history of BE undergoing surveillance will be recruited and unsedated capsule imaging will be performed on the same day prior to their endoscopy. Sensitivity and specificity for detecting BE will be assessed using multiple blinded readers and data sets suitable for developing automated BE detection algorithms will be developed. Aim 3 will develop image analysis methods for automated BE detection by investigating classifiers that operate on handcrafted features (colors and textures) and modern deep convolutional neural network methods for direct classification. If successful, this program will develop a rapid, low cost and scalable method for BE screening that would not require patient sedation, endoscopy, or tissue acquisition, and which could be performed in community primary care clinics. The procedure would be much faster and many times lower cost than endoscopy. Automated BE detection would enable immediate results for patient consultation and referral to gastroenterology if indicated. Larger patient populations with expanded risk criteria could be cost effectively screened and access to screening dramatically improved, reducing EAC mortality. Esophageal adenocarcinoma is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. The program proposes to develop an omniview tethered capsule technology, examination protocol, and automated analysis methods for low cost, rapid, well tolerated, and scalable screening in order to facilitate monitoring and timely treatment. Larger patient populations could be cost effectively screened and access to screening dramatically improved, reducing mortality.","Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients",10033192,R01CA252216,"['Algorithmic Software', 'Algorithms', 'Back', 'Barrett Esophagus', 'Biopsy', 'Blinded', 'Blood Vessels', 'Boston', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Set', 'Deglutition', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dysplasia', 'Endoscopic Biopsy', 'Endoscopy', 'Esophageal Adenocarcinoma', 'Esophageal mucous membrane', 'Esophagus', 'Family suidae', 'Gastroenterologist', 'Gastroenterology', 'Gastroesophageal reflux disease', 'Healthcare Systems', 'Histology', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Institutes', 'Interdisciplinary Study', 'Label', 'Length', 'Lesion', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Massachusetts', 'Measures', 'Methods', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Mucous Membrane', 'Nurse Practitioners', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Population', 'Primary Care Physician', 'Primary Health Care', 'Procedures', 'Protocols documentation', 'Radiofrequency Interstitial Ablation', 'Reader', 'Reading', 'Recording of previous events', 'Referral and Consultation', 'Research Personnel', 'Resolution', 'Risk', 'Screening Result', 'Sedation procedure', 'Sensitivity and Specificity', 'Series', 'Side', 'Software Design', 'Stomach', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Validation', 'Veterans', 'advanced disease', 'automated analysis', 'automated image analysis', 'base', 'capsule', 'clinical imaging', 'convolutional neural network', 'cost', 'design', 'graphical user interface', 'image processing', 'imaging software', 'imaging study', 'improved', 'medical schools', 'mortality', 'navigation aid', 'novel', 'optical imaging', 'patient population', 'point of care', 'preclinical study', 'programs', 'recruit', 'screening']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,336293,-0.020642237858708695
"Functional Cardiovascular 4D MRI in Congenital Heart Disease SUMMARY / ABSTRACT Congenital heart disease (CHD) is the most common birth defect, affecting 1.2% of all live births. Imaging plays a major role in managing CHD but remains challenging for evaluating complex cardiac and vascular abnormalities across a wide range of age and habitus. To address these limitations, the PIs have developed cardiovascular 4D flow MRI which can measure complex 3D blood flow in-vivo, a task difficult or impossible to obtain with other imaging strategies. Recent efforts have focused on two forms of CHD: 1) bicuspid aortic valve (BAV) which is the most common form of CHD, and 2) single ventricle physiology (SVP), one of the most severe forms of CHD. Our 4D flow MRI studies have successfully identified new hemodynamic biomarkers to better characterize CHD. We were the first to establish a physiologic link between aberrant 3D blood flow, elevated wall shear stress (WSS), aortopathy phenotype, and aortic wall tissue degeneration on histopathology in patients with BAV. In patients with SVP, our findings demonstrated relationships between surgical correction strategies and flow distribution to the lungs, a known factor implicated in SVP outcome. We have achieved successful clinical translation at Northwestern, where 4D flow MRI is now used as a clinical tool in diagnostic MRI exams for patients with CHD and aortic disease. Over the past four years, the PIs have assembled one of the largest 4D MRI databases with over 2500 patient exams. For this renewal application, we identified a need to increase the dynamic range of 4D MRI flow sensitivity to account for data complexity (3D + time) and the wide age range in CHD by a combination of dual-venc flow encoding, compressed sensing, and SSFP imaging. Second, three is a need for longitudinal studies to identify predictors of BAV and SVP outcome. Third, making these unique but complex 4D MRI data sets and analysis tools more widely available to the greater research community is challenging. In addition, no automated methods currently exist for advanced processing such as atlas based analysis across large cohorts. Analysis is thus time consuming and requires manual interactions (e.g. 3D vessel segmentation) which limits reproducibility and translation. To address this need, an established Northwestern data archival and pipeline processing resource based on remote high-performance computing clusters (NUNDA) will be utilized for standardized data archival, sharing, and pipeline processing of 4D MRI data. This platform will provide the unique opportunity to utilize annotated data available in the 4D MRI database (>1300 BAV, SVP, and control 4D MRI data analyzed in the initial funding cycle) for application of machine learning concepts to establish (semi-)automated 4D MRI analysis workflows in NUNDA. Thus, the renewal application for this study aims to 1) develop a rapid (15 min) non-contrast 4D MRI for clinical translation, 2) leverage the existing large 4D MRI database to identify 4D MRI metrics predictive of long-term (> 5 years) CHD patient outcome, and 3) establish a remote NUNDA platform for 4D MRI data sharing and automated analysis across large cohorts. PROJECT NARRATIVE Our goal is to develop non-contrast 4D MRI, a new diagnostic test to achieve an improved assessment for the most common and one of the most severe forms of congenital heart disease: bicuspid aortic valve and single ventricle physiology. We will leverage an existing large 4D MRI database to allow for long-term 5-8-year follow-up to establish new measures for improved outcome prediction and therapy management for patients with bicuspid aortic valve and single ventricle physiology. A comprehensive data archive will be established to allow for the dissemination of the 4D MRI data, analysis tools, and study results to the greater research community.",Functional Cardiovascular 4D MRI in Congenital Heart Disease,9903426,R01HL115828,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Aortic Diseases', 'Archives', 'Atlases', 'Biological Markers', 'Blood flow', 'Cardiac Output', 'Cardiovascular system', 'Child', 'Clinical', 'Common Ventricle', 'Communities', 'Complex', 'Congenital Abnormality', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease Progression', 'Exposure to', 'Funding', 'General Anesthesia', 'Goals', 'Growth', 'Heart Abnormalities', 'Heart Rate', 'High Performance Computing', 'Histopathology', 'Hospitals', 'Image', 'Infant', 'Link', 'Live Birth', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Operative Surgical Procedures', 'Outcome', 'Outcome Study', 'Oxygen', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Play', 'Population', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Role', 'Secure', 'Sex Differences', 'Testing', 'Time', 'Translations', 'adverse outcome', 'analysis pipeline', 'aortic valve', 'automated analysis', 'base', 'bicuspid aortic valve', 'clinical translation', 'cluster computing', 'cohort', 'congenital heart disorder', 'data analysis pipeline', 'data archive', 'data sharing', 'data standards', 'design', 'exercise capacity', 'flexibility', 'follow-up', 'hemodynamics', 'improved', 'improved outcome', 'in vivo', 'novel', 'novel diagnostics', 'outcome prediction', 'patient population', 'pediatric patients', 'prevent', 'shear stress', 'spatiotemporal', 'tissue degeneration', 'tool', 'vascular abnormality']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,747084,0.005458814886254317
"Development of a Fast Large Area Multiphoton Exoscope (FLAME) Summary. Our long-term goal is to develop a powerful tool based on multiphoton microscopy (MPM) for non- invasive human skin imaging in order to improve clinical diagnosis, guide effective treatment and advance clinical and cosmetic/pharmaceutical research by providing access to dynamic cellular and molecular processes during therapy. MPM is a nonlinear optical imaging technique that provides unique structural and molecular contrast based on endogenous signals such as second harmonic generation from collagen and two- photon excited fluorescence from NADH/FAD+, keratin, melanin and elastin fibers. This contrast allows MPM to provide multi-color, rich molecular information content images that can enhance diagnostic accuracy. MPM overcomes fundamental limitations of existing optical imaging technologies for sub-surface skin imaging and extends the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. Validation of the clinical potential of this technology has been facilitated over the past 10 years by a device developed by Jenlab in Germany, currently the only clinical MPM system on the market. This device has technical limitations in terms of field-of-view (FOV), imaging speed, complexity and cost, which are major barriers to clinical adoption. The goal of this Phase I proposal is to develop and test the technical feasibility for in vivo human skin imaging of a MPM system that is highly optimized for rapid, label-free, macroscopic imaging of human skin with microscopic resolution. The Fast Large Area Multiphoton Exoscope (FLAME) imaging platform will incorporate the innovative optical engine of a benchtop prototype developed at BLI. InfraDerm will innovate on this design to transform it into a compact, portable device, suitable for human skin imaging in clinical setting. Key innovations include: 1) a compact engineering design based on integrating a compact fs fiber laser into the imaging head along with a customized folded optical design to reduce complexity and cost and enhance portability; 2) hardware and software strategies that include a customized patient interface and a combination of optical and mechanical scanning mechanisms with deep learning image restoration to allow millimeter-to-centimeter scale imaging within minutes while maintaining sub-micron resolution. This approach will expand the in vivo imaging area from mm to cm scale, which will be scanned within minutes with sub- cellular resolution. In Aim 1 we will develop the FLAME prototype that incorporates these features. In Aim 2 we will test its technical feasibility for in vivo human skin imaging by evaluating potential effects of motion artifacts. In Aim 3, we will demonstrate the FLAME system potential for non-invasive assessment of melanin content, an ability with potential impact in differential diagnosis and early assessment of treatment efficacy of pigmentary skin disorders, such as melasma. Phase II will refine the technological approach and will test the device feasibility in a first clinical application, differential diagnosis of patients with melasma, a long time dermatology challenge and a particular interest for pharma companies developing therapies for this skin condition. Narrative  InfraDerm LLC proposes to develop and test the technical feasibility for in vivo human skin imaging of a laser scanning microscope based on multiphoton microscopy (MPM) that addresses fundamental and technical limitations of existing optical imaging technologies for sub-surface skin imaging, extending the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. The proposed Fast Large Area Multiphoton Exoscope (FLAME) prototype will be highly optimized for rapid, label- free, macroscopic imaging of human skin with microscopic resolution. An MPM clinical platform, uniquely equipped with this combination of features would embody an innovative and commercially viable product that will broadly impact clinical diagnosis and research in dermatology as well as in cosmetic and pharmaceutical research.",Development of a Fast Large Area Multiphoton Exoscope (FLAME),10153566,R43EB030931,"['3-Dimensional', 'Address', 'Adoption', 'Alopecia', 'Appearance', 'Area', 'Automobile Driving', 'Biopsy', 'Cell physiology', 'Chloasma', 'Clinic', 'Clinical', 'Clinical Research', 'Collagen', 'Color', 'Computer software', 'Cosmetics', 'Custom', 'Dermatology', 'Development', 'Devices', 'Diagnosis', 'Differential Diagnosis', 'Disclosure', 'Elastin', 'Elastin Fiber', 'Excision', 'Extracellular Matrix', 'Face', 'Fiber', 'Fluorescence', 'Generations', 'Germany', 'Goals', 'Head', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Institutes', 'Keratin', 'Label', 'Laboratories', 'Lasers', 'Legal patent', 'Lesion', 'Mechanics', 'Medical', 'Medical Device', 'Melanins', 'Microscope', 'Microscopic', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Motion', 'NADH', 'Nevus', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacologic Substance', 'Phase', 'Physiological', 'Pigments', 'Process', 'Publications', 'Research', 'Resolution', 'Scalp structure', 'Scanning', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Validation', 'base', 'cellular imaging', 'clinical Diagnosis', 'clinical application', 'cost', 'cost effective', 'deep learning', 'design', 'diagnostic accuracy', 'effective therapy', 'engineering design', 'human imaging', 'image guided', 'image guided therapy', 'imaging platform', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'millimeter', 'multiphoton imaging', 'multiphoton microscopy', 'optical imaging', 'portability', 'prototype', 'response', 'restoration', 'second harmonic', 'skin disorder', 'skin lesion', 'submicron', 'therapy development', 'tool', 'two-photon']",NIBIB,"INFRADERM, LLC",R43,2020,263074,-0.002089832246424143
"Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography PROJECT SUMMARY Integrated analysis of coronary anatomy and biology using 18F-fluoride PET and CT angiography Each year, 735,000 Americans have an acute myocardial infarction (heart attack), and approximately 120,000 die from it. Heart attacks occur most commonly due to rupture of atherosclerotic plaques in coronary arteries. Despite this, current diagnostic and treatment algorithms make no allowance for the assessment of disease activity and currently all patients with atherosclerosis are treated in a similar manner. This failure to differentiate stable from active disease may result in potentially unnecessary or insufficient therapies. In a breakthrough series of studies, our co-investigators discovered that positron emission tomography (PET) with 18F-sodium- fluoride (18F-NaF; an inexpensive and widely available tracer approved by Food and Drug Administration) can readily identify plaque rupture and increased coronary plaque activity. We propose to build further on this success, by addressing several important remaining limitations that prevent us from translating this technology to broad clinical use. The limitations include complicated and subjective image analysis, underutilization of the concomitant coronary computed tomography angiography (CTA) for plaque characterization, inability to utilize prior CTA for the analysis of 18F-NaF PET, lack of methods to integrate all available PET and CTA data and significant motion of the coronaries during the PET scan. We propose a multi-faceted approach to automate and improve coronary 18F-NaF PET imaging by full integration with CTA and correction for cardiac, respiratory, and patient motion. The overall goal of the proposal is to optimize the measurement of disease activity in coronary atherosclerosis using integrated 18F-NaF PET/CTA imaging, with the opportunity to validate this development against clinical outcome in a “real-world” multicenter patient study. For this work, we propose the following 3 specific aims: 1) to integrate quantification of CTA and PET image data 2) to develop new methods for simultaneous correction of cardiac, respiratory, and patient motion for coronary PET, and 3) to clinically evaluate new methods in a multicenter clinical trial (separately funded and already underway), further refining risk prediction for heart attacks with integrated PET+CTA risk score derived by machine learning. This work will lead to a robust and reproducible clinical method for stratification of patients for risk of heart attacks, with potential to be applied for the identification of patients who would most benefit from expensive, and potentially risky treatments. Our techniques could also be used in future clinical trials to test the efficacy of novel therapies. Moreover, the new analysis will be applicable to other PET tracers that may be developed to investigate other pathological processes in the coronary vasculature. The resulting software will be shared with clinical institutions performing coronary PET to facilitate standardization and automation of this novel plaque imaging technique. NARRATIVE A heart attack, a major cause of death, is most commonly caused by rupture of deposits in heart vessels, leading to sudden blockage of the blood flow in the vessels and disruption of blood supply to the heart muscle. Currently there is no reliable test to identify deposits at the highest risk of rupture, but in a recent scientific breakthrough, positron emission tomography has demonstrated capability to image disease activity inside these deposits, linked to their rupture; this technique, however, is currently hampered by lack of anatomical reference, image blurring due to heart motion, and variability of manual analysis. We propose to address these problems by developing automatic software that precisely integrates anatomical and biological information and virtually “freezes” vessel motion, validating this new approach in a large “real-world” multicenter patient study.",Integrated analysis of coronary anatomy and biology with 18F-fluoride PET and CT angiography,10015326,R01HL135557,"['Acute myocardial infarction', 'Address', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Area', 'Arterial Fatty Streak', 'Atherosclerosis', 'Automation', 'Binding', 'Biological', 'Biological Process', 'Biology', 'Blood flow', 'Breast Microcalcification', 'Cardiac', 'Cause of Death', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer software', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Data', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Emission-Computed Tomography', 'Enrollment', 'Event', 'FDA approved', 'Failure', 'Fluorides', 'Freezing', 'Funding', 'Future', 'Goals', 'Heart', 'Histologic', 'Image', 'Image Analysis', 'Imaging Techniques', 'Inflammation', 'Institution', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Motion', 'Multi-Institutional Clinical Trial', 'Myocardial', 'Myocardial Infarction', 'Myocardium', 'Noise', 'Outcome', 'Pathologic Processes', 'Patient risk', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Radiation', 'Recurrence', 'Reporting', 'Reproducibility', 'Research Personnel', 'Risk', 'Risk Assessment', 'Rupture', 'Scanning', 'Series', 'Signal Transduction', 'Sodium Fluoride', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tracer', 'Translating', 'United States Food and Drug Administration', 'Vascular blood supply', 'Work', 'X-Ray Computed Tomography', 'atherosclerotic plaque rupture', 'automated analysis', 'coronary computed tomography angiography', 'coronary plaque', 'coronary vasculature', 'cost', 'disorder risk', 'efficacy testing', 'experience', 'fluorodeoxyglucose positron emission tomography', 'heart motion', 'high risk', 'imaging study', 'improved', 'novel', 'novel strategies', 'novel therapeutics', 'patient stratification', 'prevent', 'prospective', 'respiratory', 'success', 'uptake', 'virtual']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2020,666434,0.017391526361552098
"STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients Project Summary/Abstract Lung cancer is the leading cause of cancer death and one of the most common cancers among both men and women in the United States. Recent advances in high-resolution imaging set the stage for radiomics to become an active emerging field in cancer research. However, the promise of radiomics is limited by a lack of image standardization tools, because computed tomography (CT) images are often acquired using scanners from different vendors with customized acquisition parameters, posing a fundamental challenge to radiomic studies across sites. To overcome this challenge, especially for large-scale, multi-site radiomic studies, advanced algorithms are required to integrate, standardize, and normalize CT images from multiple sources. We propose to develop STAN-CT, a deep learning software package that can automatically standardize and normalize a large volume of diagnostic images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification. By precisely mitigating the differences in advanced radiomic features of CT images, STAN-CT will overcome research silos and promote medical image resource sharing, ultimately improving the diagnosis and treatment of lung cancer. Our goal will be achieved through two Aims. In Aim 1, we will develop a working prototype to standardize CT images. First, we will collect raw image data from lung cancer patients and reconstruct CT images using multiple image reconstruction parameters, and we will scan a multipurpose chest phantom along with five different nodule inserts. Then, we will develop and train STAN-CT for CT image standardization. An alternative training architecture will be developed to achieve the improved model training stability. In Aim 2. We will deploy and test STAN-CT for image standardization locally and across three medical centers. First, we will make the STAN-CT software package available to the public by providing a menu-driven web-interface so that that users can conveniently convert medical images that were taken using non-standard protocols to one or multiple standards that they specify. Second, we will deploy STAN-CT at the University of Kentucky for local performance validation. We will test the functionality, reliability, and performance of STAN-CT using both patient chest CT image data collected at large-scale and the phantom image data, both independent to training. Third, we will deploy and test STAN-CT at the University of Kentucky as well as the University of Texas Southwestern Medical Center and Emory University for cross- center performance validation. We will use the same multipurpose chest phantom and both standard and non- standard protocols to validate STAN-CT at the three centers. We will test the generalizability of STAN-CT using clinical CT images of human patients and will determine whether a model trained using the data from one medical center are applicable for images collected at another place. Finally, we will distribute the software package of STAN-CT for public use. STAN-CT will enable a wide range of radiomic researches to identify diagnostic image features that strongly associated with lung cancer prognosis. Project Narrative Computed tomography (CT) is one of the most popular diagnostic image modalities routinely used for assessing anatomical tissue characteristics for disease management. However, CT images are often acquired using scanners from different vendors with different imaging standards, posing a fundamental challenge to radiomic studies across sites. The goal of the Standardization and Normalization of CT images for lung cancer patients (STAN-CT) project is to develop a deep learning software package that can automatically standardize and normalize a large volume of chest CT images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification.",STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients,9961508,R21CA231911,"['Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Cancer Etiology', 'Cancer Patient', 'Cancer Prognosis', 'Cessation of life', 'Characteristics', 'Chest', 'Clinical', 'Communities', 'Computed Tomography Scanners', 'Computer software', 'Custom', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Disease Management', 'Evolution', 'Faculty', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Kentucky', 'Life', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical Imaging', 'Medical center', 'Modeling', 'Multi-Institutional Clinical Trial', 'Names', 'Nodule', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Protocols documentation', 'Quality Control', 'Radiology Specialty', 'Research', 'Resource Sharing', 'Scanning', 'Site', 'Source', 'Specific qualifier value', 'Standardization', 'Stratification', 'Survival Rate', 'System', 'Testing', 'Texas', 'Tissues', 'Training', 'United States', 'Universities', 'Validation', 'Vendor', 'Woman', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'chest computed tomography', 'computational platform', 'data to knowledge', 'deep learning', 'feature extraction', 'high resolution imaging', 'human imaging', 'image reconstruction', 'imaging modality', 'improved', 'lung imaging', 'member', 'men', 'outcome forecast', 'prototype', 'quantitative imaging', 'radiomics', 'response', 'spatial temporal variation', 'tool', 'trait', 'tumor', 'web interface']",NCI,UNIVERSITY OF KENTUCKY,R21,2020,175505,-0.017298006902362356
"Rapid Low-Cost Quantitative 3D MRI and Gait Assessment of the Knee Project Abstract Motivation: Osteoarthritis (OA) is a painful disease that affects tens of millions of Americans, but is poorly understood, resulting in a lack of treatments. Enabling low-cost approaches for widespread study of risk factors, onset and early progression of OA will enable better understanding of OA mechanisms, treatment development, and triage of patients to different treatments based on speciﬁc disease phenotypes. Multiple systemic factors, biochemical factors, and other risk factors are associated with OA, but causes are difﬁ- cult to isolate and study during slow progression. Currently OA is diagnosed as joint-space narrowing using X-ray radiography, at a stage well beyond when interventions can be effective. Magnetic resonance imaging (MRI) of- fers sensitivity to morphologic and biochemical changes, but most methods are impractical for widespread clinical or research use. Usually MRI exams study only one knee, precluding the opportunity to compare knees. Sim- ilarly, biomechanics assessment typically requires numerous tests using advanced and rarely-available equip- ment and time-intensive analysis by skilled personnel, making this a challenge for widespread use. We have shown rapid, simultaneous 3D scanning of both knees with quantitative relaxometry and diffusion map- ping of connective tissues, combined with novel visualization of longitudinal change validated in a population with anterior cruciate ligament (ACL) tears. We have developed fully-automated cartilage and meniscus seg- mentation to simplify post-processing. (Our automated cartilage segmentation variability approaches that of reader-to-reader variability.) We now propose to combine MRI acquisition, reconstruction and analysis tech- niques with simple measures of kinematics into a widely applicable low-cost imaging and biomechanical test, which we will validate in subjects with ACL-injury and subjects with varying Kellgren-Lawrence grades of OA. Approach: We will begin by developing a robust 5-to-8-minute bilateral knee MRI exam, using an efﬁcient 3D isotropic acquisition and novel deep-learning based image reconstructions. This will be followed with automated cartilage segmentation and quantitative analysis (thickness, T2, diffusion) of all 3 knee plates and automated semiquantitative scoring approaches for synovitis, bone marrow and cartilage lesions. Inertial measurement units (IMUs) will be used to measure kinematics, and gait asymmetries. We will continue our studies in ACL pa- tients to validate techniques and to develop asymmetry analyses for both imaging and biomechanical measures. Finally, in subjects with varying OA grade, we will evaluate the potential of the overall low-cost approach to relate asymmetry and longitudinal change measures to progression and OA grade. Signiﬁcance: This project will develop an acquisition and analysis pipeline to quantify knee changes and left/right asymmetries that precede OA. We will characterize methods in idiopathic OA subjects and ACL- injured subjects at risk of post-traumatic OA. The very low target cost, under $120/subject, will ultimately enable widespread study of early onset and progression of different OA types, leading to earlier and better treatments. Project Narrative Osteoarthritis remains the leading cause of disability, and effective treatment will require efﬁcient assessment of disease risk-factors, onset, and progression, both for development and personalization of minimally invasive interventions. We propose a 5-minute 3D MRI exam of both knees without radiation or contrast injection, that will be combined with low-cost measures of knee motion and fully automated analysis methods to provide quan- titative measurements of cartilage, tendon, ligament, bone and ﬁbrocartilage health and asymmetries between knees. This low-cost, rapid, bilateral assessment will enable research studies in large populations, as well as adding quantitative bilateral information to clinical scans to dramatically improve understanding of onset of dif- ferent types of osteoarthritis.",Rapid Low-Cost Quantitative 3D MRI and Gait Assessment of the Knee,10032904,R01AR077604,"['3-Dimensional', 'Affect', 'American', 'Anterior Cruciate Ligament', 'Articulation', 'Bilateral', 'Biochemical', 'Biomechanics', 'Body mass index', 'Bone Marrow', 'Bone Spur', 'Cartilage', 'Chronic', 'Clinical', 'Cluster Analysis', 'Connective Tissue', 'Cost Measures', 'Coupled', 'Data', 'Data Pooling', 'Degenerative polyarthritis', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Environment', 'Equipment', 'Etiology', 'Evaluation', 'Female', 'Fibrocartilages', 'Future', 'Gait', 'Gait abnormality', 'Goals', 'Health', 'Human Resources', 'Image', 'Imaging Techniques', 'Inflammatory', 'Injections', 'Injury', 'Intervention', 'Joints', 'Kellgren-Lawrence grade', 'Knee', 'Knee Osteoarthritis', 'Left', 'Length', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Meniscus structure of joint', 'Methods', 'Morphology', 'Motion', 'Motivation', 'Output', 'Pain', 'Patient Triage', 'Patients', 'Population', 'Protocols documentation', 'Protons', 'Quality of life', 'Quantitative Evaluations', 'Radiation', 'Reader', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Risk Factors', 'Roentgen Rays', 'Sampling', 'Scanning', 'Sex Differences', 'Slice', 'Surface', 'Synovitis', 'Techniques', 'Tendon structure', 'Testing', 'Thick', 'Time', 'Tissues', 'Visualization', 'analysis pipeline', 'anterior cruciate ligament injury', 'anterior cruciate ligament rupture', 'automated analysis', 'base', 'bone', 'cohort', 'cost', 'deep learning', 'density', 'disability', 'disease phenotype', 'disorder risk', 'early onset', 'effective therapy', 'gait examination', 'image reconstruction', 'improved', 'kinematics', 'learning classifier', 'meniscus injury', 'minimally invasive', 'novel', 'predictive test', 'primary outcome', 'quantitative imaging', 'reconstruction', 'research study', 'sensor', 'societal costs', 'therapy development', 'tissue biomarkers']",NIAMS,STANFORD UNIVERSITY,R01,2020,658342,0.0047689362081361495
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and affect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable of discovering local and global alteration of matter without the need to apriori select an anatomical region of interest. The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image datasets is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focuses on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10139715,R42MH118845,"['Affect', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Blood flow', 'Brain', 'Clinical', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Detection', 'Deterioration', 'Diffuse', 'Disease', 'Drug Screening', 'Goals', 'Grain', 'HIV', 'Image', 'Image Analysis', 'Internet', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Measures', 'Medical Imaging', 'Metabolic', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologic Effect', 'Neurosurgeon', 'Online Systems', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Analysis', 'Population Study', 'Positioning Attribute', 'Process', 'Questionnaires', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Software Validation', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Visualization', 'Washington', 'analysis pipeline', 'base', 'data access', 'data infrastructure', 'deep learning', 'experience', 'gray matter', 'high throughput screening', 'image registration', 'imaging capabilities', 'improved', 'insight', 'interest', 'metabolic rate', 'morphometry', 'nervous system disorder', 'neurodegenerative dementia', 'novel', 'programs', 'prototype', 'regional difference', 'research and development', 'shape analysis', 'software development', 'software infrastructure', 'task analysis', 'tool', 'usability', 'web app', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R42,2020,456359,0.0014589181885840405
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this project, we present EyeMark, a system with advanced longitudinal image anal- ysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we have developed tools for computation of microan- eurysm (MA) appearance and disappearance rates (jointly known as turnover rates) for use as a biomarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high pos- itive influence on various aspects of DR care, including screening, monitoring progres- sion, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a prototype tool that robustly registers longitudinal images (even with multiple lesion changes) and effectively detects and localizes DR le- sions. This fully automated tool can work on the cloud to produces results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. This commercialization readiness pilot (CRP) project is intended to develop a regulatory strategy and a market access plan for EyeMark to enable its introduction in the US market and foster commercial success. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,10082344,SB1TR000377,"['Adult', 'Age', 'Appearance', 'Biological', 'Biological Markers', 'Biometry', 'Blindness', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Color', 'Communication', 'Computer Vision Systems', 'Consumption', 'Contracts', 'County', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Early identification', 'Environment', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Feedback', 'Fostering', 'Funding', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Legal', 'Lesion', 'Los Angeles', 'Machine Learning', 'Market Research', 'Marketing', 'Measures', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Participant', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Price', 'Process', 'Prothrombin', 'Readiness', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Sales', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'algorithm development', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'commercialization', 'computerized', 'computerized tools', 'convolutional neural network', 'design', 'diabetic patient', 'drug discovery', 'experience', 'fundus imaging', 'health economics', 'high risk', 'high throughput analysis', 'image registration', 'imaging biomarker', 'interest', 'large datasets', 'longitudinal analysis', 'medical schools', 'novel marker', 'novel therapeutics', 'payment', 'prevent', 'programs', 'prototype', 'retinal imaging', 'screening', 'serial imaging', 'sound', 'success', 'tool', 'usability']",NCATS,"EYENUK, INC.",SB1,2020,300000,0.008813533306710645
"Human Tumor Atlas Network: Data Coordinating Center Supplement This proposal is a collaboration with the HTAN Data Coordination Center DCC and describes an Image Data Project aimed at developing and deploying the technology needed for storage, distribution and basic analysis of cell and tissue images collected by multiple HTAN Centers. Multiplexed tissue images are an important type of data for nearly all of the centers contributing to the HTAN (second only to single cell sequencing data in number of centers collecting data). However, the software needed to visualize, analyze, manage, and share multiplexed images of tissues and tumors is underdeveloped. The initial availability of SARDANA images has highlighted the challenges faced by HTAN, including the DCC, in deploying an infrastructure for distributing large and complex images. We therefore propose a two-year HTAN Image Data Project (IDP) led by the DCC and HMS PCA focused on the rapid development and deployment of image informatic systems and computational resources for image management and analysis. Our goal is to put in place a functional first-generation system no later than summer 2020 and to then steadily refine the system so that it becomes the backbone of cross-functional HTAN atlases. As a matter of necessity, we will start with informatic systems and software that are either available today or in a relatively advanced state of development. However, we expect to evaluate these choices throughout the IDP and change course as necessary to incorporate potentially superior approaches. We will also support the diverse needs and formats of centers using different data collection methods. Aim 1 will focus on the deployment and progressive improvement of a cloud-based database for image management based on the OMERO standard as well as a parallel system for access to primary data. Aim 2 will develop and deploy software for visualizing HTAN image data by the general public. The IDP will use the existing MCWG and DAWG mechanisms for oversight and reporting, and all centers will be invited to participate. Within IDP, the HMS PCA will take primary responsibility for initial deployment of image informatics software. The DCC and HMS will jointly undertake software development and code hardening, and the DCC will take the lead in user assistance and software deployment, particularly in year two. Images of tumor specimens obtained from biopsy or surgery are one of the primary ways in which cancer is diagnosed and staged by pathologists, but such images have typically lacked molecular detail. The highly multiplexed tissue images being collected by HTAN will fundamentally change this, and it is therefore essential that the data be efficiently and widely distributed. The HTAN Image Data Project IDP will address an acute need for software for data dissemination and visualization.",Human Tumor Atlas Network: Data Coordinating Center Supplement,10206514,U24CA233243,"['Acute', 'Address', 'Atlases', 'Bioinformatics', 'Biopsy', 'Client', 'Code', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Databases', 'Development', 'Diagnosis', 'European', 'General Population', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Malignant Neoplasms', 'Manuscripts', 'Methods', 'Modeling', 'Molecular', 'Operative Surgical Procedures', 'Output', 'Pathologist', 'Performance', 'Reporting', 'Side', 'Slide', 'Software Tools', 'Specimen', 'System', 'Technology', 'Testing', 'Tissue imaging', 'Tissues', 'Vertebral column', 'Visualization', 'base', 'cancer imaging', 'cellular imaging', 'cloud based', 'computing resources', 'data dissemination', 'data management', 'data resource', 'data visualization', 'imaging Segmentation', 'imaging informatics', 'improved', 'machine learning algorithm', 'multiplexed imaging', 'programs', 'relational database', 'single cell sequencing', 'software development', 'supervised learning', 'tumor']",NCI,DANA-FARBER CANCER INST,U24,2020,926364,0.008928848270220084
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10115288,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'Visualization', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'machine learning method', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2020,99860,0.0016420151957678634
"Development of a Rapid Method for Imaging Regional Ventilation in Small Animals w/o Contrast Agents The objective of this R01 application is to develop a rapid method for imaging regional ventilation and lung compliance in small animals without contrast agents. Much of our current understanding of the normal functioning of the lung and mechanisms of lung disease comes from small animal studies. However, lung function imaging in small animal models is technically challenging due to motion and the relatively small size of the lungs. Pulmonary function testing using plethysmography has been employed to assess lung function and injury with limited validity and utility, particularly in small animals. Additionally, only aggregate measures of functional performance are produced and no regional lung changes can be assessed. An improved imaging method that could provide spatially- and temporally-resolved information regarding ventilation would be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases. It would also facilitate drug discovery and efficacy studies aimed to mitigate respiratory pathology. The ideal method would provide quantitative regional functional information, be applicable to longitudinal studies (low radiation dose), and have a simple and affordable implementation that permits widespread use. Currently available imaging methods including micro-CT or MRI fall short in one or more of these requirements.  To address this need, we will establish and evaluate a novel, easy to implement, and highly effective X- ray phase-contrast (XPC) method for ventilation imaging in small animal models. The lung is ideally suited to XPC imaging because it is comprised mainly of air spaces separated by thin tissue structures. The air-tissue interfaces cause the X-ray beam to experience numerous and strong refractions that produce a distinctive texture in the intensity measured over the lungs known as speckle. Detailed information regarding the regional lung air volume (RLAV) distribution is encoded in the speckle. The benefits of exploiting lung speckle for detecting and monitoring lung function are numerous but remain entirely unexplored for benchtop imaging.  Our approach involves a high degree of technical innovation regarding image formation methods and will significantly extend the current boundaries of functional lung imaging in small animals. The proposed method, referred to as parametric XPC (P-XPC) imaging, will produce 2D parametric images that depict the projected RLAV distribution. When differential images are computed for any given two points in the breathing cycle, ventilation or lung compliance imaging will be achieved. Preliminary in vivo and computational studies have been conducted in support of the proposed research. The specific aims of the project are as follows. Aim 1: Develop P-XPC image formation methods for estimating the projected RLAV distribution; Aim 2: Optimize an XPC imaging system for P-XPC imaging. Aim 3: Evaluate the diagnostic capability of P-XPC imaging in two pre-clinical animal models of disease in vivo. The proposed research will result in a novel, easy to implement, and highly effective X-ray phase-contrast (XPC) method for functional lung imaging in small animal models. It will provide spatially- and temporally- resolved information regarding lung ventilation that will be of great value to those studying basic pulmonary physiology and the onset and progression of a large range of respiratory diseases.",Development of a Rapid Method for Imaging Regional Ventilation in Small Animals w/o Contrast Agents,9888370,R01EB023045,"['Address', 'Air', 'Animal Disease Models', 'Animal Model', 'Animals', 'Breathing', 'Communities', 'Contrast Media', 'Development', 'Diagnostic', 'Evaluation', 'Functional Imaging', 'Image', 'Imaging technology', 'Longitudinal Studies', 'Low Dose Radiation', 'Lung', 'Lung Compliance', 'Lung diseases', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Monitor', 'Motion', 'Mus', 'Pathology', 'Performance', 'Phase', 'Physics', 'Physiology', 'Plethysmography', 'Process', 'Pulmonary Emphysema', 'Pulmonary function tests', 'Radiation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Resource Sharing', 'Respiratory physiology', 'Roentgen Rays', 'Scientist', 'Source', 'Structure', 'System', 'Technical Degree', 'Techniques', 'Texture', 'Thinness', 'Time', 'Tissues', 'Translating', 'animal imaging', 'base', 'computer studies', 'contrast imaging', 'cost', 'detector', 'drug discovery', 'drug efficacy', 'efficacy study', 'experience', 'falls', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'lung imaging', 'lung injury', 'lung pressure', 'lung volume', 'machine learning method', 'microCT', 'mouse model', 'novel', 'parametric imaging', 'pre-clinical', 'pressure', 'rapid technique', 'respiratory', 'supervised learning', 'ventilation']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2020,419843,-0.007344899037082696
"Multiband ASL for Neurodevelopment Study Project Summary/Abstract The developmental period between childhood to adolescence and young adulthood is marked by a mix of potential and vulnerability. A number of potentially life-long behavioral and emotional problems emerge during this critical period, including alcohol and illicit drug use, risky behaviors, and the first signs of emotional disorders. It is important to understand detailed patterns of typical development, so alterations can be identified and rectified as early as possible. As an entirely noninvasive and quantitative imaging method, arterial spin labeled (ASL) perfusion MRI is increasingly being recognized as an important biomarker for functional brain development in both healthy populations and neurodevelopmental disorders. However, there remain significant challenges for making ASL an impactful tool in studying neurodevelopment, including: 1) a coarse spatial resolution of ~4x4x4mm3, 2) susceptibility to head motion with segmented 3D acquisitions, and 3) potential confounding effects of age dependent variations in arterial transit time using a single post-labeling delay (PLD) scan. Simultaneous multi-slice (SMS) or multiband (MB) is a new accelerated imaging technology that simultaneously excites multiple slices and recovers each slice with parallel imaging techniques. Preliminary studies combining MB with ASL showed that MB can reduce T1 relaxation of the label, improve spatial coverage and/or resolution compared to those of standard 2D ASL. MB imaging may also overcome the limitation of 3D ASL acquisitions in terms of head motion and spatial blurring. However, the signal-to-noise ratio (SNR) of existing MB ASL is inferior to that of 3D ASL. This project builds on two recent innovations from our lab: 1) a constrained slice-dependent (CSD) background suppression (BS) technique that improves the SNR of 2D MB pCASL to be comparable to that of 3D pCASL; and 2) a single-shot 3D GRASE pCASL method with 2D CAIPIRINHA accelerations that improves the imaging speed of 3D pCASL. The goal of this R01 project is to develop and evaluate cutting-edge MB pCASL protocols that are able to offer a high spatial resolution of isotropic 2mm or higher, resistance to head motion and multi-delay capability for accurate perfusion quantification in pediatric populations. A convolutional neural network (CNN) based denoising algorithm for multi-delay MB pCASL will be further developed. The developed suite of MB pCASL protocol and post- processing algorithms will be evaluated in 40 typically developing children and adolescents. The successful completion of this R01 project will lead to a robust multi-delay MB pCASL protocol that is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care. To maximize the scientific and clinical impact, we will continue disseminating the pulse sequence and associated post-processing software as we have been doing in the past decade. Relevance to Public Health A number of potentially life-long behavioral and emotional problems emerge during the developmental period between childhood to adolescence and young adulthood, including alcohol and illicit drug use, risky behaviors, and emotional disorders. This project will develop a robust noninvasive imaging technique using magnetic resonance imaging (MRI) that offers high spatial resolution, resistance to head motion and accurate quantification of cerebral blood flow in children and adolescents. The developed technology is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care.",Multiband ASL for Neurodevelopment Study,9972888,R01EB028297,"['3-Dimensional', 'Acceleration', 'Adolescence', 'Adolescent', 'Affect', 'Age', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Behavior Disorders', 'Behavioral', 'Biological Markers', 'Brain', 'Cerebrovascular Circulation', 'Child', 'Childhood', 'Clinical', 'Computer software', 'Data', 'Databases', 'Development', 'Emotional', 'Emotional disorder', 'Goals', 'Head', 'Image', 'Imaging Techniques', 'Imaging technology', 'Inferior', 'Joint repair', 'Label', 'Life', 'Magnetic Resonance Imaging', 'Methods', 'Motion', 'Network-based', 'Neurodevelopmental Disorder', 'Noise', 'Pattern', 'Performance', 'Perfusion', 'Perfusion Weighted MRI', 'Phase', 'Physiologic pulse', 'Population', 'Predisposition', 'Principal Component Analysis', 'Protocols documentation', 'Public Health', 'Publishing', 'Relaxation', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Risk Behaviors', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Speed', 'Spin Labels', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'age effect', 'age related', 'autism spectrum disorder', 'base', 'child depression', 'clinical care', 'convolutional neural network', 'critical period', 'denoising', 'developmental disease', 'illicit drug use', 'imaging modality', 'improved', 'innovation', 'neurodevelopment', 'non-invasive imaging', 'novel', 'perfusion imaging', 'potential biomarker', 'quantitative imaging', 'socioeconomics', 'time use', 'tool', 'young adult']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,445500,-0.015464026237249077
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,10021685,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'algorithm development', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'data quality', 'deep learning', 'denoising', 'detector', 'drug action', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,344862,-0.000577422688628081
"Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes/eyelids and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to develop a more precise DR scoring scheme. This would help identify patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images,10082348,R44EY028081,"['Agreement', 'Algorithms', 'Applications Grants', 'Biological', 'Blindness', 'Cataract', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Ensure', 'Exposure to', 'Eye', 'Eye diseases', 'Eyelash', 'Eyelid structure', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Internet', 'Lasers', 'Lesion', 'Light', 'Localized Lesion', 'Manuals', 'Measures', 'Modality', 'Morphologic artifacts', 'Online Systems', 'Ophthalmoscopy', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scheme', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Vision', 'Work', 'automated analysis', 'base', 'cloud based', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability']",NEI,"EYENUK, INC.",R44,2020,1000000,0.014089501644412814
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,10023268,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'feature extraction', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2020,155784,0.002961256899174035
"2020 OSA Optical Coherence Tomography Meeting NIBIB PROPOSAL – ABSTRACT 2020 OSA Optical Coherence Tomography Meeting  Biophotonics technologies have clear medical and clinical applications. However, the transformation and translation from the research lab to the clinic, and then to market is a complex process. The 2020 OSA Optical Coherence Tomography meeting will be held on 20-23 April 2020 in Fort Lauderdale, Florida, in parallel with other four topical meetings (Clinical and Translational Biophotonics, Optical Tomography and Spectroscopy, Microscopy, Histopathology and Analytics, Optics and the Brain) within the same congress, the 2020 OSA Biophotonics Congress: Biomedical Optics. The ultimate objective of this conference is to disseminate recent developments in the field of optical coherence tomography (OCT) and inspire new ideas through various forms of interactions within a broad audience that includes engineers, natural scientists (physicists, biologists, chemists, etc.), clinical researchers, industrial R&D and market experts. The meeting will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. New topics to be covered are the development and application of advanced image processing algorithms to interpret to imaging data.  A unique advantage of co-locating this meeting within a congress and presenting joint plenary sessions is the extended cross-fertilization between experts in in the distinct but synergic fields. Technical sessions that include innovative methods such as campfire, fishbowl sessions or unconference, and special programming will ensure the meetings' success as the leading forum for presenting the latest advances, while providing an ideal setting to learn. This meeting will provide an opportunities for students and early career professionals to present their work, participate in professional development activities, hear from and network with internationally-renowned speakers and participate in special programming. Ultimately, holding high-quality scientific and technical meeting, where best-in-class research is presented and discussed will advance knowledge in the field of biomedical optics and biophotonics and propel technological development forward, while augmenting standard academic training and presenting opportunities for career advancement, especially for students and early career professionals. NIBIB PROPOSAL – PROJECT NARRATIVE 2020 OSA Optical Coherence Tomography Meeting The 2020 OSA Optical Coherence Tomography Meetings will bring together many of the leaders in the OCT field, who will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future, including developing and evaluating new imaging approaches to solve important clinical problems. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. These meeting will bring together researchers working in all aspects of this field and will serve as a forum for discussion of existing and emerging techniques as well as future directions.",2020 OSA Optical Coherence Tomography Meeting,9914797,R13EB029301,"['Academic Training', 'Address', 'Algorithms', 'Area', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophotonics', 'Brain', 'Career Mobility', 'Clinic', 'Clinical', 'Collaborations', 'Complex', 'Congresses', 'Data', 'Development', 'Diagnostic Imaging', 'Engineering', 'Ensure', 'Equilibrium', 'Event', 'Fertilization', 'Florida', 'Functional Imaging', 'Future', 'Goals', 'Hearing', 'Histopathology', 'Image', 'Industrialization', 'Industry', 'International', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Methods', 'Microscopy', 'National Institute of Biomedical Imaging and Bioengineering', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optical Tomography', 'Optics', 'Paper', 'Participant', 'Peer Review', 'Performance', 'Physicians', 'Process', 'Published Comment', 'Reporting', 'Research', 'Research Personnel', 'Scientist', 'Services', 'Special Event', 'Spectrum Analysis', 'Students', 'Techniques', 'Technology', 'Time', 'Translating', 'Translational Research', 'Translations', 'Work', 'academic standard', 'adaptive optics', 'bioimaging', 'career', 'clinical application', 'design', 'graduate student', 'image processing', 'imaging approach', 'improved', 'innovation', 'lectures', 'meetings', 'novel', 'posters', 'programs', 'research and development', 'success', 'symposium', 'tool']",NIBIB,OPTICAL SOCIETY OF AMERICA,R13,2020,10000,0.002338065121881321
"Simulation Tools for 3D and 4D CT and Dosimetry Abstract Photon-counting CT (PCCT) is a major technological advance in CT imaging. Using photon-counting instead of current energy-integrating detectors, PCCT can offer superior performance in terms of spatial resolution, artifact reduction, and most notably, material decomposition. PCCT’s energy differentiation utility offers an ability to more precisely distinguish different materials and optimize and expand the use of contrast agents in CT. With these abilities, PCCT can significantly facilitate quantitative imaging, reduce radiation exposure, and enable revolutionary new applications in functional and physiological imaging beyond existing CT techniques. To realize the full potential of PCCT in clinical practice, the technology needs comprehensive assessments and application-based optimizations. Effective design and deployment of PCCT depends on many design and use choices that should be made in view of the eventual clinical utility. Making these choices requires large scale trials on actual patients. However, such trials are challenging, considering the need to make many decisions prior to prototyping, the limited numbers of prototype PCCT scanners available today, and the often-unknown ground-truth in the patient images. Even for existing prototype systems, many decisions require repetitive trials with multiple acquisitions. This is both unethical and impractical considering radiation safety concerns and costs. These challenges can be overcome by utilizing virtual imaging trials (VITs) using computerized patients and imaging models. VITs provide an efficient means with which to determine the most effective and optimized design and use of imaging technologies with complete control over the study design. In our prior funded project, we developed a VIT framework to evaluate standard energy-integrating detector CT technologies. In this project, we expand the applicability of this framework to photon-counting detector CT. Specifically, we enhance our computational XCAT phantoms to model the necessary higher-resolution detail including normal and abnormal tissue heterogeneities and intra-organ contrast perfusion diversity across populations (Aim 1). To image the phantoms, we develop the first PCCT simulator capable of mimicking existing and emerging prototypes (Aim 2). The enhanced VIT framework will provide the essential foundation with which to comprehensively evaluate and optimize PCCT technologies and applications. In Aim 3, we assess and optimize the use of PCCT for morphological, textural, and compositional quantification in select oncologic and cardiac applications, two leading health detriments in the US where PCCT can offer a notable impact. The results will be the first of their kind in comprehensively evaluating the task-based merits and capabilities of PCCT, determining optimum dose per patient size for PCCT imaging of patients for cancerous lesions and cardiac plaque/stenoses, and helping to establish the effective utility of PCCT in clinical care. The purpose of this project is to develop and utilize a virtual framework to comprehensively evaluate and optimize emerging photon-counting devices and applications in CT imaging. The results will be the first of their kind evaluating the task-based merits and capabilities of photon-counting CT and will help establish its effectual utility in oncologic and cardiac care.",Simulation Tools for 3D and 4D CT and Dosimetry,10051026,R01EB001838,"['3-Dimensional', 'Abdomen', 'Anatomy', 'Cancerous', 'Cardiac', 'Caring', 'Clinic', 'Clinical', 'Computer software', 'Contrast Media', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Dose', 'Ensure', 'Ethics', 'Evaluation', 'Foundations', 'Functional Imaging', 'Funding', 'Health', 'Heterogeneity', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Industry', 'Lesion', 'Manufacturer Name', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Noise', 'Organ', 'Pathologic', 'Patient imaging', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Population', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Research Design', 'Resolution', 'Resources', 'Role', 'Safety', 'Scientist', 'Series', 'Specimen', 'Stenosis', 'System', 'Task Performances', 'Techniques', 'Technology', 'Texture', 'Tissue Model', 'Tissues', 'Work', 'X-Ray Computed Tomography', 'analytical method', 'base', 'cardiac plaque', 'clinical application', 'clinical care', 'clinical practice', 'computerized', 'computerized tools', 'cost', 'cost efficient', 'deep learning', 'design', 'detector', 'dosimetry', 'experimental study', 'human imaging', 'human subject', 'improved', 'insight', 'learning strategy', 'photon-counting detector', 'prototype', 'quantitative imaging', 'simulation', 'soft tissue', 'tool', 'virtual', 'virtual imaging']",NIBIB,DUKE UNIVERSITY,R01,2020,545403,0.012051260474313175
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9924591,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Oncology', 'Organ', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'kinetic model', 'novel', 'parametric imaging', 'predicting response', 'programmed cell death ligand 1', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2020,679852,0.017422856912198446
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,10137354,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Oncology', 'Organ', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'kinetic model', 'novel', 'parametric imaging', 'predicting response', 'programmed cell death ligand 1', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2020,149331,0.017422856912198446
"Optimization of PET Image Reconstruction for Lesion Detection Optimization of PET Image Reconstruction for Lesion Detection Abstract PET is a molecular imaging modality widely used in oncology studies due to its high sensitivity and the potential of early diagnosis. For neuroendocrine tumors (NETs), 68Ga-DOTATATE PET has been recently used in clinical routine for imaging NETs in adult and pediatric patients since 2016. It plays an important role in the diagnosis and staging of NETs. However, compared to 18F-FDG PET, the image quality of 68Ga-DOTATATE PET is lower due to much larger positron range, shorter half-life, and lower dose administration limited by generator capacity. All of these compromises the lesion detectability of 68Ga-DOTATATE PET, especially for small lesions, and can potentially lead to inaccurate NET diagnosis. As 68Ga-DOTATATE PET is increasingly used in clinics, there is an urgent and unmet need to further optimize 68Ga-DOTATATE PET/CT imaging for NET detection. Recently, data-driven methods have been developed for PET image denoising, where the PET system model is not considered. As the tumor-to-background ratio of 68Ga-DOTATATE PET is greater than 18F-FDG PET, the lesion recovery of 68Ga-DOTATATE PET can be hugely influenced by the smoothing effects as well as potential mismatches between training and testing datasets. In this study, we propose a novel data- informed and lesion detection-driven image reconstruction framework. The PET system model, image denoising module, and lesion-detection module will all be included in this reconstruction framework. The two specific aims of this exploratory proposal are (1) to develop a lesion detection-driven PET image reconstruction framework and validate it based on comprehensive computer simulations, (2) to apply the proposed reconstruction framework to existing clinical 68Ga-DOTATATE PET/CT datasets and test it based on various figure-of-merits. We expect that the integrated outcome of the specific aims will be a novel and robust image reconstruction framework to better recover lesions in a 68Ga- DOTATATE PET scan, which is essential for NET managements. Optimization of PET Image Reconstruction for Lesion Detection  Project Narrative Positron emission tomography (PET) is an imaging modality widely used in oncology. This project aims to develop a novel lesion detection-driven PET image reconstruction framework. Success of this project can enhance the lesion detectability of current PET imaging protocols, e.g. 68Ga-DOTATATE PET/CT scanning for neuroendocrine tumors (NETs).",Optimization of PET Image Reconstruction for Lesion Detection,10041119,R03EB030280,"['Address', 'Adult', 'Algorithms', 'Awareness', 'Biological Models', 'Clinic', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Distant Metastasis', 'Dose', 'Early Diagnosis', 'Enhancing Lesion', 'FOLH1 gene', 'Gallium', 'Goals', 'Half-Life', 'Image', 'Incidence', 'Injections', 'Label', 'Lead', 'Lesion', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neuroendocrine Tumors', 'Noise', 'Oncology', 'Outcome', 'Output', 'Patients', 'Performance', 'Phase', 'Physics', 'Play', 'Positron', 'Positron-Emission Tomography', 'Prevalence', 'Protocols documentation', 'Radionuclide Imaging', 'Reader', 'Recovery', 'Recurrence', 'Resolution', 'Role', 'Savings', 'Sensitivity and Specificity', 'Staging', 'Testing', 'Time', 'Tracer', 'Training', 'United States', 'Validation', 'Vendor', 'X-Ray Computed Tomography', 'base', 'cancer type', 'deep learning', 'denoising', 'effectiveness validation', 'experience', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'learning strategy', 'molecular imaging', 'neural network', 'neuroendocrine differentiation', 'novel', 'outcome forecast', 'pediatric patients', 'pentetreotide', 'radiologist', 'radiotracer', 'reconstruction', 'routine imaging', 'success', 'treatment optimization', 'treatment planning', 'tumor']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R03,2020,94255,0.014656160639809783
"Multi-Task MR Simulation for Abdominal Radiation Treatment Planning ABSTRACT The accuracy of radiation treatment planning (RTP) heavily influences the effectiveness of external beam radiotherapy (EBRT). Individualized RTP begins with a “simulation”, in which the patient in a treatment position is commonly scanned using computed tomography (CT) to define the treatment target and organs at risk (OARs). When soft-tissue contrast is inadequate to support accurate target and OAR delineation in CT based RTP, conservatively large treatment margins are used to avoid a geometric miss. The crude treatment prevents delivering sufficient radiation dose to the tumor without exceeding the tolerance of surrounding normal tissues. Magnetic resonance (MR) can be used as a simulation platform complementary to CT for improved soft-tissue conspicuity. Yet, such a complicated, costly and tedious multi-modal RTP workflow along with unavoidable systematic MR-CT co-registration errors has limited its applications in EBRT, especially at the abdominal site whereby anatomies are highly mobile. Over the past few years, there is a keen interest in the integration of MR alone into RTP and even the therapy workflow (i.e. MR-guided radiotherapy, MRgRT). The abdomen poses critical challenges to MR simulation. Current MR imaging sequences are suboptimal to produce motion-free images and resolve respiratory motion. MR data processing for abdominal RTP is underdeveloped. Contouring of OARs typically relies on manual, tedious procedures that are time-consuming and variation-prone. In this proposal, we will substantially improve the MR acquisition and multi-organ auto-segmentation, so the potential of MR as a simulation modality can be fully unleashed for abdominal EBRT. Three specific aims will be completed. In Aim 1, we will develop a standalone multi-task MR (MT-MR) sequence dedicated to abdominal MR simulation. In Aim 2, we will optimize multi-organ auto-segmentation based on MT-MR images. In Aim 3, we will assess the performance of MT-MR in the context of pancreatic cancer stereotactic body radiotherapy planning. Successful completion of the project will dramatically improve treatment precision and clinical outcomes, thus further promoting the adoption of radiotherapy in the management of abdominal cancers. Moreover, the developed techniques will open the door to future studies aiming at optimizations in many aspects of radiotherapy. PROJECT NARRATIVE Imaging is essential for precise radiation treatment planning. MR based planning is challenging in the abdomen whereby anatomies are highly mobile. We will substantially improve the MR acquisition and multi-organ auto- segmentation, so the potential of MR as an imaging-based planning modality can be fully unleashed for abdominal radiation treatment.",Multi-Task MR Simulation for Abdominal Radiation Treatment Planning,10053211,R01EB029088,"['3-Dimensional', '4D MRI', 'Abdomen', 'Adoption', 'Agreement', 'Algorithms', 'Anatomy', 'Breathing', 'Clinical', 'Consumption', 'Data', 'Data Collection', 'Development', 'Dose', 'Effectiveness', 'Fatty acid glycerol esters', 'Future', 'Geometry', 'Goals', 'Image', 'Institution', 'Interobserver Variability', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of abdomen', 'Malignant neoplasm of pancreas', 'Manuals', 'Methods', 'Modality', 'Motion', 'Normal tissue morphology', 'Organ', 'Outcome', 'Patients', 'Performance', 'Phase', 'Planning Techniques', 'Positioning Attribute', 'Precision therapeutics', 'Procedures', 'Protons', 'Radiation Dose Unit', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Site', 'Solid', 'Study Subject', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Translations', 'Variant', 'Water', 'Weight', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'computerized data processing', 'contrast imaging', 'cost', 'deep learning', 'density', 'experience', 'image reconstruction', 'improved', 'interest', 'multimodality', 'multitask', 'novel', 'prevent', 'reconstruction', 'respiratory', 'segmentation algorithm', 'simulation', 'soft tissue', 'success', 'treatment planning', 'tumor']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R01,2020,556712,-0.014178074565045148
"Enabling the Next Generation of High Performance Pediatric Whole Body MR Imaging Project Abstract Motivation: We aim to develop and implement a new approach to transform pediatric MRI. The ultimate goal is ultra-fast and motion-robust imaging in a dedicated child-friendly environment to enable more children undergo MRI without anesthesia. For those who still require anesthesia, it will be briefer and lighter, and performed in a safer environment. This project leverages a small compact magnet, designed for adult brain MRI, with gradients that enable very fast imaging. With this magnet as an outstanding starting point, we will tailor our deep experience and multiple successes in developing new MRI approaches to high-density receiver coils, fast imaging sequences, and new image reconstruction methods to set a new standard for pediatric MRI. Approach: Although the compact scanner is designed for adult heads, with a 37 cm inner diameter, it can accommodate children under eight to ten years of age to image any body part. To transform this system for ideal pediatric scanning, three development aims will be pursued. The ﬁrst is to enable optimal signal reception. This will be accomplished through creating new receive chain electronics that are matched to the gradient capabilities, for ultra-high bandwidth imaging. This will be coupled to very thin and formed receive arrays that maximize the size of the patient that can be accommodated in the small bore of the scanner. The second aim is to develop methods of obtaining the highest performance out of the system by characterizing and correcting for its imperfections. This will be coupled to a bespoke approach to peripheral nerve stimulation, enabling maximal use of the gradients on each patient. These two developments will then be leveraged for high efﬁciency and motion robust noncartesian scanning. The ﬁnal aim is to develop a full environment and infrastructure that is well suited to pediatric imaging. Patient preparation and acclimation to MRI will be enhanced by virtual reality. Support equipment for anesthesia, new physiological sensors, and a novel child-friendly audiovisual system will be created. Signiﬁcance: The result of this project will be a revolutionary change in the way that MRI is used and per- formed for children. MRI will be more available, cheaper, safer, and have markedly improved image quality. Project Narrative We will leverage the outstanding magnet and gradients of a unique small bore MRI scanner to create a new standard for unprecedented whole-body pediatric MR imaging. We will develop, integrate, and validate a set of technologies speciﬁcally for pediatric imaging. These include ultra-high bandwidth MRI signal reception from thin form-ﬁtting hardware, high-speed image data acquisition and image reconstruction, and environmental support appropriate for children.",Enabling the Next Generation of High Performance Pediatric Whole Body MR Imaging,9944392,U01EB029427,"['10 year old', '8 year old', 'Acclimatization', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Anesthesia procedures', 'Body part', 'Brain', 'Caliber', 'Caregivers', 'Child', 'Child Health', 'Childhood', 'Cone', 'Coupled', 'Custom', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Electrocardiogram', 'Electronics', 'Environment', 'Equipment', 'Flare', 'Goals', 'Head', 'Image', 'Immersion', 'Infrastructure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Morphologic artifacts', 'Motion', 'Motivation', 'Noise', 'Partner in relationship', 'Patients', 'Pediatrics', 'Performance', 'Peripheral Nerve Stimulation', 'Physiologic pulse', 'Physiological', 'Preparation', 'Radiation', 'Resolution', 'Respiration', 'Role', 'Scanning', 'Side', 'Signal Transduction', 'Speed', 'Support System', 'System', 'T2 weighted imaging', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Thinness', 'Time', 'Vendor', 'base', 'commercialization', 'contrast imaging', 'data acquisition', 'density', 'design', 'digital', 'experience', 'hemodynamics', 'image reconstruction', 'imaging capabilities', 'imaging system', 'improved', 'innovation', 'next generation', 'novel', 'novel strategies', 'open source', 'pediatric patients', 'reconstruction', 'respiratory', 'sensor', 'success', 'tool', 'virtual reality', 'whole body imaging']",NIBIB,STANFORD UNIVERSITY,U01,2020,887058,-0.012164237130104
"Section on High Resolution Optical Imaging Subproject #1  Selective Plane Illumination Microscopy for nematode neurodevelopment and minimally invasive in vivo imaging  Selective plane illumination microscopy (SPIM (1)) is a technique whereby a sample is illuminated with a thin plane of light from the side, so that fluorescence detection occurs in a direction perpendicular to excitation. Such an experimental geometry has major advantages over conventional 3D microscopy techniques, such as confocal or 2 photon microscopy. First, acquisition speed is greatly increased relative to point-scanning methods, as the entire imaging plane is detected simultaneously. Second, excitation is confined to the focal plane, so each pixel is imaged only once during each volumetric acquisition. This drastically reduces light exposure and results in far lower photobleaching and photodamage than is possible with conventional imaging techniques. These advantages have been applied to studying whole-animal (zebrafish, drosophila) embryogenesis, and to the measurement of calcium transients in tissue slices.   We are using our implementation of SPIM to construct the first atlas of neuronal positions and migrations in the developing nematode C. Elegans, in collaboration with extramural researchers Daniel Colon-Ramos (Yale University), Zhirong Bao (Memorial Sloan-Kettering Cancer Center), and William Mohler (University of Connecticut). Due to the greatly reduced light dosage, we imaged nematode embryogenesis at 30x the speed of the best available competing technology (spinning disk confocal microscopy), with equivalent signal-to-noise ratio. This advance enabled the visualization of fast neurodevelopmental events in vivo (2).   We have also constructed a second generation SPIM instrument, where illumination and detection is conducted along two perpendicular views (dual-view inverted selective plane illumination microscopy, diSPIM). The advantage of the diSPIM is that axial resolution is significantly increased by merging the results obtained from each view. This setup enables isotropic imaging with 330 nm, more than quadrupling axial resolution compared to our previous instrument. We can maintain this high spatial resolution while also operating the microscope at high frame rates, up to 200 Hz in 2D and 2 Hz in 3D (for a 50 plane volume). The microscope enables high resolution, 4D imaging with minimal photobleaching and photodamage in cells and small embryos (3, 4). We have now developed methods that further increase the resolution and sensitivity of diSPIM, by adding additional specimen views to the microscope (5).   In combination with hardware improvements, we have also collaborated with computer scientists at the NIH to develop new software tools, that enable the computational 'untwisting' of embryo data acquired with our diSPIM. This untwisting software has enabled us to track the relative orientations and positions of cells within the twitching embryo, thus enabling a systems-biology level view of the entire elongating worm embryo (6). An closely-related subproject is the development of software that renders, displays and disseminates the growing 4D atlas of cell positions that we are obtaining with our microscope (7). Finally, an emerging focus in the lab is the tracking of behavior and calcium flux (8) as the embryo develops.    Subproject #2  Increasing the speed and depth penetration of structured illumination microscopy  Structured illumination microscopy (SIM) is a super-resolution technique (9) that offers modest resolution improvement (2x better than the diffraction limit), but is readily compatible with live samples due to its low excitation intensities. SIM, while commercially available, is expensive and remains the province of relatively few labs. Furthermore, commercial SIM systems are limited to samples with thickness < 10 microns, as they do not physically reject background light. Together with Chris Combs (NHLBI), we developed a multifocal version of SIM (MSIM) that uses the confocal effect to image samples > 50 micronsfrom the coverslip surface while maintaining resolution-doubling capability (10).   We have also developed an MSIM implementation that improves the speed of acquisition 100-fold, by performing most of the computational processing operations entirely in hardware (instant SIM, (11). We have also developed a point-scanning, multiphoton version of the instant SIM that better depth penetration (12, 13) than the single-photon implementation, and continue to work on further pushing the depth penetrance by integrating adaptive optics into the microscope (14). We actively seek collaborators in order to apply these systems to biology.   (1) Huisken, J., Swoger, J., Del Bene, F., Wittbrodt, J. & Stelzer, E. H. K. Optical sectioning  deep inside live embryos by selective plane illumination microscopy. Science 305, 1007-9 (2004).  (2) Wu, Y. et al. Inverted selective plane illumination microscopy (iSPIM) enables coupled cell identity lineaging and neurodevelopmental imaging in Caenorhabditis elegans. Proc. Natl. Acad. Sci. USA 108, 17708-17713 (2011).  (3) Wu, Y., Wawrzusin, P., Senseney, J., Fischer, R.S., Christensen, R., Santella, A., York, A.G., Winter, P.W., Waterman, C.M., Bao, Z., Colon-Ramos, D., McAuliffe, M., Shroff, H. Spatially isotropic four-dimensional imaging with dual-view plane illumination microscopy. Nat. Biotechnol. 31, 1032-8 (2013).  (4) Kumar, A., Wu, Y., Christensen, R., Chandris, P., Gandler, W., McCreedy, E., Bokinsky, A., Colon-Ramos, D.A., Bao, Z., McAuliffe, M., Rondeau, G., Shroff, H. Assembly and use of dual-view inverted plane illumination microscope for rapid, spatially isotropic four-dimensional imaging. Nature Protocols 9(11):2555-73 (2014).   (5) Wu, Y., Chandris, P., ,Winter, P.W., Kim, E.Y., Jaumouille, V., Kumar, A., Guo, M., Leung, J.M., Smith, C., Rey-Suarez, I., Liu, H., Waterman, C.M., Ramamurthi, K.S., LaRiviere, P., Shroff, H. Simultaneous multi-view capture and fusion improves spatial resolution in wide-field and light-sheet microscopy. Optica, 8 897-910 (2016).  (6) Christensen, R., Bokinsky, A., Santella, A., Wu, Y., Marquina-Solis, J., Guo, M., Kovacevik, I., Kumar, A., Winter, P.W., Tashakkori, N., McCreedy, E., Liu, H., McAuliffe, M., Mohler, W., Colon-Ramos, D.A., Bao, Z., Shroff, H. Untwisting the Caenorhabditis elegans embryo. eLife 10070 (2015).   (7) Santella A., et al. WormGUIDES: an interactive single cell developmental atlas and tool for collaborative multidimensional data exploration. BMC Bioinformatics. 16:189 (2015).  (8) Ardiel E., et al. Visualizing Calcium Flux in Freely Moving Nematode Embryos. Biophys J. 112(9):1975-1983.  (9) Gustafsson, M.G. Surpassing the lateral resolution limit by a factor of two using structured illumination microscopy. J Microsc. 198, 82-7 (2000).  (10) York, A.G. et al. Resolution Doubling in Live, Multicellular Organisms via Multifocal Structured Illumination Microscopy. Nat. Methods 9, 749-754 (2012).   (11) York, A.G., Chandris, P., Dalle Nogare, D., Head, J., Wawrzusin, P., Fischer, R.S., Chitnis, A., Shroff, H. Instant super-resolution imaging in live cells and embryos via analog image processing. Nat. Methods 10, 1122-6 (2013).  (12) Winter, P., York, A.G., Dalle Nogare, D., Ingaramo, M., Christensen, R., Chitnis, A., Patterson, G.H., Shroff, H. Two-photon instant structured illumination microscopy improves the depth penetration of super-resolution imaging in thick scattering samples. Optica 1(3):181-191 (2014).  (13) Winter PW, Chandris P, Fischer RS, Wu Y, Waterman CM, Shroff H. Incoherent structured illumination improves optical sectioning and contrast in multiphoton super-resolution microscopy. Opt Express. 23(4):5327-34 (2015).   (14) Zheng, W., et al. Adaptive optics improves multiphoton super-resolution imaging. Nat. Methods Nat Methods. 2017, AOP n/a",Section on High Resolution Optical Imaging,10262998,ZIAEB000074,"['3-Dimensional', '4D Imaging', 'Animals', 'Atlases', 'Behavior', 'Bioinformatics', 'Biology', 'Caenorhabditis elegans', 'Calcium', 'Cells', 'Collaborations', 'Colon', 'Comb animal structure', 'Computer Models', 'Computer software', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'Connecticut', 'Coupled', 'Coupling', 'Data', 'Detection', 'Development', 'Drosophila genus', 'Embryo', 'Embryonic Development', 'Ensure', 'Event', 'Extramural Activities', 'Fluorescence', 'Fluorescence Microscopy', 'Generations', 'Geometry', 'Goals', 'Head', 'Image', 'Imaging Techniques', 'Laboratories', 'Lateral', 'Light', 'Lighting', 'Measurement', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Microscopy', 'Mission', 'National Heart, Lung, and Blood Institute', 'Nature', 'Nematoda', 'Neurons', 'Noise', 'Optics', 'Organism', 'Penetrance', 'Penetration', 'Photobleaching', 'Photons', 'Positioning Attribute', 'Protocols documentation', 'Province', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Side', 'Signal Transduction', 'Slice', 'Software Tools', 'Specimen', 'Speed', 'Structure', 'Surface', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Thick', 'Thinness', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Virus Receptors', 'Visualization', 'Work', 'Zebrafish', 'adaptive optics', 'analog', 'biological systems', 'data exploration', 'deep learning', 'denoising', 'dosage', 'heme receptor', 'image processing', 'improved', 'in vivo', 'in vivo imaging', 'instrument', 'instrumentation', 'learning strategy', 'migration', 'minimally invasive', 'multidimensional data', 'neurodevelopment', 'novel', 'operation', 'optical imaging', 'release of sequestered calcium ion into cytoplasm', 'restoration', 'software development', 'spatiotemporal', 'temporal measurement', 'three dimensional structure', 'three-dimensional visualization', 'tool', 'trafficking', 'two photon microscopy', 'two-photon']",NIBIB,NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING,ZIA,2020,1210000,-0.0033985341676060687
"Permeability Imaging using Simultaneous Dynamic PET and Arterial Spin Labeling MRI Abstract Candidate's Career Goals: Dr. Han has a strong background in magnetic resonance (MR) imaging, image reconstruction and arterial spin labeling (ASL), with a Ph.D. in bio and brain engineering. Dr. Han is currently at a junior-faculty rank of instructor at Massachusetts General Hospital (MGH). His goal is to expand his future career to multi-modality positron emission tomography (PET)-MR imaging for translational research and clinical improvement. His long-term goal is to become an independent, accomplished investigator that can lead future scientific and clinical imaging projects taking full advantage of multi-modality PET-MR imaging. Career Development Plan: Foundational training in PET/PET-MR imaging as well as neurology is proposed for the candidate, an area that the candidate currently lacks knowledge and experience in. The candidate plans to engage in formal course work/seminars, research via one-on-one instructions with mentors and collaborators, conferences/presentations, manuscript/grant preparations, and teaching/leadership roles to grow as an independent investigator in the field of PET-MR imaging and neurology. Research Project: The overall goal of the proposed research is to take advantage of simultaneous dynamic PET and ASL-MR imaging to estimate the permeability surface product (PS) of the PET tracer, which is new physiological information that cannot be obtained with PET or MR alone. PS describes the unidirectional flux rate of macromolecules from the blood plasma into the interstitial space of cellular tissue and is the key metric for assessing the integrity of the blood-brain barrier (BBB). Knowing the PS of the PET tracer provides powerful capability to probe the physiological delivery process of essential macromolecules involved in the pathogenesis of diseases in relation to BBB, due to the theoretically unlimiting potential in the design of radioactive analogs of important biological compounds. We plan to develop a PET tracer PS mapping method, achieve the first phantom and human study with PS mapping, and study the changes in the spatial distribution of tau neurofibrillary tangles (tau) and amyloid-beta (Aß) plaque depositions in relation to the BBB integrity changes with pathological events associated with the progression of AD, by performing dynamic-PET/mPLD-ASL studies using 18F-T807 and 11C- Pittsburgh compound B (PiB) PET tracers on AD and normal subjects. Environment: MGH provides an ideal setting for conducting research in MR, PET, and PET-MR imaging since multiple state-of-the-art imaging systems are available for preclinical/clinical MR scanners and preclinical simultaneous PET-MR scanners. There is a dynamic flow phantom designed to simulate blood flow for two compartment pharmacokinetics and an MR-compatible pump and detection system for continuous blood sampling suitable for performing ASL flow and PET imaging studies with arterial sampling. Also, there is a shared memory supercomputer ideal for the image reconstruction proposed in the project. MGH is also home to many experts in both PET-MR imaging and neurology who can provide their expertise to this project. Narrative The overall goal of the proposed research is to take advantage of simultaneous dynamic positron emission tomography (PET) and arterial spin labeling (ASL) magnetic resonance imaging (MRI) to estimate the permeability surface product (PS) of the PET tracer, which is new physiological information that cannot be obtained with PET or MR alone. Knowing the PS of the PET tracer provides powerful capability to probe the physiological delivery process of essential macromolecules involved in the pathogenesis of diseases in relation to blood-brain barrier (BBB), due to the theoretically unlimiting potential in the design of radioactive analogs of important biological compounds (e.g., glucose, amino-acids or proteins). If successful, the proposed technique will allow the extraction of new physiological information, PS, while facilitating a new understanding of the relationships between BBB integrity, neurovascular function and proteinopathy in the etiology and progression of diseases such as AD.",Permeability Imaging using Simultaneous Dynamic PET and Arterial Spin Labeling MRI,10039839,K01EB030045,"['3-Dimensional', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Amino Acids', 'Amyloid beta-Protein', 'Anatomy', 'Area', 'Base Sequence', 'Biological', 'Blood - brain barrier anatomy', 'Blood flow', 'Blood specimen', 'Brain', 'Clinical', 'Cognitive', 'Data', 'Deposition', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Drug Kinetics', 'Educational process of instructing', 'Engineering', 'Environment', 'Etiology', 'Event', 'Faculty', 'Foundations', 'Functional disorder', 'Future', 'General Hospitals', 'Glucose', 'Goals', 'Grant', 'Home environment', 'Image', 'Imaging Device', 'Instruction', 'Kinetics', 'Knowledge', 'Label', 'Lead', 'Leadership', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuscripts', 'Maps', 'Massachusetts', 'Measurement', 'Mentors', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Multimodal Imaging', 'Neurology', 'Noise', 'Pathogenesis', 'Pathologic', 'Performance', 'Permeability', 'Physiological', 'Pittsburgh Compound-B', 'Plasma', 'Play', 'Positron-Emission Tomography', 'Preparation', 'Process', 'Proteins', 'Pump', 'Radial', 'Radioactive', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Senile Plaques', 'Spatial Distribution', 'Spin Labels', 'Surface', 'System', 'Techniques', 'Time', 'Tissues', 'Tracer', 'Training', 'Translational Research', 'Work', 'analog', 'attenuation', 'base', 'career', 'career development', 'clinical imaging', 'deep learning', 'design', 'experience', 'human study', 'image reconstruction', 'imaging modality', 'imaging study', 'imaging system', 'improved', 'instructor', 'interstitial', 'macromolecule', 'multimodality', 'neurovascular', 'novel', 'pre-clinical', 'reconstruction', 'shared memory', 'supercomputer', 'symposium', 'tau Proteins', 'tau aggregation']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K01,2020,123012,-0.007023647320261813
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,10011565,K01DK110136,"['3-Dimensional', 'Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Consumption', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'automated segmentation', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2020,154915,0.006105706688597255
"Signal Processing And Instrumentation Section The research and development activities of the Signal Processing and Instrumentation Section (SPIS) are collaborative efforts with NIH Institute scientists that require the development of biomedical laboratory and clinical research systems, instrumentation, and methodologies. The majority of these collaborations require novel approaches and designs for which there are minimal established criteria or technical knowledge. SPIS staff have in-depth technical experience in all phases of engineering research and development. With their collaborators, SPIS staff review the clinical and biomedical sciences to formulate project specifications. SPIS staff evaluate the theoretical and practical constraints, consider commercially available technologies, and finally propose various solutions. SPIS responsibilities often continue with the hands-on design, implementation, testing, installation, training, documentation, and production of a custom research system or methodology. Current collaborative projects, as well as associated research studies include:  1.	2D Microfluidic Device Setup to Combine the Controlled Delivery of Oxygen with Real-Time Measurement of Intracellular Oxygen Concentration and Metabolism in vitro; NCI, NHLBI, NIBIB 2.	3D Printed Tenodesis Type Action Hand Prosthesis for Pediatric Rehabilitation; CC 3.	3D Printing Applications in Analytical Ultracentrifugation Technologies; NIBIB 4.	3D QR Code-like Cuboid as a Proposed Measurement Standard; CC 5.	3D-printed Mold to Generate Agarose Cavities for Mouse Embryo Dissection; CC 6.	An ex vivo Model using Human Peritoneum for Primary and Metastatic Cancer or Human Mesothelial Surfaces; NCI 7.	Assistive Fiber Optic Implant Holder for Mouse Surgery; NIAAA 8.	Augmented Reality Application for Interactive Enhancements for Scientific Data Visualization and Manipulation; NICHD 9.	Automation of Tissue Staining Pipeline for Multiplex Antibody Assays and Histopathology; NCI 10.	C. Elegans Embryo Tracking in Temporal SPIM Volumetric Images; NIBIB 11.	Characterizing Spontaneous Movements During Early Development of Mice; NIMH 12.	COVID-19 Autopsy Containment Box; NCI, NIMH 13.	CT Lung Visualization using VR/AR Technology; CC, UMBC 14.	Custom-made Macaque Brain Molds to Correlate MR Imaging to Whole-brain Histology; NICHD 15.	Development and Characterization of a Handheld Diffuse Optical Spectroscopy System; NICHD 16.	Development of Advanced Analytical Ultracentrifugation Fluorescence Detectors and Acquisition Systems to Study the Dynamics of Protein Assemblies; NIBIB 17.	Development of Ear Savers to Reduce Ear Strain from Face Masks for COVID-19 Pandemic; CC, NCI, OD 18.	Development of Multi-modality Imaging Techniques; NICHD, NCI 19.	Development of Multi-Well Incubation Chamber for Rodent Brain Tissue Studies; NIMH 20.	Diffusion Exchange Functional MRI; NICHD 21.	Evaluation of 3D-printed Nasopharyngeal Swabs to Address COVID Supply Shortages; NIAID, Childrens National, WRNMMC 22.	Evaluation of a Novel Cognitive Testing Framework for Individuals with Severe Cognitive Impairment; NIMH 23.	Fetal Brain DWI Imaging, Reconstructions, and 3D Rendering/Analysis; NICHD 24.	Functional Near Infrared Spectroscopy System (fNIRS) for Brain Imaging; NICHD 25.	Hands-free 3D-printed Door Opener to Minimize Spread of Coronavirus; NCI 26.	Home-Cage Monitoring Device for Learning and Memory; NIDDK 27.	Illumination Control System for Mouse Visual Cycle Studies Relating to Retinal Dystrophies; NEI 28.	Imaging Flow in Capillary Structures with Low Flowrates and Veinous like Exchange; NICHD 29.	Imaging/Interrogation of Metastatic Colonization in Perfused Resected Liver; NCI, NIBIB 30.	Implementation of a Novel Tumor Model System for Interrogation of the Metastatic Cascade and Drug Development; NCI 31.	Implementation of Augmented Reality in MRI Guided Prostate Biopsies; NCI, CC 32.	Improved Restricted Exchange Environmental Chamber (REEC); NCI, NIBIB 33.	Improved Transurethral Resection (TUR) Device; NCI 34.	Instrumentation Design and Fabrication with NIMH and NINDS; NIMH 35.	Instrumentation to Measure Response Properties of Somatosensory Neurons; NCCIH 36.	Internet Devices for Improving Animal Care (IDIA-Care) - Cloud Analytics for Research Environments; NIDDK, OD, FDA 37.	Intra-vital Microscopy Using Non-linear Optical Techniques; NHLBI 38.	Investigation of Pituitary Tumors and Related Hypothalamic Disorders using Multi-modality Imaging Techniques; NICHD 39.	Investigation of Short- and Long-term Effects of COVID-19 on Cognitive Functions; NICHD 40.	Laser Welder for Sterile Filling of Tubing for Hyperpolarized MRI Experiments; NCI, CC 41.	Methods for Soft Tissue Prostate Procurement using Patient-specific MRI-based Guiding Fixture; NCI 42.	Microfabricated Polymeric Vessel Mimetics for Cancer Cell Culture; NCI, NIBIB 43.	Microfluidics; Microfabrication; and Microanalysis Technologies for Biomedical Research; NIBIB 44.	Mirror Neuron Network Dysfunction as an Early Biomarker of Neurodevelopmental Disorder; NICHD 45.	Mouse Catheterization Holder to Instill Bladder Tumor Cells into the Bladder; NCI 46.	Mouse Whisker Tracking and Texture Preference for Brain Neural Circuit Studies (Behavior Box & Fixed-head Condition); NIMH 47.	MRI Elastography for Anisotropic Materials; NICHD 48.	Multimodal Nonlinear Microscopy with Spectral-focusing CARS and Stimulated Emission; NHLBI 49.	Next Generation Electroconvulsive Therapy (ECT) System; NIMH 50.	NIH Equipment Monitoring System; NIDDK, NIAID, NHLBI 51.	OCT - Adaptive Optics Retinal Imaging with Eye Tracking; NEI 52.	Pellet Culture (3D) Bioreactor for In Vitro Cultivation of Bone Growth Plate Cartilage Tissue; NICHD 53.	Portable Fluorescence Camera System for Offsite Ovarian Tumor Imaging; NCI, University of Tokyo 54.	Portable Low-Field Magnetic Resonance Imager; NICHD 55.	PRiME: Physiological Recording in MRI Environment for Cardiovascular Intervention; NHLBI, Children's National, Children's Hospital Dallas, UC San Diego Children's Hospital, PinMed Inc 56.	Prostate Methods Correlating Multiparametric MRI with Histopathology of Prostatectomy Specimens using Patient-specific MRI-based Prostate Mold; NCI 57.	Rapidscan Continuous Wave Electron Paramagnetic Resonance Imaging of Nitroxide Reduction for Redox Status of Tissue; NCI 58.	Real-time Oximetry of Anterior Placenta Using Near Infrared Spectroscopy; NICHD 59.	Rodent Arena Tracker (RAT); NIDDK 60.	Self-Collection Homebased Biosensor for Monitoring and Tracking Suspected COVID-19 Patients; NICHD 61.	SLO - Adaptive Optics Retinal Imaging with Eye Tracking; NEI 62.	System for Continuous Observation of Rodents in Home-cage Environment (SCORHE):  NCI, NHLBI, NIDDK, NIEHS, NINDS, FDA 63.	System to Measure Rodent Vestibular Sensory Evoked Potentials; NIDCD 64.	Therapeutic Application of Induced Electromagnetic Fields (EMFs) to Reduce Cell Growth and Migration in Glioblastoma Multiforme (GBM); NICHD, NCI, NINDS, NIBIB, Celopics Inc 65.	Time Domain Electron Paramagnetic Resonance Imaging of Oxygen Status Corresponding to Cancer Treatments; NCI 66.	Tissue Microdissection for Macromolecular Analysis of Normal Development and Pathology; NICHD, NIBIB, NCI, XMD Diagnostics LLC 67.	Using Light-sheet Microscopy to Understand Evoked Motor Sequence Generation in Drosophila; NIMH, NIBIB 68.	Video Acquisition of Mouse Locomotion and Motor Stability when Impacted by Chemogenetic Stimulation; NINDS 69.	Video Analysis System for Behavior and Activity Assessment of Fruit-Flies in High-Throughput Studies; NIDDK, NHLBI 70.	Video Monitoring System for Automated Detection of Pain Related Mice Behaviors; NIDDK 71.	Video-Based Breathing Rate Detection for COVID-19 Hamsters; FDA 72.	Walk-away Radiochemistry Laboratory Automation; NIAAA 73.	X-clometer - New Radiographic Marker; CC n/a",Signal Processing And Instrumentation Section,10253704,ZIACT000261,"['3-Dimensional', '3D Print', 'Address', 'Advanced Development', 'Anterior', 'Antibodies', 'Augmented Reality', 'Automation', 'Autopsy', 'Behavior', 'Biological Assay', 'Biological Models', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Bioreactors', 'Biosensor', 'Bladder', 'Bladder Neoplasm', 'Blood capillaries', 'Bone Growth', 'Brain', 'Brain imaging', 'Breathing', 'COVID-19', 'COVID-19 pandemic', 'Caenorhabditis elegans', 'Cardiovascular system', 'Cartilage', 'Catheterization', 'Cell Culture Techniques', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Code', 'Collaborations', 'Collection', 'Communication', 'Computers', 'Containment', 'Coronavirus', 'Custom', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diagnostic radiologic examination', 'Diffuse', 'Diffusion', 'Dissection', 'Disseminated Malignant Neoplasm', 'Documentation', 'Drosophila genus', 'Ear', 'Electroconvulsive Therapy', 'Electromagnetic Fields', 'Electron Spin Resonance Spectroscopy', 'Electronics', 'Embryo', 'Engineering', 'Environment', 'Epiphysial cartilage', 'Equipment', 'Evaluation', 'Evoked Potentials', 'Fiber Optics', 'Fluorescence', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Generations', 'Genomics', 'Glioblastoma', 'Hamsters', 'Hand', 'Head', 'Histology', 'Histopathology', 'Home environment', 'Human', 'Hypothalamic Diseases', 'Image', 'Imaging Techniques', 'Impaired cognition', 'Implant', 'In Vitro', 'Incubators', 'Individual', 'Infrastructure', 'Institutes', 'Internet', 'Intervention', 'Intramural Research Program', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Lasers', 'Learning', 'Light', 'Lighting', 'Liver', 'Locomotion', 'Long-Term Effects', 'Lung CAT Scan', 'Macaca', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Memory', 'Metabolism', 'Methodology', 'Methods', 'Microdissection', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Microscopy', 'Mobile Health Application', 'Modeling', 'Molds', 'Monitor', 'Motor', 'Movement', 'Multimodal Imaging', 'Mus', 'National Heart, Lung, and Blood Institute', 'National Institute of Allergy and Infectious Disease', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'National Institute of Environmental Health Sciences', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'National Institute on Deafness and Other Communication Disorders', 'Near-Infrared Spectroscopy', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Optics', 'Oxidation-Reduction', 'Oxygen', 'Oxygen saturation measurement', 'Pain', 'Pathology', 'Patients', 'Pediatric Hospitals', 'Peritoneum', 'Phase', 'Physiological', 'Pituitary Neoplasms', 'Placenta', 'Polymers', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Production', 'Property', 'Prostate', 'Prostatectomy', 'Protein Dynamics', 'Proteomics', 'Radiochemistry', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resected', 'Resources', 'Retinal Dystrophy', 'Robotics', 'Rodent', 'Science', 'Scientist', 'Sensory', 'Sepharose', 'Signal Transduction', 'Software Engineering', 'Specimen', 'Spectrum Analysis', 'Sterility', 'Structure', 'Structure of base of prostate', 'Surface', 'Swab', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Tokyo', 'Training', 'Transurethral Resection', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vibrissae', 'Walking', 'adaptive optics', 'analog', 'analytical ultracentrifugation', 'animal care', 'base', 'bioimaging', 'brain tissue', 'cancer cell', 'cancer imaging', 'cancer therapy', 'cell growth', 'cell motility', 'cognitive function', 'cognitive testing', 'collaborative environment', 'coronavirus disease', 'data acquisition', 'data visualization', 'design', 'detector', 'digital', 'drug development', 'ear development', 'early detection biomarkers', 'elastography', 'engineering design', 'experience', 'experimental study', 'face mask', 'fetal', 'high reward', 'high risk', 'image reconstruction', 'imager', 'improved', 'innovation', 'instrument', 'instrumentation', 'intravital microscopy', 'lung visualization', 'machine vision', 'magnetic field', 'mimetics', 'mirror neuron', 'monitoring device', 'mouse development', 'multimodality', 'neoplastic cell', 'network dysfunction', 'neural circuit', 'next generation', 'novel', 'novel strategies', 'ovarian neoplasm', 'portability', 'precision medicine', 'preference', 'printed circuit board', 'programs', 'prostate biopsy', 'prosthetic hand', 'prototype', 'radio frequency', 'research and development', 'research study', 'response', 'retinal imaging', 'signal processing', 'soft tissue', 'software development', 'somatosensory', 'systems research', 'technology development', 'temporal measurement', 'theories', 'tumor', 'visual cycle', 'visual tracking']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2020,1967762,-0.03902575387189097
