text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,9887588,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2019,286435,0.004113719231277665
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9610628,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Infrastructure', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multi-task learning', 'multitask', 'new technology', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2019,224899,0.02572340386304208
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9783881,U01EB029373,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIBIB,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2019,611358,0.02554483911370747
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9666926,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'supervised learning', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2019,242725,0.03643956059637088
"Development of statistical genetics methodology We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies. In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Ongoing work has involved further research to improve control of false positive rates while retaining excellent power , adding approaches to increase power when number of features is very large and there are only interaction effects on risk of disease and comparison of our new methods to several other feature-selection schemes. We have also been developing and testing a new approach for specifically identifying which selected features are actually interacting as opposed to acting independently. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published three papers describing this method. We are currently developing The Machine Suite which will be an extension of r2VIM. A manuscript presenting the updates to our methods is under preparation and results will be presented at two upcoming scientific meetings.   We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Development of these analysis methods and tools are ongoing, driven by our own WES and WGS sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have worked on optimizing methods for performing multipoint analyses using extremely dense WES, WGS and exome chip data sets. Work is ongoing to improve pipelines for application of family-based methods for improved quality control in whole genome sequence data. Our WGS pipeline has been presented at several scientific meetings this past year.  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. Simulations are ongoing to compare our new methods to existing methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD and Dr. Chi-Yan Chiu (a Guest Researcher who is a faculty member at University of Tennessee Health Sciences Center), we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates.We have published multiple papers in this area in previous years and one paper has been published reporting these results has been published in this reporting period 1.  We have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. A manuscript reporting on our new approach and software has been published in this reporting period 2.  Finally we have continued a collaboration with Drs. Ingo Ruczinski and Alexander Bureau on approaches to identifying causal rare variants in pedigree data. We extended our existing methodology (Rare Variant Sharing, RVS) to introduce gene-based analyses, a partial sharing test based on RV sharing probabilities for subsets of affected relatives and a haplotype-based RV definition. RVS also has the desirable feature of not requiring external estimates of variant frequency or control samples, provides functionality to assess and address violations of key assumptions, and is available as open source software for genome-wide analysis.  We have published a paper reporting on this work this year 3. n/a",Development of statistical genetics methodology,10020054,ZIAHG000153,"['Address', 'Affect', 'African American', 'Area', 'Biological Models', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'European', 'Faculty', 'Family', 'Framingham Heart Study', 'Frequencies', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Health Sciences', 'Imagery', 'Individual', 'Linear Models', 'Machine Learning', 'Manuscripts', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Publishing', 'Quality Control', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scheme', 'Sequence Analysis', 'Statistical Methods', 'Structure', 'Tennessee', 'Testing', 'Universities', 'Update', 'Variant', 'Work', 'base', 'case control', 'caucasian American', 'classification trees', 'data mining', 'data warehouse', 'disorder risk', 'exome', 'flexibility', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'genome wide association study', 'genome-wide analysis', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'novel strategies', 'open source', 'oral cleft', 'programs', 'quality assurance', 'random forest', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2019,394536,-0.014645666313567672
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9774249,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2019,332952,0.020220525556682824
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9699440,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'machine learning algorithm', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2019,186101,-0.00422349120405517
"Development of New Genome Editing Agents Using RNA Modifying Enzymes Komor – Project Summary/Abstract - “Development of New Genome Editing Agents Using RNA Modifying Enzymes”  While targeted genome editing, the introduction of a specific modification in genomic DNA, has the potential to allow researchers to study and better understand mechanisms of human genetic diseases, traditional genome editing methods (including CRISPR-Cas9) that rely on the initial introduction of double stranded DNA breaks (DSB) suffer from modest genome editing efficiencies as well as unwanted gene alterations (indels), particularly when attempting to correct point mutations. Recently, a class of genome editing agents called single base editors was developed that does not involve DSBs, but rather uses a dCas9-tethered single-stranded DNA (ssDNA) modifying enzyme to directly chemically modify target nucleobases within a ~5 nucleotide window determined by the protospacer. Two classes of editors have been developed that use cytosine and adenine deamination chemistries to catalyze the conversion of C•G base pairs to T•A (CBEs), and A•T base pairs to G•C (ABEs), respectively. Here we propose the development and characterization of new base editors capable of facilitating new point mutations using methylation chemistry. We have use a bioinformatic approach to identify RNA modifying enzymes that have the potential to be repurposed into new base editors, and have rationally designed mutant libraries to use with directed evolution to convert these enzymes into base editors (Aim 1). Concurrently, we are developing a machine learning program that utilizes existing ssDNA modifying enzymes to identify putative mutations that will expand the substrate scope of the identified methyltransferases to ssDNA (Aim 2). Mutations identified from both strategies will then be tested and characterized for base editing in multiple orthogonal systems (Aim 3). The successful completion of the proposed work will represent a significant addition to existing base editing technologies, and will enable researchers to cleanly and efficiently install two additional types of point mutations into the genome of living cells, allowing researchers to quickly and effectively general model systems for the study of human genetic diseases. Komor – Project Narrative - “Development of New Genome Editing Agents Using RNA Modifying Enzymes” Base editing enables high efficiency genomic point mutation introduction in a variety of cell types and has the potential to allow researchers to better study human genetic diseases. We propose transformative improvements to current base editing technologies that will expand the types of point mutations that can be introduced by base editors. The tools developed here will enable researchers to cleanly and efficiently install additional types of point mutations into the genome of living cells for the study and potential treatment of human genetic diseases.",Development of New Genome Editing Agents Using RNA Modifying Enzymes,9876634,R21GM135736,"['Adenine', 'Adoption', 'Algorithms', 'Base Pairing', 'Bioinformatics', 'Biological Assay', 'Biological Models', 'CRISPR/Cas technology', 'Case Study', 'Cell Line', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Cytosine', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'Deamination', 'Development', 'Directed Molecular Evolution', 'Engineering', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Mutation', 'Generations', 'Genetic Diseases', 'Genome', 'Genomic DNA', 'Genomics', 'Human', 'Human Genetics', 'In Vitro', 'Individual', 'Inosine', 'Lesion', 'Libraries', 'Link', 'Machine Learning', 'Mammalian Cell', 'Measures', 'Mediating', 'Methods', 'Methylation', 'Methyltransferase', 'Modification', 'Mutation', 'Nucleotides', 'Pathogenicity', 'Point Mutation', 'Program Development', 'Proteins', 'Purines', 'Pyrimidine', 'RNA', 'Research Personnel', 'Single-Stranded DNA', 'Site', 'Specificity', 'System', 'Technology', 'Testing', 'Transfer RNA', 'Uracil', 'Variant', 'Work', 'adenosine deaminase', 'base', 'cell type', 'combat', 'design', 'genome editing', 'insertion/deletion mutation', 'machine learning algorithm', 'molecular dynamics', 'mutant', 'novel', 'nucleobase', 'preference', 'programs', 'tool', 'transition mutation', 'transversion mutation']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2019,205479,0.05205986619867981
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9766330,R01HG009188,"['Affect', 'Base Pairing', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'Custom', 'DNA', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Reproducibility', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'competitive environment', 'cost', 'enzyme activity', 'experimental study', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2019,468098,0.016954109677855923
"The adaptive potential of translational regulation Project Summary/Abstract  Our current understanding of the adaptive effects of mutation is largely limited to alterations in protein coding sequence and disruption of transcriptional cis-regulatory promoters. Very little is known about how mutations alter translation, or the role these mutations play in adaptation and evolution. This project seeks to address this gap by identifying the functional effect of mutations on translation. To accomplish this I will first identify mutations that arise from adaptation to various nutrient limited environments. I will then use expression profiling (e.g. RNA-seq, ribosome profiling, and RATE-seq) to identify the effect these mutations have on translation, as well as other levels of gene expression. This will provide insight into the magnitude of effect mutations have on translation and their relative rate. Furthermore, to fully characterize the role synonymous mutations have on fitness I will be using a deep scanning synonymous mutation library. To understand the role tRNA abundance plays in the fitness effect of a given synonymous mutations, I will also be evaluating fitness within tRNA under- and over-expression backgrounds. Because of the closely coupled nature of translation rates and mRNA decay, I will also characterize the effect synonymous mutations have on mRNA decay using RATE-seq. My analysis of the functional effects of these mutations on gene expression, particularly within the genetic background and environment in which they arose, will allow for the development of a machine learning algorithm that can use sequence and annotation features to predict the effect of a mutation on gene expression. This tool will aid future research into the effect mutations have of gene expression by allowing the identification of high-confidence candidates for further evaluation.  This project will be conducted at New York University’s Center for Genomics and Systems Biology, whose mission is to answer otherwise intractable biological questions using applied experimental and computational approaches. The Center houses numerous facilities and cores that will be instrumental in the performance of this work. The collaborative atmosphere and multi-disciplinary nature of NYU’s research communities that will enable me to stay abreast of developments in related fields and to rapidly communicate my research to interested parties. I will be trained under the guidance of Dr. David Gresham, an excellent researcher working on complementing long-term evolution experiments with gene expression studies to characterize the adaptive potential of the regulation of gene expression. Project Narrative The translation of mRNA into protein is a critical step in gene expression that is tightly regulated with mis-regulation of translation being a hallmark of many human pathologies. Understanding how mutations can alter the regulation of translation is an understudied but important aspect of adaptation and evolution. Ultimately, without an understanding of the adaptive potential of translation we have an incomplete, and imperfect, picture of the underlying genetic causes of numerous forms of cancer and genetic diseases.",The adaptive potential of translational regulation,9683394,F32GM131573,"['Address', 'Affect', 'Amino Acid Sequence', 'Biological', 'Biological Assay', 'Biology', 'Code', 'Communities', 'Complement', 'Computer software', 'Coupled', 'Data', 'Development', 'Disease', 'Elements', 'Environment', 'Evaluation', 'Evolution', 'Expression Profiling', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Translation', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Human Pathology', 'Laboratories', 'Libraries', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mission', 'Modeling', 'Modernization', 'Mutation', 'Nature', 'New York', 'Nutrient', 'Open Reading Frames', 'Pathology', 'Performance at work', 'Phenotype', 'Play', 'Population', 'Proteins', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Research', 'Research Personnel', 'Ribosomes', 'Role', 'Scanning', 'Site', 'Stress', 'Systems Biology', 'Testing', 'Training', 'Transfer RNA', 'Translation Initiation', 'Translational Regulation', 'Translations', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'actionable mutation', 'analytical tool', 'cancer genetics', 'collaborative environment', 'environmental change', 'experimental study', 'fitness', 'genome sequencing', 'insight', 'interest', 'mRNA Decay', 'mRNA Transcript Degradation', 'machine learning algorithm', 'multidisciplinary', 'mutation screening', 'novel', 'preservation', 'promoter', 'response', 'ribosome profiling', 'tool', 'transcriptome sequencing', 'whole genome']",NIGMS,NEW YORK UNIVERSITY,F32,2019,61226,0.02524331882201129
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9658531,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2019,479215,0.030681819253386162
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9751141,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2019,1186500,-0.008066041591336696
"Addressing Open Challenges of Computational Genome Annotation We propose to capitalize on success of ongoing collaboration between the bioinformatics teams at the University of Greifswald (Germany) and at the Georgia Institute of Technology (USA) and address open challenges in computational genome annotation. In the course of this development, we plan to implement new algorithmic ideas and satisfy the needs of unbiased integration of different types of OMICS data.  We plan to address one of the long-standing problems at interface of bioinformatics and machine learning – automatic generative and discriminative parameterization of gene finding algorithms. Current methods of combining OMICS evidence frequently result in under predicting or over predicting tools. Having good understanding of the difficulties and the properties of different types of OMICS evidence we propose an optimized approach to the full unsupervised, generative and discriminative training.  We will introduce novel means to optimize integration of multiple OMICS evidence into gene prediction. These ideas will develop further the protein family-based gene finding implemented in AUGUSTUS-PPX. We propose to create representations of protein families for gene finding that for the first time include cross-species gene structure information.  We will develop a new approach that will unify two advanced research areas - transcript reconstruction from RNA-Seq and statistical gene finding that integrates RNA-Seq and homology information. We will describe a new, comprehensive model and EM-like algorithmic technique (the “wholistic” approach) to identify the sets of transcripts and their expression levels that best fit the available OMICS evidence.  We will also develop an automatic gene-finding algorithm for a full content of metagenomes including eukaryotic and viral metagenomic sequences. This task is conventionally considered too challenging. We propose a solution exploiting and advancing algorithmic ideas and approaches that we mastered in the course of creating gene finders for prokaryotic metagenomes as well as eukaryotic genomes.  All new tools will be available to the community under open source licenses. The goal of this project is to advance the science of genome interpretation by developing much needed computational methods and tools for high precision annotation of eukaryotic genomes and metagenomes. This advance will make an impact in research on model and non-model organisms including important human pathogens, parasites and viruses. New high throughput technologies generate volumes of sequence data on complex genomes as well as metagenomes. Still these big data volumes have to be transformed into scientific knowledge. Our new bioinformatics tools, matching the latest sequencing technology in speed and performance, will make a significant impact in genomic research aiming at ultimate understanding of human health and disease.",Addressing Open Challenges of Computational Genome Annotation,9761554,R01GM128145,"['Address', 'Algorithms', 'Alternative Splicing', 'Area', 'Bacteriophages', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Chronic', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complement', 'Complex', 'Computing Methodologies', 'Data', 'Deterioration', 'Development', 'Development Plans', 'Disease', 'Gene Family', 'Gene Structure', 'Genes', 'Genome', 'Genomics', 'Germany', 'Goals', 'Health', 'Human', 'Insecta', 'Institutes', 'Introns', 'Knowledge', 'Length', 'Licensing', 'Machine Learning', 'Maintenance', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Nested Genes', 'Noise', 'Overlapping Genes', 'Parasites', 'Performance', 'Population', 'Positioning Attribute', 'Property', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'RNA Splicing', 'Research', 'Running', 'Speed', 'Spliced Genes', 'Statistical Models', 'Structural Genes', 'Supervision', 'Techniques', 'Technology', 'Time', 'Training', 'Transcript', 'Universities', 'Viral', 'Virus', 'annotation  system', 'base', 'bioinformatics tool', 'computerized tools', 'cost', 'course development', 'design', 'evidence base', 'expectation', 'gene complementation', 'genome annotation', 'genome sciences', 'high throughput technology', 'human pathogen', 'improved', 'instrument', 'member', 'metagenome', 'multiple omics', 'nanopore', 'new technology', 'novel', 'novel strategies', 'open source', 'operation', 'predictive tools', 'protein profiling', 'reconstruction', 'success', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2019,344107,0.011235651005632423
"Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations PROJECT SUMMARY/ABSTRACT  Myosins are a diverse and ubiquitous class of molecular motors that are responsible for generating much of the macroscopic force in the human body. The human genome encodes 38 different isoforms of myosin, and members of this group act as force sensors or generators for a diverse set of processes throughout the body. To serve this wide array of functions, each myosin isoform has been biophysically tuned for its physiological role. In fact, the tuning is so precise that missense variants in one myosin isoform, !-cardiac myosin, can cause a congenital cardiomyopathy that is the leading cause of sudden cardiac death in people under 30. And yet, it is unknown how particular variants cause disease, or how to infer the pathogenic potential for novel mutations.  Large differences in functional properties between myosin isoforms are not the result of large differences in coding sequence or overall topology. Neither foreknowledge of phylogeny nor crystal structure is sufﬁcient to predict an isoform's biophysical properties. Furthermore, mutations causing disease frequently occur in regions of the protein far from the site of their deleterious effects. Poor understanding of the biophysical regulation of motor function has hampered the development of pharmaceuticals and the interpretation of human genomic data.  My goal is to establish a mechanistic understanding of myosin motors that is capable of predicting if and how sequence variation changes biophysical properties and can cause cardiac disease. Since myosin kinetics are not apparent from sequence or overall structure, they must be determined by other factors. I hypothesize that kinetic differences result from differences in the allosteric networks in these proteins. Allosteric network in this context refers to the coordinated conformational ﬂuctuations that give protein regulation the appearance of action at a distance. To test this hypothesis, we will use our unique combination of enormous computational power for molecular simulation and cutting-edge machine learning tools for analyzing protein allostery.  Aim 1 is to identify the biophysical determinants of myosin isoforms' differing speeds. To test our hypothesis that allosteric networks are responsible for modulating dynamics, I will use molecular simulations of different myosin isoforms and compare their allosteric networks with biochemical data about their properties. Aim 1 directly addresses outstanding questions about normal molecular-biological function of the heart, putting it in line with NHLBI overarching objective #1.  Aim 2 is to determine the difference, at atomic resolution, between healthy and diseased !-cardiac myosin. I hypothesize that the pathogenicity of variants with an unknown molecular etiology is a consequence of allosteric disruption, and will use our computational tools to test this hypothesis by simulating a set of known-pathogenic variants. This aim uses techniques from data science to understand the genetic determinants of health, and will apply equally well to rare alleles in under-represented groups as to majority groups. It is directly addresses NHLBI overarching objectives #3, #4, and #7. PROJECT NARRATIVE  Myosins are a closely-related group of molecules that are responsible for generating much of the force in the human body, including the heartbeat, the movement of limbs, and driving food through the stomach and intestines. Small changes to the myosin genes can have large effects: in healthy people, these give rise to different myosins that perform different functions, and mutations in some myosin genes can give rise to diseases that cause of sudden cardiac death. This proposal aims to learn, at the level of atoms and interatomic bonds, why and how these subtle changes to the myosin gene can create such large effects in the protein's function.",Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations,9678589,F30HL146052,"['Actins', 'Address', 'Affinity', 'Appearance', 'Automobile Driving', 'Behavior', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Process', 'Biophysics', 'Cardiac Myosins', 'Cardiomyopathies', 'Catalysis', 'Chemistry', 'Clinical', 'Code', 'Congenital cardiomyopathy', 'Crystallization', 'Data', 'Data Science', 'Development', 'Disease', 'Drug Binding Site', 'Etiology', 'Food', 'Genes', 'Genetic Determinism', 'Genetic Variation', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Genome', 'Human body', 'Intestines', 'Kinetics', 'Learning', 'Machine Learning', 'Measures', 'Membrane Proteins', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'National Heart, Lung, and Blood Institute', 'Pathogenicity', 'Patient risk', 'Pharmacologic Substance', 'Phenotype', 'Phylogeny', 'Physics', 'Physiological', 'Process', 'Property', 'Protein Analysis', 'Protein Isoforms', 'Protein Region', 'Proteins', 'Regulation', 'Relaxation', 'Resolution', 'Risk stratification', 'Role', 'Signal Transduction', 'Site', 'Solvents', 'Speed', 'Stomach', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Underrepresented Groups', 'Variant', 'base', 'biophysical properties', 'computerized tools', 'disease-causing mutation', 'genomic data', 'heart function', 'improved', 'insight', 'limb movement', 'member', 'millisecond', 'molecular dynamics', 'novel', 'precision medicine', 'protein function', 'prototype', 'rare variant', 'rat Ran 2 protein', 'sensor', 'simulation', 'sudden cardiac death', 'tool', 'whole genome']",NHLBI,WASHINGTON UNIVERSITY,F30,2019,30442,-0.01260354005762897
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9785353,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Structure', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'nonsynonymous mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,ALBERT EINSTEIN COLLEGE OF MEDICINE,K99,2019,135945,0.06647781230954235
"Statistical genetics of aging-related genomic and phenotypic change To help to analyze and understand aging-related ""complex"" traits that are affected by many genes and environmental factors, we have followed the path of developing statistical algorithms for the analyses of genome-wide genotyping and high-throughput sequencing studies. Our proposed new computational tools provide means to analyze additional types of data (e.g., to identify mitochondrial DNA (mtDNA) variants and to estimate mtDNA copy number) efficiently from whole-genome sequences. For experimental tests of the algorithms, we are capitalizing on the special advantages of the InCHIANTI project (see Annual Report AG001050) and SardiNIA project (see Annual Report AG000675) to help in the assembly of mitochondrial sequence data and multiple phenotypic data in the two Italian cohorts.   In order to conduct analyses on large-scale consortium data to study mtDNA variation and copy number, we have developed two computational programs, providing a general solution for the analysis of mtDNA dynamics based on whole-genome sequencing studies. One program (mitoCaller) is designed specifically to identify mtDNA variants; the other (mitoCalc) infers mtDNA copy number in a cell directly from genome sequences. Applying the programs to leukocyte sequences of 2,000 SardiNIA participants and 1,000 InCHIANTI participants, we have shown that heteroplasmies (mtDNA variants with more than one allele at a site) increase with age, and that copy number is relatively highly heritable and is correlated with metabolic traits, particularly central fat levels. In more recent work, we have increased the speed of mitoCalc 100-fold (fastMitoCalc). The new program is being applied to white cells of 65,000 deeply sequenced individuals (TOPMed program, NHLBI), for GWAS on copy number. We have also initiated the development of programs to test possible effects of mtDNA variants on traits and diseases.  With our expertise in studying mtDNA variation, we have an ongoing collaborative effort to study a special structural feature of DNA, G-quadruplex (G4) structures, as potential DNA roadblocks that perturb mitochondrial replication machinery. We used computational analyses of 3,000 individual genomes from two Italian cohorts to demonstrate an association between G4s and mtDNA variation. Using the software G4Hunter to predict G4-forming regions in mtDNA, we found statistically significant enrichment of mutations in stable G4 regions, with preferential occurrence of variants in the loop segments of G4 structures. Biochemical studies demonstrated a potent block of human mitochondrial replicative polymerase in DNA synthesis by G4 structure, which could be overcome by the G4-resolving helicase Pif1. Altogether, the computational and biochemical approaches indicate that mtDNA point mutations are enriched at stable G4 structures, consistent with replisome stalling at G-quadruplexes and reliance on error-prone DNA synthesis.  In another study, we have created a program that uses machine learning methods to measure effective rates of aging for individuals. We assess the extent to which an individual's physiological age could be determined as a composite score inferred from a broad range of biochemical and physiological traits from the SardiNIA and InCHIANTI longitudinal studies of aging. Physiological age inferred from our framework was highly correlated with chronological age (R2>0.8). We then defined a physiological aging rate (PAR) for each subject, a continuous trait measured as the ratio of the subjects predicted physiological age to his/her chronological age. We found that PARs were reproducible across follow-up studies, heritable (h2=0.3), and predictive of lifespan and mortality. Genome-wide association studies (GWAS) on the PARs identified both previously established age-associated loci and several new genetic associations. Our findings support a whole-body, pathology-independent aging effect that can be summarized by the physiological aging rate and our method can be used to evaluate the efficacy of treatments that target aging-related processes and disease. n/a",Statistical genetics of aging-related genomic and phenotypic change,10012627,ZIAAG000693,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Algorithms', 'Alleles', 'Ally', 'Annual Reports', 'Biochemical', 'Case-Control Studies', 'Cells', 'Chronology', 'Complex', 'Computer Analysis', 'Computer software', 'DNA', 'DNA biosynthesis', 'DNA copy number', 'Data', 'Disease', 'Environmental Risk Factor', 'Fatty acid glycerol esters', 'Follow-Up Studies', 'G-Quartets', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Leukocytes', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Mitochondria', 'Mitochondrial DNA', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Nuclear', 'Nucleotides', 'Participant', 'Pathology', 'Phenotype', 'Physiological', 'Point Mutation', 'Polymerase', 'Population Control', 'Process', 'Program Development', 'Reproducibility', 'Ribosomal DNA', 'Risk', 'Sardinia', 'Sequence Deletion', 'Site', 'Speed', 'Statistical Algorithm', 'Structure', 'Testing', 'Trans-Omics for Precision Medicine', 'Treatment Efficacy', 'Variant', 'Work', 'age effect', 'base', 'cohort', 'computerized tools', 'design', 'genetic analysis', 'genetic association', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'helicase', 'learning strategy', 'mortality', 'phenotypic data', 'programs', 'trait', 'whole genome']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2019,823193,-0.02196518214642584
"Bioinformatics Core The mission The Bioinformatics Core facilitates, amplifies, and accelerates biological and medical research and discovery through the application of the latest bioinformatics methods and technologies. This mission is achieved by delivering high quality and comprehensive support for experimental design, analysis and visualization in a timely fashion. The core is responsive to research scientists needs and effectively evolves with advances in the field. The core services include but are not limited to the following:  Statistical analysis including basic statistical analysis, advanced statistical analysis (e.g., linear and generalized mixed model analysis, longitudinal modeling), and custom statistical methods (e.g., tailored to specific research projects)  Omics Analysis including: Transcriptomics (Microarray and RNA-seq), Genomics (Genome, exome and targeted DNA-seq), Epigenomics (Methyl-seq, ChIP-seq, etc.), Proteomics, and Metabolomics  Gene/Target/Disease Analysis: Functional annotation at variant, gene, and geneset level, Interaction analysis, and Pathway enrichment analysis  Ad-hoc consultation: Advise on experimental designs, data management and analysis  Computing resource development and maintenance, including Bioinformatics Software Development, Systems Toolkits Development, customized biological databases and Web Services development  Training: Personalized training to match users specific requirements and group training and workshops  Scientific impact  We routinely meet with PIs and/or researchers to discuss the types of analyses and support that our statistical and bioinformatics expertise can provide to help them design experiments. We help with grant proposals to incorporate statistical and computational biology methods or techniques. We also prepare letters of support for such grant proposals. The Core statistical and bioinformatics consulting and collaboration covers a broad range of study design, statistical analyses and data science issues including experimental design for preclinical investigations, population studies, and Big Data analytics, and statistical analysis of next generation sequence data and omics data. The core is also actively involved in statistical and bioinformatics methods research and development and collaborates with PIs, Postdocs, and Staff in writing and implementing competitive project proposals involving methodological and software development. In fiscal year 2017, the core actively participated in 3 CHIRP grant proposals, provided letters of support for 4 postdoctoral K award applicants and as mentioned above 4consulted and collaborated with 31 PIs, and staff for their experimental design and analyses. The core has also contributed to 5 manuscripts and more than 15 posters and abstracts for conference presentation.  Cores research and method development  The Bioinformatics core in collaboration with laboratories at the MHLBI is heavily involved in research and new methods developments. Summarized below are few examples.  > lncRNA detection and functional annotation: With advances in Next Generation Sequencing (NGS), the accessibility of affordable high-throughput sequencing is now generating a wealth of novel, unannotated transcripts, especially long noncoding RNAs (lncRNAs) that are derived from genomic regions that are antisense, intronic, intergenic, and overlapping protein-coding loci. Parsing and characterizing the functions of noncoding RNAs and lncRNAs in particular, is one of the great challenges of modern genome biology. In collaboration with Dr. Haiming Cao, we devised computational methods for the identification and functional characterization of lncRNAs from genomic and transcriptomic data. We also developed bioinformatics pipelines to identify lncRNAs in a dataset and then, employed machine learning approaches for functional characterization of the fragments.  > Proteogenomics: In recent years, with advances in NGS technologies such as RNA- Seq and mass spectrometry-based proteomics, the new era of Proteogenomics research has emerged. In collaboration with several PIs and our Proteomics Core at the NHLBI, we developed customized protein sequence databases using genomic and transcriptomic information to help identify novel peptides that are not present in reference protein sequence databases from mass spectrometry-based proteomic data. We also developed pipeline and computational strategies for building and using customized protein sequence databases. The proteomic data can be used to provide protein-level evidence of gene expression and to help refine gene models.  > Software development for cell free DNA: Donor-derived cell-free DNA (dd-cfDNA), is an emerging biomarker of acute cellular rejection in organ transplant recipients. dd- cfDNA is derived from the transplanted organ and detectable in blood and urine of transplant recipients. In collaboration with Dr. Valentines laboratory, we developed methods for quantification of cell-free DNA (cfDNA) in circulating blood derived from a transplanted organ as a powerful approach for monitoring post-transplant injury and outcome. Our pipeline quantifies donor-derived cfDNA (dd-cfDNA) by discriminant analysis of single-nucleotide polymorphisms (SNPs) between donor and recipient DNA molecules that are distributed across the genome. Plasma levels of dd-cfDNA were assessed for utility in diagnosing rejection and evaluating treatment response in transplant recipients in a longitudinal observational trial.   Training and education We train users on data analysis and help with the manuscript preparation. We meet with investigators who are starting new projects to discuss the best approaches and help with the experimental design. Currently several post-bacs and post-docs frequently visit and consult with core staff on a regular basis to advance their study. n/a",Bioinformatics Core,10019300,ZICHL006228,"['Acute', 'Address', 'Amino Acid Sequence Databases', 'Applications Grants', 'Automobile Driving', 'Big Data Methods', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological databases', 'Biology', 'Blood', 'Budgets', 'ChIP-seq', 'Clinical', 'Code', 'Collaborations', 'Computational Biology', 'Computational Technique', 'Computing Methodologies', 'Consult', 'Consultations', 'Custom', 'DNA', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease', 'Educational workshop', 'Epigenetic Process', 'Experimental Designs', 'Galaxy', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Glean', 'Goals', 'High-Throughput Nucleotide Sequencing', 'Imagery', 'Injury', 'Internet', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Letters', 'Level of Evidence', 'Link', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Mass Spectrum Analysis', 'Medical Research', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Monitor', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Organ Transplantation', 'Outcome', 'Pathway interactions', 'Patients', 'Peptides', 'Phenotype', 'Plasma', 'Population Study', 'Postdoctoral Fellow', 'Preparation', 'Process', 'Proteins', 'Proteomics', 'Public Domains', 'Pythons', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Scientist', 'Services', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Statistical Methods', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Training and Education', 'Transcript', 'Transplant Recipients', 'Untranslated RNA', 'Urine', 'Variant', 'Visit', 'Work', 'Writing', 'base', 'bioinformatics tool', 'biological research', 'cell free DNA', 'computing resources', 'data management', 'design', 'epigenomics', 'evidence base', 'exome', 'experimental analysis', 'experimental study', 'genomic RNA', 'genomic data', 'innovation', 'knowledge base', 'metabolomics', 'method development', 'next generation sequence data', 'next generation sequencing', 'novel', 'post-transplant', 'posters', 'pre-clinical', 'precision medicine', 'proteogenomics', 'research and development', 'skills', 'software development', 'statistics', 'symposium', 'tool', 'transcriptome sequencing', 'transcriptomics', 'treatment response', 'web services', 'web site']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIC,2019,1995826,0.005654562963819763
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9693291,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2019,397125,0.00012837802344754123
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9765970,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Simulation', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2019,433604,0.016186260299984045
"Telomere Diseases Telomeres are repeated hexanucleotide sequences at the ends of linear chromosomes, which serve to protect them from recognition as chromosomal breaks. Asymmetric replication of DNA would lead inevitably to a loss of genetic material, and the telomere repair molecular machinery (a reverse transcriptase, RNA template, and associated proteins) functions to maintain genomic integrity. Telomerase deficiency manifests with short telomeres.  Mutations in DKC1 and in TERC (the RNA template subunit of the complex) are etiologic in dyskeratosis congenita, a constitutional form of aplastic anemia. Mutations in TERT (encoding telomerase, the rate limiting enzymatic component of the complex) and in TERC occur in apparently acquired aplastic anemia and other diseases.  Male hormones, long used to treat aplastic anemia, act to regulate TERT transcription and telomerase activity.  While critical telomere shortening leads to either cell senescence or apoptosis, occasionally cells become aneuploid due to end-to-end fusion of chromosomes. Thus, telomere attrition is a mechanism for oncogenesis, in which chromosome instability rather than the cumulative acquisition of somatic mutations in specific genes is etiologic.   In the clinic, we routinely measure telomere length commercially by a CLIA flow-FISH method, and in our research laboratory by gene amplification qpcr. Measurement of telomere length in clinical samples is required for the adequate diagnosis of aplastic anemia.  Telomere length and the rate of loss of telomere are predictive of late events after treatment with immunosuppression, and in other clinical circumstances. Our research laboratory is proficient in molecular assays related to telomere maintenance and function.Having successfully completed our clinical protocol testing danazol at high doses and prolonged administration for clinical efficacy and telomere effects in patients with telomere disease, we have initiated a new, low dose danazol trial. In the current, patients are randomized to initially receive either half or quarter doses (400 mg or 200 mg daily) compared to the original protocol, for 6 months, and then crossed over the other dose for a further 6 months. These regimens should avoid the toxicities of high dose sex hormones. The design of the current protocol also addresses deficiencies of the original study: 1. We will utilize both q-pcr and also flow-FISH for telomere length and 2. 6 month observation and wash-out periods precede and follow drug administration in order to provide baseline telomere attrition information. Additionally, because of the suggestion of stabilization and possibly improvement in pulmonary function in the earlier protocol, the inclusion criteria have been expanded to recruit patients with mainly lung manifestions of telomeropathy. Accrual is proceeding as anticipated to the low dose danazol protocol. To date, eight patients have been enrolled on study.  Also, in the clinic, relating to telomere disease especially but relevant to the larger clinical issue of distinction between constitutional and acquired etiologies for bone marrow failure, we  systematically screen by genomics, in collaboration with the University of Chicago, patients presenting to our clinic with a wide variety of manifestations of bone marrow failure. We assess for mutations and polymorphisms in >50 genes etiologic in inherited marrow failure syndromes for both research purposes and clinical reporting to the patient. For comparative purposes, we also have data from collaborators at a marrow failure center in Sao Paolo, Brazil. To date, our results indicate: first, patients with acute onset of severe aplastic anemia, defined by convention based on peripheral blood counts, very rarely have mutations in constitutional marrow failure genes, and second, that clinical correlates such as family history and multi-organ involvement are highly predictive of a germline etiology and positive genomic testing. We are applying machine learning techniques to develop an algorithm for specialists to allow distinction between acquired and inherited marrow failure syndromes.  We utilize our referral base to investigate novel genes in individual patients and their families. In collaboration with treating physicians in Lebanon, we have characterized a remarkable large, consanguineous pedigree with homozygous RTEL1 mutations that present with an extraordinary range of clinical phenotypes, from fatal myelodysplastic syndrome and leukemia early in life to mild evidence of marrow failure in adults. In an Iranian family with multiple members suffering thrombocytopenia, we identified a mutation in a highly conserved region of the SBF2 gene. SBF2 previously has only been found mutated in Charcot-Marie-Tooth syndrome. Absent a functional assay, we are introducing this mutation into a megakaryocytic cell line and primary CD34 cells in order to characterize a molecular defect in platelet formation and potentially a novel pathway in megakaryocytopoiesis.  As a component of our single cell effort, we are exploring scRNAseq in constitutional marrow failure syndromes. In the telomeropathies and related diseases, numbers of CD34 marrow cells are inadequate for such efforts, We have been successful in defining the hematopoietic defect in GATA2 deficiency, as described in our complementary annual report.  DADA2 or deficiency of adenosine deaminase-2  presents with a wide range of clinical symptoms and signs, including marrow failure, autoimmune manifestations, and vasculitis and thrombosis. In this disease, the macrophage has been the subject of most interest, and we have applied RNA sequencing of single cells to this population. We could distinguish among macrophage subsets by imputation of sequence and found a marked increase in the nonclassical subtype; among all subtypes there was striking upregulation of immuen pathway genes, especially for interferon signaling, and distinctive upregulation of the NF-kappaB in the nonclassical cells. These experiments provide novel insights into the pathogenesis of this syndrome and potentially the basis for a diagnostic test. Last, because telomeropathy is associated with chromosome instability and myeloid neoplasm--and represents an alternative pathway to acquisition of mutations in the development of cancer--we are testing new methods for sensitive detection of single copy number variation as a harbinger of gross aneuploidy and transformation. n/a",Telomere Diseases,10012685,ZIAHL006089,"['Acute', 'Address', 'Adult', 'Aftercare', 'Algorithms', 'Aneuploidy', 'Annual Reports', 'Aplastic Anemia', 'Apoptosis', 'Autoimmune Process', 'Biological Assay', 'Blood', 'Blood Platelets', 'Brazil', 'CD34 gene', 'Cell Aging', 'Cell Line', 'Cells', 'Charcot-Marie-Tooth Disease', 'Chicago', 'Chromosomal Breaks', 'Chromosomal Instability', 'Chromosomal Stability', 'Chromosomes', 'Clinic', 'Clinical', 'Clinical Protocols', 'Collaborations', 'Complex', 'Constitutional', 'Copy Number Polymorphism', 'DNA biosynthesis', 'Danazol', 'Data', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Dose', 'Dyskeratosis Congenita', 'Dysmyelopoietic Syndromes', 'Enrollment', 'Etiology', 'Event', 'Failure', 'Family', 'Gene Amplification', 'Genes', 'Genetic Materials', 'Genetic Polymorphism', 'Genetic Transcription', 'Genomics', 'Goals', 'Gonadal Steroid Hormones', 'Hematopoietic', 'Hormones', 'Immunosuppression', 'Inherited', 'Interferons', 'Laboratory Research', 'Lead', 'Lebanon', 'Length', 'Life', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Marrow', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Mutate', 'Mutation', 'Myeloproliferative disease', 'NF-kappa B', 'Organ failure', 'Pancytopenia', 'Pathogenesis', 'Pathway interactions', 'Patient Recruitments', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Proteins', 'Protocols documentation', 'RNA', 'RNA-Directed DNA Polymerase', 'Randomized', 'Recording of previous events', 'Regimen', 'Reporting', 'Research', 'Sampling', 'Signal Transduction', 'Signs and Symptoms', 'Somatic Mutation', 'Specialist', 'Suggestion', 'Syndrome', 'Techniques', 'Telomerase', 'Telomere Maintenance', 'Telomere Shortening', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Toxic effect', 'Universities', 'Up-Regulation', 'Vasculitis', 'adenosine deaminase deficiency', 'base', 'chromosome fusion', 'clinical efficacy', 'clinical phenotype', 'comparative', 'consanguineous family', 'design', 'experimental study', 'genome integrity', 'human disease', 'inclusion criteria', 'individual patient', 'insight', 'interest', 'leukemia', 'macrophage', 'male', 'member', 'novel', 'peripheral blood', 'pulmonary function', 'repaired', 'single-cell RNA sequencing', 'symposium', 'telomere', 'telomere loss', 'tumorigenesis']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIA,2019,1112403,0.004033222254124616
"Deep learning-based approach to identify non-coding cancer drivers that alter chromatin conformation Summary Most variants obtained from tumor whole-genome sequences (WGS) occur in non- coding regions of the genome. Although variants in protein-coding regions have received the majority of attention, numerous studies have now noted the importance of non- coding variants in cancer. Identification of functional non-coding variants that drive tumor growth remains a challenge and a bottleneck for the use of whole-genome sequencing in the clinic. Cancer drivers are generally identified by the high frequency at which their mutations occur across patients. However, mutation rate is highly heterogeneous in non- coding regions and many non-driver elements show higher mutation frequency than others, such as regions bound by transcription factors in melanoma or regions replicating late during cell division in colon cancer. In this proposal, we will use high- throughput pooled CRISPR screen and novel computational methods to predict non- coding cancer drivers. We will quantitatively measure the impact of thousands of non- coding mutations using our innovative high-throughput CRISPR screen that directly ties modifications in the native context of the non-coding genome (i.e. not a reporter assay) to a cancer relevant phenotype (cell growth). The results of the screen will be used as training data for the development of NC_Driver, a computational cancer driver prediction tool. NC_Driver will integrate the signals of high functional impact with the recurrence of variants across multiple tumor samples to identify the non-coding mutations under positive selection in cancer. We will identify drivers in promoters, enhancers and CTCF insulators. CTCF insulators are the most mutated yet least studied regulatory elements in the cancer genome. Using this integrative experimental and computational approach, we will identify high-confidence candidate drivers. Finally, we will perform functional evaluation of prioritized non-coding drivers in colorectal and prostate cancers. We will use CRISPR/Cas9 genome editing in patient-derived cell cultures to test 20 high-ranking candidate driver promoter/enhancer/insulator mutations. Overall, this proposal addresses the critical need to identify drivers in the non-coding genome and over long- term enable the maximal benefit of genome sequencing for each patient. Project Narrative Cancer genomes contain thousands of mutations but only a few of them play an important role in cancer proliferation and are called drivers. Most of the mutations occur in regions of the genome that do not make proteins, yet the majority of previous studies have focused on protein-coding regions. In this proposal, we will use integrative computational and experimental approaches to identify drivers in the non-protein-coding regions of the genome.",Deep learning-based approach to identify non-coding cancer drivers that alter chromatin conformation,9831005,R01CA218668,"['Accounting', 'Address', 'Attention', 'Benchmarking', 'Biological Assay', 'CRISPR screen', 'CRISPR/Cas technology', 'Cancer Patient', 'Catalogs', 'Cell Culture Techniques', 'Cell Line', 'Cell Survival', 'Cell division', 'Cells', 'Chromatin', 'Clinic', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Colon', 'Colon Carcinoma', 'Colorectal Cancer', 'Computer Simulation', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Dissection', 'Elements', 'Enhancers', 'Evaluation', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Heterogeneity', 'Institutes', 'Knock-in', 'Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methods', 'Modification', 'Molecular Conformation', 'Mutagenesis', 'Mutate', 'Mutation', 'Nature', 'Open Reading Frames', 'Parents', 'Patients', 'Phenotype', 'Play', 'Prostate', 'Proteins', 'Recurrence', 'Regulatory Element', 'Reporter', 'Research', 'Role', 'Running', 'Sampling', 'Screening Result', 'Signal Transduction', 'Somatic Mutation', 'Statistical Algorithm', 'Structure', 'Targeted Resequencing', 'Testing', 'Training', 'Transcript', 'Untranslated RNA', 'Validation', 'Variant', 'Xenograft procedure', 'actionable mutation', 'base', 'biobank', 'cancer genome', 'cancer type', 'cell growth', 'cohort', 'colon cancer cell line', 'deep learning', 'genome editing', 'genome sequencing', 'genome-wide', 'high throughput screening', 'innovation', 'knock-down', 'melanoma', 'novel', 'precision medicine', 'promoter', 'tool', 'transcription factor', 'tumor', 'tumor growth', 'tumor heterogeneity', 'tumor microenvironment', 'tumorigenesis', 'tumorigenic', 'whole genome']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2019,113967,0.006183691111957824
"Predicting and analyzing variation in cellular interactomes Project Summary Over the last two decades, significant experimental efforts have determined large sets of “reference” interactions for humans and other model organisms, along with substantial knowledge about the binding specificities of proteins, including for a large fraction of human transcription factors (TFs). The resulting data have proven to be an incredibly useful resource for understanding how cells function; nevertheless, they do not capture how molecular interactions and networks are different from the reference across individuals. Indeed, while human genomes in both healthy and disease populations are rapidly being sequenced, the corresponding individual-specific interaction networks remain largely unexamined; this represents a major gap in our knowledge, as mutations that alter molecular interactions underlie a wide range of human diseases. Further, the substantial amount of genetic variation across populations makes it infeasible in the near term to experimentally determine per-individual interaction networks. Thus our long-term goal is to develop computational methods to uncover whether and how mutations within coding and non-coding portions of the genome perturb cellular interactions and networks. Our specific aims are: (1) We will develop computational structure-based approaches to identify and catalog, at proteome-scale, variations within proteins that are likely to impact their ability to bind with DNA, RNA, small molecules, peptides or ions, thereby providing a comprehensive resource for analyzing protein interaction variation. (2) We will develop novel structure-based and probabilistic methods to predict how DNA-binding specificities are altered when a TF is mutated; since mutated TFs have been linked to numerous diseases, this will be a great aid in understanding disease networks and pathology. (3) We will develop new methods to uncover non-coding somatic mutations that alter human regulatory networks in cancer; this is a critical step towards ultimately uncovering patient-specific cancer networks. Overall by pursuing these aims—which integrate mutational information with existing knowledge about reference interactions, interfaces and specificities—we will develop novel computational methods that will significantly advance our understanding of molecular interactions perturbed in disease and healthy contexts. Narrative The proposed research will yield new software tools that predict whether specific genetic mutations alter molecular interactions and networks. Since many human diseases are caused by mutations that affect molecular interactions, this research will expand our understanding of the underlying basis of disease and will provide new avenues for diagnosis and treatment.",Predicting and analyzing variation in cellular interactomes,9740714,R01GM076275,"['Affect', 'Alleles', 'Amino Acid Sequence', 'Animal Model', 'Binding', 'Binding Proteins', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Process', 'Catalogs', 'Cell physiology', 'Code', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Binding', 'DNA Sequence Alteration', 'DNA-Protein Interaction', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Human Genome', 'Individual', 'Infrastructure', 'Internet', 'Ions', 'Knowledge', 'Ligand Binding', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Mutagenesis', 'Mutate', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Organism', 'Pathology', 'Patients', 'Pattern', 'Peptides', 'Play', 'Population', 'Property', 'Protein Analysis', 'Proteins', 'Proteome', 'RNA', 'Regulator Genes', 'Research', 'Resources', 'Sampling', 'Site', 'Software Tools', 'Somatic Mutation', 'Specificity', 'Structure', 'Untranslated RNA', 'Variant', 'Work', 'Zinc Fingers', 'base', 'cancer genome', 'disease-causing mutation', 'experimental study', 'human disease', 'improved', 'interest', 'knowledge base', 'learning strategy', 'novel', 'predictive tools', 'preference', 'small molecule', 'software development', 'transcription factor', 'tumor', 'virtual']",NIGMS,PRINCETON UNIVERSITY,R01,2019,312660,0.005758898806581461
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9693289,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analysis pipeline', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2019,864186,-0.02776878449534329
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9731524,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'nonsynonymous mutation', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2019,300000,0.048399135583241965
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9825986,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Simulation', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'actionable mutation', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2019,232291,0.08061725587836148
"PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A) PROJECT SUMMARY  Since its inception 40 years ago, in vitro fertilization (IVF) has resulted in the birth of more than 1 million babies in the United States, and has revolutionized the field of reproductive medicine. Unfortunately, the success rate of IVF is still exceedingly low, especially for women >40 years old, with only 15.5% of implanted embryos resulting in pregnancy. This is partly due to the cytological method used for pre-implantation screening, which cannot detect the most common genetic defect during IVF, aneuploidy (i.e. chromosomal copy-number variation). Aneuploidy is linked to higher rates of miscarriage, and occurs more often in women >40 years of age; thus, aneuploidy has been a frequent target for genetic screening to improve IVF outcomes.  Pre-implantation genetic testing for aneuploidy (PGT-A) refers to a variety of techniques aimed at detecting changes in chromosomal copy number, with the goal of identifying high-quality euploid embryos for implantation. Recent advances in next-generation sequencing (NGS) technologies have made it possible to screen embryos at higher levels of precision, and across a wider range of genetic defects, including mosaicism, triploidy and single nucleotide polymorphisms (SNPs). Despite these remarkable advances, there are still significant challenges with PGT-A sequencing. Indeed, the most commonly implemented software for PGT-A (i.e. BlueFuse® ) are bundled with specific sequencing platforms (i.e. VeriSeq®), and are only designed to test for aneuploidy. Furthermore, existing pipelines are not user-friendly or customizable, which is a serious obstacle prohibiting the use of NGS by clinicians / embryologists. A more accessible bioinformatics platform is desperately needed that will bridge the gap between PGT-A sequencing and IVF outcomes.  Basepair™ is an innovator in efficient, user-friendly, web-based NGS analysis systems, with fully automated ChIP-, RNA-, ATAC-, and DNA-Seq bioinformatics pipelines available online. Here, Basepair will deliver PiNDA™, the first fully integrated software solution for comprehensive PGT-A analysis. In Aim 1, we will develop modules to test for specific chromosomal abnormalities, including mosaicism and triploidy, and validate each model with training data derived from somatic cell lines with known chromosomal aberrations. In Aim 2, we will integrate our modules into the PiNDA software system, creating a user-friendly, web-based interface that will perform full data analysis (raw data to full summary report) in <15 minutes, with no manual input required. Final data will be accessible via Basepair’s online portal, facilitating rapid data transfer from embryologists to physicians, and supporting the integration of NGS tests in IVF. Our innovative bioinformatics platform will accelerate NGS analysis for IVF, improving rates of pregnancy and advancing research in the success of IVF procedures. PROJECT NARRATIVE  In vitro fertilization (IVF) methods have begun to leverage next-generation sequencing technologies for pre-implantation genetic testing of aneuploidy (PGT-A), expanding the array of chromosomal abnormalities that can be accurately detected. However, the vast majority of software can only distinguish one type of genetic defect (i.e. aneuploidy), are difficult to use, and are tied to distinct sequencing platforms, limiting the clinical utility of resulting analyses. Basepair™ Inc. is a pioneer in user-friendly, web-based bioinformatics pipelines, providing comprehensive services for a wide range of sequencing projects. Here, Basepair will develop an inclusive suite of software for PGT-A, compatible with sequencing data from multiple platforms. This product will be of high value to the field and will help bridge the gap between advances in DNA sequencing and IVF technology.",PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A),9846492,R43HD100280,"['ATAC-seq', 'Age-Years', 'Algorithms', 'Aneuploid Cells', 'Aneuploidy', 'Bioinformatics', 'Biopsy', 'Birth', 'Cell Line', 'Cell division', 'Centers for Disease Control and Prevention (U.S.)', 'ChIP-seq', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'Culture Media', 'Cytology', 'DNA sequencing', 'Data', 'Data Analyses', 'Embryo', 'Feedback', 'Fertility Agents', 'Fertilization in Vitro', 'Genetic Screening', 'Goals', 'Harvest', 'Implant', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Morphology', 'Mosaicism', 'Mutation', 'Online Systems', 'Outcome', 'Phase', 'Physicians', 'Polymorphism Analysis', 'Pregnancy', 'Pregnancy Rate', 'Preimplantation Diagnosis', 'Procedures', 'Reporting', 'Reproductive Medicine', 'Research', 'Role', 'Sampling', 'Services', 'Single Nucleotide Polymorphism', 'Somatic Cell', 'Specificity', 'Spontaneous abortion', 'Summary Reports', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Triploidy', 'United States', 'Uterus', 'Woman', 'analysis pipeline', 'aneuploidy analysis', 'cell free DNA', 'design', 'early embryonic stage', 'egg', 'implantation', 'improved', 'innovation', 'natural Blastocyst Implantation', 'next generation sequencing', 'phase 1 study', 'preimplantation', 'screening', 'sequencing platform', 'software development', 'software systems', 'sperm cell', 'success', 'transcriptome sequencing', 'user-friendly', 'web based interface']",NICHD,"BASEPAIR, INC.",R43,2019,298717,-0.0033735509851286287
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9702844,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'causal variant', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genome sequencing', 'genome-wide', 'human disease', 'human model', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'web server', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,300191,0.021385787402153054
"Comparative Analysis Of Completely Sequenced Genomes The rapidly growing database of completely and nearly completely sequenced genomes of bacteria, archaea, eukaryotes and viruses (several thousand genomes already available and many more in progress) creates both extensive new opportunities and major new challenges for genome research. During the year in review, we performed a variety of studies that took advantage of the genomic information to establish fundamental principles of genome evolution.   To a large extent, we have focused on cancer genome evolution. Cancer arises through the accumulation of somatic mutations over time. Understanding the sequence of mutation occurrence during cancer progression can assist early and accurate diagnosis and improve clinical decision-making. Here we employ long short-term memory (LSTM) networks, a class of recurrent neural network, to learn the evolution of a tumor through an ordered sequence of mutations. We demonstrate the capacity of LSTMs to learn complex dynamics of the mutational time series governing tumor progression, allowing accurate prediction of the mutational burden and the occurrence of mutations in the sequence. Using the probabilities learned by the LSTM, we simulate mutational data and show that the simulation results are statistically indistinguishable from the empirical data. We identify passenger mutations that are significantly associated with established cancer drivers in the sequence and demonstrate that the genes carrying these mutations are substantially enriched in interactions with the corresponding driver genes. Breaking the network into modules consisting of driver genes and their interactors, we show that these interactions are associated with poor patient prognosis, thus likely conferring growth advantage for tumor progression. Thus, application of LSTM provides for prediction of numerous additional conditional drivers and reveals hitherto unknown aspects of cancer evolution.  In another cancer genomics project, we explored proteomic and genomic signatures of repeat instability in cancer and adjacent normal tissues. Repetitive sequences are hotspots of evolution at multiple levels. However, due to difficulties involved in their assembly and analysis, the role of repeats in tumor evolution is poorly understood. We developed a rigorous motif-based methodology to quantify variations in the repeat content, beyond microsatellites, in proteomes and genomes directly from proteomic and genomic raw data. This method was applied to a wide range of tumors and normal tissues. We identify high similarity between repeat instability patterns in tumors and their patient-matched adjacent normal tissues. Nonetheless, tumor-specific signatures both in protein expression and in the genome strongly correlate with cancer progression and robustly predict the tumorigenic state. In a patient, the hierarchy of genomic repeat instability signatures accurately reconstructs tumor evolution, with primary tumors differentiated from metastases. We observe an inverse relationship between repeat instability and point mutation load within and across patients independent of other somatic aberrations. Thus, repeat instability is a distinct, transient, and compensatory adaptive mechanism in tumor evolution and a potential signal for early detection.  Additionally, we have continued intensive research into evolutionary genomics of viruses and antivirus defense systems. In particular, we carried out a detailed investigation of CRISPR-Cas systems encoded in mobile genetic elements and involved in counter-defence and other functions. The principal function of CRISPR-Cas systems in archaea and bacteria is defence against mobile genetic elements (MGEs), including viruses, plasmids and transposons. However, the relationships between CRISPR-Cas and MGEs are far more complex. Several classes of MGE contributed to the origin and evolution of CRISPR-Cas, and, conversely, CRISPR-Cas systems and their components were recruited by various MGEs for functions that remain largely uncharacterized. We investigated and substantially expanded the range of CRISPR-Cas components carried by MGEs. Three groups of Tn7-like transposable elements encode 'minimal' type I CRISPR-Cas derivatives capable of target recognition but not cleavage, and another group encodes an inactivated type V variant. These partially inactivated CRISPR-Cas variants might mediate guide RNA-dependent integration of the respective transposons. Numerous plasmids and some prophages encode type IV systems, with similar predicted properties, that appear to contribute to competition among plasmids and between plasmids and viruses. Many prokaryotic viruses also carry CRISPR mini-arrays, some of which recognize other viruses and are implicated in inter-virus conflicts, and solitary repeat units, which could inhibit host CRISPR-Cas systems.  We also have developed a general theory of the origin of viruses from primordial replicators that various cellular proteins as capsid formation. Viruses are ubiquitous parasites of cellular life and the most abundant biological entities on Earth. It is widely accepted that viruses are polyphyletic, but a consensus scenario for their ultimate origin is still lacking. Traditionally, three scenarios for the origin of viruses have been considered: descent from primordial, precellular genetic elements, reductive evolution from cellular ancestors and escape of genes from cellular hosts, achieving partial replicative autonomy and becoming parasitic genetic elements. These classical scenarios give different timelines for the origin(s) of viruses and do not explain the provenance of the two key functional modules that are responsible, respectively, for viral genome replication and virion morphogenesis. We developed a 'chimeric' scenario under which different types of primordial, selfish replicons gave rise to viruses by recruiting host proteins for virion formation. We also propose that new groups of viruses have repeatedly emerged at all stages of the evolution of life, often through the displacement of ancestral structural and genome replication genes.  Taken together, these studies advance the existing understanding of the general principles and specific aspects of genome evolution in diverse life forms, in particular, viruses and mobile elements, as well as cancer genome evolution. n/a",Comparative Analysis Of Completely Sequenced Genomes,10007522,ZIALM000073,"['Affect', 'Archaea', 'Bacteria', 'Biological', 'Capsid', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Consensus', 'DNA Transposable Elements', 'Data', 'Databases', 'Early Diagnosis', 'Elements', 'Eukaryota', 'Evolution', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Guide RNA', 'Horizontal Gene Transfer', 'Individual', 'Investigation', 'Learning', 'Life', 'Malignant Neoplasms', 'Mediating', 'Metagenomics', 'Methodology', 'Methods', 'Microsatellite Repeats', 'Mobile Genetic Elements', 'Morphogenesis', 'Mutation', 'Neoplasm Metastasis', 'Normal tissue morphology', 'Organism', 'Orthologous Gene', 'Parasites', 'Patients', 'Pattern', 'Phylogeny', 'Planet Earth', 'Plasmids', 'Point Mutation', 'Primary Neoplasm', 'Probability', 'Process', 'Property', 'Prophages', 'Proteins', 'Proteome', 'Proteomics', 'Repetitive Sequence', 'Replicon', 'Research', 'Role', 'Series', 'Signal Transduction', 'Somatic Mutation', 'Structure', 'System', 'Time', 'TimeLine', 'Tumor Tissue', 'Variant', 'Viral Genome', 'Virion', 'Virus', 'accurate diagnosis', 'base', 'cancer genome', 'cancer genomics', 'clinical decision-making', 'comparative', 'genetic element', 'genome-wide', 'genomic signature', 'improved', 'insight', 'long short term memory', 'long short term memory network', 'mathematical methods', 'mathematical model', 'novel', 'outcome forecast', 'paralogous gene', 'protein expression', 'proteomic signature', 'recruit', 'recurrent neural network', 'replicator', 'simulation', 'theories', 'trend', 'tumor', 'tumor progression', 'tumorigenic', 'whole genome']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2019,2638215,0.018684696813290852
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9653955,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,587448,0.041209393669260956
"Massively parallel functional analyses of human PTEN variants Project Summary  We are now able to routinely sequence human genomes at single-base resolution. However, our ability to interpret the functional consequences of detected mutations has lagged behind. Computational approaches scale well but have poor accuracy, whereas retrospective analysis of detected variants has high accuracy but does not scale well. In order to solve this problem, a new experimental paradigm has emerged to empirically characterize the effects of mutations with high accuracy at scale. This approach takes advantage of recent and ongoing improvements in DNA synthesis and sequencing, and has the potential to offer unprecedented insight into protein biochemistry and human disease. We believe these insights will prove to be critical for unlocking the potential of genomic medicine.  In this project we seek to comprehensively assess multiple molecular effects of PTEN mutations on protein function, and assess the utility of this data as a predictor for human clinical phenotype. The PTEN protein is a tumor suppressor that is frequently mutated in diverse human cancers and in the germline of some individuals with overgrowth disorders, cancer predisposition syndromes, or autism. Currently, it is impossible to predict the effects of the vast majority of PTEN germline mutations. Since the phenotypic spectrum of PTEN mutation carriers is broad, it would be highly valuable to understand the ways in which phenotypic outcomes arise from PTEN mutation genotypes.  In Aim 1, we will first employ a yeast-based screen to assess the effects all PTEN single amino acid mutations on lipid phosphatase activity, the primary biochemical function of PTEN protein. It is known that several pathogenic variants are destabilized. Therefore, in Aim 2, we will perform a second, independent screen to assess the steady state protein stability of all PTEN single amino acid mutations. In Aim 3, we will use the data derived from this study as well as publically available biochemical information to train a classifier model to predict the relationship between the mutation genotypes and clinical phenotypes observed in humans. These data will increase our fundamental understanding of PTEN function and the role of mutations in diverse disorders, and could provide a valuable clinical tool that would increase the quality of life for PTEN mutation carriers. Project Narrative  Mutations in the gene PTEN are causal for a diverse set of clinical disorders ranging from cancer to autism spectrum disorder. Here, we seek to gain new fundamental insights into the functional relationships between PTEN mutations and clinical presentations by prospectively characterizing the effects of all single amino acid PTEN mutations in parallel. These data will allow the creation of new models that can predict risk of specific PTEN mutations for different clinical outcomes and potentially lead to personalized therapies, early interventions, and optimal outcomes for PTEN mutation carriers.",Massively parallel functional analyses of human PTEN variants,9794010,F31HD095571,"['Affect', 'Amino Acids', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biology', 'Biophysics', 'Cataloging', 'Catalogs', 'Cell Separation', 'Cell Survival', 'Cells', 'Characteristics', 'Clinic', 'Clinical', 'Complex', 'Coupled', 'Coupling', 'DNA biosynthesis', 'DNA sequencing', 'Data', 'Data Set', 'Deletion Mutation', 'Development', 'Disease', 'Early Intervention', 'FRAP1 gene', 'Fluorescence', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Germ-Line Mutation', 'Goals', 'Growth', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Lead', 'Light', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Metabolism', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Outcome', 'PTEN gene', 'PTEN protein', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Phosphatidylinositols', 'Phosphoric Monoester Hydrolases', 'Play', 'Predisposition', 'Problem Solving', 'Process', 'Protein Biochemistry', 'Proteins', 'Pythons', 'Quality of life', 'Reaction', 'Resolution', 'Risk', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Syndrome', 'Techniques', 'Temperature', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tumor Suppressor Proteins', 'Ubiquitination', 'Variant', 'Yeast Model System', 'Yeasts', 'accurate diagnosis', 'autism spectrum disorder', 'base', 'clinical phenotype', 'experimental study', 'fitness', 'genomic signature', 'genomic variation', 'high throughput technology', 'human disease', 'improved', 'insight', 'mutation carrier', 'next generation', 'novel', 'open source', 'personalized medicine', 'prediction algorithm', 'predictive modeling', 'prospective', 'protein function', 'screening', 'synthetic biology', 'tool', 'tumorigenic']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,F31,2019,45016,0.05723441089269358
"Molecular Characterization of Joubert Syndrome Project Summary Congenital ataxia presents in early childhood with non-progressive hypotonia, gross motor, fine motor and cognitive delays. These disorders are distinct from the progressive ataxias because of the presence of congenital cerebellar malformations and because they are typically inherited recessively. Joubert Syndrome and Related Disorders (JSRD) constitute a major subset of these conditions, consisting of a cerebellar midline (vermis) malformation, a nearly pathognomonic Molar Tooth sign on brain Imaging (MTI) and co-existent oculomotor apraxia and episodic breathing dysrhythmias. In our published data, we have: 1] Identified ten unique genetic causes of JSRD (nearly half of the published causes), 2] Generated genotype-phenotype correlations involving cerebellar, retinal, renal, hepatic, digit, and cerebral manifestations. 3] Identified common founder mutations that allow for population-based screening. 4] Discovered that JSRD encoded proteins frequently localize to the cilium. 5] Identified ciliary transition zone (TZ) defects in cells with JSRD mutations. 6] Performed siRNA cell-based screens for defective ciliogenesis to prioritize candidate JSRD genes. 7] Generated and characterized multiple zebrafish, mouse and human cell culture models for JSRD. 8] Defined the concept of ‘Ciliary localization’ model, in which one JSRD gene is required for ciliary localization of other JSRD proteins. In our unpublished data we have: 1] Recruited an additional 200 JSRD patients without molecular diagnosis. 2] Performed whole exome (WES) and whole genome sequencing (WGS) on an additional 100 JSRD families. 3] Identified an additional 12 novel likely JSRD candidate genes. 4] Generated IPSCs and cerebellar organoids from mutation-positive and negative families to aid in functional analysis and gene discovery using RNAseq. 5] Begun functional validation of the putative mutations. 6] Developed methods to interrogate ciliary structure in a high-throughput fashion with electron microscopy (EM). The goal of this competing renewal is to identify the remaining ‘discoverable’ genes that lead to JSRD when lost, functionally validate mutations within the pathogenetic framework, and test the hypothesis that mutations in JSRD genes lead to collapse of the ciliary TZ. Because the majority of patients still have unknown cause of disease, this renewal aims to advance knowledge through molecular characterization of new genes, using newly evolving high-throughput techniques, integrated bioinformatics, and a unique resource of consanguineous families recruited world-wide. We further aim to validate these mutations in patient cells, within a mechanistic framework that JSRD genes are required for essential ciliary structural components during cerebellar development. Project Narrative Joubert syndrome is a genetically and phenotypically heterogeneous neurodevelopmental disorder unified by defects of the cellular primary cilium. This work will identify new genetic causes and dissect ciliary defects associated with genetic mutations.",Molecular Characterization of Joubert Syndrome,9749889,R01NS048453,"['Apraxias', 'Ataxia', 'Bioinformatics', 'Brain imaging', 'Breathing', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Cells', 'Cerebellar malformation', 'Cerebellar vermis structure', 'Cerebrum', 'Cilia', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognitive', 'Congenital cerebellar hypoplasia', 'Cultured Cells', 'Cytoplasmic Granules', 'DNA Sequence Alteration', 'Data', 'Databases', 'Defect', 'Development', 'Digit structure', 'Disease', 'Electron Microscopy', 'Electrons', 'Embryo', 'Enrollment', 'Face', 'Family', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic screening method', 'Genotype', 'Goals', 'Gold', 'Hepatic', 'Human', 'Individual', 'Inherited', 'Joubert syndrome', 'Kidney', 'Knock-out', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Microscopic', 'Middle East', 'Modeling', 'Molar tooth', 'Molecular', 'Molecular Diagnosis', 'Morphogenesis', 'Morphology', 'Motor', 'Mus', 'Muscle hypotonia', 'Mutation', 'Neurodevelopmental Disorder', 'Organoids', 'Pathogenicity', 'Patients', 'Phenotype', 'Probability', 'Protein Analysis', 'Proteins', 'Publishing', 'Resources', 'Retinal', 'Risk', 'Scanning Electron Microscopy', 'Series', 'Severities', 'Signal Transduction', 'Small Interfering RNA', 'Sonication', 'Structure', 'Syndrome', 'Techniques', 'Termination of pregnancy', 'Testing', 'Three-dimensional analysis', 'Training', 'Transmission Electron Microscopy', 'Validation', 'Variant', 'WNT Signaling Pathway', 'Work', 'Zebrafish', 'accurate diagnosis', 'affection', 'base', 'cell type', 'cilium biogenesis', 'cohort', 'consanguineous family', 'disorder subtype', 'early childhood', 'exome', 'exome sequencing', 'fetal', 'founder mutation', 'gene discovery', 'genome sequencing', 'genome-wide', 'insight', 'knock-down', 'loss of function mutation', 'malformation', 'mutant', 'novel', 'oculomotor', 'population based', 'reconstruction', 'recruit', 'screening', 'stem cell biology', 'transcriptome sequencing', 'whole genome']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,510012,0.02615266583553004
"Genome Based Influenza Vaccine Strain Selection using Machine Learning No abstract available PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection using Machine Learning,10044945,R01AI116744,[' '],NIAID,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2019,147704,0.00926331297045112
"Computational approaches for identifying epigenomic contexts of somatic mutations ABSTRACT During normal development, aging, and diseases such as cancer, DNA damage due to endogenous and external factors, and repair defects result in accumulation of different types of somatic mutations including single nucleotide substitutions, small InDels, copy number alterations, translocations, and ploidy changes. While a vast majority of somatic mutations in the genome are not disease drivers, their patterns of genetic changes and associated context can provide insights into past exposure to mutagens, mechanisms of DNA damage and repair defects, and extent of genomic instability, which are important for understanding disease etiology, minimizing hazardous environmental exposure, and also predicting efficacy of emerging treatment strategies such as immunotherapy. A number of mutation signatures have been identified based on local sequence contexts to address this need. But, mechanisms of DNA damage and repair preferences depend on both local sequence and epigenomic contexts, and it remains to be understood whether epigenomic contexts of emerging mutation signatures can provide critical, complementary etiological insights at a genome-wide scale, which are not apparent from sequence contexts alone. This is of fundamental importance, because (i) etiology of many of the emerging mutation signatures is currently unknown, (ii) DNA damage response and repair depends on tissue contexts, and defects in core DNA repair genes often result in cancer development in tissue-specific manner, and (iii) differences in the extent of DNA damage and repair between stem and differentiated cells within the same tissues have consequences for aging and disease incidence rates. Built logically on our previous works, we propose to develop computational approaches to determine the impact of epigenomic contexts on the patterns of somatic mutations within and across tissue types, and validate computational predictions using targeted experiments. In Aim-1, we will develop an epigenomic context preference map for emerging mutation signatures. In Aim-2, we will determine the basis of tissue-dependent differences in mutation profiles attributed to DNA repair defects. In Aim-3, we will predict the extent of cell lineage-dependent patterns of mutation accumulation from the mutational landscape of terminal cells. I am currently an early stage investigator, and the proposal is aligned with my long-term goal to identify fundamental principles of mutability and evolvability of somatic genomes. Our project will deliver novel resources and knowledge for addressing questions regarding genomic integrity during development and aging, and diseases such as cancer. ! PUBLIC HEALTH RELEVANCE: The proposed project will use computational biology approaches to determine epigenomic context preference for somatic mutations, and use that to infer tissue-dependent changes in mutation patterns. Our results will provide fundamental insights into aspects of genome maintenance, which is important for advancing our understanding of cancer etiology, reducing exposure to mutagenic factors, and also predicting efficacy of emerging treatment strategies. !",Computational approaches for identifying epigenomic contexts of somatic mutations,9737246,R01GM129066,"['Address', 'Affect', 'Aging', 'Biometry', 'Blood', 'Cancer Etiology', 'Cancer Relapse', 'Cell Differentiation process', 'Cell Line', 'Cell Lineage', 'Cells', 'Chromatin', 'Clinical', 'Computational Biology', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'Data', 'Defect', 'Development', 'Disease', 'Doctor of Philosophy', 'Environmental Exposure', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exposure to', 'Genome', 'Genomic DNA', 'Genomic Instability', 'Genomics', 'Goals', 'Immunotherapy', 'Incidence', 'Knowledge', 'Least-Squares Analysis', 'Location', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutagenesis', 'Mutagens', 'Mutation', 'Nuclear', 'Nucleotides', 'Pathway interactions', 'Pattern', 'Ploidies', 'Point Mutation', 'Process', 'Publishing', 'Radiation Tolerance', 'Research Personnel', 'Resources', 'Role', 'Somatic Mutation', 'Source', 'Stem cells', 'Tissues', 'Work', 'base', 'cancer genomics', 'computer framework', 'epigenomics', 'experimental study', 'genome integrity', 'genome-wide', 'human tissue', 'improved', 'insertion/deletion mutation', 'insight', 'markov model', 'medical schools', 'novel', 'preference', 'public health relevance', 'random forest', 'repaired', 'response', 'stem', 'transcriptomics', 'treatment strategy']",NIGMS,RBHS -CANCER INSTITUTE OF NEW JERSEY,R01,2019,336177,0.0462670464158194
"The Enzymatic Reader Project Summary At this point in time, it is generally understood and agreed upon that single-molecule sequencing (SMS) is the future of genomics, transcriptomics, epigenomics, and epitranscriptomics due to its significant advantages over other technologies and methods. However, in order for these advantages to be fully realized, and for SMS to become the “gold standard” sequencing approach, significant issues and hurdles must be solved and overcome. During this program, Electronic BioSciences, Inc. (EBS) aims to demonstrate a completely new and enabling SMS method that will possess the ability to directly and correctly identify individual nucleotides, including chemically modified nucleotides. During this project, we will both demonstrate the ability of this entirely new sequencing approach to sequence DNA with high accuracy (directly comparing the obtained accuracy, throughput, error mechanisms and associated rates to other SMS approaches) and correctly identify (and sequence) 5-methylcytosine (5mC) and its derivatives, at the single molecule level. At the conclusion of this Phase I project, we will have successfully demonstrated an entirely new and dramatically improved SMS approach, and reduced the associated risks involved with its full future commercial developments. There is a current need within the field of next generation sequencing (NGS) or so called third generation sequencing (TGS) for new, enabling instrumentation that is capable of high-accuracy, direct, native DNA sequencing, including the ability to correctly identify canonical and modified bases, homopolymer stretches, and sequence repeats. The entirely new SMS methodology that will be developed during this project will overcome known hurdles and limitations of currently available NGS, TGS, and SMS technologies, resulting in technology that is cost-efficient, highly accurate, easy to setup and utilize, capable of de novo sequencing and modified base calling, and yields highly simplistic data for easy analysis and post possessing. Through significant advancements made during this program, this resulting technology will revolutionize the use of the genome and epigenome, radically change standard R&D and clinical practices, and greatly advance clinical diagnostics, prognostics, and therapeutic decision making. Project Narrative The novel single-molecule sequencing (SMS) technology developed during this project will enable high- accuracy, direct, native DNA sequencing, including the ability to correctly identify canonical and modified bases, homopolymer stretches, and sequence repeats via a cost-efficient and easy-to-use methodology. The impact of these advances in SMS will eventually enable wide-scale, routine clinical care and diagnostics toward advanced precision medicine, not just R&D. The performance and accessibility of such technology will transform the understanding and application of genomics and epigenomics, the associated clinical practices, that ability to provide precision clinical diagnostics, prognostics, and therapeutic decision making for improved public healthcare and wellbeing.",The Enzymatic Reader,9677956,R43HG010427,"['Biological', 'Biological Sciences', 'Caliber', 'Chemicals', 'Chemistry', 'Church', 'Complex', 'DNA Primers', 'DNA Sequence', 'DNA polymerase A', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disadvantaged', 'Drops', 'Electrodes', 'Enzymes', 'Evaluation', 'Future', 'Genome', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Ions', 'Label', 'Length', 'Lipid Bilayers', 'Logistics', 'Methodology', 'Methods', 'Motor', 'Movement', 'Noise', 'Nucleotides', 'Performance', 'Personal Satisfaction', 'Phase', 'Polymerase', 'Polymers', 'Preparation', 'Process', 'Proteins', 'RNA', 'Reader', 'Reading Frames', 'Reproducibility', 'Risk', 'Sampling', 'Side', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Tools', 'Speed', 'Stretching', 'System', 'Technology', 'Therapeutic', 'Third Generation Sequencing', 'Time', 'base', 'clinical care', 'clinical diagnostics', 'clinical practice', 'cost', 'cost efficient', 'electric field', 'epigenome', 'epigenomics', 'epitranscriptomics', 'improved', 'instrumentation', 'machine learning algorithm', 'nanopore', 'next generation sequencing', 'novel', 'precision medicine', 'prevent', 'prognostic', 'programs', 'research and development', 'single molecule', 'solid state', 'transcriptomics']",NHGRI,"ELECTRONIC BIOSCIENCES, INC.",R43,2019,247611,0.027610910130181906
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9735436,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,454366,-0.014359754974416708
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9406205,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2018,372603,0.02572340386304208
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell- based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off- target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9678132,U01HL145793,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety testing', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NHLBI,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2018,651251,0.02532003625936563
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9617314,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Supervision', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2018,249000,0.03643956059637088
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed un- derstanding of admixture is essential for e ective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on pheno- type are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simpli ed models at the risk of inaccurate inferences. This pro- posal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to lever- age this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate power- ful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as e ectively as homogeneous populations. The rst step in obtaining a thorough understanding of admixture is a principled and scalable statis- tical framework to infer ne-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop e ective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major im- pact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to eciently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human pheno- types, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on ne-scale genomic struc- ture and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can bene t from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9547454,R35GM125055,"['Admixture', 'Age', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2018,332952,0.02398956584803385
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9507167,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2018,242837,-0.00422349120405517
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9486266,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2018,479215,0.030681819253386162
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9531422,R01HG009188,"['Affect', 'Base Pairing', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'Custom', 'DNA', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Reproducibility', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'collaborative environment', 'cost', 'enzyme activity', 'experimental study', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2018,468098,0.016954109677855923
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9562959,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2018,1186500,-0.008066041591336696
"Addressing Open Challenges of Computational Genome Annotation We propose to capitalize on success of ongoing collaboration between the bioinformatics teams at the University of Greifswald (Germany) and at the Georgia Institute of Technology (USA) and address open challenges in computational genome annotation. In the course of this development, we plan to implement new algorithmic ideas and satisfy the needs of unbiased integration of different types of OMICS data.  We plan to address one of the long-standing problems at interface of bioinformatics and machine learning – automatic generative and discriminative parameterization of gene finding algorithms. Current methods of combining OMICS evidence frequently result in under predicting or over predicting tools. Having good understanding of the difficulties and the properties of different types of OMICS evidence we propose an optimized approach to the full unsupervised, generative and discriminative training.  We will introduce novel means to optimize integration of multiple OMICS evidence into gene prediction. These ideas will develop further the protein family-based gene finding implemented in AUGUSTUS-PPX. We propose to create representations of protein families for gene finding that for the first time include cross-species gene structure information.  We will develop a new approach that will unify two advanced research areas - transcript reconstruction from RNA-Seq and statistical gene finding that integrates RNA-Seq and homology information. We will describe a new, comprehensive model and EM-like algorithmic technique (the “wholistic” approach) to identify the sets of transcripts and their expression levels that best fit the available OMICS evidence.  We will also develop an automatic gene-finding algorithm for a full content of metagenomes including eukaryotic and viral metagenomic sequences. This task is conventionally considered too challenging. We propose a solution exploiting and advancing algorithmic ideas and approaches that we mastered in the course of creating gene finders for prokaryotic metagenomes as well as eukaryotic genomes.  All new tools will be available to the community under open source licenses. The goal of this project is to advance the science of genome interpretation by developing much needed computational methods and tools for high precision annotation of eukaryotic genomes and metagenomes. This advance will make an impact in research on model and non-model organisms including important human pathogens, parasites and viruses. New high throughput technologies generate volumes of sequence data on complex genomes as well as metagenomes. Still these big data volumes have to be transformed into scientific knowledge. Our new bioinformatics tools, matching the latest sequencing technology in speed and performance, will make a significant impact in genomic research aiming at ultimate understanding of human health and disease.",Addressing Open Challenges of Computational Genome Annotation,9501001,R01GM128145,"['Address', 'Algorithms', 'Alternative Splicing', 'Area', 'Bacteriophages', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Chronic', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complement', 'Complex', 'Computing Methodologies', 'Data', 'Deterioration', 'Development', 'Development Plans', 'Disease', 'Gene Family', 'Gene Structure', 'Genes', 'Genome', 'Genomics', 'Germany', 'Goals', 'Health', 'Human', 'Insecta', 'Institutes', 'Introns', 'Knowledge', 'Length', 'Licensing', 'Machine Learning', 'Maintenance', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Nested Genes', 'Noise', 'Overlapping Genes', 'Parasites', 'Performance', 'Population', 'Positioning Attribute', 'Property', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'RNA Splicing', 'Research', 'Running', 'Speed', 'Spliced Genes', 'Statistical Models', 'Supervision', 'Techniques', 'Technology', 'Time', 'Training', 'Transcript', 'Universities', 'Viral', 'Virus', 'annotation  system', 'base', 'computerized tools', 'cost', 'course development', 'design', 'evidence base', 'expectation', 'gene complementation', 'genome annotation', 'genome sciences', 'high throughput technology', 'improved', 'instrument', 'member', 'metagenome', 'multiple omics', 'nanopore', 'new technology', 'novel', 'novel strategies', 'open source', 'operation', 'pathogen', 'predictive tools', 'protein profiling', 'reconstruction', 'success', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2018,359810,0.011235651005632423
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies (1-3). In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Ongoing work has involved further research to improve control of false positive rates while retaining excellent power and comparison of our new methods to several other feature-selection schemes. We have also been developing and testing a new approach for specifically identifying which selected features are actually interacting as opposed to acting independently. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published three papers describing this method. We are currently developing The Machine Suite which will be an extension of r2VIM. A manuscript presenting the updates to our methods is under preparation.   We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 and another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  We have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the 2015 International Genetic Epidemiology Society meeting (CL Simpson). Work is ongoing to improve pipelines for application of family-based methods for improved quality control in whole genome sequence data. A chapter that reviewed and compared parametric and non-parametric linkage analysis methods and their relevance to modern genomic data was published this year (1).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. Simulations are ongoing to compare our new methods to existing methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. Two papers extending these methods to pedigree data are currently under review. We are now in the process of applying these approaches to several of our genome-wide datasets.  Finally, we have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. A manuscript is under review for this recent project. n/a",Development of statistical genetics methodology,9795949,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Linear Models', 'Linkage Disequilibrium', 'Machine Learning', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Modernization', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Process', 'Publishing', 'Quality Control', 'Recurrence', 'Research', 'Running', 'Sampling', 'Scheme', 'Sequence Analysis', 'Societies', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Update', 'Variant', 'Work', 'base', 'case control', 'caucasian American', 'data mining', 'data warehouse', 'density', 'exome', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genetic pedigree', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'novel strategies', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2018,432702,0.006150530390779507
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9527264,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell Count', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",K99,2018,40760,0.06647781230954235
"Molecular impact of mutations in monogenic disease and cancer ABSTRACT  Next generation genome scale sequencing of patients is now becoming routine for two classes of disease: rare  Mendelian traits and cancer. In favorable cases, these data allow identification of relevant mutations and thus  aid diagnosis and therapy. In both classes of disease, the most common type of mutation is missense -­ single  base  changes  that  result  in  an  amino  acid  substitution  in  a  protein.  Uncertainty  as  to  the  impact  of  these  mutations on in vivo protein activity has resulted in a very conservative approach to their interpretation in the  clinic,  so  causing  many  missed  opportunities  for  targeted  treatment.  The  goal  of  this  project  is  to  use  a  combination of three strategies to make the interpretation of these mutations much more applicable in the clinic.  There are already a large number of computational methods that attempt to determine the impact of missense  mutations on function, and there is substantial evidence that these have useful accuracy. The primary difficulty  is that the accuracy in any particular case is not reliably calibrated. Therefore, our first aim is to use a combination  of these methods to develop an approach focused on more reliable estimates for the probability of high impact  on  protein  function  (i.e.  more  confident  P  values).  The  second  aim  is  to  maximize  the  utilization  of  three-­ dimensional structural information, largely ignored by most computational methods. A large fraction of missense  mutations in these classes of disease act by destabilizing protein structure and knowledge of structure allows  these to be identified with much higher reliability. Also, structure provides a framework for detailed annotation  and comprehension of function. To facilitate the utilization of structure, we will implement a modeling platform  that leverages available experimental information to maximize the structural data available for analyzing mutation  impact.  An  important  aspect  of  the  platform  is  incorporation  of  methods  for  evaluating  the  reliability  of  the  structural features relevant to analysis of each mutation. In the third aim we will build specific functional models  for each protein of interest, integrating information from current databases, the literature, and community input,  so as to provide the richest possible background against which to judge the impact of mutations. Proteopedia, a  well established media wiki for proteins, will be used to provide an integrated view of text, data, and structure. A  key component of the information resource will be contributions from curators, who will provide annotation and  also solicit input from other experts. This aspect of the project builds on experience with other crowdsourcing  endeavors,  including  CASP,  CAGI  and  Proteopedia.    There  will  be  three  primary  outcomes  from  the  project:  First, improved reliability for the interpretation of missense mutations. Second, a prototype mutation annotation  procedure suitable for use in a clinical setting. Third, the resource will provide information of benefit to a range  of other scientists, thus facilitating the analysis of disease related mutations.      NARRATIVE  Genome  scale  DNA  sequencing  is  now  contributing  to  diagnosis  and  therapy  in  cases  of  rare  human  disease and cancer.  Full exploitation of these data is currently hampered by inadequate understanding  of which DNA changes affect protein function so as to contribute to disease. This project aims to develop  the methods and tools needed to remove that obstacle. ",Molecular impact of mutations in monogenic disease and cancer,9504498,R01GM120364,"['AIDS diagnosis', 'AIDS therapy', 'Address', 'Affect', 'Amino Acid Substitution', 'Clinic', 'Clinical', 'Communities', 'Comprehension', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA sequencing', 'Data', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Goals', 'Information Resources', 'Knowledge', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mendelian disorder', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Patients', 'Play', 'Probability', 'Procedures', 'Process', 'Proteins', 'Rare Diseases', 'Reporting', 'Resources', 'Role', 'Scientist', 'Structural Models', 'Structure', 'Tertiary Protein Structure', 'Text', 'Uncertainty', 'base', 'clinically relevant', 'crowdsourcing', 'experience', 'genome-wide', 'human disease', 'human model', 'improved', 'in vivo', 'interest', 'learning strategy', 'next generation', 'primary outcome', 'protein function', 'protein protein interaction', 'protein structure', 'prototype', 'targeted treatment', 'tool', 'trait', 'wiki']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2018,336086,0.006254087136856371
"Novel Nanopore-based RNA Sequencing using Nucleobase-specific Tags Project Summary Cost-effective, and accurate sequencing of RNA, composed of both canonical and modified bases, of any length, without conversion to cDNA, and without amplification are the objectives of this project, and the ultimate goal is to sequence the transcriptome, and determine in a time-sensitive manner relative distribution of its components. Such accomplishment will directly impact prevention, diagnosis, and cure of disease and materialize the promise of personalized medicine. Current methods, such as Illumina's RNA-Seq, and the single molecule approaches of Pacific Biosciences and of Oxford Nanopore Technologies, still lag behind in many of the critical attributes mentioned above. The unresolved issue with nanopore-based sequencing is the observation that ion current vs. time recording does not refer to a single nucleobase, but to a short sequence of 4 or more bases. The problem, partially resolved with the use of sophisticated algorithms and learning machines, appears intractable for RNA that includes numerous post-transcriptional base modifications. As an illustration, if a nanopore reads a sequence of 4 bases and the specific RNA to be sequenced has a total of 8 different nucleobases (4 canonical and 4 modified), then 48 = 65,536 signals need to be discriminated from within an ion current range of 20 to 40 pA with a standard deviation of ±1 pA; this is an impossible computational task. However, if the nanopore could sense one base at a time and yield distinct ion current for each base, there will be only 8 different recordings to distinguish from, a much simpler task. Our own published results indicate that oligodeoxynucleotides conjugated with a pyrimidine-specific tag (Osmium tetroxide 2,2'-bipyrimidine or OsBp) yield enzyme-free, slow/readable translocation via α- Hemolysin, and distinct ion current levels for intact, T(OsBp), and C(OsBp) bases, suggesting that a single tag can yield sequencing information on purine, T, and C. The latter leads to the conjecture that the presence of a second, purine-specific, label would allow identification of all four canonical bases. Furthermore each tag has intrinsic selectivity for one base over another, and this will provide a handle for additional discrimination among the modified bases. In this phase I proposal we aim to demonstrate (i) near 100% labeling (true positives) with 0% internucleotide bond cleavage, and 0% false positives for RNA(OsBp), as we have already shown for DNA(OsBp), (ii) comparable labeling attributes for a purine-specific tag, and (iii) readable translocation with single pyrimidine base discrimination for RNA(OsBp). Success in these efforts will lead to single base discrimination and sequencing of RNA, including a number of post-transcriptionally modified bases, and pave the road for sequencing the transcriptome. ! PUBLIC HEALTH RELEVANCE: Advances in personalized medicine for diagnosis and treatment of disease require sequencing the RNA transcriptome with technologies that are currently unavailable. Nanopore-systems that exhibit single-base discrimination, like the one addressed in this proposal, will allow sequencing the transcriptome in an accurate, timely, and cost-effective manner.",Novel Nanopore-based RNA Sequencing using Nucleobase-specific Tags,9506880,R43HG010051,"['Address', 'Algorithmic Software', 'Algorithms', 'Base Sequence', 'Belief', 'Biological Assay', 'Biological Sciences', 'Cells', 'Complementary DNA', 'DNA', 'Development', 'Diagnosis', 'Digit structure', 'Discrimination', 'Disease', 'Enzymes', 'Exhibits', 'Genetic Transcription', 'Goals', 'Hemolysin', 'In Vitro', 'Individual', 'Investigation', 'Ions', 'Label', 'Length', 'Machine Learning', 'Measures', 'Methods', 'Modification', 'Monitor', 'Nucleic Acids', 'Nucleotides', 'Oligonucleotides', 'Osmium Tetroxide', 'Phase', 'Platinum', 'Platinum Compounds', 'Prevention', 'Protocols documentation', 'Publishing', 'Purines', 'Pyrimidine', 'Pyrimidines', 'RNA', 'RNA Sequences', 'Readability', 'Residual state', 'Signal Transduction', 'Site', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Transfer RNA', 'VDAC1 gene', 'analytical tool', 'base', 'constriction', 'cost effective', 'design', 'improved', 'nanopore', 'new technology', 'novel', 'nucleobase', 'personalized medicine', 'public health relevance', 'sensor', 'single molecule', 'success', 'transcriptome', 'transcriptome sequencing']",NHGRI,"YENOS ANALYTICAL, LLC",R43,2018,280000,0.0025775611141180634
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9498252,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Generic Drugs', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'cancer therapy', 'computerized data processing', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",R01,2018,158992,0.00012837802344754123
"Bioformatics Core The mission The Bioinformatics Core facilitates, amplifies, and accelerates biological and medical research and discovery through the application of the latest bioinformatics methods and technologies. This mission is achieved by delivering high quality and comprehensive support for experimental design, analysis and visualization in a timely fashion. The core is responsive to research scientists needs and effectively evolves with advances in the field. The core services include but are not limited to the following:  Statistical analysis including basic statistical analysis, advanced statistical analysis (e.g., linear and generalized mixed model analysis, longitudinal modeling), and custom statistical methods (e.g., tailored to specific research projects)  Omics Analysis including: Transcriptomics (Microarray and RNA-seq), Genomics (Genome, exome and targeted DNA-seq), Epigenomics (Methyl-seq, ChIP-seq, etc.), Proteomics, and Metabolomics  Gene/Target/Disease Analysis: Functional annotation at variant, gene, and geneset level, Interaction analysis, and Pathway enrichment analysis  Ad-hoc consultation: Advise on experimental designs, data management and analysis  Computing resource development and maintenance, including Bioinformatics Software Development, Systems Toolkits Development, customized biological databases and Web Services development  Training: Personalized training to match users specific requirements and group training and workshops  Scientific impact  We routinely meet with PIs and/or researchers to discuss the types of analyses and support that our statistical and bioinformatics expertise can provide to help them design experiments. We help with grant proposals to incorporate statistical and computational biology methods or techniques. We also prepare letters of support for such grant proposals. The Core statistical and bioinformatics consulting and collaboration covers a broad range of study design, statistical analyses and data science issues including experimental design for preclinical investigations, population studies, and Big Data analytics, and statistical analysis of next generation sequence data and omics data. The core is also actively involved in statistical and bioinformatics methods research and development and collaborates with PIs, Postdocs, and Staff in writing and implementing competitive project proposals involving methodological and software development. In fiscal year 2017, the core actively participated in 3 CHIRP grant proposals, provided letters of support for 4 postdoctoral K award applicants and as mentioned above 4consulted and collaborated with 31 PIs, and staff for their experimental design and analyses. The core has also contributed to 5 manuscripts and more than 15 posters and abstracts for conference presentation.  Cores research and method development  The Bioinformatics core in collaboration with laboratories at the MHLBI is heavily involved in research and new methods developments. Summarized below are few examples.  > lncRNA detection and functional annotation: With advances in Next Generation Sequencing (NGS), the accessibility of affordable high-throughput sequencing is now generating a wealth of novel, unannotated transcripts, especially long noncoding RNAs (lncRNAs) that are derived from genomic regions that are antisense, intronic, intergenic, and overlapping protein-coding loci. Parsing and characterizing the functions of noncoding RNAs and lncRNAs in particular, is one of the great challenges of modern genome biology. In collaboration with Dr. Haiming Cao, we devised computational methods for the identification and functional characterization of lncRNAs from genomic and transcriptomic data. We also developed bioinformatics pipelines to identify lncRNAs in a dataset and then, employed machine learning approaches for functional characterization of the fragments.  > Proteogenomics: In recent years, with advances in NGS technologies such as RNA- Seq and mass spectrometry-based proteomics, the new era of Proteogenomics research has emerged. In collaboration with several PIs and our Proteomics Core at the NHLBI, we developed customized protein sequence databases using genomic and transcriptomic information to help identify novel peptides that are not present in reference protein sequence databases from mass spectrometry-based proteomic data. We also developed pipeline and computational strategies for building and using customized protein sequence databases. The proteomic data can be used to provide protein-level evidence of gene expression and to help refine gene models.  > Software development for cell free DNA: Donor-derived cell-free DNA (dd-cfDNA), is an emerging biomarker of acute cellular rejection in organ transplant recipients. dd- cfDNA is derived from the transplanted organ and detectable in blood and urine of transplant recipients. In collaboration with Dr. Valentines laboratory, we developed methods for quantification of cell-free DNA (cfDNA) in circulating blood derived from a transplanted organ as a powerful approach for monitoring post-transplant injury and outcome. Our pipeline quantifies donor-derived cfDNA (dd-cfDNA) by discriminant analysis of single-nucleotide polymorphisms (SNPs) between donor and recipient DNA molecules that are distributed across the genome. Plasma levels of dd-cfDNA were assessed for utility in diagnosing rejection and evaluating treatment response in transplant recipients in a longitudinal observational trial.  Training and education We train users on data analysis and help with the manuscript preparation. We meet with investigators who are starting new projects to discuss the best approaches and help with the experimental design. Currently several post-bacs and post-docs frequently visit and consult with core staff on a regular basis to advance their study. n/a",Bioformatics Core,9788008,ZICHL006228,"['Acute', 'Amino Acid Sequence Databases', 'Applications Grants', 'Big Data', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biological databases', 'Biology', 'Biotechnology', 'Blood', 'Budgets', 'Cell Differentiation process', 'Cells', 'ChIP-seq', 'Classification', 'Code', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Consult', 'Consultations', 'Custom', 'Cytometry', 'DNA', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Development', 'Developmental Biology', 'Diagnosis', 'Dimensions', 'Discriminant Analysis', 'Disease', 'Educational workshop', 'Experimental Designs', 'Flow Cytometry', 'Fluorescence', 'Future', 'Galaxy', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'High-Throughput Nucleotide Sequencing', 'Imagery', 'Injury', 'Internet', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Letters', 'Level of Evidence', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Mass Spectrum Analysis', 'Medical Research', 'Methodology', 'Methods', 'Methylation', 'Mission', 'Modeling', 'Modernization', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Nucleotides', 'Organ Transplantation', 'Outcome', 'Pathway interactions', 'Peptides', 'Phenotype', 'Plasma', 'Population Study', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preparation', 'Proteins', 'Proteomics', 'Public Domains', 'Pythons', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Sample Size', 'Scientist', 'Sequence Analysis', 'Services', 'Single Nucleotide Polymorphism', 'Small RNA', 'Statistical Data Interpretation', 'Statistical Methods', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Training and Education', 'Transcript', 'Transplant Recipients', 'Transplantation', 'Untranslated RNA', 'Urine', 'Variant', 'Visit', 'Writing', 'base', 'biological research', 'cell free DNA', 'computing resources', 'data management', 'data visualization', 'design', 'differential expression', 'epigenomics', 'exome', 'experimental analysis', 'experimental study', 'genomic RNA', 'high dimensionality', 'histone modification', 'metabolomics', 'method development', 'next generation sequence data', 'next generation sequencing', 'novel', 'posters', 'pre-clinical', 'proteogenomics', 'research and development', 'single cell analysis', 'software development', 'symposium', 'tool', 'transcriptome sequencing', 'transcriptomics', 'treatment response', 'web services', 'web site']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIC,2018,1262439,0.005640891090097075
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9509468,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2018,300000,0.048399135583241965
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9483341,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2018,864186,-0.02776878449534329
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases Project Summary (unchanged) Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically “on” and “off” state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by a diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: · To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity · To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. Health Narrative (unchanged) Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9700377,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Development', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Genes', 'Genomics', 'Goals', 'Health', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Research', 'Research Personnel', 'Signal Transduction', 'Site', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'inhibitor/antagonist', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'predictive test', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2018,74718,0.04682617931500414
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9494629,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human model', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,300473,0.021385787402153054
"Massively parallel functional analyses of human PTEN variants Project Summary  We are now able to routinely sequence human genomes at single-base resolution. However, our ability to interpret the functional consequences of detected mutations has lagged behind. Computational approaches scale well but have poor accuracy, whereas retrospective analysis of detected variants has high accuracy but does not scale well. In order to solve this problem, a new experimental paradigm has emerged to empirically characterize the effects of mutations with high accuracy at scale. This approach takes advantage of recent and ongoing improvements in DNA synthesis and sequencing, and has the potential to offer unprecedented insight into protein biochemistry and human disease. We believe these insights will prove to be critical for unlocking the potential of genomic medicine.  In this project we seek to comprehensively assess multiple molecular effects of PTEN mutations on protein function, and assess the utility of this data as a predictor for human clinical phenotype. The PTEN protein is a tumor suppressor that is frequently mutated in diverse human cancers and in the germline of some individuals with overgrowth disorders, cancer predisposition syndromes, or autism. Currently, it is impossible to predict the effects of the vast majority of PTEN germline mutations. Since the phenotypic spectrum of PTEN mutation carriers is broad, it would be highly valuable to understand the ways in which phenotypic outcomes arise from PTEN mutation genotypes.  In Aim 1, we will first employ a yeast-based screen to assess the effects all PTEN single amino acid mutations on lipid phosphatase activity, the primary biochemical function of PTEN protein. It is known that several pathogenic variants are destabilized. Therefore, in Aim 2, we will perform a second, independent screen to assess the steady state protein stability of all PTEN single amino acid mutations. In Aim 3, we will use the data derived from this study as well as publically available biochemical information to train a classifier model to predict the relationship between the mutation genotypes and clinical phenotypes observed in humans. These data will increase our fundamental understanding of PTEN function and the role of mutations in diverse disorders, and could provide a valuable clinical tool that would increase the quality of life for PTEN mutation carriers. Project Narrative  Mutations in the gene PTEN are causal for a diverse set of clinical disorders ranging from cancer to autism spectrum disorder. Here, we seek to gain new fundamental insights into the functional relationships between PTEN mutations and clinical presentations by prospectively characterizing the effects of all single amino acid PTEN mutations in parallel. These data will allow the creation of new models that can predict risk of specific PTEN mutations for different clinical outcomes and potentially lead to personalized therapies, early interventions, and optimal outcomes for PTEN mutation carriers.",Massively parallel functional analyses of human PTEN variants,9539482,F31HD095571,"['Affect', 'Amino Acids', 'Autistic Disorder', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biology', 'Biophysics', 'Cataloging', 'Catalogs', 'Cell Separation', 'Cell Survival', 'Cells', 'Characteristics', 'Clinic', 'Clinical', 'Complex', 'Coupled', 'Coupling', 'DNA biosynthesis', 'DNA sequencing', 'Data', 'Data Set', 'Deletion Mutation', 'Development', 'Disease', 'Early Intervention', 'FRAP1 gene', 'Fluorescence', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Germ-Line Mutation', 'Goals', 'Growth', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Lead', 'Light', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Metabolism', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Outcome', 'PTEN gene', 'PTEN protein', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Phosphatidylinositols', 'Phosphoric Monoester Hydrolases', 'Play', 'Predisposition', 'Problem Solving', 'Process', 'Protein Biochemistry', 'Proteins', 'Pythons', 'Quality of life', 'Reaction', 'Resolution', 'Risk', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Syndrome', 'Techniques', 'Temperature', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tumor Suppressor Proteins', 'Ubiquitination', 'Variant', 'Yeast Model System', 'Yeasts', 'accurate diagnosis', 'autism spectrum disorder', 'base', 'clinical phenotype', 'experimental study', 'fitness', 'genomic signature', 'genomic variation', 'high throughput technology', 'human disease', 'improved', 'insight', 'mutation carrier', 'next generation', 'novel', 'open source', 'personalized medicine', 'prediction algorithm', 'predictive modeling', 'prospective', 'protein function', 'screening', 'synthetic biology', 'tool', 'tumorigenic']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,F31,2018,44524,0.05723441089269358
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9518337,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2018,537909,0.041209393669260956
"Molecular Characterization of Joubert Syndrome Project Summary Congenital ataxia presents in early childhood with non-progressive hypotonia, gross motor, fine motor and cognitive delays. These disorders are distinct from the progressive ataxias because of the presence of congenital cerebellar malformations and because they are typically inherited recessively. Joubert Syndrome and Related Disorders (JSRD) constitute a major subset of these conditions, consisting of a cerebellar midline (vermis) malformation, a nearly pathognomonic Molar Tooth sign on brain Imaging (MTI) and co-existent oculomotor apraxia and episodic breathing dysrhythmias. In our published data, we have: 1] Identified ten unique genetic causes of JSRD (nearly half of the published causes), 2] Generated genotype-phenotype correlations involving cerebellar, retinal, renal, hepatic, digit, and cerebral manifestations. 3] Identified common founder mutations that allow for population-based screening. 4] Discovered that JSRD encoded proteins frequently localize to the cilium. 5] Identified ciliary transition zone (TZ) defects in cells with JSRD mutations. 6] Performed siRNA cell-based screens for defective ciliogenesis to prioritize candidate JSRD genes. 7] Generated and characterized multiple zebrafish, mouse and human cell culture models for JSRD. 8] Defined the concept of ‘Ciliary localization’ model, in which one JSRD gene is required for ciliary localization of other JSRD proteins. In our unpublished data we have: 1] Recruited an additional 200 JSRD patients without molecular diagnosis. 2] Performed whole exome (WES) and whole genome sequencing (WGS) on an additional 100 JSRD families. 3] Identified an additional 12 novel likely JSRD candidate genes. 4] Generated IPSCs and cerebellar organoids from mutation-positive and negative families to aid in functional analysis and gene discovery using RNAseq. 5] Begun functional validation of the putative mutations. 6] Developed methods to interrogate ciliary structure in a high-throughput fashion with electron microscopy (EM). The goal of this competing renewal is to identify the remaining ‘discoverable’ genes that lead to JSRD when lost, functionally validate mutations within the pathogenetic framework, and test the hypothesis that mutations in JSRD genes lead to collapse of the ciliary TZ. Because the majority of patients still have unknown cause of disease, this renewal aims to advance knowledge through molecular characterization of new genes, using newly evolving high-throughput techniques, integrated bioinformatics, and a unique resource of consanguineous families recruited world-wide. We further aim to validate these mutations in patient cells, within a mechanistic framework that JSRD genes are required for essential ciliary structural components during cerebellar development. Project Narrative Joubert syndrome is a genetically and phenotypically heterogeneous neurodevelopmental disorder unified by defects of the cellular primary cilium. This work will identify new genetic causes and dissect ciliary defects associated with genetic mutations.",Molecular Characterization of Joubert Syndrome,9359994,R01NS048453,"['Apraxias', 'Ataxia', 'Bioinformatics', 'Brain imaging', 'Breathing', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Cells', 'Cerebellar malformation', 'Cerebellar vermis structure', 'Cerebrum', 'Cilia', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognitive', 'Congenital cerebellar hypoplasia', 'Cultured Cells', 'Cytoplasmic Granules', 'DNA Sequence Alteration', 'Data', 'Databases', 'Defect', 'Development', 'Digit structure', 'Disease', 'Electron Microscopy', 'Electrons', 'Embryo', 'Enrollment', 'Face', 'Family', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic screening method', 'Genotype', 'Goals', 'Gold', 'Hepatic', 'Human', 'Individual', 'Inherited', 'Joubert syndrome', 'Kidney', 'Knock-out', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Microscopic', 'Middle East', 'Modeling', 'Molar tooth', 'Molecular', 'Molecular Diagnosis', 'Morphogenesis', 'Morphology', 'Motor', 'Mus', 'Muscle hypotonia', 'Mutation', 'Neurodevelopmental Disorder', 'Organoids', 'Pathogenicity', 'Patients', 'Phenotype', 'Probability', 'Protein Analysis', 'Proteins', 'Publishing', 'Resources', 'Retinal', 'Risk', 'Scanning Electron Microscopy', 'Series', 'Severities', 'Signal Transduction', 'Small Interfering RNA', 'Sonication', 'Structure', 'Syndrome', 'Techniques', 'Termination of pregnancy', 'Testing', 'Three-dimensional analysis', 'Training', 'Transmission Electron Microscopy', 'Validation', 'Variant', 'WNT Signaling Pathway', 'Work', 'Zebrafish', 'accurate diagnosis', 'affection', 'base', 'cell type', 'cilium biogenesis', 'cohort', 'consanguineous family', 'disorder subtype', 'early childhood', 'exome', 'exome sequencing', 'fetal', 'founder mutation', 'gene discovery', 'genome sequencing', 'genome-wide', 'insight', 'knock-down', 'loss of function mutation', 'malformation', 'mutant', 'novel', 'oculomotor', 'population based', 'reconstruction', 'recruit', 'screening', 'stem cell biology', 'transcriptome sequencing', 'whole genome']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2018,510012,0.02615266583553004
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9416160,R00HG008171,"['Advisory Committees', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Code', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'cancer drug resistance', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'targeted nucleases', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2018,242325,-0.023732880405640384
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9205487,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2017,372603,0.02572340386304208
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,9397848,F32GM116381,"['Acceleration', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mutation', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'admixture mapping', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'learning strategy', 'melanoma', 'offspring', 'public health relevance', 'rare variant', 'rate of change', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2017,510,0.06087253464723077
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,9278228,F32GM116381,"['Acceleration', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mutation', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'admixture mapping', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'learning strategy', 'melanoma', 'offspring', 'public health relevance', 'rare variant', 'rate of change', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2017,36307,0.06087253464723077
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9333402,K99HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Supervision', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",K99,2017,37785,0.03643956059637088
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed un- derstanding of admixture is essential for e ective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on pheno- type are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simpli ed models at the risk of inaccurate inferences. This pro- posal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to lever- age this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate power- ful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as e ectively as homogeneous populations. The rst step in obtaining a thorough understanding of admixture is a principled and scalable statis- tical framework to infer ne-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop e ective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major im- pact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to eciently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human pheno- types, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on ne-scale genomic struc- ture and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can bene t from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9382936,R35GM125055,"['Admixture', 'Age', 'Alleles', 'Architecture', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'insight', 'novel', 'reference genome', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2017,225087,0.02398956584803385
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,9213314,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Supervision', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'learning strategy', 'mRNA Precursor', 'novel', 'prediction algorithm', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2017,17892,-0.03418766575583525
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9344966,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Molecular Profiling', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2017,1186500,-0.008066041591336696
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9353854,R01HG009188,"['Affect', 'Base Pairing', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'Custom', 'DNA', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modernization', 'Modification', 'Molecular Models', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Reproducibility', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'collaborative environment', 'cost', 'enzyme activity', 'experimental study', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2017,438098,0.016954109677855923
"Genome analysis based on the integration of DNA sequence and shape DESCRIPTION (provided by applicant): Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription facors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.",Genome analysis based on the integration of DNA sequence and shape,9203633,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Databases', 'DNA Integration', 'DNA Structure', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Dimensions', 'Drosophila genus', 'Embryonic Development', 'Family', 'Gaussian model', 'Gene Components', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Minor Groove', 'Modeling', 'Molecular Biology', 'Molecular Conformation', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'experimental study', 'flexibility', 'genetic evolution', 'genome analysis', 'genome browser', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'predictive tools', 'public health relevance', 'three dimensional structure', 'tool', 'transcription factor', 'vector', 'whole genome']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,309913,-0.0011765321731651587
"Molecular impact of mutations in monogenic disease and cancer ABSTRACT  Next generation genome scale sequencing of patients is now becoming routine for two classes of disease: rare  Mendelian traits and cancer. In favorable cases, these data allow identification of relevant mutations and thus  aid diagnosis and therapy. In both classes of disease, the most common type of mutation is missense -­ single  base  changes  that  result  in  an  amino  acid  substitution  in  a  protein.  Uncertainty  as  to  the  impact  of  these  mutations on in vivo protein activity has resulted in a very conservative approach to their interpretation in the  clinic,  so  causing  many  missed  opportunities  for  targeted  treatment.  The  goal  of  this  project  is  to  use  a  combination of three strategies to make the interpretation of these mutations much more applicable in the clinic.  There are already a large number of computational methods that attempt to determine the impact of missense  mutations on function, and there is substantial evidence that these have useful accuracy. The primary difficulty  is that the accuracy in any particular case is not reliably calibrated. Therefore, our first aim is to use a combination  of these methods to develop an approach focused on more reliable estimates for the probability of high impact  on  protein  function  (i.e.  more  confident  P  values).  The  second  aim  is  to  maximize  the  utilization  of  three-­ dimensional structural information, largely ignored by most computational methods. A large fraction of missense  mutations in these classes of disease act by destabilizing protein structure and knowledge of structure allows  these to be identified with much higher reliability. Also, structure provides a framework for detailed annotation  and comprehension of function. To facilitate the utilization of structure, we will implement a modeling platform  that leverages available experimental information to maximize the structural data available for analyzing mutation  impact.  An  important  aspect  of  the  platform  is  incorporation  of  methods  for  evaluating  the  reliability  of  the  structural features relevant to analysis of each mutation. In the third aim we will build specific functional models  for each protein of interest, integrating information from current databases, the literature, and community input,  so as to provide the richest possible background against which to judge the impact of mutations. Proteopedia, a  well established media wiki for proteins, will be used to provide an integrated view of text, data, and structure. A  key component of the information resource will be contributions from curators, who will provide annotation and  also solicit input from other experts. This aspect of the project builds on experience with other crowdsourcing  endeavors,  including  CASP,  CAGI  and  Proteopedia.    There  will  be  three  primary  outcomes  from  the  project:  First, improved reliability for the interpretation of missense mutations. Second, a prototype mutation annotation  procedure suitable for use in a clinical setting. Third, the resource will provide information of benefit to a range  of other scientists, thus facilitating the analysis of disease related mutations.      NARRATIVE  Genome  scale  DNA  sequencing  is  now  contributing  to  diagnosis  and  therapy  in  cases  of  rare  human  disease and cancer.  Full exploitation of these data is currently hampered by inadequate understanding  of which DNA changes affect protein function so as to contribute to disease. This project aims to develop  the methods and tools needed to remove that obstacle. ",Molecular impact of mutations in monogenic disease and cancer,9356560,R01GM120364,"['AIDS diagnosis', 'Address', 'Affect', 'Amino Acid Substitution', 'Clinic', 'Clinical', 'Communities', 'Comprehension', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA sequencing', 'Data', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mendelian disorder', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Patients', 'Play', 'Probability', 'Procedures', 'Process', 'Proteins', 'Rare Diseases', 'Reporting', 'Resources', 'Role', 'Scientist', 'Structural Models', 'Structure', 'Tertiary Protein Structure', 'Text', 'Uncertainty', 'base', 'clinically relevant', 'crowdsourcing', 'experience', 'genome-wide', 'human disease', 'improved', 'in vivo', 'interest', 'learning strategy', 'next generation', 'primary outcome', 'protein protein interaction', 'protein structure', 'prototype', 'targeted treatment', 'tool', 'trait', 'wiki']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2017,343120,0.006254087136856371
"Bioformatics Core The mission The Bioinformatics Core facilitates, amplifies, and accelerates biological and medical research and discovery through the application of the latest bioinformatics methods and technologies. This mission is achieved by delivering high quality and comprehensive support for experimental design, analysis and visualization in a timely fashion. The core is responsive to research scientists needs and effectively evolves with advances in the field. The core services include but are not limited to the following:  Statistical analysis including basic statistical analysis, advanced statistical analysis (e.g., linear and generalized mixed model analysis, longitudinal modeling), and custom statistical methods (e.g., tailored to specific research projects)  Omics Analysis including: Transcriptomics (Microarray and RNA-seq), Genomics (Genome, exome and targeted DNA-seq), Epigenomics (Methyl-seq, ChIP-seq, etc.), Proteomics, and Metabolomics  Gene/Target/Disease Analysis: Functional annotation at variant, gene, and geneset level, Interaction analysis, and Pathway enrichment analysis  Ad-hoc consultation: Advise on experimental designs, data management and analysis  Computing resource development and maintenance, including Bioinformatics Software Development, Systems Toolkits Development, customized biological databases and Web Services development  Training: Personalized training to match users specific requirements and group training and workshops  Scientific impact  We routinely meet with PIs and/or researchers to discuss the types of analyses and support that our statistical and bioinformatics expertise can provide to help them design experiments. We help with grant proposals to incorporate statistical and computational biology methods or techniques. We also prepare letters of support for such grant proposals. The Core statistical and bioinformatics consulting and collaboration covers a broad range of study design, statistical analyses and data science issues including experimental design for preclinical investigations, population studies, and Big Data analytics, and statistical analysis of next generation sequence data and omics data. The core is also actively involved in statistical and bioinformatics methods research and development and collaborates with PIs, Postdocs, and Staff in writing and implementing competitive project proposals involving methodological and software development. In fiscal year 2017, the core actively participated in 3 CHIRP grant proposals, provided letters of support for 4 postdoctoral K award applicants and as mentioned above 4consulted and collaborated with 31 PIs, and staff for their experimental design and analyses. The core has also contributed to 5 manuscripts and more than 15 posters and abstracts for conference presentation.  Cores research and method development  The Bioinformatics core in collaboration with laboratories at the MHLBI is heavily involved in research and new methods developments. Summarized below are few examples.  > lncRNA detection and functional annotation: With advances in Next Generation Sequencing (NGS), the accessibility of affordable high-throughput sequencing is now generating a wealth of novel, unannotated transcripts, especially long noncoding RNAs (lncRNAs) that are derived from genomic regions that are antisense, intronic, intergenic, and overlapping protein-coding loci. Parsing and characterizing the functions of noncoding RNAs and lncRNAs in particular, is one of the great challenges of modern genome biology. In collaboration with Dr. Haiming Cao, we devised computational methods for the identification and functional characterization of lncRNAs from genomic and transcriptomic data. We also developed bioinformatics pipelines to identify lncRNAs in a dataset and then, employed machine learning approaches for functional characterization of the fragments.  > Proteogenomics: In recent years, with advances in NGS technologies such as RNA- Seq and mass spectrometry-based proteomics, the new era of Proteogenomics research has emerged. In collaboration with several PIs and our Proteomics Core at the NHLBI, we developed customized protein sequence databases using genomic and transcriptomic information to help identify novel peptides that are not present in reference protein sequence databases from mass spectrometry-based proteomic data. We also developed pipeline and computational strategies for building and using customized protein sequence databases. The proteomic data can be used to provide protein-level evidence of gene expression and to help refine gene models.  > Software development for cell free DNA: Donor-derived cell-free DNA (dd-cfDNA), is an emerging biomarker of acute cellular rejection in organ transplant recipients. dd- cfDNA is derived from the transplanted organ and detectable in blood and urine of transplant recipients. In collaboration with Dr. Valentines laboratory, we developed methods for quantification of cell-free DNA (cfDNA) in circulating blood derived from a transplanted organ as a powerful approach for monitoring post-transplant injury and outcome. Our pipeline quantifies donor-derived cfDNA (dd-cfDNA) by discriminant analysis of single-nucleotide polymorphisms (SNPs) between donor and recipient DNA molecules that are distributed across the genome. Plasma levels of dd-cfDNA were assessed for utility in diagnosing rejection and evaluating treatment response in transplant recipients in a longitudinal observational trial.  Training and education We train users on data analysis and help with the manuscript preparation. We meet with investigators who are starting new projects to discuss the best approaches and help with the experimental design. Currently several post-bacs and post-docs frequently visit and consult with core staff on a regular basis to advance their study. n/a",Bioformatics Core,9572333,ZICHL006228,"['Acute', 'Amino Acid Sequence Databases', 'Applications Grants', 'Big Data', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biological databases', 'Biology', 'Biotechnology', 'Blood', 'Budgets', 'Cell Differentiation process', 'Cells', 'ChIP-seq', 'Classification', 'Code', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Consult', 'Consultations', 'Custom', 'Cytometry', 'DNA', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Development', 'Developmental Biology', 'Diagnosis', 'Dimensions', 'Discriminant Analysis', 'Disease', 'Educational workshop', 'Experimental Designs', 'Flow Cytometry', 'Fluorescence', 'Future', 'Galaxy', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'High-Throughput Nucleotide Sequencing', 'Imagery', 'Injury', 'Internet', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Letters', 'Level of Evidence', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Mass Spectrum Analysis', 'Medical Research', 'Methodology', 'Methods', 'Methylation', 'Mission', 'Modeling', 'Modernization', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Nucleotides', 'Organ Transplantation', 'Outcome', 'Pathway interactions', 'Peptides', 'Phenotype', 'Plasma', 'Population Study', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preparation', 'Proteins', 'Proteomics', 'Public Domains', 'Pythons', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Sample Size', 'Scientist', 'Sequence Analysis', 'Services', 'Single Nucleotide Polymorphism', 'Small RNA', 'Statistical Data Interpretation', 'Statistical Methods', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Training and Education', 'Transcript', 'Transplant Recipients', 'Transplantation', 'Untranslated RNA', 'Urine', 'Variant', 'Visit', 'Writing', 'base', 'biological research', 'cell free DNA', 'computing resources', 'data management', 'data visualization', 'design', 'differential expression', 'epigenomics', 'exome', 'experimental analysis', 'experimental study', 'genomic RNA', 'high dimensionality', 'histone modification', 'metabolomics', 'method development', 'next generation', 'next generation sequencing', 'novel', 'posters', 'pre-clinical', 'proteogenomics', 'research and development', 'single cell analysis', 'software development', 'symposium', 'tool', 'transcriptome sequencing', 'transcriptomics', 'treatment response', 'web services', 'web site']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIC,2017,1014574,0.005640891090097075
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9275537,U01HG009086,"['Accounting', 'Affect', 'Architecture', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2017,864186,-0.02776878449534329
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9301599,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2017,300000,0.048399135583241965
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9275505,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2017,300742,0.021385787402153054
"Molecular Characterization of Joubert Syndrome ﻿    DESCRIPTION (provided by applicant): Congenital ataxia presents in early childhood with non-progressive hypotonia, gross and fine motor delay and cognitive delays. These disorders are distinct from the progressive ataxias because of the presence of congenital cerebellar malformations and because they are typically inherited recessively. Joubert Syndrome and Related Disorders (JSRD) constitute a major subset of these conditions, consisting of a cerebellar midline (vermis) malformation, a nearly pathognomonic Molar Tooth sign on brain Imaging (MTI) and co-existent oculomotor apraxia and episodic breathing dysrhythmias. In our published data, we have: 1] Identified ten unique genetic causes of JSRD (nearly half of the published causes), 2] Generated genotype-phenotype correlations involving cerebellar, retinal, renal, hepatic, digit, and cerebral manifestations. 3] Identified common founder mutations that allow for population-based screening. 4] Discovered that JSRD encoded proteins localize to the cilium. 5] Identified ciliary defects in cells with JSRD mutations. 6] Performed siRNA cell-based screens for defective ciliogenesis to prioritize candidate JSRD genes. 7] Generated and characterized multiple zebrafish, mouse and human cell culture models for JSRD. 8] Defined the concept of `Ciliary localization' model, in which one JSRD gene is required for ciliary localization of other JSRD proteins. In our unpublished work we have: 1] Recruited an additional 200 JSRD patients without molecular diagnosis. 2] Performed whole exome sequencing (WES) and genetic mapping on an additional 100 JSRD families. 3] Identified an additional 12 novel likely JSRD candidate genes. 4] Begun functional validation of the putative mutations. 5] Developed methods to ultrastructurally interrogate ciliary structure in a high-throughput fashion. The goal of this competing renewal is to identify the remaining `discoverable' genes that when mutated lead to JSRD, functionally validate mutations within the pathogenetic framework, and test the hypothesis that mutations in any proven JSRD gene lead to collapse of the ciliary transition zone by correlating genetic mutations with ultrastructural ciliary defects. Because the majority of patients still have unknown cause of disease, this renewal aims to advance knowledge through molecular characterization of new genes, using newly evolving high-throughput techniques, integrated bioinformatics, and a unique resource of consanguineous families recruited world-wide. We further aim to validate these mutations within a mechanistic framework, and a model that JSRD genes are required for essential ciliary structural components during cerebellar development. PUBLIC HEALTH RELEVANCE: Joubert syndrome is a genetically and phenotypically heterogeneous neurodevelopmental disorder unified by defects of the cellular primary cilium. This work will identify new genetic causes and dissect ciliary defects associated with genetic mutations",Molecular Characterization of Joubert Syndrome,9450748,R01NS048453,"['Apraxias', 'Ataxia', 'Attention', 'Autistic Disorder', 'Bioinformatics', 'Brain Diseases', 'Brain imaging', 'Breathing', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Cells', 'Cerebellar malformation', 'Cerebellar vermis structure', 'Cerebrum', 'Childhood', 'Chromosome Mapping', 'Cilia', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognitive', 'Complex', 'Congenital cerebellar hypoplasia', 'Cultured Cells', 'DNA Sequence Alteration', 'Data', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Digit structure', 'Disease', 'Electrons', 'Embryo', 'Enrollment', 'Face', 'Family', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic screening method', 'Genotype', 'Goals', 'Gold', 'Hepatic', 'Human', 'Individual', 'Inherited', 'Joubert syndrome', 'Kidney', 'Knock-out', 'Knowledge', 'Lead', 'Learning', 'Length', 'Machine Learning', 'Mental Retardation', 'Methods', 'Microscopic', 'Middle East', 'Modeling', 'Molar tooth', 'Molecular', 'Molecular Diagnosis', 'Morphogenesis', 'Motor', 'Mus', 'Muscle hypotonia', 'Mutate', 'Mutation', 'Neurodevelopmental Disorder', 'Pathogenicity', 'Patients', 'Phenotype', 'Pregnancy Tests', 'Probability', 'Protein Analysis', 'Proteins', 'Publishing', 'Recruitment Activity', 'Resources', 'Retinal', 'Risk', 'Scanning Electron Microscopy', 'Series', 'Small Interfering RNA', 'Sonication', 'Structure', 'Syndrome', 'Techniques', 'Termination of pregnancy', 'Testing', 'Training', 'Transmission Electron Microscopy', 'Validation', 'Variant', 'WNT Signaling Pathway', 'Work', 'Zebrafish', 'affection', 'base', 'cilium biogenesis', 'cohort', 'consanguineous family', 'disorder subtype', 'early childhood', 'exome sequencing', 'founder mutation', 'gene discovery', 'genome sequencing', 'genome-wide', 'knock-down', 'loss of function mutation', 'malformation', 'mutant', 'novel', 'oculomotor', 'population based', 'public health relevance', 'reconstruction', 'screening', 'unpublished works']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2017,510012,0.02497249388533724
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9258454,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2017,244439,-0.023732880405640384
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,8994718,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Peptide Sequence Determination', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'flu', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'receptor binding', 'research study', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2016,370329,0.02572340386304208
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,9117987,F32GM116381,"['Acceleration', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Chromosome Mapping', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Health', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mutation', 'Mutation Spectra', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'admixture mapping', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'learning strategy', 'melanoma', 'offspring', 'rare variant', 'rate of change', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2016,56118,0.06087253464723077
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9180486,K99HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'abstracting', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",K99,2016,83411,0.03643956059637088
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,8991662,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'learning strategy', 'mRNA Precursor', 'novel', 'prediction algorithm', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2016,43576,-0.03418766575583525
"DNA Sequencing Using Single Molecule Electronics PROJECT SUMMARY / ABSTRACT  Progress in DNA sequencing has occurred through multiple stages of disruptive new technologies being introduced to the field, each of which has increased sequencing capabilities by lowering costs, improving throughput, and reducing errors. The goal of this research project is to investigate a new, all-electronic sequencing method that has the potential to become the next transformative step for DNA sequencing. This new method is based on single DNA polymerase molecules bound to nanoscale electronic transistors, a hybrid device that transduces the activity of a single polymerase molecule into an electronic signal.  The goal of this research project is to determine whether these hybrid polymerase-transistors are truly applicable to DNA sequencing and the competitive environment of advanced sequencing technologies. To answer this question, the project teams the scientists who have developed the devices with Illumina, Inc., a worldwide leader in the DNA sequencing market. The experiments proposed here build on encouraging preliminary results, first to demonstrate accurate DNA sequencing and second to evaluate whether the new technique could become a competitive challenge to other sequencing methods. The interdisciplinary team will combine state-of-the-art techniques from protein engineering, nanoscale fabrication, and machine learning to customize polymerase's activity and its interactions with the electronic transistors. If successful, nanoscale solid-state devices like transistors provide one of the best opportunities for increasing sequencing capabilities while decreasing sequencing costs, so that DNA sequencing can become a standard technique in health care and disease treatment. PROJECT NARRATIVE  Over the past two decades, DNA sequencing has transformed from a heroic, nearly impossible task to a routine component of modern laboratory research. The field of DNA sequencing has improved tremendously through a strategy of modifying and monitoring polymerases, a key enzyme at the heart of many DNA sequencing technologies. This proposal is motivated by developments in the field of single-molecule electronics, which provide an entirely new mode for listening to the activity of single polymerase molecules. This electronic method is very different from the biochemical, optical, or nanopore-based techniques currently in use, and it has inherent advantages that could provide exciting possibilities for DNA sequencing. The project will tailor single-molecule electronics for the specific purpose of DNA sequencing and determine whether this strategy could lead to a new generation of sequencing technology.",DNA Sequencing Using Single Molecule Electronics,9172062,R01HG009188,"['Affect', 'Base Pairing', 'Binding', 'Biochemical', 'Carbon', 'Charge', 'Collaborations', 'DNA', 'DNA Sequence', 'DNA-Directed DNA Polymerase', 'Data', 'Development', 'Devices', 'Discrimination', 'Disease', 'Electronics', 'Enzyme Kinetics', 'Enzymes', 'Event', 'Foundations', 'Generations', 'Goals', 'Health Care Research', 'Healthcare', 'Heart', 'Hybrids', 'Individual', 'Laboratory Research', 'Lead', 'Machine Learning', 'Marketing', 'Massive Parallel Sequencing', 'Methods', 'Modality', 'Modification', 'Molecular Models', 'Monitor', 'Motion', 'Mutation', 'Nanotechnology', 'Noise', 'Nucleotides', 'Optics', 'Performance', 'Polymerase', 'Process', 'Protein Engineering', 'Proteins', 'Publishing', 'Reading', 'Research', 'Research Project Grants', 'Resolution', 'Route', 'Scientist', 'Signal Transduction', 'Single-Stranded DNA', 'Site', 'Staging', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Transistors', 'Variant', 'Work', 'base', 'collaborative environment', 'cost', 'enzyme activity', 'improved', 'molecular modeling', 'nanoelectronics', 'nanopore', 'nanoscale', 'new technology', 'novel', 'research study', 'response', 'scale up', 'single molecule', 'single walled carbon nanotube', 'solid state']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2016,584552,0.016954109677855923
"Single Molecule Sequencing of Glycosaminoglycans using Recognition Tunneling Nanopores ﻿    DESCRIPTION (provided by applicant): Structural analysis of large polysaccharides remains challenging in glycobiology. The problem is especially acute when polysaccharides in question are glycosaminoglycans (GAGs). GAGs are large, linear, sulfated polysaccharides ubiquitous to all mammals. Interests in GAG structures stem from GAGs' diverse biological activities that govern phenomena such as tissue development/regeneration, inflammation, blood coagulation and amyloid plaque formation. Abnormal GAG structures have also been associated with the development of a number of diseases, notably cancer and inflammation. As a result, there has been a desire to understand how GAG structures correlate with their biological activities, especially how the distribution of sulfate groups along the chain influence their interactions with GAG-binding proteins. However, GAGs' large size and complex sulfation patterns make analysis of intact GAG chains by conventional ensemble analytical techniques difficult, if not impossible. Here we propose to develop a single molecule sequencer for analysis of polysaccharides using the recognition tunneling nanopore (RTP) device currently under development for ""$1000 genome"" project as a template. With the R21 grant, we will demonstrate the feasibility by carrying out pre-requisite work needed to achieve single molecule sequencing of intact GAG chains using RTP. A RTP device incorporates a nanopore with a tunneling nanogap that contains two electrodes functionalized with recognition molecules capable of forming transient complexes with functional groups on a polymeric chain as it translocates the nanopore, thus generating electrical signals. Single molecule sequencing of GAG chains proposed here circumvents the need to obtain homogeneous samples of GAGs, greatly reducing complexity of sample preparation. GAG analysis by RT devices also does not have the size limitations of most of the existing analytical techniques, and the solid state device planned here are economical to manufacturer and operate. In this application, we aim to carry out pilot studies needed to make GAG sequencing by RTPs feasible: (1) we will investigate the translocation of size defined sulfated GAG fragments through nanopores to optimize the translocation efficiency of GAG ligands as well as to understand the influence of GAG sulfation density and GAG size on their translocation efficiency and speed; (2) we will carry out recognition tunneling experiments on sulfated GAG disaccharides as well as trisaccharides so these signals of GAGs can be analyzed using machine learning algorithms to identify unique signatures needed to detect the presence of these sulfation motifs in longer GAG chains. Completion of these aims will provide all the knowledge required for correct interpretations of RT signals produced by GAG translocation and sets the stage for sequencing of intact GAG chains by RT devices. PUBLIC HEALTH RELEVANCE:     Work proposed here will allow single molecule sequencing of glycosaminoglycan polysaccharides using an electronic chip with a high speed and low cost for the first time. Glycosaminoglycans have important pharmacological properties and are modulators of critical biological phenomena such as tissue development/regeneration and inflammation. Determination of their sequence structures will allow better understanding of how organisms control these physiological events through glycosaminoglycans.",Single Molecule Sequencing of Glycosaminoglycans using Recognition Tunneling Nanopores,9109642,R21GM118339,"['Acute', 'Algorithms', 'Amino Acids', 'Architecture', 'Binding Proteins', 'Biological', 'Biological Markers', 'Biological Phenomena', 'Blood coagulation', 'Cells', 'Charge', 'Chemistry', 'Complex', 'Coupled', 'DNA', 'DNA Sequence', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Disaccharides', 'Disease', 'Electrodes', 'Electronics', 'Electrons', 'Environment', 'Enzymes', 'Event', 'Genome', 'Glycobiology', 'Glycosaminoglycans', 'Goals', 'Grant', 'Health', 'Imidazole', 'Individual', 'Inflammation', 'Inorganic Sulfates', 'Ions', 'Isomerism', 'Knowledge', 'Leukocyte Trafficking', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Mammals', 'Manufacturer Name', 'Mediating', 'Methods', 'Microbe', 'Natural regeneration', 'Neoplasm Metastasis', 'Oligosaccharides', 'Organism', 'Pattern', 'Physiological', 'Pilot Projects', 'Play', 'Polysaccharides', 'Preparation', 'Process', 'Property', 'Proteins', 'Publishing', 'Reader', 'Reading', 'Research', 'Role', 'Sampling', 'Senile Plaques', 'Side', 'Signal Transduction', 'Signaling Protein', 'Site', 'Speed', 'Staging', 'Structure', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Tissues', 'Trisaccharides', 'Unspecified or Sulfate Ion Sulfates', 'Work', 'amyloid formation', 'analytical method', 'base', 'cancer cell', 'cost', 'density', 'design', 'extracellular', 'functional group', 'interest', 'nanopore', 'polysulfated glycosaminoglycan', 'programs', 'research study', 'single molecule', 'solid state', 'stem', 'sugar', 'sulfation', 'therapeutic biomarker', 'tool']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2016,271743,6.0055195441426315e-05
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies (1-3). In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods (1,2). We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data and this paper is in press. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meeting and a manuscript in development. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published a paper describing this method(2). We are currently developing The Machine Suite which will be an extension of r2VIM.  We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 and another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  This year we have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the 2015 International Genetic Epidemiology Society meeting (CL Simpson).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. A paper this year was published presenting an extension to these methods for mixed effect models (4). We are now in the process of applying these approaches to several of our genome-wide datasets.  Finally, we have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including testing of their TRAP method (5) and an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. n/a",Development of statistical genetics methodology,9359824,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Caucasians', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Linear Models', 'Linkage Disequilibrium', 'Logistic Regressions', 'Machine Learning', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Probability', 'Process', 'Publishing', 'Research', 'Running', 'Sampling', 'Scheme', 'Sequence Analysis', 'Societies', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Variant', 'Work', 'base', 'case control', 'data mining', 'density', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2016,485269,-0.0053163367012196245
"Statistical and computational analysis in whole genome sequencing studies. DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges. PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.",Statistical and computational analysis in whole genome sequencing studies.,9103177,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Health', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'learning strategy', 'meetings', 'population based', 'programs', 'whole genome']",NHGRI,STANFORD UNIVERSITY,R01,2016,300000,-0.016815975517588462
"Genome analysis based on the integration of DNA sequence and shape DESCRIPTION (provided by applicant): Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription facors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.",Genome analysis based on the integration of DNA sequence and shape,8998963,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Binding', 'DNA Databases', 'DNA Methylation', 'DNA Sequence', 'DNA Structure', 'DNA-Binding Proteins', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Drosophila genus', 'Embryonic Development', 'Family', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Health', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Lead', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Mining', 'Minor Groove', 'Modeling', 'Molecular Biology', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'flexibility', 'genetic evolution', 'genome analysis', 'genome browser', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'predictive tools', 'research study', 'three dimensional structure', 'tool', 'transcription factor', 'vector', 'whole genome']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2016,306949,-0.0011765321731651587
"Molecular impact of mutations in monogenic disease and cancer ABSTRACT  Next generation genome scale sequencing of patients is now becoming routine for two classes of disease: rare  Mendelian traits and cancer. In favorable cases, these data allow identification of relevant mutations and thus  aid diagnosis and therapy. In both classes of disease, the most common type of mutation is missense -­ single  base  changes  that  result  in  an  amino  acid  substitution  in  a  protein.  Uncertainty  as  to  the  impact  of  these  mutations on in vivo protein activity has resulted in a very conservative approach to their interpretation in the  clinic,  so  causing  many  missed  opportunities  for  targeted  treatment.  The  goal  of  this  project  is  to  use  a  combination of three strategies to make the interpretation of these mutations much more applicable in the clinic.  There are already a large number of computational methods that attempt to determine the impact of missense  mutations on function, and there is substantial evidence that these have useful accuracy. The primary difficulty  is that the accuracy in any particular case is not reliably calibrated. Therefore, our first aim is to use a combination  of these methods to develop an approach focused on more reliable estimates for the probability of high impact  on  protein  function  (i.e.  more  confident  P  values).  The  second  aim  is  to  maximize  the  utilization  of  three-­ dimensional structural information, largely ignored by most computational methods. A large fraction of missense  mutations in these classes of disease act by destabilizing protein structure and knowledge of structure allows  these to be identified with much higher reliability. Also, structure provides a framework for detailed annotation  and comprehension of function. To facilitate the utilization of structure, we will implement a modeling platform  that leverages available experimental information to maximize the structural data available for analyzing mutation  impact.  An  important  aspect  of  the  platform  is  incorporation  of  methods  for  evaluating  the  reliability  of  the  structural features relevant to analysis of each mutation. In the third aim we will build specific functional models  for each protein of interest, integrating information from current databases, the literature, and community input,  so as to provide the richest possible background against which to judge the impact of mutations. Proteopedia, a  well established media wiki for proteins, will be used to provide an integrated view of text, data, and structure. A  key component of the information resource will be contributions from curators, who will provide annotation and  also solicit input from other experts. This aspect of the project builds on experience with other crowdsourcing  endeavors,  including  CASP,  CAGI  and  Proteopedia.    There  will  be  three  primary  outcomes  from  the  project:  First, improved reliability for the interpretation of missense mutations. Second, a prototype mutation annotation  procedure suitable for use in a clinical setting. Third, the resource will provide information of benefit to a range  of other scientists, thus facilitating the analysis of disease related mutations.      NARRATIVE  Genome  scale  DNA  sequencing  is  now  contributing  to  diagnosis  and  therapy  in  cases  of  rare  human  disease and cancer.  Full exploitation of these data is currently hampered by inadequate understanding  of which DNA changes affect protein function so as to contribute to disease. This project aims to develop  the methods and tools needed to remove that obstacle. ",Molecular impact of mutations in monogenic disease and cancer,9156099,R01GM120364,"['Address', 'Affect', 'Amino Acid Substitution', 'Clinic', 'Clinical', 'Communities', 'Comprehension', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Diagnosis', 'Disease', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mendelian disorder', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Patients', 'Play', 'Probability', 'Procedures', 'Process', 'Proteins', 'Rare Diseases', 'Reporting', 'Resources', 'Role', 'Scientist', 'Structural Models', 'Structure', 'Tertiary Protein Structure', 'Text', 'Uncertainty', 'base', 'clinically relevant', 'crowdsourcing', 'data structure', 'experience', 'genome-wide', 'human disease', 'improved', 'in vivo', 'interest', 'learning strategy', 'next generation', 'primary outcome', 'protein function', 'protein protein interaction', 'protein structure', 'prototype', 'targeted treatment', 'tool', 'trait', 'wiki']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2016,372928,0.006254087136856371
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community.         PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.            ","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9132585,U01HG009086,"['Accounting', 'Affect', 'Architecture', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Learning', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'research study', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2016,854333,-0.02776878449534329
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9116916,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug Regulations', 'Drug resistance', 'Family', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Health', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2016,300000,0.048399135583241965
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases.         PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.            ",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9083570,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Time', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic evolution', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,300999,0.021385787402153054
"Molecular Characterization of Joubert Syndrome Project Summary Congenital ataxia presents in early childhood with non-progressive hypotonia, gross motor, fine motor and cognitive delays. These disorders are distinct from the progressive ataxias because of the presence of congenital cerebellar malformations and because they are typically inherited recessively. Joubert Syndrome and Related Disorders (JSRD) constitute a major subset of these conditions, consisting of a cerebellar midline (vermis) malformation, a nearly pathognomonic Molar Tooth sign on brain Imaging (MTI) and co-existent oculomotor apraxia and episodic breathing dysrhythmias. In our published data, we have: 1] Identified ten unique genetic causes of JSRD (nearly half of the published causes), 2] Generated genotype-phenotype correlations involving cerebellar, retinal, renal, hepatic, digit, and cerebral manifestations. 3] Identified common founder mutations that allow for population-based screening. 4] Discovered that JSRD encoded proteins frequently localize to the cilium. 5] Identified ciliary transition zone (TZ) defects in cells with JSRD mutations. 6] Performed siRNA cell-based screens for defective ciliogenesis to prioritize candidate JSRD genes. 7] Generated and characterized multiple zebrafish, mouse and human cell culture models for JSRD. 8] Defined the concept of ‘Ciliary localization’ model, in which one JSRD gene is required for ciliary localization of other JSRD proteins. In our unpublished data we have: 1] Recruited an additional 200 JSRD patients without molecular diagnosis. 2] Performed whole exome (WES) and whole genome sequencing (WGS) on an additional 100 JSRD families. 3] Identified an additional 12 novel likely JSRD candidate genes. 4] Generated IPSCs and cerebellar organoids from mutation-positive and negative families to aid in functional analysis and gene discovery using RNAseq. 5] Begun functional validation of the putative mutations. 6] Developed methods to interrogate ciliary structure in a high-throughput fashion with electron microscopy (EM). The goal of this competing renewal is to identify the remaining ‘discoverable’ genes that lead to JSRD when lost, functionally validate mutations within the pathogenetic framework, and test the hypothesis that mutations in JSRD genes lead to collapse of the ciliary TZ. Because the majority of patients still have unknown cause of disease, this renewal aims to advance knowledge through molecular characterization of new genes, using newly evolving high-throughput techniques, integrated bioinformatics, and a unique resource of consanguineous families recruited world-wide. We further aim to validate these mutations in patient cells, within a mechanistic framework that JSRD genes are required for essential ciliary structural components during cerebellar development. Project Narrative Joubert syndrome is a genetically and phenotypically heterogeneous neurodevelopmental disorder unified by defects of the cellular primary cilium. This work will identify new genetic causes and dissect ciliary defects associated with genetic mutations.",Molecular Characterization of Joubert Syndrome,9239923,R01NS048453,"['Apraxias', 'Ataxia', 'Bioinformatics', 'Brain imaging', 'Breathing', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Cells', 'Cerebellar malformation', 'Cerebellar vermis structure', 'Cerebrum', 'Cilia', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognitive', 'Congenital cerebellar hypoplasia', 'Cultured Cells', 'Cytoplasmic Granules', 'DNA Sequence Alteration', 'Data', 'Databases', 'Defect', 'Development', 'Digit structure', 'Disease', 'Electron Microscopy', 'Electrons', 'Embryo', 'Enrollment', 'Face', 'Family', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic screening method', 'Genotype', 'Goals', 'Gold', 'Hepatic', 'Human', 'Individual', 'Inherited', 'Joubert syndrome', 'Kidney', 'Knock-out', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Microscopic', 'Middle East', 'Modeling', 'Molar tooth', 'Molecular', 'Molecular Diagnosis', 'Morphogenesis', 'Morphology', 'Motor', 'Mus', 'Muscle hypotonia', 'Mutation', 'Neurodevelopmental Disorder', 'Organoids', 'Pathogenicity', 'Patients', 'Phenotype', 'Probability', 'Protein Analysis', 'Proteins', 'Publishing', 'Recruitment Activity', 'Resources', 'Retinal', 'Risk', 'Scanning Electron Microscopy', 'Series', 'Severities', 'Signal Transduction', 'Small Interfering RNA', 'Structure', 'Syndrome', 'Techniques', 'Termination of pregnancy', 'Testing', 'Three-dimensional analysis', 'Training', 'Transmission Electron Microscopy', 'Validation', 'Variant', 'Work', 'Zebrafish', 'accurate diagnosis', 'affection', 'base', 'cell type', 'cilium biogenesis', 'cohort', 'consanguineous family', 'disorder subtype', 'early childhood', 'exome', 'exome sequencing', 'fetal', 'founder mutation', 'gene discovery', 'genome sequencing', 'genome-wide', 'induced pluripotent stem cell', 'insight', 'knock-down', 'loss of function mutation', 'malformation', 'mutant', 'novel', 'oculomotor', 'population based', 'reconstruction', 'screening', 'stem cell biology', 'transcriptome sequencing', 'whole genome']",NINDS,ROCKEFELLER UNIVERSITY,R01,2016,557723,0.02615266583553004
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,8974432,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",K99,2016,25020,-0.023732880405640384
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9242250,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2016,246031,-0.023732880405640384
"Lymphoma Disease Discovery and Definition Pediatric-type follicular lymphoma (PTFL) is a variant of FL with distinctive clinico-pathological features, previously characterized in our group. The molecular pathogenesis of this disease has been unknown, although prior studies had indicated it differed from classical follicular lymphoma as seen in adults. Patients are predominantly young males presenting with localized lymphadenopathy; the tumor shows high grade cytology and lacks both BCL2 expression and t(14;18) translocation. In this study we examined 42 PTFL (40 males and 2 females; mean age: 16 years, (range 5-31) for genetic aberrations using a variety of techniques. Copy number analysis was performed with the Oncoscan protocol for formalin fixed paraffin embedded (FFPE) tissues. Next generation sequencing (NGS) analysis was done on the Ion Torrent platform. An Ion AmpliSeq Custom Panel covering twelve genes that have been shown to be frequently mutated in FL was used. The panel covered 98.24% of all exons of TNFRSF14, KMT2D (MLL2), FOXO1, EP300, MEF2B, HIST1H1B-E and GNA13 as well as hot spot regions of EZH2 (exon 16) and CREBBP (exons 24-38 and 30) For comparison 11 cases of conventional t(14:18)-negative FL in adults were investigated. Gains and losses and copy number neutral loss of heterozygosity (CNN-LOH) regions were evaluated and visually inspected using Nexus Biodiscovery version 7.5 software. Morphologically, PTFL cases had follicular growth pattern without diffuse areas and characteristic immunophenotype. All cases showed monoclonal IG rearrangement. PTFL displays low genomic complexity when compared with t(14;18)-negative FL (mean 0.77 vs 9 CNA/case, P0.001). Both groups presented 1p36 alterations including TNFRSF14 but copy number neutral loss of heterozygosity (CNN-LOH) of this locus was more frequently observed in PTFL (40% vs 9% P=0.075). TNFRSF14 was the most frequently affected gene in PTFL (21 mutations and 2 deletions), identified in 54% of cases followed by KMT2D mutations in 16%. Other histone-modifying genes were rarely affected. In contrast, t(14;18)-negative FL displayed a mutational profile similar to t(14;18)-positive FL. In eight PTFL cases (19%), no genetic alterations were identified, beyond IG monoclonal rearrangement. The genetic landscape of PTFL suggests that TNFRSF14 mutations accompanied by CNN-LOH of the 1p36 locus in over 70% of mutated cases, as additional selection mechanism, might play a key role in the pathogenesis of this disease. The genetic profiles of PTFL and t(14;18)-negative FL in adults indicate that these are two different disorders. In a separate study our group analyzed patterns of histological progression in chronic lymphocytic leukemia (CLL). Hodgkin/Reed-Sternberg (HRS) cells in the setting of chronic lymphocytic leukemia (CLL) exist in two forms: type I with isolated HRS cells in a CLL background (Hodgkin-like lesion), and type II with typical classic Hodgkin lymphoma (CHL), a variant of Richter transformation (CHL-RT). The clinical significance of the two morphological patterns is unclear, and their biological features have not been compared. Moreover, the clinical significance of the Type I lesion and whether it should be aggressively treated has been questioned. We retrospectively reviewed 77 cases: 26 of type I and 51 of type II CHL-RT; 3 cases progressed from type I to type II. We examined clinical features, EBV status, and clonal relatedness after microdissection. Median age for type I was 62 years vs. 73 years for type II (P=.01). 27% (type I) vs. 73% (type II) had a history of CLL. HRS cells were positive for EBV in 71% (55/77), similar in type I and II. Clonality analysis was performed in 33 cases (type I and type II combined): HRS cells were clonally related to the underlying CLL in 14 and unrelated in 19. ZAP-70 expression of the CLL cells, but not EBV status or morphological pattern was correlated with clonal relatedness: all 14 clonally related cases were ZAP-70-negative while 74% (14/19) of clonally unrelated cases were ZAP-70-positive. Overall median survival (types I and II) after diagnosis was 44 months. Advanced age was an adverse risk factor for survival, but not histological pattern, type I vs type II. HRS-like cells in a background of CLL carries a similar clinical risk to that of CHL-RT, and may progress in CHL in some cases. Our study provides evidence for the aggressive treatment of both forms of histological progression. Our group described marginal zone lymphomas of mucosa-associated lymphoid tissue (MALT type) arising in the dura of the meninges in 1997. It was unknown how this tumor relates to MALT lymphomas in other extranodal sites. We performed genome-wide DNA copy number and targeted mutational analysis of 14 dural MZL to determine the genetic landscape of this entity. Monoallelic and biallelic inactivation of TNFAIP3 by mutation (n=5) or loss (n=1) was observed in 6/9 (67%) dural MZL exhibiting plasmacytic differentiation, including 3 IgG4+ cases. In contrast, activating NOTCH2 mutations were detected in 4/5 (80%) dural MZL displaying variable monocytoid morphology. Inactivating TBL1XR1 mutations were identified in all NOTCH2 mutated cases. Recurrent mutations in KLHL6 (n=2) and MLL2 (n=2) were also detected. Gains at 6p25.3 (n=2) and losses at 1p36.32 (n=3) were common chromosomal imbalances, with loss of heterozygosity (LOH) of these loci observed in a subset of cases. Translocations involving the IGH or MALT1 genes were not identified. Our results indicate genetic similarities between dural MZL and other MZL subtypes. However, recurrent and mutually exclusive genetic alterations of TNFAIP3 and NOTCH2 appear to be associated with distinct disease phenotypes in dural MZL. Primary central nervous system (CNS) lymphomas are relatively rare with the most common subtype being diffuse large B-cell lymphoma. Primary CNS T-cell lymphomas (PCNSTL) account for fewer than 5% of CNS lymphomas. We reported the clinical, morphologic, immunophenotypic, and molecular characteristics of 18 PCNSTLs. Median age was 58.5 years (range, 21 to 81 y), with an M:F ratio of 11:7. Imaging results showed that 15 patients had supratentorial lesions. Most cases studied had a cytotoxic phenotype with expression of TIA1 (13/15) and granzyme-B (9/13). Polymerase chain reaction analysis of T-cell receptor gamma rearrangement confirmed a T-cell clone in 14 cases with adequate DNA quality. Next-generation sequencing showed somatic mutations in 36% of cases studied; 2 had more than 1 mutation, and none showed overlapping mutations. These included mutations in DNMT3A, KRAS, JAK3, STAT3, STAT5B, GNB1, and TET2 genes, genes implicated previously in other T-cell neoplasms. The outcome was heterogenous; 2 patients are alive without disease, 4 are alive with disease, and 6 died of disease. In conclusion primary central nervous system lymphomas of T-cell origin are histologically and genomically heterogenous with frequent phenotypic aberrancy and a cytotoxic phenotype in most cases. This study should help in the accurate diagnosis of this rare tumor type. n/a",Lymphoma Disease Discovery and Definition,9344090,ZIASC000550,"['16 year old', '1p36', 'Accounting', 'Adult', 'Affect', 'Age', 'Area', 'BCL2 gene', 'Biological', 'CREBBP gene', 'Case Study', 'Cell Proliferation', 'Cells', 'Central Nervous System Lymphoma', 'Characteristics', 'Childhood', 'Chronic Lymphocytic Leukemia', 'Classification', 'Clinical', 'Clonality', 'Computer software', 'Custom', 'Cytology', 'DNA', 'DNA copy number', 'Diagnosis', 'Diffuse', 'Disease', 'Dura Mater', 'EP300 gene', 'EZH2 gene', 'Elderly', 'Exhibits', 'Exons', 'Extranodal', 'FOXO1A gene', 'Female', 'Follicular Lymphoma', 'Formalin', 'Functional disorder', 'GNB1 gene', 'Gap Junctions', 'Gene-Modified', 'General Population', 'Genes', 'Genetic', 'Genomic approach', 'Genomics', 'Goals', 'Granzyme', 'Growth', 'Heel', 'Histologic', 'Histones', 'Hodgkin Disease', 'Hot Spot', 'Human Herpesvirus 4', 'IGH@ gene cluster', 'IgG4', 'Image', 'Immune system', 'Immunophenotyping', 'Ions', 'JAK3 gene', 'KRAS2 gene', 'Lesion', 'Loss of Heterozygosity', 'Lymphatic Diseases', 'Lymphoma', 'MLL2 gene', 'Malignant Neoplasms', 'Meninges', 'Microdissection', 'Molecular', 'Morphology', 'Mucosa- associated lymphoid tissue lymphoma translocation protein-1', 'Mutate', 'Mutation', 'Neuraxis', 'Outcome', 'Paraffin Embedding', 'Pathogenesis', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Polymerase Chain Reaction', 'Protocols documentation', 'Recording of previous events', 'Recurrence', 'Reed-Sternberg Cells', 'Reed-Sternberg-like Cell', 'Reporting', 'Risk Factors', 'STAT3 gene', 'STAT5B gene', 'Sequence Analysis', 'Signal Pathway', 'Site', 'Somatic Mutation', 'Supratentorial', 'T-Cell Lymphoma', 'T-Cell Receptor', 'T-Cell and NK-Cell Neoplasm', 'T-Lymphocyte', 'Techniques', 'Tissues', 'Translating', 'Variant', 'Work', 'ZAP-70 Gene', 'accurate diagnosis', 'base', 'clinical practice', 'clinical risk', 'clinically significant', 'cytotoxic', 'disease classification', 'disease phenotype', 'genetic approach', 'genetic profiling', 'genome-wide', 'herpesvirus entry mediator', 'improved', 'insight', 'large cell Diffuse non-Hodgkin&apos', 's lymphoma', 'male', 'mucosa-associated lymphoid tissue lymphoma', 'next generation sequencing', 'novel diagnostics', 'outcome forecast', 'tool', 'treatment response', 'tumor']",NCI,DIVISION OF CLINICAL SCIENCES - NCI,ZIA,2016,843916,0.004816335884983624
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control.         PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.                ",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,8859887,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Peptide Sequence Determination', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'flu', 'genome sequencing', 'improved', 'influenza outbreak', 'influenza virus vaccine', 'influenzavirus', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'research study', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2015,381704,0.02572340386304208
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,8982093,F32GM116381,"['Acceleration', 'Admixture', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Chromosome Mapping', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Health', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Mutation', 'Mutation Spectra', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'melanoma', 'offspring', 'rare variant', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2015,50690,0.06087253464723077
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,8833507,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Sequences', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'mRNA Precursor', 'novel', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2015,43120,-0.03418766575583525
"Telomere Diseases Telomeres are repeated hexanucleotide sequences at the ends of linear chromosomes, which serve to protect them from recognition as chromosomal breaks; furthermore, the asymmetric replication of DNA would lead inevitably to a loss of genetic material, and telomerase, an enzymatic complex that adds telomeric sequences at mitosis, functions to maintain genomic integrity. Telomerase deficiency manifests with short telomeres and loss of both enzymatic activity: its consequences can be measured in vitro and in vivo. Mutations in DKC1 and in TERC (the RNA template subunit of the complex) are etiologic in some cases of dyskeratosis congenita, a constitutional form of aplastic anemia. Mutations in TERT (encoding telomerase, the rate limiting enzymatic component of the complex) occur in apparently acquired aplastic anemia and other diseases. Heterozygous mutations in TERT lead to defective telomere repair and short telomeres due to a mechanism of haploinsufficiency. Male hormones, long used to treat aplastic anemia, act by up regulating TERT transcription and telomerase activity, including in lymphocytes and hematopoietic progenitor cells. While critical telomere shortening often leads to either cell senescence or apoptosis, occasional cells become anneuploid due to end-to-end fusion of chromosomes. Thus, telomere attrition is a mechanism for oncogenesis.  Telomere length of leukocyte is now measured routinely in our CLIA laboratory by gene amplification using robotic methodology provided by a Quiagen Quiagility and Rotor GeneQ; high throughput analysis is useful both for research and in the clinic, and our procedure is certified for patient data. Measurement of clinical samples is required for the adequate diagnosis of aplastic anemia and is predictive of late events after treatment with immunosuppression, and probably in other clinical circumstances.  We now have established single telomere length analysis (STELA), which relies on amplification using chromosome specific sub-telomeric DNA sequence to detect critical telomere shortening in individual chromosomes. We utilize flow-FISH, a flow cytometry assay that allows measurement of telomere length individual cells in suspension.  As reported last year, we analyzed telomere attrition in a subgroup of patients with aplastic anemia who ultimately developed monosomy 7, the dominant cytogenetic abnormality in clonal evolution from aplastic anemia to myelodysplastic syndrome/acute myeloid leukemia.  Accelerated telomere attrition was insistently present in these patients, but only a few showed mutations in MDS/AML candidate genes.  We are incorporating telomere testing at diagnosis and at three and six months post treatment prospectively to assess patients in our clinic for prognosis in general and for risk of development of myeloid malignancy.  Of note, in patients who evolve to MDS/AML on eltrombopag therapy, there was also little evidence of candidate gene mutation in serial samples; serial telomere measurements are also being performed in these cases.  We are utilizing a combination of deep clinical phenotyping and machine learning to model telomere disease in the context of bone marrow failure syndromes in general as well as to characterize genotype-phenotype relationships.  Over 150 patients with a putative diagnosis of telomeropathy, with or without documented gene mutations, have been compared to a similar number of patients with moderate and severe aplastic anemia.  Among telomere disease patients, most (66) have TERT mutations, followed by TERC (25), and unidentified mutations (40).  Bothe two and three class random forest analyses have been applied.  A large number of clinical and laboratory parameters are available in these patients.  A family or personal history of lung disease was a major discriminator between TERC and TERT telomere disease, and a relatively limited cassette of clinical features appears to be predictive with high sensitivity and specificity.  Early greying was more characteristic of TERT mutant patients.  TERC was distinguishable from unidentified mutations while patients with unidentified mutations tend to cluster with those who have TERT deficiency.  For analysis in the context of bone marrow failure, random forest disclosed clustering of subgroups of patients, distinct from those with moderate and severe aplastic anemia; characterization of these subgroups by clinical parameters in genotype is in progress.  The major predictors of telomere disease versus aplastic anemia in general was family or personal history of androgen therapy and a personal history of early greying of the hair and lung diseases. Application of machine learning in this context is unusual and should be generally applicable in other diseases in which subsets of patients have clearly defined molecular mechanisms.  Finally, we have completed and submitted for publication our interventional trial of danazol, a synthetic androgen, in patients with suspected telomere disease, defined as short telomeres in the context of an appropriate clinical syndrome, with or without documented mutation in TERT, TERC, or other telomere repair complex gene or shelterin protein gene.  A total of 27 patients were enrolled to receive danazol at maximal doses for two years, with the primary endpoint being drug safety and alteration in the telomere attrition rate.  Adverse effects were anticipated and observed, mainly related to changes in lipid profiles, elevated liver enzymes, and muscle cramps.  Nevertheless, danazol was generally well tolerated.  Remarkably, accelerated telomere attrition at a rate of 156 base pair loss annually was reversed by administration of an androgen, leading to an average gain in telomere length of 175 base pairs at six months and 360 base pairs at 12 months as compared to baseline.  These data were generated using q-PCR and confirmed when patient samples were available by flow-FISH.  The hematologic response rate was high, 70% at three months and 63% at six months; for those patients able to complete two years on study, 83% had improved blood counts.  This study represents the first favorable modulation of telomere length in humans.  Although not primary or secondary endpoints, there were also improvements in pulmonary function, as measured by CO diffusion capacity, and stabilization of liver fibrosis on imaging.  We anticipate new protocols examining lower doses of androgens in telomeropathy patients as well as the application of androgen therapy to patients with predominantly lung and liver disease with underlying telomere gene mutations. n/a",Telomere Diseases,9157405,ZIAHL006089,"['Acute Myelocytic Leukemia', 'Adverse effects', 'Aftercare', 'Androgen Analogues', 'Androgen Therapy', 'Androgens', 'Aplastic Anemia', 'Apoptosis', 'Base Pairing', 'Biological Assay', 'Blood', 'Candidate Disease Gene', 'Cell Aging', 'Cells', 'Characteristics', 'Chromosomal Breaks', 'Chromosomal Stability', 'Chromosome abnormality', 'Chromosomes', 'Clinic', 'Clinical', 'Clonal Evolution', 'Complex', 'Constitutional', 'DNA Sequence', 'DNA biosynthesis', 'Danazol', 'Data', 'Development', 'Diagnosis', 'Diffusion', 'Disease', 'Dose', 'Dyskeratosis Congenita', 'Dysmyelopoietic Syndromes', 'Enrollment', 'Enzymes', 'Event', 'Family', 'Flow Cytometry', 'Gene Amplification', 'Gene Mutation', 'Gene Proteins', 'Genes', 'Genetic Materials', 'Genetic Transcription', 'Genotype', 'Goals', 'Gray unit of radiation dose', 'Hair Diseases', 'Hematopoietic stem cells', 'Hormones', 'Human', 'Image', 'Immunosuppression', 'In Vitro', 'Individual', 'Intervention Trial', 'Laboratories', 'Lead', 'Length', 'Leukocytes', 'Lipids', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Lung diseases', 'Lymphocyte', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Mitosis', 'Modeling', 'Molecular', 'Monosomy 7', 'Muscle Cramp', 'Mutation', 'Myeloproliferative disease', 'Organ failure', 'Pancytopenia', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Procedures', 'Protocols documentation', 'Publications', 'RNA', 'Recording of previous events', 'Repair Complex', 'Reporting', 'Research', 'Risk', 'Robotics', 'Safety', 'Sampling', 'Sensitivity and Specificity', 'Subgroup', 'Suspension substance', 'Suspensions', 'Syndrome', 'Telomerase', 'Telomere Shortening', 'Testing', 'bone marrow failure syndrome', 'clinical phenotype', 'design', 'forest', 'genome integrity', 'high throughput analysis', 'human disease', 'improved', 'in vivo', 'male', 'mutant', 'outcome forecast', 'pulmonary function', 'repaired', 'response', 'telomere', 'telomere loss', 'tumorigenesis']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIA,2015,987089,0.028928171452858732
"Informatics Tools for High-Throughput Sequences Data Analysis DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK. The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.",Informatics Tools for High-Throughput Sequences Data Analysis,8788050,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2015,967608,0.030798501645917097
"Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions DESCRIPTION (provided by applicant): The goal of the proposed research training program is to provide me (Dr. Collin Melton) with additional training in areas that will accelerate my career development as I transition from a post-doctoral fellow in Dr. Michael Snyder's lab to an independent tenure track professor. The key elements of this plan are: Candidate: I have extensive training in experimental and computational approaches to studying biomedicine. Areas of additional focus for career development during the K99 mentored post-doctoral research phase include the acquisition of additional experimental skills and supplemental training in cancer biology, human genetics, human genomics, applied statistics, and parallel computing. Additionally, I will receive training in laboratory management, mentorship, and responsible conduct of research. This well-rounded plan will provide me with a skill set that will enable a facile transition from postdoctoral fellow to tenure track faculty. Environment: I have a valuable advisory committee with experts in the areas of genomics, genetics, and cancer biology to ensure my success in this training program and to guide me through the successful acquisition of a faculty job. These include my mentor Dr. Michael Snyder, my co-mentor Dr. James Ford and two advisors, Dr. Hanlee Ji and Dr. Anshul Kundaje. The environment at Stanford University in the Snyder lab and department of Genetics fosters productivity and collaboration with word class facilities, resources, and researchers. Research: My proposed research plan in cancer genomics is timely, relevant, and innovative. The majority of current research in cancer genomics has made groundbreaking progress in understanding the relevant DNA variation that occurs in coding regions of the genome; however, 97-98% of the human genome does not code for protein. This proposal focuses specifically on studying the regulatory regions of the human genome to identify, characterize, and interpret the impact of point mutations in these regulatory regions. The central hypothesis of this proposal is that point mutations in regulatory regions of the human genome drive cancer formation and the functional consequences of these mutations can be predicted using machine learning algorithms. Aim 1 proposes the statistical identification of regulatory regions which are mutated across cancer samples, Aim 2 proposes functional characterization of the prevalent mutations identified in Aim 1, and Aim 3 extends the analysis of characterizing the effects of mutations genome-wide through use of genomics approaches and proposes the use of machine learning to classify novel mutations as either disrupting, activating, or having no effect on regulatory element activity. Through its use of experimental datasets combined with predictive models for functional consequences of individual cancer variation, this research will further the goal of personalized genome interpretation for cancer therapy. PUBLIC HEALTH RELEVANCE: Every cancer patient's disease is caused by unique set of abnormal variation in the human genome. Advancing our understanding this variation aids in the development of new treatments and the proper application of existing treatments. This proposal focuses on understanding a particular type of cancer variation that occurs in regulatory regions of the human genome.","Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions",8931936,K99CA191093,"['Address', 'Advisory Committees', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Area', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cause of Death', 'Cell Line', 'ChIP-seq', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Distal', 'Elements', 'Encyclopedia of DNA Elements', 'Ensure', 'Environment', 'Evaluation', 'Faculty', 'Fostering', 'Future', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Hela Cells', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Mentorship', 'Mutate', 'Mutation', 'Normal Cell', 'Nucleic Acid Regulatory Sequences', 'Occupations', 'Phase', 'Point Mutation', 'Postdoctoral Fellow', 'Productivity', 'Proteins', 'Regimen', 'Regulatory Element', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Site', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Training Programs', 'United States', 'Universities', 'Untranslated RNA', 'Variant', 'Vision', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cancer type', 'carcinogenesis', 'career development', 'epigenomics', 'genome sequencing', 'genome-wide', 'innovation', 'interest', 'migration', 'mutant', 'novel', 'parallel computer', 'predictive modeling', 'professor', 'responsible research conduct', 'skills', 'statistics', 'success', 'trend', 'tumor progression']",NCI,STANFORD UNIVERSITY,K99,2015,116122,0.011106228112093523
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. This year we have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods (1). We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data and this paper was recently accepted for publication. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meeting and a manuscript in development. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access. We are currently developing The Machine Suite which will be an extension of r2VIM and are writing several book chapters on maching learning in collaboration with Dr. James Malley of CIT.  We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published this year (2) presenting some of this work. This novel method was also described and used in a recent applied analysis of oral cleft GWAS data and a paper was published this year (3). Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 an another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  This year we have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the upcoming 2015 International Genetic Epidemiology Society meeting (CL Simpson).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. A paper this year was published presenting an extension to these methods for pleiotropy analyses (4). We are now in the process of applying these approaches to several of our genome-wide datasets.  Dr. Emily Holzinger has also published three papers on machine learning methods this year, in collaboration with her PhD mentor, as an extension of her PhD work and independent of Dr. Bailey-Wilson(5-7). n/a",Development of statistical genetics methodology,9152711,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Book Chapters', 'Caucasians', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Learning', 'Linear Models', 'Linkage Disequilibrium', 'Logistic Regressions', 'Machine Learning', 'Manuscripts', 'Mentors', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Probability', 'Process', 'Publications', 'Publishing', 'Research', 'Running', 'Scheme', 'Sequence Analysis', 'Societies', 'Solutions', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Variant', 'Work', 'Writing', 'base', 'case control', 'data mining', 'density', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'improved', 'meetings', 'novel', 'oral cleft', 'pleiotropism', 'programs', 'quality assurance', 'rare variant', 'simulation', 'targeted sequencing', 'tool', 'trait', 'web site']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2015,473837,0.0034803185947325605
"Single Molecule Sequencing of Glycosaminoglycans using Recognition Tunneling Nanopores ﻿    DESCRIPTION (provided by applicant): Structural analysis of large polysaccharides remains challenging in glycobiology. The problem is especially acute when polysaccharides in question are glycosaminoglycans (GAGs). GAGs are large, linear, sulfated polysaccharides ubiquitous to all mammals. Interests in GAG structures stem from GAGs' diverse biological activities that govern phenomena such as tissue development/regeneration, inflammation, blood coagulation and amyloid plaque formation. Abnormal GAG structures have also been associated with the development of a number of diseases, notably cancer and inflammation. As a result, there has been a desire to understand how GAG structures correlate with their biological activities, especially how the distribution of sulfate groups along the chain influence their interactions with GAG-binding proteins. However, GAGs' large size and complex sulfation patterns make analysis of intact GAG chains by conventional ensemble analytical techniques difficult, if not impossible. Here we propose to develop a single molecule sequencer for analysis of polysaccharides using the recognition tunneling nanopore (RTP) device currently under development for ""$1000 genome"" project as a template. With the R21 grant, we will demonstrate the feasibility by carrying out pre-requisite work needed to achieve single molecule sequencing of intact GAG chains using RTP. A RTP device incorporates a nanopore with a tunneling nanogap that contains two electrodes functionalized with recognition molecules capable of forming transient complexes with functional groups on a polymeric chain as it translocates the nanopore, thus generating electrical signals. Single molecule sequencing of GAG chains proposed here circumvents the need to obtain homogeneous samples of GAGs, greatly reducing complexity of sample preparation. GAG analysis by RT devices also does not have the size limitations of most of the existing analytical techniques, and the solid state device planned here are economical to manufacturer and operate. In this application, we aim to carry out pilot studies needed to make GAG sequencing by RTPs feasible: (1) we will investigate the translocation of size defined sulfated GAG fragments through nanopores to optimize the translocation efficiency of GAG ligands as well as to understand the influence of GAG sulfation density and GAG size on their translocation efficiency and speed; (2) we will carry out recognition tunneling experiments on sulfated GAG disaccharides as well as trisaccharides so these signals of GAGs can be analyzed using machine learning algorithms to identify unique signatures needed to detect the presence of these sulfation motifs in longer GAG chains. Completion of these aims will provide all the knowledge required for correct interpretations of RT signals produced by GAG translocation and sets the stage for sequencing of intact GAG chains by RT devices.         PUBLIC HEALTH RELEVANCE:     Work proposed here will allow single molecule sequencing of glycosaminoglycan polysaccharides using an electronic chip with a high speed and low cost for the first time. Glycosaminoglycans have important pharmacological properties and are modulators of critical biological phenomena such as tissue development/regeneration and inflammation. Determination of their sequence structures will allow better understanding of how organisms control these physiological events through glycosaminoglycans.            ",Single Molecule Sequencing of Glycosaminoglycans using Recognition Tunneling Nanopores,8984813,R21GM118339,"['Acute', 'Algorithms', 'Amino Acids', 'Architecture', 'Binding Proteins', 'Biological', 'Biological Markers', 'Biological Phenomena', 'Blood coagulation', 'Cells', 'Charge', 'Chemistry', 'Complex', 'Coupled', 'DNA', 'DNA Sequence', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Disaccharides', 'Disease', 'Electrodes', 'Electronics', 'Electrons', 'Environment', 'Enzymes', 'Event', 'Genome', 'Glycobiology', 'Glycosaminoglycans', 'Goals', 'Grant', 'Imidazole', 'Individual', 'Inflammation', 'Inorganic Sulfates', 'Ions', 'Isomerism', 'Knowledge', 'Leukocyte Trafficking', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Mammals', 'Manufacturer Name', 'Mediating', 'Methods', 'Microbe', 'Natural regeneration', 'Neoplasm Metastasis', 'Oligosaccharides', 'Organism', 'Pattern', 'Physiological', 'Pilot Projects', 'Play', 'Polysaccharides', 'Preparation', 'Process', 'Property', 'Proteins', 'Publishing', 'Reader', 'Reading', 'Research', 'Role', 'Sampling', 'Senile Plaques', 'Side', 'Signal Transduction', 'Signaling Protein', 'Site', 'Speed', 'Staging', 'Structure', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Tissues', 'Trisaccharides', 'Unspecified or Sulfate Ion Sulfates', 'Work', 'amyloid formation', 'analytical method', 'base', 'cancer cell', 'cost', 'density', 'design', 'extracellular', 'functional group', 'interest', 'nanopore', 'polysulfated glycosaminoglycan', 'programs', 'public health relevance', 'research study', 'single molecule', 'solid state', 'stem', 'sugar', 'sulfation', 'tool']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2015,273816,6.0055195441426315e-05
"Statistical and computational analysis in whole genome sequencing studies. DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges. PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.",Statistical and computational analysis in whole genome sequencing studies.,8930750,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Health', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'meetings', 'population based', 'programs']",NHGRI,STANFORD UNIVERSITY,R01,2015,292499,-0.016815975517588462
"Human-Specific Gain and Loss of Function DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university. PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.",Human-Specific Gain and Loss of Function,8796200,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomic Segment', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2015,54194,-0.00602406894877986
"Genome analysis based on the integration of DNA sequence and shape DESCRIPTION (provided by applicant): Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription facors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.",Genome analysis based on the integration of DNA sequence and shape,8795204,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Binding', 'DNA Databases', 'DNA Methylation', 'DNA Sequence', 'DNA Structure', 'DNA-Binding Proteins', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Drosophila genus', 'Embryonic Development', 'Family', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Health', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Lead', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Mining', 'Minor Groove', 'Modeling', 'Molecular Biology', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Binding', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Relative (related person)', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'flexibility', 'genetic evolution', 'genome analysis', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'research study', 'three dimensional structure', 'tool', 'transcription factor', 'vector']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2015,304719,-0.0011765321731651587
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies.         PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.            ",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,8984471,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug Regulations', 'Drug resistance', 'Family', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2015,300000,0.048399135583241965
"Informatics Tools for High-throughput Analysis of Cancer Mutations DESCRIPTION (provided by applicant): Large tumor exome sequencing projects have identified a very large number of mutations whose cancer relevance is not yet understood. To begin to address this need, our team has produced two web applications for high-throughput computational analysis of cancer mutations: the Cancer-Related Analysis of VAriants Toolkit (CRAVAT) and the Mutation Position Imaging Toolbox (MuPIT). CRAVAT accepts millions of mutations in a single batch upload and maps mutations from genomic coordinates to annotated transcripts and proteins. MuPIT currently accepts batch uploads of up to 2500 SNVs and maps from genomic coordinates onto X-ray crystal structures of proteins from Protein Data Bank (PDB). We propose to combine and harden CRAVAT and MuPIT into a single web application, in which we will substantially improve the tools, user interface, software infrastructure, integration with external data resources and tools used by the community, and support for protected data. The scope of all tools in the web application will be broadened to handle analysis of the full range of small-scale mutation consequence types found in cancer exomes.  CRAVAT analysis identifies mutations most likely to have deleterious impact on protein function and those that are most likely to confer a selective advantage to cancer cells (drivers), using classifiers developed by our team. Classifier scores are supplemented with annotations, including population allele frequencies, previous occurrence in tumor tissue types, and gene functional categories, enabling filtering (e.g. removing polymorphisms) and prioritization. Gene-level annotation and scoring, by aggregation of classifier scores from mutations in a cohort is also provided.  MuPIT maps mutations from genomic positions onto to protein structures and provides interactive viewing of mutations in the context of protein structure, and in relation to a variety of annotations. To enable prioritization of interesting mutations and genes, the application provides a preview describing each structure and all available annotations (e.g., binding sites, experimental mutagenesis results, polymorphic and disease- associated variants that have been previously documented). After selecting a PDB of interest, the user is led to an interactive visualization page. An enhanced Jmol applet displays all SNVs mapped onto the structure. Frequently, many SNVs in the input list can be mapped onto a single structure, revealing clustering patterns around key functional sites.  Based only on word-of-mouth, since the debut of the two applications in August 2012, CRAVAT has been utilized by 129 unique users from 39 countries, and it has analyzed 1,136 submitted jobs, totaling 27.9 million mutations. MuPIT has been utilized by 242 unique users from 25 countries, with 720 submitted jobs. (Source: Google Analytics). PUBLIC HEALTH RELEVANCE: The proposed work will harden and develop web applications for the cancer genomics community to interpret small-scale mutations in cancer exomes. They are designed to handle very large number of mutations and to provide analysis targeted at researchers who are not bioinformatics experts. The work will contribute to understanding of the genetic complexity and heterogeneity of tumors and assist in discovery of new approaches for cancer prognosis and treatments.",Informatics Tools for High-throughput Analysis of Cancer Mutations,8910262,U01CA180956,"['Address', 'Binding Sites', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer Prognosis', 'Categories', 'Classification', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer software', 'Country', 'Data', 'Databases', 'Development', 'Disease', 'Doctor of Medicine', 'Ensure', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Health', 'Heterogeneity', 'Histocompatibility Testing', 'Housing', 'Image', 'Imagery', 'Informatics', 'Internet', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Missense Mutation', 'Molecular', 'Mutagenesis', 'Mutate', 'Mutation', 'Mutation Analysis', 'Occupations', 'Pathway Analysis', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Privacy', 'Production', 'Proteins', 'Publications', 'Qualifying', 'RNA Splicing', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Scientist', 'Secure', 'Site', 'Source', 'Structure', 'Technology', 'The Cancer Genome Atlas', 'Transcript', 'Translations', 'Tumor Tissue', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'anticancer research', 'base', 'cancer cell', 'cancer classification', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cohort', 'data exchange', 'design', 'exome', 'exome sequencing', 'experience', 'high throughput analysis', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'next generation sequencing', 'novel strategies', 'personalized diagnostics', 'prognostic', 'protein function', 'protein structure', 'software development', 'tool', 'tumor', 'user-friendly', 'web interface', 'web services']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2015,315948,0.020606807706495936
"Genome engineering tools for functional screening of non-coding elements     DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root).         PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.                ",Genome engineering tools for functional screening of non-coding elements,8804084,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Laboratories', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Relative (related person)', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",K99,2015,99937,-0.023732880405640384
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8840551,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'genetic variant', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,219004,-0.010568622585051474
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,0.03829096450087399
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8601147,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2014,989800,0.030798501645917097
"Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions     DESCRIPTION (provided by applicant): The goal of the proposed research training program is to provide me (Dr. Collin Melton) with additional training in areas that will accelerate my career development as I transition from a post-doctoral fellow in Dr. Michael Snyder's lab to an independent tenure track professor. The key elements of this plan are: Candidate: I have extensive training in experimental and computational approaches to studying biomedicine. Areas of additional focus for career development during the K99 mentored post-doctoral research phase include the acquisition of additional experimental skills and supplemental training in cancer biology, human genetics, human genomics, applied statistics, and parallel computing. Additionally, I will receive training in laboratory management, mentorship, and responsible conduct of research. This well-rounded plan will provide me with a skill set that will enable a facile transition from postdoctoral fellow to tenure track faculty. Environment: I have a valuable advisory committee with experts in the areas of genomics, genetics, and cancer biology to ensure my success in this training program and to guide me through the successful acquisition of a faculty job. These include my mentor Dr. Michael Snyder, my co-mentor Dr. James Ford and two advisors, Dr. Hanlee Ji and Dr. Anshul Kundaje. The environment at Stanford University in the Snyder lab and department of Genetics fosters productivity and collaboration with word class facilities, resources, and researchers. Research: My proposed research plan in cancer genomics is timely, relevant, and innovative. The majority of current research in cancer genomics has made groundbreaking progress in understanding the relevant DNA variation that occurs in coding regions of the genome; however, 97-98% of the human genome does not code for protein. This proposal focuses specifically on studying the regulatory regions of the human genome to identify, characterize, and interpret the impact of point mutations in these regulatory regions. The central hypothesis of this proposal is that point mutations in regulatory regions of the human genome drive cancer formation and the functional consequences of these mutations can be predicted using machine learning algorithms. Aim 1 proposes the statistical identification of regulatory regions which are mutated across cancer samples, Aim 2 proposes functional characterization of the prevalent mutations identified in Aim 1, and Aim 3 extends the analysis of characterizing the effects of mutations genome-wide through use of genomics approaches and proposes the use of machine learning to classify novel mutations as either disrupting, activating, or having no effect on regulatory element activity. Through its use of experimental datasets combined with predictive models for functional consequences of individual cancer variation, this research will further the goal of personalized genome interpretation for cancer therapy.         PUBLIC HEALTH RELEVANCE: Every cancer patient's disease is caused by unique set of abnormal variation in the human genome. Advancing our understanding this variation aids in the development of new treatments and the proper application of existing treatments. This proposal focuses on understanding a particular type of cancer variation that occurs in regulatory regions of the human genome.        The written critiques of individual reviewers are provided in essentially unedited form in this section. Please note that these critiques and criteria scores were prepared prior to the meeting and may not have been revised subsequent to any discussions at the review meeting. The ""Resume and Summary of Discussion"" section above summarizes the final opinions of the committee.                ","Identification, Characterization, and Prediction of Cancer Driver Mutations in Regulatory Regions",8805723,K99CA191093,"['Address', 'Advisory Committees', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Area', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cause of Death', 'Cell Line', 'ChIP-seq', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Collaborations', 'Critiques', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Distal', 'Elements', 'Encyclopedia of DNA Elements', 'Ensure', 'Environment', 'Evaluation', 'Faculty', 'Fostering', 'Functional RNA', 'Future', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Hela Cells', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Laboratories', 'Machine Learning', 'Malignant Neoplasms', 'Mentors', 'Mentorship', 'Mutate', 'Mutation', 'Normal Cell', 'Nucleic Acid Regulatory Sequences', 'Occupations', 'Phase', 'Point Mutation', 'Postdoctoral Fellow', 'Productivity', 'Proteins', 'Regimen', 'Regulatory Element', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Site', 'The Cancer Genome Atlas', 'Therapeutic', 'Training', 'Training Programs', 'United States', 'Universities', 'Variant', 'Vision', 'Writing', 'base', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cancer type', 'carcinogenesis', 'career development', 'epigenomics', 'genome sequencing', 'genome-wide', 'innovation', 'interest', 'meetings', 'migration', 'mutant', 'novel', 'parallel computer', 'predictive modeling', 'professor', 'public health relevance', 'responsible research conduct', 'skills', 'statistics', 'success', 'trend', 'tumor progression']",NCI,STANFORD UNIVERSITY,K99,2014,116122,0.011482608467562206
"Gene Prediction by Markov Models and Complementary Methods DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad. NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8909702,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'metagenome', 'novel', 'pathogen', 'programs', 'pyrosequencing', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2014,100000,0.024161526996229137
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.  The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects is ongoing. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We have created programs for calculating permutation p-values for the linkage results obtained when using propensity scores in LODPAL in the S.A.G.E. program package and have created programs that convert multipoint IBD sharing values calculated in SIMWALK2 so that they can be used by LODPAL in place of the IBD sharing calculated by the GENIBD program. The SIMWALK2 results are often more accurate than the approximations from GENIBD and calculation time is much faster. This year we have utilized propensity scores in IBDReg, have completed development of a program to compute empirical p-values and are applying these methods to Dr. Bailey-Wilson's prostate cancer data.  We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. This year we have published a paper showing a method for estimating interaction effect sizes 1. We have developed a recurrency method in Random Forests that seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and are also applying this method to GAW18 data. Several manuscripts presenting this work are in preparation or submitted. We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets. This novel method was used in a recent applied analysis of oral cleft GWAS data and a paper is under review.  We have used the GAW17 simulated whole-exome sequence (WES) data to develop novel tools for analysis and interpretation of WES data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. This paper has been published for publication in BMC Proceedings (2014). Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data. In addition, this year we contributed to the development of an approach to analysis of very rare variants in WES/WGS data using exact probabilities 2 that was recently published in Bioinformatics. Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models. In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates Two papers were published presenting this work 3,4. We are now in the process of applying these approaches to several of our genome-wide datasets. n/a",Development of statistical genetics methodology,8948354,ZIAHG000153,"['African American', 'Bioinformatics', 'Biological Models', 'Caucasians', 'Caucasoid Race', 'Classification', 'Collaborations', 'Complex', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'Linear Models', 'Logistic Regressions', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Process', 'Publications', 'Publishing', 'Running', 'Scheme', 'Sequence Analysis', 'Simulate', 'Solutions', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trees', 'Variant', 'Work', 'base', 'case control', 'data mining', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'improved', 'novel', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2014,462019,-0.007002505046336373
"Statistical and computational analysis in whole genome sequencing studies.     DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges.         PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.                ",Statistical and computational analysis in whole genome sequencing studies.,8750827,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'meetings', 'population based', 'programs', 'public health relevance']",NHGRI,STANFORD UNIVERSITY,R01,2014,300000,-0.016815975517588462
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8635216,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2014,51530,-0.00602406894877986
"Genome analysis based on the integration of DNA sequence and shape  Title: Genome analysis based on the integration of DNA sequence and shape PI: Rohs, Remo (USC); Co-I: Noble, William Stafford (UW); Co-I: Tullius, Thomas D. (BU) PROJECT SUMMARY Current techniques for genome analysis are mainly based on the one-dimensional DNA sequence, comprised of the letters A, C, G, and T. However, proteins recognize DNA as a three-dimensional (3D) object. Nuances in DNA shape at single nucleotide resolution play a crucial role in the binding specificity of transcription factors (TFs), including those involved in embryonic development and human cancer. This project involves the development of a battery of tools for genome analysis, through the integration of information derived from the DNA sequence and the 3D structure of DNA, or ""DNA shape"". The basis for these novel tools is a high- throughput (HT) method for the prediction of multiple features of local DNA shape at the genomic scale. Data will be made available to the community in the UCSC Genome Browser track format through a web server interface. These tools will enable users to analyze the shape of any number or length of DNA sequences, including whole genomes and the effect of DNA methylation. HT shape predictions will be validated based on X-ray crystallography, NMR spectroscopy, and hydroxyl radical cleavage data. Predictions will be combined with ORChID, an ENCODE project that infers DNA minor groove geometry from hydroxyl radical cleavage experiments. The HT method will be used to study how paralogous TFs select different target sites in vivo despite sharing core-binding motifs or having similar binding properties in vitro. To study this question, we will investigate the effect of flanking sequences on multiple structural features of TF binding sites (TFBSs). The initial focus of this study will be homeodomains and basic helix-loop-helix (bHLH) TFs. Other protein families will later be included and used to construct a comprehensive TFBS database that provides shape features for binding motifs derived from JASPAR and other motif databases. Structural effects of single nucleotide polymorphisms (SNPs) will also be analyzed. Some SNPs are associated with deleterious functions, whereas others have no apparent effect. The HT shape prediction method will be used to predict the function of SNPs in non-coding regions based on DNA shape. We will correlate quantitative effects of SNPs on DNA structure with expression quantitative trait loci (eQTLs) and genome-wide association study (GWAS) signals, to develop a predictive tool for the functional effect of SNPs. The HT shape prediction approach will be used to design DNA sequences with different AT/GC contents but similar shapes. The relative contributions of sequence and shape to binding will be tested with analytic models including multiple linear regression (MLR) and support vector regression (SVR). For systems in which the integration of sequence and shape proves advantageous, novel motif finding tools will be developed based on an extended alphabet that combines sequence with informative structural features, selected by machine learning and feature selection approaches. Sequence+shape motifs will be tested by motif scanning, compared to sequence-only motifs, and integrated into the MEME Suite. The goal of this sequence-shape integration is to increase the accuracy of finding in vivo TFBSs in the genome. PUBLIC HEALTH RELEVANCE: Protein-DNA recognition is a critical yet poorly understood component of gene regulation. This proposal will connect the fields of DNA sequence and structure analysis, which so far have been developed in parallel but largely disconnected from each other. Integration of the one-dimensional DNA sequence at a genome-wide scale with the three-dimensional DNA structure at atomic resolution will lead to the development of novel genome analysis tools and will advance our understanding of genome function, leading to fundamentally new insights into the mechanisms of gene regulation and its impact on human disease.            ",Genome analysis based on the integration of DNA sequence and shape,8632246,R01GM106056,"['Affect', 'Affinity', 'Algorithms', 'BHLH Protein', 'Base Pairing', 'Base Sequence', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological Process', 'ChIP-on-chip', 'ChIP-seq', 'Characteristics', 'Communities', 'Computational algorithm', 'DNA', 'DNA Binding', 'DNA Databases', 'DNA Methylation', 'DNA Sequence', 'DNA Structure', 'DNA-Binding Proteins', 'DNase-I Footprinting', 'Data', 'Data Analyses', 'Databases', 'Deoxyribonuclease I', 'Development', 'Drosophila genus', 'Embryonic Development', 'Family', 'Functional RNA', 'Gene Expression Regulation', 'Genetic Transcription', 'Genome', 'Genome Scan', 'Genomics', 'Geometry', 'Goals', 'Guanine + Cytosine Composition', 'Helix-Turn-Helix Motifs', 'Human', 'Hybrids', 'Hydroxyl Radical', 'In Vitro', 'Internet', 'Lead', 'Length', 'Letters', 'Linear Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Methylation', 'Mining', 'Minor Groove', 'Modeling', 'Molecular Biology', 'NMR Spectroscopy', 'Nucleotides', 'Pilot Projects', 'Play', 'Process', 'Property', 'Protein Binding', 'Protein Family', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Relative (related person)', 'Resolution', 'Role', 'Scanning', 'Sequence Analysis', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Site', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Variant', 'Width', 'X-Ray Crystallography', 'Yeasts', 'base', 'design', 'flexibility', 'genetic evolution', 'genome analysis', 'genome wide association study', 'genome-wide', 'homeodomain', 'human disease', 'in vivo', 'insight', 'member', 'novel', 'novel strategies', 'public health relevance', 'research study', 'three dimensional structure', 'tool', 'transcription factor', 'vector']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2014,334303,-5.297157124339164e-05
"Informatic Profiling of Clinically Relevant Mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic Profiling of Clinically Relevant Mutation,8722025,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome sequencing', 'genetic regulatory protein', 'genetic variant', 'genome annotation', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2014,114720,0.00946477862914271
"Informatics Tools for High-throughput Analysis of Cancer Mutations     DESCRIPTION (provided by applicant): Large tumor exome sequencing projects have identified a very large number of mutations whose cancer relevance is not yet understood. To begin to address this need, our team has produced two web applications for high-throughput computational analysis of cancer mutations: the Cancer-Related Analysis of VAriants Toolkit (CRAVAT) and the Mutation Position Imaging Toolbox (MuPIT). CRAVAT accepts millions of mutations in a single batch upload and maps mutations from genomic coordinates to annotated transcripts and proteins. MuPIT currently accepts batch uploads of up to 2500 SNVs and maps from genomic coordinates onto X-ray crystal structures of proteins from Protein Data Bank (PDB). We propose to combine and harden CRAVAT and MuPIT into a single web application, in which we will substantially improve the tools, user interface, software infrastructure, integration with external data resources and tools used by the community, and support for protected data. The scope of all tools in the web application will be broadened to handle analysis of the full range of small-scale mutation consequence types found in cancer exomes.  CRAVAT analysis identifies mutations most likely to have deleterious impact on protein function and those that are most likely to confer a selective advantage to cancer cells (drivers), using classifiers developed by our team. Classifier scores are supplemented with annotations, including population allele frequencies, previous occurrence in tumor tissue types, and gene functional categories, enabling filtering (e.g. removing polymorphisms) and prioritization. Gene-level annotation and scoring, by aggregation of classifier scores from mutations in a cohort is also provided.  MuPIT maps mutations from genomic positions onto to protein structures and provides interactive viewing of mutations in the context of protein structure, and in relation to a variety of annotations. To enable prioritization of interesting mutations and genes, the application provides a preview describing each structure and all available annotations (e.g., binding sites, experimental mutagenesis results, polymorphic and disease- associated variants that have been previously documented). After selecting a PDB of interest, the user is led to an interactive visualization page. An enhanced Jmol applet displays all SNVs mapped onto the structure. Frequently, many SNVs in the input list can be mapped onto a single structure, revealing clustering patterns around key functional sites.  Based only on word-of-mouth, since the debut of the two applications in August 2012, CRAVAT has been utilized by 129 unique users from 39 countries, and it has analyzed 1,136 submitted jobs, totaling 27.9 million mutations. MuPIT has been utilized by 242 unique users from 25 countries, with 720 submitted jobs. (Source: Google Analytics).         PUBLIC HEALTH RELEVANCE: The proposed work will harden and develop web applications for the cancer genomics community to interpret small-scale mutations in cancer exomes. They are designed to handle very large number of mutations and to provide analysis targeted at researchers who are not bioinformatics experts. The work will contribute to understanding of the genetic complexity and heterogeneity of tumors and assist in discovery of new approaches for cancer prognosis and treatments.            ",Informatics Tools for High-throughput Analysis of Cancer Mutations,8735910,U01CA180956,"['Address', 'Binding Sites', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer Prognosis', 'Categories', 'Classification', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer software', 'Country', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Doctor of Medicine', 'Ensure', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Heterogeneity', 'Histocompatibility Testing', 'Housing', 'Image', 'Imagery', 'Informatics', 'Internet', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Missense Mutation', 'Molecular', 'Mutagenesis', 'Mutate', 'Mutation', 'Mutation Analysis', 'Occupations', 'Pathway Analysis', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Privacy', 'Production', 'Proteins', 'Publications', 'Qualifying', 'RNA Splicing', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Scientist', 'Secure', 'Site', 'Source', 'Structure', 'Technology', 'The Cancer Genome Atlas', 'Transcript', 'Translations', 'Tumor Tissue', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'anticancer research', 'base', 'cancer cell', 'cancer classification', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cloud based', 'cohort', 'data exchange', 'design', 'exome', 'exome sequencing', 'experience', 'high throughput analysis', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'microbial alkaline proteinase inhibitor', 'next generation sequencing', 'novel strategies', 'prognostic', 'protein function', 'protein structure', 'public health relevance', 'software development', 'tool', 'tumor', 'user-friendly', 'web interface', 'web services']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2014,317146,0.020606807706495936
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8642168,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,207764,-0.010568622585051474
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8699810,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic DNA', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,641093,0.0455049157255351
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,0.03829096450087399
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8416349,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2013,964551,0.030798501645917097
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects is ongoing. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We have created programs for calculating permutation p-values for the linkage results obtained when using propensity scores in LODPAL in the S.A.G.E. program package and have created programs that convert multipoint IBD sharing values calculated in SIMWALK2 so that they can be used by LODPAL in place of the IBD sharing calculated by the GENIBD program. The SIMWALK2 results are often more accurate than the approximations from GENIBD and calculation time is much faster. This year we have utilized propensity scores in IBDReg, are developing a program to compute empirical p-values and are performing studies of its performance. We plan on applying these methods to Dr. Bailey-Wilson's lung cancer and prostate cancer data.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have developed a recurrency method in Random Forests that seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data. One manuscript is in revision and others are in preparation. We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets. This novel method is undergoing additional testing.   We have used the GAW17 simulated whole-exome sequence (WES) data to develop novel tools for analysis and interpretation of WES data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. This paper has been accepted for publication in BMC Proceedings 1 . Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.   Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and gene by environment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models.  In collaboration with Dr. Qing Li in my section and Dr. Ingo Ruczinski at Johns Hopkins Bloomberg School of Public Health, an R program has been developed to simulate case-parent trio data for use in testing our ongoing development of methods for analyzing trio data.  Dr. Li in my section has also been developing a haplotype-based association method to analyze longitudinal data in collaboration with Dr. Kelly Benke at Johns Hopkins Bloomberg School of Public Health. n/a",Development of statistical genetics methodology,8750668,ZIAHG000153,"['African American', 'Biological Models', 'Caucasians', 'Caucasoid Race', 'Classification', 'Collaborations', 'Complex', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'Logistic Regressions', 'Machine Learning', 'Malignant neoplasm of lung', 'Malignant neoplasm of prostate', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Public Health Schools', 'Publications', 'Publishing', 'Running', 'Scheme', 'Sequence Analysis', 'Simulate', 'Solutions', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trees', 'Variant', 'base', 'case control', 'data mining', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'improved', 'method development', 'novel', 'programs', 'quality assurance', 'simulation', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2013,551144,-0.001495442237877701
"Second generation sequencing and analysis for cancer    DESCRIPTION (provided by applicant): Kevin Squire is a PhD in Electrical Engineering and former Computer Science professor with a strong interest in bioinformatics and human genetics. To this end, he joined Dr. Stanley F. Nelson's laboratory as a Postdoctoral Fellow in Human Genetics at UCLA one year ago, in order to retrain in bioinformatics and sequencing. Kevin's background in machine learning gives him a good foundation for a career in bioinformatics. What he needs, and what obtaining this grant will give him, is a good background in basic biology, biochemistry, and genetics, in order to better understand the biological processes behind the data he is working with. Kevin explorations in genetics have inspired him to make his career in this field. He hopes to gain a much better understanding of biology in order to ask and answer research questions relevant to the biology of cancer using second (and later) generation sequencing and through the use and development of relevant tools and analysis. As part of the research development plan, Kevin will complete a didactic coursework component in the first 2 years, to fill in the gaps in biology and bioinformatics in his background. During and after that, his research will focus on giving him a better understanding the genetics of cancer, attempting to answer relevant research questions from high throughput genomic sequencing data, through the use and creation of sequence analysis tools and other bioinformatics tools. Through his coursework and research, Kevin will attain the necessary skills to become an independent researcher in bioinformatics and genetics.       PUBLIC HEALTH RELEVANCE: Cancer is a genetic disease, caused by mutations in DNA and other genetic changes which affect how cells work. The work in this proposal uses and enhances new sequencing technology to help accurately determine exactly what changes are occurring in tumor DNA and RNA, which in turn affect protein production and the health of the cell. While much of the work is broadly applicable, the research will be evaluated in glioblastoma, the most common and most deadly form of brain cancer, and will help determine the best course of treatment for patients with this disease.         ",Second generation sequencing and analysis for cancer,8471121,K25GM097097,"['Address', 'Affect', 'Aftercare', 'Algorithms', 'Alternative Splicing', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Biological Process', 'Biology', 'Cancer Biology', 'Cells', 'Collaborations', 'Complex', 'DNA', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Electrical Engineering', 'Exons', 'Fellowship', 'Foundations', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Glioblastoma', 'Glioma', 'Grant', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Laboratories', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Measurement', 'Mentors', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Molecular', 'Mutation', 'Normal tissue morphology', 'Nucleotides', 'Other Genetics', 'Patients', 'Postdoctoral Fellow', 'Prevention strategy', 'Process', 'Production', 'Protein Isoforms', 'Proteins', 'RNA', 'RNA Sequences', 'Radiation therapy', 'Recording of previous events', 'Recurrence', 'Recurrent tumor', 'Relapse', 'Research', 'Research Personnel', 'Salvage Therapy', 'Sampling', 'Sequence Analysis', 'Spliced Genes', 'Techniques', 'Technology', 'Training Programs', 'Tumor Cell Biology', 'Tumor Tissue', 'Variant', 'Work', 'anticancer research', 'base', 'bevacizumab', 'cancer genetics', 'cancer genomics', 'career', 'computer science', 'disease-causing mutation', 'exome', 'exome sequencing', 'expectation', 'experience', 'genetic selection', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'methylome', 'next generation sequencing', 'professor', 'programs', 'public health relevance', 'research and development', 'resistance mechanism', 'skills', 'temozolomide', 'tool', 'tumor']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2013,123483,0.002032383470243438
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8457179,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2013,47114,-0.00602406894877986
"Comparative Genomics Unit Research Bioinformatics Developments  The Comparative Genomics Unit continues to develop, maintain, and distribute several software tools for the analysis of DNA sequence data.  This year we released a new mutation detection program, Shimmer, which detects somatic single nucleotide and small indel variants using hypothesis testing with correction for multiple testing.  In addition to making this program publicly available on github, we have published a report in Bioinformatics detailing Shimmers algorithm and describing its sensitivity and specificity when run on simulated data and real sequence data from the melanoma cell line COLO-829 Hansen et al., 2013.  We also continue to update and maintain the publicly available code for our genotyping program, bam2mpg, along with its recently introduced MPV scoring option.    In other work on somatic variant detection, we have developed a new copy number variant (CNV) detection algorithm, bardCNV, which predicts copy number alterations from matched sequence datasets (e.g., from tumor and normal tissue from the same individual, or parental cell lines and their derived child cell lines).  Using machine learning, bardCNV trains on observed read depths and variant allele frequencies, then predicts overall cell ploidy and purity, as well as copy number state for one or both alleles in haploid or diploid regions, respectively.  This year, our group participated in the Cancer Genome Atlas (TCGA) projects Benchmark 4 exercise by submitting VCF files with single nucleotide, small indel, and copy number variant predictions using Shimmer, MPV, and bardCNV for the exercises two breast cancer cell lines.  Another project in its early stages in the Comparative Genomics Unit is the development of a general purpose CNV caller.  This new caller combines both read depth and allele frequency information provided by sequence data with a hidden Markov model, and will be suitable for case/control, population survey, and parent-child trios data, to detect both germline and de novo CNVs.  It can also improve SNV calling in duplicated regions.  In collaboration with members of Leslie Bieseckers research group, we are also investigating the reliability of currently available CNV detection software in a comparison study.  For phylogenetic analyses, we have developed a fast, scalable and flexible method called PartFinder, and applied it to a variety of multi-species comparative genomics datasets to show their various levels of phylogenetic incongruence Prasad et al., 2012. We found significant correlations of incongruence across the genomes of human-chimpanzee-gorilla relative to genomic features like GC content, conservation and SNP density.  Whole Exome Pipeline Developments  In collaboration with the NISC Bioinformatics group, the Mullikin group continues to develop its software pipeline for the analysis of next generation sequence from captured exomic DNA.  This year, the pipeline was amended to include in its output variant frequencies from NHLBIs GO exome project, as well as Polyphen2 predictions of variant functional impact.  In addition, variant reports now include filtering for various modes of Mendelian inheritance when applicable.  Collaborative Work  Our groups collaboration with Daphne Bell has contributed to the publication of two papers reporting increased somatic mutation rates in multiple genes in endometrial cancers Price et al., 2013, Le Gallo et al., 2012.  These studies involved the analysis of both Sanger and next-generation (Illumina) sequencing, as well as statistical analyses of study design and gene mutation rates.  We have worked with numerous collaborators on the application and interpretation of results from the NISC whole exome sequencing (WES) pipeline.  Together with Ben Solomon and others, we investigated how one can apply WES genomic analysis for newborn screening Solomon et al., 2012, and in another study we looked for differences between monozygotic twins that might explain their discordant features of VACTERL association Solomon et al., 2013.  In two separate WES studies, new disease-related gene mutations were found, one related to early onset of EMARDD Pierson et al., 2013 through the homozygous deletion of exon 7 in the MEGF10 gene and the other causing a congenital neutrophil defect syndrome caused by mutations in the VPS45 gene Vilboux et al., 2013.  In the field of common disease, we reviewed known secondary cardiac disease variants in an exome cohort for prevalence and return of results with recomendations for follow-up Ng et al., 2013.  Finally, we compared X chromosome exome capture versus X chromosome sorting followed by next generation sequencing to evaluate the efficacy of these two approaches Teer et al., 2013.  Comparative sequence analyses of species other than human resulted in five publications for this reporting period.  Three of these publications resulted from our prior efforts on assembly and variation detection of the cat genome, as we have reported in prior years.  A better understanding of the extent of linkage disequilibrium across domestic cat breeds is described here Alhaddad et al., 2013.  Using cat SNPs genotyped across many breeds identified the gene that gives the Cornish Rex its curly coat trait Gandolfi et al., 2013.  In addition, using SNP genotype array analysis, we identified the gene responsible for tabby pattern variation in domestic cats, as well as the rare king cheetah phenotype as mutation in the gene Taqpep, which helps to establish a periodic pre-pattern during skin development Kaelin et al., 2012.  Using traditional BAC sequencing and assembly of Sanger reads, we investigated the segmental duplication expansions in primates, showing the evolutionary dynamics of the LRRC37 gene family Giannuzzi et al., 2013.  And finally, using an array of technologies and sequencing methods, we looked at genetic diversity and population history across the great apes Prado-Martinez et al., 2013. n/a",Comparative Genomics Unit Research,8750687,ZIAHG200330,"['Algorithms', 'Alleles', 'Benchmarking', 'Bioinformatics', 'Breast Cancer Cell', 'Breeding', 'Cancer cell line', 'Cell Line', 'Cells', 'Cheetahs', 'Child', 'Code', 'Collaborations', 'Communities', 'Computer software', 'DNA', 'DNA Sequence Analysis', 'Daphne plant', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Diploidy', 'Disease', 'Endometrial Carcinoma', 'Exercise', 'Exons', 'Felis catus', 'Frequencies', 'Gene Family', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Gorilla gorilla', 'Guanine + Cytosine Composition', 'Haploidy', 'Heart Diseases', 'Human', 'Human Genome', 'Individual', 'Institutes', 'Linkage Disequilibrium', 'Machine Learning', 'Melanoma Cell', 'Methods', 'Monozygotic Twinning', 'Monozygotic twins', 'Mutation', 'Mutation Detection', 'National Human Genome Research Institute', 'Neonatal Screening', 'Normal tissue morphology', 'Nucleotides', 'Output', 'Pan Genus', 'Paper', 'Parents', 'Pattern', 'Performance', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Ploidies', 'Pongidae', 'Population', 'Prevalence', 'Primates', 'Publications', 'Publishing', 'Reading', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'SNP genotyping', 'Sensitivity and Specificity', 'Sequence Analysis', 'Simulate', 'Skin', 'Software Tools', 'Somatic Mutation', 'Sorting - Cell Movement', 'Staging', 'Syndrome', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Update', 'Variant', 'Work', 'X Chromosome', 'case control', 'cat genome', 'cohort', 'comparative', 'comparative genomics', 'density', 'early onset', 'exome', 'exome sequencing', 'fascinate', 'flexibility', 'follow-up', 'improved', 'markov model', 'member', 'neutrophil', 'next generation', 'next generation sequencing', 'population survey', 'programs', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2013,1327152,-0.019895648441397764
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8526549,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome sequencing', 'genetic regulatory protein', 'genetic variant', 'genome annotation', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2013,444076,0.00946477862914271
"Informatics Tools for High-throughput Analysis of Cancer Mutations  PROJECT SUMMARY  Large tumor exome sequencing projects have identified a very large number of mutations whose cancer relevance is not yet understood. To begin to address this need, our team has produced two web applications for high-throughput computational analysis of cancer mutations: the Cancer-Related Analysis of VAriants Toolkit (CRAVAT) and the Mutation Position Imaging Toolbox (MuPIT). CRAVAT accepts millions of mutations in a single batch upload and maps mutations from genomic coordinates to annotated transcripts and proteins. MuPIT currently accepts batch uploads of up to 2500 SNVs and maps from genomic coordinates onto X-ray crystal structures of proteins from Protein Data Bank (PDB). We propose to combine and harden CRAVAT and MuPIT into a single web application, in which we will substantially improve the tools, user interface, software infrastructure, integration with external data resources and tools used by the community, and support for protected data. The scope of all tools in the web application will be broadened to handle analysis of the full range of small-scale mutation consequence types found in cancer exomes.  CRAVAT analysis identifies mutations most likely to have deleterious impact on protein function and those that are most likely to confer a selective advantage to cancer cells (drivers), using classifiers developed by our team. Classifier scores are supplemented with annotations, including population allele frequencies, previous occurrence in tumor tissue types, and gene functional categories, enabling filtering (e.g. removing polymorphisms) and prioritization. Gene-level annotation and scoring, by aggregation of classifier scores from mutations in a cohort is also provided.  MuPIT maps mutations from genomic positions onto to protein structures and provides interactive viewing of mutations in the context of protein structure, and in relation to a variety of annotations. To enable prioritization of interesting mutations and genes, the application provides a preview describing each structure and all available annotations (e.g., binding sites, experimental mutagenesis results, polymorphic and disease- associated variants that have been previously documented). After selecting a PDB of interest, the user is led to an interactive visualization page. An enhanced Jmol applet displays all SNVs mapped onto the structure. Frequently, many SNVs in the input list can be mapped onto a single structure, revealing clustering patterns around key functional sites.  Based only on word-of-mouth, since the debut of the two applications in August 2012, CRAVAT has been utilized by 129 unique users from 39 countries, and it has analyzed 1,136 submitted jobs, totaling 27.9 million mutations. MuPIT has been utilized by 242 unique users from 25 countries, with 720 submitted jobs. (Source: Google Analytics). PUBLIC HEALTH RELEVANCE: The proposed work will harden and develop web applications for the cancer genomics community to interpret small-scale mutations in cancer exomes. They are designed to handle very large number of mutations and to provide analysis targeted at researchers who are not bioinformatics experts. The work will contribute to understanding of the genetic complexity and heterogeneity of tumors and assist in discovery of new approaches for cancer prognosis and treatments.            ",Informatics Tools for High-throughput Analysis of Cancer Mutations,8606625,U01CA180956,"['Address', 'Binding Sites', 'Bioinformatics', 'Biological', 'Cancer Center', 'Cancer Prognosis', 'Categories', 'Classification', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer software', 'Country', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Doctor of Medicine', 'Ensure', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Heterogeneity', 'Histocompatibility Testing', 'Housing', 'Image', 'Imagery', 'Informatics', 'Internet', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Missense Mutation', 'Molecular', 'Mutagenesis', 'Mutate', 'Mutation', 'Mutation Analysis', 'Occupations', 'Pathway Analysis', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Privacy', 'Production', 'Proteins', 'Publications', 'Qualifying', 'RNA Splicing', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Scientist', 'Secure', 'Site', 'Source', 'Structure', 'Technology', 'The Cancer Genome Atlas', 'Transcript', 'Translations', 'Tumor Tissue', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'anticancer research', 'base', 'cancer cell', 'cancer classification', 'cancer genome', 'cancer genomics', 'cancer therapy', 'cohort', 'data exchange', 'design', 'exome', 'exome sequencing', 'experience', 'high throughput analysis', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'microbial alkaline proteinase inhibitor', 'next generation sequencing', 'novel strategies', 'prognostic', 'protein function', 'protein structure', 'public health relevance', 'software development', 'tool', 'tumor', 'user-friendly', 'web interface', 'web services']",NCI,JOHNS HOPKINS UNIVERSITY,U01,2013,289971,0.02056121711479388
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8599826,R01CA180777,"['Bees', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,214832,-0.010568622585051474
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8537965,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,624741,0.0455049157255351
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.        PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.              DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8350385,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Base Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'RNA', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'tool', 'transcription factor', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,220000,0.03244988791013562
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.      PUBLIC HEALTH RELEVANCE: The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.              The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8237596,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Delivery Systems', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2012,1010000,0.034052794011809585
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.           Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8320160,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'metagenome', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2012,204974,-0.0006234595604776425
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8521766,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'metagenome', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2012,75000,0.024161526996229137
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8266525,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'metagenome', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2012,577121,0.024161526996229137
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8228154,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'ChIP-seq', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,323572,0.012424806189051339
"Second generation sequencing and analysis for cancer    DESCRIPTION (provided by applicant): Kevin Squire is a PhD in Electrical Engineering and former Computer Science professor with a strong interest in bioinformatics and human genetics. To this end, he joined Dr. Stanley F. Nelson's laboratory as a Postdoctoral Fellow in Human Genetics at UCLA one year ago, in order to retrain in bioinformatics and sequencing. Kevin's background in machine learning gives him a good foundation for a career in bioinformatics. What he needs, and what obtaining this grant will give him, is a good background in basic biology, biochemistry, and genetics, in order to better understand the biological processes behind the data he is working with. Kevin explorations in genetics have inspired him to make his career in this field. He hopes to gain a much better understanding of biology in order to ask and answer research questions relevant to the biology of cancer using second (and later) generation sequencing and through the use and development of relevant tools and analysis. As part of the research development plan, Kevin will complete a didactic coursework component in the first 2 years, to fill in the gaps in biology and bioinformatics in his background. During and after that, his research will focus on giving him a better understanding the genetics of cancer, attempting to answer relevant research questions from high throughput genomic sequencing data, through the use and creation of sequence analysis tools and other bioinformatics tools. Through his coursework and research, Kevin will attain the necessary skills to become an independent researcher in bioinformatics and genetics.      PUBLIC HEALTH RELEVANCE: Cancer is a genetic disease, caused by mutations in DNA and other genetic changes which affect how cells work. The work in this proposal uses and enhances new sequencing technology to help accurately determine exactly what changes are occurring in tumor DNA and RNA, which in turn affect protein production and the health of the cell. While much of the work is broadly applicable, the research will be evaluated in glioblastoma, the most common and most deadly form of brain cancer, and will help determine the best course of treatment for patients with this disease.           Cancer is a genetic disease, caused by mutations in DNA and other genetic changes which affect how cells work. The work in this proposal uses and enhances new sequencing technology to help accurately determine exactly what changes are occurring in tumor DNA and RNA, which in turn affect protein production and the health of the cell. While much of the work is broadly applicable, the research will be evaluated in glioblastoma, the most common and most deadly form of brain cancer, and will help determine the best course of treatment for patients with this disease.         ",Second generation sequencing and analysis for cancer,8242400,K25GM097097,"['Address', 'Affect', 'Aftercare', 'Algorithms', 'Alternative Splicing', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Biological Process', 'Biology', 'Cancer Biology', 'Cells', 'Collaborations', 'Complex', 'DNA', 'DNA Sequence Rearrangement', 'Data', 'Data Analyses', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Electrical Engineering', 'Exons', 'Fellowship', 'Foundations', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Glioblastoma', 'Glioma', 'Grant', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Laboratories', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Measurement', 'Mentors', 'Methodology', 'Methods', 'Methylation', 'Modeling', 'Molecular', 'Mutation', 'Normal tissue morphology', 'Nucleotides', 'Other Genetics', 'Patients', 'Postdoctoral Fellow', 'Prevention strategy', 'Process', 'Production', 'Protein Isoforms', 'Proteins', 'RNA', 'RNA Sequences', 'Radiation therapy', 'Recording of previous events', 'Recurrence', 'Recurrent tumor', 'Relapse', 'Research', 'Research Personnel', 'Salvage Therapy', 'Sampling', 'Sequence Analysis', 'Spliced Genes', 'Techniques', 'Technology', 'Training Programs', 'Tumor Cell Biology', 'Tumor Tissue', 'Variant', 'Work', 'anticancer research', 'base', 'bevacizumab', 'cancer genetics', 'cancer genomics', 'career', 'computer science', 'disease-causing mutation', 'exome', 'expectation', 'experience', 'genetic selection', 'improved', 'insertion/deletion mutation', 'insight', 'interest', 'next generation', 'professor', 'programs', 'research and development', 'resistance mechanism', 'skills', 'temozolomide', 'tool', 'tumor']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2012,123483,-0.0007848715213375023
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8328943,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome', 'genetic regulatory protein', 'genetic variant', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2012,461516,0.00946477862914271
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.        PUBLIC HEALTH RELEVANCE: Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.              Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8373752,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,654177,0.04140644623629841
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,8134360,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait', 'treatment strategy']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2011,342569,-0.017583135928410102
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,8053866,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2011,577264,0.024161526996229137
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.      PUBLIC HEALTH RELEVANCE:    Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.                 Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8192895,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2011,180669,-0.016311373465238872
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8035949,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,321670,0.012424806189051339
"Pattern Discovery for comparative epigenomics    DESCRIPTION (provided by applicant): We propose a training program that will prepare an effective independent investigator in computational genomics. The candidate has a PhD in biology from the University of Cambridge and will extend his skills in both computational and wet-lab methods through a two-year program of organized mentorship and training, and a structured five-year research program.  This program will promote the command of machine learning as applied to functional genomics data. Dr. William Noble will mentor the candidate's scientific development. Dr. Noble is a recognized leader in computational biology and machine learning. He holds a dual appointment as Associate Professor in Genome Sciences and Com- puter Science and Engineering, and has trained numerous postdoctoral fellows and graduate students. Dr. Jeff Bilmes, Associate Professor of Electrical Engineering, will contribute to the mentoring effort, and a committee of experienced genome and computational biologists will advise on science and the candidate's career goals.  Research will focus on the analysis of multiple tracks of data from high-throughput sequencing assays, such as the ChIP-seq data produced by the ENCODE Project. These experiments allow us to obtain a more complete picture of the structure of human chromatin, revealing the behavior of transcription factors, the organization of epigenetic modifications, and the locations of accessible DNA across the entire genome at up to single-base resolution. A current challenge is to discover joint patterns across multiple tracks of these functional genomics results simultaneously. This project will (1) develop computational methods for identifying such patterns, providing new ways of finding both well-understood genomic features and novel functional elements, (2) apply those methods to characterize the similarities and differences among different biological samples, establishing a better understanding of chromatin, the bounds of its variation, and its role in human disease, and (3) validate computational findings with laboratory experiments. The project will use a dynamic Bayesian network (DBN), a type of probabilistic graphical model, to represent the statistical dependencies between observed data, such as sequencing tag density, on an inferred hidden state sequence.  The Department of Genome Sciences of the University Of Washington School Of Medicine provides an ideal setting for training a new independent investigator with an extensive program of formal and informal education for postdoctoral scientists, opportunities for collaboration with researchers with expertise in diverse areas, and modern computational and laboratory resources. This environment maximizes the potential for the candidate to obtain the training and perform the research necessary to establish himself as a skilled investigator with an independent research program.       PUBLIC HEALTH RELEVANCE: The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.              The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.            ",Pattern Discovery for comparative epigenomics,8164533,K99HG006259,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Appointment', 'Area', 'Base Pairing', 'Behavior', 'Biological', 'Biological Assay', 'Biology', 'Cell physiology', 'Cells', 'Censuses', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Methylation', 'DNA Sequence', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Data Sources', 'Deoxyribonucleases', 'Dependency', 'Development', 'Digestion', 'Disease', 'Doctor of Philosophy', 'Education', 'Electrical Engineering', 'Elements', 'Engineering', 'Enhancers', 'Environment', 'Epigenetic Process', 'Event', 'Exposure to', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Human', 'Individual', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Probability', 'Qualifying', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sampling', 'Schools', 'Science', 'Scientist', 'Seeds', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'Techniques', 'Time', 'Training', 'Training Programs', 'Transfection', 'Transgenic Mice', 'Universities', 'Variant', 'Washington', 'Work', 'base', 'career', 'cell type', 'chromatin immunoprecipitation', 'clinically relevant', 'comparative', 'computer based statistical methods', 'computer science', 'cytokine', 'density', 'disorder control', 'empowered', 'epigenomics', 'experience', 'follow-up', 'functional genomics', 'genome-wide', 'graduate student', 'histone modification', 'human disease', 'human tissue', 'improved', 'network models', 'new technology', 'novel', 'professor', 'programs', 'promoter', 'research study', 'skills', 'speech processing', 'transcription factor']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2011,102709,-0.03299253559893076
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8321717,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,342218,-0.008530812778093833
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8320051,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,2615448,-0.008530812778093833
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8238173,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome', 'genetic regulatory protein', 'genetic variant', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2011,500661,0.00946477862914271
"Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform    DESCRIPTION (provided by applicant): DNAnexus proposes to develop a complete solution for the identification and stratification of personal genetic variation from ultra-high-throughput sequencing projects. The solution will be implemented as a Web 2.0 service and online browsing tool that will integrate public data sources such as the 1000 genomes project, comparative information, and the ENCODE II project data. Users will be able to browse and stratify the identified variation in the context of these genomic annotations, and according to the likely functional impact. In Phase I of our project, we will develop a basic browser for displaying sequence reads that are mapped to a reference genome with our state-of-the-art read mapper. The browser will support viewing mate paired reads as well as display of the variation between these reads and the reference genome. It will facilitate the algorithmic development that we will perform during Phase II, and it will be the foundation for the more sophisticated variation browser also proposed in Phase II. In Phase II, we will develop algorithms for detecting genomic variation, and a state-of-the-art browser for viewing variation in the context of existing genome annotations, functional genomic and comparative genomic data. Our algorithms for detecting variation will support all major types of genomic variation, including SNPs, microindels, larger insertions and deletions, duplications, copy number variations, inversions, and translocations. Our algorithms will be based on state-of-the-art statistical and machine learning methodology for human genome resequencing. The DNAnexus browser will have two components: a list browser that displays variation as a list filtered and stratified by criteria that a user chooses, and a powerful GUI whose navigation capabilities are inspired by modern online tools such as Google Maps.      PUBLIC HEALTH RELEVANCE: DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.           Project Narrative DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.",Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform,7909096,R43HG005794,"['Algorithms', 'Architecture', 'Arts', 'Code', 'Copy Number Polymorphism', 'DNA Resequencing', 'Data', 'Data Display', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Environment', 'Foundations', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Human Genome', 'Imagery', 'Individual', 'Internet', 'Machine Learning', 'Maps', 'Methodology', 'Partner in relationship', 'Phase', 'Point Mutation', 'Reading', 'Services', 'Solutions', 'Statistical Methods', 'Stratification', 'Technology', 'Variant', 'base', 'comparative', 'comparative genomics', 'cost', 'flexibility', 'functional genomics', 'genome sequencing', 'graphical user interface', 'insertion/deletion mutation', 'public health relevance', 'tool']",NHGRI,"DNANEXUS, INC.",R43,2010,74477,-0.025564631286112246
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7902231,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2010,346884,-0.017583135928410102
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,7809669,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Arts', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2010,573248,0.024161526996229137
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7795846,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,326175,0.012424806189051339
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       Informatic profiling of clinically relevant mutation      Many approaches have been developed to predict whether a mutation associated with a disease is actually causative. In contrast to other approaches to predicting deleterious mutations, our approach, called in silico functional profiling, starts with learning residue-specific protein function and then estimates when it is disrupted. This research will continue our efforts to characterize what the underlying molecular disruption a mutation is causing and thereby improve accuracy of these approaches. We will do this by building a database that links clinical observation with molecular phenotype and using this to develop bioinformatic models of mutation. This is particularly relevant to cancer, since many mutations in cancer are both poorly understood and simply associated with cancer. The hypothesis of this proposal is that computational methods that predict a specific residue function using protein sequence and structure can classify known disease-associated mutations based on their function better than existing computational methods, and less expensively than experimental assays. In short, we will describe each phenotypically annotated mutation as possibly affecting catalysis, protein interactions, posttranslational modification and stability of the protein. The structural environments around disease associated mutations can be characterized using a combination of computational biochemical methods based on first principles of biomolecular structure and function and statistical informatics methods. We will continue this research by implementing the following steps: First, we will build a database of how often mutations in cancer, pharmacogenetics, Mendelian and complex disease are disrupted by phosphorylation, stability, catalysis, protein interaction and other posttranslational modifications. Second, we will build a bioinformatic model of disruption using machine learning methods trained with these and other commonly used features. Finally, we will link these to clinical observation by annotating disease causing mutation with an ontology of diseases and integrate these predictions into databases of mutation. Thus, we will link clinical observation with molecular phenotypes by building a useful database and new models of how mutations cause disease.          n/a",Informatic profiling of clinically relevant mutation,7929905,R01LM009722,"['Acetylation', 'Address', 'Affect', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Basic Science', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biology', 'Catalysis', 'Catalytic Domain', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computing Methodologies', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Databases', 'Disease', 'Environment', 'Funding', 'Genetic', 'Genetic Variation', 'Goals', 'Hereditary Disease', 'Human Resources', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Spectra', 'Ontology', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phosphorylation', 'Positioning Attribute', 'Post-Translational Protein Processing', 'Principal Investigator', 'Productivity', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Site', 'Structure', 'Testing', 'Training', 'Ubiquitination', 'Variant', 'Work', 'base', 'cancer classification', 'clinical care', 'clinically relevant', 'computer science', 'computerized tools', 'disease phenotype', 'disease-causing mutation', 'experience', 'falls', 'improved', 'innovation', 'molecular phenotype', 'novel strategies', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'tool', 'translational medicine']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2010,383293,0.02931166426004237
"Population Genetics Theory    DESCRIPTION (provided by applicant): Four areas of theoretical population genetics will be studied. In the first, we will develop mathematical and statistical framework for studying the evolution of genes that affect how other sets of genes interact with one another. This theory helps in understanding conditions under which the genome can be expected to become modular in its production of phenotypes, as well as when synergy between mutations in different genes should be produced by evolution. We shall study how the pattern of interaction between deleterious mutations evolves as a function of the mutation rate, the recombination rate, and the degree of fitness loss of each mutation. We shall also study buildup of statistical association between genes that influence culturally transmitted traits that are associated either through transmission or through fitness. The second area of study concerns the evolution of pathogens such as influenza. Here we build models to predict the accumulation of mutations during epidemics and pandemics in a way that can assist in guiding vaccination strategies. We will develop algorithms that search for potential recombinants and reassortants among a collection of up to 1000 viral sequences. Here we aim to devise a statistical test to indicate whether identified recombinants or reassortants are spurious or statistically significant. Our recent theory of niche construction will form the basis of studies of how pathogens might evolve in response to human actions that they induce, such as use of antibiotics. The final research area will develop multiple-gene models for sex-linked control of genomic imprinting. These will include cis and trans modifiers of imprinting. Fertility selection as well as sex- specific viabilities will be studied in order to clarify the role of multiple paternities, which has been proposed as a driving force in the evolution of genomic imprinting. Genomic data from mammalian species will be analyzed using tools from statistical learning in order to predict which genes are likely to be imprinted. Correlations between DMA sequence properties and predicted imprinting status based on life history characteristics will also be sought.           n/a",Population Genetics Theory,7869395,R01GM028016,"['Affect', 'Algorithms', 'Alleles', 'Antibiotics', 'Antigens', 'Area', 'Bacteria', 'Bacteriophages', 'Characteristics', 'Collection', 'Complex', 'Computers', 'DNA Sequence', 'Data', 'Development', 'Drug Formulations', 'Epidemic', 'Evolution', 'Fertility', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomic Imprinting', 'Genomics', 'Haploidy', 'Human', 'Influenza', 'Laboratories', 'Link', 'Machine Learning', 'Mammals', 'Modeling', 'Modification', 'Mutation', 'Organism', 'Pattern', 'Phenotype', 'Population Genetics', 'Production', 'Property', 'Recombinants', 'Research', 'Role', 'Specific qualifier value', 'Taxon', 'Testing', 'Time', 'Tweens', 'Vaccination', 'Variant', 'Viral', 'Virus', 'base', 'driving force', 'father role', 'fitness', 'gene function', 'genome sequencing', 'imprint', 'influenza epidemic', 'life history', 'pandemic disease', 'pathogen', 'research study', 'response', 'sex', 'social', 'theories', 'tool', 'trait', 'transmission process', 'vaccination strategy']",NIGMS,STANFORD UNIVERSITY,R01,2010,261556,0.049678420051971116
"Population Genetics Theory    DESCRIPTION (provided by applicant): Four areas of theoretical population genetics will be studied. In the first, we will develop mathematical and statistical framework for studying the evolution of genes that affect how other sets of genes interact with one another. This theory helps in understanding conditions under which the genome can be expected to become modular in its production of phenotypes, as well as when synergy between mutations in different genes should be produced by evolution. We shall study how the pattern of interaction between deleterious mutations evolves as a function of the mutation rate, the recombination rate, and the degree of fitness loss of each mutation. We shall also study buildup of statistical association between genes that influence culturally transmitted traits that are associated either through transmission or through fitness. The second area of study concerns the evolution of pathogens such as influenza. Here we build models to predict the accumulation of mutations during epidemics and pandemics in a way that can assist in guiding vaccination strategies. We will develop algorithms that search for potential recombinants and reassortants among a collection of up to 1000 viral sequences. Here we aim to devise a statistical test to indicate whether identified recombinants or reassortants are spurious or statistically significant. Our recent theory of niche construction will form the basis of studies of how pathogens might evolve in response to human actions that they induce, such as use of antibiotics. The final research area will develop multiple-gene models for sex-linked control of genomic imprinting. These will include cis and trans modifiers of imprinting. Fertility selection as well as sex- specific viabilities will be studied in order to clarify the role of multiple paternities, which has been proposed as a driving force in the evolution of genomic imprinting. Genomic data from mammalian species will be analyzed using tools from statistical learning in order to predict which genes are likely to be imprinted. Correlations between DMA sequence properties and predicted imprinting status based on life history characteristics will also be sought.           n/a",Population Genetics Theory,7986659,R01GM028016,"['Affect', 'Algorithms', 'Alleles', 'Antibiotics', 'Antigens', 'Area', 'Bacteria', 'Bacteriophages', 'Characteristics', 'Collection', 'Complex', 'Computers', 'DNA Sequence', 'Data', 'Development', 'Drug Formulations', 'Epidemic', 'Evolution', 'Fertility', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomic Imprinting', 'Genomics', 'Haploidy', 'Human', 'Influenza', 'Laboratories', 'Link', 'Machine Learning', 'Mammals', 'Modeling', 'Modification', 'Mutation', 'Organism', 'Pattern', 'Phenotype', 'Population Genetics', 'Production', 'Property', 'Recombinants', 'Research', 'Role', 'Specific qualifier value', 'Taxon', 'Testing', 'Time', 'Tweens', 'Vaccination', 'Variant', 'Viral', 'Virus', 'base', 'driving force', 'father role', 'fitness', 'gene function', 'genome sequencing', 'imprint', 'influenza epidemic', 'life history', 'pandemic disease', 'pathogen', 'research study', 'response', 'sex', 'social', 'theories', 'tool', 'trait', 'transmission process', 'vaccination strategy']",NIGMS,STANFORD UNIVERSITY,R01,2010,142237,0.049678420051971116
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7681225,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2009,351164,-0.017583135928410102
"Gene Prediction by Markov Models and Complementary Methods    DESCRIPTION (provided by applicant): We propose to extend the ab initio self-training algorithms for eukaryotic gene finding developed in the previous grant period in several important directions. First we will upgrade this algorithm to a multilevel data mining approach to allow construction of a consistent ""genome- transcriptome-proteome"" data structure at the early stages of a genome project. Here, we will compensate for an information deficit in various segments of experimental data (such as EST data) by unsupervised machine learning on existing and abundant data segments (an anonymous genomic sequence) with subsequent computational modeling of missing biological information (protein-coding genes and proteins). An important new feature of the self-training algorithm will be the utilization of protein level information to monitor and increase biological relevance of the models derived by the unsupervised iterative algorithm. Second, we will enhance the self-training algorithm developed earlier on a smaller scale and tested on fungal and other ""compact"" eukaryotic genomes (such as Caenorhabditis elegans and Drosophila melanogaster) to work with most complex eukaryotic genomes. At this higher level of complexity we see species with host genes occupying just a small fraction of genome which can be inhomogeneous in GC composition, populated with transposable elements and pseudogenes (besides animal genomes, genomes of some fungal pathogens as well as human parasites and their vectors fall into this category). Third, for the human microbiome containing bacterial, archaeal, viral and fungal species, situated at yet another end of the genome in homogeneity spectrum, we will develop improved algorithms and tools for ab initio gene identification. This work will be done in close contact with sequencing and annotation groups from leading genome centers both in the US and abroad.           NARRATIVE Rational systems biology, cancer cure, vaccine development, drug design, is impossible without understanding genomic DNA in human cell. Gene prediction is a cornerstone of biological interpretation of DNA sequence. The goal of this proposal is developing automatic and accurate gene prediction algorithms for the most complex genomic sequences important for human health.",Gene Prediction by Markov Models and Complementary Methods,7656528,R01HG000783,"['Address', 'Algorithms', 'Animals', 'Architecture', 'Arts', 'Biological', 'Biological Sciences', 'Biology', 'Caenorhabditis elegans', 'Categories', 'Cells', 'Code', 'Communication', 'Complex', 'Computer Simulation', 'DNA', 'DNA Sequence', 'DNA Transposable Elements', 'Data', 'Development', 'Drosophila melanogaster', 'Drug Design', 'Employee Strikes', 'Escherichia coli', 'Eukaryota', 'Expressed Sequence Tags', 'Feedback', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grant', 'Guanine + Cytosine Composition', 'Haemophilus influenzae', 'Health', 'Human', 'Human Genome', 'Human Microbiome', 'Intercistronic Region', 'Introns', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Parasites', 'Population', 'Prokaryotic Cells', 'Proteins', 'Proteome', 'Pseudogenes', 'RNA Splicing', 'Repetitive Sequence', 'Research', 'Shapes', 'Software Tools', 'Speed', 'Staging', 'Systems Biology', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Variant', 'Viral', 'Work', 'data mining', 'data structure', 'experience', 'falls', 'improved', 'markov model', 'novel', 'pathogen', 'programs', 'research and development', 'tool', 'vaccine development', 'vector']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2009,560000,0.024161526996229137
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7635337,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2009,330660,0.012424806189051339
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       Informatic profiling of clinically relevant mutation      Many approaches have been developed to predict whether a mutation associated with a disease is actually causative. In contrast to other approaches to predicting deleterious mutations, our approach, called in silico functional profiling, starts with learning residue-specific protein function and then estimates when it is disrupted. This research will continue our efforts to characterize what the underlying molecular disruption a mutation is causing and thereby improve accuracy of these approaches. We will do this by building a database that links clinical observation with molecular phenotype and using this to develop bioinformatic models of mutation. This is particularly relevant to cancer, since many mutations in cancer are both poorly understood and simply associated with cancer. The hypothesis of this proposal is that computational methods that predict a specific residue function using protein sequence and structure can classify known disease-associated mutations based on their function better than existing computational methods, and less expensively than experimental assays. In short, we will describe each phenotypically annotated mutation as possibly affecting catalysis, protein interactions, posttranslational modification and stability of the protein. The structural environments around disease associated mutations can be characterized using a combination of computational biochemical methods based on first principles of biomolecular structure and function and statistical informatics methods. We will continue this research by implementing the following steps: First, we will build a database of how often mutations in cancer, pharmacogenetics, Mendelian and complex disease are disrupted by phosphorylation, stability, catalysis, protein interaction and other posttranslational modifications. Second, we will build a bioinformatic model of disruption using machine learning methods trained with these and other commonly used features. Finally, we will link these to clinical observation by annotating disease causing mutation with an ontology of diseases and integrate these predictions into databases of mutation. Thus, we will link clinical observation with molecular phenotypes by building a useful database and new models of how mutations cause disease.          n/a",Informatic profiling of clinically relevant mutation,7675482,R01LM009722,"['Acetylation', 'Address', 'Affect', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Basic Science', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biology', 'Catalysis', 'Catalytic Domain', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computing Methodologies', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Databases', 'Disease', 'Environment', 'Funding', 'Genetic', 'Genetic Variation', 'Goals', 'Hereditary Disease', 'Human Resources', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Spectra', 'Ontology', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phosphorylation', 'Positioning Attribute', 'Post-Translational Protein Processing', 'Principal Investigator', 'Productivity', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Site', 'Structure', 'Testing', 'Training', 'Ubiquitination', 'Variant', 'Work', 'base', 'cancer classification', 'clinical care', 'clinically relevant', 'computer science', 'computerized tools', 'disease phenotype', 'disease-causing mutation', 'experience', 'falls', 'improved', 'innovation', 'molecular phenotype', 'novel strategies', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'tool', 'translational medicine']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2009,401422,0.02931166426004237
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       Informatic profiling of clinically relevant mutation      Many approaches have been developed to predict whether a mutation associated with a disease is actually causative. In contrast to other approaches to predicting deleterious mutations, our approach, called in silico functional profiling, starts with learning residue-specific protein function and then estimates when it is disrupted. This research will continue our efforts to characterize what the underlying molecular disruption a mutation is causing and thereby improve accuracy of these approaches. We will do this by building a database that links clinical observation with molecular phenotype and using this to develop bioinformatic models of mutation. This is particularly relevant to cancer, since many mutations in cancer are both poorly understood and simply associated with cancer. The hypothesis of this proposal is that computational methods that predict a specific residue function using protein sequence and structure can classify known disease-associated mutations based on their function better than existing computational methods, and less expensively than experimental assays. In short, we will describe each phenotypically annotated mutation as possibly affecting catalysis, protein interactions, posttranslational modification and stability of the protein. The structural environments around disease associated mutations can be characterized using a combination of computational biochemical methods based on first principles of biomolecular structure and function and statistical informatics methods. We will continue this research by implementing the following steps: First, we will build a database of how often mutations in cancer, pharmacogenetics, Mendelian and complex disease are disrupted by phosphorylation, stability, catalysis, protein interaction and other posttranslational modifications. Second, we will build a bioinformatic model of disruption using machine learning methods trained with these and other commonly used features. Finally, we will link these to clinical observation by annotating disease causing mutation with an ontology of diseases and integrate these predictions into databases of mutation. Thus, we will link clinical observation with molecular phenotypes by building a useful database and new models of how mutations cause disease.          n/a",Informatic profiling of clinically relevant mutation,7878232,R01LM009722,"['Acetylation', 'Address', 'Affect', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Basic Science', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biology', 'Catalysis', 'Catalytic Domain', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computing Methodologies', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Databases', 'Disease', 'Environment', 'Funding', 'Genetic', 'Genetic Variation', 'Goals', 'Hereditary Disease', 'Human Resources', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Spectra', 'Ontology', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phosphorylation', 'Positioning Attribute', 'Post-Translational Protein Processing', 'Principal Investigator', 'Productivity', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Site', 'Structure', 'Testing', 'Training', 'Ubiquitination', 'Variant', 'Work', 'base', 'cancer classification', 'clinical care', 'clinically relevant', 'computer science', 'computerized tools', 'disease phenotype', 'disease-causing mutation', 'experience', 'falls', 'improved', 'innovation', 'molecular phenotype', 'novel strategies', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'tool', 'translational medicine']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2009,46511,0.02931166426004237
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       We are submitting this proposal pursuant to NOT-0D-09-058, NIH Announces the Availability of Recovery Act Funds for Competitive Revision Applications.       Our group focuses on understanding how amino acid substitutions disrupt molecular functions that cause human disease. In our currently funded R01, we are developing methods we call in silico functional profiling. This method works by learning residue-specific protein function and then estimates when it is disrupted. This research funds our efforts to characterize what the underlying molecular disruption a protein mutation is causing and thereby improve accuracy of these approaches. In this competitive revision application, we are proposing to expand our efforts to the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation or transcript splicing. Additionally, we have formed collaborations with genetic data managers and will apply all of our methods to aid in their research and identify new testable hypotheses. We will do this in three supplemental aims. First, we will evaluate genomic features for prediction of regulatory nucleotide substitutions and construct new methods to aid in their classification. Second, we will collaboratively work to develop machine learning methods for classification of nucleotide substitutions that disrupt transcript splicing. Finally, we will work to collaboratively annotate genetic data found in inherited disease, pharmacogenetics and somatic mutations in cancer. Together this Recovery Act proposal will fund two groups in bioinformatics and will support trainees, technical staff, and two faculty members.           7. Narrative In this research, we will identify genetic variants that are likely to disrupt genome function, mRNA transcript processing and protein function. We will develop new methods and databases that will hypothesize the underlying molecular mechanism of genetic disease and genetic phenotypes.",Informatic profiling of clinically relevant mutation,7809730,R01LM009722,"['Affect', 'American', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Area', 'Binding Sites', 'Bioinformatics', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Computer Simulation', 'CpG Islands', 'DNA Resequencing', 'Data', 'Data Collection', 'Databases', 'Dideoxy Chain Termination DNA Sequencing', 'Disease', 'Economics', 'Elements', 'Epigenetic Process', 'Faculty', 'Focus Groups', 'Funding', 'Gene Expression Regulation', 'Gene Mutation', 'Generations', 'Genetic', 'Genetic Polymorphism', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genome', 'Genomics', 'Hereditary Disease', 'Indium', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Messenger RNA', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Nucleotides', 'Paper', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Protein Analysis', 'Proteins', 'RNA Splicing', 'Recovery', 'Research', 'Research Personnel', 'Research Priority', 'Scientist', 'Site', 'Somatic Mutation', 'Tertiary Protein Structure', 'Time', 'Training', 'Transcript', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical application', 'clinically relevant', 'data management', 'data mining', 'disease-causing mutation', 'genetic variant', 'human disease', 'improved', 'innovation', 'member', 'molecular phenotype', 'novel strategies', 'protein function', 'sound', 'tool', 'transcription factor']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2009,145500,-0.010610012011119095
"Population Genetics Theory    DESCRIPTION (provided by applicant): Four areas of theoretical population genetics will be studied. In the first, we will develop mathematical and statistical framework for studying the evolution of genes that affect how other sets of genes interact with one another. This theory helps in understanding conditions under which the genome can be expected to become modular in its production of phenotypes, as well as when synergy between mutations in different genes should be produced by evolution. We shall study how the pattern of interaction between deleterious mutations evolves as a function of the mutation rate, the recombination rate, and the degree of fitness loss of each mutation. We shall also study buildup of statistical association between genes that influence culturally transmitted traits that are associated either through transmission or through fitness. The second area of study concerns the evolution of pathogens such as influenza. Here we build models to predict the accumulation of mutations during epidemics and pandemics in a way that can assist in guiding vaccination strategies. We will develop algorithms that search for potential recombinants and reassortants among a collection of up to 1000 viral sequences. Here we aim to devise a statistical test to indicate whether identified recombinants or reassortants are spurious or statistically significant. Our recent theory of niche construction will form the basis of studies of how pathogens might evolve in response to human actions that they induce, such as use of antibiotics. The final research area will develop multiple-gene models for sex-linked control of genomic imprinting. These will include cis and trans modifiers of imprinting. Fertility selection as well as sex- specific viabilities will be studied in order to clarify the role of multiple paternities, which has been proposed as a driving force in the evolution of genomic imprinting. Genomic data from mammalian species will be analyzed using tools from statistical learning in order to predict which genes are likely to be imprinted. Correlations between DMA sequence properties and predicted imprinting status based on life history characteristics will also be sought.           n/a",Population Genetics Theory,7631265,R01GM028016,"['Affect', 'Algorithms', 'Alleles', 'Antibiotics', 'Antigens', 'Area', 'Bacteria', 'Bacteriophages', 'Characteristics', 'Collection', 'Complex', 'Computers', 'DNA Sequence', 'Data', 'Development', 'Drug Formulations', 'Epidemic', 'Evolution', 'Fertility', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomic Imprinting', 'Genomics', 'Haploidy', 'Human', 'Influenza', 'Laboratories', 'Link', 'Machine Learning', 'Mammals', 'Modeling', 'Modification', 'Mutation', 'Organism', 'Pan Genus', 'Pattern', 'Phenotype', 'Population Genetics', 'Production', 'Property', 'Recombinants', 'Research', 'Role', 'Specific qualifier value', 'Taxon', 'Testing', 'Time', 'Tweens', 'Vaccination', 'Variant', 'Viral', 'Virus', 'base', 'driving force', 'father role', 'fitness', 'gene function', 'genome sequencing', 'imprint', 'influenza epidemic', 'life history', 'pandemic disease', 'pathogen', 'research study', 'response', 'sex', 'social', 'theories', 'tool', 'trait', 'transmission process', 'vaccination strategy']",NIGMS,STANFORD UNIVERSITY,R01,2009,259841,0.049678420051971116
"Exon recognition during constitutive pre-mRNA splicing    DESCRIPTION (provided by applicant): The splicing together of exons during the transcription of most eukaryotic pre-mRNA molecules is a fundamental step in the transfer of information from DNA to protein. However, how the splice sites are recognized to initiate this fast and accurate process in not at all clear, since false sequences that resemble real sites outnumber the latter by 1 or 2 orders of magnitude yet are not used. We are searching for the additional information that specifies splice site recognition during pre-mRNA splicing in mammalian cells. In previous work we have used computational analysis to discover that: 1) that exon flanks 50 nt beyond the splice site consensuses can greatly influence splicing and contain sequences that stand out from the background; and 2) there are a large number of specific 8 mers that can act either as exonic splicing enhancers or splicing silencers. We will characterize both of these types of sequences, defining their base requirements, extent, position dependence, and specificity. With regard to the last, we will develop a novel exhaustive survey method that uses massively parallel solid state sequencing to identify every possible 8-mer that can be functional in a particular context, and we will compare this profile in different intronic, exonic and cellular contexts for constitutive and alternatively spliced exons. The flanking sequences fall into 2 distinct classes according to their G+C contents; we will test the idea that the rules governing exon definition differ for the two classes. To simplify the discovery of rules that govern exon definition, we will create designer exons made up of synthetic 8-mer modules we have identified as enhancers, silencers or neutral sequences. The numbers and spacing of these modules will reveal relationships that are hidden in the complexity of natural sequences. Finally, we will continue to use computation, including new machine learning algorithms, to better define intronic elements and to discover interactions between two or more features of a local sequence that define a splice site. We will also develop a Web-based exon-finding program that integrates all the information we have accumulated. Pre-mRNA splicing goes awry in a large proportion or human genetic disease cases. An understanding of the rules that govern the recognition of splice sites should help in the design of therapeutic intervention strategies to reverse such ill effects.                           n/a",Exon recognition during constitutive pre-mRNA splicing,7469442,R01GM072740,"['Algorithms', 'Alternative Splicing', 'Class', 'Computer Analysis', 'Consensus', 'DNA', 'Dependence', 'Elements', 'Enhancers', 'Exons', 'Genetic Transcription', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'Heterogeneous Nuclear RNA', 'Human', 'Intervention', 'Introns', 'Machine Learning', 'Mammalian Cell', 'Numbers', 'Online Systems', 'Positioning Attribute', 'Process', 'Proteins', 'RNA Splicing', 'Role', 'Signal Transduction', 'Site', 'Specific qualifier value', 'Specificity', 'Structure', 'Survey Methodology', 'Surveys', 'Testing', 'Therapeutic Intervention', 'Work', 'base', 'design', 'falls', 'genetic selection', 'mRNA Precursor', 'novel', 'prevent', 'programs', 'size', 'solid state']",NIGMS,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2008,291756,-0.001770988848961623
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7522602,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Class', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pan troglodytes', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Rate', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2008,369424,-0.017583135928410102
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       Informatic profiling of clinically relevant mutation      Many approaches have been developed to predict whether a mutation associated with a disease is actually causative. In contrast to other approaches to predicting deleterious mutations, our approach, called in silico functional profiling, starts with learning residue-specific protein function and then estimates when it is disrupted. This research will continue our efforts to characterize what the underlying molecular disruption a mutation is causing and thereby improve accuracy of these approaches. We will do this by building a database that links clinical observation with molecular phenotype and using this to develop bioinformatic models of mutation. This is particularly relevant to cancer, since many mutations in cancer are both poorly understood and simply associated with cancer. The hypothesis of this proposal is that computational methods that predict a specific residue function using protein sequence and structure can classify known disease-associated mutations based on their function better than existing computational methods, and less expensively than experimental assays. In short, we will describe each phenotypically annotated mutation as possibly affecting catalysis, protein interactions, posttranslational modification and stability of the protein. The structural environments around disease associated mutations can be characterized using a combination of computational biochemical methods based on first principles of biomolecular structure and function and statistical informatics methods. We will continue this research by implementing the following steps: First, we will build a database of how often mutations in cancer, pharmacogenetics, Mendelian and complex disease are disrupted by phosphorylation, stability, catalysis, protein interaction and other posttranslational modifications. Second, we will build a bioinformatic model of disruption using machine learning methods trained with these and other commonly used features. Finally, we will link these to clinical observation by annotating disease causing mutation with an ontology of diseases and integrate these predictions into databases of mutation. Thus, we will link clinical observation with molecular phenotypes by building a useful database and new models of how mutations cause disease.          n/a",Informatic profiling of clinically relevant mutation,7502757,R01LM009722,"['Acetylation', 'Address', 'Affect', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Basic Science', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biology', 'Caring', 'Catalysis', 'Catalytic Domain', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computing Methodologies', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Databases', 'Disease', 'Disruption', 'Environment', 'Funding', 'Genetic', 'Genetic Variation', 'Goals', 'Hereditary Disease', 'Human Resources', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Spectra', 'Ontology', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phenotype', 'Phosphorylation', 'Positioning Attribute', 'Post-Translational Protein Processing', 'Principal Investigator', 'Productivity', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Score', 'Site', 'Structure', 'Testing', 'Training', 'Ubiquitination', 'Variant', 'Work', 'base', 'cancer classification', 'clinically relevant', 'computer science', 'computerized tools', 'disease phenotype', 'disease-causing mutation', 'experience', 'falls', 'improved', 'innovation', 'novel strategies', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'tool', 'translational medicine']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2008,158863,0.02931166426004237
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       Informatic profiling of clinically relevant mutation      Many approaches have been developed to predict whether a mutation associated with a disease is actually causative. In contrast to other approaches to predicting deleterious mutations, our approach, called in silico functional profiling, starts with learning residue-specific protein function and then estimates when it is disrupted. This research will continue our efforts to characterize what the underlying molecular disruption a mutation is causing and thereby improve accuracy of these approaches. We will do this by building a database that links clinical observation with molecular phenotype and using this to develop bioinformatic models of mutation. This is particularly relevant to cancer, since many mutations in cancer are both poorly understood and simply associated with cancer. The hypothesis of this proposal is that computational methods that predict a specific residue function using protein sequence and structure can classify known disease-associated mutations based on their function better than existing computational methods, and less expensively than experimental assays. In short, we will describe each phenotypically annotated mutation as possibly affecting catalysis, protein interactions, posttranslational modification and stability of the protein. The structural environments around disease associated mutations can be characterized using a combination of computational biochemical methods based on first principles of biomolecular structure and function and statistical informatics methods. We will continue this research by implementing the following steps: First, we will build a database of how often mutations in cancer, pharmacogenetics, Mendelian and complex disease are disrupted by phosphorylation, stability, catalysis, protein interaction and other posttranslational modifications. Second, we will build a bioinformatic model of disruption using machine learning methods trained with these and other commonly used features. Finally, we will link these to clinical observation by annotating disease causing mutation with an ontology of diseases and integrate these predictions into databases of mutation. Thus, we will link clinical observation with molecular phenotypes by building a useful database and new models of how mutations cause disease.          n/a",Informatic profiling of clinically relevant mutation,7841085,R01LM009722,"['Acetylation', 'Address', 'Affect', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Basic Science', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biology', 'Caring', 'Catalysis', 'Catalytic Domain', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computing Methodologies', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Databases', 'Disease', 'Disruption', 'Environment', 'Funding', 'Genetic', 'Genetic Variation', 'Goals', 'Hereditary Disease', 'Human Resources', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Spectra', 'Ontology', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phenotype', 'Phosphorylation', 'Positioning Attribute', 'Post-Translational Protein Processing', 'Principal Investigator', 'Productivity', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Score', 'Site', 'Structure', 'Testing', 'Training', 'Ubiquitination', 'Variant', 'Work', 'base', 'cancer classification', 'clinically relevant', 'computer science', 'computerized tools', 'disease phenotype', 'disease-causing mutation', 'experience', 'falls', 'improved', 'innovation', 'novel strategies', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'tool', 'translational medicine']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2008,163321,0.02931166426004237
"Population Genetics Theory    DESCRIPTION (provided by applicant): Four areas of theoretical population genetics will be studied. In the first, we will develop mathematical and statistical framework for studying the evolution of genes that affect how other sets of genes interact with one another. This theory helps in understanding conditions under which the genome can be expected to become modular in its production of phenotypes, as well as when synergy between mutations in different genes should be produced by evolution. We shall study how the pattern of interaction between deleterious mutations evolves as a function of the mutation rate, the recombination rate, and the degree of fitness loss of each mutation. We shall also study buildup of statistical association between genes that influence culturally transmitted traits that are associated either through transmission or through fitness. The second area of study concerns the evolution of pathogens such as influenza. Here we build models to predict the accumulation of mutations during epidemics and pandemics in a way that can assist in guiding vaccination strategies. We will develop algorithms that search for potential recombinants and reassortants among a collection of up to 1000 viral sequences. Here we aim to devise a statistical test to indicate whether identified recombinants or reassortants are spurious or statistically significant. Our recent theory of niche construction will form the basis of studies of how pathogens might evolve in response to human actions that they induce, such as use of antibiotics. The final research area will develop multiple-gene models for sex-linked control of genomic imprinting. These will include cis and trans modifiers of imprinting. Fertility selection as well as sex- specific viabilities will be studied in order to clarify the role of multiple paternities, which has been proposed as a driving force in the evolution of genomic imprinting. Genomic data from mammalian species will be analyzed using tools from statistical learning in order to predict which genes are likely to be imprinted. Correlations between DMA sequence properties and predicted imprinting status based on life history characteristics will also be sought.           n/a",Population Genetics Theory,7457930,R01GM028016,"['Affect', 'Algorithms', 'Alleles', 'Antibiotics', 'Antigens', 'Area', 'Bacteria', 'Bacteriophages', 'Characteristics', 'Class', 'Collection', 'Complex', 'Computers', 'Condition', 'DNA Sequence', 'Data', 'Development', 'Drug Formulations', 'Epidemic', 'Evolution', 'Facility Construction Funding Category', 'Fertility', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomic Imprinting', 'Genomics', 'Haploidy', 'Human', 'Influenza', 'Laboratories', 'Link', 'Machine Learning', 'Mammals', 'Modeling', 'Modification', 'Mutation', 'Numbers', 'Organism', 'Pan Genus', 'Pattern', 'Personal Satisfaction', 'Phenotype', 'Population Genetics', 'Production', 'Property', 'Purpose', 'Rate', 'Recombinants', 'Research', 'Role', 'Specific qualifier value', 'Standards of Weights and Measures', 'Statistically Significant', 'Taxon', 'Testing', 'Time', 'Tweens', 'Vaccination', 'Variant', 'Viral', 'Virus', 'base', 'driving force', 'father role', 'fitness', 'gene function', 'genome sequencing', 'imprint', 'influenza epidemic', 'life history', 'pandemic disease', 'pathogen', 'research study', 'response', 'sex', 'social', 'theories', 'tool', 'trait', 'transmission process', 'vaccination strategy']",NIGMS,STANFORD UNIVERSITY,R01,2008,254996,0.049678420051971116
"A Comprehensive Structural and Dynamic Map of DNA Duplex Ends    DESCRIPTION (provided by applicant): The structure and dynamics of DNA duplex ends can influence numerous enzyme-dependent processes such as transposition of phage Mu, and integration of HIV dsDNA copies into target chromosomal DNA. Despite their critical importance in biology, DNA duplex ends are significantly under-represented in NMR and crystal structure studies, and their dynamic properties have not been measured directly. The long-term goal of this project is to establish a comprehensive dynamic and structural map of DNA duplex ends. This map will be at near angstrom precision and will include all possible combinations of base pairs for the last six positions of the DNA helix (i.e. 46 = 4096 unique sequences). The approach we will use to generate the map couples NMR spectroscopy with an instrument developed in our laboratory for single molecule measurements. This instrument is based on a nanoscale pore formed by the bacterial toxin, ?-hemolysin. When individual DNA hairpins are captured in this pore by an applied electric field, the duplex stem is suspended in the pore vestibule. Preliminary results suggest that low frequency (kHz) current noise during DNA capture is caused by structural changes of the helix terminus. The aim of this R-21 proposal is to determine if the nanopore detector gives unbiased reads of DNA duplex end structure and dynamics in the Hz to MHz range. Specific questions we will address include: 1) To what extent does the pore vestibule and the applied electric field influence DNA dynamics? 2) Are the duplex end kinetics independent of hairpin loop identity and duplex stem length? 3) There is broad consensus that some sequences are unusually rigid (e.g. A tracts) while others are highly flexible (e.g. TATA). Do these sequences cause nanopore current signatures that cluster together as predicted? 4) Can pattern recognition algorithms be used to automate data analysis? We consider this research to be suited for R-21 funding because there is substantial risk that the outcome will be negative, i.e. we may find that the observed current dynamics are only relevant to the limited case of DNA hairpins captured in a nanoscale protein cavity. However, if the research is successful, it will yield a new way to observe DNA dynamics that reports precise kinetic data, and that is amenable to high throughput experiments. These nanopore experiments will be used to direct subsequent NMR experiments and vice versa.         n/a",A Comprehensive Structural and Dynamic Map of DNA Duplex Ends,7447802,R21GM073617,"['Address', 'Algorithms', 'Automated Pattern Recognition', 'Bacterial Toxins', 'Bacteriophage mu', 'Base Pairing', 'Bathing', 'Behavior', 'Biology', 'Caliber', 'Canada', 'Chromosomes, Human, Pair 5', 'Computer software', 'Consensus', 'Couples', 'DNA', 'DNA mapping', 'Data', 'Data Analyses', 'Devices', 'Digestion', 'Enzymes', 'Exonuclease', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'HIV', 'Helix (Snails)', 'Hemolysin', 'Individual', 'Kinetics', 'Laboratories', 'Length', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'NMR Spectroscopy', 'Noise', 'Outcome', 'Output', 'Pattern Recognition', 'Phase', 'Pore Proteins', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Range', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Robotics', 'Roentgen Rays', 'Shapes', 'Structure', 'System', 'Teflon', 'Testing', 'Time', 'Tube', 'Universities', 'Vestibule', 'base', 'detector', 'ear helix', 'electric field', 'improved', 'instrument', 'interest', 'nanopore', 'nanoscale', 'polymerization', 'professor', 'research study', 'single molecule', 'stem', 'two-dimensional']",NIGMS,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2008,100329,-0.02067238691501417
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       Informatic profiling of clinically relevant mutation      Many approaches have been developed to predict whether a mutation associated with a disease is actually causative. In contrast to other approaches to predicting deleterious mutations, our approach, called in silico functional profiling, starts with learning residue-specific protein function and then estimates when it is disrupted. This research will continue our efforts to characterize what the underlying molecular disruption a mutation is causing and thereby improve accuracy of these approaches. We will do this by building a database that links clinical observation with molecular phenotype and using this to develop bioinformatic models of mutation. This is particularly relevant to cancer, since many mutations in cancer are both poorly understood and simply associated with cancer. The hypothesis of this proposal is that computational methods that predict a specific residue function using protein sequence and structure can classify known disease-associated mutations based on their function better than existing computational methods, and less expensively than experimental assays. In short, we will describe each phenotypically annotated mutation as possibly affecting catalysis, protein interactions, posttranslational modification and stability of the protein. The structural environments around disease associated mutations can be characterized using a combination of computational biochemical methods based on first principles of biomolecular structure and function and statistical informatics methods. We will continue this research by implementing the following steps: First, we will build a database of how often mutations in cancer, pharmacogenetics, Mendelian and complex disease are disrupted by phosphorylation, stability, catalysis, protein interaction and other posttranslational modifications. Second, we will build a bioinformatic model of disruption using machine learning methods trained with these and other commonly used features. Finally, we will link these to clinical observation by annotating disease causing mutation with an ontology of diseases and integrate these predictions into databases of mutation. Thus, we will link clinical observation with molecular phenotypes by building a useful database and new models of how mutations cause disease.          n/a",Informatic profiling of clinically relevant mutation,7351411,R01LM009722,"['Acetylation', 'Address', 'Affect', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Basic Science', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Biology', 'Caring', 'Catalysis', 'Catalytic Domain', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computing Methodologies', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Databases', 'Disease', 'Disruption', 'Environment', 'Funding', 'Genetic', 'Genetic Variation', 'Goals', 'Hereditary Disease', 'Human Resources', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Spectra', 'Ontology', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phenotype', 'Phosphorylation', 'Positioning Attribute', 'Post-Translational Protein Processing', 'Principal Investigator', 'Productivity', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Score', 'Site', 'Structure', 'Testing', 'Training', 'Ubiquitination', 'Variant', 'Work', 'base', 'cancer classification', 'clinically relevant', 'computer science', 'computerized tools', 'disease phenotype', 'disease-causing mutation', 'experience', 'falls', 'improved', 'innovation', 'novel strategies', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'tool', 'translational medicine']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2007,329240,0.02931166426004237
"Text Mining Point Mutations for Genetic Diagnosis Array Text mining applications seek to alleviate the problems with identifying, searching, and extracting relevant information from large sets of literature. The goal of this proposal is to create a text mining application to extract protein point mutations from biomedical literature. The developed application will be used to extract point mutations from literature discussing human genetic disorders, and the retrieved database of point mutations used to design a DMA microarray chip for prenatal genetic diagnosis. First, the text mining application will be developed using machine learning and statistical natural language processing techniques. Second, the point mutation mining application will be applied to a large set of literature related to genetic disorders, and the retrieved point mutations deposited in an electronic database. This collection of point mutations will be examined to find polymorphisms in genes that are markers for genetic disorders. These polymorphic positions in the human genome will be gathered and used to design a DMA microarray chip that can genotype tens of thousands of single nucelotide polymorphisms. The microarray chip can be used for prenatal genetic diagnosis purposes to screen for hundreds of genetic disorders. n/a",Text Mining Point Mutations for Genetic Diagnosis Array,7156197,F37LM008883,[' '],NLM,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,F37,2007,45812,0.011304178728498062
"Population Genetics Theory    DESCRIPTION (provided by applicant): Four areas of theoretical population genetics will be studied. In the first, we will develop mathematical and statistical framework for studying the evolution of genes that affect how other sets of genes interact with one another. This theory helps in understanding conditions under which the genome can be expected to become modular in its production of phenotypes, as well as when synergy between mutations in different genes should be produced by evolution. We shall study how the pattern of interaction between deleterious mutations evolves as a function of the mutation rate, the recombination rate, and the degree of fitness loss of each mutation. We shall also study buildup of statistical association between genes that influence culturally transmitted traits that are associated either through transmission or through fitness. The second area of study concerns the evolution of pathogens such as influenza. Here we build models to predict the accumulation of mutations during epidemics and pandemics in a way that can assist in guiding vaccination strategies. We will develop algorithms that search for potential recombinants and reassortants among a collection of up to 1000 viral sequences. Here we aim to devise a statistical test to indicate whether identified recombinants or reassortants are spurious or statistically significant. Our recent theory of niche construction will form the basis of studies of how pathogens might evolve in response to human actions that they induce, such as use of antibiotics. The final research area will develop multiple-gene models for sex-linked control of genomic imprinting. These will include cis and trans modifiers of imprinting. Fertility selection as well as sex- specific viabilities will be studied in order to clarify the role of multiple paternities, which has been proposed as a driving force in the evolution of genomic imprinting. Genomic data from mammalian species will be analyzed using tools from statistical learning in order to predict which genes are likely to be imprinted. Correlations between DMA sequence properties and predicted imprinting status based on life history characteristics will also be sought.           n/a",Population Genetics Theory,7313297,R01GM028016,"['Affect', 'Algorithms', 'Alleles', 'Antibiotics', 'Antigens', 'Area', 'Bacteria', 'Bacteriophages', 'Characteristics', 'Class', 'Collection', 'Complex', 'Computers', 'Condition', 'DNA Sequence', 'Data', 'Development', 'Drug Formulations', 'Epidemic', 'Evolution', 'Facility Construction Funding Category', 'Fertility', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomic Imprinting', 'Genomics', 'Haploidy', 'Human', 'Influenza', 'Laboratories', 'Link', 'Machine Learning', 'Mammals', 'Modeling', 'Modification', 'Mutation', 'Numbers', 'Organism', 'Pan Genus', 'Pattern', 'Personal Satisfaction', 'Phenotype', 'Population Genetics', 'Production', 'Property', 'Purpose', 'Rate', 'Recombinants', 'Research', 'Role', 'Specific qualifier value', 'Standards of Weights and Measures', 'Statistically Significant', 'Taxon', 'Testing', 'Time', 'Tweens', 'Vaccination', 'Variant', 'Viral', 'Virus', 'base', 'driving force', 'father role', 'fitness', 'gene function', 'genome sequencing', 'imprint', 'influenza epidemic', 'life history', 'pandemic disease', 'pathogen', 'research study', 'response', 'sex', 'social', 'theories', 'tool', 'trait', 'transmission process', 'vaccination strategy']",NIGMS,STANFORD UNIVERSITY,R01,2007,258957,0.049678420051971116
"A Comprehensive catalog of human DNasel hypersensitive sites    DESCRIPTION (provided by applicant):   The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNaseI hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNaseI hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5).           n/a",A Comprehensive catalog of human DNasel hypersensitive sites,7410206,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Class', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonuclease I', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Histones', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Modification', 'Molecular', 'Noise', 'Numbers', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Preparation', 'Production', 'Public Domains', 'Range', 'Rate', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Score', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Standards of Weights and Measures', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'density', 'design', 'digital', 'experience', 'functional genomics', 'high throughput screening', 'human tissue', 'in vivo', 'insight', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2007,3114596,-0.008082422158935162
"A Comprehensive Structural and Dynamic Map of DNA Duplex Ends    DESCRIPTION (provided by applicant): The structure and dynamics of DNA duplex ends can influence numerous enzyme-dependent processes such as transposition of phage Mu, and integration of HIV dsDNA copies into target chromosomal DNA. Despite their critical importance in biology, DNA duplex ends are significantly under-represented in NMR and crystal structure studies, and their dynamic properties have not been measured directly. The long-term goal of this project is to establish a comprehensive dynamic and structural map of DNA duplex ends. This map will be at near angstrom precision and will include all possible combinations of base pairs for the last six positions of the DNA helix (i.e. 46 = 4096 unique sequences). The approach we will use to generate the map couples NMR spectroscopy with an instrument developed in our laboratory for single molecule measurements. This instrument is based on a nanoscale pore formed by the bacterial toxin, ?-hemolysin. When individual DNA hairpins are captured in this pore by an applied electric field, the duplex stem is suspended in the pore vestibule. Preliminary results suggest that low frequency (kHz) current noise during DNA capture is caused by structural changes of the helix terminus. The aim of this R-21 proposal is to determine if the nanopore detector gives unbiased reads of DNA duplex end structure and dynamics in the Hz to MHz range. Specific questions we will address include: 1) To what extent does the pore vestibule and the applied electric field influence DNA dynamics? 2) Are the duplex end kinetics independent of hairpin loop identity and duplex stem length? 3) There is broad consensus that some sequences are unusually rigid (e.g. A tracts) while others are highly flexible (e.g. TATA). Do these sequences cause nanopore current signatures that cluster together as predicted? 4) Can pattern recognition algorithms be used to automate data analysis? We consider this research to be suited for R-21 funding because there is substantial risk that the outcome will be negative, i.e. we may find that the observed current dynamics are only relevant to the limited case of DNA hairpins captured in a nanoscale protein cavity. However, if the research is successful, it will yield a new way to observe DNA dynamics that reports precise kinetic data, and that is amenable to high throughput experiments. These nanopore experiments will be used to direct subsequent NMR experiments and vice versa.         n/a",A Comprehensive Structural and Dynamic Map of DNA Duplex Ends,7229898,R21GM073617,"['Address', 'Algorithms', 'Automated Pattern Recognition', 'Bacterial Toxins', 'Bacteriophage mu', 'Base Pairing', 'Bathing', 'Behavior', 'Biology', 'Caliber', 'Canada', 'Chromosomes, Human, Pair 5', 'Computer software', 'Consensus', 'Couples', 'DNA', 'DNA mapping', 'Data', 'Data Analyses', 'Devices', 'Digestion', 'Enzymes', 'Exonuclease', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'HIV', 'Helix (Snails)', 'Hemolysin', 'Individual', 'Kinetics', 'Laboratories', 'Length', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'NMR Spectroscopy', 'Noise', 'Outcome', 'Output', 'Pattern Recognition', 'Phase', 'Pore Proteins', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Range', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Robotics', 'Roentgen Rays', 'Shapes', 'Structure', 'System', 'Teflon', 'Testing', 'Time', 'Tube', 'Universities', 'Vestibule', 'base', 'detector', 'ear helix', 'electric field', 'improved', 'instrument', 'interest', 'nanopore', 'nanoscale', 'polymerization', 'professor', 'research study', 'single molecule', 'stem', 'two-dimensional']",NIGMS,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2007,143598,-0.02067238691501417
"Exon recognition during constitutive pre-mRNA splicing    DESCRIPTION (provided by applicant): The splicing together of exons during the transcription of most eukaryotic pre-mRNA molecules is a fundamental step in the transfer of information from DNA to protein. However, how the splice sites are recognized to initiate this fast and accurate process in not at all clear, since false sequences that resemble real sites outnumber the latter by 1 or 2 orders of magnitude yet are not used. We are searching for the additional information that specifies splice site recognition during pre-mRNA splicing in mammalian cells. In previous work we have used computational analysis to discover that: 1) that exon flanks 50 nt beyond the splice site consensuses can greatly influence splicing and contain sequences that stand out from the background; and 2) there are a large number of specific 8 mers that can act either as exonic splicing enhancers or splicing silencers. We will characterize both of these types of sequences, defining their base requirements, extent, position dependence, and specificity. With regard to the last, we will develop a novel exhaustive survey method that uses massively parallel solid state sequencing to identify every possible 8-mer that can be functional in a particular context, and we will compare this profile in different intronic, exonic and cellular contexts for constitutive and alternatively spliced exons. The flanking sequences fall into 2 distinct classes according to their G+C contents; we will test the idea that the rules governing exon definition differ for the two classes. To simplify the discovery of rules that govern exon definition, we will create designer exons made up of synthetic 8-mer modules we have identified as enhancers, silencers or neutral sequences. The numbers and spacing of these modules will reveal relationships that are hidden in the complexity of natural sequences. Finally, we will continue to use computation, including new machine learning algorithms, to better define intronic elements and to discover interactions between two or more features of a local sequence that define a splice site. We will also develop a Web-based exon-finding program that integrates all the information we have accumulated. Pre-mRNA splicing goes awry in a large proportion or human genetic disease cases. An understanding of the rules that govern the recognition of splice sites should help in the design of therapeutic intervention strategies to reverse such ill effects.                           n/a",Exon recognition during constitutive pre-mRNA splicing,7261326,R01GM072740,[' '],NIGMS,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2007,290853,-0.001770988848961623
"A Comprehensive Structural and Dynamic Map of DNA Duplex Ends    DESCRIPTION (provided by applicant): The structure and dynamics of DNA duplex ends can influence numerous enzyme-dependent processes such as transposition of phage Mu, and integration of HIV dsDNA copies into target chromosomal DNA. Despite their critical importance in biology, DNA duplex ends are significantly under-represented in NMR and crystal structure studies, and their dynamic properties have not been measured directly. The long-term goal of this project is to establish a comprehensive dynamic and structural map of DNA duplex ends. This map will be at near angstrom precision and will include all possible combinations of base pairs for the last six positions of the DNA helix (i.e. 46 = 4096 unique sequences). The approach we will use to generate the map couples NMR spectroscopy with an instrument developed in our laboratory for single molecule measurements. This instrument is based on a nanoscale pore formed by the bacterial toxin, ?-hemolysin. When individual DNA hairpins are captured in this pore by an applied electric field, the duplex stem is suspended in the pore vestibule. Preliminary results suggest that low frequency (kHz) current noise during DNA capture is caused by structural changes of the helix terminus. The aim of this R-21 proposal is to determine if the nanopore detector gives unbiased reads of DNA duplex end structure and dynamics in the Hz to MHz range. Specific questions we will address include: 1) To what extent does the pore vestibule and the applied electric field influence DNA dynamics? 2) Are the duplex end kinetics independent of hairpin loop identity and duplex stem length? 3) There is broad consensus that some sequences are unusually rigid (e.g. A tracts) while others are highly flexible (e.g. TATA). Do these sequences cause nanopore current signatures that cluster together as predicted? 4) Can pattern recognition algorithms be used to automate data analysis? We consider this research to be suited for R-21 funding because there is substantial risk that the outcome will be negative, i.e. we may find that the observed current dynamics are only relevant to the limited case of DNA hairpins captured in a nanoscale protein cavity. However, if the research is successful, it will yield a new way to observe DNA dynamics that reports precise kinetic data, and that is amenable to high throughput experiments. These nanopore experiments will be used to direct subsequent NMR experiments and vice versa.         n/a",A Comprehensive Structural and Dynamic Map of DNA Duplex Ends,7024252,R21GM073617,"['DNA', 'artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment', 'chemical kinetics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'electric field', 'method development', 'molecular dynamics', 'nanotechnology', 'nuclear magnetic resonance spectroscopy', 'nucleic acid structure', 'nucleobase', 'protein structure', 'technology /technique development']",NIGMS,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2006,172838,-0.02067238691501417
"Exon recognition during constitutive pre-mRNA splicing    DESCRIPTION (provided by applicant): The splicing together of exons during the transcription of most eukaryotic pre-mRNA molecules is a fundamental step in the transfer of information from DNA to protein. However, how the splice sites are recognized to initiate this fast and accurate process in not at all clear, since false sequences that resemble real sites outnumber the latter by 1 or 2 orders of magnitude yet are not used. We are searching for the additional information that specifies splice site recognition during pre-mRNA splicing in mammalian cells. In previous work we have used computational analysis to discover that: 1) that exon flanks 50 nt beyond the splice site consensuses can greatly influence splicing and contain sequences that stand out from the background; and 2) there are a large number of specific 8 mers that can act either as exonic splicing enhancers or splicing silencers. We will characterize both of these types of sequences, defining their base requirements, extent, position dependence, and specificity. With regard to the last, we will develop a novel exhaustive survey method that uses massively parallel solid state sequencing to identify every possible 8-mer that can be functional in a particular context, and we will compare this profile in different intronic, exonic and cellular contexts for constitutive and alternatively spliced exons. The flanking sequences fall into 2 distinct classes according to their G+C contents; we will test the idea that the rules governing exon definition differ for the two classes. To simplify the discovery of rules that govern exon definition, we will create designer exons made up of synthetic 8-mer modules we have identified as enhancers, silencers or neutral sequences. The numbers and spacing of these modules will reveal relationships that are hidden in the complexity of natural sequences. Finally, we will continue to use computation, including new machine learning algorithms, to better define intronic elements and to discover interactions between two or more features of a local sequence that define a splice site. We will also develop a Web-based exon-finding program that integrates all the information we have accumulated. Pre-mRNA splicing goes awry in a large proportion or human genetic disease cases. An understanding of the rules that govern the recognition of splice sites should help in the design of therapeutic intervention strategies to reverse such ill effects.                           n/a",Exon recognition during constitutive pre-mRNA splicing,7105514,R01GM072740,"['Internet', 'RNA splicing', 'binding sites', 'computational biology', 'computer system design /evaluation', 'genetic regulation', 'messenger RNA', 'molecular biology information system', 'molecular shape', 'nucleic acid sequence', 'polymerase chain reaction', 'serial analysis of gene expression', 'statistics /biometry']",NIGMS,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2006,298611,-0.001770988848961623
"Text Mining Point Mutations for Genetic Diagnosis Array DESCRIPTION:    Text mining applications seek to alleviate the problems with identifying, searching, and extracting relevant information from large sets of literature. The goal of this proposal is to create a text mining application to extract protein point mutations from biomedical literature. The developed application will be used to extract point mutations from literature discussing human genetic disorders, and the retrieved database of point mutations used to design a DNA microarray chip for prenatal genetic diagnosis. First, the text mining application will be developed using machine learning and statistical natural language processing techniques. Second, the point mutation mining application will be applied to a large set of literature related to genetic disorders, and the retrieved point mutations deposited in an electronic database. This collection of point mutations will be examined to find polymorphisms in genes that are markers for genetic disorders. These polymorphic positions in the human genome will be gathered and used to design a DMA microarray chip that can genotype tens of thousands of single nucleotide polymorphisms. The microarray chip can be used for prenatal genetic diagnosis purposes to screen for hundreds of genetic disorders. n/a",Text Mining Point Mutations for Genetic Diagnosis Array,6993320,F37LM008883,"['biotechnology', 'information retrieval', 'microarray technology', 'molecular biology information system', 'point mutation', 'predoctoral investigator', 'technology /technique development']",NLM,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,F37,2005,45812,0.013928322919707622
"Shifting Conceptions of Human Identity DESCRIPTION (provided by applicant):  . One of the most important questions raised by the ongoing achievements of the Human Genome Project is how this new biological knowledge - and the powers it confers - will affect our identity and self-understanding as human beings. This book project focuses on one key aspect of this complex issue: exploring the extent to which human identity can be reconciled with deliberate design or partial redesign. The author proposes to shed new light on this question by comparing the debates surrounding two areas of scientific innovation that are not normally associated with each other, but that are in fact deeply related: the enterprise of human genetic intervention and the enterprise of building intelligent machines. Both these enterprises entail ""pushing the limits"" of traditional concepts of what it means to be human; and both ultimately confront their makers with the same core ""family"" of questions: What are the defining features of human personhood? To what extent can those features be modified or extended, before human personhood begins to break down? Can some (or all) of those features find embodiment in an entity other than a human being? These kinds of questions are no longer the sole province of science fiction writers, but have been taken up with increasing seriousness by mainstream scientists and technologists, as well as by a wide array of ""science watchers"" in academia, legislative circles, and the news media.   . Through documentary research and interviews, this project aims to deepen our understanding of the history and sociology of the debates surrounding these powerful new technologies, electro-mechanical and biological, that are perceived as destabilizing human identity. The intended audience for the book is a broad one: scientists and technological practitioners interested in the social and cultural reception of their research; legislators and other policymakers with a stake in the governance of science; general educated readers who are concerned about the role of science and technology in shaping our collective future. n/a",Shifting Conceptions of Human Identity,6915830,R03HG003298,"['adult human (21+)', 'artificial intelligence', 'behavioral /social science research tag', 'biotechnology', 'books', 'clinical research', 'ethics', 'genetic manipulation', 'history of life science', 'human subject', 'identity', 'interview', 'robotics', 'self concept', 'sociology /anthropology']",NHGRI,VANDERBILT UNIVERSITY,R03,2005,75833,-0.010346739949063889
"BioHDF - Open Binary File Standards for Bioinformatics DESCRIPTION (provided by applicant):  Geospiza Inc. and the National Center for Supercomputing Applications (NCSA) are creating a standards based software framework around NCSA's Heirarchical Data Format (HDF5). The envisioned framework will integrate algorithms important in DNA and protein sequence analysis to create scalable high throughput software systems which will be accessed using new graphical user interfaces (GUIs) to provide researchers with new views of their data to finish sequencing projects in large-scale genome sequencing, microbial genome sequencing, viral epidemiology, polymorphism detection, phylogenetic analysis, multi-locus sequence typing, confirmatory sequencing, and EST analysis.    In our vision, algorithms will be either integrated into the system to directly read and write from HDF5 project files, or they will communicate with project files via filter programs that produce standardized XML formatted data. Through this model, a scalable solution will support different applications of DNA sequencing, fulfilling the many needs and requirements expressed by the medical research community now and into the future. As the first step in this process we will, define requirements for editing and versioning data in DNA sequencing, research and propose data models for the computational phases of DNA sequencing and annotating DNA sequence data using existing standards, create a prototype application for DNA sequencing based SNP discovery, and engage the bioinformatics community for BioHDF adoption.       In the past ten years the cost of sequencing DNA has dropped over 1000 fold and the amount of raw sequence data, entering our national repositories is doubling every 12 months. DNA sequencing is fundamental to biological research activities such as genomics, systems biology, and clinical medicine. Proposals are being sought to decrease sequencing costs by two orders of magnitude through technology refinements with an ultimate vision of developing technology to sequence human genome equivalents for $1000 each. The amount of data that will be produced through these endeavors is unimaginable. However, the $1,000 genome will not advance medical research unless we integrate all phases of the DNA sequencing process and treat the creation, management, finishing, analysis, and sharing of the data as common goals. n/a",BioHDF - Open Binary File Standards for Bioinformatics,6992995,R41HG003792,"['DNA', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'functional /structural genomics', 'genetic mapping', 'genetic polymorphism', 'mathematics', 'molecular biology information system', 'nucleic acid sequence', 'single nucleotide polymorphism', 'virus genetics']",NHGRI,"GEOSPIZA, INC.",R41,2005,142775,0.04407858083697489
"Exon recognition during constitutive pre-mRNA splicing    DESCRIPTION (provided by applicant): The splicing together of exons during the transcription of most eukaryotic pre-mRNA molecules is a fundamental step in the transfer of information from DNA to protein. However, how the splice sites are recognized to initiate this fast and accurate process in not at all clear, since false sequences that resemble real sites outnumber the latter by 1 or 2 orders of magnitude yet are not used. We are searching for the additional information that specifies splice site recognition during pre-mRNA splicing in mammalian cells. In previous work we have used computational analysis to discover that: 1) that exon flanks 50 nt beyond the splice site consensuses can greatly influence splicing and contain sequences that stand out from the background; and 2) there are a large number of specific 8 mers that can act either as exonic splicing enhancers or splicing silencers. We will characterize both of these types of sequences, defining their base requirements, extent, position dependence, and specificity. With regard to the last, we will develop a novel exhaustive survey method that uses massively parallel solid state sequencing to identify every possible 8-mer that can be functional in a particular context, and we will compare this profile in different intronic, exonic and cellular contexts for constitutive and alternatively spliced exons. The flanking sequences fall into 2 distinct classes according to their G+C contents; we will test the idea that the rules governing exon definition differ for the two classes. To simplify the discovery of rules that govern exon definition, we will create designer exons made up of synthetic 8-mer modules we have identified as enhancers, silencers or neutral sequences. The numbers and spacing of these modules will reveal relationships that are hidden in the complexity of natural sequences. Finally, we will continue to use computation, including new machine learning algorithms, to better define intronic elements and to discover interactions between two or more features of a local sequence that define a splice site. We will also develop a Web-based exon-finding program that integrates all the information we have accumulated. Pre-mRNA splicing goes awry in a large proportion or human genetic disease cases. An understanding of the rules that govern the recognition of splice sites should help in the design of therapeutic intervention strategies to reverse such ill effects.                           n/a",Exon recognition during constitutive pre-mRNA splicing,6966860,R01GM072740,"['Internet', 'RNA splicing', 'binding sites', 'computational biology', 'computer system design /evaluation', 'genetic regulation', 'messenger RNA', 'molecular biology information system', 'molecular shape', 'nucleic acid sequence', 'polymerase chain reaction', 'serial analysis of gene expression', 'statistics /biometry']",NIGMS,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2005,304845,-0.001770988848961623
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6912979,R44HG002244,"['artificial intelligence', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'data management', 'genotype', 'informatics', 'mathematical model', 'nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2004,191986,0.03335286620175336
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6721300,R37GM030998,"['DNA', 'artificial intelligence', 'biochemical evolution', 'computational neuroscience', 'computer assisted sequence analysis', 'computer simulation', 'gene frequency', 'genetic models', 'mathematical model', 'method development', 'model design /development', 'natural selections', 'nucleic acid sequence', 'species difference', 'statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2004,161792,0.018319848642341145
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6622259,R44HG002244,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' genotype', ' informatics', ' mathematical model', ' nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2003,560392,0.03335286620175336
"Development of Bioinformatic Tools for Virtual Cloning    DESCRIPTION (provided by applicant): The ability to delineate (at least in theory) all the proteins encoded in the human genome and all of those encoded by the genomes of major human parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease.  However, the vast increase in biological knowledge that has resulted from the last decade of genomic DNA sequencing has led us to a a crisis in bioinformatics.  This crisis is two-fold: analysis of data and planning of experiments.  Most of the scientific resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology.  All modern experimental molecular biology (and, increasingly, structural biology) depends upon the availability of plasmid clones to address specific scientific questions.  Although software facilitating DNA manipulations exists, few programs advise users of optimal strategies and none automate the process of clone generation. Genomics initiatives identify proteins at the genome level and demand the generation of hundreds of expression clones for recombinant protein production in exogenous hosts such as E. coli.  Establishment of libraries of expression clones requires automation and optimization as well as effective means of data storage, archiving, annotation and query.  To address these needs, as well as to facilitate routine DNA manipulations in virtually any molecular biology laboratory, we propose (1) to test and build a task centered virtual cloning expert system that serves as a knowledge base for DNA manipulations, and (2) to test and build an information automaton for the construction of expression clone libraries in support of structural genomics initiatives and other high throughput experiments.         n/a",Development of Bioinformatic Tools for Virtual Cloning,6583437,R43GM067279,"['artificial intelligence', ' biomedical automation', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' expression cloning', ' gene expression', ' genetic library', ' genetic manipulation', ' informatics', ' molecular biology information system', ' transfection /expression vector']",NIGMS,"VIRMATICS, LLC",R43,2003,100000,-0.006525758928708032
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6635877,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2003,161792,0.018319848642341145
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6444292,R44HG002244,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' genotype', ' informatics', ' mathematical model', ' nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2002,531259,0.03335286620175336
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6519073,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2002,161792,0.018319848642341145
"GENE PREDICTION: MARKOV MODELS AND COMPLEMENTARY METHODS   DESCRIPTION (Adapted from the Investigator's Abstract): The goal of the project                                               is to build more accurate and powerful DNA sequence interpretation algorithms        utilizing the positive experience and ideas of previously proven GeneMark and        GenMark.hmm methods.                                                                                                                                                      We plan to improve the quality of gene finding in prokaryotic genomes in terms       of reliable and accurate prediction of gene starts and detection of frameshift                                                   sequencing errors. We also plan to develop a machine-learning iterative              procedure for deriving all necessary models for precise gene                         prediction/annotation from totally anonymous prokaryotic sequences.                                                                                                       For eukaryotic species, we will improve the accuracy of the ab initio method         GeneMark.hmm by building more accurate models for splice sites and                   initiation/termination sites, and we will address the problem of accurately          finding intergenic regions with polyadenilation sites and promoters.                                                                                                      On the basis of GeneMark.hmm, we plan to develop an integrated gene finding          approach by ""projecting"" pieces of diverse extrinsic evidence into DNA level,        the translating them into DNA patterns and combining these patterns with             statistical patterns of DNA coding and non-coding sequence within a generalized      HMM model. The most intriguing sources of this additional information are            evolutionary conserved regions in DNA sequences of closely related species,          functional motifs in protein sequences and protein sequence patterns reflecting      three dimensional structural motifs.                                                                                                                                      All these newly developed methods, as well as several others mentioned in the        proposal, will deal with anonymous DNA for which interpretation is increasingly      needed in the post-genomic era.                                                                                                                                           n/a",GENE PREDICTION: MARKOV MODELS AND COMPLEMENTARY METHODS,6536458,R01HG000783,"['DNA', ' RNA splicing', ' computer assisted sequence analysis', ' computer program /software', ' computer system design /evaluation', ' eukaryote', ' frameshift mutation', ' genetic mapping', ' introns', ' mathematical model', ' model design /development', ' nucleic acid sequence', ' protein sequence', ' statistics /biometry']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2002,318645,0.004457140563123694
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6385455,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2001,161792,0.018319848642341145
"GENE PREDICTION: MARKOV MODELS AND COMPLEMENTARY METHODS   DESCRIPTION (Adapted from the Investigator's Abstract): The goal of the project                                               is to build more accurate and powerful DNA sequence interpretation algorithms        utilizing the positive experience and ideas of previously proven GeneMark and        GenMark.hmm methods.                                                                                                                                                      We plan to improve the quality of gene finding in prokaryotic genomes in terms       of reliable and accurate prediction of gene starts and detection of frameshift                                                   sequencing errors. We also plan to develop a machine-learning iterative              procedure for deriving all necessary models for precise gene                         prediction/annotation from totally anonymous prokaryotic sequences.                                                                                                       For eukaryotic species, we will improve the accuracy of the ab initio method         GeneMark.hmm by building more accurate models for splice sites and                   initiation/termination sites, and we will address the problem of accurately          finding intergenic regions with polyadenilation sites and promoters.                                                                                                      On the basis of GeneMark.hmm, we plan to develop an integrated gene finding          approach by ""projecting"" pieces of diverse extrinsic evidence into DNA level,        the translating them into DNA patterns and combining these patterns with             statistical patterns of DNA coding and non-coding sequence within a generalized      HMM model. The most intriguing sources of this additional information are            evolutionary conserved regions in DNA sequences of closely related species,          functional motifs in protein sequences and protein sequence patterns reflecting      three dimensional structural motifs.                                                                                                                                      All these newly developed methods, as well as several others mentioned in the        proposal, will deal with anonymous DNA for which interpretation is increasingly      needed in the post-genomic era.                                                                                                                                           n/a",GENE PREDICTION: MARKOV MODELS AND COMPLEMENTARY METHODS,6388304,R01HG000783,"['DNA', ' RNA splicing', ' computer assisted sequence analysis', ' computer program /software', ' computer system design /evaluation', ' eukaryote', ' frameshift mutation', ' genetic mapping', ' introns', ' mathematical model', ' model design /development', ' nucleic acid sequence', ' protein sequence', ' statistics /biometry']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2001,318645,0.004457140563123694
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6131906,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2000,152928,0.018319848642341145
"GENE PREDICTION--MARKOV MODELS AND COMPLEMENTARY METHODS   DESCRIPTION (Adapted from the Investigator's Abstract): The goal of the project                                               is to build more accurate and powerful DNA sequence interpretation algorithms        utilizing the positive experience and ideas of previously proven GeneMark and        GenMark.hmm methods.                                                                                                                                                      We plan to improve the quality of gene finding in prokaryotic genomes in terms       of reliable and accurate prediction of gene starts and detection of frameshift                                                   sequencing errors. We also plan to develop a machine-learning iterative              procedure for deriving all necessary models for precise gene                         prediction/annotation from totally anonymous prokaryotic sequences.                                                                                                       For eukaryotic species, we will improve the accuracy of the ab initio method         GeneMark.hmm by building more accurate models for splice sites and                   initiation/termination sites, and we will address the problem of accurately          finding intergenic regions with polyadenilation sites and promoters.                                                                                                      On the basis of GeneMark.hmm, we plan to develop an integrated gene finding          approach by ""projecting"" pieces of diverse extrinsic evidence into DNA level,        the translating them into DNA patterns and combining these patterns with             statistical patterns of DNA coding and non-coding sequence within a generalized      HMM model. The most intriguing sources of this additional information are            evolutionary conserved regions in DNA sequences of closely related species,          functional motifs in protein sequences and protein sequence patterns reflecting      three dimensional structural motifs.                                                                                                                                      All these newly developed methods, as well as several others mentioned in the        proposal, will deal with anonymous DNA for which interpretation is increasingly      needed in the post-genomic era.                                                                                                                                           n/a",GENE PREDICTION--MARKOV MODELS AND COMPLEMENTARY METHODS,6286238,R01HG000783,"['DNA', ' RNA splicing', ' computer assisted sequence analysis', ' computer program /software', ' computer system design /evaluation', ' eukaryote', ' frameshift mutation', ' genetic mapping', ' introns', ' mathematical model', ' model design /development', ' nucleic acid sequence', ' protein sequence', ' statistics /biometry']",NHGRI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2000,414664,0.004457140563123694
"COMPUTER BASED SEQUENCE ANALYSIS AND RNA VIRUS EVOLUTION The goal of the proposed research is the analysis of biological sequence         data to address the molecular mechanisms of evolution and the origin(s)          of all viruses and related genetic elements. Phylogenetic trees will             provide a framework for the mapping of cell and tissue tropism,                  pathogenicity and virulence, modes of transmission and geographical              distributions, and many other higher order characteristics of viruses.           The specific aims of proposed analytical studies are: 1) determining             functionally equivalent networks and frequency of exchange among and             between retroid elements, and their potential cellular homologues,               including new studies on 300 retroviral env proteins; 2) inferring               functionally important regions of all proteins of paramyxo-, rhabdo- and         filoviruses, (with privileged access to new Ebola sequences), and Borna          Disease virus, (including potential BDV sequences from schizophrenic             patients); and 3) the analysis of the dUTPase gene, as a model system,           to address issues relevant to the structure, function and evolution of           duplicated sequences, and potential horizontal transfer among and between        host and viral genomes. The specific aims of the technical studies are:          1) evaluation of stochastic production model approaches for generation           of multiple alignments, detection of recombination, and calculation of           evolutionary distances; and 2) development and testing of new and                existing methods for historical reconstruction of functionally equivalent        networks.                                                                                                                                                         RNA viruses (e.g. HIV, or Ebola) are the major causative agents of human,        animal and plant viral diseases world wide. The heterogeneous nature of          RNA populations makes it difficult to develop effective, anti-viral              agents. The sequence database is now large enough to conduct comparative         studies on natural variants versus chemotheraputically induced mutants           for several retroviral proteins. This model study will provide new               information on the nature of selected mutations which will be useful in          future anti-viral drug development.                                                                                                                               Computational analysis of primary sequence data is an area of intense            interest in biology, mathematics, statistics and systems science. In the         last few years new approaches to problem solving and classification, such        as machine learning, neural networks, genetic algorithms, and stochastic         production models or, ""intelligent systems"" as they are referred to              collectively, have become available. Unfortunately most biologists are           unaware of these developments. Application of these methods to real data         remains unexplored. The proposed studies will go a long way in rectifying        this gap in technological utilization. These studies will continue to            define important evolutionary relationships and events, provide                  biologically informative sequence relationships for bench-marking new            software, and contribute new information relevant to the structure and           function of viral proteins suggesting new directions in laboratory               experimentation. Strategies and techniques developed for the analysis of         highly divergent genomes can also be applied to the study of the wealth          of sequence information generated under the auspices of the Human Genome         Project.                                                                          n/a",COMPUTER BASED SEQUENCE ANALYSIS AND RNA VIRUS EVOLUTION,6163865,R01AI028309,"['DNA replication', ' Mononegavirales', ' RNA biosynthesis', ' biochemical evolution', ' computer assisted sequence analysis', ' computer program /software', ' nucleic acid sequence', ' virus genetics', ' virus protein']",NIAID,MONTANA STATE UNIVERSITY (BOZEMAN),R01,2000,225156,-0.013195766433269567
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,10020995,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2020,287504,0.004113719231277665
"DNA 3.0: Developing novel enzymes for DNA synthesis with deep learning and combinatorial genetics Project Summary/Abstract  DNA synthesis has played a key role in the biotechnology revolution. The ready availability of synthetic DNA oligonucleotides and of genes assembled from them, has been invaluable for elucidating and unlocking biological function and enabling the new field of synthetic biology which can create novel cells, enzymes, therapeutics, diagnostics and other reagents of commercial value. Despite this impact, DNA synthesis uses chemical strategies developed over 30 years ago which are costly and limited to molecules of 200 nucleotides or less in length.  Next-generation enzymatic DNA synthesis technologies are being explored that use template- independent DNA polymerases (TIDPs) for controlled addition of nucleotides to a growing DNA strand. Although advances have been reported recently, enzymatic DNA synthesis is still limited by the low efficiency of available TIDPs, and specifically by the relative inability of these polymerases to incorporate 3'-blocked nucleotides.  In this Phase I Small Business Innovation Research (SBIR) project, Primordial Genetics Inc, a synthetic biology company with differentiated combinatorial genetic technology, and Denovium Inc., an artificial intelligence company pioneering novel Al methods for genetic discovery, are joining forces to develop novel and highly efficient TIDPs for enzymatic DNA synthesis in vitro.  Denovium will use their computational capabilities based on machine learning algorithms to discover novel TIDPs with the desired activities from proprietary and public databases. Denovium will also perform proprietary artificial intelligence (AI) scans to determine the functional impact of all possible mutations on the selected TIDPs. Primordial Genetics will synthesize and express the resulting collection of sequences, and test them in vitro to identify the most active enzymes. The best 2 enzymes will be diversified using Primordial Genetics' proprietary Function Generator technology and other randomized diversification methods. Populations of genes encoding enzyme variants will be screened with ultra-high-throughput screens to identify the most active enzymes. The dataset resulting from this work will be used to train Denovium's sequence prediction algorithm to accelerate further enzyme improvements in Phase II.  The proposed work is a feasibility study for isolating and developing novel enzymes suitable for enzymatic DNA synthesis, and also for creating a pipeline of enzyme optimization tools. The enzymes discovered and in this work will be directly useful for enzymatic DNA synthesis applications, and can be licensed or sold to leading DNA and gene manufaturers. Project Narrative The principal aim of this project is to develop novel and improved DNA polymerases for the industrial synthesis of DNA, which is currently performed by synthetic chemical methods and represents one of the cornerstone technologies of the biotechnology industry. To overcome limitations of the current chemical technology in cost, efficiency and the length of DNA molecules that can be synthesized, there have been widespread attempts to develop specific DNA polymerases as efficient molecular machines for synthesizing DNA. This project will develop novel and more efficient polymerases than are currently available, which will impact the diagnosis, prevention and treatment of human diseases such as cancer, heart disease, HIV and genetic diseases such as cystic fibrosis.",DNA 3.0: Developing novel enzymes for DNA synthesis with deep learning and combinatorial genetics,10010243,R43HG010995,"['Artificial Intelligence', 'Bioinformatics', 'Biological', 'Biological Process', 'Biotechnology', 'Capital', 'Cells', 'Chemicals', 'Chemistry', 'Collection', 'Computing Methodologies', 'Cost efficiency', 'Cystic Fibrosis', 'DNA', 'DNA Nucleotidylexotransferase', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Enzymes', 'Equipment', 'Evolution', 'Feasibility Studies', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'HIV', 'Heart Diseases', 'In Vitro', 'Industrialization', 'Industry', 'Length', 'Libraries', 'Licensing', 'Malignant Neoplasms', 'Methods', 'Microbe', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Machines', 'Mutation', 'Nucleotides', 'Oligonucleotides', 'Performance', 'Phase', 'Play', 'Polymerase', 'Population', 'Prevention', 'Process', 'Proteins', 'Randomized', 'Reagent', 'Reporting', 'Research Project Grants', 'Scanning', 'Single-Stranded DNA', 'Small Business Innovation Research Grant', 'Technology', 'Testing', 'Therapeutic', 'TimeLine', 'Training', 'Variant', 'Work', 'base', 'combinatorial', 'cost', 'deep learning', 'genetic technology', 'high throughput screening', 'human disease', 'improved', 'in vitro testing', 'machine learning algorithm', 'model development', 'next generation', 'novel', 'phosphoramidite', 'prediction algorithm', 'predictive test', 'research and development', 'synthetic biology', 'synthetic construct', 'tool']",NHGRI,"PRIMORDIAL GENETICS, INC",R43,2020,374524,-0.03449702631346451
"Pattern Identification in Sequence Activity Data Explaining the persistence of L1 retrotransposons during mammalian evolution is a major issue as their replication process generated as much as 50% of some mammalian genomes and they are active in many modern species including humans. All vertebrate L1 families encode an essential coiled-coil domain-containing protein and the coincidence of coiled coil remodeling with emerging novel L1 families, suggested that adaptative change in the coiled coil ensures L1 survival. In primates,  extensive coiled coil amino acid substitutions occurred 30 - 10 Myr ago during emergence of the now extinct L1Pa7  L1Pa3 families, and understanding its basis would advance in our understanding of L1/host interaction. Theoretical and experimental studies have shown that rather than evolving stepwise through discrete adaptive states, evolutionary change can also be achieved by sampling related networks of biological sequences. This evolutionary scenario depends on genetic robustness, i.e., retention of function despite substantial amino acid substitutions, referred to as cryptic genetic variation revealed only in response to epistatic changes elsewhere in the molecule. Here we experimentally demonstrate both genetic robustness of the coiled coil and its extreme sensitivity to epistatic changes. L1Pa7-L1Pa3 families harbor coexisting, distinct coiled coil regimens and some persisted over several generations of L1 families. Our identification of the sequence context for both positive and negative epistatic substitutions is consistent with the concept that enlarged functional coiled coil sequence space would be beneficial by buffering coiled coil function against adventitious inactivating epistatic substitutions, a known threat to coiled coil function.   Classification is one of the ur-problems of machine learning. There is no classification algorithm that is optimal for all datasets, leading to a plethora of choices for the practicing scientist. In general, more sophisticated algorithms tend to have more hyper-parameters designed to allow tuning for specific datasets, improving performance but requiring exponentially more computational resources. Two central issues for biomedical or biological classification are: (1) Datasets can have many predictors measured but relatively few instances to determine the relationship between predictor values and the phenotypic separation that we need to predict. The use of sparse regressors is then imperative with concomitant hyper-parameter tuning requirements for predictor pruning.  (2) Outliers lead to increases in coefficients of variation in performance measures when algorithms are trained on different subsets of data. We adapted Expectation Reflection (ER), a multiplicative optimization method that is particularly suited to the limit of small numbers of instances relative to the number of predictors, with a stable variant of Least Absolute Deviation (LAD), to solve both problems with the introduction of only one hyper-parameter. We compared k-Nearest Neighbors, Naive Bayes (NB), Decision Trees, Support Vector Machines, Multi-layer Perceptrons, Logistic Regression, Extreme Gradient Boosting (XGB), Random Forests and ER on 30 different (largely) biological/biomedical datasets on five different performance metrics (Accuracy, ROC-Area Under the Curve, Precision, Recall and F1-score). We found that ER  had the best performance on every performance metric for more datasets than any other method, except for Recall for which XGB was best on 13 datasets and ER and NB were best on 12 each, and F1-score for which XGB and ER were tied with 15 datasets. Even for Recall, ER had the highest mean Recall over all datasets. ER had the least or second-least mean coefficient of variation across all 30 datasets for all five metrics. To conclude, note that XGB requires four hyper-parameters while ER has just one so computation time is lopsided in favor of ER, even comparing an implementation of ER written in garden-variety NumPy with the specialized code of the xgboost library. n/a",Pattern Identification in Sequence Activity Data,10253756,ZIADK075091,"['Algorithms', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Area Under Curve', 'Bayesian Analysis', 'Biological', 'Biological Assay', 'Biology', 'Biophysics', 'Buffers', 'Calculi', 'Classification', 'Code', 'Coiled-Coil Domain', 'Coupling', 'Data', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Trees', 'Development', 'Digit structure', 'Ensure', 'Evolution', 'Face', 'Family', 'Gardenal', 'Generations', 'Genetic', 'Genetic Variation', 'Graph', 'Growth', 'Human', 'Image', 'Information Sciences', 'Lead', 'Libraries', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Phenotype', 'Predictive Value', 'Primates', 'Probability', 'Problem Solving', 'Proteins', 'Regimen', 'Replication-Associated Process', 'Reporter', 'Retrotransposon', 'Sampling', 'Science', 'Scientist', 'Sequence Alignment', 'Structure', 'System', 'Techniques', 'Theoretical Studies', 'Time', 'Transcription Initiation Site', 'Variant', 'Work', 'algorithm training', 'classification algorithm', 'combinatorial', 'commensal bacteria', 'computing resources', 'design', 'dynamic system', 'expectation', 'experimental study', 'genome wide association study', 'genome-wide', 'heuristics', 'improved', 'insight', 'large datasets', 'large scale data', 'mammalian genome', 'multilayer perceptron', 'novel', 'protein structure', 'quantum field theory', 'random forest', 'real world application', 'reconstruction', 'response', 'support vector machine']",NIDDK,NATIONAL INSTITUTE OF DIABETES AND DIGESTIVE AND KIDNEY DISEASES,ZIA,2020,376484,-0.0046288666410110564
"Development of a joint machine learning/de novo assembly system for resolving viral quasispecies PROJECT SUMMARY Viral hepatitis from hepatitis B (HBV) establishes chronic infections in >250M people worldwide; chronicity is on the rise, and approximately one-third of the world’s population (2 billion) has serologic evidence of exposure. HBV coinfection with HCV and HIV is a hidden consequence of the substance use disorder epidemic. Viral populations have extremely high sequence diversity and rapidly evolve, which explains the vaccine failure rates and viral resistance to existing therapies and makes discovering lasting therapies extremely challenging. Next Generation Sequencing (NGS) is the method of choice to assess the intra-host virus population, termed a “quasispecies”. While a large set of short DNA sequencing reads are acquired that represent the virions in the quasispecies, computational technologies are limited in their analysis capabilities, resulting in particularly low resolution of complex HBV genomic structures. Another challenge is assembling NGS reads representing short fragment of the host genome into full strains (haplotypes) without knowledge of their true occurrence in the samples. To meet these challenges, GATACA is developing pathogen-specific bioinformatics software, GAT-ML (GATACA Assembly Tool – machine learning [ML]) to support treatment discovery and improve infection control. Its specifically designed algorithm utilizes novel ML methodologies adapted and modified for assisting genome assembly that will allow GAT-ML to reconstruct complete viral haplotypes and populations by learning the ‘language’ of the sequences. Tailored initially for HBV samples, GAT and its new ML system will be integrated for feasibility testing in this Phase I with the following Specific Aims: 1. Specific Aim 1. Build a joint learning system. Train and test natural language processing (NLP) methods on HBV genetic variation. 2. Specific Aim 2. Implement and test the machine learning methods in GAT (GAT-ML). We anticipate a working tool for characterizing HBV haplotypes, validated with multi-sourced datasets, and extensive testing and benchmarking of offline and integrated methods. The proposed project will develop and increase the capabilities of our novel computational tool, GAT, to help researchers identify the full spectrum of genetic features of a viral population—such as emergence and persistence of resistance or baseline polymorphisms regardless of their frequencies—and translate these findings to the development of new or improved antiviral drugs and other applications requiring high analytic sensitivity. GAT will particularly benefit researchers working in preclinical stages of drug development who require rapid, sensitive, and reliable results to inform decisions about which targets to advance to clinical trial testing.",Development of a joint machine learning/de novo assembly system for resolving viral quasispecies,10011686,R43AI152894,"['Adoption', 'Algorithm Design', 'Algorithms', 'Antiviral Agents', 'Benchmarking', 'Bioinformatics', 'Chronic', 'Chronic Hepatitis', 'Classification', 'Clinical Trials', 'Complex', 'Computer software', 'DNA Structure', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Dimensions', 'Epidemic', 'Failure', 'Frequencies', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'HIV', 'HIV/HCV', 'Haplotypes', 'Healthcare', 'Hepatitis B', 'Hepatitis B Virus', 'Infection Control', 'Joints', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Link', 'Liver diseases', 'Machine Learning', 'Metagenomics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Natural Language Processing', 'Outcome', 'Pattern', 'Performance', 'Phase', 'Population', 'Population Analysis', 'Privatization', 'Research Personnel', 'Resistance', 'Resolution', 'Sampling', 'Semantics', 'Serological', 'Serotyping', 'Source', 'Speed', 'Substance Use Disorder', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Trust', 'Vaccines', 'Validation', 'Variant', 'Viral', 'Viral hepatitis', 'Virion', 'Virus', 'base', 'chronic infection', 'co-infection', 'commercialization', 'computerized tools', 'contig', 'design', 'drug development', 'improved', 'insertion/deletion mutation', 'machine learning algorithm', 'machine learning method', 'multiple data sources', 'neural network', 'next generation sequencing', 'novel', 'pathogen', 'pre-clinical', 'structural genomics', 'syntax', 'tool', 'viral resistance']",NIAID,"GATACA, LLC",R43,2020,267225,-0.008941608461540155
"Identifying non-coding drivers of cancer After compiling and annotating publicly available, single nucleotide variants in Lung cancer, we quantify the effect of non-coding mutations using CAPE, a machine learning approach that estimates the probability of a mutation deactivating transcription factor (TF) binding. When we compare enhancer mutations with coding region mutations, we do not see significant differences between the scores. Further, when we examine if there is a correlation between high magnitude CAPE scores and changes in gene expression between normal and cancer tissue contexts, we again do not see any significant correlation. The results suggest that lung enhancers do not exhibit significantly higher deleterious effects when we use CAPE as a method for quantifying mutational consequences. We are considering alternative approaches and additional datasets to test our hypotheses. With regards to our sub-aim of prioritizing TF binding, We have compiled a set of 10 TF-tissue pairs and are in the process of developing a model for scoring using deep learning based on sequence features. Previously, we tried this with a decision tree model trained using motifs as features, and found weak correlation with different tests of functionality (e.g. conservation, overlap with an enhancer, found in replicate samples). For example, for HNF4A in liver tissue and GATA2 in K562 cells, we found significantly higher evolutionary conservation in the highly scored peaks vs. the low scoring peaks. We think that utilizing a deep learning model will achieve more success in distinguishing functional peaks. n/a",Identifying non-coding drivers of cancer,10262588,ZIABC011979,"['Affect', 'Binding', 'Binding Sites', 'Biological Process', 'ChIP-seq', 'Code', 'Data Set', 'Decision Trees', 'Enhancers', 'Gene Expression', 'Gene Expression Regulation', 'Genetic Transcription', 'Glean', 'Goals', 'HNF4A gene', 'K562 Cells', 'Liver', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Mutation', 'Probability', 'Process', 'Sampling', 'Single Nucleotide Polymorphism', 'Somatic Mutation', 'Testing', 'Thromboplastin', 'Tissues', 'Training', 'Untranslated RNA', 'Variant', 'base', 'cancer initiation', 'cancer type', 'deep learning', 'driver mutation', 'experimental study', 'genome sequencing', 'success', 'transcription factor', 'tumor', 'tumor progression', 'whole genome']",NCI,DIVISION OF BASIC SCIENCES - NCI,ZIA,2020,189957,-0.012209644730912962
"Center for Critical Assessment of Genome Interpretation Genomic data hold the promise of revolutionizing our understanding and treatment of human disease. Multiple barriers stand between the acquisition of the data and realizing these and other benefits. Rapid accumulation of genomic data far exceeds our capacity to reliably interpret genomic variation. New developments in artificial intelligence and machine learning, combined with increased computing power and domain knowledge, provide hope for the deployment of enhanced computational tools in both basic research and clinical practice. Use of these methods critically depends upon reliable characterization of their performance.  The Center for Critical Assessment of Genome Interpretation (C-CAGI) will address these needs, through objective evaluation of the state of the art in relating human genetic variation and health. CAGI has had five editions since 2010 with 50 challenges posed to the community taken on by hundreds of predictors, leading to scores of publications about prediction methods and their assessment. We propose for C-CAGI to continue to advance the field of variant interpretation through the following Specific Aims: 1. Develop community experiments to evaluate the quality of computational methods for interpreting genomic variation data. C-CAGI will conduct community experiments in which participants make bona fide blinded predictions of disease related phenotypes on the basis of genomic data. We will engage a diverse predictor community to spur innovation. The CAGI Ethics Forum will vet studies to ensure that privacy and sharing maintain the highest standards and will educate the community. 2. Assess the quality of current computational methods for interpreting genomic variation data; highlight innovations and progress at interactive conferences. Predictions will be evaluated by independent assessors, who will be supported by new assessment approaches from C-CAGI. Results will be presented at CAGI experiment conferences with deep technical engagement, which will be interleaved with reflective CAGIâ meetings that create an environment for a comprehensive evaluation of the field, facilitating identification of major bottlenecks and problems faced by the current genome interpretation approaches. 3. Broadly disseminate the results and conclusions from the CAGI experiments and analysis. C-CAGI will outreach to the broader scientific and clinical community through its publications, and the creation of a calibrated reference integrated into the most common workflows for ready adoption. CAGI will also be represented at international meetings with presentations and workshops. 4. Operate effectively and responsively. C-CAGI will operate efficiently as it closely interacts with hundreds of participants. CAGI will build upon a robust information infrastructure that securely facilitates data dissemination, prediction submission, and assessment. Genomic variation is responsible for numerous rare diseases, for propensity for many common traits and diseases, for drug response, and is a key characteristic of cancer evolution. At present, our ability to characterize genetic differences far exceeds our capacity to interpret them either for basic research understanding or for clinical application. The Center for Critical Assessment of Genome Interpretation, operating on robust ethical foundations, will provide an evaluation of the current state of the art and help promote progress in understanding the impact of genomic variation.",Center for Critical Assessment of Genome Interpretation,9937546,U24HG007346,"['Address', 'Adoption', 'Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Basic Science', 'Blinded', 'Characteristics', 'Clinical', 'Communities', 'Computing Methodologies', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Ensure', 'Environment', 'Ethics', 'Evaluation', 'Evolution', 'Foundations', 'Genetic', 'Genetic Variation', 'Genome', 'Health', 'Human Genetics', 'Infrastructure', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Nucleotides', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Privacy', 'Provider', 'Publications', 'RNA Splicing', 'Rare Diseases', 'Secure', 'Structure', 'Trust', 'Variant', 'Work', 'base', 'clinical application', 'clinical practice', 'computerized tools', 'data acquisition', 'data dissemination', 'exome', 'experimental study', 'genetic information', 'genetic variant', 'genomic data', 'genomic variation', 'high standard', 'human disease', 'innovation', 'meetings', 'multiple omics', 'operation', 'outreach', 'response', 'symposium', 'trait', 'whole genome']",NHGRI,UNIVERSITY OF CALIFORNIA BERKELEY,U24,2020,314933,-0.009520594107524266
"Center for Critical Assessment of Genome Interpretation Genomic data hold the promise of revolutionizing our understanding and treatment of human disease. Multiple barriers stand between the acquisition of the data and realizing these and other benefits. Rapid accumulation of genomic data far exceeds our capacity to reliably interpret genomic variation. New developments in artificial intelligence and machine learning, combined with increased computing power and domain knowledge, provide hope for the deployment of enhanced computational tools in both basic research and clinical practice. Use of these methods critically depends upon reliable characterization of their performance.  The Center for Critical Assessment of Genome Interpretation (C-CAGI) will address these needs, through objective evaluation of the state of the art in relating human genetic variation and health. CAGI has had five editions since 2010 with 50 challenges posed to the community taken on by hundreds of predictors, leading to scores of publications about prediction methods and their assessment. We propose for C-CAGI to continue to advance the field of variant interpretation through the following Specific Aims: 1. Develop community experiments to evaluate the quality of computational methods for interpreting genomic variation data. C-CAGI will conduct community experiments in which participants make bona fide blinded predictions of disease related phenotypes on the basis of genomic data. We will engage a diverse predictor community to spur innovation. The CAGI Ethics Forum will vet studies to ensure that privacy and sharing maintain the highest standards and will educate the community. 2. Assess the quality of current computational methods for interpreting genomic variation data; highlight innovations and progress at interactive conferences. Predictions will be evaluated by independent assessors, who will be supported by new assessment approaches from C-CAGI. Results will be presented at CAGI experiment conferences with deep technical engagement, which will be interleaved with reflective CAGIâ meetings that create an environment for a comprehensive evaluation of the field, facilitating identification of major bottlenecks and problems faced by the current genome interpretation approaches. 3. Broadly disseminate the results and conclusions from the CAGI experiments and analysis. C-CAGI will outreach to the broader scientific and clinical community through its publications, and the creation of a calibrated reference integrated into the most common workflows for ready adoption. CAGI will also be represented at international meetings with presentations and workshops. 4. Operate effectively and responsively. C-CAGI will operate efficiently as it closely interacts with hundreds of participants. CAGI will build upon a robust information infrastructure that securely facilitates data dissemination, prediction submission, and assessment. Genomic variation is responsible for numerous rare diseases, for propensity for many common traits and diseases, for drug response, and is a key characteristic of cancer evolution. At present, our ability to characterize genetic differences far exceeds our capacity to interpret them either for basic research understanding or for clinical application. The Center for Critical Assessment of Genome Interpretation, operating on robust ethical foundations, will provide an evaluation of the current state of the art and help promote progress in understanding the impact of genomic variation.",Center for Critical Assessment of Genome Interpretation,9937546,U24HG007346,"['Address', 'Adoption', 'Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Basic Science', 'Blinded', 'Characteristics', 'Clinical', 'Communities', 'Computing Methodologies', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Ensure', 'Environment', 'Ethics', 'Evaluation', 'Evolution', 'Foundations', 'Genetic', 'Genetic Variation', 'Genome', 'Health', 'Human Genetics', 'Infrastructure', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Nucleotides', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Privacy', 'Provider', 'Publications', 'RNA Splicing', 'Rare Diseases', 'Secure', 'Structure', 'Trust', 'Variant', 'Work', 'base', 'clinical application', 'clinical practice', 'computerized tools', 'data acquisition', 'data dissemination', 'exome', 'experimental study', 'genetic information', 'genetic variant', 'genomic data', 'genomic variation', 'high standard', 'human disease', 'innovation', 'meetings', 'multiple omics', 'operation', 'outreach', 'response', 'symposium', 'trait', 'whole genome']",NHGRI,UNIVERSITY OF CALIFORNIA BERKELEY,U24,2020,478516,-0.009520594107524266
"Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders The purpose of this training and research application is to study the functional impact of mobile element insertions (MEIs) in neurological disorders (NDs) using new developments in deep learning techniques. MEIs are transposable DNA fragments that are able to insert throughout the human genome. There are at least 124 independent MEIs associated with human diseases. Approximately 20% of these diseases represent a spectrum of NDs, yet the overall contribute of MEIs to the etiology of NDs has not been systematically estimated. To address this, we will (1) characterize functional MEIs in GTEx cohorts in healthy individuals; (2) build a comprehensive functional map of MEIs to determine tissue-specific and brain-specific impact; and (3) impute transcriptional changes on various NDs where whole-genome sequencing (WGS) data will be generated. The proposed application will also develop an extensive research program for Dr. Dadi Gao, a computational biologist and statistical geneticist who has trained in functional genomic studies of alternative splicing in neurodegenerative disorders and therapeutic targeting of a splicing defect that causes a severe neurodevelopmental disorder. He has developed novel methods to investigate regulation of the transcriptome and to facilitate analyses in drug development. He now seeks to expand his expertise by applying statistical and deep learning models on large cohorts of sequencing data from controls and cases with NDs from post-mortem tissues, then impute functional consequences of MEIs from WGS in large-scale disease cohorts. The training plan consists of two years of mentored research to learn new skills in genome analysis, MEI characterization, and advanced deep learning techniques, followed by three years of shaping an independent laboratory. The research plan is developed to comprehensively explore functional variation in the genome by decomposing transcriptomic changes against MEIs. Dr. Michael Talkowski at Massachusetts General Hospital, Harvard, and the Broad Institute will serve as the primary mentor, while Dr. Manolis Kellis at MIT and the MIT Computational Biology Group, and the Broad Institute will serve as a co-mentor and close collaborator. These mentors are recognized experts in genomic structural variants, functional genomics, the genetics of neurological disorders, and computational modeling to establish functional elements in the human genome. In addition, a team of independent investigators from basic and translational research will provide Dr. Gao with comprehensive feedback to keep both his science and career development on track. The highly collaborative environment in CGM, MGH, Harvard Medical School, the Broad Institute and the University of Michigan Medical School will prepare Dr. Gao for his transition to an independent investigator. This outstanding mentorship team and training program will facilitate the career development of Dr. Gao as he seeks to redefine the functional maps of MEIs in the human genome and to impute their impact in large-scale neurological disorders. Mobile element insertions (MEIs) represent a largely undefined component of the genetic architecture of neurological disorders, as a number of MEIs have been associated with alternative splicing in these disorders but large-scale genome-wide functional characterization has not been systematically performed across tissues. This program study will functionally characterize the impact of MEIs on alternative splicing from whole-genome sequencing and transcriptome sequencing in large cohorts using new developments in deep learning models. These results will enhance our understanding of the etiological role and pathogenic mechanisms associated with MEIs in neuronal development and human neurological disorders.",Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders,10041366,K99NS118109,"['Address', 'Algorithms', 'Alternative Splicing', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Basic Science', 'Biology', 'Blood', 'Brain', 'Brain Diseases', 'CRISPR/Cas technology', 'Cells', 'Chromosome Pairing', 'Cohort Studies', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Insertion Elements', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Disease', 'Disease model', 'Dorsal', 'Dystonia', 'Elements', 'Etiology', 'Event', 'Evolution', 'Excision Repair', 'Familial Dysautonomia', 'Feedback', 'Fellowship', 'Filipino', 'General Hospitals', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Haplotypes', 'Human', 'Human Genome', 'Individual', 'Institutes', 'International', 'Introns', 'Laboratories', 'Lateral', 'Lead', 'Learning', 'Linear Regressions', 'Link', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Mind', 'Minisatellite Repeats', 'Modeling', 'Molecular', 'Mosaicism', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'Neurons', 'Outcome', 'Parkinsonian Disorders', 'Pathogenicity', 'Pattern', 'Peripheral', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Prefrontal Cortex', 'Process', 'Property', 'RNA Splicing', 'Regulation', 'Research', 'Research Personnel', 'Retroelements', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Shapes', 'Short Interspersed Nucleotide Elements', 'Source', 'Specificity', 'Structure', 'TAF1 gene', 'Techniques', 'Therapeutic Trials', 'Tissue-Specific Splicing', 'Tissues', 'Training', 'Training Programs', 'Transcription Alteration', 'Translational Research', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'brain tissue', 'career development', 'cohort', 'collaborative environment', 'convolutional neural network', 'deep learning', 'drug development', 'functional genomics', 'functional outcomes', 'gene function', 'genetic architecture', 'genome analysis', 'genome editing', 'genome sequencing', 'genome-wide', 'human disease', 'in silico', 'insight', 'medical schools', 'mind control', 'nervous system disorder', 'neuron development', 'novel', 'programs', 'response', 'skills', 'statistical learning', 'structural genomics', 'therapeutic target', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,K99,2020,91226,-0.029194824831537874
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,10016298,U01AI157189,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Bar Codes', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'machine learning method', 'next generation', 'novel', 'novel therapeutics', 'off-target mutation', 'off-target site', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2020,610710,0.02554483911370747
"Scalable detection and interpretation of structural variation in human genomes PROJECT SUMMARY Structural variation (SV), is a diverse class of genome variation that includes copy number variants (CNVs) such as deletions and duplications, as well as balanced rearrangements, such as inversions and reciprocal translocations. A typical human genome harbors >4,000 SVs larger than 300bp and their large size increases the potential to delete or duplicate genes, disrupt chromatin structure, and alter expression. Despite their prevalence and potential for phenotypic consequence, SVs remain notoriously difficult to detect and genotype with high accuracy. Much of this difficulty is driven by the fact DNA sequence alignment “signals” indicating SVs are far more complex than for single-nucleotide and insertion deletion variants. Unlike SNP alignments that vary only in allele state, alignments supporting SVs vary in state (supports an alternate structure or not) alignment location, and type. Consequently, the accuracy of SV discovery is much lower than that of SNPs and INDELs. Furthermore, SV pipelines scale poorly and are difficult to run. These challenges are a barrier for single genome analysis and studies of families must invest substantial effort into eliminating a sea of false positives. These problems become exponentially more acute for large-scale sequencing efforts such as TOPmed, the Centers for Common Disease Genetics, and the All of Us program. Software efficiency is key to scalability for such projects. However, of equal importance is comprehensive, accurate discovery.  Building upon more than a decade of software development experience and analyzing SV in diverse disease contexts, we have invested significant effort into understanding the causes of the insufficient accuracy for SV discovery. These efforts, together with our research and development experience in this area, give us unique insight into improving the accuracy and scalability of SV discovery. Our goal is to narrow the accuracy gap between SNP/INDEL variation and structural variation discovery. These developments will empower studies of human genomes in diverse contexts and will therefore have broad impact. Our goals are to: 1. Develop a deep learning model to correct systematic variation in sequence depth. This new machine  learning model will correct systematic biases in DNA sequence depth and dramatically improve the  discovery of deletions and duplications. 2. Improve the speed, scalability, and accuracy of SV detection and genotyping. Using new algorithms,  we will bring the accuracy of SV detection much closer to that of SNP and INDEL discovery and allow  accurate SV discovery to be deployed at scale. 3. Create a map of genomic constraint for SV from population-scale genome analysis. We will deploy  our new methods to detect and genotype structural variation among tens of thousands of human genomes.  The resulting SV map will empower the creation of a model of genomic constraint for SV and enable new  software to predict deleterious SVs, especially in the noncoding genome. PROJECT NARRATIVE Single-nucleotide DNA changes paint an incomplete picture of a human’s genome. A more complete picture must include a genome's structural variation (SV), an important class of genome variation that includes copy number variants (CNVs) such as deletions and duplications. However, existing methods have poor accuracy. As the genetics community transitions to large-scale genome sequencing studies, there is an acute need for improved SV discovery methods. This proposal introduces a series of algorithmic and software innovations that will empower SV discovery, genotyping, and interpretation in large-scale human disease studies.",Scalable detection and interpretation of structural variation in human genomes,9973582,R01HG010757,"['Acute', 'Affect', 'Algorithmic Software', 'Algorithms', 'All of Us Research Program', 'Alleles', 'Area', 'Automobile Driving', 'Biological Assay', 'Chromatin Structure', 'Chromosome Structures', 'Clip', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence', 'Data', 'Data Reporting', 'Detection', 'Development', 'Disease', 'Environment', 'Error Sources', 'Exhibits', 'Family Study', 'Funding', 'Future', 'Gene Duplication', 'Gene Expression', 'Gene Fusion', 'Gene Structure', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Individual', 'Laboratories', 'Large-Scale Sequencing', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Noise', 'Nucleotides', 'Paint', 'Pathogenicity', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Process', 'Reciprocal Translocation', 'Research', 'Running', 'Sampling', 'Sea', 'Sensitivity and Specificity', 'Sequence Alignment', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Speed', 'Structure', 'Systematic Bias', 'Techniques', 'Technology', 'Training', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'algorithm development', 'base', 'convolutional neural network', 'deep learning', 'developmental disease', 'dosage', 'exome', 'experience', 'genome analysis', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'innovation', 'insertion/deletion mutation', 'insight', 'large datasets', 'method development', 'nanopore', 'novel', 'prevent', 'research and development', 'software development', 'success', 'tool', 'variant detection', 'whole genome']",NHGRI,UNIVERSITY OF UTAH,R01,2020,692048,0.008213879571140498
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9868315,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'de novo mutation', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'machine learning method', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'supervised learning', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2020,237600,0.03643956059637088
"Development of statistical genetics methodology We continue to develop machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, and to explore their utility, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published three papers describing this method. We are currently developing The Machine Suite which will be an extension of r2VIM. In this reporting period we have  further improved control of false positive rates while retaining excellent power, adding multistep, weighted approaches that we are calling weighted replanting to increase power when number of features is very large and there are only interaction effects on risk of disease or when such interactions exist in the presence of large numbers of other additive polygenic risk variants. Simulations confirm this excellent power and false positive control under a wide variety of realistic genome-wide scenarios.  A manuscript presenting this new method, r2VIM-W, is in preparation and results will be presented at upcoming scientific meetings. We have also been developing and testing a new approach, InteractionDetector, for specifically identifying which selected features are actually interacting with each other as opposed to acting independently. This work will continue in the next fiscal year and we plan applications to several of our datasets. We are also working on  our ongoing development of the Machine Suite which will include open source software for r2VIM-W, InteractionDetector and OptimalCrowd which will be our implementation of Dr. James Malleys published methodology, since freely available software for this method does not exist at present. These software packages will all be shared on Dr. Bailey-Wilsons NHGRI website and possibly also on github and cran. The massive number of simulations for this project relied heavily on the Biowulf computational resource at NIH.  We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Development of these analysis methods and tools are ongoing, driven by our own WES and WGS sequence data from multiple studies of complex traits.  We have recently updated our sequence data quality assurance pipeline and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have worked on optimizing methods for performing multipoint analyses using extremely dense WES, WGS and exome chip data sets. Also this year, we made many improvements to our pipelines for application of family-based methods for improved quality control in whole genome sequence data. Our WGS pipeline has been presented at several scientific meetings this past year.   In collaboration with Dr. Ruzong Fan (s Guest Researcher who is a Professor at Georgetown University) and Dr. Chi-Yang Chiu (a Guest Researcher who is a faculty member at University of Tennessee Health Sciences Center), we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. We have published multiple papers in this area in previous years. In this reporting period, we have utilized gene-based association analysis to develop and test a new method for association analysis of survival traits using functional regression based mixed effect cos models for use in family data. This work, along with the extensive simulation studies showing its good power and false positive control was published in this reporting period  (1). The massive number of simulations for this project relied heavily on the Biowulf computational resource at NIH.  We began a new collaboration with Dr. Kathleen Vazzana and Laura Lewandowski at NIAMS, who had performed TDT analysis using whole exome sequence data on a moderately sized sample of parent-parent-affected child trios for lupus.  This study used both single variant and gene-based association tests. We developed a permutation-based approach to determine the significance of the results of these analyses, using 10,000 permuted data replicates that we then analyzed in the same manner as the original TDT analyses.  We used the p-values from the permuted datasets (under the null hypothesis of no association) to determine new significance thresholds for the applied analyses and to evaluate the empirical significance of the most significant results.  This is being done separately for the single variant and gene-based tests. A manuscript will be prepared to present this work in the next reporting period. n/a",Development of statistical genetics methodology,10267086,ZIAHG000153,"['Affect', 'Area', 'Child', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Faculty', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Health Sciences', 'Linear Models', 'Lupus', 'Manuscripts', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Preparation', 'Publishing', 'Quality Control', 'Recurrence', 'Reporting', 'Research Personnel', 'Sample Size', 'Scheme', 'Sequence Analysis', 'Statistical Methods', 'Survival Analysis', 'Tennessee', 'Testing', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'Yang', 'base', 'case control', 'classification trees', 'computing resources', 'data mining', 'data quality', 'data warehouse', 'disorder risk', 'exome', 'flexibility', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genetic testing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'machine learning method', 'meetings', 'member', 'novel', 'novel strategies', 'open source', 'oral cleft', 'professor', 'quality assurance', 'random forest', 'rare variant', 'risk variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2020,202397,0.0024688308293397414
"Identification of Transposable Element Insertions in the Kids First Data Project Summary Insertion of transposable elements (TEs, sometimes referred to as “jumping genes”) into the human genome can be pathogenic. Our aim in this project is to use sophisticated computational approaches to characterize TE insertions in the whole-genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program and identify any insertional mutations that may disrupt gene function. The large scale of the Kids First program provides an unprecedented opportunity to investigate the role of TE insertions in childhood cancers and structural birth defects, as well as to create a resource of reference TE maps that will be important for all other TE studies. We will first modify our existing algorithm called xTEA for the trio design of the Kids First studies and increase the accuracy and efficiency of the algorithm. Then, we will apply it to the thousands of trios that have been profiled in the Kids First program, using a pipeline optimized for the cloud environment. The resulting set of TE insertions (especially L1, Alu, SVA, and HERV insertions) will be curated with all relevant features and be made into a database for the community. We will also apply machine learning methods to improve the calls once a sufficient amount of training data have been obtained. To investigate the potential pathogenicity of the mutation, we will first focus on insertions within genes, but we will also explore those in regulatory elements inferred from epigenetic profiling data. PROJECT NARRATIVE Transposable elements, or “jumping genes”, are genetic elements that can alter the DNA of an individual. We aim to utilize a computational method to identify such elements in the genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program. Our analysis will identify transposable elements that may be causal for a disease phenotype.",Identification of Transposable Element Insertions in the Kids First Data,9957262,R03CA249364,"['Algorithms', 'Communities', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Insertion Elements', 'DNA Transposable Elements', 'Data', 'Data Set', 'Databases', 'Disease', 'Elements', 'Endogenous Retroviruses', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Human Genome', 'Individual', 'Inherited', 'Insertion Mutation', 'Jumping Genes', 'Length', 'Location', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Maps', 'Mendelian disorder', 'Methods', 'Modeling', 'Mutation', 'Neurons', 'Output', 'Parents', 'Paste substance', 'Pathogenicity', 'Pediatric Research', 'Play', 'Population', 'Regulatory Element', 'Reporting', 'Resources', 'Retrotransposon', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Site', 'Source', 'Speed', 'Structural Congenital Anomalies', 'Training', 'base', 'cloud based', 'cohort', 'design', 'disease phenotype', 'epigenetic profiling', 'gene function', 'genetic element', 'genome sequencing', 'improved', 'machine learning method', 'proband', 'programs', 'transcriptome sequencing', 'whole genome']",NCI,HARVARD MEDICAL SCHOOL,R03,2020,169041,-0.024010359991996747
"Advancing evolutionary genetic inference in humans and other taxa Project Summary/Abstract Background: A major challenge in evolutionary genomics is to characterize the forces shaping present-day patterns of genetic variation. For instance, the extent and manner in which natural selection affects genetic diversity remains highly controversial. Researchers have largely addressed this problem by developing statistical tests or summaries of genome sequence variation that provide insights into the evolutionary forces at play. However, because such approaches typically rely on a single univariate summary of the data, valuable discriminatory information present in the original dataset is lost. A more fruitful strategy would thus be to use multidimensional summaries of genomic data (e.g. a large vector of summary statistics) or even the totality of the input data (e.g. a matrix-representation of a sequence alignment) to make more accurate inferences. An even more powerful approach is to utilize data sets in which the same population is sampled at multiple time points, allowing one to observe evolutionary dynamics in action. Although such genomic time-series data are becoming more prevalent, the development of appropriate computational methodologies has lagged behind the proliferation of such data. Proposal: The Schrider Lab seeks to develop and apply powerful machine learning methods for evolutionary inference. Our work over the next five years will yield powerful software tools leveraging novel representations of genomic datasets, including time-series data. These efforts will dramatically improve researchers' ability to make accurate evolutionary inferences from both population genomic and phylogenetic data. Indeed, preliminary results demonstrate that our methods vastly outperform current approaches in evolutionary genetics. More importantly, we will use these tools to answer pressing evolutionary questions. In particular, our use of time-series data will reveal loci responsible for recent adaptation with much greater confidence than currently possible. Our efforts will help to resolve the controversy over the role of adaptation in shaping patterns of diversity across the human genome. This research has important implications for public health as well, as genes underlying recent adaptations are enriched for disease-associations. Moreover, we are constructing a time-series dataset in the mosquito vector species Aedes aegypti and Aedes albopictus. We will interrogate these data for evidence of recent and ongoing adaptation—this work will reveal loci responsible for the evolution of resistance to insecticides and other control efforts. Encouraging preliminary data also suggest that our work in phylogenetics will substantially improve inferential power in this important research area. More broadly, the success of the novel approaches described in this proposal has the potential to transform the methodological landscape of evolutionary genomic data analysis. Project Narrative The work proposed here seeks to develop and apply powerful machine-learning based software tools for evolutionary genetic inference in humans, mosquito vectors, and other species. Such efforts have important health implications, as they can identify genes involved in adaptation, which in humans are often associated with disease and in mosquitos are often associated with resistance to insecticides and other control efforts.",Advancing evolutionary genetic inference in humans and other taxa,10028474,R35GM138286,"['Address', 'Aedes', 'Affect', 'Area', 'Computing Methodologies', 'Culicidae', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Health', 'Human', 'Human Genome', 'Insecticides', 'Machine Learning', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phylogenetic Analysis', 'Play', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Sequence Alignment', 'Series', 'Shapes', 'Software Tools', 'Testing', 'Time', 'Variant', 'Work', 'base', 'genomic data', 'improved', 'insight', 'machine learning method', 'novel', 'novel strategies', 'statistics', 'success', 'time use', 'tool', 'vector', 'vector mosquito']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2020,382894,0.0012549668798378277
"The adaptive potential of translational regulation Project Summary/Abstract  Our current understanding of the adaptive effects of mutation is largely limited to alterations in protein coding sequence and disruption of transcriptional cis-regulatory promoters. Very little is known about how mutations alter translation, or the role these mutations play in adaptation and evolution. This project seeks to address this gap by identifying the functional effect of mutations on translation. To accomplish this I will first identify mutations that arise from adaptation to various nutrient limited environments. I will then use expression profiling (e.g. RNA-seq, ribosome profiling, and RATE-seq) to identify the effect these mutations have on translation, as well as other levels of gene expression. This will provide insight into the magnitude of effect mutations have on translation and their relative rate. Furthermore, to fully characterize the role synonymous mutations have on fitness I will be using a deep scanning synonymous mutation library. To understand the role tRNA abundance plays in the fitness effect of a given synonymous mutations, I will also be evaluating fitness within tRNA under- and over-expression backgrounds. Because of the closely coupled nature of translation rates and mRNA decay, I will also characterize the effect synonymous mutations have on mRNA decay using RATE-seq. My analysis of the functional effects of these mutations on gene expression, particularly within the genetic background and environment in which they arose, will allow for the development of a machine learning algorithm that can use sequence and annotation features to predict the effect of a mutation on gene expression. This tool will aid future research into the effect mutations have of gene expression by allowing the identification of high-confidence candidates for further evaluation.  This project will be conducted at New York University’s Center for Genomics and Systems Biology, whose mission is to answer otherwise intractable biological questions using applied experimental and computational approaches. The Center houses numerous facilities and cores that will be instrumental in the performance of this work. The collaborative atmosphere and multi-disciplinary nature of NYU’s research communities that will enable me to stay abreast of developments in related fields and to rapidly communicate my research to interested parties. I will be trained under the guidance of Dr. David Gresham, an excellent researcher working on complementing long-term evolution experiments with gene expression studies to characterize the adaptive potential of the regulation of gene expression. Project Narrative The translation of mRNA into protein is a critical step in gene expression that is tightly regulated with mis-regulation of translation being a hallmark of many human pathologies. Understanding how mutations can alter the regulation of translation is an understudied but important aspect of adaptation and evolution. Ultimately, without an understanding of the adaptive potential of translation we have an incomplete, and imperfect, picture of the underlying genetic causes of numerous forms of cancer and genetic diseases.",The adaptive potential of translational regulation,9893712,F32GM131573,"['Address', 'Affect', 'Amino Acid Sequence', 'Biological', 'Biological Assay', 'Biology', 'Code', 'Communities', 'Complement', 'Computer software', 'Coupled', 'Data', 'Development', 'Disease', 'Elements', 'Environment', 'Evaluation', 'Evolution', 'Expression Profiling', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Translation', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Human Pathology', 'Laboratories', 'Libraries', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mission', 'Modeling', 'Modernization', 'Mutation', 'Nature', 'New York', 'Nutrient', 'Open Reading Frames', 'Pathology', 'Performance at work', 'Phenotype', 'Play', 'Population', 'Proteins', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Research', 'Research Personnel', 'Ribosomes', 'Role', 'Scanning', 'Site', 'Stress', 'Systems Biology', 'Testing', 'Training', 'Transfer RNA', 'Translation Initiation', 'Translational Regulation', 'Translations', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'analytical tool', 'cancer genetics', 'collaborative environment', 'driver mutation', 'environmental change', 'experimental study', 'fitness', 'genome sequencing', 'insight', 'interest', 'mRNA Decay', 'mRNA Transcript Degradation', 'machine learning algorithm', 'multidisciplinary', 'mutation screening', 'novel', 'preservation', 'promoter', 'response', 'ribosome profiling', 'tool', 'transcriptome sequencing', 'whole genome']",NIGMS,NEW YORK UNIVERSITY,F32,2020,65310,0.02524331882201129
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9990809,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'statistical and machine learning', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2020,332952,0.020220525556682824
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9870944,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2020,397125,0.00012837802344754123
"The fitness effects of de novo structural variants PROJECT SUMMARY/ABSTRACT This proposal for the NIH Pathway to Independence Award (K99/R00) focuses on the training of Dr. PingHsun Hsieh to become an independent investigator of large-scale genomics and human population genetics. Dr. Hsieh is a population geneticist by training, and the proposed studies will advance his training into long-read- based sequencing technologies and novel machine-learning approaches to study the fitness consequences of new mutations, with a focus on structural variants (SVs), in humans and nonhuman primates. Another essential piece will be the development of resources on which types of new SVs are most likely to be pathogenic and hence most worth further effort by medical researchers. The methods developed in this work will enable other researchers to do more hypothesis-free analysis of SVs in disease etiology. Specifically, the training program will center on the study of the distribution of fitness effects of new SVs in human and nonhuman primates using high-quality SV calls and genotypes from several large-scale long- and short-read sequencing projects. The mentored work will take place under the supervision of the primary mentor, Dr. Evan Eichler, and the co-mentor, Dr. Sharon Browning, both at the University of Washington (UW). The mentor and co-mentor are well-established experts in the characterization of genomic variations using high-throughput technologies and the development of stochastic modeling methods for large-scale genetic data, respectively. Dr. Hsieh will also gain advice from a formal advisory committee as well as through activities arranged by the Department of Genome Sciences (GS), which is an optimal place for the mentored training providing the candidate with access to outstanding scientists in areas including genetics of model organisms, disease, population genetics, and the development of high-throughput genomic technologies. While found in nature and yet generally deemed to be deleterious given their size, SVs can be beneficial, and thus, the distribution of fitness effects (DFE) of new SVs (i.e., the relative frequencies of beneficial, neutral, and deleterious SVs) remains elusive. In the proposed studies, we will infer the DFE of new SVs and other variants to assess their relative importance in nature, which in turn helps prioritize variants (e.g., SVs vs. single- nucleotide variants [SNVs]) in medical genetics. Specifically, in the K99/R00 phases we will (1) infer the DFE of new SVs and SNVs using a diverse panel of ~100 long-read and ~4,000 short-read high-coverage human and nonhuman primate genomes; (2) compare the DFE of new mutations among primates using contemporary and ancient DNA genomes; and (3) study the fitness effects and selective constraints on diseases in different mutation categories in large cohorts of >20,000 genomes. The skills learned in this proposal are on the cutting-edge and are tailored for the candidate to amass a great amount of knowledge in new areas of genomics, which will be applicable to many organisms and diseases and critical to the candidate’s future independent laboratory. NARRATIVE Understanding the relative abundance of beneficial, neutral, and deleterious mutations in different variant categories (e.g., genic vs. intergenic) provides useful guidance and resources for biomedical researchers to prioritize disease-causing mutations and strategize their efforts. To date, however, little effort has been made to study the full spectrum of fitness effects of new structural variants – an important but largely underappreciated genomic variation. The work proposed here seeks to leverage long-read sequencing technologies and develop novel machine-learning approaches to quantify the fitness effects of new mutation, with a focus on structural variants, and subsequently delineate the relative importance among different types of mutations in genetic diseases.",The fitness effects of de novo structural variants,9950314,K99HG011041,"['Advisory Committees', 'Affect', 'Animal Model', 'Area', 'Award', 'Base Pairing', 'Benchmarking', 'Categories', 'Communities', 'Complex', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence', 'Data', 'Demography', 'Development', 'Diploidy', 'Disease', 'Etiology', 'Evolution', 'Frequencies', 'Future', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Models', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Individual', 'Instruction', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Genetics', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Mutation', 'Natural Selections', 'Nature', 'Organism', 'Outcome', 'Parents', 'Pathogenicity', 'Pathway interactions', 'Phase', 'Phylogenetic Analysis', 'Population', 'Population Genetics', 'Primates', 'Public Health', 'Quantitative Trait Loci', 'Recurrence', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Sample Size', 'Sampling', 'Scientist', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Structure', 'Supervision', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Uncertainty', 'United States National Institutes of Health', 'Universities', 'Variant', 'Washington', 'Work', 'autism spectrum disorder', 'base', 'biological systems', 'biomedical resource', 'career', 'cohort', 'disease-causing mutation', 'expectation', 'fitness', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic locus', 'genomic variation', 'high throughput technology', 'human population genetics', 'improved', 'machine learning method', 'nonhuman primate', 'novel', 'pressure', 'simulation', 'skills', 'technology development', 'trait']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2020,132244,-0.04434670057883932
"Addressing Open Challenges of Computational Genome Annotation We propose to capitalize on success of ongoing collaboration between the bioinformatics teams at the University of Greifswald (Germany) and at the Georgia Institute of Technology (USA) and address open challenges in computational genome annotation. In the course of this development, we plan to implement new algorithmic ideas and satisfy the needs of unbiased integration of different types of OMICS data.  We plan to address one of the long-standing problems at interface of bioinformatics and machine learning – automatic generative and discriminative parameterization of gene finding algorithms. Current methods of combining OMICS evidence frequently result in under predicting or over predicting tools. Having good understanding of the difficulties and the properties of different types of OMICS evidence we propose an optimized approach to the full unsupervised, generative and discriminative training.  We will introduce novel means to optimize integration of multiple OMICS evidence into gene prediction. These ideas will develop further the protein family-based gene finding implemented in AUGUSTUS-PPX. We propose to create representations of protein families for gene finding that for the first time include cross-species gene structure information.  We will develop a new approach that will unify two advanced research areas - transcript reconstruction from RNA-Seq and statistical gene finding that integrates RNA-Seq and homology information. We will describe a new, comprehensive model and EM-like algorithmic technique (the “wholistic” approach) to identify the sets of transcripts and their expression levels that best fit the available OMICS evidence.  We will also develop an automatic gene-finding algorithm for a full content of metagenomes including eukaryotic and viral metagenomic sequences. This task is conventionally considered too challenging. We propose a solution exploiting and advancing algorithmic ideas and approaches that we mastered in the course of creating gene finders for prokaryotic metagenomes as well as eukaryotic genomes.  All new tools will be available to the community under open source licenses. The goal of this project is to advance the science of genome interpretation by developing much needed computational methods and tools for high precision annotation of eukaryotic genomes and metagenomes. This advance will make an impact in research on model and non-model organisms including important human pathogens, parasites and viruses. New high throughput technologies generate volumes of sequence data on complex genomes as well as metagenomes. Still these big data volumes have to be transformed into scientific knowledge. Our new bioinformatics tools, matching the latest sequencing technology in speed and performance, will make a significant impact in genomic research aiming at ultimate understanding of human health and disease.",Addressing Open Challenges of Computational Genome Annotation,9975182,R01GM128145,"['Address', 'Algorithms', 'Alternative Splicing', 'Area', 'Bacteriophages', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Chronic', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complement', 'Complex', 'Computing Methodologies', 'Data', 'Deterioration', 'Development', 'Development Plans', 'Disease', 'Gene Family', 'Gene Structure', 'Genes', 'Genome', 'Genomics', 'Germany', 'Goals', 'Health', 'Human', 'Insecta', 'Institutes', 'Introns', 'Knowledge', 'Length', 'Licensing', 'Machine Learning', 'Maintenance', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Nested Genes', 'Noise', 'Overlapping Genes', 'Parasites', 'Performance', 'Population', 'Positioning Attribute', 'Property', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'RNA Splicing', 'Research', 'Running', 'Speed', 'Spliced Genes', 'Statistical Models', 'Supervision', 'Techniques', 'Technology', 'Time', 'Training', 'Transcript', 'Universities', 'Viral', 'Virus', 'annotation  system', 'base', 'bioinformatics tool', 'computerized tools', 'cost', 'course development', 'design', 'evidence base', 'expectation', 'gene complementation', 'genome annotation', 'genome sciences', 'high throughput technology', 'human pathogen', 'improved', 'instrument', 'member', 'metagenome', 'multiple omics', 'nanopore', 'new technology', 'novel', 'novel strategies', 'open source', 'operation', 'predictive tools', 'protein profiling', 'reconstruction', 'success', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIGMS,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2020,342390,0.011235651005632423
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9928344,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2020,1186500,-0.008066041591336696
"Advanced algorithms to infer and analyze 3D genome structures Project Summary For the past decade, the population-cell Hi-C technique has significantly improved our ability to discover genome-wide DNA proximities. However, because population Hi-C is based on a pool of cells, it will not help us reveal each single cell's 3D genome structure or understand cell-to-cell variability in terms of 3D genome structure and gene regulation. It is also difficult to achieve a high resolution, such as 1 Kbp, with population Hi- C; therefore, when finding and analyzing the spatial interactions for the promoter or enhancer regions typically associated with biologically-important regulatory elements, population Hi-C data's resolution is too low to be useful. Moreover, while we know that the CTCF-cohesin complex plays a key role in the formation of genome 3D structures, the question is whether long non-coding RNAs (lncRNAs) are involved in the process since lncRNAs have been found to recruit proteins needed for chromatin remodeling, and our preliminary research has found that lncRNA LINC00346 directly interacts with CTCF. Finally, while members of the bioinformatics community, including the PI, have developed many algorithms to reconstruct 3D genome structures based on population Hi-C data, important questions still must be answered regarding how 3D genome structures are involved in gene regulation and whether there are relationships between 3D genome structures and genetic and epigenetic features. The PI proposes to conduct leading research to overcome these challenges and address these questions. During the next five years, the PI will develop algorithms to reconstruct the 3D whole- genome structures for single cells and analyze cell-to-cell variabilities in terms of 3D genome structure and gene regulation. The PI will develop a deep learning algorithm to enhance the resolution of population Hi-C data to that of Capture Hi-C data (1 Kbp) so that we can make good use of the large amount of Hi-C data accumulated in the past decade. An online database will be built to allow the community to access both population and single-cell 3D genome structures in an integrated way. The PI will work with a cancer biologist to discover any lncRNAs that function as a scaffold to fine-tune the CTCF-cohesin protein complex, as well as two neuron scientists to develop a more complete understanding of gene regulation while considering 3D genome and other genetic and epigenetic features. Given the PI's track record and productivity, having three computational goals and two collaborative goals is not only feasible but computationally and biologically rewarding. In five years, once the proposed studies are accomplished, the PI should have established a uniquely independent place in the field of 3D genome, maintaining leading positions in inferring single-cell 3D genome structures, enhancing Hi-C data resolution, and building 3D genome databases, while establishing similar positions in reconstructing high-resolution 3D genome structures, finding lncRNAs' roles in the formation of genome structures, and understanding how 3D genome structures are involved in gene regulation. Project Narrative The three-dimensional (3D) structure of genome is critically important for gene regulation; and the abnormal 3D genome structures are often associated with diseases such as cancer. This proposal aims to reconstruct and analyze the 3D genome structures of thousands of individual cells, study how 3D genome structures participate in gene regulation, determine whether long noncoding RNAs (lncRNAs) are involved in the formation of genome structures, and build an online knowledge base integrating 3D genome structures with other biological information.",Advanced algorithms to infer and analyze 3D genome structures,10027542,R35GM137974,"['3-Dimensional', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Cells', 'Communities', 'Complex', 'DNA', 'Data', 'Databases', 'Disease', 'Enhancers', 'Epigenetic Process', 'Gene Expression Regulation', 'Genetic', 'Genome', 'Goals', 'Individual', 'Malignant Neoplasms', 'Neurons', 'Other Genetics', 'Play', 'Population', 'Positioning Attribute', 'Process', 'Productivity', 'Proteins', 'Regulatory Element', 'Research', 'Resolution', 'Rewards', 'Role', 'Scientist', 'Structure', 'Techniques', 'Untranslated RNA', 'Work', 'base', 'chromatin remodeling', 'cohesin', 'deep learning algorithm', 'genome database', 'genome-wide', 'improved', 'knowledge base', 'member', 'promoter', 'protein complex', 'recruit', 'scaffold', 'three dimensional structure', 'whole genome']",NIGMS,UNIVERSITY OF MIAMI CORAL GABLES,R35,2020,354694,-0.016573210693248314
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9876220,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2020,479215,0.030681819253386162
"Telomere Diseases and Other Constitutional and Acquired Genetic Disorders of Hematopoiesis Telomeres are repeated hexanucleotide sequences at the ends of linear chromosomes, which serve to protect them from recognition as chromosomal breaks. Asymmetric replication of DNA would lead inevitably to a loss of genetic material, and the telomere repair molecular machinery (a reverse transcriptase, RNA template, and associated proteins) functions to maintain genomic integrity. Telomerase deficiency manifests with short telomeres. Mutations in DKC1 and in TERC (the RNA template subunit of the complex) are etiologic in dyskeratosis congenita, a constitutional form of aplastic anemia. Mutations in TERT (encoding telomerase, the rate limiting enzymatic component of the complex) and in TERC occur in apparently acquired aplastic anemia and other diseases. Male hormones, long used to treat aplastic anemia, act to regulate TERT transcription and telomerase activity. While critical telomere shortening leads to either cell senescence or apoptosis, occasionally cells become aneuploid due to end-to-end fusion of chromosomes. Telomere attrition creates chromosome instability and is a mechanism of oncogenesis. Telomere attrition also a reflects generalized DNA damage, and this report includes studies directed at acquisition of somatic mutations, specific genes, and relevant etiologic and functional considerations.   In the clinic, having successfully completed our clinical protocol testing danazol at high doses and prolonged administration for clinical efficacy and telomere effects in patients with telomere disease, we are now accruing cases to a new, low dose danazol trial. In the current study, patients are randomized to initially receive either half or quarter doses (400 mg or 200 mg daily) compared to the original protocol, for 6 months, and then crossed over the other dose for a further 6 months. These regimens should avoid the toxicities of high dose sex hormones. The design of the current protocol also addresses deficiencies of the original study: 1. We will utilize both q-pcr and also flow-FISH for telomere length and 2. 6 month observation and wash-out periods precede and follow drug administration in order to provide baseline telomere attrition information. Additionally, because of the suggestion of stabilization and possibly improvement in pulmonary function in the earlier protocol, the inclusion criteria have been expanded to recruit patients with mainly lung manifestations of telomeropathy.   Relevant to the larger clinical issue of distinction between constitutional and acquired etiologies for bone marrow failure, we systematically screen by genomics patients presenting to our clinic with a wide variety of bone marrow failure syndromes. We assess for mutations and polymorphisms in >50 genes etiologic in inherited marrow failure syndromes for both research purposes and clinical reporting to the patient. We also have data from collaborators in Sao Paolo, Brazil. We are developing a machine learning approach to identify BMF patients with increased risk of having inherited BMF. As inherited BMF are marked by an overlap of clinical presentations and are very heterogenous, supervised learning may be particularly useful to obtain a model that incorporates the complex clinical and molecular patterns in a predictive model. In collaboration with intra- and extramural colleagues, we have gathered clinical and molecular data from more than 600 patients In early iterations our model displays an accuracy of 90% but moderate specificity (80%). Clustering prior to machine learning should further improve specificity by detecting constitutional syndromes and associated variables.   We are exploring scRNAseq in constitutional marrow failure syndromes. In the telomeropathies and related diseases, numbers of CD34 marrow cells are inadequate. We have been successful in defining the hematopoietic defect in GATA2 deficiency and have utilized thid approach now in DADA2 deficiency, in which monocytes from patients were studied. The striking inflammatory clinical phenotype of DADA2 deficiency has not been linked other than generally to innate immunity. We found large differences in classical, non-classical, and transitional subsets between patients and healthy controls, consistent with the abnormal cytokine profile of plasma and a pro-inflammatory clinical phenotype.   We performed a comparative analysis to assess the clinical utility of cfDNA for detection and quantification of clonal hematopoiesis. In a comparison of the clinical utility of cfDNA for detection and quantification of clonal hematopoiesis. Compared to matched blood cells, cfDNA sensitivity and specific was high to detect variants only when their VAF was higher than 12%. Also, agreement between cfDNA and blood cells in clones quantification was very poor, suggesting that screening in cfDNA is not interchangeable to bone marrow or peripheral blood cells. We have collaborated with Dr. Mehta from NHLBI and Dr. Grayson from NIAMS in projects that aim to identify mutations associated with clonal hematopoiesis in patients with chronic inflammation, such as psoriasis and ANCA-associated vasculitis. In parallel, we are screening patients with telomere diseases for somatic mutations in genes associated with clonal hematopoiesis and telomere maintenance. POT1 mutations were found exclusively mutated in telomere diseases and are being studied as potential clonal marker of genetic rescuing in these patients. Also, recurrent mutations in U2AF1 were found in patients that presented with MDS and are likely to be a clonal marker of clonal evolution in telomere diseases. In collaboration with other NIH investigators, we helped characterize a novel syndrome in which a somatic mutation in an hematopoietic stem cell that alters an early stage of ubiquitinylation results in a severe multisystem disease, manifesting as polychondritis and vasculitis in adult men; one component is a dysplastic bone marrow featuring vacuolization and variable profound cytopenias. In other related work at the population level, we were successful  in obtaining a large research grant from the Department of Defense to establish an international consortium which will undertake the largest multi-ethnic genome wide study of risk genetic risk factors in AA, aimed especially to uncover novel variants associated with the increased frequency of AA in Asian countries n/a",Telomere Diseases and Other Constitutional and Acquired Genetic Disorders of Hematopoiesis,10253850,ZIAHL006089,"['Address', 'Adult', 'Agreement', 'Aneuploidy', 'Antineutrophil Cytoplasmic Antibodies', 'Aplastic Anemia', 'Apoptosis', 'Asians', 'Blood', 'Blood Cells', 'Bone Marrow', 'Brazil', 'CD34 gene', 'Cell Aging', 'Cells', 'Chromosomal Breaks', 'Chromosomal Instability', 'Chromosomal Stability', 'Chromosomes', 'Chronic', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clonal Evolution', 'Collaborations', 'Complex', 'Constitutional', 'Country', 'DNA Damage', 'DNA biosynthesis', 'Danazol', 'Data', 'Defect', 'Department of Defense', 'Detection', 'Disease', 'Dose', 'Dyskeratosis Congenita', 'Dysmyelopoietic Syndromes', 'Etiology', 'Extramural Activities', 'Failure', 'Frequencies', 'Genes', 'Genetic Diseases', 'Genetic Markers', 'Genetic Materials', 'Genetic Polymorphism', 'Genetic Risk', 'Genetic Transcription', 'Genomics', 'Goals', 'Gonadal Steroid Hormones', 'Hematopoiesis', 'Hematopoietic', 'Hematopoietic stem cells', 'Hormones', 'Inflammation', 'Inflammatory', 'Inherited', 'International', 'Lead', 'Length', 'Link', 'Lung', 'Machine Learning', 'Marrow', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'National Heart, Lung, and Blood Institute', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Immunity', 'Organ failure', 'Pancytopenia', 'Patient Recruitments', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Plasma', 'Polychondritis', 'Population', 'Proteins', 'Protocols documentation', 'Psoriasis', 'RNA', 'RNA-Directed DNA Polymerase', 'Randomized', 'Recurrence', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'Somatic Mutation', 'Specificity', 'Suggestion', 'Syndrome', 'Telomerase', 'Telomere Maintenance', 'Telomere Shortening', 'Testing', 'Toxic effect', 'United States National Institutes of Health', 'Vacuole', 'Variant', 'Vasculitis', 'Work', 'bone marrow failure syndrome', 'chromosome fusion', 'clinical efficacy', 'clinical phenotype', 'comparative', 'cytokine', 'cytopenia', 'design', 'genetic risk factor', 'genome integrity', 'genome-wide analysis', 'human disease', 'improved', 'inclusion criteria', 'male', 'men', 'monocyte', 'novel', 'patient screening', 'predictive modeling', 'pulmonary function', 'repaired', 'screening', 'supervised learning', 'telomere', 'tumorigenesis']",NHLBI,"NATIONAL HEART, LUNG, AND BLOOD INSTITUTE",ZIA,2020,1041424,0.01729516790964121
"Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations PROJECT SUMMARY/ABSTRACT  Myosins are a diverse and ubiquitous class of molecular motors that are responsible for generating much of the macroscopic force in the human body. The human genome encodes 38 different isoforms of myosin, and members of this group act as force sensors or generators for a diverse set of processes throughout the body. To serve this wide array of functions, each myosin isoform has been biophysically tuned for its physiological role. In fact, the tuning is so precise that missense variants in one myosin isoform, !-cardiac myosin, can cause a congenital cardiomyopathy that is the leading cause of sudden cardiac death in people under 30. And yet, it is unknown how particular variants cause disease, or how to infer the pathogenic potential for novel mutations.  Large differences in functional properties between myosin isoforms are not the result of large differences in coding sequence or overall topology. Neither foreknowledge of phylogeny nor crystal structure is sufﬁcient to predict an isoform's biophysical properties. Furthermore, mutations causing disease frequently occur in regions of the protein far from the site of their deleterious effects. Poor understanding of the biophysical regulation of motor function has hampered the development of pharmaceuticals and the interpretation of human genomic data.  My goal is to establish a mechanistic understanding of myosin motors that is capable of predicting if and how sequence variation changes biophysical properties and can cause cardiac disease. Since myosin kinetics are not apparent from sequence or overall structure, they must be determined by other factors. I hypothesize that kinetic differences result from differences in the allosteric networks in these proteins. Allosteric network in this context refers to the coordinated conformational ﬂuctuations that give protein regulation the appearance of action at a distance. To test this hypothesis, we will use our unique combination of enormous computational power for molecular simulation and cutting-edge machine learning tools for analyzing protein allostery.  Aim 1 is to identify the biophysical determinants of myosin isoforms' differing speeds. To test our hypothesis that allosteric networks are responsible for modulating dynamics, I will use molecular simulations of different myosin isoforms and compare their allosteric networks with biochemical data about their properties. Aim 1 directly addresses outstanding questions about normal molecular-biological function of the heart, putting it in line with NHLBI overarching objective #1.  Aim 2 is to determine the difference, at atomic resolution, between healthy and diseased !-cardiac myosin. I hypothesize that the pathogenicity of variants with an unknown molecular etiology is a consequence of allosteric disruption, and will use our computational tools to test this hypothesis by simulating a set of known-pathogenic variants. This aim uses techniques from data science to understand the genetic determinants of health, and will apply equally well to rare alleles in under-represented groups as to majority groups. It is directly addresses NHLBI overarching objectives #3, #4, and #7. PROJECT NARRATIVE  Myosins are a closely-related group of molecules that are responsible for generating much of the force in the human body, including the heartbeat, the movement of limbs, and driving food through the stomach and intestines. Small changes to the myosin genes can have large effects: in healthy people, these give rise to different myosins that perform different functions, and mutations in some myosin genes can give rise to diseases that cause of sudden cardiac death. This proposal aims to learn, at the level of atoms and interatomic bonds, why and how these subtle changes to the myosin gene can create such large effects in the protein's function.",Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations,9881184,F30HL146052,"['Actins', 'Address', 'Affinity', 'Appearance', 'Automobile Driving', 'Behavior', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Process', 'Biophysics', 'Cardiac Myosins', 'Cardiomyopathies', 'Catalysis', 'Chemistry', 'Clinical', 'Code', 'Congenital cardiomyopathy', 'Crystallization', 'Data', 'Data Science', 'Development', 'Disease', 'Drug Binding Site', 'Etiology', 'Food', 'Genes', 'Genetic Determinism', 'Genetic Variation', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Genome', 'Human body', 'Intestines', 'Kinetics', 'Learning', 'Machine Learning', 'Measures', 'Membrane Proteins', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'National Heart, Lung, and Blood Institute', 'Pathogenicity', 'Patient risk', 'Pharmacologic Substance', 'Phenotype', 'Phylogeny', 'Physics', 'Physiological', 'Process', 'Property', 'Protein Analysis', 'Protein Isoforms', 'Protein Region', 'Proteins', 'Regulation', 'Relaxation', 'Resolution', 'Risk stratification', 'Role', 'Signal Transduction', 'Site', 'Solvents', 'Speed', 'Stomach', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Underrepresented Groups', 'Variant', 'base', 'biophysical properties', 'computerized tools', 'disease-causing mutation', 'force sensor', 'genomic data', 'heart function', 'improved', 'insight', 'limb movement', 'member', 'millisecond', 'molecular dynamics', 'novel', 'precision medicine', 'protein function', 'prototype', 'rare variant', 'rat Ran 2 protein', 'simulation', 'sudden cardiac death', 'tool', 'whole genome']",NHLBI,WASHINGTON UNIVERSITY,F30,2020,48719,-0.01260354005762897
"Statistical genetics of aging-related genomic and phenotypic change To help to analyze and understand aging-related ""complex"" traits that are affected by many genes and environmental factors, we have followed the path of developing statistical algorithms for the analyses of genome-wide genotyping and high-throughput sequencing studies. Our proposed new computational tools provide means to analyze additional types of data e.g., to identify mitochondrial DNA (mtDNA) variants and to estimate mtDNA copy number efficiently from whole-genome sequences. For experimental tests of the algorithms, we are capitalizing on the special advantages of the InCHIANTI project (see Annual Report AG001050) and SardiNIA project (see Annual Report AG000675) to help in the assembly of mitochondrial sequence data and multiple phenotypic data in the two Italian cohorts.   In order to conduct analyses on large-scale consortium data to study mtDNA variation and copy number, we have developed two computational programs, providing a general solution for the analysis of mtDNA dynamics based on whole-genome sequencing studies. One program (mitoCaller) is designed specifically to identify mtDNA variants; the other (mitoCalc) infers mtDNA copy number in a cell directly from genome sequences. Applying the programs to leukocyte sequences of 2,000 SardiNIA participants and 1,000 InCHIANTI participants, we have shown that heteroplasmies (mtDNA variants with more than one allele at a site) increase with age, and that copy number is relatively highly heritable and is correlated with metabolic traits, particularly central fat levels. In more recent work, we have increased the speed of mitoCalc 100-fold (fastMitoCalc). The new program is being applied to white cells of 65,000 deeply sequenced individuals (TOPMed program, NHLBI), for GWAS on copy number.   With our expertise in studying mtDNA variation, we have an ongoing collaborative effort to study a special structural feature of DNA, G-quadruplex (G4) structures, as potential DNA roadblocks that perturb mitochondrial replication machinery. We used computational analyses of 3,000 individual genomes from two Italian cohorts to demonstrate an association between G4s and mtDNA variation. Using the software G4Hunter to predict G4-forming regions in mtDNA, we found statistically significant enrichment of mutations in stable G4 regions, with preferential occurrence of variants in the loop segments of G4 structures. Biochemical studies demonstrated a potent block of human mitochondrial replicative polymerase in DNA synthesis by G4 structure, which could be overcome by the G4-resolving helicase Pif1. Altogether, the computational and biochemical approaches indicate that mtDNA point mutations are enriched at stable G4 structures, consistent with replisome stalling at G-quadruplexes and reliance on error-prone DNA synthesis.  Expanding our other focus on the mtDNA copy number (mtDNAcn) analysis, we are setting out to examine the association between mtDNAcn and personality in participants of the Baltimore Longitudinal Study of Aging (BLSA). We assess the big five personality traits and facets using the Revised NEO Personality Inventory (NEO-PI-R) and estimate mtDNAcn efficiently from whole-genome DNA sequences. Our preliminary analyses show that mtDNAcn is significantly associated with specific domains of the personality inventory. We are currently performing mediation analysis to study the potential impact of mtDNAcn on the relationship between certain personality traits and mortality.  In another study, we have created a program that uses machine learning methods to measure effective rates of aging for individuals. We assess the extent to which an individual's physiological age could be determined as a composite score inferred from a broad range of biochemical and physiological traits from the SardiNIA and InCHIANTI longitudinal studies of aging. Physiological age inferred from our framework was highly correlated with chronological age (R2>0.8). We then defined a physiological aging rate (PAR) for each subject, a continuous trait measured as the ratio of the subjects predicted physiological age to his/her chronological age. We found that PARs were reproducible across follow-up studies, heritable (h20.3), and predictive of lifespan and mortality. Genome-wide association studies (GWAS) on the PARs identified both previously established age-associated loci and several new genetic associations. Our findings support a whole-body, pathology-independent aging effect that can be summarized by the physiological aging rate and our method can be used to evaluate the efficacy of treatments that target aging-related processes and disease. n/a",Statistical genetics of aging-related genomic and phenotypic change,10259330,ZIAAG000693,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Algorithms', 'Alleles', 'Ally', 'Annual Reports', 'Baltimore', 'Biochemical', 'Case-Control Studies', 'Cells', 'Chronology', 'Complex', 'Computer Analysis', 'Computer software', 'DNA', 'DNA Sequence', 'DNA biosynthesis', 'DNA copy number', 'Data', 'Disease', 'Environmental Risk Factor', 'Fatty acid glycerol esters', 'Follow-Up Studies', 'G-Quartets', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Leukocytes', 'Longevity', 'Longitudinal Studies', 'Measures', 'Mediation', 'Metabolic', 'Methods', 'Mitochondria', 'Mitochondrial DNA', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Nuclear', 'Participant', 'Pathology', 'Personality', 'Personality Traits', 'Personality inventories', 'Phenotype', 'Physiological', 'Point Mutation', 'Polymerase', 'Population Control', 'Process', 'Reproducibility', 'Risk', 'Sardinia', 'Sequence Deletion', 'Single Nucleotide Polymorphism', 'Site', 'Speed', 'Statistical Algorithm', 'Structure', 'Testing', 'Trans-Omics for Precision Medicine', 'Treatment Efficacy', 'Variant', 'Work', 'age effect', 'base', 'cohort', 'computerized tools', 'design', 'genetic analysis', 'genetic association', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'helicase', 'machine learning method', 'mortality', 'phenotypic data', 'programs', 'trait', 'whole genome']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2020,1547874,-0.006785091061171083
"Computational approaches for identifying epigenomic contexts of somatic mutations ABSTRACT During normal development, aging, and diseases such as cancer, DNA damage due to endogenous and external factors, and repair defects result in accumulation of different types of somatic mutations including single nucleotide substitutions, small InDels, copy number alterations, translocations, and ploidy changes. While a vast majority of somatic mutations in the genome are not disease drivers, their patterns of genetic changes and associated context can provide insights into past exposure to mutagens, mechanisms of DNA damage and repair defects, and extent of genomic instability, which are important for understanding disease etiology, minimizing hazardous environmental exposure, and also predicting efficacy of emerging treatment strategies such as immunotherapy. A number of mutation signatures have been identified based on local sequence contexts to address this need. But, mechanisms of DNA damage and repair preferences depend on both local sequence and epigenomic contexts, and it remains to be understood whether epigenomic contexts of emerging mutation signatures can provide critical, complementary etiological insights at a genome-wide scale, which are not apparent from sequence contexts alone. This is of fundamental importance, because (i) etiology of many of the emerging mutation signatures is currently unknown, (ii) DNA damage response and repair depends on tissue contexts, and defects in core DNA repair genes often result in cancer development in tissue-specific manner, and (iii) differences in the extent of DNA damage and repair between stem and differentiated cells within the same tissues have consequences for aging and disease incidence rates. Built logically on our previous works, we propose to develop computational approaches to determine the impact of epigenomic contexts on the patterns of somatic mutations within and across tissue types, and validate computational predictions using targeted experiments. In Aim-1, we will develop an epigenomic context preference map for emerging mutation signatures. In Aim-2, we will determine the basis of tissue-dependent differences in mutation profiles attributed to DNA repair defects. In Aim-3, we will predict the extent of cell lineage-dependent patterns of mutation accumulation from the mutational landscape of terminal cells. I am currently an early stage investigator, and the proposal is aligned with my long-term goal to identify fundamental principles of mutability and evolvability of somatic genomes. Our project will deliver novel resources and knowledge for addressing questions regarding genomic integrity during development and aging, and diseases such as cancer. ! PUBLIC HEALTH RELEVANCE: The proposed project will use computational biology approaches to determine epigenomic context preference for somatic mutations, and use that to infer tissue-dependent changes in mutation patterns. Our results will provide fundamental insights into aspects of genome maintenance, which is important for advancing our understanding of cancer etiology, reducing exposure to mutagenic factors, and also predicting efficacy of emerging treatment strategies. !",Computational approaches for identifying epigenomic contexts of somatic mutations,9902467,R01GM129066,"['Address', 'Affect', 'Aging', 'Biometry', 'Blood', 'Cancer Etiology', 'Cancer Relapse', 'Cell Differentiation process', 'Cell Line', 'Cell Lineage', 'Cells', 'Chromatin', 'Clinical', 'Computational Biology', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'Data', 'Defect', 'Development', 'Disease', 'Doctor of Philosophy', 'Environmental Exposure', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exposure to', 'Genome', 'Genomic DNA', 'Genomic Instability', 'Genomics', 'Goals', 'Immunotherapy', 'Incidence', 'Knowledge', 'Least-Squares Analysis', 'Location', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutagenesis', 'Mutagens', 'Mutation', 'Nuclear', 'Nucleotides', 'Pathway interactions', 'Pattern', 'Ploidies', 'Point Mutation', 'Process', 'Publishing', 'Radiation Tolerance', 'Research Personnel', 'Resources', 'Role', 'Somatic Mutation', 'Source', 'Tissues', 'Work', 'base', 'cancer genomics', 'computer framework', 'epigenomics', 'experimental study', 'genome integrity', 'genome-wide', 'human tissue', 'improved', 'insertion/deletion mutation', 'insight', 'markov model', 'medical schools', 'novel', 'preference', 'public health relevance', 'random forest', 'repaired', 'response', 'stem', 'stem cells', 'tissue stem cells', 'transcriptomics', 'treatment strategy']",NIGMS,RBHS -CANCER INSTITUTE OF NEW JERSEY,R01,2020,324350,0.0462670464158194
"Comparative Analysis Of Completely Sequenced Genomes The rapidly growing database of completely and nearly completely sequenced genomes of bacteria, archaea, eukaryotes and viruses (several thousand genomes already available and many more in progress) creates both extensive new opportunities and major new challenges for genome research. During the year in review, we performed a variety of studies that took advantage of the genomic information to establish fundamental principles of genome evolution.   To a large extent, we have focused on cancer genome evolution. Cancer arises through the accumulation of somatic mutations over time. Driver mutations and chromosomal aneuploidy are major determinants of tumorigenesis that exhibit complex relationships. We applied deep learning techniques to identify associations between driver mutations and chromosomal aberrations that define two tumor clusters, with distinct regimes of tumor evolution underpinned by unique sets of mutations in different components of DNA damage response. Gastrointestinal and endometrial tumors comprise a separate cluster for which chromosomal-arm aneuploidy and driver mutations are mutually exclusive. The landscape of driver mutations in these tumors is dominated by mutations in DNA repair genes that are further linked to microsatellite instability. The rest of the cancer types show a positive association between driver mutations and aneuploidy, and a characteristic set of mutations that involves primarily genes for components of the apoptotic machinery. The distinct sets of mutated genes derived here show substantial prognostic power and suggest specific vulnerabilities of different cancers that might have therapeutic potential.   We continued and expanded intensive research into evolutionary genomics of viruses and antivirus defense systems. In particular, we carried out extensive analyses of metagenomic datasets that have become the principal source of new virus discovery. RNA viruses in aquatic environments remain poorly studied. We analyzed the RNA virome from approximately 10 l water from Yangshan Deep-Water Harbour near the Yangtze River estuary in China and identified more than 4,500 distinct RNA viruses, doubling the previously known set of viruses. Phylogenomic analysis identified several major lineages, roughly, at the taxonomic ranks of class, order and family. The 719-member-strong Yangshan virus assemblage is the sister clade to the expansive class Alsuviricetes and consists of viruses with simple genomes that typically encode only RNA-dependent RNA polymerase (RdRP), capping enzyme and capsid protein. Several clades within the Yangshan assemblage independently evolved domain permutation in the RdRP. Another previously unknown clade shares ancestry with Potyviridae, the largest known plant virus family. The 'Aquatic picorna-like viruses/Marnaviridae' clade was greatly expanded, with more than 800 added viruses. Several RdRP-linked protein domains not previously detected in any RNA viruses were identified, such as the small ubiquitin-like modifier (SUMO) domain, phospholipase A2 and PrsW-family protease domain. Multiple viruses utilize alternative genetic codes implying protist (especially ciliate) hosts. The results reveal a vast RNA virome that includes many previously unknown groups. However, phylogenetic analysis of the RdRPs supports the previously established five-branch structure of the RNA virus evolutionary tree, with no additional phyla.   Capitalizing on the new RNA virus discoveries and other research on virus evolution, we reconstructed a comprehensive scenario of the evolution of viruses and employed to propose a new hierarchical taxonomy of viruses that has been approved by the International Committee on Taxonomy of Viruses and implemented in GenBank and other databases. Viruses and mobile genetic elements are molecular parasites or symbionts that coevolve with nearly all forms of cellular life. The route of virus replication and protein expression is determined by the viral genome type. Comparison of these routes led to the classification of viruses into seven ""Baltimore classes"" (BCs) that define the major features of virus reproduction. However, recent phylogenomic studies identified multiple evolutionary connections among viruses within each of the BCs as well as between different classes. Due to the modular organization of virus genomes, these relationships defy simple representation as lines of descent but rather form complex networks. Phylogenetic analyses of virus hallmark genes combined with analyses of gene-sharing networks show that replication modules of five BCs (three classes of RNA viruses and two classes of reverse-transcribing viruses) evolved from a common ancestor that encoded an RNA-directed RNA polymerase or a reverse transcriptase. Bona fide viruses evolved from this ancestor on multiple, independent occasions via the recruitment of distinct cellular proteins as capsid subunits and other structural components of virions. The single-stranded DNA (ssDNA) viruses are a polyphyletic class, with different groups evolving by recombination between rolling-circle-replicating plasmids, which contributed the replication protein, and positive-sense RNA viruses, which contributed the capsid protein. The double-stranded DNA (dsDNA) viruses are distributed among several large monophyletic groups and arose via the combination of distinct structural modules with equally diverse replication modules. Phylogenomic analyses reveal the finer structure of evolutionary connections among RNA viruses and reverse-transcribing viruses, ssDNA viruses, and large subsets of dsDNA viruses. Taken together, these analyses allow us to outline the global organization of the virus world. Here, we describe the key aspects of this organization and propose a comprehensive hierarchical taxonomy of viruses.   A more theoretically oriented project involved reconstruction of the virome of the Last Universal Cellular Ancestor (LUCA) informed by comparative genomics. The LUCA is the most recent population of organisms from which all cellular life on Earth descends. The reconstruction of the genome and phenotype of the LUCA is a major challenge in evolutionary biology. Given that all life forms are associated with viruses and/or other mobile genetic elements, there is no doubt that the LUCA was a host to viruses. By projecting back in time using the extant distribution of viruses across the two primary domains of life, bacteria and archaea, and tracing the evolutionary histories of some key virus genes, we attempted a reconstruction of the LUCA virome. Even a conservative version of this reconstruction suggests a remarkably complex virome that already included the main groups of extant viruses of bacteria and archaea. We further presented evidence of extensive virus evolution antedating the LUCA. The presence of a highly complex virome implies the substantial genomic and pan-genomic complexity of the LUCA itself.   Taken together, these studies advance the existing understanding of the general principles and specific aspects of genome evolution in diverse life forms, in particular, viruses and mobile elements, as well as cancer genome evolution. n/a",Comparative Analysis Of Completely Sequenced Genomes,10261216,ZIALM000073,"['Affect', 'Aneuploidy', 'Apoptotic', 'Archaea', 'Back', 'Bacteria', 'Baltimore', 'Biology', 'Capsid', 'Capsid Proteins', 'Characteristics', 'China', 'Chromosome abnormality', 'Complex', 'Computing Methodologies', 'DNA Damage', 'DNA Repair Gene', 'Data', 'Data Set', 'Databases', 'Double Stranded DNA Virus', 'Elements', 'Endometrial Neoplasms', 'Environment', 'Enzymes', 'Eukaryota', 'Evolution', 'Exhibits', 'Family', 'Gastrointestinal Neoplasms', 'Genbank', 'Genes', 'Genetic Code', 'Genetic Recombination', 'Genome', 'Genomics', 'Goals', 'Horizontal Gene Transfer', 'Individual', 'International', 'Life', 'Link', 'Malignant Neoplasms', 'Metagenomics', 'Microsatellite Instability', 'Mobile Genetic Elements', 'Molecular', 'Mutate', 'Mutation', 'Organism', 'Orthologous Gene', 'Parasites', 'Phenotype', 'Phospholipase A2', 'Phylogenetic Analysis', 'Phylogeny', 'Planet Earth', 'Plant Viruses', 'Plasmids', 'Population', 'Potyviridae', 'Process', 'Protease Domain', 'Proteins', 'RNA', 'RNA Viruses', 'RNA analysis', 'RNA-Directed DNA Polymerase', 'RNA-Directed RNA Polymerase', 'Recording of previous events', 'Reproduction', 'Research', 'Rest', 'Rivers', 'Route', 'Single Stranded DNA Virus', 'Sister', 'Somatic Mutation', 'Source', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Tertiary Protein Structure', 'Therapeutic', 'Time', 'Trees', 'Ubiquitin', 'Uncertainty', 'Viral Genome', 'Viral Proteins', 'Virion', 'Virus', 'Virus Replication', 'Water', 'arm', 'cancer genome', 'cancer type', 'comparative', 'comparative genomics', 'deep learning', 'driver mutation', 'genome-wide', 'insight', 'link protein', 'mathematical methods', 'mathematical model', 'member', 'novel', 'paralogous gene', 'prognostic value', 'protein expression', 'reconstruction', 'recruit', 'response', 'symbiont', 'time use', 'trend', 'tumor', 'tumorigenesis', 'viral genomics', 'virome', 'virus classification', 'whole genome']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2020,2379122,0.014898845468639841
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9959498,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Models', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'Visualization', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2020,360268,0.016186260299984045
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,10145865,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'learning classifier', 'molecular dynamics', 'mutant', 'nonsynonymous mutation', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2020,9815,0.048399135583241965
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,10260680,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,177000,0.08061725587836148
"Predicting and analyzing variation in cellular interactomes Project Summary Over the last two decades, significant experimental efforts have determined large sets of “reference” interactions for humans and other model organisms, along with substantial knowledge about the binding specificities of proteins, including for a large fraction of human transcription factors (TFs). The resulting data have proven to be an incredibly useful resource for understanding how cells function; nevertheless, they do not capture how molecular interactions and networks are different from the reference across individuals. Indeed, while human genomes in both healthy and disease populations are rapidly being sequenced, the corresponding individual-specific interaction networks remain largely unexamined; this represents a major gap in our knowledge, as mutations that alter molecular interactions underlie a wide range of human diseases. Further, the substantial amount of genetic variation across populations makes it infeasible in the near term to experimentally determine per-individual interaction networks. Thus our long-term goal is to develop computational methods to uncover whether and how mutations within coding and non-coding portions of the genome perturb cellular interactions and networks. Our specific aims are: (1) We will develop computational structure-based approaches to identify and catalog, at proteome-scale, variations within proteins that are likely to impact their ability to bind with DNA, RNA, small molecules, peptides or ions, thereby providing a comprehensive resource for analyzing protein interaction variation. (2) We will develop novel structure-based and probabilistic methods to predict how DNA-binding specificities are altered when a TF is mutated; since mutated TFs have been linked to numerous diseases, this will be a great aid in understanding disease networks and pathology. (3) We will develop new methods to uncover non-coding somatic mutations that alter human regulatory networks in cancer; this is a critical step towards ultimately uncovering patient-specific cancer networks. Overall by pursuing these aims—which integrate mutational information with existing knowledge about reference interactions, interfaces and specificities—we will develop novel computational methods that will significantly advance our understanding of molecular interactions perturbed in disease and healthy contexts. Narrative The proposed research will yield new software tools that predict whether specific genetic mutations alter molecular interactions and networks. Since many human diseases are caused by mutations that affect molecular interactions, this research will expand our understanding of the underlying basis of disease and will provide new avenues for diagnosis and treatment.",Predicting and analyzing variation in cellular interactomes,9896829,R01GM076275,"['Affect', 'Alleles', 'Amino Acid Sequence', 'Animal Model', 'Binding', 'Binding Proteins', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Process', 'Catalogs', 'Cell physiology', 'Code', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Binding', 'DNA Sequence Alteration', 'DNA-Protein Interaction', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Human Genome', 'Individual', 'Infrastructure', 'Internet', 'Ions', 'Knowledge', 'Ligand Binding', 'Link', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Mutagenesis', 'Mutate', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Organism', 'Pathology', 'Patients', 'Pattern', 'Peptides', 'Play', 'Population', 'Property', 'Protein Analysis', 'Proteins', 'Proteome', 'RNA', 'Regulator Genes', 'Research', 'Resources', 'Sampling', 'Site', 'Software Tools', 'Somatic Mutation', 'Specificity', 'Structure', 'Untranslated RNA', 'Variant', 'Work', 'Zinc Fingers', 'base', 'cancer genome', 'disease-causing mutation', 'experimental study', 'human disease', 'improved', 'interest', 'knowledge base', 'machine learning method', 'novel', 'predictive tools', 'preference', 'small molecule', 'software development', 'transcription factor', 'tumor', 'virtual']",NIGMS,PRINCETON UNIVERSITY,R01,2020,312660,0.005758898806581461
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9957082,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,193576,0.08061725587836148
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,9970939,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2020,523409,-0.01091863775515014
"RNA Sequencing Via Single Reverse Transcript Assessments Project Summary While very substantial progress has been made over the last 10 or so years with regards to next generation sequencing (NGS) and third generation sequencing (TGS) of DNA, the development of novel and enabling tool sets for RNA sequencing has lagged significantly. During this project, we aim to make significant progress with regards to that gap by developing and validating an entirely new solid-state sequencing platform, developed specifically and ideally for direct RNA sequencing, including its structural complexities and nucleotide modifications, all with high accuracy. While there are over 100 known RNA nucleotide modifications, due to the lack of analytical characterization methods available, the exact roles of these modifications remain to be determined. The technology that will be developed during the project will be capable of elucidating the roles of these modifications, and revolutionizing our understanding and use of the transcriptome/epitranscriptome. Project Narrative A method/technology capable of directly (without transcription) sequencing RNA, with extremely high accuracy and the inherent ability to identify nucleotide modifications, has the potential to revolutionize the use of the transcriptome and epitranscriptome, radically change standard R&D practices, as well as enable revolutionary diagnostics and therapeutics. The entirely new direct RNA sequencing methodology/technology that will be developed during this project will overcome known hurdles and limitation with currently available NGS, TGS, and single-molecule sequencing (SMS) approaches, resulting in technology that is cost efficient, highly accurate, easy-to setup and utilize, capable of de novo sequencing and modified base calling, and capable of producing highly simplistic data for easy analysis and post possessing.",RNA Sequencing Via Single Reverse Transcript Assessments,9961426,R43HG011070,"['Biological', 'Biological Sciences', 'Caliber', 'Carbon Nanotubes', 'Chemistry', 'Complex', 'DNA', 'DNA sequencing', 'DNA-Directed RNA Polymerase', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Devices', 'Diagnostic', 'Drops', 'Electrodes', 'Enzymes', 'Evaluation', 'Future', 'Genetic Transcription', 'Genomics', 'Geometry', 'Glass', 'Goals', 'Individual', 'Inosine', 'Ions', 'Label', 'Length', 'Lipid Bilayers', 'Logistics', 'Machine Learning', 'Measurement', 'Mediating', 'Methodology', 'Methods', 'Modification', 'Monitor', 'Motor', 'Movement', 'Noise', 'Nucleotides', 'Phase', 'Polymerase', 'Preparation', 'Process', 'Proteins', 'Pseudouridine', 'RNA', 'RNA primers', 'RNA-Directed DNA Polymerase', 'Reader', 'Reading Frames', 'Reproducibility', 'Risk', 'Role', 'Sampling', 'Series', 'Side', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'Systems Development', 'Technology', 'Therapeutic', 'Third Generation Sequencing', 'Time', 'Transcript', 'Transistors', 'Variant', 'base', 'clinical diagnostics', 'complex data ', 'cost', 'cost efficient', 'electric field', 'epigenomics', 'epitranscriptome', 'epitranscriptomics', 'experimental study', 'improved', 'infancy', 'nanopore', 'neural network', 'new technology', 'next generation sequencing', 'novel', 'programs', 'research and development', 'sequencing platform', 'single molecule', 'solid state', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics']",NHGRI,"ELECTRONIC BIOSCIENCES, INC.",R43,2020,279999,0.0033216061440678544
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",10116927,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analysis pipeline', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic testing', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2020,864183,-0.02776878449534329
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9923466,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large scale data', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,446831,-0.014359754974416708
"Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration PROJECT SUMMARY The cell nucleus is a heterogeneous organelle that consists of nuclear bodies such as nuclear lamina, speckles, nucleoli and PML bodies. These structures continuously tether and tug chromatin at the small and large scales to synergistically orchestrate dynamic functions in distinct spatio-temporal compartments. A major obstacle to the production of navigable 4D reference maps and relating structure to function in the nucleus remains understanding how these different scales of organization influence each other. In particular, we have a poor understanding of the large-scale genome organization. Growing evidence suggests that such nuclear compartmentalization is causally connected with vital genome functions in human health and disease. However, the principles of this nuclear compartmentalization, its dynamics during changes in cell conditions, and its functional relevance are poorly understood. One lesson from Phase 1 4DN was the huge gap in throughput between imaging methods, that directly measure large-scale multi-landmark relationships, and genomic methods, that aim for whole genome high-resolution maps but are indirect measurements and provide limited information about large-scale compartments. For this 4DN UM1 Center application, we propose to meet these needs through the following Aims: (1) Generate multi-modal imaging and genomic datasets to reveal the structure, dynamics, and function of nuclear compartmentalization; (2) Develop and apply computational tools for data-driven genome structure modeling and integrative analysis of nuclear compartmentalization; (3) Develop an integrative analysis and visualization platform with navigable 4D reference maps of nuclear organization. The combined datasets and results of our proposed approaches will advance our understanding of nuclear compartmentalization, the interwoven connections among different nuclear components, and their functional significance. Our new integrative analysis tools and data-driven predictive models will produce more complete nuclear organization reference maps that integrate large-scale chromosome structure data from live and super-resolution microscopy with multi-modal genomic data including smaller scale chromatin interaction maps and predict functional relationships and dynamic responses. Our navigable reference maps will be publicly accessible through an analysis platform that provides interactive visualization of multiple data types, thus enabling investigators with diverse expertise to simultaneously explore their own data and related datasets/tools and promoting collaborations that will open new horizons into the role of the 4D nucleome in human health and disease. PROJECT NARRATIVE The proposed research is relevant to public health because it will enhance our understanding of nuclear genome organization and functions that are increasingly being linked to health and disease. Because we develop tools to disseminate this information and enable others to work with our data and their own data, we will also bring nuclear architecture to bear on a broad range of ongoing health related research. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration,10156141,UM1HG011593,"['Address', 'Architecture', 'Atlases', 'Binding', 'Biochemical', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Chromatin', 'Chromatin Loop', 'Chromatin Structure', 'Chromosome Structures', 'Chromosomes', 'Collaborations', 'Communities', 'Complement', 'Computing Methodologies', 'Cytology', 'DNA Replication Timing', 'Data', 'Data Set', 'Development', 'Disease', 'Formulation', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Interphase Chromosome', 'Intuition', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nuclear', 'Nuclear Lamina', 'Nuclear Structure', 'Organelles', 'Outcome', 'Output', 'Phase', 'Population', 'Production', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Structural Models', 'Structure', 'Technology', 'Three-Dimensional Imaging', 'United States National Institutes of Health', 'Ursidae Family', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'cell cycle genetics', 'cell type', 'computer framework', 'computerized tools', 'data exploration', 'data integration', 'data tools', 'experimental study', 'genome-wide', 'genomic data', 'histone modification', 'imaging modality', 'improved', 'insight', 'machine learning algorithm', 'mental function', 'multimodal data', 'multimodality', 'multiple data types', 'multiscale data', 'predictive modeling', 'response', 'spatiotemporal', 'structured data', 'tool', 'transcription factor', 'transcriptome sequencing', 'user-friendly', 'whole genome']",NHGRI,CARNEGIE-MELLON UNIVERSITY,UM1,2020,2075409,-0.012113089177405013
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,10090262,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,38074,0.041209393669260956
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9882227,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,591815,0.041209393669260956
"Molecular Characterization of Joubert Syndrome Project Summary Congenital ataxia presents in early childhood with non-progressive hypotonia, gross motor, fine motor and cognitive delays. These disorders are distinct from the progressive ataxias because of the presence of congenital cerebellar malformations and because they are typically inherited recessively. Joubert Syndrome and Related Disorders (JSRD) constitute a major subset of these conditions, consisting of a cerebellar midline (vermis) malformation, a nearly pathognomonic Molar Tooth sign on brain Imaging (MTI) and co-existent oculomotor apraxia and episodic breathing dysrhythmias. In our published data, we have: 1] Identified ten unique genetic causes of JSRD (nearly half of the published causes), 2] Generated genotype-phenotype correlations involving cerebellar, retinal, renal, hepatic, digit, and cerebral manifestations. 3] Identified common founder mutations that allow for population-based screening. 4] Discovered that JSRD encoded proteins frequently localize to the cilium. 5] Identified ciliary transition zone (TZ) defects in cells with JSRD mutations. 6] Performed siRNA cell-based screens for defective ciliogenesis to prioritize candidate JSRD genes. 7] Generated and characterized multiple zebrafish, mouse and human cell culture models for JSRD. 8] Defined the concept of ‘Ciliary localization’ model, in which one JSRD gene is required for ciliary localization of other JSRD proteins. In our unpublished data we have: 1] Recruited an additional 200 JSRD patients without molecular diagnosis. 2] Performed whole exome (WES) and whole genome sequencing (WGS) on an additional 100 JSRD families. 3] Identified an additional 12 novel likely JSRD candidate genes. 4] Generated IPSCs and cerebellar organoids from mutation-positive and negative families to aid in functional analysis and gene discovery using RNAseq. 5] Begun functional validation of the putative mutations. 6] Developed methods to interrogate ciliary structure in a high-throughput fashion with electron microscopy (EM). The goal of this competing renewal is to identify the remaining ‘discoverable’ genes that lead to JSRD when lost, functionally validate mutations within the pathogenetic framework, and test the hypothesis that mutations in JSRD genes lead to collapse of the ciliary TZ. Because the majority of patients still have unknown cause of disease, this renewal aims to advance knowledge through molecular characterization of new genes, using newly evolving high-throughput techniques, integrated bioinformatics, and a unique resource of consanguineous families recruited world-wide. We further aim to validate these mutations in patient cells, within a mechanistic framework that JSRD genes are required for essential ciliary structural components during cerebellar development. Project Narrative Joubert syndrome is a genetically and phenotypically heterogeneous neurodevelopmental disorder unified by defects of the cellular primary cilium. This work will identify new genetic causes and dissect ciliary defects associated with genetic mutations.",Molecular Characterization of Joubert Syndrome,9988508,R01NS048453,"['Apraxias', 'Ataxia', 'Bioinformatics', 'Brain imaging', 'Breathing', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Cells', 'Cerebellar malformation', 'Cerebellar vermis structure', 'Cerebrum', 'Cilia', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognitive', 'Congenital cerebellar hypoplasia', 'Cultured Cells', 'Cytoplasmic Granules', 'DNA Sequence Alteration', 'Data', 'Databases', 'Defect', 'Development', 'Digit structure', 'Disease', 'Electron Microscopy', 'Electrons', 'Embryo', 'Enrollment', 'Face', 'Family', 'Gene Mutation', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Gold', 'Hepatic', 'Human', 'Individual', 'Inherited', 'Joubert syndrome', 'Kidney', 'Knock-out', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Microscopic', 'Middle East', 'Modeling', 'Molar tooth', 'Molecular', 'Molecular Diagnosis', 'Morphogenesis', 'Morphology', 'Motor', 'Mus', 'Muscle hypotonia', 'Mutation', 'Neurodevelopmental Disorder', 'Organoids', 'Pathogenicity', 'Patients', 'Phenotype', 'Probability', 'Protein Analysis', 'Proteins', 'Publishing', 'Resources', 'Retina', 'Risk', 'Scanning Electron Microscopy', 'Series', 'Severities', 'Signal Transduction', 'Small Interfering RNA', 'Sonication', 'Structure', 'Syndrome', 'Techniques', 'Termination of pregnancy', 'Testing', 'Three-dimensional analysis', 'Training', 'Transmission Electron Microscopy', 'Validation', 'Variant', 'WNT Signaling Pathway', 'Work', 'Zebrafish', 'accurate diagnosis', 'affection', 'base', 'cell type', 'cilium biogenesis', 'cohort', 'consanguineous family', 'disorder subtype', 'early childhood', 'exome', 'exome sequencing', 'fetal', 'founder mutation', 'gene discovery', 'genetic testing', 'genome sequencing', 'genome-wide', 'insight', 'knock-down', 'loss of function mutation', 'malformation', 'mutant', 'novel', 'oculomotor', 'population based', 'reconstruction', 'recruit', 'screening', 'stem cell biology', 'transcriptome sequencing', 'whole genome']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,510012,0.02615266583553004
