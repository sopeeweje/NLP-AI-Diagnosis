text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Contextual ASR to Support EHR Adoption    DESCRIPTION (provided by applicant): The adoption of electronic health record (EHR) systems is a national healthcare priority. However studies show massive physician productivity drop of up to 25-40% upon transition to EHR. The majority of workflow delay is based on the need to perform manual operations to fill structured forms within the EHR, as opposed to simple unstructured narratives used in traditional written notes and transcriptions. Vanguard Medical Technologies (VMT), under NIH grant 1R43LM010750, proved feasibility for DocTalk, a real-time, speech-driven, open-source augmented, small practice encounter recording system that processes voice to text to structured medical data to EHR input, utilizing integrated automated speech recognition (ASR) and natural language processing (NLP) in the cloud. While NLP accuracy in Phase I was high, voice accuracy prior to physician review was inadequate. Fortunately, the tight integration of ASR and NLP combined with the formal structure of physician notes offers unique context based approaches to address the challenge. Current speech recognition methods use a single general-purpose medical lexicon to train a recognizer when identifying words. Medical context-specific probabilities are ignored. The four Specific Aims of this Phase I SBIR project are to: 1. Create a textual corpus for each section of a patient encounter note by processing 1 million text based narrative structured encounter notes 2. Build a family of Section-Specific Statistical Language Models (SS-SLMs) specialized in recognizing speech pertaining to each specific section of a patient encounter note, using industry standard open source statistical language modeling tools. 3. Use NLP techniques to infer patterns of language usage from text of each section, a. To detect section boundaries to be used as trigger words for invoking SS-SLMs b. To determine characteristic word distributions of each section 4. Assess improvement in accuracy per section due to use of SS-SLMs, with the goal of 50% overall reduction of errors compared to non-section-specific SLMs in the same medical dictation system.      PUBLIC HEALTH RELEVANCE: Successful completion of this innovative proposed program of NLP-enhanced context based ASR, will provide the accuracy required to deploy an integrated, interactive, intuitive, low-cost data entry system for small practice primary care physicians. The augmented DocTalk system will enable physicians to increase usable information, avoid third-party transcription errors, and mitigate workflow delays. Increased small practice EHR adoption directly addresses national healthcare goals.              Successful completion of this innovative proposed program of NLP-enhanced context based ASR, will provide the accuracy required to deploy an integrated, interactive, intuitive, low-cost data entry system for small practice primary care physicians. The augmented DocTalk system will enable physicians to increase usable information, avoid third-party transcription errors, and mitigate workflow delays. Increased small practice EHR adoption directly addresses national healthcare goals.            ",Contextual ASR to Support EHR Adoption,8253003,R43TR000179,"['Address', 'Adoption', 'Characteristics', 'Code', 'Data', 'Documentation', 'Drops', 'Electronic Health Record', 'Electronics', 'Family', 'Genetic Transcription', 'Goals', 'Grant', 'Healthcare', 'Industry', 'Language', 'Libraries', 'Manuals', 'Medical', 'Medical Records', 'Medical Technology', 'Methods', 'Modeling', 'Natural Language Processing', 'Patients', 'Pattern', 'Phase', 'Physicians', 'Positioning Attribute', 'Primary Care Physician', 'Probability', 'Process', 'Productivity', 'Research Infrastructure', 'Safety', 'Small Business Innovation Research Grant', 'Solutions', 'Speech', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Variant', 'Voice', 'Writing', 'base', 'cost', 'innovation', 'open source', 'operation', 'programs', 'speech recognition', 'tool', 'voice recognition']",NCATS,"HEALTH FIDELITY, INC.",R43,2012,150000,0.025771908977720782
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6717704,P01EB000216,"['automated medical record system', 'health care facility information system', 'radiology', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2004,1723576,0.00881989642103082
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6682850,P01EB000216,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2003,1645392,0.00881989642103082
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6512665,P01EB000216,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2002,2120168,0.00881989642103082
"A Data-mining Approach to CAM Medication Reconciliation    DESCRIPTION (provided by applicant): Due to its complex, multi-herb nature, many patients who use Complementary and Alternative Medicine (CAM) do not have full knowledge of the ingredients included in their remedies. Lack of disclosure about CAM can place patients at risk, as some herbal products can have adverse interactions with pharmaceuticals or cause harmful side effects. This proposal seeks to address that challenge by developing a computer-aided expert system that can algorithmically determine the content of a patient's CAM herbal remedy. In the absence of reliable patient recall, the envisioned system employs proven analytics techniques and a known set of data- including historical patient records and patient-reported data, such as patient demographic and symptomatic details-to statistically generate a prescription list. The envisioned analytics engine will be a powerful clinical decision support tool that enhances patient safety and patient-provider communication surrounding CAM use. Phase I activities will generate a prototype for evaluating one frequently encountered condition: the common cold. This prototype will provide a solid foundation for system expansion, in Phase II, to cover a broad range of diseases and conditions.      PUBLIC HEALTH RELEVANCE: Despite their growing prevalence, Complementary and Alternative Medicine (CAM) therapies are seldom a topic of discussion between healthcare professionals and patients; patient-provider communication and patient disclosure rates are further complicated by the language barrier (Eisenberg et al. 1993). Lack of communication about CAM can place patients at risk, as some herbal products can have adverse interactions with pharmaceuticals or cause harmful side effects (Kupiec et al. 2005). The computer-aided expert system, as envisioned in this application, will fill a critical void in our healthcare system's ability to thoroughly document CAM usage in patient medication history, equip providers to make more informed clinical decisions, and-by avoidance or earlier detection of herb-drug interactions-improve patient safety and quality of care.           Despite their growing prevalence, Complementary and Alternative Medicine (CAM) therapies are seldom a topic of discussion between healthcare professionals and patients; patient-provider communication and patient disclosure rates are further complicated by the language barrier (Eisenberg et al. 1993). Lack of communication about CAM can place patients at risk, as some herbal products can have adverse interactions with pharmaceuticals or cause harmful side effects (Kupiec et al. 2005). The computer-aided expert system, as envisioned in this application, will fill a critical void in our healthcare system's ability to thoroughly document CAM usage in patient medication history, equip providers to make more informed clinical decisions, and-by avoidance or earlier detection of herb-drug interactions-improve patient safety and quality of care.         ",A Data-mining Approach to CAM Medication Reconciliation,8253427,R43TR000361,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Attention', 'Caliber', 'Chinese Traditional Medicine', 'Clinical', 'Common Cold', 'Communication', 'Complementary and alternative medicine', 'Complex', 'Computer Assisted', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disclosure', 'Disease', 'Early Diagnosis', 'Education', 'Educational Materials', 'Evaluation', 'Expert Systems', 'Foundations', 'Health Care Sector', 'Health Personnel', 'Health Professional', 'Health system', 'Healthcare', 'Healthcare Systems', 'Herb', 'Herb-Drug Interactions', 'Hong Kong', 'Immigrant', 'Individual', 'Infection', 'Informatics', 'Information Technology', 'Knowledge', 'Language', 'Libraries', 'Linguistics', 'Mainstreaming', 'Medical', 'Medicine', 'Modeling', 'Monograph', 'Nature', 'Output', 'Patient Education', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Population', 'Preparation', 'Prevalence', 'Printing', 'Protocols documentation', 'Provider', 'Quality of Care', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Services', 'Small Business Innovation Research Grant', 'Solid', 'Solutions', 'Symptoms', 'System', 'Techniques', 'Technology', 'Translating', 'Underserved Population', 'Universities', 'adverse outcome', 'data mining', 'evidence base', 'falls', 'forging', 'frontier', 'improved', 'innovation', 'patient safety', 'preference', 'prototype', 'research and development', 'tool', 'touchscreen']",NCATS,"TRANSCENDENT INTERNATIONAL, LLC",R43,2012,241701,0.02545735921374774
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,7249382,R01EB000362,"['Address', 'Architecture', 'Caring', 'Chronic', 'Clinical', 'Clinical Medicine', 'Complex', 'Computer Architectures', 'Condition', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Documentation', 'Early Diagnosis', 'Effectiveness', 'Engineering', 'Environment', 'Evaluation', 'Evidence Based Medicine', 'Extensible Markup Language', 'Geographic Locations', 'Healthcare', 'Image', 'Imagery', 'Individual', 'Information Management', 'Laboratories', 'Language', 'Link', 'Management Information Systems', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Methodology', 'Metric', 'Multimedia', 'Natural Language Processing', 'Numbers', 'Online Systems', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Problem Solving', 'Procedures', 'Process', 'Provider', 'Radiology Specialty', 'Records', 'Reporting', 'Research', 'Research Design', 'Series', 'Services', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'TimeLine', 'United States', 'Urology', 'Visit', 'base', 'concept', 'cost', 'data acquisition', 'data management', 'data modeling', 'improved', 'information gathering', 'innovation', 'innovative technologies', 'insight', 'peer', 'point of care', 'portability', 'research clinical testing', 'urologic', 'usability']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,517331,0.04301054614847021
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,7083613,R01EB000362,"['automated medical record system', 'clinical research', 'computer assisted medical decision making', 'data collection methodology /evaluation', 'human data', 'informatics', 'information display', 'information system analysis', 'mathematical model', 'medical records', 'outcomes research', 'patient care management', 'performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,535569,0.04301054614847021
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,6917854,R01EB000362,"['automated medical record system', 'clinical research', 'computer assisted medical decision making', 'data collection methodology /evaluation', 'human data', 'informatics', 'information display', 'information system analysis', 'mathematical model', 'medical records', 'outcomes research', 'patient care management', 'performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,593264,0.04301054614847021
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,6749459,R01EB000362,"['automated medical record system', 'clinical research', 'computer assisted medical decision making', 'data collection methodology /evaluation', 'human data', 'informatics', 'information display', 'information system analysis', 'mathematical model', 'medical records', 'outcomes research', 'patient care management', 'performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,594553,0.04301054614847021
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,6678913,R01EB000362,"['automated medical record system', ' clinical research', ' computer assisted medical decision making', ' data collection methodology /evaluation', ' human data', ' informatics', ' information display', ' information system analysis', ' mathematical model', ' medical records', ' outcomes research', ' patient care management', ' performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,572597,0.04301054614847021
"Risk Prediction and Computational Tools for Cancer Patient Adherence.    DESCRIPTION (provided by applicant): Substantial evidence gathered over the last 50 years shows that non-adherence to treatment poses a crucial barrier to effective care and survival for cancer and other chronic diseases. At least one in five cancer patients do not adhere to treatment regimen, with much higher disease-specific rates. This non-adherence, or deviation from the recommended and expected clinical path, can dramatically increase costs of care, hospitalizations, adverse outcomes and the chance of preventable death. What causes non-adherence to treatment regimens is currently not rigorously understood. Current adherence research methods largely rely on survey instruments that have limited scale and scope, provide lagging information that inhibits timely intervention, and offer little actionable information to help patients to adhere to their care regimens. With continuous changes in cancer treatment, newer proactive approaches and methods for surveillance of patient adherence and targeted interventions are needed. In this Phase 2 SBIR project we will examine the validity of a novel approach (based on the completed Phase-1 project) that uses a novel computational algorithm to glean fine- grained attributes of cancer patients from standard electronic medical records. Our preliminary work has shown that most electronic medical records contain free-form text describing patient health progress, sentiment, vitals, medical condition, side effects, and social history written by physicians, nurses, medical assistants, and other staff during every visit encounter. With the steady adoption of electronic medical records by clinicians across the US (currently 29% and rising at 12% per year), clinical notes found in electronic records offer a tantalizing source of insight into patient adherence and behavior. In this Phase-2 SBIR project we aim to commercialize a novel, scalable prototype that can glean a rich set of risk factors for patient non-adherence from 1.5 million patient encounter records, corresponding to 30,050 patients that span a 10 year time-horizon from a community cancer clinic. Our objectives are to estimate the risk of a patient's ability to adhere to a prescribed regimen and enable targeted and timely interventions by using computational analysis of unstructured and structured fields in standard clinical documentation. We also aim to monitor and measure important patient treatment and adherence metrics (e.g. as defined by the American Society of Clinical Oncology) that can play a significant role in tracking high-risk patients for improved patient treatment outcomes, adherence, quality and safety.  Our approach represents a significant, actionable advance over the lagging indicators offered by survey-based methods prevalent in adherence research. Our proposed approach has deep implications for improved quality of care, proactive management of chronic diseases, retention of patients in clinical practice and clinical trials, patient safety, improved patient follow-up and risk assessment, drug and disease surveillance, enablement of new care models, targeted intervention, and improved outcomes by helping patients to better adhere to their regimens.       PUBLIC HEALTH RELEVANCE: We aim to show the feasibility of a commercial early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.            ",Risk Prediction and Computational Tools for Cancer Patient Adherence.,8518494,R44TR000363,"['Adherence', 'Adoption', 'Adverse effects', 'American Society of Clinical Oncology', 'Area', 'Behavior', 'Behavioral', 'Cancer Center', 'Cancer Patient', 'Caring', 'Case Management', 'Case Manager', 'Cereals', 'Cessation of life', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Paths', 'Clinical Trials', 'Communities', 'Community Clinical Oncology Program', 'Computational algorithm', 'Computer Analysis', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Data Set', 'Dictionary', 'Disease', 'Documentation', 'Electronics', 'Emotional', 'Employment', 'Enrollment', 'Family', 'Glean', 'Health', 'Hospitalization', 'Individual', 'Intervention', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Nurses', 'Ontology', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patient Noncompliance', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Protocols documentation', 'Quality of Care', 'Recording of previous events', 'Records', 'Regimen', 'Research', 'Research Methodology', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Role', 'Safety', 'Scientific Advances and Accomplishments', 'Semantics', 'Services', 'Signal Transduction', 'Single-Blind Study', 'Small Business Innovation Research Grant', 'Source', 'Structure', 'Surveillance Methods', 'Surveys', 'System', 'Technology', 'Text', 'Time', 'Treatment Protocols', 'Treatment outcome', 'Visit', 'Weight', 'Work', 'Writing', 'adverse outcome', 'base', 'cancer therapy', 'clinical practice', 'clinically relevant', 'compliance behavior', 'computerized tools', 'cost', 'follow-up', 'high risk', 'improved', 'information model', 'innovation', 'insight', 'mathematical algorithm', 'novel', 'novel strategies', 'oncology', 'patient safety', 'prototype', 'psychologic', 'public health relevance', 'social', 'text searching', 'treatment adherence']",NCATS,"360FRESH, INC.",R44,2013,499892,0.048244800673802476
"Risk Prediction and Computational Tools for Cancer Patient Adherence.    DESCRIPTION (provided by applicant): Substantial evidence gathered over the last 50 years shows that non-adherence to treatment poses a crucial barrier to effective care and survival for cancer and other chronic diseases. At least one in five cancer patients do not adhere to treatment regimen, with much higher disease-specific rates. This non-adherence, or deviation from the recommended and expected clinical path, can dramatically increase costs of care, hospitalizations, adverse outcomes and the chance of preventable death. What causes non-adherence to treatment regimens is currently not rigorously understood. Current adherence research methods largely rely on survey instruments that have limited scale and scope, provide lagging information that inhibits timely intervention, and offer little actionable information to help patients to adhere to their care regimens. With continuous changes in cancer treatment, newer proactive approaches and methods for surveillance of patient adherence and targeted interventions are needed. In this Phase 2 SBIR project we will examine the validity of a novel approach (based on the completed Phase-1 project) that uses a novel computational algorithm to glean fine- grained attributes of cancer patients from standard electronic medical records. Our preliminary work has shown that most electronic medical records contain free-form text describing patient health progress, sentiment, vitals, medical condition, side effects, and social history written by physicians, nurses, medical assistants, and other staff during every visit encounter. With the steady adoption of electronic medical records by clinicians across the US (currently 29% and rising at 12% per year), clinical notes found in electronic records offer a tantalizing source of insight into patient adherence and behavior. In this Phase-2 SBIR project we aim to commercialize a novel, scalable prototype that can glean a rich set of risk factors for patient non-adherence from 1.5 million patient encounter records, corresponding to 30,050 patients that span a 10 year time-horizon from a community cancer clinic. Our objectives are to estimate the risk of a patient's ability to adhere to a prescribed regimen and enable targeted and timely interventions by using computational analysis of unstructured and structured fields in standard clinical documentation. We also aim to monitor and measure important patient treatment and adherence metrics (e.g. as defined by the American Society of Clinical Oncology) that can play a significant role in tracking high-risk patients for improved patient treatment outcomes, adherence, quality and safety.  Our approach represents a significant, actionable advance over the lagging indicators offered by survey-based methods prevalent in adherence research. Our proposed approach has deep implications for improved quality of care, proactive management of chronic diseases, retention of patients in clinical practice and clinical trials, patient safety, improved patient follow-up and risk assessment, drug and disease surveillance, enablement of new care models, targeted intervention, and improved outcomes by helping patients to better adhere to their regimens.      PUBLIC HEALTH RELEVANCE: We aim to show the feasibility of a commercial early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.              We aim to show the feasibility of a commercial early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.            ",Risk Prediction and Computational Tools for Cancer Patient Adherence.,8249014,R44TR000363,"['Adherence', 'Adoption', 'Adverse effects', 'American Society of Clinical Oncology', 'Area', 'Behavior', 'Behavioral', 'Cancer Center', 'Cancer Patient', 'Caring', 'Case Management', 'Case Manager', 'Cereals', 'Cessation of life', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Paths', 'Clinical Trials', 'Communities', 'Community Clinical Oncology Program', 'Computational algorithm', 'Computer Analysis', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Data Set', 'Dictionary', 'Disease', 'Documentation', 'Electronics', 'Emotional', 'Employment', 'Enrollment', 'Family', 'Glean', 'Health', 'Hospitalization', 'Individual', 'Intervention', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Nurses', 'Ontology', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patient Noncompliance', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Protocols documentation', 'Quality of Care', 'Recording of previous events', 'Records', 'Regimen', 'Research', 'Research Methodology', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Role', 'Safety', 'Scientific Advances and Accomplishments', 'Semantics', 'Services', 'Signal Transduction', 'Single-Blind Study', 'Small Business Innovation Research Grant', 'Source', 'Structure', 'Surveillance Methods', 'Surveys', 'System', 'Technology', 'Text', 'Time', 'Treatment Protocols', 'Treatment outcome', 'Visit', 'Weight', 'Work', 'Writing', 'adverse outcome', 'base', 'cancer therapy', 'clinical practice', 'clinically relevant', 'compliance behavior', 'computerized tools', 'cost', 'follow-up', 'high risk', 'improved', 'information model', 'innovation', 'insight', 'mathematical algorithm', 'novel', 'novel strategies', 'oncology', 'patient safety', 'prototype', 'psychologic', 'social', 'text searching', 'treatment adherence']",NCATS,"360FRESH, INC.",R44,2012,542509,0.04611947923134683
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,9534365,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2018,449751,0.030861796764615968
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,9319536,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2017,449993,0.030861796764615968
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,9120230,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2016,425000,0.030861796764615968
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,8915498,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2015,419993,0.030861796764615968
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,8821956,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2014,449993,0.030861796764615968
"Clinical and Translational Science Award PROJECT SUMMARY: COMBATCOVID The coronavirus (COVID-19) pandemic has affected every corner of the globe and has redefined healthcare throughout the United States. COVID-19 cases in the New York City tri-state area have reached an extraordinarily high number and have quickly become the epicenter region of the crisis in the United States. In New York State alone, there are over 372,000 confirmed cases as of June 1, 2020. NYU Langone Health (NYULH) has been particularly hard hit, with more than 8,100 COVID-19 hospitalizations to date. In response, the entire clinical research community is marshalling resources in an attempt to improve our understanding of how the virus spreads, how it infects various tissues in the body, which patients are more susceptible to infection and fatal outcomes, which therapeutics improve symptoms and survival, whether the immune response confers long-lasting protection against reinfection, and many other crucially important questions. The complexity of the development of this disease and unpredictability of progression into severity, as well as the variety of phenotypic outcomes observed during and post COVID-19, pose major challenges in understanding, predicting, preventing, managing and treating this disease and its sequelae. Answers to these challenges can only be achieved through the comprehensive analysis of a significantly high number of COVID cases. Given how recent and unknown this disease is, and its inherent epidemic nature, there is a limited number of cases at individual medical institutions. The limitation of number of cases per institution becomes even more relevant when isolating subpopulations with specific health conditions and across the lifespan. This proposed study will aim to overcome the above-mentioned challenges by supporting the formation of a consortium comprising multiple medical institutions in the U.S.: COMBATCOVID (Consortium for Multisite Biomedical Analytics and Trials on COVID-19). COMBATCOVID will bring together electronic health records (EHR) data from multiple participating institutions into a shared centralized database. As part of the COMBATCOVID effort, biorepository data of COVID-19 patients collected by some of the participating institutions will also be shared and linked to the respective EHR data. The COMBATCOVID consortium will be responsible for transferring EHR data pertaining to participating institutions interested in contributing EHR data to the N3C database. PROJECT NARRATIVE: COMBATCOVID The coronavirus (COVID-19) pandemic has affected every corner of the globe and has redefined healthcare throughout the United States. To adequately understand the virus much more data is needed, necessitating sharing of data across multiple institutions. The COMBATCOVID (Consortium for Multisite Biomedical Analytics and Trials on COVID-19) initiative will support regional and national efforts by forming a consortium comprising multiple medical institutions in the U.S. to create a shared centralized database of COVID-related EHR data.",Clinical and Translational Science Award,10183901,UL1TR001445,"['2019-nCoV', 'Affect', 'Area', 'COVID-19', 'COVID-19 pandemic', 'Categories', 'Cessation of life', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical and Translational Science Awards', 'Code', 'Communities', 'Coronavirus', 'Critical Care', 'Critical Illness', 'Data', 'Data Science', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Epidemic', 'Event', 'Fatal Outcome', 'Health', 'Health system', 'Healthcare', 'Hospitalization', 'Immune response', 'Individual', 'Infection', 'Inflammatory', 'Informatics', 'Institution', 'Ischemic Stroke', 'Knowledge', 'Laboratories', 'Link', 'Longevity', 'Marshal', 'Medical', 'Natural Language Processing', 'Nature', 'New York', 'New York City', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phenotype', 'Pneumonia', 'Procedures', 'Records', 'Research Personnel', 'Resources', 'Respiratory Failure', 'Risk', 'Severities', 'Site', 'Subgroup', 'Syndrome', 'Testing', 'Text', 'Therapeutic', 'Thrombosis', 'Time', 'Tissues', 'Underrepresented Groups', 'United States', 'Upper respiratory tract', 'Venous', 'Viral Pneumonia', 'Virus', 'biobank', 'central database', 'cohort', 'coronavirus disease', 'data sharing', 'demographics', 'design', 'ethnic minority population', 'health data', 'improved', 'interest', 'medical specialties', 'meetings', 'member', 'pandemic disease', 'prevent', 'racial minority', 'response', 'structured data', 'symptomatic improvement', 'unstructured data', 'venous thromboembolism']",NCATS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,UL1,2020,768511,0.02902823415734356
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,10005506,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Pooling', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data infrastructure', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phenotyping algorithm', 'phrases', 'portability', 'preservation', 'privacy preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2020,1500847,0.09759136049980102
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9774338,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2019,1521748,0.09759136049980102
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9547946,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2018,1542081,0.09759136049980102
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9385056,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Biological Preservation', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2017,1589604,0.09759136049980102
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,7272822,R01EB002247,"['Address', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Body of uterus', 'Cancer Patient', 'Caregivers', 'Chronic', 'Chronic Disease', 'Clinical', 'Communication', 'Communities', 'Condition', 'Consultations', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Health Personnel', 'Healthcare', 'Image', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Metric', 'Modeling', 'Musculoskeletal', 'Musculoskeletal Pain', 'Natural Language Processing', 'Neurologic', 'Oncologist', 'Optics', 'Patients', 'Performance', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Process', 'Quality of Care', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Infrastructure', 'Slice', 'Specialist', 'Structure', 'Surgeon', 'System', 'Techniques', 'Technology', 'Teleconsultations', 'Telemedicine', 'Testing', 'Time', 'Upper arm', 'Work', 'base', 'chemotherapy', 'data mining', 'diagnostic accuracy', 'health care quality', 'image registration', 'improved', 'interest', 'knowledge base', 'medical specialties', 'novel', 'research clinical testing', 'size', 'telehealth']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,394864,0.03182328766300955
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,7115855,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,396341,0.03182328766300955
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6948251,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,399327,0.03182328766300955
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6802269,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,387825,0.03182328766300955
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6725819,R01EB002247,"['anatomy', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer assisted patient care', ' computer data analysis', ' computer graphics /printing', ' computer system design /evaluation', ' diagnosis quality /standard', ' health care quality', ' health care referral /consultation', ' human data', ' image enhancement', ' image processing', ' magnetic resonance imaging', ' musculoskeletal disorder', ' nervous system disorder', ' statistics /biometry', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,383268,0.03182328766300955
"Using clinical treatment data in a machine learning approach for sepsis detection Abstract Significance: In this SBIR project, we propose to develop novel software, HindSight, that will improve InSight, a machine-learning based clinical decision support (CDS) system for sepsis prediction and detection. HindSight will identify clinicians sepsis-related decisions in the records of former patients; it will then use these events to supply InSight with labeled examples of sepsis cases, incorporating clinicians judgement to demonstrate appropriate and inappropriate alarms. Together with an online training module that accordingly refines InSights predictors, this capability will enable InSight to quickly adapt to the idiosyncrasies of a particular clinical deployment, reduce false or irrelevant alarms, and do both without explicit human supervision. Research Question: Can a machine-learning-based, retrospective labeler learn to autonomously label sepsis and sepsis treatments by integrating the total clinical record, thereby providing many high-quality examples and labels for training a sepsis CDS? In concert with an online learning algorithm, can this labeler facilitate online, supervised learning without explicit human intervention? Prior Work: We have developed InSight for application in a number of sepsis prediction settings. Existing InSight classifiers attain an area under the receiver operating characteristic curve (AUROC) of 0.88 for sepsis detection, and 0.74 for 4-hour early sepsis prediction. Specific Aims: To identify patients who were evaluated for sepsis, treated for sepsis, or who actually had sepsis using the retrospective clinical patient record and label them accordingly (Aim 1); to use these labels with an online learning algorithm to implement autonomous, supervised learning of alert behavior which reflects clinician judgement (Aim 2). Methods: We will identify evaluated, treated, and septic patients using a machine learning labeler trained on retrospective data from patients electronic health records (EHR) at time of discharge. Using a set of 100 test cases ( 20 septic) hand-annotated by our clinician investigators, we will assess the labelers performance. Labeling AUROC  0.95 will constitute success in Aim 1. We will develop an online learning algorithm which enables InSight to continuously retrain during deployment. With Aim 1s labeler, we will simulate a deployment with online learning, producing a learning curve of predictive AUROC on a held-out test set versus number of observed patients. Aim 2 will be successful if the online training results in superior area under the learning curve versus the initial model and periodic retraining. All experiments will be executed using the MIMIC-III data set. Future Directions: Following the proposed work, the InSight system with an online, HindSight-based retraining module will be deployed at partner hospitals for prospective studies. Narrative Clinical decision support (CDS) systems present critical information to medical professionals by examining patient data and providing alerts. Machine learning is a powerful method for creating CDS tools, but it requires labels which reflect the desired alert behavior. We will develop software that examines discharged patients electronic health records (EHR), identifies clinicians sepsis treatment decisions and patient outcomes, and passes these labeled examples to an online algorithm for retraining InSight, our machine-learning-based CDS tool for real-time sepsis prediction.",Using clinical treatment data in a machine learning approach for sepsis detection,9557659,R43TR002309,"['Algorithms', 'Area', 'Behavior', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Computer software', 'Data', 'Data Set', 'Detection', 'Drops', 'E-learning', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'Evaluation', 'Event', 'Fatigue', 'Future', 'Gold', 'Hand', 'Healthcare Systems', 'Hospitals', 'Hour', 'Human', 'Immune response', 'Institution', 'Intervention', 'Judgment', 'Label', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Multicenter Studies', 'Nature', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Positioning Attribute', 'Prospective Studies', 'Pythons', 'Receiver Operating Characteristics', 'Records', 'Research', 'Research Personnel', 'Risk', 'Sepsis', 'Signal Transduction', 'Site', 'Small Business Innovation Research Grant', 'Specificity', 'Supervision', 'Surgical Oncology', 'Survival Rate', 'Symptoms', 'System', 'TensorFlow', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'base', 'clinical decision support', 'cost', 'experience', 'experimental study', 'falls', 'improved', 'insight', 'learning strategy', 'novel', 'prospective', 'recurrent neural network', 'research clinical testing', 'septic', 'septic patients', 'software development', 'success', 'support tools']",NCATS,"DASCENA, INC.",R43,2018,324971,0.05591750492528918
"Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare Project Summary With newly available electronic health data and a massive increase in processing power, data-driven personalized medicine is just now becoming possible.1 However, advances to improve health care are inherently limited by data quality. One of the most used sources of data, the patient problem list, is also the greatest source of data inaccuracy. According to recent studies, the patient problem list is often less than 50% accurate in documenting the most critical conditions.2 3 4 5 These errors exacerbate inefficiencies throughout the American health care system from care delivery to quality improvement. Primary care physicians rely on problem lists to develop transitional treatment plans for the 68 million Americans who change providers every year. Errors related to care transitions harm more than 1.5 million people each year in the United States, costing the nation an estimated $3.5 billion annually.6 Population health efforts, a cornerstone of value-based healthcare, rely on problem lists to determine risk levels and deployment of resources. These efforts cannot succeed if the source data produce faulty results. This application seeks to enable better individual patient care, enhanced population health management, and effective downstream analytics by building an automated problem list builder, which provides an accurate and granular account of the patients medical conditions. If the program is successful, one of the greatest technical risks in value-based healthcare will be addressed. Phase I exceeded success criteria in proving feasibility of core modules in natural language processing (NLP) and artificial intelligence. Based on Phase I success, implementation pathways are demonstrated through pilots with one of the largest US healthcare systems and one of the largest global biotechnology firms. The team is comprised of commercial and academic leaders in the field of NLP-based products applied to value-based healthcare. Project Narrative VMT proposes to use advanced semantic technologies and artificial intelligence to enhance the individualized patient problem list, which frequently has 50% or lower accuracy for common conditions such as cancer, smoking, and heart failure. 1 2 3 The problem list represents source data in care delivery, population health, shared-risk contracting, and research. This proposal aims to support more accurate and granular source data to enhance care delivery and value-based healthcare.",Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare,9762237,R44TR002437,"['Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Big Data', 'Biotechnology', 'Businesses', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Continuity of Patient Care', 'Contracts', 'Coughing', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Development', 'Disease', 'Feedback', 'Foundations', 'Garbage', 'General Hospitals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Heart failure', 'Knowledge', 'Letters', 'Malignant Neoplasms', 'Manuals', 'Massachusetts', 'Medical', 'Modeling', 'Natural Language Processing', 'Noise', 'Pathway interactions', 'Patient Care', 'Patients', 'Peer Review', 'Phase', 'Physicians', 'Primary Care Physician', 'Provider', 'Research', 'Resources', 'Review Literature', 'Risk', 'Semantics', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Smoking', 'Source', 'Symptoms', 'System', 'Systems Integration', 'Technology', 'Text', 'Time', 'United States', 'United States Department of Veterans Affairs', 'Update', 'Writing', 'base', 'care delivery', 'clinical decision support', 'clinical phenotype', 'comparative effectiveness', 'cost', 'discrete data', 'effectiveness research', 'evidence base', 'expectation', 'falls', 'health data', 'health management', 'high reward', 'high risk', 'improved', 'individual patient', 'interest', 'payment', 'personalized care', 'personalized medicine', 'point of care', 'population health', 'programs', 'risk sharing', 'screening', 'success', 'support tools', 'treatment planning']",NCATS,"VERANTOS, INC.",R44,2019,749614,0.01772468485345614
"Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare Project Summary With newly available electronic health data and a massive increase in processing power, data-driven personalized medicine is just now becoming possible.1 However, advances to improve health care are inherently limited by data quality. One of the most used sources of data, the patient problem list, is also the greatest source of data inaccuracy. According to recent studies, the patient problem list is often less than 50% accurate in documenting the most critical conditions.2 3 4 5 These errors exacerbate inefficiencies throughout the American health care system from care delivery to quality improvement. Primary care physicians rely on problem lists to develop transitional treatment plans for the 68 million Americans who change providers every year. Errors related to care transitions harm more than 1.5 million people each year in the United States, costing the nation an estimated $3.5 billion annually.6 Population health efforts, a cornerstone of value-based healthcare, rely on problem lists to determine risk levels and deployment of resources. These efforts cannot succeed if the source data produce faulty results. This application seeks to enable better individual patient care, enhanced population health management, and effective downstream analytics by building an automated problem list builder, which provides an accurate and granular account of the patients medical conditions. If the program is successful, one of the greatest technical risks in value-based healthcare will be addressed. Phase I exceeded success criteria in proving feasibility of core modules in natural language processing (NLP) and artificial intelligence. Based on Phase I success, implementation pathways are demonstrated through pilots with one of the largest US healthcare systems and one of the largest global biotechnology firms. The team is comprised of commercial and academic leaders in the field of NLP-based products applied to value-based healthcare. Project Narrative VMT proposes to use advanced semantic technologies and artificial intelligence to enhance the individualized patient problem list, which frequently has 50% or lower accuracy for common conditions such as cancer, smoking, and heart failure. 1 2 3 The problem list represents source data in care delivery, population health, shared-risk contracting, and research. This proposal aims to support more accurate and granular source data to enhance care delivery and value-based healthcare.",Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare,9622425,R44TR002437,"['Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Big Data', 'Biotechnology', 'Businesses', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Continuity of Patient Care', 'Contracts', 'Coughing', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Development', 'Disease', 'Feedback', 'Foundations', 'Garbage', 'General Hospitals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Heart failure', 'Knowledge', 'Letters', 'Malignant Neoplasms', 'Manuals', 'Massachusetts', 'Medical', 'Modeling', 'Natural Language Processing', 'Noise', 'Pathway interactions', 'Patient Care', 'Patients', 'Peer Review', 'Phase', 'Physicians', 'Primary Care Physician', 'Provider', 'Research', 'Resources', 'Review Literature', 'Risk', 'Semantics', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Smoking', 'Source', 'Symptoms', 'System', 'Systems Integration', 'Technology', 'Text', 'Time', 'United States', 'United States Department of Veterans Affairs', 'Update', 'Writing', 'base', 'care delivery', 'clinical decision support', 'clinical phenotype', 'comparative effectiveness', 'cost', 'discrete data', 'effectiveness research', 'evidence base', 'expectation', 'falls', 'health data', 'health management', 'high reward', 'high risk', 'improved', 'individual patient', 'interest', 'payment', 'personalized care', 'personalized medicine', 'point of care', 'population health', 'programs', 'risk sharing', 'screening', 'success', 'support tools', 'treatment planning']",NCATS,"VMT, INC.",R44,2018,149999,0.01772468485345614
"Enhancing Infrastructure for Clinical and Translational Research to Address the Opioid Epidemic PROJECT SUMMARY Up-to-date information about non-fatal overdose emergency department (ED) encounters can provide critical information about the evolution of the opioid epidemic and response of the healthcare system and is an essential to planning of clinical trials to address the problems underlying this epidemic. Establishing a platform that delivers high positive predictive value for opioid-related overdose (OD) using a combination of coded and natural language terms in electronic health records (EHRs) is an essential step toward the large-scale surveillance necessary to evaluate the pragmatic effectiveness of numerous systemic and policy-based efforts and to create the infrastructure for large scale trials to reduce drug-related mortality and morbidity. However, to date, localized and federal efforts have been largely based on discrete ICD-10 code data or have had time lags of one-to-three years for more detailed data. Perhaps more Importantly, they have not had the capacity for planning and feasibility assessment for clinical and translational research at specific sites. We propose foundational work to create an inter-institutional research database and network focused on patients presenting to EDs with opioid-related OD. To create this network, we will extend previous work to develop: (1) an e-phenotype for case identification in the ED based on EHR data, and (2) combine this with a data dictionary and coded data extraction tools, and natural language processing (NLP) algorithms, to obtain additional data from EHRs; tools for primary capture of data during clinical care; and tools for integration of data on social determinants of health. This will allow for a more thorough characterization of individuals presenting to EDs with opioid-related OD including: demographics, comorbidities, OD agent and source, intentionality of the OD, ED treatment and discharge disposition. Through refinement and automation, the data extraction process will be extended to a set of pilot CTSA Accrual to Clinical Trials (ACT) Network sites and then potentially to other CTSA's nation-wide. This new functionality focuses on providing a platform to accelerate research. To accomplish this work, our Specific Aims are to: 1) Demonstrate the feasibility of extending the ACT Network data model and infrastructure to monitor the opioid epidemic using ED data, 2) Create a prototype opioid overdose monitoring and response network across participating institutions and a toolkit for other CTSA sites to join the network, and 3) Demonstrate potential usefulness of the network in monitoring the opioid epidemic and in planning clinical trials. This proposal is innovative as it aims to develop a feasible and effective near real time means of monitoring opioid-related OD presentation in EDs across the country to inform point-of-care service delivery, prevention and treatment intervention development and evaluation. Downstream, the application of project deliverables include dissemination of the replication toolkit to leverage the platform of the CTSAs and NIDA Clinical Trials Network to build capacity for timely surveillance of opioid-related OD to facilitate prevention and treatment research and intervention. PROJECT NARRATIVE Patients presenting with opioid-related overdose to hospital emergency departments represent a high-risk group for morbidity and mortality and a potential target for interventions to combat the opioid epidemic. This proposal is innovative as it aims to develop a feasible and effective inter-institutional research database and network focused on these patients. These tools will inform point-of-care service delivery, as well as enhance nationwide prevention and treatment interventions.",Enhancing Infrastructure for Clinical and Translational Research to Address the Opioid Epidemic,9821606,U01TR002628,"['Accident and Emergency department', 'Address', 'Algorithms', 'Automation', 'California', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Database', 'Clinical Trials Network', 'Clinical assessments', 'Code', 'Comorbidity', 'Country', 'Data', 'Databases', 'Dictionary', 'Effectiveness', 'Electronic Health Record', 'Epidemic', 'Evaluation', 'Evolution', 'Fentanyl', 'Foundations', 'Funding', 'Health Care Costs', 'Health Resources', 'Health system', 'Healthcare Systems', 'Heroin', 'Hospitals', 'Individual', 'Infrastructure', 'Institution', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Intervention', 'Intervention Trial', 'Investments', 'Kentucky', 'Laboratories', 'Modification', 'Monitor', 'Morbidity - disease rate', 'National Institute of Drug Abuse', 'Natural Language Processing', 'Non-Prescription Drugs', 'Odds Ratio', 'Opiate Addiction', 'Opioid', 'Outcome Study', 'Overdose', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Policies', 'Predictive Value', 'Prevention', 'Procedures', 'Process', 'Public Health', 'Research', 'Site', 'Source', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Work', 'base', 'clinical care', 'clinical infrastructure', 'combat', 'data integration', 'data modeling', 'demographics', 'design', 'effective therapy', 'electronic data', 'fitness', 'high risk population', 'innovation', 'inter-institutional', 'mortality', 'natural language', 'opioid epidemic', 'opioid misuse', 'opioid overdose', 'opioid use disorder', 'overdose prevention', 'point of care', 'prescription opioid', 'prescription opioid misuse', 'prototype', 'response', 'service delivery', 'social', 'social health determinants', 'synthetic opioid', 'therapy design', 'therapy development', 'tool', 'translational study']",NCATS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,U01,2019,778563,0.038441573530033635
"Enhancing Infrastructure for Clinical and Translational Research to Address the Opioid Epidemic PROJECT SUMMARY Up-to-date information about non-fatal overdose emergency department (ED) encounters can provide critical information about the evolution of the opioid epidemic and response of the healthcare system and is an essential to planning of clinical trials to address the problems underlying this epidemic. Establishing a platform that delivers high positive predictive value for opioid-related overdose (OD) using a combination of coded and natural language terms in electronic health records (EHRs) is an essential step toward the large-scale surveillance necessary to evaluate the pragmatic effectiveness of numerous systemic and policy-based efforts and to create the infrastructure for large scale trials to reduce drug-related mortality and morbidity. However, to date, localized and federal efforts have been largely based on discrete ICD-10 code data or have had time lags of one-to-three years for more detailed data. Perhaps more Importantly, they have not had the capacity for planning and feasibility assessment for clinical and translational research at specific sites. We propose foundational work to create an inter-institutional research database and network focused on patients presenting to EDs with opioid-related OD. To create this network, we will extend previous work to develop: (1) an e-phenotype for case identification in the ED based on EHR data, and (2) combine this with a data dictionary and coded data extraction tools, and natural language processing (NLP) algorithms, to obtain additional data from EHRs; tools for primary capture of data during clinical care; and tools for integration of data on social determinants of health. This will allow for a more thorough characterization of individuals presenting to EDs with opioid-related OD including: demographics, comorbidities, OD agent and source, intentionality of the OD, ED treatment and discharge disposition. Through refinement and automation, the data extraction process will be extended to a set of pilot CTSA Accrual to Clinical Trials (ACT) Network sites and then potentially to other CTSA's nation-wide. This new functionality focuses on providing a platform to accelerate research. To accomplish this work, our Specific Aims are to: 1) Demonstrate the feasibility of extending the ACT Network data model and infrastructure to monitor the opioid epidemic using ED data, 2) Create a prototype opioid overdose monitoring and response network across participating institutions and a toolkit for other CTSA sites to join the network, and 3) Demonstrate potential usefulness of the network in monitoring the opioid epidemic and in planning clinical trials. This proposal is innovative as it aims to develop a feasible and effective near real time means of monitoring opioid-related OD presentation in EDs across the country to inform point-of-care service delivery, prevention and treatment intervention development and evaluation. Downstream, the application of project deliverables include dissemination of the replication toolkit to leverage the platform of the CTSAs and NIDA Clinical Trials Network to build capacity for timely surveillance of opioid-related OD to facilitate prevention and treatment research and intervention. PROJECT NARRATIVE Patients presenting with opioid-related overdose to hospital emergency departments represent a high-risk group for morbidity and mortality and a potential target for interventions to combat the opioid epidemic. This proposal is innovative as it aims to develop a feasible and effective inter-institutional research database and network focused on these patients. These tools will inform point-of-care service delivery, as well as enhance nationwide prevention and treatment interventions.",Enhancing Infrastructure for Clinical and Translational Research to Address the Opioid Epidemic,9989930,U01TR002628,"['Accident and Emergency department', 'Address', 'Algorithms', 'Automation', 'California', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Database', 'Clinical Trials Network', 'Clinical assessments', 'Code', 'Country', 'Data', 'Databases', 'Effectiveness', 'Electronic Health Record', 'Epidemic', 'Evaluation', 'Evolution', 'Fentanyl', 'Foundations', 'Funding', 'Health Care Costs', 'Health Resources', 'Health system', 'Healthcare Systems', 'Heroin', 'Hospitals', 'Individual', 'Infrastructure', 'Institution', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Intervention', 'Intervention Trial', 'Investments', 'Kentucky', 'Laboratories', 'Modification', 'Monitor', 'Morbidity - disease rate', 'National Institute of Drug Abuse', 'Natural Language Processing', 'Non-Prescription Drugs', 'Odds Ratio', 'Opiate Addiction', 'Opioid', 'Outcome Study', 'Overdose', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Policies', 'Predictive Value', 'Prevention', 'Prevention Research', 'Procedures', 'Process', 'Public Health', 'Research', 'Site', 'Source', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Work', 'base', 'clinical care', 'clinical infrastructure', 'combat', 'comorbidity', 'data dictionary', 'data infrastructure', 'data integration', 'data modeling', 'data tools', 'demographics', 'design', 'effective therapy', 'electronic data', 'fitness', 'high risk population', 'innovation', 'inter-institutional', 'mortality', 'natural language', 'opioid epidemic', 'opioid misuse', 'opioid overdose', 'opioid use disorder', 'overdose prevention', 'point of care', 'prescription opioid', 'prescription opioid misuse', 'prototype', 'response', 'service delivery', 'social', 'social health determinants', 'synthetic opioid', 'therapy design', 'therapy development', 'tool', 'translational study', 'treatment research']",NCATS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,U01,2020,736713,0.038441573530033635
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10011177,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2020,503546,0.057707612284744955
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7677599,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2008,20000,0.026668802947458332
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7326883,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2007,99773,0.026668802947458332
"High Performance Text Mining for Translator We propose to build a knowledge provider that will seek out, integrate and provide AIready, BioLink-compatible models via high-performance text-mining of the biomedical literature. Problems with Translators current mining of the biomedical literature that we intend to solve include: (1) weaknesses in framework extensibility and benchmarking that make integrating and validating new text-mining approaches difficult; (2) problematic licensing of software, terminologies and other resources that do not adequately support FAIR (and TLC) best practices; (3) processing only PubMed titles and abstracts, not full text publications; (4) Translators use of older NLP technology with relatively poor performance; (5) lack of a mechanism for community feedback regarding errors and other problems; (6) lack of continuous updates to add knowledge from new publications; (7) output knowledge representation that is simplistic and vague, failing to reflect the richness of what is expressed in scientific documents. n/a",High Performance Text Mining for Translator,10053507,OT2TR003422,"['Benchmarking', 'Communities', 'Computer software', 'Feedback', 'Knowledge', 'Licensing', 'Literature', 'Mining', 'Modeling', 'Output', 'Performance', 'Provider', 'PubMed', 'Publications', 'Resources', 'Technology', 'Terminology', 'Text', 'Update', 'information organization', 'text searching']",NCATS,UNIVERSITY OF COLORADO DENVER,OT2,2020,735622,0.0032929825058308987
"INDEXING AND RETRIEVING INFORMATION The goal of this proposal is to develop an expert system for archiving medical information.  The main feature of the system will be the ability to automatically index medical text with keywords.  Input to the system will consist of reports from medical charts, abstracts from the medical literature, and descriptive passages from teaching collections.  The system will retrieve information through requests formulated in natural language, or through Boolean combinations of keywords.   The knowledge base for the expert system will be a semantic network generated from thesauri of medical terms.  The expert system shell; the natural language and Boolean retrieval routines and utilities for thesaurus construction have already been developed. Partial thesauri containing an average of 3,000 terms and 15,000 links have been constructed for neuropathology, neuroradiology, and psychiatry.  These thesauri have been successfully tested in pilot studies of automated indexing and natural language retrieval.  During the course of this project we will complete these thesauri and compare the performance of the full autoindexing system to human indexers.  If these tests are successful, we will extend thesaurus construction to neurology and neurosurgery developing a merged thesaurus covering the clinical neurosciences.  The expert system will then be integrated into a comprehensive medical information system under development at the University of Pittsburgh.  n/a",INDEXING AND RETRIEVING INFORMATION,3373894,R01LM004635,"['automated data processing', ' indexing', ' information retrieval', ' information system analysis']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,1990,159491,0.019442923813052293
"INDEXING AND RETRIEVING INFORMATION The goal of this proposal is to develop an expert system for archiving medical information.  The main feature of the system will be the ability to automatically index medical text with keywords.  Input to the system will consist of reports from medical charts, abstracts from the medical literature, and descriptive passages from teaching collections.  The system will retrieve information through requests formulated in natural language, or through Boolean combinations of keywords.   The knowledge base for the expert system will be a semantic network generated from thesauri of medical terms.  The expert system shell; the natural language and Boolean retrieval routines and utilities for thesaurus construction have already been developed. Partial thesauri containing an average of 3,000 terms and 15,000 links have been constructed for neuropathology, neuroradiology, and psychiatry.  These thesauri have been successfully tested in pilot studies of automated indexing and natural language retrieval.  During the course of this project we will complete these thesauri and compare the performance of the full autoindexing system to human indexers.  If these tests are successful, we will extend thesaurus construction to neurology and neurosurgery developing a merged thesaurus covering the clinical neurosciences.  The expert system will then be integrated into a comprehensive medical information system under development at the University of Pittsburgh.  n/a",INDEXING AND RETRIEVING INFORMATION,3373893,R01LM004635,"['automated data processing', ' indexing', ' information retrieval', ' information system analysis']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,1989,167639,0.019442923813052293
"INDEXING AND RETRIEVING INFORMATION The goal of this proposal is to develop an expert system for archiving medical information.  The main feature of the system will be the ability to automatically index medical text with keywords.  Input to the system will consist of reports from medical charts, abstracts from the medical literature, and descriptive passages from teaching collections.  The system will retrieve information through requests formulated in natural language, or through Boolean combinations of keywords.   The knowledge base for the expert system will be a semantic network generated from thesauri of medical terms.  The expert system shell; the natural language and Boolean retrieval routines and utilities for thesaurus construction have already been developed. Partial thesauri containing an average of 3,000 terms and 15,000 links have been constructed for neuropathology, neuroradiology, and psychiatry.  These thesauri have been successfully tested in pilot studies of automated indexing and natural language retrieval.  During the course of this project we will complete these thesauri and compare the performance of the full autoindexing system to human indexers.  If these tests are successful, we will extend thesaurus construction to neurology and neurosurgery developing a merged thesaurus covering the clinical neurosciences.  The expert system will then be integrated into a comprehensive medical information system under development at the University of Pittsburgh.  n/a",INDEXING AND RETRIEVING INFORMATION,3373892,R01LM004635,"['automated data processing', ' indexing', ' information retrieval', ' information system analysis']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,1988,179102,0.019442923813052293
"New Resources for e-Patients    DESCRIPTION (provided by applicant): ""New Resources for e-Patients"" addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in currently available online health information resources. It will maximize the value of public domain health information from U.S. Government sources. Textual consumer health information will be collected from NIH, FDA and other government sources. This information will be subjected to automated topic analysis and classification using methods of natural language processing and statistical text-mining to discover and extract topics on i) diseases and conditions; ii) treatments, benefits and risks; and iii) genomic risks and responses. These topics will be integrated and mapped to the most frequent health topics of interest to consumers. Personally-controlled electronic health records and personal genotypes will be studied for their potential contributions to personalized medicine for e-patients. Phase I of this project will achieve proof-of-principle and develop an advanced prototype as a foundation for construction of a new web-based resource in Phase II.    PUBLIC HEALTH RELEVANCE: This project addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in current online health information resources and also target new opportunities in genomic and personalized medicine. In the process we will create consumer-friendly, automated systems that make online information search and retrieval more efficient more efficient and maximize the value of public domain health information from U.S. Government sources. The work will lead to more reliable, personalized and actionable information for a new generation of web-savvy and socially-networked ""e-patients"" and will lead to more efficient and productive encounters between patients and healthcare systems.           This project addresses the unmet medical needs of consumers who search for  health and healthcare information online, currently a population of more than  160 million people in the U.S. It will fill gaps and address deficiencies in current  online health information resources and also target new opportunities in  genomic and personalized medicine. In the process we will create consumer-  friendly, automated systems that make online information search and retrieval  more efficient more efficient and maximize the value of public domain health  information from U.S. Government sources. The work will lead to more reliable,  personalized and actionable information for a new generation of web-savvy and  socially-networked ""e-patients"" and will lead to more efficient and productive  encounters between patients and healthcare systems.",New Resources for e-Patients,8129905,R43HG005046,"['Address', 'Benefits and Risks', 'Businesses', 'Classification', 'Communication', 'Data', 'Development', 'Development Plans', 'Disease', 'Electronic Health Record', 'Foundations', 'Fund Raising', 'Generations', 'Genes', 'Genomics', 'Genotype', 'Government', 'Health', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Information Resources', 'Institutes', 'Internet', 'Lead', 'Maps', 'Marketing', 'Medical', 'Medicine', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Public Domains', 'Research', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Site', 'Source', 'Surveys', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Update', 'Validation', 'Work', 'base', 'commercialization', 'data integration', 'design', 'health record', 'interest', 'prototype', 'public health relevance', 'research study', 'response', 'text searching', 'web site']",NHGRI,"RESOUNDING HEALTH, INC.",R43,2010,35000,0.026266477376003846
"New Resources for e-Patients    DESCRIPTION (provided by applicant): ""New Resources for e-Patients"" addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in currently available online health information resources. It will maximize the value of public domain health information from U.S. Government sources. Textual consumer health information will be collected from NIH, FDA and other government sources. This information will be subjected to automated topic analysis and classification using methods of natural language processing and statistical text-mining to discover and extract topics on i) diseases and conditions; ii) treatments, benefits and risks; and iii) genomic risks and responses. These topics will be integrated and mapped to the most frequent health topics of interest to consumers. Personally-controlled electronic health records and personal genotypes will be studied for their potential contributions to personalized medicine for e-patients. Phase I of this project will achieve proof-of-principle and develop an advanced prototype as a foundation for construction of a new web-based resource in Phase II.    PUBLIC HEALTH RELEVANCE: This project addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in current online health information resources and also target new opportunities in genomic and personalized medicine. In the process we will create consumer-friendly, automated systems that make online information search and retrieval more efficient more efficient and maximize the value of public domain health information from U.S. Government sources. The work will lead to more reliable, personalized and actionable information for a new generation of web-savvy and socially-networked ""e-patients"" and will lead to more efficient and productive encounters between patients and healthcare systems.           This project addresses the unmet medical needs of consumers who search for  health and healthcare information online, currently a population of more than  160 million people in the U.S. It will fill gaps and address deficiencies in current  online health information resources and also target new opportunities in  genomic and personalized medicine. In the process we will create consumer-  friendly, automated systems that make online information search and retrieval  more efficient more efficient and maximize the value of public domain health  information from U.S. Government sources. The work will lead to more reliable,  personalized and actionable information for a new generation of web-savvy and  socially-networked ""e-patients"" and will lead to more efficient and productive  encounters between patients and healthcare systems.",New Resources for e-Patients,7748337,R43HG005046,"['Address', 'Benefits and Risks', 'Body of uterus', 'Businesses', 'Classification', 'Communication', 'Data', 'Development', 'Development Plans', 'Disease', 'Electronic Health Record', 'Foundations', 'Fund Raising', 'Generations', 'Genes', 'Genomics', 'Genotype', 'Government', 'Health', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Information Resources', 'Institutes', 'Internet', 'Lead', 'Maps', 'Marketing', 'Medical', 'Medicine', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Public Domains', 'Research', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Site', 'Source', 'Surveys', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Update', 'Validation', 'Work', 'base', 'commercialization', 'data integration', 'design', 'health record', 'interest', 'prototype', 'public health relevance', 'research study', 'response', 'text searching', 'web site']",NHGRI,"RESOUNDING HEALTH, INC.",R43,2009,119499,0.026266477376003846
"SAPHIRE--A CONCEPT-BASED APPROACH TO INFO RETRIEVAL The major goal of this project is to develop and evaluate innovative approaches to information retrieval (IR) in the biomedical domain. Building on the initial work done by the Principal Investigator (PI) with the SAPHIRE Project and taking advantage of the efforts of the Unified Medical Language Systems (UMLS) Project, we aim to design and test new methods for automated indexing and retrieval.  The underlying thesis of the SAPHIRE approach to IR is movement of information representation from the level of terms to that of concepts.  Terms, such as MeSH entries, are surface string representations of underlying concepts.  A problem with their use in representing concepts is that they cannot account for the different ways a concept may be expressed in medical texts or information system queries.  SAPHIRE is a first step in the direction of concept-based IR, and we plan to investigate several enhancements to this approach.  The major goal will be achieved with six separate but interrelated tasks:  1. Develop methodology for evaluation of IR systems in laboratory and clinical settings.  2. Assess the utility of computational linguistic approaches to concept discovery in text using constrained natural language processing and knowledge base construction.  3. Refine strategies for automated indexing of a wide variety of textual material, including abstracts, full text of articles, textbooks, and hypertext.  4. Explore different user interfaces, aiming to allow optimal retrieval for both novice and expert users.  5. Assess the use of semantic relationships between concepts in indexing and retrieval.  6. Integrate the SAPHIRE approach with other programs, such as the CODEX system and Explorer-2, and scale up to large text collections.  In the course of the project we will create an IR system that will help meet the information needs of busy health care providers.  Such a system should have a diverse variety of content available as well as quality indexing to represent content accurately.  It should also feature retrieval capability that is fast and easy to use.  In this grant, we propose to iteratively build an IR system that utilizes concept-based probabilistic indexing and retrieval, and evaluate it each step along the way in laboratory as well as real world settings.  n/a",SAPHIRE--A CONCEPT-BASED APPROACH TO INFO RETRIEVAL,2237758,R29LM005307,"['artificial intelligence', ' health care facility information system', ' indexing', ' information retrieval', ' information system analysis', ' information systems', ' language']",NLM,OREGON HEALTH AND SCIENCE UNIVERSITY,R29,1994,98036,0.012256758610967236
"SAPHIRE:  A CONCEPT-BASED APPROACH TO INFO RETRIEVAL The major goal of this project is to develop and evaluate innovative approaches to information retrieval (IR) in the biomedical domain. Building on the initial work done by the Principal Investigator (PI) with the SAPHIRE Project and taking advantage of the efforts of the Unified Medical Language Systems (UMLS) Project, we aim to design and test new methods for automated indexing and retrieval.  The underlying thesis of the SAPHIRE approach to IR is movement of information representation from the level of terms to that of concepts.  Terms, such as MeSH entries, are surface string representations of underlying concepts.  A problem with their use in representing concepts is that they cannot account for the different ways a concept may be expressed in medical texts or information system queries.  SAPHIRE is a first step in the direction of concept-based IR, and we plan to investigate several enhancements to this approach.  The major goal will be achieved with six separate but interrelated tasks:  1. Develop methodology for evaluation of IR systems in laboratory and clinical settings.  2. Assess the utility of computational linguistic approaches to concept discovery in text using constrained natural language processing and knowledge base construction.  3. Refine strategies for automated indexing of a wide variety of textual material, including abstracts, full text of articles, textbooks, and hypertext.  4. Explore different user interfaces, aiming to allow optimal retrieval for both novice and expert users.  5. Assess the use of semantic relationships between concepts in indexing and retrieval.  6. Integrate the SAPHIRE approach with other programs, such as the CODEX system and Explorer-2, and scale up to large text collections.  In the course of the project we will create an IR system that will help meet the information needs of busy health care providers.  Such a system should have a diverse variety of content available as well as quality indexing to represent content accurately.  It should also feature retrieval capability that is fast and easy to use.  In this grant, we propose to iteratively build an IR system that utilizes concept-based probabilistic indexing and retrieval, and evaluate it each step along the way in laboratory as well as real world settings.  n/a",SAPHIRE:  A CONCEPT-BASED APPROACH TO INFO RETRIEVAL,3474527,R29LM005307,"['artificial intelligence', ' health care facility information system', ' indexing', ' information retrieval', ' information system analysis', ' information systems', ' language']",NLM,OREGON HEALTH AND SCIENCE UNIVERSITY,R29,1993,91942,0.012256758610967236
"SAPHIRE--A CONCEPT-BASED APPROACH TO INFO RETRIEVAL The major goal of this project is to develop and evaluate innovative approaches to information retrieval (IR) in the biomedical domain. Building on the initial work done by the Principal Investigator (PI) with the SAPHIRE Project and taking advantage of the efforts of the Unified Medical Language Systems (UMLS) Project, we aim to design and test new methods for automated indexing and retrieval.  The underlying thesis of the SAPHIRE approach to IR is movement of information representation from the level of terms to that of concepts.  Terms, such as MeSH entries, are surface string representations of underlying concepts.  A problem with their use in representing concepts is that they cannot account for the different ways a concept may be expressed in medical texts or information system queries.  SAPHIRE is a first step in the direction of concept-based IR, and we plan to investigate several enhancements to this approach.  The major goal will be achieved with six separate but interrelated tasks:  1. Develop methodology for evaluation of IR systems in laboratory and clinical settings.  2. Assess the utility of computational linguistic approaches to concept discovery in text using constrained natural language processing and knowledge base construction.  3. Refine strategies for automated indexing of a wide variety of textual material, including abstracts, full text of articles, textbooks, and hypertext.  4. Explore different user interfaces, aiming to allow optimal retrieval for both novice and expert users.  5. Assess the use of semantic relationships between concepts in indexing and retrieval.  6. Integrate the SAPHIRE approach with other programs, such as the CODEX system and Explorer-2, and scale up to large text collections.  In the course of the project we will create an IR system that will help meet the information needs of busy health care providers.  Such a system should have a diverse variety of content available as well as quality indexing to represent content accurately.  It should also feature retrieval capability that is fast and easy to use.  In this grant, we propose to iteratively build an IR system that utilizes concept-based probabilistic indexing and retrieval, and evaluate it each step along the way in laboratory as well as real world settings.  n/a",SAPHIRE--A CONCEPT-BASED APPROACH TO INFO RETRIEVAL,3474526,R29LM005307,"['artificial intelligence', ' health care facility information system', ' indexing', ' information retrieval', ' information system analysis', ' information systems', ' language']",NLM,OREGON HEALTH AND SCIENCE UNIVERSITY,R29,1992,94952,0.012256758610967236
"SAPHIRE:  A CONCEPT-BASED APPROACH TO INFO RETRIEVAL The major goal of this project is to develop and evaluate innovative approaches to information retrieval (IR) in the biomedical domain. Building on the initial work done by the Principal Investigator (PI) with the SAPHIRE Project and taking advantage of the efforts of the Unified Medical Language Systems (UMLS) Project, we aim to design and test new methods for automated indexing and retrieval.  The underlying thesis of the SAPHIRE approach to IR is movement of information representation from the level of terms to that of concepts.  Terms, such as MeSH entries, are surface string representations of underlying concepts.  A problem with their use in representing concepts is that they cannot account for the different ways a concept may be expressed in medical texts or information system queries.  SAPHIRE is a first step in the direction of concept-based IR, and we plan to investigate several enhancements to this approach.  The major goal will be achieved with six separate but interrelated tasks:  1. Develop methodology for evaluation of IR systems in laboratory and clinical settings.  2. Assess the utility of computational linguistic approaches to concept discovery in text using constrained natural language processing and knowledge base construction.  3. Refine strategies for automated indexing of a wide variety of textual material, including abstracts, full text of articles, textbooks, and hypertext.  4. Explore different user interfaces, aiming to allow optimal retrieval for both novice and expert users.  5. Assess the use of semantic relationships between concepts in indexing and retrieval.  6. Integrate the SAPHIRE approach with other programs, such as the CODEX system and Explorer-2, and scale up to large text collections.  In the course of the project we will create an IR system that will help meet the information needs of busy health care providers.  Such a system should have a diverse variety of content available as well as quality indexing to represent content accurately.  It should also feature retrieval capability that is fast and easy to use.  In this grant, we propose to iteratively build an IR system that utilizes concept-based probabilistic indexing and retrieval, and evaluate it each step along the way in laboratory as well as real world settings.  n/a",SAPHIRE:  A CONCEPT-BASED APPROACH TO INFO RETRIEVAL,3474525,R29LM005307,"['artificial intelligence', ' health care facility information system', ' indexing', ' information retrieval', ' information system analysis', ' information systems', ' language']",NLM,OREGON HEALTH AND SCIENCE UNIVERSITY,R29,1991,91537,0.012256758610967236
"DEVELOPMENT OF A SEMANTIC PARSER FOR MEDICAL TEXT This project seeks to develop a natural language understanding system specifically aimed at extracting relevant clinical facts from medical reports.  The system is based largely on a semantic parsing technique that stresses the use of medical knowledge encoded in four forms.  These forms include: a hierarchy of terms embedded in a general purpose medical data dictionary; a semantic network designed to capture knowledge concerning the relative locations of different anatomic sites; a collection of frames specifying allowable combinations of terms.  These frames also have a hierarchial organization designed to help the parser find an appropriate format for the recognition and storage of a complex medical fact; a transformational grammar attached to the hierarchy of frames which can propose the different ways a medical fact, as indicated by the combined terms in a frame, might be expressed; a causal network developed specifically to allow disambiguation of the many incompletely expressed facts that can be found in a medical report.  Both a lexicon expressing the different words known to the system and a thesaurus expressing all meaningful phrases expected in the reporting domain will also be built.  A system that uses this information to parse medical text will be constructed and evaluated.  The domains tested will be the reports of chest x-rays and admitting history and physical examination for patients with pulmonary and/or cardiac diseases.  The evaluation will determine whether relevant medical facts presented in the reports are captured and stored by the natural language parser in an integrated, general purpose medical data base.  The goal of this project is to further techniques that allow the encoding of medical information captured as free text into a form appropriate for research, quality, assurance, and direct clinical decision support.  n/a",DEVELOPMENT OF A SEMANTIC PARSER FOR MEDICAL TEXT,2237761,R01LM005323,"['abstracting', ' artificial intelligence', ' computer program /software', ' health care facility information system', ' information system analysis', ' respiratory imaging /visualization', ' semantics']",NLM,LDS HOSPITAL,R01,1993,158368,0.029358800490993556
"DEVELOPMENT OF A SEMANTIC PARSER FOR MEDICAL TEXT This project seeks to develop a natural language understanding system specifically aimed at extracting relevant clinical facts from medical reports.  The system is based largely on a semantic parsing technique that stresses the use of medical knowledge encoded in four forms.  These forms include: a hierarchy of terms embedded in a general purpose medical data dictionary; a semantic network designed to capture knowledge concerning the relative locations of different anatomic sites; a collection of frames specifying allowable combinations of terms.  These frames also have a hierarchial organization designed to help the parser find an appropriate format for the recognition and storage of a complex medical fact; a transformational grammar attached to the hierarchy of frames which can propose the different ways a medical fact, as indicated by the combined terms in a frame, might be expressed; a causal network developed specifically to allow disambiguation of the many incompletely expressed facts that can be found in a medical report.  Both a lexicon expressing the different words known to the system and a thesaurus expressing all meaningful phrases expected in the reporting domain will also be built.  A system that uses this information to parse medical text will be constructed and evaluated.  The domains tested will be the reports of chest x-rays and admitting history and physical examination for patients with pulmonary and/or cardiac diseases.  The evaluation will determine whether relevant medical facts presented in the reports are captured and stored by the natural language parser in an integrated, general purpose medical data base.  The goal of this project is to further techniques that allow the encoding of medical information captured as free text into a form appropriate for research, quality, assurance, and direct clinical decision support.  n/a",DEVELOPMENT OF A SEMANTIC PARSER FOR MEDICAL TEXT,3374328,R01LM005323,"['abstracting', ' artificial intelligence', ' health care facility information system', ' information system analysis', ' respiratory imaging /visualization', ' semantics']",NLM,LDS HOSPITAL,R01,1992,148634,0.029358800490993556
"DEVELOPMENT OF A SEMANTIC PARSER FOR MEDICAL TEXT This project seeks to develop a natural language understanding system specifically aimed at extracting relevant clinical facts from medical reports.  The system is based largely on a semantic parsing technique that stresses the use of medical knowledge encoded in four forms.  These forms include: a hierarchy of terms embedded in a general purpose medical data dictionary; a semantic network designed to capture knowledge concerning the relative locations of different anatomic sites; a collection of frames specifying allowable combinations of terms.  These frames also have a hierarchial organization designed to help the parser find an appropriate format for the recognition and storage of a complex medical fact; a transformational grammar attached to the hierarchy of frames which can propose the different ways a medical fact, as indicated by the combined terms in a frame, might be expressed; a causal network developed specifically to allow disambiguation of the many incompletely expressed facts that can be found in a medical report.  Both a lexicon expressing the different words known to the system and a thesaurus expressing all meaningful phrases expected in the reporting domain will also be built.  A system that uses this information to parse medical text will be constructed and evaluated.  The domains tested will be the reports of chest x-rays and admitting history and physical examination for patients with pulmonary and/or cardiac diseases.  The evaluation will determine whether relevant medical facts presented in the reports are captured and stored by the natural language parser in an integrated, general purpose medical data base.  The goal of this project is to further techniques that allow the encoding of medical information captured as free text into a form appropriate for research, quality, assurance, and direct clinical decision support.  n/a",DEVELOPMENT OF A SEMANTIC PARSER FOR MEDICAL TEXT,3374327,R01LM005323,"['abstracting', ' artificial intelligence', ' health care facility information system', ' information system analysis', ' respiratory imaging /visualization', ' semantics']",NLM,LDS HOSPITAL,R01,1991,143397,0.029358800490993556
"LATENT SEMANTIC INDEXING--PATIENT DATA RETRIEVAL Most medical knowledge and patient record data are represented as natural language.  Record-based clinical research in the areas of outcome analysis, epidemiology, and health services research are dependent upon the organization of patient data into analyzable categories.  Thus classifying patient events (diagnoses, procedures, or findings) is critical for the conduct of research based on the patient record.  Any progress in computer assisted medical text classification would directly contribute to the efficient conduct of clinical research deriving from patient data.  This proposal seeks to bring state of the art information retrieval techniques to bear on the problem of computer classification of clinical phrases about patients.  Success in this effort will make possible patient record-based research that includes text descriptions, a practice presently too costly or tedious to conduct widely in most medical centers.  We outline experimental variations on lexicon based word and phrase mapping into canonical form using the CLARIT system from Carnegie Mellon University.  This work will include synonym mapping, phrase recognition, and the assignment of term weights for  information matrix construction.  We have evaluated a modification of the Latent Semantic Indexing (LSI) information retrieval technique to exploit the rich structure of the UMLS Metathesaurus.  We propose refinements on our preliminary work, which constitute testable strategies for incorporating several weighting options, multidimensional structures, and ancillary information resources such as the complete ICD-9-CM.  Because this task is dependent on the computationally demanding singular value decomposition (SVD) to create principal components for statistical mapping, we include a consortium agreement with the University of Minnesota to address algorithmic variations suited to our sparse information matrix structure.  This aspect of our proposal will make the initial solution of SVD practical, removing its present dependence on supercomputers.  However, application of our proposed techniques, once a solution is computed, can be undertaken on personal computers.  Our proposal promises to improve computer-assisted classification of medical text by using the structured knowledge sources of the UMLS and its contributing nosologies in an application of LSI.  This research minimizes dependence on hand built semantic networks, focusing on statistical decomposition of existing classification structures, enriched by lexicon based preprocessing of medical text sources.  These techniques apply equally to classifying patient records and processing natural language inquiries of these databases, thereby broadening the scope and opportunity for research based on clinical records.  n/a",LATENT SEMANTIC INDEXING--PATIENT DATA RETRIEVAL,2237806,R01LM005416,"['automated medical record system', ' computer assisted medical decision making', ' computer program /software', ' indexing', ' information retrieval', ' semantics', ' vocabulary development for information system']",NLM,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R01,1994,115842,0.018610147844261866
"LATENT SEMANTIC INDEXING IN SUPPORT OF PATIENT DATA RETR Most medical knowledge and patient record data are represented as natural language.  Record-based clinical research in the areas of outcome analysis, epidemiology, and health services research are dependent upon the organization of patient data into analyzable categories.  Thus classifying patient events (diagnoses, procedures, or findings) is critical for the conduct of research based on the patient record.  Any progress in computer assisted medical text classification would directly contribute to the efficient conduct of clinical research deriving from patient data.  This proposal seeks to bring state of the art information retrieval techniques to bear on the problem of computer classification of clinical phrases about patients.  Success in this effort will make possible patient record-based research that includes text descriptions, a practice presently too costly or tedious to conduct widely in most medical centers.  We outline experimental variations on lexicon based word and phrase mapping into canonical form using the CLARIT system from Carnegie Mellon University.  This work will include synonym mapping, phrase recognition, and the assignment of term weights for  information matrix construction.  We have evaluated a modification of the Latent Semantic Indexing (LSI) information retrieval technique to exploit the rich structure of the UMLS Metathesaurus.  We propose refinements on our preliminary work, which constitute testable strategies for incorporating several weighting options, multidimensional structures, and ancillary information resources such as the complete ICD-9-CM.  Because this task is dependent on the computationally demanding singular value decomposition (SVD) to create principal components for statistical mapping, we include a consortium agreement with the University of Minnesota to address algorithmic variations suited to our sparse information matrix structure.  This aspect of our proposal will make the initial solution of SVD practical, removing its present dependence on supercomputers.  However, application of our proposed techniques, once a solution is computed, can be undertaken on personal computers.  Our proposal promises to improve computer-assisted classification of medical text by using the structured knowledge sources of the UMLS and its contributing nosologies in an application of LSI.  This research minimizes dependence on hand built semantic networks, focusing on statistical decomposition of existing classification structures, enriched by lexicon based preprocessing of medical text sources.  These techniques apply equally to classifying patient records and processing natural language inquiries of these databases, thereby broadening the scope and opportunity for research based on clinical records.  n/a",LATENT SEMANTIC INDEXING IN SUPPORT OF PATIENT DATA RETR,3374374,R01LM005416,"['automated medical record system', ' computer assisted medical decision making', ' computer program /software', ' indexing', ' information retrieval', ' semantics', ' vocabulary development for information system']",NLM,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R01,1993,111387,0.018610147844261866
"LATENT SEMANTIC INDEXING IN SUPPORT OF PATIENT DATA RETR Most medical knowledge and patient record data are represented as natural language.  Record-based clinical research in the areas of outcome analysis, epidemiology, and health services research are dependent upon the organization of patient data into analyzable categories.  Thus classifying patient events (diagnoses, procedures, or findings) is critical for the conduct of research based on the patient record.  Any progress in computer assisted medical text classification would directly contribute to the efficient conduct of clinical research deriving from patient data.  This proposal seeks to bring state of the art information retrieval techniques to bear on the problem of computer classification of clinical phrases about patients.  Success in this effort will make possible patient record-based research that includes text descriptions, a practice presently too costly or tedious to conduct widely in most medical centers.  We outline experimental variations on lexicon based word and phrase mapping into canonical form using the CLARIT system from Carnegie Mellon University.  This work will include synonym mapping, phrase recognition, and the assignment of term weights for  information matrix construction.  We have evaluated a modification of the Latent Semantic Indexing (LSI) information retrieval technique to exploit the rich structure of the UMLS Metathesaurus.  We propose refinements on our preliminary work, which constitute testable strategies for incorporating several weighting options, multidimensional structures, and ancillary information resources such as the complete ICD-9-CM.  Because this task is dependent on the computationally demanding singular value decomposition (SVD) to create principal components for statistical mapping, we include a consortium agreement with the University of Minnesota to address algorithmic variations suited to our sparse information matrix structure.  This aspect of our proposal will make the initial solution of SVD practical, removing its present dependence on supercomputers.  However, application of our proposed techniques, once a solution is computed, can be undertaken on personal computers.  Our proposal promises to improve computer-assisted classification of medical text by using the structured knowledge sources of the UMLS and its contributing nosologies in an application of LSI.  This research minimizes dependence on hand built semantic networks, focusing on statistical decomposition of existing classification structures, enriched by lexicon based preprocessing of medical text sources.  These techniques apply equally to classifying patient records and processing natural language inquiries of these databases, thereby broadening the scope and opportunity for research based on clinical records.  n/a",LATENT SEMANTIC INDEXING IN SUPPORT OF PATIENT DATA RETR,3374373,R01LM005416,"['automated medical record system', ' computer assisted medical decision making', ' indexing', ' information retrieval', ' semantics', ' vocabulary development for information system']",NLM,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R01,1992,140691,0.018610147844261866
"Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships     DESCRIPTION (provided by applicant): The rate at which new drugs are being introduced to market is decreasing, with grave implications for human health. Knowledge about the molecular mechanisms relevant to drug response is critical, but is collected in myriad individual experiments. As a result, the published literature contains rich information about how drugs and genes/gene products interact to produce phenotypes at the molecular, cellular and organismal levels, but this textual data requires substantial additional processing. As a result, there are efforts to manually curate the literature, and extract relationships between three key entities: genes/gene products, drugs and phenotypes-with the goal of representing the information in structured, computable formats. Although automated text mining may ultimately replace expert human curators, its best current role is to triage the literature and bring potentially important information to the attention of human curators. Recent advances in computational natural language processing (NLP) generally, and within our laboratory specifically, offer an opportunity to extract relationships between key entities with high accuracy. In particular, we have prototyped methods that take a relatively small set of examples of a relationship of interest (e.g. examples of gene-drug pairs in which the gene product metabolizes the drug) and then and other pairs that share a similar relationship. These methods can be applied to any relationship between our three key entity types. Thus, we propose an ambitious plan to (1) gather large corpora of biomedical text and extend existing lexicons for these entities, (2) build a database of all sentences/paragraphs relating these entities to one another, (3) create methods for accurately extracting semantically precise relationships from all pairs of entity types, and (4) validate these extracted relationships using both available gold standard data experimental sources and expert curator evaluation. In addition to directly supporting curation, our methods and extractions will be made available as general purpose resources for understanding drug action. Project Narrative Published biological text contains an abundance of valuable information about how drugs work at the molecular, cellular and organism levels and how they affect patients. However, it is difcult to gather all relevant information to support discovery of new drugs and optimal use of existing drugs. This proposal outlines a plan to develop methods for extracting drug-related information from huge collections of text, and using it to improve drug discovery and use.",Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships,9521542,R01LM005652,"['Affect', 'Algorithms', 'Attention', 'Basic Science', 'Biological', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Dependence', 'Drug effect disorder', 'Drug usage', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'Gold', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Linguistics', 'Literature', 'Manuals', 'Metabolism', 'Methods', 'Molecular', 'Natural Language Processing', 'Organism', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Proteins', 'Publishing', 'Reporting', 'Research', 'Resources', 'Role', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Triage', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'computer science', 'drug discovery', 'experience', 'experimental study', 'gene discovery', 'gene product', 'improved', 'interest', 'knowledge base', 'novel therapeutics', 'prototype', 'response', 'text searching', 'tool']",NLM,STANFORD UNIVERSITY,R01,2018,341913,0.014729245800849534
"Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships Project Summary The rate at which new drugs are being introduced to market is decreasing, with grave implications for human health. Knowledge about the molecular mechanisms relevant to drug response is critical, but is collected in myriad individual experiments. As a result, the published literature contains rich information about how drugs and genes/gene products interact to produce phenotypes at the molecular, cellular and organismal levels, but this textual data requires substantial additional processing. As a result, there are efforts to manually curate the literature, and extract relationships between three key entities: genes/gene products, drugs and phenotypeswith the goal of representing the information in structured, computable formats. Although automated text mining may ultimately replace expert human curators, its best current role is to triage the literature and bring potentially important information to the attention of human curators. Recent advances in computational natural language processing (NLP) generally, and within our laboratory specically, offer an opportunity to extract relationships between key entities with high accuracy. In particular, we have prototyped methods that take a relatively small set of examples of a relationship of interest (e.g. examples of gene-drug pairs in which the gene product metabolizes the drug) and then nd other pairs that share a similar relationship. These methods can be applied to any relationship between our three key entity types. Thus, we propose an ambitious plan to (1) gather large corpora of biomedical text and extend existing lexicons for these entities, (2) build a database of all sentences/paragraphs relating these entities to one another, (3) create methods for accurately extracting semantically precise relationships from all pairs of entity types, and (4) validate these extracted relationships using both available gold standard data experimental sources and expert curator evaluation. In addition to directly supporting curation, our methods and extractions will be made available as general purpose resources for understanding drug action. Project Narrative Published biological text contains an abundance of valuable information about how drugs work at the molecular, cellular and organism levels and how they affect patients. However, it is difcult to gather all relevant information to support discovery of new drugs and optimal use of existing drugs. This proposal outlines a plan to develop methods for extracting drug-related information from huge collections of text, and using it to improve drug discovery and use.",Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships,9755730,R01LM005652,"['Affect', 'Algorithms', 'Attention', 'Basic Science', 'Biological', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Dependence', 'Drug effect disorder', 'Drug usage', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'Gold', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Linguistics', 'Literature', 'Manuals', 'Metabolism', 'Methods', 'Molecular', 'Natural Language Processing', 'Organism', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Proteins', 'Publishing', 'Reporting', 'Research', 'Resources', 'Role', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Triage', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'computer science', 'drug discovery', 'experience', 'experimental study', 'gene discovery', 'gene product', 'improved', 'interest', 'knowledge base', 'novel therapeutics', 'prototype', 'response', 'text searching', 'tool']",NLM,STANFORD UNIVERSITY,R01,2018,353976,0.014729245800849534
"Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships     DESCRIPTION (provided by applicant): The rate at which new drugs are being introduced to market is decreasing, with grave implications for human health. Knowledge about the molecular mechanisms relevant to drug response is critical, but is collected in myriad individual experiments. As a result, the published literature contains rich information about how drugs and genes/gene products interact to produce phenotypes at the molecular, cellular and organismal levels, but this textual data requires substantial additional processing. As a result, there are efforts to manually curate the literature, and extract relationships between three key entities: genes/gene products, drugs and phenotypes-with the goal of representing the information in structured, computable formats. Although automated text mining may ultimately replace expert human curators, its best current role is to triage the literature and bring potentially important information to the attention of human curators. Recent advances in computational natural language processing (NLP) generally, and within our laboratory specifically, offer an opportunity to extract relationships between key entities with high accuracy. In particular, we have prototyped methods that take a relatively small set of examples of a relationship of interest (e.g. examples of gene-drug pairs in which the gene product metabolizes the drug) and then and other pairs that share a similar relationship. These methods can be applied to any relationship between our three key entity types. Thus, we propose an ambitious plan to (1) gather large corpora of biomedical text and extend existing lexicons for these entities, (2) build a database of all sentences/paragraphs relating these entities to one another, (3) create methods for accurately extracting semantically precise relationships from all pairs of entity types, and (4) validate these extracted relationships using both available gold standard data experimental sources and expert curator evaluation. In addition to directly supporting curation, our methods and extractions will be made available as general purpose resources for understanding drug action. Project Narrative Published biological text contains an abundance of valuable information about how drugs work at the molecular, cellular and organism levels and how they affect patients. However, it is difcult to gather all relevant information to support discovery of new drugs and optimal use of existing drugs. This proposal outlines a plan to develop methods for extracting drug-related information from huge collections of text, and using it to improve drug discovery and use.",Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships,9306199,R01LM005652,"['Affect', 'Algorithms', 'Attention', 'Basic Science', 'Biological', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Dependency', 'Drug effect disorder', 'Drug usage', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'Gold', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Linguistics', 'Literature', 'Manuals', 'Metabolism', 'Methods', 'Molecular', 'Natural Language Processing', 'Organism', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Proteins', 'Publishing', 'Reporting', 'Research', 'Resources', 'Role', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Triage', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'computer science', 'drug discovery', 'experience', 'experimental study', 'gene discovery', 'gene product', 'improved', 'interest', 'knowledge base', 'novel therapeutics', 'prototype', 'response', 'text searching', 'tool']",NLM,STANFORD UNIVERSITY,R01,2017,331290,0.014729245800849534
"Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships     DESCRIPTION (provided by applicant): The rate at which new drugs are being introduced to market is decreasing, with grave implications for human health. Knowledge about the molecular mechanisms relevant to drug response is critical, but is collected in myriad individual experiments. As a result, the published literature contains rich information about how drugs and genes/gene products interact to produce phenotypes at the molecular, cellular and organismal levels, but this textual data requires substantial additional processing. As a result, there are efforts to manually curate the literature, and extract relationships between three key entities: genes/gene products, drugs and phenotypes-with the goal of representing the information in structured, computable formats. Although automated text mining may ultimately replace expert human curators, its best current role is to triage the literature and bring potentially important information to the attention of human curators. Recent advances in computational natural language processing (NLP) generally, and within our laboratory specifically, offer an opportunity to extract relationships between key entities with high accuracy. In particular, we have prototyped methods that take a relatively small set of examples of a relationship of interest (e.g. examples of gene-drug pairs in which the gene product metabolizes the drug) and then and other pairs that share a similar relationship. These methods can be applied to any relationship between our three key entity types. Thus, we propose an ambitious plan to (1) gather large corpora of biomedical text and extend existing lexicons for these entities, (2) build a database of all sentences/paragraphs relating these entities to one another, (3) create methods for accurately extracting semantically precise relationships from all pairs of entity types, and (4) validate these extracted relationships using both available gold standard data experimental sources and expert curator evaluation. In addition to directly supporting curation, our methods and extractions will be made available as general purpose resources for understanding drug action. Project Narrative Published biological text contains an abundance of valuable information about how drugs work at the molecular, cellular and organism levels and how they affect patients. However, it is difcult to gather all relevant information to support discovery of new drugs and optimal use of existing drugs. This proposal outlines a plan to develop methods for extracting drug-related information from huge collections of text, and using it to improve drug discovery and use.",Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships,9119636,R01LM005652,"['Affect', 'Algorithms', 'Attention', 'Basic Science', 'Biological', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Dependency', 'Drug effect disorder', 'Drug usage', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'Gold', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Linguistics', 'Literature', 'Marketing', 'Metabolism', 'Methods', 'Molecular', 'Natural Language Processing', 'Organism', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Reporting', 'Research', 'Resources', 'Role', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Triage', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'computer science', 'drug discovery', 'experience', 'gene discovery', 'gene product', 'improved', 'interest', 'knowledge base', 'novel therapeutics', 'research study', 'response', 'text searching', 'tool']",NLM,STANFORD UNIVERSITY,R01,2016,340748,0.014729245800849534
"Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships     DESCRIPTION (provided by applicant): The rate at which new drugs are being introduced to market is decreasing, with grave implications for human health. Knowledge about the molecular mechanisms relevant to drug response is critical, but is collected in myriad individual experiments. As a result, the published literature contains rich information about how drugs and genes/gene products interact to produce phenotypes at the molecular, cellular and organismal levels, but this textual data requires substantial additional processing. As a result, there are efforts to manually curate the literature, and extract relationships between three key entities: genes/gene products, drugs and phenotypes-with the goal of representing the information in structured, computable formats. Although automated text mining may ultimately replace expert human curators, its best current role is to triage the literature and bring potentially important information to the attention of human curators. Recent advances in computational natural language processing (NLP) generally, and within our laboratory specifically, offer an opportunity to extract relationships between key entities with high accuracy. In particular, we have prototyped methods that take a relatively small set of examples of a relationship of interest (e.g. examples of gene-drug pairs in which the gene product metabolizes the drug) and then and other pairs that share a similar relationship. These methods can be applied to any relationship between our three key entity types. Thus, we propose an ambitious plan to (1) gather large corpora of biomedical text and extend existing lexicons for these entities, (2) build a database of all sentences/paragraphs relating these entities to one another, (3) create methods for accurately extracting semantically precise relationships from all pairs of entity types, and (4) validate these extracted relationships using both available gold standard data experimental sources and expert curator evaluation. In addition to directly supporting curation, our methods and extractions will be made available as general purpose resources for understanding drug action.             Project Narrative Published biological text contains an abundance of valuable information about how drugs work at the molecular, cellular and organism levels and how they affect patients. However, it is difcult to gather all relevant information to support discovery of new drugs and optimal use of existing drugs. This proposal outlines a plan to develop methods for extracting drug-related information from huge collections of text, and using it to improve drug discovery and use.",Text Mining for High-fidelity Curation and Discovery of Gene-drug-phenotype Relationships,8963236,R01LM005652,"['Affect', 'Algorithms', 'Attention', 'Basic Science', 'Biological', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Dependency', 'Drug effect disorder', 'Drug usage', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'Gold', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Linguistics', 'Literature', 'Marketing', 'Metabolism', 'Methods', 'Molecular', 'Natural Language Processing', 'Organism', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Reporting', 'Research', 'Resources', 'Role', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Triage', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'computer science', 'drug discovery', 'experience', 'gene discovery', 'improved', 'interest', 'knowledge base', 'novel therapeutics', 'research study', 'response', 'text searching', 'tool']",NLM,STANFORD UNIVERSITY,R01,2015,344659,0.014729245800849534
"VOCABULARY AND TEXT DATA EXTRACTION FROM THE EMR The electronic medical record (EMR) holds great allure to both the               medical informatics and health services research communities. In this            project, we propose to enhance the capability of electronic medical              record (EMR) systems by creating and evaluating tools to extract                 clinical vocabularies as well as patient data from narrative text                reports. We will apply advanced natural language processing tools from           the CLARIT system to both of the above problems. We contend that fast            and robust automated text processing methods are the only way that the           problems of vocabulary construction and narrative text extraction can            be solved.                                                                                                                                                        We will address the clinical vocabulary problem by utilizing the                 thesaurus extraction techniques already present in the CLARIT system.            Using several gigabytes of narrative text, including discharge                   summaries, progress notes, radiology reports, and other clinical text,           we plan to:                                                                      l. Identify empirically the terminology used in medicine.                        2. Compare the coverage of that terminology in several existing large            medical vocabularies: UMLS, SNOMED, and the Medical Entities                     Dictionary.                                                                      3. Discern the semantic characteristics of that terminology to allow             other structured vocabularies a richer substrate of terms as well as             providing us the opportunity to implement a clinical vocabulary schema           based on the methods of the MedSORT-II Project.                                  4. Evaluate how well our tools assist the vocabulary building efforts            of ourselves and others.                                                                                                                                          The narrative extraction problem will be approached differently than             in the past, building on the efforts of previous investigators who               have tackled this problem before but changing the perspective by                 focusing on the development of tools specific to researchers and                 others with a need to extract data from narrative text. This approach            will be applied in two domains:                                                  l.Consortium-based research in the use of esophogastroduodenoscopy               (EGD).                                                                           2.Practice guidelines implementation in blood product transfusion.                n/a",VOCABULARY AND TEXT DATA EXTRACTION FROM THE EMR,2332614,U01LM005879,"['abstracting', ' automated medical record system', ' blood transfusion', ' cooperative study', ' endoscopy', ' vocabulary development for information system']",NLM,OREGON HEALTH AND SCIENCE UNIVERSITY,U01,1997,294900,0.04898334321328704
"VOCABULARY AND TEXT DATA EXTRACTION FROM THE EMR The electronic medical record (EMR) holds great allure to both the  medical informatics and health services research communities. In this  project, we propose to enhance the capability of electronic medical  record (EMR) systems by creating and evaluating tools to extract  clinical vocabularies as well as patient data from narrative text  reports. We will apply advanced natural language processing tools from  the CLARIT system to both of the above problems. We contend that fast  and robust automated text processing methods are the only way that the  problems of vocabulary construction and narrative text extraction can  be solved.    We will address the clinical vocabulary problem by utilizing the  thesaurus extraction techniques already present in the CLARIT system.  Using several gigabytes of narrative text, including discharge  summaries, progress notes, radiology reports, and other clinical text,  we plan to:  l. Identify empirically the terminology used in medicine.  2. Compare the coverage of that terminology in several existing large  medical vocabularies: UMLS, SNOMED, and the Medical Entities  Dictionary.  3. Discern the semantic characteristics of that terminology to allow  other structured vocabularies a richer substrate of terms as well as  providing us the opportunity to implement a clinical vocabulary schema  based on the methods of the MedSORT-II Project.  4. Evaluate how well our tools assist the vocabulary building efforts  of ourselves and others.    The narrative extraction problem will be approached differently than  in the past, building on the efforts of previous investigators who  have tackled this problem before but changing the perspective by  focusing on the development of tools specific to researchers and  others with a need to extract data from narrative text. This approach  will be applied in two domains:  l.Consortium-based research in the use of esophogastroduodenoscopy  (EGD).  2.Practice guidelines implementation in blood product transfusion.  n/a",VOCABULARY AND TEXT DATA EXTRACTION FROM THE EMR,2238284,U01LM005879,"['abstracting', ' automated medical record system', ' blood transfusion', ' cooperative study', ' endoscopy', ' vocabulary development for information system']",NLM,OREGON HEALTH AND SCIENCE UNIVERSITY,U01,1995,375570,0.04898334321328704
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6490773,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2002,288252,0.050482151572908314
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6095940,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2001,303860,0.050482151572908314
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING DESCRIPTION (Taken from application abstract):  The long-term aim of this        project is to use natural language methods in order to enhance the               functionality of the electronic medical record, which is a source of             abundant clinical data.  However, the data is mostly in textual form and         therefore unusable for automated clinical applications, such as decision         support, research, quality assurance, and outcomes assessment.  By using a       natural language processor to map the clinical information in the reports        into structured codified clinical data, the data will be made readily            accessible so that it could be utilized by subsequent automated clinical         applications.  We have already shown that it is possible to build an             effective text processor that accurately codifies textual reports within the     specialized domain of radiology.  In this project we intend to build upon        our successful experience and will extend the processor to another limited       domain that is different from radiology and to a broad domain in order to        study the feasibility of transferring the processor to all of medicine.                                                                                           More specifically, we will broaden the processor so that it codifies             clinical information in the physical examination section of the discharge        summary and then to all of the discharge summary, where we will focus on         coding diagnoses.  The emphasis of our work will not only be concerned with      extending the language processor but will also focus on scalability,             evaluation of the performance, the effort, and the portability aspects.  In      addition, because discharge summaries are so complex and comprehensive, we       will have to extend the formal representational model of the clinical            information and also develop new natural language processing techniques and      new vocabulary development tools.  This work will continue to be performed       within an operational clinical setting.                                           n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,2897383,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,1999,209130,0.04945879942077019
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING DESCRIPTION (Taken from application abstract):  The long-term aim of this        project is to use natural language methods in order to enhance the               functionality of the electronic medical record, which is a source of             abundant clinical data.  However, the data is mostly in textual form and         therefore unusable for automated clinical applications, such as decision         support, research, quality assurance, and outcomes assessment.  By using a       natural language processor to map the clinical information in the reports        into structured codified clinical data, the data will be made readily            accessible so that it could be utilized by subsequent automated clinical         applications.  We have already shown that it is possible to build an             effective text processor that accurately codifies textual reports within the     specialized domain of radiology.  In this project we intend to build upon        our successful experience and will extend the processor to another limited       domain that is different from radiology and to a broad domain in order to        study the feasibility of transferring the processor to all of medicine.                                                                                           More specifically, we will broaden the processor so that it codifies             clinical information in the physical examination section of the discharge        summary and then to all of the discharge summary, where we will focus on         coding diagnoses.  The emphasis of our work will not only be concerned with      extending the language processor but will also focus on scalability,             evaluation of the performance, the effort, and the portability aspects.  In      addition, because discharge summaries are so complex and comprehensive, we       will have to extend the formal representational model of the clinical            information and also develop new natural language processing techniques and      new vocabulary development tools.  This work will continue to be performed       within an operational clinical setting.                                           n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,2735428,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,1998,204002,0.04945879942077019
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING DESCRIPTION (Taken from application abstract):  The long-term aim of this        project is to use natural language methods in order to enhance the               functionality of the electronic medical record, which is a source of             abundant clinical data.  However, the data is mostly in textual form and         therefore unusable for automated clinical applications, such as decision         support, research, quality assurance, and outcomes assessment.  By using a       natural language processor to map the clinical information in the reports        into structured codified clinical data, the data will be made readily            accessible so that it could be utilized by subsequent automated clinical         applications.  We have already shown that it is possible to build an             effective text processor that accurately codifies textual reports within the     specialized domain of radiology.  In this project we intend to build upon        our successful experience and will extend the processor to another limited       domain that is different from radiology and to a broad domain in order to        study the feasibility of transferring the processor to all of medicine.                                                                                           More specifically, we will broaden the processor so that it codifies             clinical information in the physical examination section of the discharge        summary and then to all of the discharge summary, where we will focus on         coding diagnoses.  The emphasis of our work will not only be concerned with      extending the language processor but will also focus on scalability,             evaluation of the performance, the effort, and the portability aspects.  In      addition, because discharge summaries are so complex and comprehensive, we       will have to extend the formal representational model of the clinical            information and also develop new natural language processing techniques and      new vocabulary development tools.  This work will continue to be performed       within an operational clinical setting.                                           n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,2032409,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,1997,218581,0.04945879942077019
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8493901,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2012,1154966,0.019455709971714665
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8192387,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2011,818798,0.019455709971714665
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8721471,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2014,191107,0.019455709971714665
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8728454,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2013,197687,0.019455709971714665
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8517791,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2013,935039,0.019455709971714665
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8731268,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2014,141159,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8733235,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2013,172763,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8523193,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2013,958491,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8510804,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2012,240967,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8548641,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2012,120000,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8329776,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2011,117762,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8194378,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2011,762500,0.023730625422593476
"A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience    DESCRIPTION (provided by applicant): One promise of the human genome project was to enable genome-informed personalized medicine. During the past four years Northwestern has been a site in the eMERGE network. This consortium of biobanks linked to electronic health records (EHR) has developed portable algorithms to identify cases and controls from EHR data and then performed genome-wide association studies (GWAS) to correlate genetic variation with disease and normal physiological variation in widely measured laboratory values. In response to RFA-HG-10-009, we propose to contribute to the network development of additional phenotype algorithms and the analysis of the genotype data from the Northwestern eMERGE cohort supplemented by approximately 3,000 additional EHR-linked samples, each associated with 660k GWAS genotypes. We will develop a range of phenotypes that will allow us to assess patient and physician attitudes to the utility of genetic information in predicting disease susceptibility, drug response and therapeutic outcomes. Based on these consultations, we propose to develop a modified quality improvement model for determining, in a pilot study, which genotypes might be most valuable to present in a clinical care setting. We will develop a consent model and associated educational methods in support of providing experimental subjects with genotype information in a clinical encounter, including CLIA certified re-genotyping of participants who were previously genotyped for research purposes. At Northwestern, we utilize a widely-deployed, commercial EHR, EPIC, and propose to develop technical approaches for integrating genetic variation data into the health record and to effectively present these results using point-of-care, decision support tools to physicians. A goal of this effort is to develop best practices collaboratively within the network, for reporting of genetic variation data and developing local practice guidelines for using genetic data in primary care clinical encounters. Finally, we propose a rigorous assessment of the impact of these approaches on primary care physicians and their patients, defining the regulatory issues and then disseminating lessons learned and best practice recommendations. Together, the work proposed should provide an assessment of key elements of genome-informed personalized medicine.       RELEVANCE:  This project begins to answer questions about using genomic analysis and applying it to real world clinical situations. We propose to study the clinical and personal utility of genomic variation in a diverse primary care patient and physician population.           n/a",A Personalized Genomic Medicine Pilot Program Using the NJgene eMERGE Experience,8319350,U01HG006388,"['African American', 'Algorithms', 'Asthma', 'Attitude', 'Cardiac', 'Clinical', 'Collection', 'Consent', 'Consult', 'Consultations', 'Data', 'Deposition', 'Development', 'Diabetes Mellitus', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Electronics', 'Elements', 'Focus Groups', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Height', 'Human', 'Human Genome Project', 'Hypothyroidism', 'Individual', 'Institutional Review Boards', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Logic', 'Measures', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Physiological', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Practice Guidelines', 'Primary Care Physician', 'Primary Health Care', 'Principal Investigator', 'Process', 'Recommendation', 'Reporting', 'Research', 'Sampling', 'Site', 'Surveys', 'Testing', 'Therapeutic', 'Toxic effect', 'Variant', 'Work', 'base', 'biobank', 'case control', 'clinical care', 'clinically relevant', 'cohort', 'community consultation', 'exome', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'health record', 'meetings', 'point of care', 'programs', 'response', 'text searching', 'tool']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2012,762500,0.023730625422593476
"INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING DESCRIPTION (Taken from application abstract):  This proposed study will         replicate and extend methodology used in earlier studies and will use            extensive clinical data repositories, informatics tools, and expert              practitioners for perinatal medical knowledge building.                                                                                                           Clinical Data Repository:  Duke University's Medical Center (DUMC) TMR (The      Medical Record) data repository will be used for this study, and contains        45,922 electronic medical records for both low and high-risk pregnant women      (and their infants) who have received prenatal care at DUMC, and its             affiliated regional clinics, between 1/1/86 and 12/3l/95.  Each patient's        electronic data is used for clinical patient care and contains a potential       4000 variables per record.  This volume of data requires new approaches for      data analysis and medical decision support, since human information              processing limitations become quickly overloaded by both an individual           patient s data and the aggregate information collected for the perinatal         patient population.                                                                                                                                               lnformatics Tools:  Informatics techniques for knowledge acquisition and         data mining will use machine learning programs, statistical analysis, and        domain expert input to articulate relationships between the data and             perinatal patent outcomes.  The goal is to provide decision support for          perinatal care providers to accurately identify patients at risk and assist      them with modifiable preterm birth ask factors.  An expert system will use       data-generated and verified knowledge bases to test its predictive validity      when new patient cases are induced to the expert system.  Earlier studies        found 53-90% predictive accuracies for an expert system prototype, as            compared to 17-38% accuracies, reported in the literature, using current         manual techniques.  Mapping the expert system's knowledge base terms to          medical library resources will be explored for additional decision support.                                                                                       Expert Practitioner:  The perinatal expert panel will consist of the             Principal Investigator, a Board Certified OB-Gyn Physician, and a certified      Perinatal RN.  Each of the panel members has more than 20 years of perinatal     experience.  Participating informatics experts are known, both nationally        and internationally for their expertise in the field of Medical Informatics.      n/a",INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING,6577458,R01LM006488,"['artificial intelligence', ' computer system design /evaluation', ' human data', ' information systems', ' prenatal care']",NLM,DUKE UNIVERSITY,R01,2002,382114,0.030069179816462434
"INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING DESCRIPTION (Taken from application abstract):  This proposed study will         replicate and extend methodology used in earlier studies and will use            extensive clinical data repositories, informatics tools, and expert              practitioners for perinatal medical knowledge building.                                                                                                           Clinical Data Repository:  Duke University's Medical Center (DUMC) TMR (The      Medical Record) data repository will be used for this study, and contains        45,922 electronic medical records for both low and high-risk pregnant women      (and their infants) who have received prenatal care at DUMC, and its             affiliated regional clinics, between 1/1/86 and 12/3l/95.  Each patient's        electronic data is used for clinical patient care and contains a potential       4000 variables per record.  This volume of data requires new approaches for      data analysis and medical decision support, since human information              processing limitations become quickly overloaded by both an individual           patient s data and the aggregate information collected for the perinatal         patient population.                                                                                                                                               lnformatics Tools:  Informatics techniques for knowledge acquisition and         data mining will use machine learning programs, statistical analysis, and        domain expert input to articulate relationships between the data and             perinatal patent outcomes.  The goal is to provide decision support for          perinatal care providers to accurately identify patients at risk and assist      them with modifiable preterm birth ask factors.  An expert system will use       data-generated and verified knowledge bases to test its predictive validity      when new patient cases are induced to the expert system.  Earlier studies        found 53-90% predictive accuracies for an expert system prototype, as            compared to 17-38% accuracies, reported in the literature, using current         manual techniques.  Mapping the expert system's knowledge base terms to          medical library resources will be explored for additional decision support.                                                                                       Expert Practitioner:  The perinatal expert panel will consist of the             Principal Investigator, a Board Certified OB-Gyn Physician, and a certified      Perinatal RN.  Each of the panel members has more than 20 years of perinatal     experience.  Participating informatics experts are known, both nationally        and internationally for their expertise in the field of Medical Informatics.      n/a",INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING,2897391,R01LM006488,"['artificial intelligence', ' computer system design /evaluation', ' human data', ' information systems', ' prenatal care']",NLM,DUKE UNIVERSITY,R01,1999,308857,0.030069179816462434
"INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING DESCRIPTION (Taken from application abstract):  This proposed study will         replicate and extend methodology used in earlier studies and will use            extensive clinical data repositories, informatics tools, and expert              practitioners for perinatal medical knowledge building.                                                                                                           Clinical Data Repository:  Duke University's Medical Center (DUMC) TMR (The      Medical Record) data repository will be used for this study, and contains        45,922 electronic medical records for both low and high-risk pregnant women      (and their infants) who have received prenatal care at DUMC, and its             affiliated regional clinics, between 1/1/86 and 12/3l/95.  Each patient's        electronic data is used for clinical patient care and contains a potential       4000 variables per record.  This volume of data requires new approaches for      data analysis and medical decision support, since human information              processing limitations become quickly overloaded by both an individual           patient s data and the aggregate information collected for the perinatal         patient population.                                                                                                                                               lnformatics Tools:  Informatics techniques for knowledge acquisition and         data mining will use machine learning programs, statistical analysis, and        domain expert input to articulate relationships between the data and             perinatal patent outcomes.  The goal is to provide decision support for          perinatal care providers to accurately identify patients at risk and assist      them with modifiable preterm birth ask factors.  An expert system will use       data-generated and verified knowledge bases to test its predictive validity      when new patient cases are induced to the expert system.  Earlier studies        found 53-90% predictive accuracies for an expert system prototype, as            compared to 17-38% accuracies, reported in the literature, using current         manual techniques.  Mapping the expert system's knowledge base terms to          medical library resources will be explored for additional decision support.                                                                                       Expert Practitioner:  The perinatal expert panel will consist of the             Principal Investigator, a Board Certified OB-Gyn Physician, and a certified      Perinatal RN.  Each of the panel members has more than 20 years of perinatal     experience.  Participating informatics experts are known, both nationally        and internationally for their expertise in the field of Medical Informatics.      n/a",INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING,2714219,R01LM006488,"['artificial intelligence', ' computer system design /evaluation', ' human data', ' information systems', ' prenatal care']",NLM,DUKE UNIVERSITY,R01,1998,274266,0.030069179816462434
"INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING DESCRIPTION (Taken from application abstract):  This proposed study will         replicate and extend methodology used in earlier studies and will use            extensive clinical data repositories, informatics tools, and expert              practitioners for perinatal medical knowledge building.                                                                                                           Clinical Data Repository:  Duke University's Medical Center (DUMC) TMR (The      Medical Record) data repository will be used for this study, and contains        45,922 electronic medical records for both low and high-risk pregnant women      (and their infants) who have received prenatal care at DUMC, and its             affiliated regional clinics, between 1/1/86 and 12/3l/95.  Each patient's        electronic data is used for clinical patient care and contains a potential       4000 variables per record.  This volume of data requires new approaches for      data analysis and medical decision support, since human information              processing limitations become quickly overloaded by both an individual           patient s data and the aggregate information collected for the perinatal         patient population.                                                                                                                                               lnformatics Tools:  Informatics techniques for knowledge acquisition and         data mining will use machine learning programs, statistical analysis, and        domain expert input to articulate relationships between the data and             perinatal patent outcomes.  The goal is to provide decision support for          perinatal care providers to accurately identify patients at risk and assist      them with modifiable preterm birth ask factors.  An expert system will use       data-generated and verified knowledge bases to test its predictive validity      when new patient cases are induced to the expert system.  Earlier studies        found 53-90% predictive accuracies for an expert system prototype, as            compared to 17-38% accuracies, reported in the literature, using current         manual techniques.  Mapping the expert system's knowledge base terms to          medical library resources will be explored for additional decision support.                                                                                       Expert Practitioner:  The perinatal expert panel will consist of the             Principal Investigator, a Board Certified OB-Gyn Physician, and a certified      Perinatal RN.  Each of the panel members has more than 20 years of perinatal     experience.  Participating informatics experts are known, both nationally        and internationally for their expertise in the field of Medical Informatics.      n/a",INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING,2032587,R01LM006488,"['artificial intelligence', ' computer system design /evaluation', ' human data', ' information systems', ' prenatal care']",NLM,DUKE UNIVERSITY,R01,1997,279649,0.030069179816462434
"Multisite Electronic Health Record-Based Surveillance of the Burden of Diabetes by Type in Young Adults Approximately 3 million young adults aged 18-44 years currently have diabetes in the United States. This number is projected to increase to ~5.8 million by 2060. Differentiating diabetes types is crucial, because the etiology, treatments, and outcomes of diabetes differ substantially by type. Type 1 diabetes (T1D) accounts for ~17% and type 2 diabetes (T2D) ~75% of total diabetes in US young adults. This distribution of diabetes types continuously evolves. We do not have a large-scale surveillance system to monitor the prevalence and incidence of T1D and T2D in US young adults. The widespread use and increasing functionality of electronic health record (EHR) systems substantially increase the quantity, breadth, and timeliness of data available for surveillance and reduce costs compared with population-based registries and surveys. EHR algorithms have shown great potential in identifying diabetes cases. This study will analyze both structured EHR data (e.g., diagnosis codes, medications, and laboratory results) and unstructured clinical notes. We will apply expert knowledge, machine learning, and natural language processing to develop the best algorithms for identifying prevalent and incident T1D and T2D cases. The primary objective of this study is to establish an EHR-based surveillance system for monitoring the burden of T1D and T2D in US young adults. We will collaborate with 3 EHR research networks from the National Patient-Centered Clinical Research Network (PCORnet), covering ~6 million racially, ethnically, and socioeconomically diverse young adults from 4 states (IL, LA, NY, and TX) in 3 Census regions. The patient populations in this study are roughly representative of the source populations in the catchment areas. The specific aims of this study are 1) to estimate the prevalence of T1D and T2D in US young adults by age, sex, race/ethnicity, and geographic region in 2019; 2) to estimate the incidence of T1D and T2D in US young adults by age, sex, race/ethnicity, and geographic region in 2019; 3) to estimate 10-year trends in the prevalence and incidence of T1D and T2D in US young adults by age, sex, race/ethnicity, and geographic region, 2014-2023; and 4) to compare the prevalence and incidence of diabetes by type, as well as temporal trends, in US young adults with those in young adults from other countries and regions. This study is innovative, because it will detect a false negative rate as low as 0.2%, leverage EHRs for surveillance (more efficient and cost-effective than registries and surveys), use advanced statistical approaches (e.g., machine learning and natural language processing), estimate a denominator using patient zip codes, build flexibility into the surveillance methods according to local availability of clinical notes, and use a 2-staged sampling approach to improve chart review efficiency. This study will advance our understanding of the age, sex, racial/ethnic, and geographic differences in the burden of T1D and T2D in US young adults. The obtained surveillance data will inform planning for healthcare needs, prioritize the allocation of healthcare resources, and reduce health disparities via identifying and prioritizing subpopulations for prevention of diabetes and related comorbidities. The burden of diabetes has been increasing considerably in recent decades in US young adults. However, there is no large-scale surveillance system for monitoring the burden of diabetes by type in US young adults. This study will build an efficient and cost-effective multisite surveillance system using electronic health records, to estimate the prevalence, incidence, and temporal trends of type 1 and type 2 diabetes in US young adults according to age, sex, race/ethnicity, and geographic region.",Multisite Electronic Health Record-Based Surveillance of the Burden of Diabetes by Type in Young Adults,10085448,U18DP006502,[' '],NCCDPHP,CORNELL UNIVERSITY,U18,2020,250000,0.03345689200944888
"Electronic Health Record-based Surveillance of Diabetes by Type in Young Adults in Pennsylvania 1 Currently there are 4.6 million young adults (18 to 44 years of age) with diabetes in the US and the incidence  2 and prevalence are increasing in this age group. However, due to limitations of traditional surveillance  3 strategies, it remains unknown whether these increases are in type 1 or type 2 diabetes. Electronic health  4 record (EHR)-based surveillance is a relatively simple, sustainable, and timely alternative to more traditional  5 methods. Recognizing the attributes of EHR-based surveillance, the Centers for Disease Control and  6 Prevention (CDC) has funded efforts to develop, evaluate, and deploy EHR-based surveillance of diabetes,  7 including the SEARCH for Diabetes in Youth (SEARCH) study and the Diabetes in Young Adults (DiYA) Study.  8 However, the geographic coverage of these studies has been limited. The geographical gaps in these studies  9 are problematic, as there are known geographic disparities in diabetes prevalence and incidence. Moreover, 10 little is known about how the methods applied in these studies will perform in other regions of the country, in 11 rural communities, and in other health systems. The proposed study will use more than two decades of EHR 12 data and administrative claims data to develop and implement EHR-based surveillance of type 1 and type 2 13 diabetes among young adults in a large region of Pennsylvania, the state with the 5th highest prevalence of 14 diabetes in this age group. This information is essential to informing public health strategies, assessing disease 15 burden, and prioritizing type-specific health services. We will use EHR data from Geisinger, a health system 16 serving a large and diverse region of Pennsylvania, to expand the geography of existing surveillance of 17 diabetes subtypes in young adults to the Middle Atlantic, an area without prior EHR-based diabetes 18 surveillance estimates. This region includes a combination of rural and urban communities, enabling us to 19 evaluate differences in the performance of EHR-based algorithms for case ascertainment by community type. 20 In the first phase of the study, we will evaluate the validity; simplicity; and consistency of EHR-based 21 algorithms for identifying diabetes subtypes. This work will build on previously developed algorithms from the 22 SEARCH and DiYA studies. We will use manual review of clinician notes as the gold standard to determine the 23 positive predictive value, sensitivity, and specificity of these algorithms. We propose to use an innovative, 24 efficient, and rigorous validation approach that incorporates natural language processing of clinician notes. We 25 will use a secondary data source, administrative claims data, to assess data completeness and our ability to 26 distinguish between incident and prevalent cases. In the second phase, we will use the best performing 27 algorithms to report on the annual incidence and prevalence of diabetes, by type, in young adults, between 28 2014 and 2024 in 38 Pennsylvania counties. All analyses will be stratified by age, sex, race/ethnicity, insurance 29 status, and community type (rural/urban). Finally, we will coordinate with CDC and other sites to conduct joint 30 analyses of aggregated data, greatly expanding the population under study. Narrative Currently there are 4.6 million young adults (18 to 44 years of age) with diabetes in the US and the incidence and prevalence estimates in this age group have been increasing. However, due to limitations of traditional surveillance strategies, it remains unknown whether these increases are in type 1 or type 2 diabetes. The proposed research will coordinate, develop, implement, and validate electronic-record based surveillance of diabetes in young adults, by subtype, to inform type-specific public health responses, assess disease burden, and identify priorities for type-specific health services.",Electronic Health Record-based Surveillance of Diabetes by Type in Young Adults in Pennsylvania,10085078,U18DP006509,[' '],NCCDPHP,GEISINGER CLINIC,U18,2020,249631,0.026818330121820198
"MEDLINK DESCRIPTION:  Access to comprehensive medical information is literally           a matter of life and death for health professionals.  The applicants             propose to develop a state-of-the-art medical information system based           on natural language processing (NLP) which provides innovative access            first to the literature of complementary medicine and then to the                traditional medical literature.  The goal of Phase I is dual:  to                develop a finely tuned, immediately usable information system for                alternative medicine, and to determine on an experimental level what             linguistic elements within the medical subject domain are critical to            optimizing retrieval.  For this purpose, an extensive analysis of                medical sublanguage and the text structure of medical documents will be          undertaken, and the results will be applied to each module of the system         in order to optimize it for medical domain.  The Phase I system will be          used by the medical community both for access to hard-to-find                    information, and to begin to assess the usefulness of complementary              medicine techniques in treating chronic problems.  Phase II will add             traditional medical literature to the system to provide a fully                  integrated solution for rich, precise access to medical information.                                                                                              PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                    n/a",MEDLINK,2867891,R43LM006671,"['alternative medicine', ' artificial intelligence', ' computer system design /evaluation', ' information retrieval', ' information systems', ' language']",NLM,"TEXTWISE, LLC",R43,1998,50000,-0.001776832462142625
"MEDLINK DESCRIPTION:  Access to comprehensive medical information is literally           a matter of life and death for health professionals.  The applicants             propose to develop a state-of-the-art medical information system based           on natural language processing (NLP) which provides innovative access            first to the literature of complementary medicine and then to the                traditional medical literature.  The goal of Phase I is dual:  to                develop a finely tuned, immediately usable information system for                alternative medicine, and to determine on an experimental level what             linguistic elements within the medical subject domain are critical to            optimizing retrieval.  For this purpose, an extensive analysis of                medical sublanguage and the text structure of medical documents will be          undertaken, and the results will be applied to each module of the system         in order to optimize it for medical domain.  The Phase I system will be          used by the medical community both for access to hard-to-find                    information, and to begin to assess the usefulness of complementary              medicine techniques in treating chronic problems.  Phase II will add             traditional medical literature to the system to provide a fully                  integrated solution for rich, precise access to medical information.                                                                                              PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                    n/a",MEDLINK,2647486,R43LM006671,"['alternative medicine', ' artificial intelligence', ' computer system design /evaluation', ' information retrieval', ' information systems', ' language']",NLM,"TEXTWISE, LLC",R43,1998,98672,-0.001776832462142625
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,9052542,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation sequencing', 'novel', 'prevent', 'public health relevance', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U01,2015,130994,0.0072854597457919
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,8686917,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation sequencing', 'novel', 'prevent', 'public health relevance', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U01,2014,277488,0.0072854597457919
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,8549925,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation sequencing', 'novel', 'prevent', 'public health relevance', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2013,54233,0.0072854597457919
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.        PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.              The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,8348769,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation', 'novel', 'prevent', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2012,247879,0.005909559037279947
"IMIA WG6 CONFERENCE The basic science of representing patient events, findings, interventions, and outcomes in a semantically consistent and logically reproducible way is medical concept representation.  It embodies principles of linguistics, logic, computer science, cognition, biology and clinical medicine to undertake this highly multidisciplinary activity. Much of this work is undertaken in experimental settings, which hypothesize practical extensions to existing models, and test their utility against standardized retrieval sets or clinical usability environments. The proposed conference intends to continue the tradition of the International Medical Informatics Association (IMIA), Working Group 6 on Medical Concept Representation, to provide a forum for the academic discussion of problems, issues, theories, and applications of natural language processing, knowledge representation, terminology development, and concept coordination to biomedicine and healthcare.  the proposed tracks at this time are: 1. Natural Language Processing  2. Clinical Classifications 3. Cognitive Evaluations  4. Terminology Models  5. Maintenance and Uptake Strategies.  n/a",IMIA WG6 CONFERENCE,6027283,R13LM006899,"['informatics', ' international health /scientific organization', ' meeting /conference /symposium', ' travel']",NLM,MAYO CLINIC ROCHESTER,R13,2000,20000,0.021795481204088137
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7933293,R01LM006910,"['Address', 'Area', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Machine Learning', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'clinical care', 'data mining', 'improved', 'knowledge base', 'natural language', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,152617,0.05347914490653184
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7495030,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,338600,0.05347914490653184
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY The long-term goal of our parent project, Discovering and applying knowledge in clinical databases, is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. Its first two aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. For this supplement, we plan to focus on COVID-19. The emergence of the virus SARS-CoV-2 and its corresponding disease, COVID-19, has led to about 100,000 deaths in the US and great economic loss and human suffering. Carrying out randomized clinical trials to assess treatment is essential but stymied by the difficulty recruiting sufficient patients and the urgency of the question. Clinical databases are beginning to fill with COVID-19 patients, but the acuity and severity of the disease make drawing causal conclusion much more difficult, resulting in a literature filled with conflicting observational studies. We propose to employ structural causal modeling in the study of COVID-19, engaging expertise in such modeling. We will use the Columbia University Irving Medical Center's clinical data warehouse with over 6000 testing positive for SARS-CoV-2 and the Observational Health Data Science and Informatics (OHDSI) network, which includes most COVID-19 patients in Korea, Spain, the US Veterans Administration, Stanford, Tufts, and new sites coming on board. PROJECT NARRATIVE COVID-19 has had a giant impact on society and understanding the risks and finding effective treatments is essential. This project develops and tests methods to better elucidate those risks and treatments.",Discovering and Applying Knowledge in Clinical Databases,10175300,R01LM006910,"['2019-nCoV', 'Acute', 'Affect', 'Assimilations', 'COVID-19', 'Cessation of life', 'Clinical', 'Complement', 'Conflict (Psychology)', 'Data', 'Data Science', 'Disease', 'Economics', 'Electronic Health Record', 'Engineering', 'Goals', 'Health', 'Healthcare', 'Human', 'Knowledge', 'Korea', 'Learning', 'Literature', 'Machine Learning', 'Medical center', 'Methods', 'Modeling', 'Nature', 'Observational Study', 'Patients', 'Phenotype', 'Physiological', 'Process', 'Randomized Clinical Trials', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severity of illness', 'Site', 'Societies', 'Spain', 'Structure', 'Techniques', 'Testing', 'United States Department of Veterans Affairs', 'Universities', 'Variant', 'Virus', 'Work', 'base', 'causal model', 'clinical data warehouse', 'clinical database', 'effective therapy', 'health data', 'improved', 'network informatics', 'parent project', 'recruit']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,37243,0.03107349502773685
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY / ABSTRACT The long-term goal of our ongoing project, Discovering and applying knowledge in clinical databases, is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. The EHR, because of its broad capture of human health, greatly amplifies our ability to carry out observational research, opening the possibility of covering emerging problems, diverse populations, rare diseases, and chronic diseases in long-term longitudinal studies. Unfortunately, the strength of EHR dataits breadth and flexible natureimposes additional challenges. We have found that the biggest challenge comes from the inaccuracy, incompleteness, complexity, and resulting bias inherent in the recording of the health care process. We previously showed that health care process bias exists to the extent, for example, that simple use of the data can create signals implying the opposite of what we know to be true. One of the most important factors is sparse, irregular sampling; we found that sampling bias can be reduced by reparameterizing time and that prediction techniques that can accommodate EHR-specific data and resist their biases like data assimilation can be used on EHR data to produce good estimates of glucose and HA1c. The previous cycle of this project produced 75 publications. We propose to develop methods to accommodate health care process bias, using both knowledge engineering and experience with health care process bias as well as advanced statistical techniques that employ dynamical models and latent variables. We hypothesize that heuristics and models combined with knowledge can improve our ability to generate inferences and learn phenotypes despite health care process bias. Our aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. (3) Use data assimilation and mechanistic models to learn otherwise unmeasurable physiologic phenotypes despite irregular, sparse sampling typical of electronic health records. (4) Use the developed models and generated phenotypes to answer clinical questions, and disseminate the results. PROJECT NARRATIVE This project studies the biases that health care processes bring to electronic health record data, and it develops methods to overcome those biases to improve reuse of the data for purposes such as clinical research and quality improvement.",Discovering and Applying Knowledge in Clinical Databases,9873996,R01LM006910,"['Active Learning', 'Adopted', 'Adverse drug effect', 'Affect', 'Algorithms', 'Area', 'Assimilations', 'Award', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Reporting', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'Generations', 'Glucose', 'Goals', 'Health', 'Healthcare', 'Human', 'Insulin', 'Knowledge', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nonlinear Dynamics', 'Observational Study', 'Patients', 'Performance', 'Phenotype', 'Physiological', 'Physiology', 'Population Heterogeneity', 'Process', 'Publications', 'Rare Diseases', 'Research', 'Sampling', 'Sampling Biases', 'Signal Transduction', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'abstracting', 'clinical database', 'data reuse', 'deep learning', 'experience', 'flexibility', 'heuristics', 'improved', 'novel', 'precision medicine', 'predictive modeling']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,582678,0.04747714641182023
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY / ABSTRACT The long-term goal of our ongoing project, Discovering and applying knowledge in clinical databases, is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. The EHR, because of its broad capture of human health, greatly amplifies our ability to carry out observational research, opening the possibility of covering emerging problems, diverse populations, rare diseases, and chronic diseases in long-term longitudinal studies. Unfortunately, the strength of EHR dataits breadth and flexible natureimposes additional challenges. We have found that the biggest challenge comes from the inaccuracy, incompleteness, complexity, and resulting bias inherent in the recording of the health care process. We previously showed that health care process bias exists to the extent, for example, that simple use of the data can create signals implying the opposite of what we know to be true. One of the most important factors is sparse, irregular sampling; we found that sampling bias can be reduced by reparameterizing time and that prediction techniques that can accommodate EHR-specific data and resist their biases like data assimilation can be used on EHR data to produce good estimates of glucose and HA1c. The previous cycle of this project produced 75 publications. We propose to develop methods to accommodate health care process bias, using both knowledge engineering and experience with health care process bias as well as advanced statistical techniques that employ dynamical models and latent variables. We hypothesize that heuristics and models combined with knowledge can improve our ability to generate inferences and learn phenotypes despite health care process bias. Our aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. (3) Use data assimilation and mechanistic models to learn otherwise unmeasurable physiologic phenotypes despite irregular, sparse sampling typical of electronic health records. (4) Use the developed models and generated phenotypes to answer clinical questions, and disseminate the results. PROJECT NARRATIVE This project studies the biases that health care processes bring to electronic health record data, and it develops methods to overcome those biases to improve reuse of the data for purposes such as clinical research and quality improvement.",Discovering and Applying Knowledge in Clinical Databases,9659641,R01LM006910,"['Active Learning', 'Adopted', 'Adverse drug effect', 'Affect', 'Algorithms', 'Area', 'Assimilations', 'Award', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Reporting', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'Generations', 'Glucose', 'Goals', 'Health', 'Healthcare', 'Human', 'Insulin', 'Knowledge', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nonlinear Dynamics', 'Observational Study', 'Patients', 'Performance', 'Phenotype', 'Physiological', 'Physiology', 'Population Heterogeneity', 'Process', 'Publications', 'Rare Diseases', 'Research', 'Sampling', 'Sampling Biases', 'Signal Transduction', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'abstracting', 'clinical database', 'deep learning', 'experience', 'flexibility', 'heuristics', 'improved', 'novel', 'precision medicine', 'predictive modeling']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,596772,0.04747714641182023
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7288319,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,345833,0.05347914490653184
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7147611,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372106,0.05347914490653184
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6892934,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,384538,0.0037819758665517083
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6754395,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,380979,0.0037819758665517083
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6630735,R01LM006910,"['artificial intelligence', ' classification', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information system analysis', ' method development', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,377617,0.0037819758665517083
"Automated Data Collection on Antimicrobial Use in Dogs and Cats in a Tertiary Hospital and Private Practices Judicious antimicrobial use in veterinary medicine is important because improper antimicrobial use can contribute to the evolution of antimicrobial resistance in bacterial pathogens, which makes subsequent use of these drugs less effective in both human and veterinary medicine. There is very little on-the-ground information about veterinary clinicians antimicrobial use (AMU) practices in companion animal practice in the US. veterinary medicine. To improve our understanding of antimicrobial use in dogs and cats, we propose to create a nationwide digital surveillance system to collect critical AMU data using existing electronic practice information management systems (PIMS) in collaboration with veterinary industry partners. The system will automatically harvest AMU and patient data from digital PIMS. The proposed system will harvest data collected in routine veterinary examinations from existing PIMS systems and therefore will not require any additional effort from practitioners to participate in the program. Natural language processing, a machine learning method used to classify unstructured text, will be used to review electronic medical records to determine patients diagnosis. We aim to prototype the system in our native digital PIMS at North Carolina State Universitys College of Veterinary Medicine Teaching hospital. We will then enroll additional private veterinary practices, including general practice, specialty hospitals, and emergency clinics, as sentinels and collect the same detailed PIMS data from a more representative set of clinics. Working closely with the sentinel clinics will provide a deep understanding of how our system operates in private clinics, and in the final stage we aim to expand the fully automated system to PIMS nationwide. The combination of sentinel clinics with the nationwide survey of clinics will create a powerful broad and deep surveillance system for antimicrobial use in veterinary clinics. A broad suite of AMU parameters will be estimated from this data, and the results reported to the FDA in an annual report. Additionally, we will share the data with other researchers through an web-based portal and GitHub repositories. This system will provide the critical data and analysis to understand veterinary AMU in the US. NARRATIVE Veterinarians play a central role in protecting animal and human health by preserving the efficacy of the antibiotics that their use for their patients. We have created a partnership among a public university, private veterinary hospitals, and a leading industry partner to collect information on how antibiotics are being used in cat and dog practices across the country with no disruption to the participating hospitals. The data will support FDAs commitment to promoting antimicrobial stewardship.",Automated Data Collection on Antimicrobial Use in Dogs and Cats in a Tertiary Hospital and Private Practices,10166402,U01FD007057,[' '],FDA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,U01,2020,199999,0.021558913425468312
"Using Narrative Data to Enrich the Online Medical Record  DESCRIPTION (provided by applicant):    Narrative information is vital to health care, because it enables physicians to synthesize the raw facts and provide a context and interpretation for them.  Electronic medical record systems contain a wealth of clinical data, but typically lack the clinical narrative found in paper records, e.g., the patient history and progress notes.  Numerous barriers prevent the timely acquisition of narrative data, and most computer systems are unable to use such information productively.  Current approaches offer a tradeoff, capture of rich clinical data that lacks structure (using transcription services or speech technology), versus entry of structured data that lacks flexibility and expressiveness (using template systems).  Natural language processing can integrate these approaches by allowing physicians full freedom of expression while producing structured documents that preserve the richness and enable further computer processing.   This proposal seeks to capture and structure narrative in the online medical record in order to improve entry time, completeness, information content and consistency of clinical documentation.  The specific aims of this proposal are:  1) Maintain the continuity of the medical record; a lengthy medical record requires significant time to review and digest.  Many facts from past narratives remain true in the present or persist with minor changes.  By automatically bringing these facts forward into the current narrative, the system can reduce the time to enter the document, and improve the completeness of documentation by maintaining continuity of what is known about a patient; 2) Integrate the medical record:  Electronic medical records contain a vast amount of data.  However, most of these data are raw facts.  By helping the physician to connect, interpret and summarize these facts, the system can improve the usefulness of the information in the record, and reduce the time to enter documents by performing some syntheses automatically; and 3) Harmonize the medical record; the multidisciplinary nature of health care creates the potential for the differing perspectives and interpretations in the medical record, and even contradictions.  By bringing possible discrepancies to the attention of the physician, the system can help resolve the inconsistencies.     n/a",Using Narrative Data to Enrich the Online Medical Record,6802698,R01LM007268,"['automated medical record system', 'clinical research', 'computer data analysis', 'data collection methodology /evaluation', 'human data', 'information systems', 'medical records', 'online computer', 'primary care physician', 'vocabulary']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,437194,-0.001625821728612817
"Using Narrative Data to Enrich the Online Medical Record  DESCRIPTION (provided by applicant):    Narrative information is vital to health care, because it enables physicians to synthesize the raw facts and provide a context and interpretation for them.  Electronic medical record systems contain a wealth of clinical data, but typically lack the clinical narrative found in paper records, e.g., the patient history and progress notes.  Numerous barriers prevent the timely acquisition of narrative data, and most computer systems are unable to use such information productively.  Current approaches offer a tradeoff, capture of rich clinical data that lacks structure (using transcription services or speech technology), versus entry of structured data that lacks flexibility and expressiveness (using template systems).  Natural language processing can integrate these approaches by allowing physicians full freedom of expression while producing structured documents that preserve the richness and enable further computer processing.   This proposal seeks to capture and structure narrative in the online medical record in order to improve entry time, completeness, information content and consistency of clinical documentation.  The specific aims of this proposal are:  1) Maintain the continuity of the medical record; a lengthy medical record requires significant time to review and digest.  Many facts from past narratives remain true in the present or persist with minor changes.  By automatically bringing these facts forward into the current narrative, the system can reduce the time to enter the document, and improve the completeness of documentation by maintaining continuity of what is known about a patient; 2) Integrate the medical record:  Electronic medical records contain a vast amount of data.  However, most of these data are raw facts.  By helping the physician to connect, interpret and summarize these facts, the system can improve the usefulness of the information in the record, and reduce the time to enter documents by performing some syntheses automatically; and 3) Harmonize the medical record; the multidisciplinary nature of health care creates the potential for the differing perspectives and interpretations in the medical record, and even contradictions.  By bringing possible discrepancies to the attention of the physician, the system can help resolve the inconsistencies.     n/a",Using Narrative Data to Enrich the Online Medical Record,6665504,R01LM007268,"['automated medical record system', ' clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' information systems', ' medical records', ' online computer', ' primary care physician', ' vocabulary']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,424735,-0.001625821728612817
"Using Narrative Data to Enrich the Online Medical Record  DESCRIPTION (provided by applicant):    Narrative information is vital to health care, because it enables physicians to synthesize the raw facts and provide a context and interpretation for them.  Electronic medical record systems contain a wealth of clinical data, but typically lack the clinical narrative found in paper records, e.g., the patient history and progress notes.  Numerous barriers prevent the timely acquisition of narrative data, and most computer systems are unable to use such information productively.  Current approaches offer a tradeoff, capture of rich clinical data that lacks structure (using transcription services or speech technology), versus entry of structured data that lacks flexibility and expressiveness (using template systems).  Natural language processing can integrate these approaches by allowing physicians full freedom of expression while producing structured documents that preserve the richness and enable further computer processing.   This proposal seeks to capture and structure narrative in the online medical record in order to improve entry time, completeness, information content and consistency of clinical documentation.  The specific aims of this proposal are:  1) Maintain the continuity of the medical record; a lengthy medical record requires significant time to review and digest.  Many facts from past narratives remain true in the present or persist with minor changes.  By automatically bringing these facts forward into the current narrative, the system can reduce the time to enter the document, and improve the completeness of documentation by maintaining continuity of what is known about a patient; 2) Integrate the medical record:  Electronic medical records contain a vast amount of data.  However, most of these data are raw facts.  By helping the physician to connect, interpret and summarize these facts, the system can improve the usefulness of the information in the record, and reduce the time to enter documents by performing some syntheses automatically; and 3) Harmonize the medical record; the multidisciplinary nature of health care creates the potential for the differing perspectives and interpretations in the medical record, and even contradictions.  By bringing possible discrepancies to the attention of the physician, the system can help resolve the inconsistencies.     n/a",Using Narrative Data to Enrich the Online Medical Record,6535939,R01LM007268,"['automated medical record system', ' clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' information systems', ' medical records', ' online computer', ' primary care physician', ' vocabulary']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2002,395391,-0.001625821728612817
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,7110256,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,478733,0.06766964704883745
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6912634,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,478937,0.06766964704883745
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6781785,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,468590,0.06766964704883745
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6558664,R01LM007659,"['cancer information system', ' clinical research', ' data collection', ' health science research', ' human data', ' informatics', ' library', ' medical records', ' molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,464049,0.06766964704883745
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7638001,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Non-Prescription Drugs', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'clinical practice', 'evidence base', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'patient population', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY,R01,2009,374185,0.028988074036671547
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7448662,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY,R01,2008,383338,0.028988074036671547
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7262635,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY MED CTR,R01,2007,304785,0.028988074036671547
"TIME:(Tools for Inpatient Monitoring using Evidence)for Safe & AppropriateTesting The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care. Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence- based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients. Public Statement The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury. n/a",TIME:(Tools for Inpatient Monitoring using Evidence)for Safe & AppropriateTesting,7347232,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY MED CTR,R01,2007,55295,0.029765872186442752
"VALIDATING A MODEL FOR REPRESENTING MEDICAL INFORMATION The need to better utilize medical information is constantly increasing. The main cause of this trend is the economic pressure to reduce the cost of medical care while preserving and enhancing its quality.  One proposal for solving this dilemma is to develop medical information systems that assist physicians and clinical researchers in the analysis and use of the available information. A central problem that has retarded the development of useful medical information systems is the lack of suitable methods for representing clinical data.  The central goal of this project is to evaluate Event Definitions (EDs) as a potential representation model for clinical data. The ED model is based on a conceptual view that a patient's medical record is a sequence of clinical events.  The representation capability of the ED model will be tested in two experiments, both in the domain of chest radiology. The first experiment evaluates if the model can be used for intervocabulary translation. We want to know if the semantic nature of the EDs will provide the underlying structure necessary to map semantically related concepts. The second experiment evaluates the representation of free text.  Chest x-ray reports will be abstracted in a set of clinically relevant questions with their appropriate answers. The same reports will be represented using the model. We plan to measure the information loss as the difference in the number of questions that can be answered from the ED representation versus from the narrative form.  n/a",VALIDATING A MODEL FOR REPRESENTING MEDICAL INFORMATION,2236428,R03HS008053,"['artificial intelligence', ' biomedical automation', ' health care facility information system', ' health care model', ' model design /development', ' semantics', ' vocabulary development for information system']",AHRQ,UNIVERSITY OF UTAH,R03,1993,21600,0.011760680965235377
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,8309419,R01LM008111,"['Address', 'Biomedical Research', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2012,596909,-0.005701220634468999
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,8117587,R01LM008111,"['Address', 'Biomedical Research', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2011,597135,-0.005701220634468999
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,7908806,R01LM008111,"['Address', 'Biomedical Research', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2010,618469,-0.005701220634468999
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,7668609,R01LM008111,"['Address', 'Biomedical Research', 'Body of uterus', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Ontology', 'Phenotype', 'Readiness', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2009,613451,-0.005701220634468999
"Technology Development for a MolBio Knowledge-base    DESCRIPTION (provided by applicant):       In the three years since the original proposal was submitted, the claims we made about the impending readiness of knowledge-based approaches and natural language processing to address pressing problems of information overload in molecular biology have been resoundingly confirmed, and such methods have become increasingly accepted within the computational bioscience and systems biology communities. We are now well into the era of broad use of semantic representation technology to support biomedical research, and at the cusp of the use of biomedical natural language processing software to create the enormous number of necessary formal representations automatically from biomedical texts. The results of the work during the last funding period have not only contributed    innovative and significant new methods, but have helped us identify a set of specific research issues we claim are now the rate-limiting factors in building an extensive, high-quality computational knowledge-base of molecular biology. The aims of this competitive renewal are to address those factors, making it possible to scale our impressive results on intentionally narrow applications to much   larger (and more significant) tasks, specifically: (1) to create an enriched, relationally decomposed set of conceptual frames, hewing closely to multiple, community curated ontologies; (2) develop language  processing tools capable of recognizing and populating instances of those conceptual frames, and (3) develop systems for integrating and using diverse knowledge from multiple sources to generate scientific insights, focusing on the analysis of sets of dozens to hundreds of genes produced by diverse high-throughput methodologies. An innovative aspect of this proposal is the creation and application of novel, insight-based extrinsic evaluation techniques for such systems.          n/a",Technology Development for a MolBio Knowledge-base,7474790,R01LM008111,"['Address', 'Biomedical Research', 'Body of uterus', 'Budgets', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Data Set', 'Evaluation', 'Funding', 'Genes', 'Goals', 'Human', 'Information Resources', 'Knowledge', 'Linguistics', 'Methodology', 'Methods', 'Modeling', 'Molecular Biology', 'Natural Language Processing', 'Numbers', 'Ontology', 'Phenotype', 'Rate', 'Readiness', 'Representations, Knowledge (Computer)', 'Research', 'Semantics', 'Source', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Text', 'Work', 'base', 'cell type', 'computer based Semantic Analysis', 'concept', 'high throughput analysis', 'improved', 'information organization', 'innovation', 'insight', 'interest', 'knowledge base', 'language processing', 'new technology', 'novel', 'technology development', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2008,614419,-0.005701220634468999
"Developing and applying information extraction resources and technology to create DESCRIPTION (provided by applicant): Building on 8 years of highly productive work in technology development that included the creation of the Colorado Richly Annotated Full Text corpus (CRAFT), we hypothesize that text mining resources and methods are approaching the level of maturity required to productively process a significant proportion of the full text biomedical literature to create a well-represented formal knowledge base of molecular biology. We propose a detailed, integrated plan to achieve this long-standing goal. Success in this effort will make possible a transformative new way for the biomedical research community to identify access and integrate existing knowledge, breaking down disciplinary boundaries and other silos that have kept scientists from fully exploiting relevant prior results in their research.      Our successes in the prior funding period broadened the applicability of biomedical concept identification systems to a much wider set of tasks, demonstrating the ability to target multiple community-curated ontologies in text mining, and generate scientifically significant insights from the results. The proposed work would take advantage of the resources we produced to transcend several of the limitations of previous efforts. We propose innovative new approaches to formal knowledge representation and to characterizing relationships between textual elements and semantic content. We will design, implement and evaluate computational systems that have the potential to transform enormous text collections into semantically rich, logic-based, standards-compliant, formal representations of biomedical knowledge with clearly identified provenance. The resulting representations will express complex assertions about a very wide range of entities, processes, qualities, and, most importantly, their specific relationships with one another. Program Director/Principal Investigator (Last, First, Middle): Hunter, Lawrence E. Project narrative  This project will affect public health by increasing the access of physicians, researchers, and the general public to highly targeted information from published research and electronic health records. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page",Developing and applying information extraction resources and technology to create,9306202,R01LM008111,"['Adrenergic beta-Antagonists', 'Affect', 'Biomedical Research', 'Collection', 'Colorado', 'Communities', 'Complex', 'Data', 'Electronic Health Record', 'Elements', 'Funding', 'General Population', 'Goals', 'Gold', 'Guidelines', 'Heart failure', 'Knowledge', 'Linguistics', 'Literature', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Molecular Analysis', 'Molecular Biology', 'Ontology', 'Output', 'Pattern', 'Performance', 'Physicians', 'Principal Investigator', 'Process', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'System', 'Techniques', 'Technology', 'Text', 'Transcend', 'Work', 'base', 'design', 'improved', 'information organization', 'innovation', 'insight', 'knowledge base', 'novel strategies', 'programs', 'success', 'syntax', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2017,591990,-0.008321211090311203
"Developing and applying information extraction resources and technology to create DESCRIPTION (provided by applicant): Building on 8 years of highly productive work in technology development that included the creation of the Colorado Richly Annotated Full Text corpus (CRAFT), we hypothesize that text mining resources and methods are approaching the level of maturity required to productively process a significant proportion of the full text biomedical literature to create a well-represented formal knowledge base of molecular biology. We propose a detailed, integrated plan to achieve this long-standing goal. Success in this effort will make possible a transformative new way for the biomedical research community to identify access and integrate existing knowledge, breaking down disciplinary boundaries and other silos that have kept scientists from fully exploiting relevant prior results in their research.      Our successes in the prior funding period broadened the applicability of biomedical concept identification systems to a much wider set of tasks, demonstrating the ability to target multiple community-curated ontologies in text mining, and generate scientifically significant insights from the results. The proposed work would take advantage of the resources we produced to transcend several of the limitations of previous efforts. We propose innovative new approaches to formal knowledge representation and to characterizing relationships between textual elements and semantic content. We will design, implement and evaluate computational systems that have the potential to transform enormous text collections into semantically rich, logic-based, standards-compliant, formal representations of biomedical knowledge with clearly identified provenance. The resulting representations will express complex assertions about a very wide range of entities, processes, qualities, and, most importantly, their specific relationships with one another. Program Director/Principal Investigator (Last, First, Middle): Hunter, Lawrence E. Project narrative  This project will affect public health by increasing the access of physicians, researchers, and the general public to highly targeted information from published research and electronic health records. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page",Developing and applying information extraction resources and technology to create,9113614,R01LM008111,"['Adrenergic beta-Antagonists', 'Affect', 'Biomedical Research', 'Collection', 'Colorado', 'Communities', 'Complex', 'Data', 'Electronic Health Record', 'Elements', 'Funding', 'General Population', 'Goals', 'Gold', 'Guidelines', 'Heart failure', 'Knowledge', 'Linguistics', 'Literature', 'Logic', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Ontology', 'Output', 'Pattern', 'Performance', 'Physicians', 'Principal Investigator', 'Process', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'System', 'Techniques', 'Technology', 'Text', 'Transcend', 'Work', 'base', 'design', 'improved', 'information organization', 'innovation', 'insight', 'knowledge base', 'novel strategies', 'programs', 'success', 'syntax', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2016,601709,-0.008321211090311203
"Developing and applying information extraction resources and technology to create DESCRIPTION (provided by applicant): Building on 8 years of highly productive work in technology development that included the creation of the Colorado Richly Annotated Full Text corpus (CRAFT), we hypothesize that text mining resources and methods are approaching the level of maturity required to productively process a significant proportion of the full text biomedical literature to create a well-represented formal knowledge base of molecular biology. We propose a detailed, integrated plan to achieve this long-standing goal. Success in this effort will make possible a transformative new way for the biomedical research community to identify access and integrate existing knowledge, breaking down disciplinary boundaries and other silos that have kept scientists from fully exploiting relevant prior results in their research.      Our successes in the prior funding period broadened the applicability of biomedical concept identification systems to a much wider set of tasks, demonstrating the ability to target multiple community-curated ontologies in text mining, and generate scientifically significant insights from the results. The proposed work would take advantage of the resources we produced to transcend several of the limitations of previous efforts. We propose innovative new approaches to formal knowledge representation and to characterizing relationships between textual elements and semantic content. We will design, implement and evaluate computational systems that have the potential to transform enormous text collections into semantically rich, logic-based, standards-compliant, formal representations of biomedical knowledge with clearly identified provenance. The resulting representations will express complex assertions about a very wide range of entities, processes, qualities, and, most importantly, their specific relationships with one another. Program Director/Principal Investigator (Last, First, Middle): Hunter, Lawrence E. Project narrative  This project will affect public health by increasing the access of physicians, researchers, and the general public to highly targeted information from published research and electronic health records. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page",Developing and applying information extraction resources and technology to create,8866232,R01LM008111,"['Adrenergic beta-Antagonists', 'Affect', 'Biomedical Research', 'Collection', 'Colorado', 'Communities', 'Complex', 'Data', 'Electronic Health Record', 'Elements', 'Funding', 'General Population', 'Goals', 'Gold', 'Guidelines', 'Heart failure', 'Knowledge', 'Linguistics', 'Literature', 'Logic', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Ontology', 'Output', 'Pattern', 'Performance', 'Physicians', 'Principal Investigator', 'Process', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'System', 'Techniques', 'Technology', 'Text', 'Transcend', 'Work', 'base', 'design', 'improved', 'information organization', 'innovation', 'insight', 'knowledge base', 'novel strategies', 'programs', 'success', 'syntax', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2015,602189,-0.008321211090311203
"Developing and applying information extraction resources and technology to create     DESCRIPTION (provided by applicant): Building on 8 years of highly productive work in technology development that included the creation of the Colorado Richly Annotated Full Text corpus (CRAFT), we hypothesize that text mining resources and methods are approaching the level of maturity required to productively process a significant proportion of the full text biomedical literature to create a well-represented formal knowledge base of molecular biology. We propose a detailed, integrated plan to achieve this long-standing goal. Success in this effort will make possible a transformative new way for the biomedical research community to identify access and integrate existing knowledge, breaking down disciplinary boundaries and other silos that have kept scientists from fully exploiting relevant prior results in their research.      Our successes in the prior funding period broadened the applicability of biomedical concept identification systems to a much wider set of tasks, demonstrating the ability to target multiple community-curated ontologies in text mining, and generate scientifically significant insights from the results. The proposed work would take advantage of the resources we produced to transcend several of the limitations of previous efforts. We propose innovative new approaches to formal knowledge representation and to characterizing relationships between textual elements and semantic content. We will design, implement and evaluate computational systems that have the potential to transform enormous text collections into semantically rich, logic-based, standards-compliant, formal representations of biomedical knowledge with clearly identified provenance. The resulting representations will express complex assertions about a very wide range of entities, processes, qualities, and, most importantly, their specific relationships with one another.              Program Director/Principal Investigator (Last, First, Middle): Hunter, Lawrence E. Project narrative  This project will affect public health by increasing the access of physicians, researchers, and the general public to highly targeted information from published research and electronic health records. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page",Developing and applying information extraction resources and technology to create,8694375,R01LM008111,"['Adrenergic beta-Antagonists', 'Affect', 'Biomedical Research', 'Collection', 'Colorado', 'Communities', 'Complex', 'Data', 'Electronic Health Record', 'Elements', 'Funding', 'General Population', 'Goals', 'Gold', 'Guidelines', 'Heart failure', 'Knowledge', 'Linguistics', 'Literature', 'Logic', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Ontology', 'Output', 'Pattern', 'Performance', 'Physicians', 'Principal Investigator', 'Process', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'System', 'Techniques', 'Technology', 'Text', 'Transcend', 'Work', 'base', 'design', 'improved', 'information organization', 'innovation', 'insight', 'knowledge base', 'novel strategies', 'programs', 'success', 'syntax', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2014,746561,-0.008321211090311203
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,7076099,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2006,162000,0.05166983797182102
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6898458,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2005,162000,0.05166983797182102
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6768325,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2004,135000,0.05166983797182102
"MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine     DESCRIPTION (provided by applicant): The velocity, variety, volume and veracity of data from relevant information sources make it extremely challenging for oncologists to collect and review pertinent data that can support routine personalized treatment for their patients. There is an urgent need to develop data wrangling approaches including Natural Language Processing and information retrieval methods to extract and curate personalized-therapy related publications and clinical trials. Once curated, the structured data can be used by biomedical researchers to generate novel scientific hypotheses, design new studies, obtain a better understanding of biological mechanisms of disease, perform meta-analyses, and create clinical decision support systems. There is an urgent need to develop improved search interfaces specific to the field of personalized therapy, including ways to display, rank, and save results by end users. While several database and web-based keyword search engine algorithms exist, there is a lack of tools that meet the unique challenges of personalized medicine. There is also an urgent need to develop software that allows for verification and validation of information extracted and ranked through computational methods using subject matter expertise to improve the gold standard corpus that can be used for biomedical research into personalized therapies.  To address these issues, we will build an innovative software stack (MACE2K) to adapt and extend widely tested Biocreative natural language processing (NLP) tools to automatically retrieve and pre-process targeted therapy information from clinicaltrials.gov, PubMed abstracts as well as open access articles, and conference proceedings. We will build an entity extraction cartridge to accurately parse gene mutations, translocations, gene expression, protein expression, and protein phosphorylation. A marker disambiguation cartridge will be built to assess for trial inclusion or exclusion criteria and to determine marker-related primary endpoints. We will include a ranking cartridge that uses the disambiguated information on markers, drugs and trials to provide a rigorous scoring of trials and studies according to their relevance for personalized medicine. A novel gamification cartridge will be built to allow subject matter experts to verify and validate the information corpus. Our research leverages National Cancer Institute's investments in several programs (many of which we are involved in) including the NCI drug dictionary, National Cancer Informatics Program (NCIP), I-SPY trials, and Center for cancer systems biology (CCSB) to efficiently accomplish our aims.         PUBLIC HEALTH RELEVANCE: This project will develop new computational methods and software to retrieve targeted molecular and drug therapy information from multiple sources of big data including: clinicaltrials.gov, PubMed abstracts, open access articles, and conference proceedings. The software can be used by biomedical researchers to generate new hypotheses for research on personalized cancer treatment decisions based on enormous volumes of public data already in existence. A novel gamification component will be built to allow subject matter experts to verify and validate the information corpus to enhance accuracy of the software.            ",MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine,8874546,U01HG008390,"['Address', 'Algorithms', 'Big Data', 'Biological', 'Biomedical Research', 'Cancer Center', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Computer software', 'Computing Methodologies', 'Crowding', 'Data', 'Data Aggregation', 'Databases', 'Dictionary', 'Disease', 'Exclusion Criteria', 'Gene Expression', 'Gene Mutation', 'Genome', 'Goals', 'Gold', 'Informatics', 'Information Retrieval', 'Investments', 'Knowledge', 'Letters', 'Literature', 'Malignant Neoplasms', 'Maps', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Molecular Target', 'Mutation', 'National Cancer Institute', 'Natural Language Processing', 'Oncologist', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phosphorylation', 'Process', 'PubMed', 'Publications', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Software Validation', 'Source', 'Structure', 'System', 'Systems Biology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'abstracting', 'base', 'design', 'improved', 'inclusion criteria', 'innovation', 'interest', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'personalized cancer care', 'personalized cancer therapy', 'personalized medicine', 'programs', 'protein expression', 'public health relevance', 'software development', 'symposium', 'targeted treatment', 'tool', 'user friendly software', 'verification and validation']",NHGRI,GEORGETOWN UNIVERSITY,U01,2015,478724,0.016884772915331667
"MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine     DESCRIPTION (provided by applicant): The velocity, variety, volume and veracity of data from relevant information sources make it extremely challenging for oncologists to collect and review pertinent data that can support routine personalized treatment for their patients. There is an urgent need to develop data wrangling approaches including Natural Language Processing and information retrieval methods to extract and curate personalized-therapy related publications and clinical trials. Once curated, the structured data can be used by biomedical researchers to generate novel scientific hypotheses, design new studies, obtain a better understanding of biological mechanisms of disease, perform meta-analyses, and create clinical decision support systems. There is an urgent need to develop improved search interfaces specific to the field of personalized therapy, including ways to display, rank, and save results by end users. While several database and web-based keyword search engine algorithms exist, there is a lack of tools that meet the unique challenges of personalized medicine. There is also an urgent need to develop software that allows for verification and validation of information extracted and ranked through computational methods using subject matter expertise to improve the gold standard corpus that can be used for biomedical research into personalized therapies.  To address these issues, we will build an innovative software stack (MACE2K) to adapt and extend widely tested Biocreative natural language processing (NLP) tools to automatically retrieve and pre-process targeted therapy information from clinicaltrials.gov, PubMed abstracts as well as open access articles, and conference proceedings. We will build an entity extraction cartridge to accurately parse gene mutations, translocations, gene expression, protein expression, and protein phosphorylation. A marker disambiguation cartridge will be built to assess for trial inclusion or exclusion criteria and to determine marker-related primary endpoints. We will include a ranking cartridge that uses the disambiguated information on markers, drugs and trials to provide a rigorous scoring of trials and studies according to their relevance for personalized medicine. A novel gamification cartridge will be built to allow subject matter experts to verify and validate the information corpus. Our research leverages National Cancer Institute's investments in several programs (many of which we are involved in) including the NCI drug dictionary, National Cancer Informatics Program (NCIP), I-SPY trials, and Center for cancer systems biology (CCSB) to efficiently accomplish our aims. PUBLIC HEALTH RELEVANCE: This project will develop new computational methods and software to retrieve targeted molecular and drug therapy information from multiple sources of big data including: clinicaltrials.gov, PubMed abstracts, open access articles, and conference proceedings. The software can be used by biomedical researchers to generate new hypotheses for research on personalized cancer treatment decisions based on enormous volumes of public data already in existence. A novel gamification component will be built to allow subject matter experts to verify and validate the information corpus to enhance accuracy of the software.",MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine,9282279,U01HG008390,"['Address', 'Algorithms', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biomedical Research', 'Cancer Center', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Computer software', 'Computing Methodologies', 'Custom', 'Data', 'Data Aggregation', 'Databases', 'Dictionary', 'Disease', 'Exclusion Criteria', 'Gene Expression', 'Gene Mutation', 'Genome', 'Goals', 'Gold', 'Informatics', 'Information Retrieval', 'Investments', 'Letters', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Molecular Target', 'Mutation', 'National Cancer Institute', 'Natural Language Processing', 'Oncologist', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phosphorylation', 'Process', 'PubMed', 'Publications', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Source', 'Standardization', 'Structure', 'System', 'Systems Biology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'base', 'crowdsourcing', 'data to knowledge', 'data wrangling', 'design', 'improved', 'inclusion criteria', 'innovation', 'interest', 'knowledge base', 'novel', 'novel strategies', 'personalized cancer care', 'personalized cancer therapy', 'personalized medicine', 'programs', 'protein expression', 'public health relevance', 'search engine', 'software development', 'symposium', 'targeted treatment', 'tool', 'user friendly software', 'verification and validation']",NHGRI,GEORGETOWN UNIVERSITY,U01,2017,455519,0.016884772915331667
"MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine     DESCRIPTION (provided by applicant): The velocity, variety, volume and veracity of data from relevant information sources make it extremely challenging for oncologists to collect and review pertinent data that can support routine personalized treatment for their patients. There is an urgent need to develop data wrangling approaches including Natural Language Processing and information retrieval methods to extract and curate personalized-therapy related publications and clinical trials. Once curated, the structured data can be used by biomedical researchers to generate novel scientific hypotheses, design new studies, obtain a better understanding of biological mechanisms of disease, perform meta-analyses, and create clinical decision support systems. There is an urgent need to develop improved search interfaces specific to the field of personalized therapy, including ways to display, rank, and save results by end users. While several database and web-based keyword search engine algorithms exist, there is a lack of tools that meet the unique challenges of personalized medicine. There is also an urgent need to develop software that allows for verification and validation of information extracted and ranked through computational methods using subject matter expertise to improve the gold standard corpus that can be used for biomedical research into personalized therapies.  To address these issues, we will build an innovative software stack (MACE2K) to adapt and extend widely tested Biocreative natural language processing (NLP) tools to automatically retrieve and pre-process targeted therapy information from clinicaltrials.gov, PubMed abstracts as well as open access articles, and conference proceedings. We will build an entity extraction cartridge to accurately parse gene mutations, translocations, gene expression, protein expression, and protein phosphorylation. A marker disambiguation cartridge will be built to assess for trial inclusion or exclusion criteria and to determine marker-related primary endpoints. We will include a ranking cartridge that uses the disambiguated information on markers, drugs and trials to provide a rigorous scoring of trials and studies according to their relevance for personalized medicine. A novel gamification cartridge will be built to allow subject matter experts to verify and validate the information corpus. Our research leverages National Cancer Institute's investments in several programs (many of which we are involved in) including the NCI drug dictionary, National Cancer Informatics Program (NCIP), I-SPY trials, and Center for cancer systems biology (CCSB) to efficiently accomplish our aims. PUBLIC HEALTH RELEVANCE: This project will develop new computational methods and software to retrieve targeted molecular and drug therapy information from multiple sources of big data including: clinicaltrials.gov, PubMed abstracts, open access articles, and conference proceedings. The software can be used by biomedical researchers to generate new hypotheses for research on personalized cancer treatment decisions based on enormous volumes of public data already in existence. A novel gamification component will be built to allow subject matter experts to verify and validate the information corpus to enhance accuracy of the software.",MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine,9146381,U01HG008390,"['Address', 'Algorithms', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biomedical Research', 'Cancer Center', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Computer software', 'Computing Methodologies', 'Crowding', 'Data', 'Data Aggregation', 'Databases', 'Dictionary', 'Disease', 'Exclusion Criteria', 'Gene Expression', 'Gene Mutation', 'Genome', 'Goals', 'Gold', 'Health', 'Informatics', 'Information Retrieval', 'Investments', 'Letters', 'Literature', 'Malignant Neoplasms', 'Maps', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Molecular Target', 'Mutation', 'National Cancer Institute', 'Natural Language Processing', 'Oncologist', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phosphorylation', 'Process', 'PubMed', 'Publications', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Software Validation', 'Source', 'Structure', 'System', 'Systems Biology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'abstracting', 'base', 'crowdsourcing', 'data to knowledge', 'data wrangling', 'design', 'improved', 'inclusion criteria', 'innovation', 'interest', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'personalized cancer care', 'personalized cancer therapy', 'personalized medicine', 'programs', 'protein expression', 'search engine', 'software development', 'symposium', 'targeted treatment', 'tool', 'user friendly software', 'verification and validation']",NHGRI,GEORGETOWN UNIVERSITY,U01,2016,457075,0.016884772915331667
"MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine     DESCRIPTION (provided by applicant): The velocity, variety, volume and veracity of data from relevant information sources make it extremely challenging for oncologists to collect and review pertinent data that can support routine personalized treatment for their patients. There is an urgent need to develop data wrangling approaches including Natural Language Processing and information retrieval methods to extract and curate personalized-therapy related publications and clinical trials. Once curated, the structured data can be used by biomedical researchers to generate novel scientific hypotheses, design new studies, obtain a better understanding of biological mechanisms of disease, perform meta-analyses, and create clinical decision support systems. There is an urgent need to develop improved search interfaces specific to the field of personalized therapy, including ways to display, rank, and save results by end users. While several database and web-based keyword search engine algorithms exist, there is a lack of tools that meet the unique challenges of personalized medicine. There is also an urgent need to develop software that allows for verification and validation of information extracted and ranked through computational methods using subject matter expertise to improve the gold standard corpus that can be used for biomedical research into personalized therapies.  To address these issues, we will build an innovative software stack (MACE2K) to adapt and extend widely tested Biocreative natural language processing (NLP) tools to automatically retrieve and pre-process targeted therapy information from clinicaltrials.gov, PubMed abstracts as well as open access articles, and conference proceedings. We will build an entity extraction cartridge to accurately parse gene mutations, translocations, gene expression, protein expression, and protein phosphorylation. A marker disambiguation cartridge will be built to assess for trial inclusion or exclusion criteria and to determine marker-related primary endpoints. We will include a ranking cartridge that uses the disambiguated information on markers, drugs and trials to provide a rigorous scoring of trials and studies according to their relevance for personalized medicine. A novel gamification cartridge will be built to allow subject matter experts to verify and validate the information corpus. Our research leverages National Cancer Institute's investments in several programs (many of which we are involved in) including the NCI drug dictionary, National Cancer Informatics Program (NCIP), I-SPY trials, and Center for cancer systems biology (CCSB) to efficiently accomplish our aims. PUBLIC HEALTH RELEVANCE: This project will develop new computational methods and software to retrieve targeted molecular and drug therapy information from multiple sources of big data including: clinicaltrials.gov, PubMed abstracts, open access articles, and conference proceedings. The software can be used by biomedical researchers to generate new hypotheses for research on personalized cancer treatment decisions based on enormous volumes of public data already in existence. A novel gamification component will be built to allow subject matter experts to verify and validate the information corpus to enhance accuracy of the software.",MACE2K - Molecular And Clinical Extraction: A Natural Language Processing Tool for Personalized Medicine,9243496,U01HG008390,"['Address', 'Algorithms', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biomedical Research', 'Cancer Center', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Computer software', 'Computing Methodologies', 'Crowding', 'Data', 'Data Aggregation', 'Databases', 'Dictionary', 'Disease', 'Exclusion Criteria', 'Gene Expression', 'Gene Mutation', 'Genome', 'Goals', 'Gold', 'Health', 'Informatics', 'Information Retrieval', 'Investments', 'Letters', 'Literature', 'Malignant Neoplasms', 'Maps', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Molecular Target', 'Mutation', 'National Cancer Institute', 'Natural Language Processing', 'Oncologist', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phosphorylation', 'Process', 'PubMed', 'Publications', 'Recording of previous events', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Software Validation', 'Source', 'Structure', 'System', 'Systems Biology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'abstracting', 'base', 'crowdsourcing', 'data to knowledge', 'data wrangling', 'design', 'improved', 'inclusion criteria', 'innovation', 'interest', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'personalized cancer care', 'personalized cancer therapy', 'personalized medicine', 'programs', 'protein expression', 'search engine', 'software development', 'symposium', 'targeted treatment', 'tool', 'user friendly software', 'verification and validation']",NHGRI,GEORGETOWN UNIVERSITY,U01,2016,150865,0.016884772915331667
"Statistical NLP Analysis of Cross-discipline Clinical Text emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical inforrnatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6944955,F38LM008478,"['Categories', 'Clinical', 'Clinical Pathology', 'Computers', 'Coupled', 'Diagnosis', 'Discipline', 'Event', 'Fellowship', 'Goals', 'Human', 'Inpatients', 'Linguistics', 'Machine Learning', 'Medical', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Procedures', 'Radiology Specialty', 'Research', 'Statistical Study', 'Text', 'Training', 'Work', 'Writing', 'design', 'experience', 'knowledge base', 'skills', 'syntax', 'theories', 'tool', 'trend', 'ward']",NLM,UNIVERSITY OF UTAH,F38,2007,38768,0.05937717476916773
"Statistical NLP Analysis of Cross-discipline Clinical Text DESCRIPTION (provided by applicant):     An emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical informatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6836781,F38LM008478,"['bioinformatics', 'clinical research', 'computational biology', 'human data', 'library', 'mathematical model', 'public health', 'statistics /biometry']",NLM,UNIVERSITY OF UTAH,F38,2004,94545,0.06110397741733006
"A Biomedical Natural Language Processing Resource DESCRIPTION:    The long-term aim of this project is to advance clinical care and biomedical research by establishing a natural language processing (NLP) resource for the biomedical community. A major bottleneck for development of automated tools for clinical applications and biomedical research is that most of the data and knowledge occur in the form of text, resulting in a lack of coded data. This NLP resource will make possible a host of automated applications by enabling high throughput access to coded biomedical knowledge and data. The foundation of this resource will be the MedLEE NLP system, which has been used operationally for almost a decade in healthcare settings for a broad range of applications that have proven to be valuable for clinical care. The NLP resource will also include BioMedLEE (a derivative of MedLEE), which encodes genotypic-phenotypic (GP) relations in the scientific literature. It currently focuses on GP relations associated with cancer and infectious diseases, and is being used to organize the extracted information to facilitate research, curation, and ontological development within model organism databases. This proposal will enable us to 1) disseminate our NLP resource to the community, 2) conduct technological research and development (R&D) to facilitate expansion and adaptation of the resource to new applications and specialties, 3) conduct R&D of tools that facilitate use of the extracted data and knowledge after coding, and 4) promote the resource, and provide service to users in the form of technical support, documentation, and tutorials. MedLEE and BioMedLEE are extendable systems that encompass the clinical and scientific communities. The dissemination of a proven NLP system that is applicable to the entire biomedical community provides an exceptional opportunity for multiple developers and researchers to work to unleash the true potential of NLP technology, increasing development of applications that aim to enhance scientific research and improve all levels of health. n/a",A Biomedical Natural Language Processing Resource,7429768,R01LM008635,"['Address', 'Alzheimer&apos', 's Disease', 'Autistic Disorder', 'Biological', 'Biomedical Research', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Condition', 'Data', 'Databases', 'Detection', 'Development', 'Discipline', 'Disease', 'Documentation', 'Educational workshop', 'Fostering', 'Foundations', 'Health Status', 'Healthcare', 'Human', 'Imagery', 'Improve Access', 'Internet', 'Knowledge', 'Literature', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Errors', 'Medical Surveillance', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Numbers', 'Ontology', 'Organism', 'Output', 'Partner in relationship', 'Patient Care', 'Performance', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Range', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Semantics', 'Services', 'Side', 'Source', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Terminology', 'Text', 'Universities', 'Work', 'biological research', 'biomedical resource', 'clinical application', 'concept', 'high throughput technology', 'improved', 'knowledge base', 'medical specialties', 'model organisms databases', 'open source', 'research and development', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,534463,0.07440365570182532
"A Biomedical Natural Language Processing Resource DESCRIPTION:    The long-term aim of this project is to advance clinical care and biomedical research by establishing a natural language processing (NLP) resource for the biomedical community. A major bottleneck for development of automated tools for clinical applications and biomedical research is that most of the data and knowledge occur in the form of text, resulting in a lack of coded data. This NLP resource will make possible a host of automated applications by enabling high throughput access to coded biomedical knowledge and data. The foundation of this resource will be the MedLEE NLP system, which has been used operationally for almost a decade in healthcare settings for a broad range of applications that have proven to be valuable for clinical care. The NLP resource will also include BioMedLEE (a derivative of MedLEE), which encodes genotypic-phenotypic (GP) relations in the scientific literature. It currently focuses on GP relations associated with cancer and infectious diseases, and is being used to organize the extracted information to facilitate research, curation, and ontological development within model organism databases. This proposal will enable us to 1) disseminate our NLP resource to the community, 2) conduct technological research and development (R&D) to facilitate expansion and adaptation of the resource to new applications and specialties, 3) conduct R&D of tools that facilitate use of the extracted data and knowledge after coding, and 4) promote the resource, and provide service to users in the form of technical support, documentation, and tutorials. MedLEE and BioMedLEE are extendable systems that encompass the clinical and scientific communities. The dissemination of a proven NLP system that is applicable to the entire biomedical community provides an exceptional opportunity for multiple developers and researchers to work to unleash the true potential of NLP technology, increasing development of applications that aim to enhance scientific research and improve all levels of health. n/a",A Biomedical Natural Language Processing Resource,7257857,R01LM008635,"['Address', 'Alzheimer&apos', 's Disease', 'Autistic Disorder', 'Biological', 'Biomedical Research', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Condition', 'Data', 'Databases', 'Detection', 'Development', 'Discipline', 'Disease', 'Documentation', 'Educational workshop', 'Fostering', 'Foundations', 'Health Status', 'Healthcare', 'Human', 'Imagery', 'Improve Access', 'Internet', 'Knowledge', 'Literature', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Errors', 'Medical Surveillance', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Numbers', 'Ontology', 'Organism', 'Output', 'Partner in relationship', 'Patient Care', 'Performance', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Range', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Semantics', 'Services', 'Side', 'Source', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Terminology', 'Text', 'Universities', 'Work', 'biological research', 'biomedical resource', 'clinical application', 'concept', 'high throughput technology', 'improved', 'knowledge base', 'medical specialties', 'model organisms databases', 'open source', 'research and development', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,529014,0.07440365570182532
"A Biomedical Natural Language Processing Resource DESCRIPTION:    The long-term aim of this project is to advance clinical care and biomedical research by establishing a natural language processing (NLP) resource for the biomedical community. A major bottleneck for development of automated tools for clinical applications and biomedical research is that most of the data and knowledge occur in the form of text, resulting in a lack of coded data. This NLP resource will make possible a host of automated applications by enabling high throughput access to coded biomedical knowledge and data. The foundation of this resource will be the MedLEE NLP system, which has been used operationally for almost a decade in healthcare settings for a broad range of applications that have proven to be valuable for clinical care. The NLP resource will also include BioMedLEE (a derivative of MedLEE), which encodes genotypic-phenotypic (GP) relations in the scientific literature. It currently focuses on GP relations associated with cancer and infectious diseases, and is being used to organize the extracted information to facilitate research, curation, and ontological development within model organism databases. This proposal will enable us to 1) disseminate our NLP resource to the community, 2) conduct technological research and development (R&D) to facilitate expansion and adaptation of the resource to new applications and specialties, 3) conduct R&D of tools that facilitate use of the extracted data and knowledge after coding, and 4) promote the resource, and provide service to users in the form of technical support, documentation, and tutorials. MedLEE and BioMedLEE are extendable systems that encompass the clinical and scientific communities. The dissemination of a proven NLP system that is applicable to the entire biomedical community provides an exceptional opportunity for multiple developers and researchers to work to unleash the true potential of NLP technology, increasing development of applications that aim to enhance scientific research and improve all levels of health. n/a",A Biomedical Natural Language Processing Resource,7075417,R01LM008635,"['artificial intelligence', 'automated medical record system', 'bioinformatics', 'biomedical automation', 'biomedical resource', 'clinical research', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data management', 'health science research', 'high throughput technology', 'human data']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,544814,0.07440365570182532
"A Biomedical Natural Language Processing Resource DESCRIPTION:    The long-term aim of this project is to advance clinical care and biomedical research by establishing a natural language processing (NLP) resource for the biomedical community. A major bottleneck for development of automated tools for clinical applications and biomedical research is that most of the data and knowledge occur in the form of text, resulting in a lack of coded data. This NLP resource will make possible a host of automated applications by enabling high throughput access to coded biomedical knowledge and data. The foundation of this resource will be the MedLEE NLP system, which has been used operationally for almost a decade in healthcare settings for a broad range of applications that have proven to be valuable for clinical care. The NLP resource will also include BioMedLEE (a derivative of MedLEE), which encodes genotypic-phenotypic (GP) relations in the scientific literature. It currently focuses on GP relations associated with cancer and infectious diseases, and is being used to organize the extracted information to facilitate research, curation, and ontological development within model organism databases. This proposal will enable us to 1) disseminate our NLP resource to the community, 2) conduct technological research and development (R&D) to facilitate expansion and adaptation of the resource to new applications and specialties, 3) conduct R&D of tools that facilitate use of the extracted data and knowledge after coding, and 4) promote the resource, and provide service to users in the form of technical support, documentation, and tutorials. MedLEE and BioMedLEE are extendable systems that encompass the clinical and scientific communities. The dissemination of a proven NLP system that is applicable to the entire biomedical community provides an exceptional opportunity for multiple developers and researchers to work to unleash the true potential of NLP technology, increasing development of applications that aim to enhance scientific research and improve all levels of health. n/a",A Biomedical Natural Language Processing Resource,6899974,R01LM008635,"['artificial intelligence', 'automated medical record system', 'bioinformatics', 'biomedical automation', 'biomedical resource', 'clinical research', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data management', 'health science research', 'high throughput technology', 'human data']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,515359,0.07440365570182532
"eMERGE IV Northwest: A partnership to evaluate the use of genomic information in the health care of diverse participants Project Abstract eMERGE IV (E4) proposes to investigate the implementation of 15 genomic risk assessment (GRA) scores in a network-wide set of diverse participants. These GRAs will include polygenic risk score (PRS) information, as well as risk information, such as personal and family health history, environmental and social health determinants, and physical and lab measures. The GRA will aggregate these factors into a single score to identify those who would benefit from screening and other interventions. Substantial challenges must be addressed before genomic medicine is a part of standard medical care. We will collaborate to refine multi-ancestry GRAs and support the inclusion of non-genetic risk factors extracted from the electronic health record with innovative natural language processing approaches and apply them in a cohort enriched for Asian ancestry, and sexual and gender minorities. The specific aims of our proposal are designed to use an implementation science approach to advance the integration of genomic data into clinical practice, including evaluation of patient perspectives and economic outcomes, and broadening the impact of eMERGE through collaborations. The University of Washington Medicine dedication to preventative health in a learning health system and broad expertise across genomics, statistical, ethical, informatic, implementation, outcomes and economic disciplines will support this multi-site clinical trial. Specific Aims: Aim 1: Refine GRA scores and outcomes measures for five high impact conditions, considering stakeholder input, for implementation in the electronic health record. The conditions are: colorectal cancer, breast cancer, osteoporosis, coronary artery disease, and glaucoma. Aim 2: Integrate 15 GRA scores and electronic clinical decision support for management into clinical care and the EHR and capture clinical outcomes. Aim 3: Evaluate the implementation, effectiveness, and economic utility of GRA result return. Project Narrative As part of the eMERGE IV (E4) Network clinical trial, we propose to develop 5, and investigate the implementation of 15, genomic risk assessment (GRA) scores in a large set of diverse participants. These GRAs will include genetic and non-genetic information. We specifically propose study of implementation and outcomes of GRA scores for colorectal cancer, breast cancer, osteoporosis, coronary artery disease, and glaucoma in the electronic health record.",eMERGE IV Northwest: A partnership to evaluate the use of genomic information in the health care of diverse participants,9986310,U01HG008657,"['3-Dimensional', 'Address', 'Adopted', 'Adult', 'Alaska Native', 'Asians', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials Network', 'Collaborations', 'Colorectal Cancer', 'Coronary Arteriosclerosis', 'Data', 'Dedications', 'Development', 'Discipline', 'Disease', 'Economics', 'Education', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environmental Risk Factor', 'Ethics', 'Evaluation', 'Family', 'Family health status', 'Genetic', 'Genetic Risk', 'Genomic medicine', 'Genomics', 'Genotype', 'Glaucoma', 'Health', 'Health system', 'Healthcare', 'Informatics', 'Intervention', 'Leadership', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medicine', 'Methods', 'Mission', 'Morbidity - disease rate', 'Multi-Institutional Clinical Trial', 'Native Americans', 'Natural Language Processing', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Pacific Island Americans', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Population', 'Population Heterogeneity', 'Primary Health Care', 'Process', 'Provider', 'Publishing', 'Recording of previous events', 'Risk', 'Risk Assessment', 'Risk Factors', 'Risk Management', 'Sexual and Gender Minorities', 'Site', 'Underrepresented Groups', 'Universities', 'Variant', 'Washington', 'base', 'clinical care', 'clinical decision support', 'clinical practice', 'cohort', 'data curation', 'design', 'economic outcome', 'economic value', 'ethical legal social implication', 'genetic risk assessment', 'genome wide association study', 'genome-wide', 'genomic data', 'high risk', 'implementation science', 'improved', 'innovation', 'malignant breast neoplasm', 'medical specialties', 'mortality', 'non-genetic', 'novel', 'online resource', 'outreach', 'polygenic risk score', 'prevent', 'racial and ethnic', 'screening', 'social health determinants', 'support tools', 'tool']",NHGRI,UNIVERSITY OF WASHINGTON,U01,2020,1346291,-0.032776237202250244
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9515026,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Base Sequence', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'DNA sequencing', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Ritalin', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinical decision support', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'data warehouse', 'database of Genotypes and Phenotypes', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'patient oriented', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'social', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2018,855289,0.033118132246601935
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9901995,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Base Sequence', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'DNA sequencing', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Recommendation', 'Records', 'Research', 'Research Institute', 'Research Personnel', 'Ritalin', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'autism spectrum disorder', 'base', 'biobank', 'clinical care', 'clinical decision support', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'data warehouse', 'database of Genotypes and Phenotypes', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'patient oriented', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'social', 'success', 'support tools', 'targeted sequencing', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2019,742762,0.033118132246601935
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics.         PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.                ",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,8967443,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'success', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2015,855289,0.033118132246601935
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9282532,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Base Sequence', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'DNA sequencing', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'database of Genotypes and Phenotypes', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'patient oriented', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'social', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2017,811897,0.033118132246601935
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9358502,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'response', 'senior faculty', 'skills', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2016,62400,0.033118132246601935
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9247889,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'response', 'senior faculty', 'skills', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2016,54784,0.033118132246601935
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy     DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9134798,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'response', 'senior faculty', 'skills', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2016,855289,0.033118132246601935
"EHR-based Genomic Risk Assessment and Management for Diverse Populations PROJECT SUMMARY/ABSTRACT Recently, large-scale genome-wide association studies (GWAS) provide evidence for a substantial polygenic contribution to the risk of many common complex diseases. However, most of these studies were performed in Europeans, and new data and methods are necessary to tailor polygenic risk prediction to non-Europeans, to ensure that genomic stratification does not further exacerbate health disparities. The overarching goal of the eMERGE-IV network is to leverage genetic and electronic health record (EHR) data for diverse populations to design, validate and test the clinical utility of ancestry-tailored polygenic risk scores for common diseases. As a current member of the eMERGE network, Columbia University has significantly advanced its goals, having recruited over 2,500 diverse patients for sequencing and return of actionable findings, leading the effort to transition the network to the OMOP Common Data Model to improve the efficiency, accuracy, reproducibility and portability of electronic phenotypes, and contributing a widely-adopted XML parser for structuring genetic test reports. Since our last application, the Columbia Precision Medicine Initiative has also grown and now includes participation in several national initiatives, such as the All-of-Us program, in which we have demonstrated our ability to rapidly recruit patients under-represented in biomedical research. Our scientific expertise combined with our strong tradition of patient-centered research and community engagement in a socioeconomically, racially, and ethnically diverse community of Northern Manhattan, positions us to successfully contribute as the Enhanced Diversity Clinical Site of the eEMERGE-IV network. We will leverage our prior experience with eMERGE, scientific expertise, and knowledge gained from participation in other national precision medicine initiatives to develop, optimize, validate and disseminate ancestry-tailored genomic risk assessment and clinical management tools. In Aim 1, we will continue to advance electronic phenotyping by contributing sharable natural language processing tools for converting clinical text into OMOP-based discrete data and facilitating phenotype interoperability. In Aim 2, we will develop and optimize accurate ancestry-tailored genome-wide polygenic predictors, integrate them with clinical risk predictions, and test their performance in diverse populations. In Aim 3, we will investigate ELSI issues related to the return of health risk predictions to diverse patients by ascertaining patients, clinicians, and IRB members views through focus groups. In Aim 4, we will develop portable EHR plug-ins to facilitate prospective risk communication and management using integrated genomic data, family history, and clinical data. In Aim 5, we will recruit 2,500 diverse patients and use a randomized controlled trial design to assess the impact of return of genomic prediction on the accuracy of risk perception, health surveillance, and risk reducing measures. This proposal will address major knowledge gaps in genetic risk assessment for diverse populations, and the solutions and knowledge gained will be broadly applicable to precision medicine for common complex traits across many clinical specialties. PROJECT NARRATIVE Advances in precision medicine are making it increasingly possible to tailor healthcare decisions based on the individual patients genomic risk profile. However, large-scale validation studies of risk prediction accuracy and its clinical utility are severely lacking in diverse populations. The goal of this eMERGE-IV project is to leverage genetic and electronic health record data for diverse populations to design, optimize, validate and test the clinical utility of ancestry-tailored polygenic risk scores for common diseases of high public health impact.",EHR-based Genomic Risk Assessment and Management for Diverse Populations,9988801,U01HG008680,"['Address', 'Adopted', 'Adoption', 'All of Us Research Program', 'Behavior', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Research', 'Collaborations', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Coronary Arteriosclerosis', 'Cost Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Education', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Ensure', 'Ethnic group', 'European', 'Extensible Markup Language', 'Family', 'Focus Groups', 'Funding', 'Genetic', 'Genetic Risk', 'Genetic Structures', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Health Status', 'Hospitals', 'Individual', 'Informatics', 'Institutional Review Boards', 'Kidney', 'Knowledge', 'Link', 'Measures', 'Medical Genetics', 'Medical center', 'Methods', 'Natural Language Processing', 'New York City', 'Participant', 'Patient Preferences', 'Patient Recruitments', 'Patients', 'Performance', 'Phenotype', 'Population Heterogeneity', 'Positioning Attribute', 'Precision Medicine Initiative', 'Prevention strategy', 'Primary Prevention', 'Provider', 'Public Health', 'Randomized Controlled Trials', 'Recommendation', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Risk Management', 'Stratification', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Translational Research', 'Universities', 'Variant', 'Washington', 'base', 'clinical research site', 'clinical risk', 'cost effectiveness', 'data modeling', 'design', 'discrete data', 'diverse data', 'ethnic diversity', 'experience', 'genetic risk assessment', 'genetic testing', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'health disparity', 'high risk', 'improved', 'individual patient', 'interoperability', 'literacy', 'malignant breast neoplasm', 'mathematical ability', 'medical specialties', 'medically underserved', 'member', 'patient oriented', 'polygenic risk score', 'portability', 'precision medicine', 'programs', 'prospective', 'public health relevance', 'racial and ethnic', 'racial diversity', 'rare variant', 'recruit', 'risk perception', 'screening', 'socioeconomics', 'structural genomics', 'tailored health care', 'tool', 'trait', 'trial design', 'user centered design', 'validation studies']",NHGRI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2020,1336256,0.05645202568595623
"EHR-based Genomic Risk Assessment and Management for Diverse Populations PROJECT SUMMARY/ABSTRACT Recently, large-scale genome-wide association studies (GWAS) provide evidence for a substantial polygenic contribution to the risk of many common complex diseases. However, most of these studies were performed in Europeans, and new data and methods are necessary to tailor polygenic risk prediction to non-Europeans, to ensure that genomic stratification does not further exacerbate health disparities. The overarching goal of the eMERGE-IV network is to leverage genetic and electronic health record (EHR) data for diverse populations to design, validate and test the clinical utility of ancestry-tailored polygenic risk scores for common diseases. As a current member of the eMERGE network, Columbia University has significantly advanced its goals, having recruited over 2,500 diverse patients for sequencing and return of actionable findings, leading the effort to transition the network to the OMOP Common Data Model to improve the efficiency, accuracy, reproducibility and portability of electronic phenotypes, and contributing a widely-adopted XML parser for structuring genetic test reports. Since our last application, the Columbia Precision Medicine Initiative has also grown and now includes participation in several national initiatives, such as the All-of-Us program, in which we have demonstrated our ability to rapidly recruit patients under-represented in biomedical research. Our scientific expertise combined with our strong tradition of patient-centered research and community engagement in a socioeconomically, racially, and ethnically diverse community of Northern Manhattan, positions us to successfully contribute as the Enhanced Diversity Clinical Site of the eEMERGE-IV network. We will leverage our prior experience with eMERGE, scientific expertise, and knowledge gained from participation in other national precision medicine initiatives to develop, optimize, validate and disseminate ancestry-tailored genomic risk assessment and clinical management tools. In Aim 1, we will continue to advance electronic phenotyping by contributing sharable natural language processing tools for converting clinical text into OMOP-based discrete data and facilitating phenotype interoperability. In Aim 2, we will develop and optimize accurate ancestry-tailored genome-wide polygenic predictors, integrate them with clinical risk predictions, and test their performance in diverse populations. In Aim 3, we will investigate ELSI issues related to the return of health risk predictions to diverse patients by ascertaining patients, clinicians, and IRB members views through focus groups. In Aim 4, we will develop portable EHR plug-ins to facilitate prospective risk communication and management using integrated genomic data, family history, and clinical data. In Aim 5, we will recruit 2,500 diverse patients and use a randomized controlled trial design to assess the impact of return of genomic prediction on the accuracy of risk perception, health surveillance, and risk reducing measures. This proposal will address major knowledge gaps in genetic risk assessment for diverse populations, and the solutions and knowledge gained will be broadly applicable to precision medicine for common complex traits across many clinical specialties. PROJECT NARRATIVE Advances in precision medicine are making it increasingly possible to tailor healthcare decisions based on the individual patients genomic risk profile. However, large-scale validation studies of risk prediction accuracy and its clinical utility are severely lacking in diverse populations. The goal of this eMERGE-IV project is to leverage genetic and electronic health record data for diverse populations to design, optimize, validate and test the clinical utility of ancestry-tailored polygenic risk scores for common diseases of high public health impact.",EHR-based Genomic Risk Assessment and Management for Diverse Populations,10201799,U01HG008680,"['Address', 'Adopted', 'Adoption', 'All of Us Research Program', 'Behavior', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Research', 'Collaborations', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Coronary Arteriosclerosis', 'Cost Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Education', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Ensure', 'Ethnic group', 'European', 'Extensible Markup Language', 'Family', 'Focus Groups', 'Funding', 'Genetic', 'Genetic Risk', 'Genetic Structures', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Health Status', 'Hospitals', 'Individual', 'Informatics', 'Institutional Review Boards', 'Kidney', 'Knowledge', 'Link', 'Measures', 'Medical Genetics', 'Medical center', 'Methods', 'Natural Language Processing', 'New York City', 'Participant', 'Patient Preferences', 'Patient Recruitments', 'Patients', 'Performance', 'Phenotype', 'Population Heterogeneity', 'Positioning Attribute', 'Precision Medicine Initiative', 'Prevention strategy', 'Primary Prevention', 'Provider', 'Public Health', 'Randomized Controlled Trials', 'Recommendation', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Risk Management', 'Stratification', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Translational Research', 'Universities', 'Variant', 'Washington', 'base', 'clinical research site', 'clinical risk', 'cost effectiveness', 'data modeling', 'design', 'discrete data', 'diverse data', 'ethnic diversity', 'experience', 'genetic risk assessment', 'genetic testing', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'health disparity', 'high risk', 'improved', 'individual patient', 'interoperability', 'literacy', 'malignant breast neoplasm', 'mathematical ability', 'medical specialties', 'medically underserved', 'member', 'patient oriented', 'polygenic risk score', 'portability', 'precision medicine', 'programs', 'prospective', 'public health relevance', 'racial and ethnic', 'racial diversity', 'rare variant', 'recruit', 'risk perception', 'screening', 'socioeconomics', 'structural genomics', 'tailored health care', 'tool', 'trait', 'trial design', 'user centered design', 'validation studies']",NHGRI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2020,121251,0.05645202568595623
"eMERGE Phase IV Clinical Center at Partners HealthCare Abstract: To enable the application of PRS development and implementation, our eMERGE IV proposal from Partners HealthCare leverages a large biobank (>105,000 consented with genotype data on 40,000), clinical data in the electronic health records (EHR) for >4 million patients from the largest integrated health care provider in New England, advanced bioinformatics expertise, prior leadership in PRS development and state- of-the-art genetic analysis, established expertise in returning genomics results, and experience using information technology to transform clinical processes and assessing outcomes. We propose to build on our expertise to accomplish the specific aims: Aim 1 (Discovery): Hypothesis: Polygenic risks scores will allow us to stratify eMERGE subjects based on genetic risk for common complex traits. Using the largest available genomic data resources, we will calculate and validate new PRS for coronary artery disease, atrial fibrillation, type 2 diabetes, colorectal cancer and major depression across diverse ancestries. We will 1) compare and benchmark the performance of existing PRS construction methods in different ancestral groups, 2) develop novel statistical methods for robust trans-ethnic PRS prediction, and integrate PRS with established clinical risk factors and family history. We will obtain PRS from our network colleagues for an additional 15-e- phenotypes (total 20) with a goal of identifying high-risk individuals, e.g., top 2% of PRS risk Aim 2 (RiskInsight Report/ELSI): We will develop a Risk Insight Report with clinical risk factors, family history, and PRS with evidence-based recommendations for high risk participants (top 2% of phenotype specific PRS distribution) for electronic clinical implementation. We will assess risk communication formats in our ELSI Sub-Aim 1: To test the impact and interpretability of two mock RiskInsight Reports summarizing PRS as either (a) dichotomous (defining the patient as high-risk vs intermediate/low risk) or (b) quantitative (providing a numerical estimate of the percentile of risk for the patient), with linked clinical recommendations in both cases. We will then assess, through surveys of diverse HCPs and patients, the extent to which the mock reports are understood by both HCPs and patients. Aim 3 (Outcomes): Hypothesis: Physicians will alter their surveillance and treatment of patients based on eCDS of RiskInsight Reports. Among HCPs for high-risk subjects, we will see at least one change in clinical care after disclosure discussions with subjects. We will recruit 2500 participants for implementation of clinical PRS in RiskInsight Reports using a SMART on FHIR app for eCDS integrated with the EHR. The primary outcome will be whether any HCP took any action within 12 months after receipt of e-CDS defined by ordering screening tests, prescribing a preventive medication, or providing lifestyle advice. We will conduct analyses of the effect of disclosing results to high risk participants to determine how personalized results changed patient outcomes in laboratory values, risk reduction behaviors, or health care utilization. PROJECT NARRATIVE The discovery and clinical use of polygenic risk scores (PRS) for complex traits promises to dramatically change the practice of medicine. Our eMERGE IV grant will leverage a large Biobank and a rich electronic medical record to define the clinical impact of PRS derived from diverse populations and the clinical impact of returning these results along with family history and clinical risk information to participants and their healthcare providers.",eMERGE Phase IV Clinical Center at Partners HealthCare,9988785,U01HG008685,"['Algorithms', 'All of Us Research Program', 'Asians', 'Atrial Fibrillation', 'Benchmarking', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Colorectal Cancer', 'Communication', 'Complex', 'Computerized Medical Record', 'Consent', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Development', 'Disclosure', 'Disease', 'Disease Outcome', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Family', 'Fast Healthcare Interoperability Resources', 'Genetic Risk', 'Genomics', 'Genotype', 'Glycosylated hemoglobin A', 'Goals', 'Grant', 'Harm Reduction', 'Health Personnel', 'Healthcare', 'Hispanics', 'Individual', 'Information Technology', 'Intervention', 'Japan', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Low-Density Lipoproteins', 'Major Depressive Disorder', 'Medical', 'Medicine', 'Mental Depression', 'Methods', 'New England', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physical activity', 'Physicians', 'Population Heterogeneity', 'Predictive Value', 'Preventive', 'Preventive therapy', 'Process', 'Recommendation', 'Recording of previous events', 'Reporting', 'Risk', 'Risk Factors', 'Risk Reduction Behavior', 'Risk stratification', 'Statistical Methods', 'Surveys', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'Veterans', 'Visit', 'base', 'behavioral outcome', 'biobank', 'clinical care', 'clinical center', 'clinical decision support', 'clinical implementation', 'clinical practice', 'clinical research site', 'clinical risk', 'data resource', 'design', 'economic outcome', 'evidence based guidelines', 'exome', 'experience', 'genetic analysis', 'genome wide association study', 'genomic data', 'health care service utilization', 'high risk', 'insight', 'machine learning algorithm', 'novel', 'polygenic risk score', 'portability', 'primary outcome', 'programs', 'psychiatric genomics', 'recruit', 'screening', 'support tools', 'trait']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2020,1216161,-0.0017528246992356486
"Finding Genomic Profiles of COVID-19 Phenotypes from the EHR Abstract: As the world searches for effective treatments and potential cures for the COVID-19 pandemic, the ability to consolidate data, insights, and expertise from many disparate sources will be key to fully understanding the patient outcomes of the infection. Key to facilitating this type of research is a cohesive and secure research environment that enables clinicians, researchers, data scientists, and technologists from multiple organizations to work together with a common goal of better understanding COVID-19 symptoms, associated risk factors, and successful therapies. Building upon faculty, staff and infrastructure already in place through the eMERGE IV Clinical Center at Mass General Brigham, we are proposing the creation of a COVID- 19 Biobank Portal to provide a foundation for building a truly collaborative environment that is compliant with patient privacy and offers a common set of bioinformatic tools and a standardized IT approach for the staging of data and analyses. We will do this by accomplishing the following three Specific Aims which supplement the parent grants Aim I which is: Polygenic risks scores will allow us to stratify eMERGE participants based on genetic risk for common complex traits which will focus in this supplement on risk factors for severity of COVID-19 illness in our biobank participants. We propose to build on our expertise to accomplish the specific aims: Aim 1: We will create a COVID-19 Centric Biobank Portal that allows general institutional use with proper research agreements in place where patient cohorts can be studied using easily assessable and transformed data and through which genomic samples can be obtained. Aim 2: Supplement the COVID-19 Biobank Portal with test results, phenotype risk factors, symptoms, and outcomes for COVID-19 which are derived from data in the electronic health record (EHR) by using natural language processing and computational phenotypes and by performing chart reviews to validate severity indices and clinical outcomes found in COVID-19 infected patients. Aim 3: Genetic data (array and sequence data) will be contributed to the eMERGE IV network and to the International l COVID-19 Host Genetics Initiative (https://covid19hg.org) such that data can be used to calculate polygenic risk scores (PRS) for genome-wide association studies of risk phenotypes and patient outcomes and polygenic risk scores (PRS) for COVID-19 outcomes in our dataset and in collaborations with others. PROJECT NARRATIVE We will create a COVID-19 Centric Biobank Portal that allows general institutional use with proper agreements in place where patient cohorts can be studied using easily accessible and transformed data through which genomic samples can be obtained. The COVID-19 Biobank Portal with test results, phenotype risk factors, symptoms, and outcomes for COVID-19 which are derived from data in the electronic health record using natural language processing, using computational phenotypes, and performing chart review which will be compared to severity indexes and outcomes found from COVID-19 infected patients. Samples will be contributed to the eMERGE and the International Host Genomic Consortium such that risk phenotypes and patient outcomes for COVID-19 can be used to calculate polygenic risk scores.",Finding Genomic Profiles of COVID-19 Phenotypes from the EHR,10166411,U01HG008685,"['Agreement', 'COVID-19', 'COVID-19 pandemic', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Electronic Health Record', 'Environment', 'Faculty', 'Foundations', 'Genetic', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Infection', 'Infrastructure', 'International', 'Natural Language Processing', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Sampling', 'Secure', 'Severities', 'Source', 'Staging', 'Standardization', 'Symptoms', 'Test Result', 'Work', 'base', 'biobank', 'bioinformatics tool', 'clinical center', 'cohesion', 'cohort', 'collaborative environment', 'effective therapy', 'genome wide association study', 'genomic data', 'genomic profiles', 'indexing', 'insight', 'parent grant', 'patient privacy', 'polygenic risk score', 'research clinical testing', 'trait']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2020,401928,0.030355060137161986
"Informatics for Integrating Biology & the Bedside (i2b2) DESCRIPTION (PROVIDED BY APPLICANT): The large and growing size of the healthcare system makes it imperative to understand what is happening to us, the recipients of healthcare, to be able to efficiently conduct research to improve healthcare delivery and to improve the state of biomedicine by advancing its science. i2b2, ""Informatics for Integrating Biology and the Bedside"" seeks to provide this instrumentation using the informational by products of healthcare and the biological materials accumulated through the delivery of healthcare. This complements existing efforts to create prospective cohort studies or trials outside the delivery of routine healthcare. In the first round of i2b2, we demonstrated that we could identify known adverse events and phenotypically select and then genotype patients for genetic association at approximately 1/10* of the price and less than l/10 of the time usually entailed to develop such populations for study. The challenge we have set ourselves for the next methodological challenge in i2b2 is the development of Virtual Cohort Studies (VCS) encompassing the population of a healthcare system as study subjects and asking questions of comparative effectiveness, unforeseen adverse events and identification of clinically relevant subpopulations including both clinical and genome-scale measures. We will be comparing the results of the VCS to those of carefully planned and executed cohort studies such as the Framingham Heart Study. VCS will require multiple methodological advances and tools development including in the disciplines of natural language processing, temporal reasoning, predictive modeling, biostatistics and machine learning. VCS methods will be tested by two driving biology projects, the first studying a collection of autoimmune diseases and the second type 2 diabetes. In both projects, VCS methods will be applied to investigate the components of cardiovascular risk from the genetic to the epigenetic and including the full range of clinical history including medications exposure. A systems/integrative approach will be taken to identify commonalities in these risk profiles across these disparate disease domains. VCS methods will be shared with i2b2 user community under open source governance while i2b2 user community contributions are folded into the i2b2 toolkit. Public Health Relevance: The i2b2 model of using existing clinical data for high throughput, cost effective, and timely research promises to rapidly leverage our nation's ability to better understand the existing disease burden and how best to achieve cost-effective clinical effectiveness, including new drug targets, new uses of existing drugs and improved management of existing disease.",Informatics for Integrating Biology & the Bedside (i2b2),8514121,U54LM008748,"['Adverse event', 'Autoimmune Diseases', 'Automobile Driving', 'Biocompatible Materials', 'Biology', 'Biometry', 'Clinical', 'Clinical Data', 'Clinical effectiveness', 'Cohort Studies', 'Collection', 'Communities', 'Complement', 'Development', 'Discipline', 'Disease', 'Drug Delivery Systems', 'Epigenetic Process', 'Framingham Heart Study', 'Genetic', 'Genome', 'Genotype', 'Healthcare', 'Healthcare Systems', 'Informatics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Study', 'Price', 'Recording of previous events', 'Research', 'Risk', 'Science', 'Study Subject', 'System', 'Testing', 'Time', 'burden of illness', 'cardiovascular risk factor', 'clinically relevant', 'comparative effectiveness', 'cost effective', 'genetic association', 'health care delivery', 'improved', 'instrumentation', 'open source', 'predictive modeling', 'prospective', 'public health relevance', 'tool development', 'virtual']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,U54,2012,39250,0.030933222490452546
"Informatics for Integrating Biology & the Bedside (i2b2) DESCRIPTION (PROVIDED BY APPLICANT): The large and growing size of the healthcare system makes it imperative to understand what is happening to us, the recipients of healthcare, to be able to efficiently conduct research to improve healthcare delivery and to improve the state of biomedicine by advancing its science. i2b2, ""Informatics for Integrating Biology and the Bedside"" seeks to provide this instrumentation using the informational by products of healthcare and the biological materials accumulated through the delivery of healthcare. This complements existing efforts to create prospective cohort studies or trials outside the delivery of routine healthcare. In the first round of i2b2, we demonstrated that we could identify known adverse events and phenotypically select and then genotype patients for genetic association at approximately 1/10* of the price and less than l/10 of the time usually entailed to develop such populations for study. The challenge we have set ourselves for the next methodological challenge in i2b2 is the development of Virtual Cohort Studies (VCS) encompassing the population of a healthcare system as study subjects and asking questions of comparative effectiveness, unforeseen adverse events and identification of clinically relevant subpopulations including both clinical and genome-scale measures. We will be comparing the results of the VCS to those of carefully planned and executed cohort studies such as the Framingham Heart Study. VCS will require multiple methodological advances and tools development including in the disciplines of natural language processing, temporal reasoning, predictive modeling, biostatistics and machine learning. VCS methods will be tested by two driving biology projects, the first studying a collection of autoimmune diseases and the second type 2 diabetes. In both projects, VCS methods will be applied to investigate the components of cardiovascular risk from the genetic to the epigenetic and including the full range of clinical history including medications exposure. A systems/integrative approach will be taken to identify commonalities in these risk profiles across these disparate disease domains. VCS methods will be shared with i2b2 user community under open source governance while i2b2 user community contributions are folded into the i2b2 toolkit. Public Health Relevance: The i2b2 model of using existing clinical data for high throughput, cost effective, and timely research promises to rapidly leverage our nation's ability to better understand the existing disease burden and how best to achieve cost-effective clinical effectiveness, including new drug targets, new uses of existing drugs and improved management of existing disease.",Informatics for Integrating Biology & the Bedside (i2b2),8519533,U54LM008748,"['Adverse event', 'Autoimmune Diseases', 'Automobile Driving', 'Biocompatible Materials', 'Biology', 'Biometry', 'Clinical', 'Clinical Data', 'Clinical effectiveness', 'Cohort Studies', 'Collection', 'Communities', 'Complement', 'Development', 'Discipline', 'Disease', 'Drug Targeting', 'Epigenetic Process', 'Framingham Heart Study', 'Genetic', 'Genome', 'Genotype', 'Healthcare', 'Healthcare Systems', 'Informatics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Study', 'Price', 'Recording of previous events', 'Research', 'Risk', 'Science', 'Study Subject', 'System', 'Testing', 'Time', 'burden of illness', 'cardiovascular risk factor', 'clinically relevant', 'comparative effectiveness', 'cost effective', 'genetic association', 'health care delivery', 'improved', 'instrumentation', 'open source', 'predictive modeling', 'prospective', 'public health relevance', 'tool development', 'virtual']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,U54,2013,3017637,0.030933222490452546
"Informatics for Integrating Biology & the Bedside (i2b2) DESCRIPTION (PROVIDED BY APPLICANT): The large and growing size of the healthcare system makes it imperative to understand what is happening to us, the recipients of healthcare, to be able to efficiently conduct research to improve healthcare delivery and to improve the state of biomedicine by advancing its science. i2b2, ""Informatics for Integrating Biology and the Bedside"" seeks to provide this instrumentation using the informational by products of healthcare and the biological materials accumulated through the delivery of healthcare. This complements existing efforts to create prospective cohort studies or trials outside the delivery of routine healthcare. In the first round of i2b2, we demonstrated that we could identify known adverse events and phenotypically select and then genotype patients for genetic association at approximately 1/10* of the price and less than l/10 of the time usually entailed to develop such populations for study. The challenge we have set ourselves for the next methodological challenge in i2b2 is the development of Virtual Cohort Studies (VCS) encompassing the population of a healthcare system as study subjects and asking questions of comparative effectiveness, unforeseen adverse events and identification of clinically relevant subpopulations including both clinical and genome-scale measures. We will be comparing the results of the VCS to those of carefully planned and executed cohort studies such as the Framingham Heart Study. VCS will require multiple methodological advances and tools development including in the disciplines of natural language processing, temporal reasoning, predictive modeling, biostatistics and machine learning. VCS methods will be tested by two driving biology projects, the first studying a collection of autoimmune diseases and the second type 2 diabetes. In both projects, VCS methods will be applied to investigate the components of cardiovascular risk from the genetic to the epigenetic and including the full range of clinical history including medications exposure. A systems/integrative approach will be taken to identify commonalities in these risk profiles across these disparate disease domains. VCS methods will be shared with i2b2 user community under open source governance while i2b2 user community contributions are folded into the i2b2 toolkit. Public Health Relevance: The i2b2 model of using existing clinical data for high throughput, cost effective, and timely research promises to rapidly leverage our nation's ability to better understand the existing disease burden and how best to achieve cost-effective clinical effectiveness, including new drug targets, new uses of existing drugs and improved management of existing disease.",Informatics for Integrating Biology & the Bedside (i2b2),8326732,U54LM008748,[' '],NLM,BRIGHAM AND WOMEN'S HOSPITAL,U54,2012,1282800,0.030933222490452546
"Informatics for Integrating Biology & the Bedside (i2b2) DESCRIPTION (PROVIDED BY APPLICANT): The large and growing size of the healthcare system makes it imperative to understand what is happening to us, the recipients of healthcare, to be able to efficiently conduct research to improve healthcare delivery and to improve the state of biomedicine by advancing its science. i2b2, ""Informatics for Integrating Biology and the Bedside"" seeks to provide this instrumentation using the informational by products of healthcare and the biological materials accumulated through the delivery of healthcare. This complements existing efforts to create prospective cohort studies or trials outside the delivery of routine healthcare. In the first round of i2b2, we demonstrated that we could identify known adverse events and phenotypically select and then genotype patients for genetic association at approximately 1/10* of the price and less than l/10 of the time usually entailed to develop such populations for study. The challenge we have set ourselves for the next methodological challenge in i2b2 is the development of Virtual Cohort Studies (VCS) encompassing the population of a healthcare system as study subjects and asking questions of comparative effectiveness, unforeseen adverse events and identification of clinically relevant subpopulations including both clinical and genome-scale measures. We will be comparing the results of the VCS to those of carefully planned and executed cohort studies such as the Framingham Heart Study. VCS will require multiple methodological advances and tools development including in the disciplines of natural language processing, temporal reasoning, predictive modeling, biostatistics and machine learning. VCS methods will be tested by two driving biology projects, the first studying a collection of autoimmune diseases and the second type 2 diabetes. In both projects, VCS methods will be applied to investigate the components of cardiovascular risk from the genetic to the epigenetic and including the full range of clinical history including medications exposure. A systems/integrative approach will be taken to identify commonalities in these risk profiles across these disparate disease domains. VCS methods will be shared with i2b2 user community under open source governance while i2b2 user community contributions are folded into the i2b2 toolkit. Public Health Relevance: The i2b2 model of using existing clinical data for high throughput, cost effective, and timely research promises to rapidly leverage our nation's ability to better understand the existing disease burden and how best to achieve cost-effective clinical effectiveness, including new drug targets, new uses of existing drugs and improved management of existing disease.",Informatics for Integrating Biology & the Bedside (i2b2),8144250,U54LM008748,[' '],NLM,BRIGHAM AND WOMEN'S HOSPITAL,U54,2011,100000,0.030933222490452546
"Informatics for Integrating Biology & the Bedside (i2b2) DESCRIPTION (PROVIDED BY APPLICANT): The large and growing size of the healthcare system makes it imperative to understand what is happening to us, the recipients of healthcare, to be able to efficiently conduct research to improve healthcare delivery and to improve the state of biomedicine by advancing its science. i2b2, ""Informatics for Integrating Biology and the Bedside"" seeks to provide this instrumentation using the informational by products of healthcare and the biological materials accumulated through the delivery of healthcare. This complements existing efforts to create prospective cohort studies or trials outside the delivery of routine healthcare. In the first round of i2b2, we demonstrated that we could identify known adverse events and phenotypically select and then genotype patients for genetic association at approximately 1/10* of the price and less than l/10 of the time usually entailed to develop such populations for study. The challenge we have set ourselves for the next methodological challenge in i2b2 is the development of Virtual Cohort Studies (VCS) encompassing the population of a healthcare system as study subjects and asking questions of comparative effectiveness, unforeseen adverse events and identification of clinically relevant subpopulations including both clinical and genome-scale measures. We will be comparing the results of the VCS to those of carefully planned and executed cohort studies such as the Framingham Heart Study. VCS will require multiple methodological advances and tools development including in the disciplines of natural language processing, temporal reasoning, predictive modeling, biostatistics and machine learning. VCS methods will be tested by two driving biology projects, the first studying a collection of autoimmune diseases and the second type 2 diabetes. In both projects, VCS methods will be applied to investigate the components of cardiovascular risk from the genetic to the epigenetic and including the full range of clinical history including medications exposure. A systems/integrative approach will be taken to identify commonalities in these risk profiles across these disparate disease domains. VCS methods will be shared with i2b2 user community under open source governance while i2b2 user community contributions are folded into the i2b2 toolkit. Public Health Relevance: The i2b2 model of using existing clinical data for high throughput, cost effective, and timely research promises to rapidly leverage our nation's ability to better understand the existing disease burden and how best to achieve cost-effective clinical effectiveness, including new drug targets, new uses of existing drugs and improved management of existing disease.",Informatics for Integrating Biology & the Bedside (i2b2),8012931,U54LM008748,[' '],NLM,BRIGHAM AND WOMEN'S HOSPITAL,U54,2010,3966606,0.030933222490452546
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7918614,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'clinical practice', 'forgetting', 'innovation', 'natural language', 'preference', 'speech processing', 'symposium']",NLM,UNIVERSITY OF CHICAGO,R01,2009,185745,0.02131387440569843
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7675157,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Language', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'day', 'forgetting', 'innovation', 'preference', 'speech processing', 'symposium']",NLM,UNIVERSITY OF CHICAGO,R01,2008,354823,0.02131387440569843
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7217497,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Language', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'day', 'forgetting', 'innovation', 'preference', 'speech processing', 'symposium']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,361696,0.02131387440569843
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7101997,R01LM008799,"['clinical research', 'human', 'language', 'memory disorders', 'model', 'physicians', 'training', 'voice']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372499,0.02131387440569843
"Automated Detection of Medical Errors DESCRIPTION:    The long-term goal of this proposal is to use the electronic medical record, including narrative text, to understand and encode the process of care for individual patients in order to improve patient safety.   Achieving this goal has the potential to help detect adverse events, and to differentiate medical errors from appropriately tailored care. The specific aims for this proposal are as follows: 1) To understand and encode the process of care for individual patients using data in the electronic medical record, including narrative text.   2) To use a more detailed understanding of patients' processes of care to improve automated adverse event detection. 3) To match processes of care for individual patients against accepted care pathways in order to identify discrepancies. We will capitalize on three core technologies that are in active use by clinicians and researchers in our busy clinical setting: 1) a Web-based clinical information system and its associated clinical data repository (WebCIS), 2) a full medical language parser (MedLEE), and 3) a semi-structured, electronic physician documentation system built by the applicant specifically to support this project (eNote).   Methods will include evaluating the performance (sensitivity, specificity and positive predictive value) of our system, DETER+MINE (DETecting ERrors Mining Narrative Electronically), to model the care process and detect adverse events and pathway deviations. We will utilize explicit process criteria and manual, retrospective chart review as a gold standard.   This research is intended to provide proof of concept that combining natural language processing of clinical narrative with traditional sources of coded data is required for effective screening with automated defection systems. This approach has the potential to impact significantly on our ability to detect and investigate medical errors, adverse medical events, and pathway deviations by reducing reliance on costly and slow manual chart reviews. n/a",Automated Detection of Medical Errors,7282343,K22LM008805,"['Address', 'Adverse event', 'Applications Grants', 'Caring', 'Causations', 'Cause of Death', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Pathways', 'Code', 'Computerized Medical Record', 'Critical Care', 'Data', 'Databases', 'Decision Support Systems', 'Detection', 'Documentation', 'Effectiveness', 'Electronics', 'Event', 'Goals', 'Gold', 'Guidelines', 'Hospitals', 'Human', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Language', 'Manuals', 'Medical', 'Medical Errors', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Negligence', 'Online Systems', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Predictive Value', 'Prevention', 'Process', 'Range', 'Recommendation', 'Reliance', 'Reporting', 'Research', 'Research Personnel', 'Screening procedure', 'Sensitivity and Specificity', 'Source Code', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'United States', 'base', 'computerized', 'concept', 'experience', 'improved', 'patient safety', 'programs', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K22,2007,135000,0.06574942618498844
"Automated Detection of Medical Errors DESCRIPTION:    The long-term goal of this proposal is to use the electronic medical record, including narrative text, to understand and encode the process of care for individual patients in order to improve patient safety.   Achieving this goal has the potential to help detect adverse events, and to differentiate medical errors from appropriately tailored care. The specific aims for this proposal are as follows: 1) To understand and encode the process of care for individual patients using data in the electronic medical record, including narrative text.   2) To use a more detailed understanding of patients' processes of care to improve automated adverse event detection. 3) To match processes of care for individual patients against accepted care pathways in order to identify discrepancies. We will capitalize on three core technologies that are in active use by clinicians and researchers in our busy clinical setting: 1) a Web-based clinical information system and its associated clinical data repository (WebCIS), 2) a full medical language parser (MedLEE), and 3) a semi-structured, electronic physician documentation system built by the applicant specifically to support this project (eNote).   Methods will include evaluating the performance (sensitivity, specificity and positive predictive value) of our system, DETER+MINE (DETecting ERrors Mining Narrative Electronically), to model the care process and detect adverse events and pathway deviations. We will utilize explicit process criteria and manual, retrospective chart review as a gold standard.   This research is intended to provide proof of concept that combining natural language processing of clinical narrative with traditional sources of coded data is required for effective screening with automated defection systems. This approach has the potential to impact significantly on our ability to detect and investigate medical errors, adverse medical events, and pathway deviations by reducing reliance on costly and slow manual chart reviews. n/a",Automated Detection of Medical Errors,7124706,K22LM008805,"['automated medical record system', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'health care quality', 'health services research tag', 'human data', 'information retrieval', 'medical records', 'method development', 'patient care management', 'patient safety /medical error']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K22,2006,135000,0.06574942618498844
"Automated Detection of Medical Errors DESCRIPTION:    The long-term goal of this proposal is to use the electronic medical record, including narrative text, to understand and encode the process of care for individual patients in order to improve patient safety.   Achieving this goal has the potential to help detect adverse events, and to differentiate medical errors from appropriately tailored care. The specific aims for this proposal are as follows: 1) To understand and encode the process of care for individual patients using data in the electronic medical record, including narrative text.   2) To use a more detailed understanding of patients' processes of care to improve automated adverse event detection. 3) To match processes of care for individual patients against accepted care pathways in order to identify discrepancies. We will capitalize on three core technologies that are in active use by clinicians and researchers in our busy clinical setting: 1) a Web-based clinical information system and its associated clinical data repository (WebCIS), 2) a full medical language parser (MedLEE), and 3) a semi-structured, electronic physician documentation system built by the applicant specifically to support this project (eNote).   Methods will include evaluating the performance (sensitivity, specificity and positive predictive value) of our system, DETER+MINE (DETecting ERrors Mining Narrative Electronically), to model the care process and detect adverse events and pathway deviations. We will utilize explicit process criteria and manual, retrospective chart review as a gold standard.   This research is intended to provide proof of concept that combining natural language processing of clinical narrative with traditional sources of coded data is required for effective screening with automated defection systems. This approach has the potential to impact significantly on our ability to detect and investigate medical errors, adverse medical events, and pathway deviations by reducing reliance on costly and slow manual chart reviews. n/a",Automated Detection of Medical Errors,6958394,K22LM008805,"['automated medical record system', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'health care quality', 'health services research tag', 'human data', 'information retrieval', 'medical records', 'method development', 'patient care management', 'patient safety /medical error']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K22,2005,134800,0.06574942618498844
"Extracting Semantic Knowledge from Clinical Data Sources DESCRIPTION (provided by applicant):    Electronic medical record systems (EMR) contain a wealth of clinical data that is invaluable for biomedical research, but because there are no satisfactory methods to build coherent specialized knowledge bases, which represent the information in free text medical records, data mining and clinical discovery are held back. Medical Reporting Solutions, Inc. has developed advanced technology, which we propose to extend, refine, and test for constructing specialized semantic knowledge bases. These knowledge bases will encode the clinical information in medical reports, and enable automated natural language processing systems for extracting clinical knowledge.      Our research and development uses methods in corpus linguistics and sentential logic to represent the knowledge in free-text medical reports in an efficient, codeable manner. We have created tools to map sentences in a medical domain to unique codeable propositions. Our method for creating knowledge ontologies makes it easy for biomedical researchers to get semantic information at the appropriate level of detail. The knowledge base and mapping tables allow us to analyze medical reports in near real-time. One knowledge base, under development, is derived from hundreds of thousands of reports in the radiology domain, and we intend to analyze other medical domains using the methods we have pioneered.      Our phase one project plan includes further improving our knowledge editing tools, substantially enlarging our semantic knowledge base to cover over 60-70% of the radiology domain, and extensively test our knowledge representation schema against actual radiology reports. We plan to make the knowledge base freely accessible to the biomedical research community, while providing commercial services to codify free text reports found in EMRs. n/a",Extracting Semantic Knowledge from Clinical Data Sources,6988908,R43LM008974,"['automated medical record system', 'clinical research', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'human data', 'informatics', 'information retrieval']",NLM,"LOGICAL SEMANTICS, INC.",R43,2005,100000,0.005728736121548238
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7908946,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'meetings', 'natural language', 'population based', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2009,71200,-0.0037897741599370884
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7414601,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2008,142400,-0.0037897741599370884
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7195053,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2007,145510,-0.0037897741599370884
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7019753,G08LM008983,"['clinical research', 'public health']",NLM,SYRACUSE UNIVERSITY,G08,2006,149472,-0.0037897741599370884
"Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral    DESCRIPTION (provided by applicant):       Recent developments in text mining research, and in scientific publication, have brought us to the moment when the long-standing potential of natural language processing technology to benefit biomedical researchers may finally be realized. Technological advances, recent results in computational linguistics, maturation of biomedical ontology, and the advent of resources such as PubMedCentral have set the stage for an attempt at an integrated computational analysis of a large proportion of the full text biomedical literature. Such an analysis has the potential to dramatically extend the way that biomedical researchers can effectively use the scientific literature, particularly in the analysis of genome-scale datasets, broadly accelerating and increasing the efficiency of scientific discovery. We hypothesize that it is now possible to extract a wide variety of ontologically-grounded entities and relationships by processing the entire PubMedCentral document collection accurately and with good coverage, to use this extracted information to produce new genres of scientifically valuable tools and analysis techniques, and to demonstrate its utility in the analysis of genome-scale data. The challenges that we plan to overcome range from fundamental linguistic issues (e.g. cross- document coreference resolution) to high-performance computing (e.g. scaling up integrated processing to include millions of complex documents), to fielding practical systems that can exploit enormous knowledge-bases to accelerate the analysis of very large molecular data sets.              Project narrative Enormous amounts of biomedical information are now available in the PubMedCentral database, but computers cannot work with it because it is in the form of human-language text and humans can't read it all due to its large volume. The goal of this project is to harvest large amounts of that information automatically, making it available to humans in summarized form and to computers in computer-readable form.",Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral,8318224,R01LM009254,"['Biological', 'Collection', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Evaluation Research', 'Funding', 'Gene Expression', 'Genes', 'Genome', 'Goals', 'Harvest', 'Health', 'High Performance Computing', 'Human', 'Imagery', 'Journals', 'Knowledge', 'Language', 'Linguistics', 'Literature', 'Methods', 'Molecular', 'Natural Language Processing', 'Nature', 'Pharmaceutical Preparations', 'Process', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Staging', 'System', 'Techniques', 'Technology', 'Text', 'Work', 'biomedical ontology', 'clinically relevant', 'information organization', 'knowledge base', 'language processing', 'scale up', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2012,572436,-0.02082175058656765
"Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral    DESCRIPTION (provided by applicant):       Recent developments in text mining research, and in scientific publication, have brought us to the moment when the long-standing potential of natural language processing technology to benefit biomedical researchers may finally be realized. Technological advances, recent results in computational linguistics, maturation of biomedical ontology, and the advent of resources such as PubMedCentral have set the stage for an attempt at an integrated computational analysis of a large proportion of the full text biomedical literature. Such an analysis has the potential to dramatically extend the way that biomedical researchers can effectively use the scientific literature, particularly in the analysis of genome-scale datasets, broadly accelerating and increasing the efficiency of scientific discovery. We hypothesize that it is now possible to extract a wide variety of ontologically-grounded entities and relationships by processing the entire PubMedCentral document collection accurately and with good coverage, to use this extracted information to produce new genres of scientifically valuable tools and analysis techniques, and to demonstrate its utility in the analysis of genome-scale data. The challenges that we plan to overcome range from fundamental linguistic issues (e.g. cross- document coreference resolution) to high-performance computing (e.g. scaling up integrated processing to include millions of complex documents), to fielding practical systems that can exploit enormous knowledge-bases to accelerate the analysis of very large molecular data sets.              Project narrative Enormous amounts of biomedical information are now available in the PubMedCentral database, but computers cannot work with it because it is in the form of human-language text and humans can't read it all due to its large volume. The goal of this project is to harvest large amounts of that information automatically, making it available to humans in summarized form and to computers in computer-readable form.",Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral,8139258,R01LM009254,"['Biological', 'Collection', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Evaluation Research', 'Funding', 'Gene Expression', 'Genes', 'Genome', 'Goals', 'Harvest', 'Health', 'High Performance Computing', 'Human', 'Imagery', 'Journals', 'Knowledge', 'Language', 'Linguistics', 'Literature', 'Methods', 'Molecular', 'Natural Language Processing', 'Nature', 'Pharmaceutical Preparations', 'Process', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Staging', 'System', 'Techniques', 'Technology', 'Text', 'Work', 'biomedical ontology', 'clinically relevant', 'information organization', 'knowledge base', 'language processing', 'scale up', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2011,513952,-0.02082175058656765
"Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral    DESCRIPTION (provided by applicant):       Recent developments in text mining research, and in scientific publication, have brought us to the moment when the long-standing potential of natural language processing technology to benefit biomedical researchers may finally be realized. Technological advances, recent results in computational linguistics, maturation of biomedical ontology, and the advent of resources such as PubMedCentral have set the stage for an attempt at an integrated computational analysis of a large proportion of the full text biomedical literature. Such an analysis has the potential to dramatically extend the way that biomedical researchers can effectively use the scientific literature, particularly in the analysis of genome-scale datasets, broadly accelerating and increasing the efficiency of scientific discovery. We hypothesize that it is now possible to extract a wide variety of ontologically-grounded entities and relationships by processing the entire PubMedCentral document collection accurately and with good coverage, to use this extracted information to produce new genres of scientifically valuable tools and analysis techniques, and to demonstrate its utility in the analysis of genome-scale data. The challenges that we plan to overcome range from fundamental linguistic issues (e.g. cross- document coreference resolution) to high-performance computing (e.g. scaling up integrated processing to include millions of complex documents), to fielding practical systems that can exploit enormous knowledge-bases to accelerate the analysis of very large molecular data sets.              Project narrative Enormous amounts of biomedical information are now available in the PubMedCentral database, but computers cannot work with it because it is in the form of human-language text and humans can't read it all due to its large volume. The goal of this project is to harvest large amounts of that information automatically, making it available to humans in summarized form and to computers in computer-readable form.",Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral,7935408,R01LM009254,"['Biological', 'Collection', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Evaluation Research', 'Funding', 'Gene Expression', 'Genes', 'Genome', 'Goals', 'Harvest', 'Health', 'High Performance Computing', 'Human', 'Imagery', 'Journals', 'Knowledge', 'Language', 'Linguistics', 'Literature', 'Methods', 'Molecular', 'Natural Language Processing', 'Nature', 'Pharmaceutical Preparations', 'Process', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Staging', 'System', 'Techniques', 'Technology', 'Text', 'Work', 'biomedical ontology', 'clinically relevant', 'information organization', 'knowledge base', 'language processing', 'scale up', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2010,515594,-0.02082175058656765
"Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral    DESCRIPTION (provided by applicant):       Recent developments in text mining research, and in scientific publication, have brought us to the moment when the long-standing potential of natural language processing technology to benefit biomedical researchers may finally be realized. Technological advances, recent results in computational linguistics, maturation of biomedical ontology, and the advent of resources such as PubMedCentral have set the stage for an attempt at an integrated computational analysis of a large proportion of the full text biomedical literature. Such an analysis has the potential to dramatically extend the way that biomedical researchers can effectively use the scientific literature, particularly in the analysis of genome-scale datasets, broadly accelerating and increasing the efficiency of scientific discovery. We hypothesize that it is now possible to extract a wide variety of ontologically-grounded entities and relationships by processing the entire PubMedCentral document collection accurately and with good coverage, to use this extracted information to produce new genres of scientifically valuable tools and analysis techniques, and to demonstrate its utility in the analysis of genome-scale data. The challenges that we plan to overcome range from fundamental linguistic issues (e.g. cross- document coreference resolution) to high-performance computing (e.g. scaling up integrated processing to include millions of complex documents), to fielding practical systems that can exploit enormous knowledge-bases to accelerate the analysis of very large molecular data sets.              Project narrative Enormous amounts of biomedical information are now available in the PubMedCentral database, but computers cannot work with it because it is in the form of human-language text and humans can't read it all due to its large volume. The goal of this project is to harvest large amounts of that information automatically, making it available to humans in summarized form and to computers in computer-readable form.",Biomedical Language Processing Writ Large:  Scaling to all of PubMedCentral,7781934,R01LM009254,"['Biological', 'Collection', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Evaluation Research', 'Funding', 'Gene Expression', 'Genes', 'Genome', 'Goals', 'Harvest', 'Health', 'High Performance Computing', 'Human', 'Imagery', 'Journals', 'Knowledge', 'Language', 'Linguistics', 'Literature', 'Methods', 'Molecular', 'Natural Language Processing', 'Nature', 'Pharmaceutical Preparations', 'Process', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Staging', 'System', 'Techniques', 'Technology', 'Text', 'Work', 'biomedical ontology', 'clinically relevant', 'information organization', 'knowledge base', 'language processing', 'scale up', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2009,505564,-0.02082175058656765
"Beyond Abstracts:  Issues in Mining Full Texts    DESCRIPTION (provided by applicant):     Biomedical language processing, the application of computational techniques to human-generated texts in biomedicine, is an increasingly important enabling technology for basic and applied biomedical research. The exponential growth of the peer-reviewed literature and the breakdown of disciplinary boundaries associated with high-throughput techniques have increased the importance of automated tools for keeping scientists abreast of all of the published material relevant to their work. However, despite decades of research, the performance of state-of-the-art tools for basic language processing tasks like information extraction and document retrieval remain below the level necessary for adequate utility and widespread adoption of this technology. The development, performance and evaluation of text mining systems depend crucially on the availability of appropriate corpora: collections of representative documents that have been annotated with human judgments relevant to a language-processing task. Corpora play two roles in the development of this technology: first, they act as ""gold standards"" by which alternative automated methods can be fairly compared, and second, they provide data for the training of statistical and machine learning systems that create empirical models of patterns in language use. The conventional view is that corpora are neutral, random samples of the domain of interest. Our preliminary work suggests that the restrictions in size, quality, genre, and representational schema of the small number of existing corpora are themselves a critical limiting factor for near-term breakthroughs in biomedical text processing technology. Therefore, we propose to test the following hypothesis: Creation of large, high-quality, biomedical corpora from multiple genres will lead to significant improvements in the performance of biomedical text mining systems and the creation of new approaches to text mining tasks. Specific aims include constructing several large corpora covering a range of genres and incorporating a rich knowledge representation; identifying factors that affect differential performance on full text versus abstracts; and developing new methods for language processing, especially of full text. Because improvements in the ability to automatically extract information from many textual genres will assist scientists and clinicians in the crucial task of keeping up with the burgeoning biomedical literature, the potential public health impact is quite large.          n/a",Beyond Abstracts:  Issues in Mining Full Texts,7488396,R01LM009254,"['Adoption', 'Affect', 'Agreement', 'Arts', 'Biomedical Research', 'Body of uterus', 'Collection', 'Computational Technique', 'Data', 'Development', 'Evaluation', 'Gold', 'Growth', 'Human', 'Judgment', 'Language', 'Lead', 'Literature', 'Machine Learning', 'Memory', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular Biology', 'Numbers', 'Pattern', 'Peer Review', 'Performance', 'Play', 'Process', 'Public Health', 'Publishing', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Retrieval', 'Review Literature', 'Role', 'Sampling', 'Scheme', 'Scientist', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'Work', 'abstracting', 'base', 'concept', 'improved', 'information organization', 'interest', 'journal article', 'language processing', 'novel strategies', 'prototype', 'size', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2008,268713,0.012450428727708275
"Bio Text NLP     DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9477110,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'analytical method', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2018,548298,0.04265979017701559
"Bio Text NLP     DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9442241,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'analytical method', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2017,57870,0.04265979017701559
"Bio Text NLP     DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9266490,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'analytical method', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2017,552544,0.04265979017701559
"Bio Text NLP     DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows. Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,9065611,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Process', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'abstracting', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'meetings', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2016,548438,0.04265979017701559
"Bio Text NLP     DESCRIPTION (provided by applicant):         Since our last renewal, the challenges for biomedical researchers of keeping up with the scientific literature have become even more acute. Last year marked the first time that Medline indexed more than a million journal articles; more than 210,000 of these had full text deposited in PubMedCentral, bringing the total number of full texts archived in PMC to over 3 million. The stunning pleiotropy of genes and their products, combined with the adoption of genome-scale technologies throughout biomedical research, has made obsolete the notion that reading within one's own specialty plus a few ""top"" journals is enough to keep track of all of the results relevan to one's research. Fortunately, advances in biomedical natural language processing and increasing access to digital full text journal publications offer the potential for innovative new approaches to delivering relevant information to working bench scientists.         We hypothesize that realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing Biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.             Project Narrative This project will affect public health by increasing the ability of biologists to investigate hypotheses using the biomedical literature. Realizing the potential of biomedical natural language processing applied to full text journal articles to make a sustained and powerful contribution to biomedical research requires contextualizing biomedical natural language processing in the daily life of bench scientists, focusing on their unmet information gathering needs, and providing interfaces that fit well into existing research workflows.",Bio Text NLP,8819017,R01LM009254,"['Acute', 'Address', 'Adopted', 'Adoption', 'Affect', 'Archives', 'Area', 'Biomedical Research', 'Characteristics', 'Collaborations', 'Complex', 'Data Set', 'Deposition', 'Discipline', 'Ensure', 'Environment', 'Funding', 'Genes', 'Genomics', 'Goals', 'Heart Diseases', 'Histone Code', 'Information Retrieval', 'Journals', 'Life', 'Literature', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Names', 'Natural Language Processing', 'Performance', 'Process', 'Public Health', 'Publications', 'Reading', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Semantics', 'Techniques', 'Technology', 'Text', 'Time', 'To specify', 'United States National Institutes of Health', 'Visual', 'Work', 'abstracting', 'base', 'digital', 'genome-wide', 'improved', 'indexing', 'information gathering', 'innovation', 'interest', 'journal article', 'medical specialties', 'meetings', 'novel', 'novel strategies', 'pleiotropism', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2015,548439,0.04265979017701559
"Beyond Abstracts:  Issues in Mining Full Texts    DESCRIPTION (provided by applicant):     Biomedical language processing, the application of computational techniques to human-generated texts in biomedicine, is an increasingly important enabling technology for basic and applied biomedical research. The exponential growth of the peer-reviewed literature and the breakdown of disciplinary boundaries associated with high-throughput techniques have increased the importance of automated tools for keeping scientists abreast of all of the published material relevant to their work. However, despite decades of research, the performance of state-of-the-art tools for basic language processing tasks like information extraction and document retrieval remain below the level necessary for adequate utility and widespread adoption of this technology. The development, performance and evaluation of text mining systems depend crucially on the availability of appropriate corpora: collections of representative documents that have been annotated with human judgments relevant to a language-processing task. Corpora play two roles in the development of this technology: first, they act as ""gold standards"" by which alternative automated methods can be fairly compared, and second, they provide data for the training of statistical and machine learning systems that create empirical models of patterns in language use. The conventional view is that corpora are neutral, random samples of the domain of interest. Our preliminary work suggests that the restrictions in size, quality, genre, and representational schema of the small number of existing corpora are themselves a critical limiting factor for near-term breakthroughs in biomedical text processing technology. Therefore, we propose to test the following hypothesis: Creation of large, high-quality, biomedical corpora from multiple genres will lead to significant improvements in the performance of biomedical text mining systems and the creation of new approaches to text mining tasks. Specific aims include constructing several large corpora covering a range of genres and incorporating a rich knowledge representation; identifying factors that affect differential performance on full text versus abstracts; and developing new methods for language processing, especially of full text. Because improvements in the ability to automatically extract information from many textual genres will assist scientists and clinicians in the crucial task of keeping up with the burgeoning biomedical literature, the potential public health impact is quite large.          n/a",Beyond Abstracts:  Issues in Mining Full Texts,7287359,R01LM009254,"['Adoption', 'Affect', 'Agreement', 'Arts', 'Biomedical Research', 'Body of uterus', 'Collection', 'Computational Technique', 'Data', 'Development', 'Evaluation', 'Gold', 'Growth', 'Human', 'Judgment', 'Language', 'Lead', 'Literature', 'Machine Learning', 'Memory', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular Biology', 'Numbers', 'Pattern', 'Peer Review', 'Performance', 'Play', 'Process', 'Public Health', 'Publishing', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Retrieval', 'Review Literature', 'Role', 'Sampling', 'Scheme', 'Scientist', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'Work', 'abstracting', 'base', 'concept', 'improved', 'information organization', 'interest', 'journal article', 'language processing', 'novel strategies', 'prototype', 'size', 'technology development', 'text searching', 'tool']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2007,350638,0.012450428727708275
"Beyond Abstracts:  Issues in Mining Full Texts    DESCRIPTION (provided by applicant):     Biomedical language processing, the application of computational techniques to human-generated texts in biomedicine, is an increasingly important enabling technology for basic and applied biomedical research. The exponential growth of the peer-reviewed literature and the breakdown of disciplinary boundaries associated with high-throughput techniques have increased the importance of automated tools for keeping scientists abreast of all of the published material relevant to their work. However, despite decades of research, the performance of state-of-the-art tools for basic language processing tasks like information extraction and document retrieval remain below the level necessary for adequate utility and widespread adoption of this technology. The development, performance and evaluation of text mining systems depend crucially on the availability of appropriate corpora: collections of representative documents that have been annotated with human judgments relevant to a language-processing task. Corpora play two roles in the development of this technology: first, they act as ""gold standards"" by which alternative automated methods can be fairly compared, and second, they provide data for the training of statistical and machine learning systems that create empirical models of patterns in language use. The conventional view is that corpora are neutral, random samples of the domain of interest. Our preliminary work suggests that the restrictions in size, quality, genre, and representational schema of the small number of existing corpora are themselves a critical limiting factor for near-term breakthroughs in biomedical text processing technology. Therefore, we propose to test the following hypothesis: Creation of large, high-quality, biomedical corpora from multiple genres will lead to significant improvements in the performance of biomedical text mining systems and the creation of new approaches to text mining tasks. Specific aims include constructing several large corpora covering a range of genres and incorporating a rich knowledge representation; identifying factors that affect differential performance on full text versus abstracts; and developing new methods for language processing, especially of full text. Because improvements in the ability to automatically extract information from many textual genres will assist scientists and clinicians in the crucial task of keeping up with the burgeoning biomedical literature, the potential public health impact is quite large.          n/a",Beyond Abstracts:  Issues in Mining Full Texts,7135482,R01LM009254,"['abstracting', 'human', 'language', 'performance', 'training']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2006,369593,0.012450428727708275
"Text Mining as a Translational Tool in Biomedicine    DESCRIPTION (provided by applicant):      The candidate's long-term career goal is to become an independent investigator in biomedical informatics, with a specific focus on text mining as a translational tool in biomedical research. The candidate's immediate goals are to strengthen his independent position as a faculty at Yale University, to position biomedical text mining as an essential part of the University's curriculum and to build strong collaboration with scientists in both computational linguistics and basic biomedical research. The candidate career development plan is a logical continuation of his previous work. The proposed project will help to establish the candidate as an independent researcher in the wider biomedical informatics community. The general aim of this proposal is to develop a text mining-based translation informatics tool that helps geneticists in pinpointing likely disease candidate genes from whole genome linkage scans. A collaborative environment here at Yale enables the experimental validation of these findings, and an iterative refinement of analytical methods. While the focus of the project is on genetics, there is a growing demand to analyze and make sense of whole genome high throughput information in various disciplines. The candidate aims at establishing text mining as an important tool for such purposes.          n/a",Text Mining as a Translational Tool in Biomedicine,7483271,K22LM009255,"['Binding', 'Biomedical Research', 'Candidate Disease Gene', 'Collaborations', 'Communities', 'Data', 'Development Plans', 'Discipline', 'Disease', 'Educational Curriculum', 'Environment', 'Faculty', 'Genes', 'Genetic', 'Genetic Research', 'Genome', 'Goals', 'Head', 'Human Genome', 'Informatics', 'Linguistics', 'Maps', 'Methods', 'Molecular', 'Positioning Attribute', 'Process', 'Purpose', 'Research Design', 'Research Personnel', 'Scanning', 'Scientist', 'Translations', 'Universities', 'Validation', 'Work', 'analytical method', 'base', 'biomedical informatics', 'career', 'protein protein interaction', 'text searching', 'tool']",NLM,YALE UNIVERSITY,K22,2008,144819,0.014570827810987739
"Text Mining as a Translational Tool in Biomedicine    DESCRIPTION (provided by applicant):      The candidate's long-term career goal is to become an independent investigator in biomedical informatics, with a specific focus on text mining as a translational tool in biomedical research. The candidate's immediate goals are to strengthen his independent position as a faculty at Yale University, to position biomedical text mining as an essential part of the University's curriculum and to build strong collaboration with scientists in both computational linguistics and basic biomedical research. The candidate career development plan is a logical continuation of his previous work. The proposed project will help to establish the candidate as an independent researcher in the wider biomedical informatics community. The general aim of this proposal is to develop a text mining-based translation informatics tool that helps geneticists in pinpointing likely disease candidate genes from whole genome linkage scans. A collaborative environment here at Yale enables the experimental validation of these findings, and an iterative refinement of analytical methods. While the focus of the project is on genetics, there is a growing demand to analyze and make sense of whole genome high throughput information in various disciplines. The candidate aims at establishing text mining as an important tool for such purposes.          n/a",Text Mining as a Translational Tool in Biomedicine,7290386,K22LM009255,"['Binding', 'Biomedical Research', 'Candidate Disease Gene', 'Collaborations', 'Communities', 'Data', 'Development Plans', 'Discipline', 'Disease', 'Educational Curriculum', 'Environment', 'Faculty', 'Genes', 'Genetic', 'Genetic Research', 'Genome', 'Goals', 'Head', 'Human Genome', 'Informatics', 'Linguistics', 'Maps', 'Methods', 'Molecular', 'Positioning Attribute', 'Process', 'Purpose', 'Research Design', 'Research Personnel', 'Scanning', 'Scientist', 'Translations', 'Universities', 'Validation', 'Work', 'analytical method', 'base', 'biomedical informatics', 'career', 'protein protein interaction', 'text searching', 'tool']",NLM,YALE UNIVERSITY,K22,2007,144819,0.014570827810987739
"Text Mining as a Translational Tool in Biomedicine    DESCRIPTION (provided by applicant):      The candidate's long-term career goal is to become an independent investigator in biomedical informatics, with a specific focus on text mining as a translational tool in biomedical research. The candidate's immediate goals are to strengthen his independent position as a faculty at Yale University, to position biomedical text mining as an essential part of the University's curriculum and to build strong collaboration with scientists in both computational linguistics and basic biomedical research. The candidate career development plan is a logical continuation of his previous work. The proposed project will help to establish the candidate as an independent researcher in the wider biomedical informatics community. The general aim of this proposal is to develop a text mining-based translation informatics tool that helps geneticists in pinpointing likely disease candidate genes from whole genome linkage scans. A collaborative environment here at Yale enables the experimental validation of these findings, and an iterative refinement of analytical methods. While the focus of the project is on genetics, there is a growing demand to analyze and make sense of whole genome high throughput information in various disciplines. The candidate aims at establishing text mining as an important tool for such purposes.          n/a",Text Mining as a Translational Tool in Biomedicine,7133136,K22LM009255,"['career', 'genes', 'genetics', 'genome', 'informatics', 'university']",NLM,YALE UNIVERSITY,K22,2006,150219,0.014570827810987739
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7908086,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,130902,0.05184457487299685
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7660312,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,362514,0.05184457487299685
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7469551,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Condition', 'Constitutional', 'Depth', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Medical Surveillance', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'concept', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2008,392337,0.05184457487299685
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions PROJECT SUMMARY Most U.S. adults (68%) take dietary supplements and there is increasing evidence of drug-supplement interactions (DSIs); In recent years, there has been increasing evidence supporting the role of DSs in ADRD in preventing cognitive impairment but there is limited evidence and the sample sizes have been small. Real- world data (RWD) especially the EHR contain detailed treatment and response information from patients and could be used to detect the usage and effect of DSs, DSIs, which is more translational to clinical outcomes (e.g., MCI to ADRD conversion). To the best of our knowledge, there is no investigation on DSs usage and safety among patients in MCI and ADRD using EHR data. Our current parent award is focusing on the development of a translational informatics framework to enable the discovery of drug-supplement interactions (DSIs) by linking scientific evidence from the biomedical literature. To response to NOT-AG-20-008, this administrative supplement application will complement our parent award in multiple aspects: (1) developing novel and advanced data analytic methods for mining RWD in EHR, (2) identifying DSs usage information among patients with ADRD, and (3) detecting safety and effect of DS among patients with ADRD from existing EHR data. In our preliminary work, we have investigated the methods to identify DSs terms on EHR and developed natural language processing (NLP) methods to identify use status of DSs. We will further our efforts to collect a EHR dataset with DSs usage and AE-DSs signals from AD patients and develop innovative informatics methods to extract such information. Our specific aims are: (1) identifying DSs usage among patients with MCI and ADRD from existing EHR data; and (2) detecting the DSs safety signals and exploring the effect of DSs use on the conversion from MCI to ADRD from existing EHR data. The successful completion of this project will stimulate our further investigation on the role of DS use in patients with ADRD in a larger scale involving EHR data from other healthcare institutions. PROJECT NARRATIVE In this administrative supplement application, we will evaluate the usage and safety of dietary supplements (DSs) usage in patients with Mild Cognitive Impairment (MCI) and Alzheimers disease and related dementias (ADRD), respectively using electronic health records (EHR) data. We will also explore the feasibility of using EHR to detect DS effect on the conversion from MCI to ADRD. This research will address a critical and unmet need to conduct large-scale clinical research in DSs and improve evidence bases for healthcare practice. The successful accomplishment of this supplement project will deliver a novel informatics methods and generate DSI signals among patients with ADRD. This project will stimulate our further investigation on the role of DS use in patients with ADRD in a larger scale involving EHR data from other healthcare institutions.",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,10119590,R01AT009457,"['Address', 'Administrative Supplement', 'Adult', 'Alzheimer&apos', 's disease patient', 'Alzheimer&apos', 's disease related dementia', 'Artificial Intelligence', 'Award', 'Big Data', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Complement', 'Computerized Medical Record', 'Consumption', 'Data', 'Data Analytics', 'Data Set', 'Data Sources', 'Dementia', 'Detection', 'Development', 'Elderly', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Florida', 'Future', 'Genomics', 'Healthcare', 'Healthcare Systems', 'Human', 'Impaired cognition', 'Individual', 'Informatics', 'Institution', 'Intake', 'Investigation', 'Letters', 'Link', 'Literature', 'Methods', 'Mining', 'Natural Language Processing', 'Outcome', 'Parents', 'Patients', 'Pharmaceutical Preparations', 'Records', 'Research', 'Role', 'Safety', 'Sample Size', 'Signal Transduction', 'Surveys', 'Terminology', 'Training', 'Universities', 'Vascular Dementia', 'Work', 'analytical method', 'base', 'cohort', 'deep learning', 'dietary supplements', 'evidence base', 'genomic data', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'novel', 'pharmacovigilance', 'prevent', 'response', 'treatment response']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2020,339298,0.06725019625456115
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions Most U.S. adults (68%) take dietary supplements (DS) and there is increasing evidence of drug-supplement interactions (DSIs); our ability to readily identify interactions between DS with prescription medications is currently very limited. To optimize the safe use of DS, there remains a critical and unmet need for informatics methods to detect DSIs. Our rationale is that an innovative informatics framework to discover potential DSIs from the large scale of biomedical literature will enable a new line of research for targeted DSI validation and will also significantly narrow the range of DSIs that must be further explored. Our long-term goal is to use informatics approaches to enhance DSI clinical research and translate its findings to clinical practice ultimately via clinical decision support systems. The objective of this application is to develop an informatics framework to enable the discovery of DSIs by creating a DS terminology and mining scientific evidence from the biomedical literature. Towards these objectives, we propose the following specific aims: (1) Compile a comprehensive DS terminology using online resources; and (2) Discover potential DSIs from the biomedical literature. The successful accomplishment of this project will deliver a novel informatics paradigm and resources for identifying most clinically significant DSI signals and their biological mechanisms. This information is critical to subsequent efforts aimed at improving patient safety and efficacy of therapeutic interventions. The results from this study are imperative in order to achieve the ultimate goal of reducing an individuals risk of potential DSIs. PROJECT NARRATIVE This research will address a critical and unmet need to conduct large-scale clinical research in drug-supplement interactions (DSIs) and improve evidence bases for healthcare practice. Our primary overarching goal is to use informatics approaches to enhance DSI clinical research and translate our findings to clinical practice ultimately via clinical decision support. The successful accomplishment of this project will deliver a novel informatics paradigm and valuable resources for identifying novel clinically significant DSI signals and their associated scientific evidence.",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,9285168,R01AT009457,"['Address', 'Adult', 'Adverse event', 'Biological', 'Cancer Patient', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Complement', 'Data', 'Data Element', 'Databases', 'Development', 'Drug Targeting', 'Education', 'Effectiveness', 'Electronic Health Record', 'Failure', 'Food', 'Ginkgo biloba', 'Goals', 'Health', 'Healthcare', 'Herbal supplement', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Label', 'Link', 'Literature', 'MEDLINE', 'Machine Learning', 'Medicine', 'Methods', 'Minnesota', 'Natural Language Processing', 'Natural Products', 'Outcome', 'Pathway interactions', 'Patient risk', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Postoperative Hemorrhage', 'Probability', 'Research', 'Resources', 'Risk', 'Safety', 'Semantics', 'Signal Transduction', 'Standardization', 'Structure', 'Surveys', 'System', 'Targeted Research', 'Terminology', 'Therapeutic', 'Translating', 'Treatment Efficacy', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Warfarin', 'Work', 'base', 'clinical practice', 'clinically significant', 'colon cancer patients', 'data modeling', 'design', 'dietary supplements', 'drug testing', 'evidence base', 'improved', 'individual patient', 'innovation', 'learning strategy', 'novel', 'nutrition', 'online resource', 'open source', 'patient population', 'patient safety', 'post-market', 'screening', 'tool']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2017,267313,0.015380134437309768
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions Most U.S. adults (68%) take dietary supplements (DS) and there is increasing evidence of drug-supplement interactions (DSIs); our ability to readily identify interactions between DS with prescription medications is currently very limited. To optimize the safe use of DS, there remains a critical and unmet need for informatics methods to detect DSIs. Our rationale is that an innovative informatics framework to discover potential DSIs from the large scale of biomedical literature will enable a new line of research for targeted DSI validation and will also significantly narrow the range of DSIs that must be further explored. Our long-term goal is to use informatics approaches to enhance DSI clinical research and translate its findings to clinical practice ultimately via clinical decision support systems. The objective of this application is to develop an informatics framework to enable the discovery of DSIs by creating a DS terminology and mining scientific evidence from the biomedical literature. Towards these objectives, we propose the following specific aims: (1) Compile a comprehensive DS terminology using online resources; and (2) Discover potential DSIs from the biomedical literature. The successful accomplishment of this project will deliver a novel informatics paradigm and resources for identifying most clinically significant DSI signals and their biological mechanisms. This information is critical to subsequent efforts aimed at improving patient safety and efficacy of therapeutic interventions. The results from this study are imperative in order to achieve the ultimate goal of reducing an individuals risk of potential DSIs. PROJECT NARRATIVE This research will address a critical and unmet need to conduct large-scale clinical research in drug-supplement interactions (DSIs) and improve evidence bases for healthcare practice. Our primary overarching goal is to use informatics approaches to enhance DSI clinical research and translate our findings to clinical practice ultimately via clinical decision support. The successful accomplishment of this project will deliver a novel informatics paradigm and valuable resources for identifying novel clinically significant DSI signals and their associated scientific evidence.",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,9453640,R01AT009457,"['Address', 'Adult', 'Adverse event', 'Biological', 'Cancer Patient', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Complement', 'Data', 'Data Element', 'Databases', 'Development', 'Drug Targeting', 'Education', 'Effectiveness', 'Electronic Health Record', 'Failure', 'Food', 'Ginkgo biloba', 'Goals', 'Health', 'Healthcare', 'Herbal supplement', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Label', 'Link', 'Literature', 'MEDLINE', 'Machine Learning', 'Medicine', 'Methods', 'Minnesota', 'Natural Language Processing', 'Natural Products', 'Outcome', 'Pathway interactions', 'Patient risk', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Postoperative Hemorrhage', 'Probability', 'Research', 'Resources', 'Risk', 'Safety', 'Semantics', 'Signal Transduction', 'Standardization', 'Structure', 'Surveys', 'System', 'Targeted Research', 'Terminology', 'Therapeutic', 'Therapeutic Intervention', 'Translating', 'Treatment Efficacy', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Warfarin', 'Work', 'base', 'clinical decision support', 'clinical practice', 'clinically significant', 'colon cancer patients', 'data modeling', 'design', 'dietary supplements', 'drug testing', 'evidence base', 'improved', 'individual patient', 'innovation', 'learning strategy', 'novel', 'nutrition', 'online resource', 'open source', 'patient population', 'patient safety', 'post-market', 'screening', 'tool']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2018,305500,0.015380134437309768
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions Most U.S. adults (68%) take dietary supplements (DS) and there is increasing evidence of drug-supplement interactions (DSIs); our ability to readily identify interactions between DS with prescription medications is currently very limited. To optimize the safe use of DS, there remains a critical and unmet need for informatics methods to detect DSIs. Our rationale is that an innovative informatics framework to discover potential DSIs from the large scale of biomedical literature will enable a new line of research for targeted DSI validation and will also significantly narrow the range of DSIs that must be further explored. Our long-term goal is to use informatics approaches to enhance DSI clinical research and translate its findings to clinical practice ultimately via clinical decision support systems. The objective of this application is to develop an informatics framework to enable the discovery of DSIs by creating a DS terminology and mining scientific evidence from the biomedical literature. Towards these objectives, we propose the following specific aims: (1) Compile a comprehensive DS terminology using online resources; and (2) Discover potential DSIs from the biomedical literature. The successful accomplishment of this project will deliver a novel informatics paradigm and resources for identifying most clinically significant DSI signals and their biological mechanisms. This information is critical to subsequent efforts aimed at improving patient safety and efficacy of therapeutic interventions. The results from this study are imperative in order to achieve the ultimate goal of reducing an individuals risk of potential DSIs. PROJECT NARRATIVE This research will address a critical and unmet need to conduct large-scale clinical research in drug-supplement interactions (DSIs) and improve evidence bases for healthcare practice. Our primary overarching goal is to use informatics approaches to enhance DSI clinical research and translate our findings to clinical practice ultimately via clinical decision support. The successful accomplishment of this project will deliver a novel informatics paradigm and valuable resources for identifying novel clinically significant DSI signals and their associated scientific evidence.",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,9894759,R01AT009457,"['Address', 'Adult', 'Adverse event', 'Biological', 'Cancer Patient', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Complement', 'Data', 'Data Element', 'Databases', 'Development', 'Drug Targeting', 'Education', 'Effectiveness', 'Electronic Health Record', 'Failure', 'Food', 'Ginkgo biloba', 'Goals', 'Health', 'Healthcare', 'Herbal supplement', 'Individual', 'Informatics', 'Information Retrieval', 'Investigation', 'Knowledge', 'Label', 'Link', 'Literature', 'MEDLINE', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Natural Products', 'Outcome', 'Pathway interactions', 'Patient risk', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Postoperative Hemorrhage', 'Probability', 'Research', 'Resources', 'Risk', 'Safety', 'Semantics', 'Signal Transduction', 'Standardization', 'Surveys', 'System', 'Targeted Research', 'Terminology', 'Therapeutic', 'Therapeutic Intervention', 'Translating', 'Treatment Efficacy', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Warfarin', 'Work', 'base', 'clinical decision support', 'clinical practice', 'clinically significant', 'colon cancer patients', 'data modeling', 'design', 'dietary supplements', 'drug testing', 'evidence base', 'improved', 'individual patient', 'innovation', 'machine learning method', 'novel', 'nutrition', 'online resource', 'open source', 'patient population', 'patient safety', 'post-market', 'screening', 'structured data', 'tool', 'unstructured data']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2020,269500,0.015380134437309768
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions Most U.S. adults (68%) take dietary supplements (DS) and there is increasing evidence of drug-supplement interactions (DSIs); our ability to readily identify interactions between DS with prescription medications is currently very limited. To optimize the safe use of DS, there remains a critical and unmet need for informatics methods to detect DSIs. Our rationale is that an innovative informatics framework to discover potential DSIs from the large scale of biomedical literature will enable a new line of research for targeted DSI validation and will also significantly narrow the range of DSIs that must be further explored. Our long-term goal is to use informatics approaches to enhance DSI clinical research and translate its findings to clinical practice ultimately via clinical decision support systems. The objective of this application is to develop an informatics framework to enable the discovery of DSIs by creating a DS terminology and mining scientific evidence from the biomedical literature. Towards these objectives, we propose the following specific aims: (1) Compile a comprehensive DS terminology using online resources; and (2) Discover potential DSIs from the biomedical literature. The successful accomplishment of this project will deliver a novel informatics paradigm and resources for identifying most clinically significant DSI signals and their biological mechanisms. This information is critical to subsequent efforts aimed at improving patient safety and efficacy of therapeutic interventions. The results from this study are imperative in order to achieve the ultimate goal of reducing an individuals risk of potential DSIs. PROJECT NARRATIVE This research will address a critical and unmet need to conduct large-scale clinical research in drug-supplement interactions (DSIs) and improve evidence bases for healthcare practice. Our primary overarching goal is to use informatics approaches to enhance DSI clinical research and translate our findings to clinical practice ultimately via clinical decision support. The successful accomplishment of this project will deliver a novel informatics paradigm and valuable resources for identifying novel clinically significant DSI signals and their associated scientific evidence.",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,9676043,R01AT009457,"['Address', 'Adult', 'Adverse event', 'Biological', 'Cancer Patient', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Complement', 'Data', 'Data Element', 'Databases', 'Development', 'Drug Targeting', 'Education', 'Effectiveness', 'Electronic Health Record', 'Failure', 'Food', 'Ginkgo biloba', 'Goals', 'Health', 'Healthcare', 'Herbal supplement', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Label', 'Link', 'Literature', 'MEDLINE', 'Machine Learning', 'Medicine', 'Methods', 'Minnesota', 'Natural Language Processing', 'Natural Products', 'Outcome', 'Pathway interactions', 'Patient risk', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Postoperative Hemorrhage', 'Probability', 'Research', 'Resources', 'Risk', 'Safety', 'Semantics', 'Signal Transduction', 'Standardization', 'Structure', 'Surveys', 'System', 'Targeted Research', 'Terminology', 'Therapeutic', 'Therapeutic Intervention', 'Translating', 'Treatment Efficacy', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Warfarin', 'Work', 'base', 'clinical decision support', 'clinical practice', 'clinically significant', 'colon cancer patients', 'data modeling', 'design', 'dietary supplements', 'drug testing', 'evidence base', 'improved', 'individual patient', 'innovation', 'learning strategy', 'novel', 'nutrition', 'online resource', 'open source', 'patient population', 'patient safety', 'post-market', 'screening', 'tool']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2019,308000,0.015380134437309768
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions Most U.S. adults (68%) take dietary supplements (DS) and there is increasing evidence of drug-supplement interactions (DSIs); our ability to readily identify interactions between DS with prescription medications is currently very limited. To optimize the safe use of DS, there remains a critical and unmet need for informatics methods to detect DSIs. Our rationale is that an innovative informatics framework to discover potential DSIs from the large scale of biomedical literature will enable a new line of research for targeted DSI validation and will also significantly narrow the range of DSIs that must be further explored. Our long-term goal is to use informatics approaches to enhance DSI clinical research and translate its findings to clinical practice ultimately via clinical decision support systems. The objective of this application is to develop an informatics framework to enable the discovery of DSIs by creating a DS terminology and mining scientific evidence from the biomedical literature. Towards these objectives, we propose the following specific aims: (1) Compile a comprehensive DS terminology using online resources; and (2) Discover potential DSIs from the biomedical literature. The successful accomplishment of this project will deliver a novel informatics paradigm and resources for identifying most clinically significant DSI signals and their biological mechanisms. This information is critical to subsequent efforts aimed at improving patient safety and efficacy of therapeutic interventions. The results from this study are imperative in order to achieve the ultimate goal of reducing an individuals risk of potential DSIs. n/a",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,9882672,R01AT009457,"['Address', 'Adult', 'Adverse event', 'Biological', 'Cancer Patient', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Complement', 'Data', 'Data Element', 'Databases', 'Development', 'Drug Targeting', 'Education', 'Effectiveness', 'Electronic Health Record', 'Failure', 'Food', 'Ginkgo biloba', 'Goals', 'Health', 'Healthcare', 'Herbal supplement', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Label', 'Link', 'Literature', 'MEDLINE', 'Machine Learning', 'Medicine', 'Methods', 'Minnesota', 'Natural Language Processing', 'Natural Products', 'Outcome', 'Pathway interactions', 'Patient risk', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Postoperative Hemorrhage', 'Probability', 'Research', 'Resources', 'Risk', 'Safety', 'Semantics', 'Signal Transduction', 'Standardization', 'Structure', 'Surveys', 'System', 'Targeted Research', 'Terminology', 'Therapeutic', 'Therapeutic Intervention', 'Translating', 'Treatment Efficacy', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Warfarin', 'Work', 'base', 'clinical decision support', 'clinical practice', 'clinically significant', 'colon cancer patients', 'data modeling', 'design', 'dietary supplements', 'drug testing', 'evidence base', 'improved', 'individual patient', 'innovation', 'learning strategy', 'novel', 'nutrition', 'online resource', 'open source', 'patient population', 'patient safety', 'post-market', 'screening', 'tool']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2019,149810,0.006521991818899883
"Evaluation of the Impact of Health Information Exchange on Emergency Medicine    DESCRIPTION (provided by applicant):       Computer-based health information exchange (HIE) projects are being developed throughout the country to improve the safety, quality and efficiency with which health care is delivered, and to create the building blocks of a nationwide health information network (NHIN) as called for by President George W. Bush and the Department of Health and Human Services. Although it is expected that the electronic exchange of clinical data among disparate providers will improve clinical care, there are few direct data showing its utility. The project described here seeks to evaluate the impact of an HIE project on the quality, safety and cost of clinical care provided in New York metropolitan area. An evaluation showing the benefits of HIE in this diverse and densely populated region would be a significant step toward building a body of knowledge that discusses and supports the use of HIE.      The specific hypothesis behind the proposed evaluation plan is that the implementation of a computerbased HIE network in the New York metropolitan area will improve the quality and safety and decrease the cost of health care delivery, while being met with a high degree of provider satisfaction. This hypothesis is based on the following observations. First, information gaps exist for clinicians at the bedside that likely lead to errors and a reduction in the quality and safety of the health care they deliver, and these gaps would be significantly improved by HIE. Second, in limited instances access to clinical data through HIE has been shown to increase efficiency and save money, and is projected to save billions of dollars annually if implemented nationwide. Third, there is a perceived need among emergency physicians in the New York metropolitan area for computer-based HIE and therefore an implementation in this region is likely to elicit a high degree of user satisfaction.      The specific aims of this study are to:      1. Evaluate the impact on quality and safety of an HIE application implemented in ten emergency departments in the New York metropolitan area.      2. Evaluate the return on investment for an HIE application implemented in ten emergency departments in the New York metropolitan area from the perspectives of both providers and payers.      3. Evaluate provider satisfaction with the HIE application in ten emergency departments in the New York metropolitan area.             n/a",Evaluation of the Impact of Health Information Exchange on Emergency Medicine,7469568,K99LM009556,"['Abbreviations', 'Accident and Emergency department', 'Adverse event', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Computers', 'Country', 'Data', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Evaluation', 'Event', 'Health', 'Health Benefit', 'Health Care Costs', 'Healthcare', 'Hospitals', 'Impact evaluation', 'Information Networks', 'Information Technology', 'Institute of Medicine (U.S.)', 'Investments', 'Knowledge', 'Lead', 'New York', 'Pharmaceutical Preparations', 'Physicians', 'Presbyterian Church', 'Provider', 'Research Personnel', 'Safety', 'United States Dept. of Health and Human Services', 'Universities', 'base', 'biomedical informatics', 'cost', 'health care delivery', 'improved', 'information organization', 'metropolitan', 'programs', 'satisfaction']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2008,134152,0.03273555900771864
"Evaluation of the Impact of Health Information Exchange on Emergency Medicine    DESCRIPTION (provided by applicant):       Computer-based health information exchange (HIE) projects are being developed throughout the country to improve the safety, quality and efficiency with which health care is delivered, and to create the building blocks of a nationwide health information network (NHIN) as called for by President George W. Bush and the Department of Health and Human Services. Although it is expected that the electronic exchange of clinical data among disparate providers will improve clinical care, there are few direct data showing its utility. The project described here seeks to evaluate the impact of an HIE project on the quality, safety and cost of clinical care provided in New York metropolitan area. An evaluation showing the benefits of HIE in this diverse and densely populated region would be a significant step toward building a body of knowledge that discusses and supports the use of HIE.      The specific hypothesis behind the proposed evaluation plan is that the implementation of a computerbased HIE network in the New York metropolitan area will improve the quality and safety and decrease the cost of health care delivery, while being met with a high degree of provider satisfaction. This hypothesis is based on the following observations. First, information gaps exist for clinicians at the bedside that likely lead to errors and a reduction in the quality and safety of the health care they deliver, and these gaps would be significantly improved by HIE. Second, in limited instances access to clinical data through HIE has been shown to increase efficiency and save money, and is projected to save billions of dollars annually if implemented nationwide. Third, there is a perceived need among emergency physicians in the New York metropolitan area for computer-based HIE and therefore an implementation in this region is likely to elicit a high degree of user satisfaction.      The specific aims of this study are to:      1. Evaluate the impact on quality and safety of an HIE application implemented in ten emergency departments in the New York metropolitan area.      2. Evaluate the return on investment for an HIE application implemented in ten emergency departments in the New York metropolitan area from the perspectives of both providers and payers.      3. Evaluate provider satisfaction with the HIE application in ten emergency departments in the New York metropolitan area.             n/a",Evaluation of the Impact of Health Information Exchange on Emergency Medicine,7250442,K99LM009556,"['Abbreviations', 'Accident and Emergency department', 'Adverse event', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Computers', 'Country', 'Data', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Evaluation', 'Event', 'Health', 'Health Benefit', 'Health Care Costs', 'Healthcare', 'Hospitals', 'Impact evaluation', 'Information Networks', 'Information Technology', 'Institute of Medicine (U.S.)', 'Investments', 'Knowledge', 'Lead', 'New York', 'Pharmaceutical Preparations', 'Physicians', 'Presbyterian Church', 'Provider', 'Research Personnel', 'Safety', 'United States Dept. of Health and Human Services', 'Universities', 'base', 'biomedical informatics', 'cost', 'health care delivery', 'improved', 'information organization', 'metropolitan', 'programs', 'satisfaction']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2007,132673,0.03273555900771864
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7579478,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computational Technique', 'Computerized Medical Record', 'Count', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Medical Surveillance', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'Numbers', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Pliability', 'Population', 'Positioning Attribute', 'Practice based research', 'Primary Health Care', 'Procedures', 'Process', 'Purpose', 'Range', 'Reaction', 'Records', 'Reference Standards', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Role', 'Safety', 'Score', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'concept', 'data mining', 'design', 'experience', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2008,299619,0.061867979803165996
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7691699,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,311821,0.061867979803165996
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7908950,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,17240,0.061867979803165996
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7942766,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2010,320155,0.061867979803165996
"Temporal Processing for Medical Discharge Summaries    DESCRIPTION (provided by applicant):       The goals of our project are as follows:     1. Create a corpus of temporally annotated data. Under the supervision of our consultants Dr. Frank Sacks, Dr. Vincent Carey, and two Registered Nurses, we will create a gold-standard annotation of events and temporal information within patient narratives from de- identified Electronic Health Record data using the CLEF and TimeML guidelines. We will use the framework of the Brandeis Annotation Tool, a system we have designed to facilitate the quick construction of accurately annotated corpora against a specified guideline. Extensions to the current event library and lexicon with medical event references will be made during the annotation process, under the guidance of the Registered Nurses.          2. Adapt the TARSQI Toolkit (TTK) to targeted temporal properties and relations in the EHR domain. We will use the TARSQI toolkit, a robust set of temporal processing algorithms we have designed for parsing natural language text, to automatically annotate the events and temporal information in EHR data. Combined with the Brandeis AcroMed Medical Abbreviation Server and those terms introduced in part 1, we will employ the Specialist Lexicon and other medical resources to extend the toolkit capabilities for recognizing and interpreting medical event information. Algorithms for identifying events, temporal expressions, and event anchorings and orderings will be trained against the gold standard created in Aim 1, and tested against held-out data.     3. Create a cross-document temporal database of medical events. Using the recognition algorithms introduced in Aim 2, we will create a searchable, temporally ordered database of medical events such as diseases, symptoms, surgeries/interventions, and test results. Events referred to multiple times in the data will be merged using a constraint- satisfaction analysis in order to create a more coherent narrative for a single patient over multiple records.           Project Narrative It is becoming increasingly common for medical researchers to use Electronic Health Records (EHRs) as a primary source of data for researching correlations between various medical issues and concepts. However, EHRs typically contain unstructured text, making them difficult to mine. This research will create a database of temporal orderings from events extracted from EHR patient narratives, using algorithms previously applied to news articles.",Temporal Processing for Medical Discharge Summaries,7941063,R21LM009633,"['Abbreviations', 'Adopted', 'Algorithms', 'Authorization documentation', 'Clinical', 'Clinical Research', 'Data', 'Data Sources', 'Databases', 'Diagnosis', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Event', 'Goals', 'Gold', 'Guidelines', 'Intervention', 'Language', 'Libraries', 'Licensing', 'Machine Learning', 'Medical', 'Medical History', 'Medical Libraries', 'Mining', 'Operative Surgical Procedures', 'Patients', 'Process', 'Property', 'Records', 'Registered nurse', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Science', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Supervision', 'Symptoms', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Vocabulary', 'acronyms', 'base', 'design', 'evidence base', 'experience', 'interest', 'lexical', 'natural language', 'news', 'open source', 'relational database', 'repository', 'satisfaction', 'tool']",NLM,BRANDEIS UNIVERSITY,R21,2010,175973,0.04282870660983209
"Temporal Processing for Medical Discharge Summaries    DESCRIPTION (provided by applicant):       The goals of our project are as follows:     1. Create a corpus of temporally annotated data. Under the supervision of our consultants Dr. Frank Sacks, Dr. Vincent Carey, and two Registered Nurses, we will create a gold-standard annotation of events and temporal information within patient narratives from de- identified Electronic Health Record data using the CLEF and TimeML guidelines. We will use the framework of the Brandeis Annotation Tool, a system we have designed to facilitate the quick construction of accurately annotated corpora against a specified guideline. Extensions to the current event library and lexicon with medical event references will be made during the annotation process, under the guidance of the Registered Nurses.          2. Adapt the TARSQI Toolkit (TTK) to targeted temporal properties and relations in the EHR domain. We will use the TARSQI toolkit, a robust set of temporal processing algorithms we have designed for parsing natural language text, to automatically annotate the events and temporal information in EHR data. Combined with the Brandeis AcroMed Medical Abbreviation Server and those terms introduced in part 1, we will employ the Specialist Lexicon and other medical resources to extend the toolkit capabilities for recognizing and interpreting medical event information. Algorithms for identifying events, temporal expressions, and event anchorings and orderings will be trained against the gold standard created in Aim 1, and tested against held-out data.     3. Create a cross-document temporal database of medical events. Using the recognition algorithms introduced in Aim 2, we will create a searchable, temporally ordered database of medical events such as diseases, symptoms, surgeries/interventions, and test results. Events referred to multiple times in the data will be merged using a constraint- satisfaction analysis in order to create a more coherent narrative for a single patient over multiple records.           Project Narrative It is becoming increasingly common for medical researchers to use Electronic Health Records (EHRs) as a primary source of data for researching correlations between various medical issues and concepts. However, EHRs typically contain unstructured text, making them difficult to mine. This research will create a database of temporal orderings from events extracted from EHR patient narratives, using algorithms previously applied to news articles.",Temporal Processing for Medical Discharge Summaries,7789943,R21LM009633,"['Abbreviations', 'Adopted', 'Algorithms', 'Authorization documentation', 'Body of uterus', 'Clinical', 'Clinical Research', 'Data', 'Data Sources', 'Databases', 'Diagnosis', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Event', 'Goals', 'Gold', 'Guidelines', 'Information Resources', 'Intervention', 'Language', 'Libraries', 'Licensing', 'Machine Learning', 'Medical', 'Medical History', 'Medical Libraries', 'Mining', 'Operative Surgical Procedures', 'Patients', 'Process', 'Property', 'Records', 'Registered nurse', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Science', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Supervision', 'Symptoms', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Vocabulary', 'acronyms', 'base', 'design', 'evidence base', 'experience', 'interest', 'lexical', 'natural language', 'news', 'open source', 'repository', 'satisfaction', 'tool']",NLM,BRANDEIS UNIVERSITY,R21,2009,177750,0.04282870660983209
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9920181,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Comparative Effectiveness Research', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'computer science', 'data sharing', 'design', 'digital', 'diverse data', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'machine learning algorithm', 'machine learning method', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2020,249000,0.016694533092391172
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9857305,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'comparative effectiveness', 'computer science', 'data sharing', 'design', 'digital', 'effectiveness research', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2019,249000,0.016694533092391172
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9549126,K99HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'comparative effectiveness', 'computer science', 'data sharing', 'design', 'digital', 'effectiveness research', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'learning strategy', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy protection', 'programs', 'public trust', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2018,81977,0.016694533092391172
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9371707,K99HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Databases', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'comparative effectiveness', 'computer science', 'data sharing', 'design', 'digital', 'effectiveness research', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'learning strategy', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'permissiveness', 'point of care', 'predictive modeling', 'privacy protection', 'programs', 'public trust', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2017,93824,0.016694533092391172
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7691692,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development', 'web site']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2009,177750,0.06838187505835093
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7850343,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development', 'web site']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2009,99971,0.06838187505835093
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7529967,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Numbers', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Purpose', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Standards of Weights and Measures', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'concept', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2008,213300,0.06838187505835093
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,8144459,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2011,147161,0.05704152442424193
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7921455,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2010,148350,0.05704152442424193
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7693117,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2009,145926,0.05704152442424193
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7690941,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'clinical practice', 'design', 'foot', 'journal article', 'language processing', 'meetings', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2009,351549,0.016270380991831278
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7908952,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'clinical practice', 'design', 'foot', 'journal article', 'language processing', 'meetings', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2009,170662,0.016270380991831278
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7502749,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Numbers', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'design', 'foot', 'journal article', 'language processing', 'mecarzole', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2008,352226,0.016270380991831278
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7380099,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Numbers', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'design', 'foot', 'journal article', 'language processing', 'mecarzole', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2007,383550,0.016270380991831278
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data DESCRIPTION (provided by applicant):         Averaging about $1,000 per patient1, recruitment remains an expensive bottleneck for human studies. The rapidly increasing adoption of electronic health records (EHR) has made electronic prescreening (E-screening hereafter) a practicable solution to this bottleneck. Our long-term goal is to achieve this ""holy grail"". Our short- term goal of this competing continuation is to develop an intelligent patient query consultant to improve the accuracy and efficiency of E-screening.             One of the difficulties for E-screening is the semantic gap between eligibility criteria and clinical data.2 Each eligibility criterion (e.g., hypertension) describes a patient characteristic, which is correlated with multiple data features (e.g., orders of hypertension drugs, elevated blood pressure, and symptoms of hypertension) in EHR. Moreover, each data feature may have multiple semantic representations (e.g., ""SBP"", ""BP"", or ""blood pressure"") from disparate data sources. For example, elevated systolic blood pressure can be recorded in varying formats in an emergency room, a doctor's office, an ICU, and an in-patient unit, but not all of these readings necessarily indicate chronic hypertension.             The use of clinical data to identify patients eligible for clinical research requires specialized knowledge and expert guidance to navigate the vast space of data features and intelligent inferences from data features for eligibility determination. A user must understand the characteristics of available data before using them to search for patients. For example, when only 5% of hypertensive patients have ICD-9 codes for hypertension but 73% of these patients have hypertension drug orders, using drug information to construct a query of hypertensive patients will be more effective than one using ICD-9 codes. Even sophisticated biomedical data query tools such as i2b2, VISAGE, and STRIDE only passively translate user-specified data features into a query statement. They do not guide a researcher in selecting a data feature and its most appropriate semantic representations or data sources. Little aid is available to inform researchers about data characteristics or to help them conduct exploratory data analyses for optimal data feature selection.     Mixed-initiative interaction,3 which allows human and computer to collaboratively contribute to converged problem solutions, can potentially fulfill this need. We hypothesize that by equipping biomedical researchers with a knowledge-based, mixed-initiative dialog system, we can maximize the efficiency and accuracy of E- screening by supporting exploratory analyses of correlated data features for query optimization. Our approach is innovative because it (1) addresses the user needs for intelligent query interfaces for clinical data, (2) provides a novel data-driven approach to eligibility determination based on correlated data features, and (3) enables efficient query optimization through support of human-computer collaborative problem solving.      We will build on the results from our first funding period for bridging the semantic gap.4-21 We developed an analysis pipeline called EliXR to construct a semantic knowledge representation for eligibility criteria 6,9,16,17, which can be used to transform free-text eligibility criteria ito structured narrative.6 We developed methods to dynamically categorize eligibility criteria by data type.8 We accumulated E-screening experience from three NIH-sponsored clinical trials.7,13,21 We developed a method combining PubMed knowledge and EHR data to infer patient phenotype4 and reconciled structured and unstructured clinical data to support E-screening.18 We are prepared with methods and a preliminary understanding of the building blocks necessary to optimally translate eligibility criteria into data features; therefore, our current proposal is the logical next step.                        Our specific aims are to:     1.	Use mixed methods to understand the needs of biomedical researchers for query clarification and identify common strategies used by query analysts for plan optimization for complex eligibility queries.     2.	Develop a knowledge-based, mixed-initiative dialog system to improve human-computer collaboration for query formulation using participatory design methods.     3.	Evaluate the efficacy and usability of the mixed-initiative dialog system using a research data warehouse and two use cases: research protocol feasibility testing and trial recruitment prescreening.                        We will advance the field by contributing knowledge of the needs for query support among biomedical researchers and an effective E-screening method that combines intelligent query recommendation and iterative query by review22 to improve data access for researchers through human-computer collaboration. Project Narrative  This project addresses the needs of clinician scientists to understand data characteristics when using clinical data to search for potentially eligible clinical research participants. It will develop a novel intelligent query consultant to guide clinicians in interrogating clinical databases. This project has the potential to improve the efficiency and accuracy and reduce cost of patient prescreening for clinical and translational research.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8884643,R01LM009886,"['Accident and Emergency department', 'Address', 'Adoption', 'Blood Pressure', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collaborations', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Drug Formulations', 'Drug usage', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Funding', 'Goals', 'Human', 'Hypertension', 'ICD-9', 'Knowledge', 'Methods', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Problem Solving', 'Protocols documentation', 'PubMed', 'Reading', 'Recommendation', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Solutions', 'Specific qualifier value', 'Structure', 'Symptoms', 'System', 'Testing', 'Text', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'base', 'cost', 'data space', 'design', 'experience', 'improved', 'information organization', 'innovation', 'knowledge base', 'novel', 'query optimization', 'screening', 'tool', 'usability']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2015,345750,0.03819385166858095
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data     DESCRIPTION (provided by applicant):         Averaging about $1,000 per patient1, recruitment remains an expensive bottleneck for human studies. The rapidly increasing adoption of electronic health records (EHR) has made electronic prescreening (E-screening hereafter) a practicable solution to this bottleneck. Our long-term goal is to achieve this ""holy grail"". Our short- term goal of this competing continuation is to develop an intelligent patient query consultant to improve the accuracy and efficiency of E-screening.             One of the difficulties for E-screening is the semantic gap between eligibility criteria and clinical data.2 Each eligibility criterion (e.g., hypertension) describes a patient characteristic, which is correlated with multiple data features (e.g., orders of hypertension drugs, elevated blood pressure, and symptoms of hypertension) in EHR. Moreover, each data feature may have multiple semantic representations (e.g., ""SBP"", ""BP"", or ""blood pressure"") from disparate data sources. For example, elevated systolic blood pressure can be recorded in varying formats in an emergency room, a doctor's office, an ICU, and an in-patient unit, but not all of these readings necessarily indicate chronic hypertension.             The use of clinical data to identify patients eligible for clinical research requires specialized knowledge and expert guidance to navigate the vast space of data features and intelligent inferences from data features for eligibility determination. A user must understand the characteristics of available data before using them to search for patients. For example, when only 5% of hypertensive patients have ICD-9 codes for hypertension but 73% of these patients have hypertension drug orders, using drug information to construct a query of hypertensive patients will be more effective than one using ICD-9 codes. Even sophisticated biomedical data query tools such as i2b2, VISAGE, and STRIDE only passively translate user-specified data features into a query statement. They do not guide a researcher in selecting a data feature and its most appropriate semantic representations or data sources. Little aid is available to inform researchers about data characteristics or to help them conduct exploratory data analyses for optimal data feature selection.     Mixed-initiative interaction,3 which allows human and computer to collaboratively contribute to converged problem solutions, can potentially fulfill this need. We hypothesize that by equipping biomedical researchers with a knowledge-based, mixed-initiative dialog system, we can maximize the efficiency and accuracy of E- screening by supporting exploratory analyses of correlated data features for query optimization. Our approach is innovative because it (1) addresses the user needs for intelligent query interfaces for clinical data, (2) provides a novel data-driven approach to eligibility determination based on correlated data features, and (3) enables efficient query optimization through support of human-computer collaborative problem solving.      We will build on the results from our first funding period for bridging the semantic gap.4-21 We developed an analysis pipeline called EliXR to construct a semantic knowledge representation for eligibility criteria 6,9,16,17, which can be used to transform free-text eligibility criteria ito structured narrative.6 We developed methods to dynamically categorize eligibility criteria by data type.8 We accumulated E-screening experience from three NIH-sponsored clinical trials.7,13,21 We developed a method combining PubMed knowledge and EHR data to infer patient phenotype4 and reconciled structured and unstructured clinical data to support E-screening.18 We are prepared with methods and a preliminary understanding of the building blocks necessary to optimally translate eligibility criteria into data features; therefore, our current proposal is the logical next step.                        Our specific aims are to:     1.	Use mixed methods to understand the needs of biomedical researchers for query clarification and identify common strategies used by query analysts for plan optimization for complex eligibility queries.     2.	Develop a knowledge-based, mixed-initiative dialog system to improve human-computer collaboration for query formulation using participatory design methods.     3.	Evaluate the efficacy and usability of the mixed-initiative dialog system using a research data warehouse and two use cases: research protocol feasibility testing and trial recruitment prescreening.                        We will advance the field by contributing knowledge of the needs for query support among biomedical researchers and an effective E-screening method that combines intelligent query recommendation and iterative query by review22 to improve data access for researchers through human-computer collaboration.              Project Narrative  This project addresses the needs of clinician scientists to understand data characteristics when using clinical data to search for potentially eligible clinical research participants. It will develop a novel intelligent query consultant to guide clinicians in interrogating clinical databases. This project has the potential to improve the efficiency and accuracy and reduce cost of patient prescreening for clinical and translational research.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8695478,R01LM009886,"['Accident and Emergency department', 'Address', 'Adoption', 'Blood Pressure', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collaborations', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Drug Formulations', 'Drug usage', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Funding', 'Goals', 'Human', 'Hypertension', 'ICD-9', 'Knowledge', 'Methods', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Problem Solving', 'Protocols documentation', 'PubMed', 'Reading', 'Recommendation', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Solutions', 'Specific qualifier value', 'Structure', 'Symptoms', 'System', 'Testing', 'Text', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'base', 'cost', 'data space', 'design', 'experience', 'improved', 'information organization', 'innovation', 'knowledge base', 'novel', 'screening', 'tool', 'usability']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2014,381171,0.03819385166858095
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data     DESCRIPTION (provided by applicant):         Averaging about $1,000 per patient1, recruitment remains an expensive bottleneck for human studies. The rapidly increasing adoption of electronic health records (EHR) has made electronic prescreening (E-screening hereafter) a practicable solution to this bottleneck. Our long-term goal is to achieve this ""holy grail"". Our short- term goal of this competing continuation is to develop an intelligent patient query consultant to improve the accuracy and efficiency of E-screening.             One of the difficulties for E-screening is the semantic gap between eligibility criteria and clinical data.2 Each eligibility criterion (e.g., hypertension) describes a patient characteristic, which is correlated with multiple data features (e.g., orders of hypertension drugs, elevated blood pressure, and symptoms of hypertension) in EHR. Moreover, each data feature may have multiple semantic representations (e.g., ""SBP"", ""BP"", or ""blood pressure"") from disparate data sources. For example, elevated systolic blood pressure can be recorded in varying formats in an emergency room, a doctor's office, an ICU, and an in-patient unit, but not all of these readings necessarily indicate chronic hypertension.             The use of clinical data to identify patients eligible for clinical research requires specialized knowledge and expert guidance to navigate the vast space of data features and intelligent inferences from data features for eligibility determination. A user must understand the characteristics of available data before using them to search for patients. For example, when only 5% of hypertensive patients have ICD-9 codes for hypertension but 73% of these patients have hypertension drug orders, using drug information to construct a query of hypertensive patients will be more effective than one using ICD-9 codes. Even sophisticated biomedical data query tools such as i2b2, VISAGE, and STRIDE only passively translate user-specified data features into a query statement. They do not guide a researcher in selecting a data feature and its most appropriate semantic representations or data sources. Little aid is available to inform researchers about data characteristics or to help them conduct exploratory data analyses for optimal data feature selection.     Mixed-initiative interaction,3 which allows human and computer to collaboratively contribute to converged problem solutions, can potentially fulfill this need. We hypothesize that by equipping biomedical researchers with a knowledge-based, mixed-initiative dialog system, we can maximize the efficiency and accuracy of E- screening by supporting exploratory analyses of correlated data features for query optimization. Our approach is innovative because it (1) addresses the user needs for intelligent query interfaces for clinical data, (2) provides a novel data-driven approach to eligibility determination based on correlated data features, and (3) enables efficient query optimization through support of human-computer collaborative problem solving.      We will build on the results from our first funding period for bridging the semantic gap.4-21 We developed an analysis pipeline called EliXR to construct a semantic knowledge representation for eligibility criteria 6,9,16,17, which can be used to transform free-text eligibility criteria ito structured narrative.6 We developed methods to dynamically categorize eligibility criteria by data type.8 We accumulated E-screening experience from three NIH-sponsored clinical trials.7,13,21 We developed a method combining PubMed knowledge and EHR data to infer patient phenotype4 and reconciled structured and unstructured clinical data to support E-screening.18 We are prepared with methods and a preliminary understanding of the building blocks necessary to optimally translate eligibility criteria into data features; therefore, our current proposal is the logical next step.                        Our specific aims are to:     1.	Use mixed methods to understand the needs of biomedical researchers for query clarification and identify common strategies used by query analysts for plan optimization for complex eligibility queries.     2.	Develop a knowledge-based, mixed-initiative dialog system to improve human-computer collaboration for query formulation using participatory design methods.     3.	Evaluate the efficacy and usability of the mixed-initiative dialog system using a research data warehouse and two use cases: research protocol feasibility testing and trial recruitment prescreening.                        We will advance the field by contributing knowledge of the needs for query support among biomedical researchers and an effective E-screening method that combines intelligent query recommendation and iterative query by review22 to improve data access for researchers through human-computer collaboration.              Project Narrative  This project addresses the needs of clinician scientists to understand data characteristics when using clinical data to search for potentially eligible clinical research participants. It will develop a novel intelligent query consultant to guide clinicians in interrogating clinical databases. This project has the potential to improve the efficiency and accuracy and reduce cost of patient prescreening for clinical and translational research.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8509023,R01LM009886,"['Accident and Emergency department', 'Address', 'Adoption', 'Blood Pressure', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collaborations', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Drug Formulations', 'Drug usage', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Funding', 'Goals', 'Human', 'Hypertension', 'ICD-9', 'Knowledge', 'Methods', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Problem Solving', 'Protocols documentation', 'PubMed', 'Reading', 'Recommendation', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Solutions', 'Specific qualifier value', 'Structure', 'Symptoms', 'System', 'Testing', 'Text', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'base', 'cost', 'data space', 'design', 'experience', 'improved', 'information organization', 'innovation', 'knowledge base', 'novel', 'screening', 'tool', 'usability']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2013,401181,0.03819385166858095
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data     DESCRIPTION (provided by applicant):         Averaging about $1,000 per patient1, recruitment remains an expensive bottleneck for human studies. The rapidly increasing adoption of electronic health records (EHR) has made electronic prescreening (E-screening hereafter) a practicable solution to this bottleneck. Our long-term goal is to achieve this ""holy grail"". Our short- term goal of this competing continuation is to develop an intelligent patient query consultant to improve the accuracy and efficiency of E-screening.             One of the difficulties for E-screening is the semantic gap between eligibility criteria and clinical data.2 Each eligibility criterion (e.g., hypertension) describes a patient characteristic, which is correlated with multiple data features (e.g., orders of hypertension drugs, elevated blood pressure, and symptoms of hypertension) in EHR. Moreover, each data feature may have multiple semantic representations (e.g., ""SBP"", ""BP"", or ""blood pressure"") from disparate data sources. For example, elevated systolic blood pressure can be recorded in varying formats in an emergency room, a doctor's office, an ICU, and an in-patient unit, but not all of these readings necessarily indicate chronic hypertension.             The use of clinical data to identify patients eligible for clinical research requires specialized knowledge and expert guidance to navigate the vast space of data features and intelligent inferences from data features for eligibility determination. A user must understand the characteristics of available data before using them to search for patients. For example, when only 5% of hypertensive patients have ICD-9 codes for hypertension but 73% of these patients have hypertension drug orders, using drug information to construct a query of hypertensive patients will be more effective than one using ICD-9 codes. Even sophisticated biomedical data query tools such as i2b2, VISAGE, and STRIDE only passively translate user-specified data features into a query statement. They do not guide a researcher in selecting a data feature and its most appropriate semantic representations or data sources. Little aid is available to inform researchers about data characteristics or to help them conduct exploratory data analyses for optimal data feature selection.     Mixed-initiative interaction,3 which allows human and computer to collaboratively contribute to converged problem solutions, can potentially fulfill this need. We hypothesize that by equipping biomedical researchers with a knowledge-based, mixed-initiative dialog system, we can maximize the efficiency and accuracy of E- screening by supporting exploratory analyses of correlated data features for query optimization. Our approach is innovative because it (1) addresses the user needs for intelligent query interfaces for clinical data, (2) provides a novel data-driven approach to eligibility determination based on correlated data features, and (3) enables efficient query optimization through support of human-computer collaborative problem solving.      We will build on the results from our first funding period for bridging the semantic gap.4-21 We developed an analysis pipeline called EliXR to construct a semantic knowledge representation for eligibility criteria 6,9,16,17, which can be used to transform free-text eligibility criteria ito structured narrative.6 We developed methods to dynamically categorize eligibility criteria by data type.8 We accumulated E-screening experience from three NIH-sponsored clinical trials.7,13,21 We developed a method combining PubMed knowledge and EHR data to infer patient phenotype4 and reconciled structured and unstructured clinical data to support E-screening.18 We are prepared with methods and a preliminary understanding of the building blocks necessary to optimally translate eligibility criteria into data features; therefore, our current proposal is the logical next step.                        Our specific aims are to:     1.	Use mixed methods to understand the needs of biomedical researchers for query clarification and identify common strategies used by query analysts for plan optimization for complex eligibility queries.     2.	Develop a knowledge-based, mixed-initiative dialog system to improve human-computer collaboration for query formulation using participatory design methods.     3.	Evaluate the efficacy and usability of the mixed-initiative dialog system using a research data warehouse and two use cases: research protocol feasibility testing and trial recruitment prescreening.                        We will advance the field by contributing knowledge of the needs for query support among biomedical researchers and an effective E-screening method that combines intelligent query recommendation and iterative query by review22 to improve data access for researchers through human-computer collaboration.              Project Narrative  This project addresses the needs of clinician scientists to understand data characteristics when using clinical data to search for potentially eligible clinical research participants. It will develop a novel intelligent query consultant to guide clinicians in interrogating clinical databases. This project has the potential to improve the efficiency and accuracy and reduce cost of patient prescreening for clinical and translational research.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8292499,R01LM009886,"['Accident and Emergency department', 'Address', 'Adoption', 'Blood Pressure', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collaborations', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Drug Formulations', 'Drug usage', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Funding', 'Goals', 'Human', 'Hypertension', 'ICD-9', 'Knowledge', 'Methods', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Problem Solving', 'Protocols documentation', 'PubMed', 'Reading', 'Recommendation', 'Research', 'Research Personnel', 'Scientist', 'Screening procedure', 'Semantics', 'Solutions', 'Specific qualifier value', 'Structure', 'Symptoms', 'System', 'Testing', 'Text', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'base', 'cost', 'data space', 'design', 'experience', 'improved', 'information organization', 'innovation', 'knowledge base', 'novel', 'tool', 'usability']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2012,487432,0.03819385166858095
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8055880,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical data warehouse', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,328942,0.04221158361308508
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,7784533,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical data warehouse', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,341606,0.04221158361308508
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8056227,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical data warehouse', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,177422,0.04221158361308508
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,7653874,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Databases', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,357875,0.04221158361308508
"POET: Consolidated, Comprehensive Clinical Text Preprocessing    DESCRIPTION (provided by applicant):       As electronic health records (EHRs) continue their expansion into clinical settings, there has been a corresponding increase in interest in mining the data they contain, both for research as well as for clinical decision support. Informaticists are increasingly studying ways to mine EHR textual content. This is an important trend, because there is a wealth of information contained in clinical text not represented anywhere else in the EHR. There is a low level text-as-data issue which presents a significant obstacle to the widespread use of available medical NLP systems: hand-typed clinical narratives in EHRs are usually ungrammatical; short or telegraphic in style; full of abbreviations, acronyms, and misspellings; formatted in a templated or pseudo-tabular form; and contain embedded non-text such as a list of laboratory values cut-and-pasted from elsewhere in the EHR. As we show in the Preliminary Studies Section, this makes high-level processing by popular tools like MedLEE and MetaMap effectively useless for all but a few ""clean"" document types like discharge summaries or consult reports (e.g., pathology or radiology reports). This in turn explains why there is so little published about what is certainly the preponderance of clinical texts, those that are not as well-behaved lexically and syntactically as a discharge summary.       In this application we distinguish clinical narratives (e.g., a progress note) from biomedical narratives (e.g., a PubMed abstract). We are interested in texts that arise in the clinical or research setting; texts that are composed by clinicians and researchers directly into a computer system. We propose to build and publish a tool called POET (Parsable Output Extracted from Text). POET will be designed to accept unstructured textual documents and return structured, linguistic equivalents that are, to the extent possible, parsable by higher-level NLP engines. POET will have an architecture is modular, extensible, and based on open-source platforms and sources (e.g., Java, Perl, UMLS, NegEx, the Stanford Parser, HL7 Clinical Document Architecture, caGRID, etc.). To implement POET, we will collect, program, and evaluate published as well as novel algorithms for: acronym/abbreviation resolution; spelling correction; template and pseudo-table re-writing; and removal of embedded non-text. To test POET we will use a large corpus of cross-discipline (e.g., medical, nursing, pharmacy, etc.) clinical note types, as well as the clinical research texts MedWatch reports and IRB adverse event reports. The development of POET will combine the best practices found in the literature and new research efforts as part of the project. To validate the fidelity of POET processing we plan a formal analysis of information loss and information gain pre- and post-process. To ensure broad access to the tools, POET will be released under an open-source license. Finally, we plan to assess the feasibility of offering POET as a Web service for remote processing.           Public Health Relevance This project attempts the construction of POET, a low-level preprocessing system for full text that can be used to open up large portions of the electronic health record (EHR) to high-level NLP systems. The potential public health implications are: 1) POET will allow the expansion of the use of well-proven clinical NLP systems  (currently limited to only a few document types found in the EHR) to the entire  clinical text record; with the entirety of the clinical record accessible to NLP,  serious and realistic attempts at real-time clinical text surveillance can be  mounted to improve patient safety and quality of care; 2) POET will be made available through open source distribution and other means  to encourage the practical deployment of innovative decision support systems  using large healthcare network EHRs across the country; 3) POET meets an important translational public health informatics need by solving  persistent low-level barriers to effective data mining of clinical marriages in the  EHR. The wider public health implications include promoting effective computerized decision support and data mining to improve both personal and public health outcomes.","POET: Consolidated, Comprehensive Clinical Text Preprocessing",7847940,R21LM009967,"['Abbreviations', 'Adverse event', 'Algorithms', 'Architecture', 'Body of uterus', 'Clinical', 'Clinical Pharmacists', 'Clinical Research', 'Computer Systems', 'Consult', 'Country', 'Data', 'Decision Support Systems', 'Development', 'Discipline', 'Discipline of Nursing', 'Electronic Health Record', 'Ensure', 'Excision', 'Hand', 'Healthcare', 'Internet', 'Java', 'Laboratories', 'Licensing', 'Linguistics', 'Literature', 'Marriage', 'Medical', 'Mind', 'Mining', 'Natural Language Processing', 'Nature', 'Nurses', 'Outcome', 'Output', 'Paste substance', 'Pathology', 'Pathology Report', 'Pharmacy facility', 'Physical assessment', 'Process', 'PubMed', 'Public Health', 'Public Health Informatics', 'Publishing', 'Quality of Care', 'Radiology Specialty', 'Report (document)', 'Reporting', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resolution', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Study Section', 'System', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'acronyms', 'base', 'caGrid', 'computerized', 'data mining', 'design', 'discrete data', 'improved', 'innovation', 'interest', 'meetings', 'novel', 'open source', 'patient safety', 'programs', 'public health relevance', 'spelling', 'tool', 'trend']",NLM,UNIVERSITY OF UTAH,R21,2009,84657,0.09992803870236658
"POET: Consolidated, Comprehensive Clinical Text Preprocessing    DESCRIPTION (provided by applicant):       As electronic health records (EHRs) continue their expansion into clinical settings, there has been a corresponding increase in interest in mining the data they contain, both for research as well as for clinical decision support. Informaticists are increasingly studying ways to mine EHR textual content. This is an important trend, because there is a wealth of information contained in clinical text not represented anywhere else in the EHR. There is a low level text-as-data issue which presents a significant obstacle to the widespread use of available medical NLP systems: hand-typed clinical narratives in EHRs are usually ungrammatical; short or telegraphic in style; full of abbreviations, acronyms, and misspellings; formatted in a templated or pseudo-tabular form; and contain embedded non-text such as a list of laboratory values cut-and-pasted from elsewhere in the EHR. As we show in the Preliminary Studies Section, this makes high-level processing by popular tools like MedLEE and MetaMap effectively useless for all but a few ""clean"" document types like discharge summaries or consult reports (e.g., pathology or radiology reports). This in turn explains why there is so little published about what is certainly the preponderance of clinical texts, those that are not as well-behaved lexically and syntactically as a discharge summary.       In this application we distinguish clinical narratives (e.g., a progress note) from biomedical narratives (e.g., a PubMed abstract). We are interested in texts that arise in the clinical or research setting; texts that are composed by clinicians and researchers directly into a computer system. We propose to build and publish a tool called POET (Parsable Output Extracted from Text). POET will be designed to accept unstructured textual documents and return structured, linguistic equivalents that are, to the extent possible, parsable by higher-level NLP engines. POET will have an architecture is modular, extensible, and based on open-source platforms and sources (e.g., Java, Perl, UMLS, NegEx, the Stanford Parser, HL7 Clinical Document Architecture, caGRID, etc.). To implement POET, we will collect, program, and evaluate published as well as novel algorithms for: acronym/abbreviation resolution; spelling correction; template and pseudo-table re-writing; and removal of embedded non-text. To test POET we will use a large corpus of cross-discipline (e.g., medical, nursing, pharmacy, etc.) clinical note types, as well as the clinical research texts MedWatch reports and IRB adverse event reports. The development of POET will combine the best practices found in the literature and new research efforts as part of the project. To validate the fidelity of POET processing we plan a formal analysis of information loss and information gain pre- and post-process. To ensure broad access to the tools, POET will be released under an open-source license. Finally, we plan to assess the feasibility of offering POET as a Web service for remote processing.           Public Health Relevance This project attempts the construction of POET, a low-level preprocessing system for full text that can be used to open up large portions of the electronic health record (EHR) to high-level NLP systems. The potential public health implications are: 1) POET will allow the expansion of the use of well-proven clinical NLP systems  (currently limited to only a few document types found in the EHR) to the entire  clinical text record; with the entirety of the clinical record accessible to NLP,  serious and realistic attempts at real-time clinical text surveillance can be  mounted to improve patient safety and quality of care; 2) POET will be made available through open source distribution and other means  to encourage the practical deployment of innovative decision support systems  using large healthcare network EHRs across the country; 3) POET meets an important translational public health informatics need by solving  persistent low-level barriers to effective data mining of clinical marriages in the  EHR. The wider public health implications include promoting effective computerized decision support and data mining to improve both personal and public health outcomes.","POET: Consolidated, Comprehensive Clinical Text Preprocessing",7689273,R21LM009967,"['Abbreviations', 'Adverse event', 'Algorithms', 'Architecture', 'Body of uterus', 'Clinical', 'Clinical Pharmacists', 'Clinical Research', 'Computer Systems', 'Consult', 'Country', 'Data', 'Decision Support Systems', 'Development', 'Discipline', 'Discipline of Nursing', 'Electronic Health Record', 'Ensure', 'Excision', 'Hand', 'Healthcare', 'Internet', 'Java', 'Laboratories', 'Licensing', 'Linguistics', 'Literature', 'Marriage', 'Medical', 'Mind', 'Mining', 'Natural Language Processing', 'Nature', 'Nurses', 'Outcome', 'Output', 'Paste substance', 'Pathology', 'Pathology Report', 'Pharmacy facility', 'Physical assessment', 'Process', 'PubMed', 'Public Health', 'Public Health Informatics', 'Publishing', 'Quality of Care', 'Radiology Specialty', 'Report (document)', 'Reporting', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resolution', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Study Section', 'System', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'acronyms', 'base', 'caGrid', 'computerized', 'data mining', 'design', 'discrete data', 'improved', 'innovation', 'interest', 'meetings', 'novel', 'open source', 'patient safety', 'programs', 'public health relevance', 'spelling', 'tool', 'trend']",NLM,UNIVERSITY OF UTAH,R21,2009,166590,0.09992803870236658
"POET: Consolidated, Comprehensive Clinical Text Preprocessing    DESCRIPTION (provided by applicant):       As electronic health records (EHRs) continue their expansion into clinical settings, there has been a corresponding increase in interest in mining the data they contain, both for research as well as for clinical decision support. Informaticists are increasingly studying ways to mine EHR textual content. This is an important trend, because there is a wealth of information contained in clinical text not represented anywhere else in the EHR. There is a low level text-as-data issue which presents a significant obstacle to the widespread use of available medical NLP systems: hand-typed clinical narratives in EHRs are usually ungrammatical; short or telegraphic in style; full of abbreviations, acronyms, and misspellings; formatted in a templated or pseudo-tabular form; and contain embedded non-text such as a list of laboratory values cut-and-pasted from elsewhere in the EHR. As we show in the Preliminary Studies Section, this makes high-level processing by popular tools like MedLEE and MetaMap effectively useless for all but a few ""clean"" document types like discharge summaries or consult reports (e.g., pathology or radiology reports). This in turn explains why there is so little published about what is certainly the preponderance of clinical texts, those that are not as well-behaved lexically and syntactically as a discharge summary.       In this application we distinguish clinical narratives (e.g., a progress note) from biomedical narratives (e.g., a PubMed abstract). We are interested in texts that arise in the clinical or research setting; texts that are composed by clinicians and researchers directly into a computer system. We propose to build and publish a tool called POET (Parsable Output Extracted from Text). POET will be designed to accept unstructured textual documents and return structured, linguistic equivalents that are, to the extent possible, parsable by higher-level NLP engines. POET will have an architecture is modular, extensible, and based on open-source platforms and sources (e.g., Java, Perl, UMLS, NegEx, the Stanford Parser, HL7 Clinical Document Architecture, caGRID, etc.). To implement POET, we will collect, program, and evaluate published as well as novel algorithms for: acronym/abbreviation resolution; spelling correction; template and pseudo-table re-writing; and removal of embedded non-text. To test POET we will use a large corpus of cross-discipline (e.g., medical, nursing, pharmacy, etc.) clinical note types, as well as the clinical research texts MedWatch reports and IRB adverse event reports. The development of POET will combine the best practices found in the literature and new research efforts as part of the project. To validate the fidelity of POET processing we plan a formal analysis of information loss and information gain pre- and post-process. To ensure broad access to the tools, POET will be released under an open-source license. Finally, we plan to assess the feasibility of offering POET as a Web service for remote processing.           Public Health Relevance This project attempts the construction of POET, a low-level preprocessing system for full text that can be used to open up large portions of the electronic health record (EHR) to high-level NLP systems. The potential public health implications are: 1) POET will allow the expansion of the use of well-proven clinical NLP systems  (currently limited to only a few document types found in the EHR) to the entire  clinical text record; with the entirety of the clinical record accessible to NLP,  serious and realistic attempts at real-time clinical text surveillance can be  mounted to improve patient safety and quality of care; 2) POET will be made available through open source distribution and other means  to encourage the practical deployment of innovative decision support systems  using large healthcare network EHRs across the country; 3) POET meets an important translational public health informatics need by solving  persistent low-level barriers to effective data mining of clinical marriages in the  EHR. The wider public health implications include promoting effective computerized decision support and data mining to improve both personal and public health outcomes.","POET: Consolidated, Comprehensive Clinical Text Preprocessing",7570254,R21LM009967,"['Abbreviations', 'Adverse event', 'Algorithms', 'Architecture', 'Body of uterus', 'Clinical', 'Clinical Pharmacists', 'Clinical Research', 'Computer Systems', 'Consult', 'Data', 'Development', 'Discipline', 'Discipline of Nursing', 'Electronic Health Record', 'Ensure', 'Excision', 'Hand', 'Internet', 'Java', 'Laboratories', 'Licensing', 'Linguistics', 'Literature', 'Medical', 'Mind', 'Mining', 'Natural Language Processing', 'Nature', 'Nurses', 'Output', 'Paste substance', 'Pathology', 'Pathology Report', 'Pharmacy facility', 'Physical assessment', 'Process', 'PubMed', 'Publishing', 'Radiology Specialty', 'Report (document)', 'Reporting', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resolution', 'Services', 'Source', 'Specific qualifier value', 'Standards of Weights and Measures', 'Structure', 'Study Section', 'System', 'Testing', 'Text', 'Thinking', 'Unified Medical Language System', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'base', 'data mining', 'design', 'discrete data', 'interest', 'novel', 'open source', 'programs', 'spelling', 'tool', 'trend']",NLM,UNIVERSITY OF UTAH,R21,2008,169313,0.09992803870236658
"Near Miss Narratives from the Fire Service: A Bayesian Analysis    DESCRIPTION (provided by applicant): This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source that has not yet been rigorously investigated. The proposal has 3 aims:  I. to use recently developed auto coding methods to characterize firefighter near miss narratives and classify these narratives into mechanisms of risk/injury. This analysis will apply the International Classification of External Cause of Injuries (ICECI) using Bayesian machine learning techniques to identify the various mechanisms captured in the near miss narratives and their relative prevalence.  II. To identify the correlation between each mechanism of risk/injury and each of the ""Contributing Factors"" listed on the NFFNMRS reporting form. The results will reveal any patterns and trends in the distribution of the contributing factors among the mechanisms, creating a deeper understanding of near miss circumstances, as well as a basis for improving the quality of future near miss data collection.  III. To use manual coding to identify actual injury incidents contained within a random sample of 1,000 near miss narratives and correlate these injuries with the ""Loss Potential"" categories on the NFFNMRS reporting form. The results will demonstrate how actual injuries are distributed within the reporting form's ""Loss Potential"" categories. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention. This study addresses a major gap in firefighter safety knowledge, i.e. the insufficient understanding of near miss events, and will have a high impact on efforts to improve the occupational health and safety of firefighters.         This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source, the NFFNMRS that has not yet been rigorously investigated. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention.         ",Near Miss Narratives from the Fire Service: A Bayesian Analysis,8325335,R03OH009984,[' '],NIOSH,DREXEL UNIVERSITY,R03,2012,76332,0.04550123995368424
"Near Miss Narratives from the Fire Service: A Bayesian Analysis    DESCRIPTION (provided by applicant): This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source that has not yet been rigorously investigated. The proposal has 3 aims:  I. to use recently developed auto coding methods to characterize firefighter near miss narratives and classify these narratives into mechanisms of risk/injury. This analysis will apply the International Classification of External Cause of Injuries (ICECI) using Bayesian machine learning techniques to identify the various mechanisms captured in the near miss narratives and their relative prevalence.  II. To identify the correlation between each mechanism of risk/injury and each of the ""Contributing Factors"" listed on the NFFNMRS reporting form. The results will reveal any patterns and trends in the distribution of the contributing factors among the mechanisms, creating a deeper understanding of near miss circumstances, as well as a basis for improving the quality of future near miss data collection.  III. To use manual coding to identify actual injury incidents contained within a random sample of 1,000 near miss narratives and correlate these injuries with the ""Loss Potential"" categories on the NFFNMRS reporting form. The results will demonstrate how actual injuries are distributed within the reporting form's ""Loss Potential"" categories. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention. This study addresses a major gap in firefighter safety knowledge, i.e. the insufficient understanding of near miss events, and will have a high impact on efforts to improve the occupational health and safety of firefighters.      PUBLIC HEALTH RELEVANCE:  This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source, the NFFNMRS that has not yet been rigorously investigated. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention.            This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source, the NFFNMRS that has not yet been rigorously investigated. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention.         ",Near Miss Narratives from the Fire Service: A Bayesian Analysis,8206110,R03OH009984,[' '],NIOSH,DREXEL UNIVERSITY,R03,2011,74075,0.04688769015603987
"Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data Adverse drug reactions (ADRs) are a major burden for patients and healthcare, causing preventable  hospitalizations and deaths, and incurring a huge cost. The long-term objective of this proposal is to advance  patient safety and reduce costs by discovering novel serious ADRs through use of automated methods that  combine information from large and varied patient populations as well as from the literature. There have been  considerable advances in pharmacovigilance, but more work is needed. For example, Vioxx, a commonly used  drug, was recently found to cause at least 88,000 occurrences of myocardial infarction, highlighting the  insufficiency of current methods. To date, methods have mainly depended on the use of single sources of data,  primarily from the Federal Food and Drug Administration Adverse Event Reporting System (FAERS) and from  electronic health records (EHRS). Although important, each of the sources has different limitations and  advantages, and therefore, combining the data across them should lead to more effective drug safety  surveillance by increasing the statistical power, and also by allowing each data source to complement the other  sources. We already have developed methods associated with each of the single sources, and therefore, this  is an excellent opportunity to build upon our research accomplishments to advance the state of the art in  pharmacovigilance.   More specifically, we will a) acquire and combine comprehensive clinical data from the electronic health  records (EHRs) of two different health care sites serving diverse populations by utilizing natural language  processing (NLP) to obtain vast quantities of fine-grained data, and then by developing data mining  methodologies on the clinical data to detect novel ADR signals, b) analyze differences in therapy-related risk  factors between the two EHR populations, such as racial and ethnic differences, c) detect ADR signals in the  FAERS database using an established methodology, d) develop improved methods to acquire ADR signals  based on information in the literature, and e) develop methods that utilize the results from the above sources to  maximize effectiveness. We will focus on eight serious ADRs, and collect a high-quality reference standard for  those ADRs so that we will be able to evaluate and compare performance of the different detection methods  individually as well as the methods that combine the sources.   This proposal is well positioned to overcome problems associated with existing automated methods, which  are primarily based on use of individual sources of data. We are confident the methods will be effective  because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in  this proposal presents an excellent chance to leverage heterogeneous data sources to dramatically improve  patient safety and reduce costs. Adverse drug reactions (ADRs) are a major burden for patients and health care, causing preventable  hospitalizations and deaths, and incurring huge costs, and, therefore, continuous post-marketing surveillance  is crucial for patient safety. This proposal aims to improve patient safety and reduce health care costs by  developing effective methods to discover new adverse drug reactions through the combination of information in  the FDA's Adverse Event Reporting System, the literature, and comprehensive clinical data from electronic  health records of two different sites with diverse populations, thereby overcoming limitations that rely mainly on  use of one data source.",Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data,9109047,R01LM010016,"['Academic Medical Centers', 'Address', 'Adverse event', 'Adverse reactions', 'Cereals', 'Cessation of life', 'Chemicals', 'Clinical', 'Clinical Data', 'Complement', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Drug usage', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Hospitals', 'Individual', 'Knowledge', 'Lead', 'Literature', 'Logistic Regressions', 'Medical Care Costs', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Natural Language Processing', 'New York', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Presbyterian Church', 'Probability', 'Process', 'PubMed', 'Publications', 'Reaction', 'Reference Standards', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Factors', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'United States Food and Drug Administration', 'Work', 'base', 'chemical property', 'conditioning', 'cost', 'data mining', 'ethnic difference', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'prevent', 'racial difference', 'research and development', 'text searching']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,430717,0.08254562480483084
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7870862,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,172278,0.09579596233890268
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7631876,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,344239,0.09579596233890268
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7937173,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,172210,0.09579596233890268
"Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data Adverse drug reactions (ADRs) are a major burden for patients and healthcare, causing preventable  hospitalizations and deaths, and incurring a huge cost. The long-term objective of this proposal is to advance  patient safety and reduce costs by discovering novel serious ADRs through use of automated methods that  combine information from large and varied patient populations as well as from the literature. There have been  considerable advances in pharmacovigilance, but more work is needed. For example, Vioxx, a commonly used  drug, was recently found to cause at least 88,000 occurrences of myocardial infarction, highlighting the  insufficiency of current methods. To date, methods have mainly depended on the use of single sources of data,  primarily from the Federal Food and Drug Administration Adverse Event Reporting System (FAERS) and from  electronic health records (EHRS). Although important, each of the sources has different limitations and  advantages, and therefore, combining the data across them should lead to more effective drug safety  surveillance by increasing the statistical power, and also by allowing each data source to complement the other  sources. We already have developed methods associated with each of the single sources, and therefore, this  is an excellent opportunity to build upon our research accomplishments to advance the state of the art in  pharmacovigilance.   More specifically, we will a) acquire and combine comprehensive clinical data from the electronic health  records (EHRs) of two different health care sites serving diverse populations by utilizing natural language  processing (NLP) to obtain vast quantities of fine-grained data, and then by developing data mining  methodologies on the clinical data to detect novel ADR signals, b) analyze differences in therapy-related risk  factors between the two EHR populations, such as racial and ethnic differences, c) detect ADR signals in the  FAERS database using an established methodology, d) develop improved methods to acquire ADR signals  based on information in the literature, and e) develop methods that utilize the results from the above sources to  maximize effectiveness. We will focus on eight serious ADRs, and collect a high-quality reference standard for  those ADRs so that we will be able to evaluate and compare performance of the different detection methods  individually as well as the methods that combine the sources.   This proposal is well positioned to overcome problems associated with existing automated methods, which  are primarily based on use of individual sources of data. We are confident the methods will be effective  because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in  this proposal presents an excellent chance to leverage heterogeneous data sources to dramatically improve  patient safety and reduce costs. Adverse drug reactions (ADRs) are a major burden for patients and health care, causing preventable  hospitalizations and deaths, and incurring huge costs, and, therefore, continuous post-marketing surveillance  is crucial for patient safety. This proposal aims to improve patient safety and reduce health care costs by  developing effective methods to discover new adverse drug reactions through the combination of information in  the FDA's Adverse Event Reporting System, the literature, and comprehensive clinical data from electronic  health records of two different sites with diverse populations, thereby overcoming limitations that rely mainly on  use of one data source.",Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data,8882546,R01LM010016,"['Academic Medical Centers', 'Address', 'Adverse event', 'Adverse reactions', 'Cereals', 'Cessation of life', 'Chemicals', 'Clinical', 'Clinical Data', 'Complement', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Drug usage', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Hospitals', 'Individual', 'Knowledge', 'Lead', 'Literature', 'Logistic Regressions', 'Medical Care Costs', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Natural Language Processing', 'New York', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Presbyterian Church', 'Probability', 'Process', 'PubMed', 'Publications', 'Reaction', 'Reference Standards', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Factors', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'United States Food and Drug Administration', 'Work', 'base', 'chemical property', 'conditioning', 'cost', 'data mining', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'prevent', 'racial/ethnic difference', 'research and development', 'text searching']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2015,417794,0.08254562480483084
"Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data Adverse drug reactions (ADRs) are a major burden for patients and healthcare, causing preventable  hospitalizations and deaths, and incurring a huge cost. The long-term objective of this proposal is to advance  patient safety and reduce costs by discovering novel serious ADRs through use of automated methods that  combine information from large and varied patient populations as well as from the literature. There have been  considerable advances in pharmacovigilance, but more work is needed. For example, Vioxx, a commonly used  drug, was recently found to cause at least 88,000 occurrences of myocardial infarction, highlighting the  insufficiency of current methods. To date, methods have mainly depended on the use of single sources of data,  primarily from the Federal Food and Drug Administration Adverse Event Reporting System (FAERS) and from  electronic health records (EHRS). Although important, each of the sources has different limitations and  advantages, and therefore, combining the data across them should lead to more effective drug safety  surveillance by increasing the statistical power, and also by allowing each data source to complement the other  sources. We already have developed methods associated with each of the single sources, and therefore, this  is an excellent opportunity to build upon our research accomplishments to advance the state of the art in  pharmacovigilance.   More specifically, we will a) acquire and combine comprehensive clinical data from the electronic health  records (EHRs) of two different health care sites serving diverse populations by utilizing natural language  processing (NLP) to obtain vast quantities of fine-grained data, and then by developing data mining  methodologies on the clinical data to detect novel ADR signals, b) analyze differences in therapy-related risk  factors between the two EHR populations, such as racial and ethnic differences, c) detect ADR signals in the  FAERS database using an established methodology, d) develop improved methods to acquire ADR signals  based on information in the literature, and e) develop methods that utilize the results from the above sources to  maximize effectiveness. We will focus on eight serious ADRs, and collect a high-quality reference standard for  those ADRs so that we will be able to evaluate and compare performance of the different detection methods  individually as well as the methods that combine the sources.   This proposal is well positioned to overcome problems associated with existing automated methods, which  are primarily based on use of individual sources of data. We are confident the methods will be effective  because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in  this proposal presents an excellent chance to leverage heterogeneous data sources to dramatically improve  patient safety and reduce costs. Adverse drug reactions (ADRs) are a major burden for patients and health care, causing preventable  hospitalizations and deaths, and incurring huge costs, and, therefore, continuous post-marketing surveillance  is crucial for patient safety. This proposal aims to improve patient safety and reduce health care costs by  developing effective methods to discover new adverse drug reactions through the combination of information in  the FDA's Adverse Event Reporting System, the literature, and comprehensive clinical data from electronic  health records of two different sites with diverse populations, thereby overcoming limitations that rely mainly on  use of one data source.",Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data,8660067,R01LM010016,"['Academic Medical Centers', 'Address', 'Adverse event', 'Adverse reactions', 'Cereals', 'Cessation of life', 'Chemicals', 'Clinical', 'Clinical Data', 'Complement', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Drug usage', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Hospitals', 'Individual', 'Knowledge', 'Lead', 'Literature', 'Logistic Regressions', 'Medical Care Costs', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Natural Language Processing', 'New York', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Presbyterian Church', 'Probability', 'Process', 'PubMed', 'Publications', 'Reaction', 'Reference Standards', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Factors', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'United States Food and Drug Administration', 'Work', 'base', 'chemical property', 'conditioning', 'cost', 'data mining', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'prevent', 'racial/ethnic difference', 'research and development', 'text searching']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2014,417795,0.08254562480483084
"Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data Adverse drug reactions (ADRs) are a major burden for patients and healthcare, causing preventable  hospitalizations and deaths, and incurring a huge cost. The long-term objective of this proposal is to advance  patient safety and reduce costs by discovering novel serious ADRs through use of automated methods that  combine information from large and varied patient populations as well as from the literature. There have been  considerable advances in pharmacovigilance, but more work is needed. For example, Vioxx, a commonly used  drug, was recently found to cause at least 88,000 occurrences of myocardial infarction, highlighting the  insufficiency of current methods. To date, methods have mainly depended on the use of single sources of data,  primarily from the Federal Food and Drug Administration Adverse Event Reporting System (FAERS) and from  electronic health records (EHRS). Although important, each of the sources has different limitations and  advantages, and therefore, combining the data across them should lead to more effective drug safety  surveillance by increasing the statistical power, and also by allowing each data source to complement the other  sources. We already have developed methods associated with each of the single sources, and therefore, this  is an excellent opportunity to build upon our research accomplishments to advance the state of the art in  pharmacovigilance.   More specifically, we will a) acquire and combine comprehensive clinical data from the electronic health  records (EHRs) of two different health care sites serving diverse populations by utilizing natural language  processing (NLP) to obtain vast quantities of fine-grained data, and then by developing data mining  methodologies on the clinical data to detect novel ADR signals, b) analyze differences in therapy-related risk  factors between the two EHR populations, such as racial and ethnic differences, c) detect ADR signals in the  FAERS database using an established methodology, d) develop improved methods to acquire ADR signals  based on information in the literature, and e) develop methods that utilize the results from the above sources to  maximize effectiveness. We will focus on eight serious ADRs, and collect a high-quality reference standard for  those ADRs so that we will be able to evaluate and compare performance of the different detection methods  individually as well as the methods that combine the sources.   This proposal is well positioned to overcome problems associated with existing automated methods, which  are primarily based on use of individual sources of data. We are confident the methods will be effective  because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in  this proposal presents an excellent chance to leverage heterogeneous data sources to dramatically improve  patient safety and reduce costs. Adverse drug reactions (ADRs) are a major burden for patients and health care, causing preventable  hospitalizations and deaths, and incurring huge costs, and, therefore, continuous post-marketing surveillance  is crucial for patient safety. This proposal aims to improve patient safety and reduce health care costs by  developing effective methods to discover new adverse drug reactions through the combination of information in  the FDA's Adverse Event Reporting System, the literature, and comprehensive clinical data from electronic  health records of two different sites with diverse populations, thereby overcoming limitations that rely mainly on  use of one data source.",Pharmacovigilance Methods: Leveraging Heterogeneous Adverse Drug Reaction Data,8438732,R01LM010016,"['Academic Medical Centers', 'Address', 'Adverse event', 'Adverse reactions', 'Cereals', 'Cessation of life', 'Chemicals', 'Clinical', 'Clinical Data', 'Complement', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Drug usage', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Hospitals', 'Individual', 'Knowledge', 'Lead', 'Literature', 'Logistic Regressions', 'Medical Care Costs', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Natural Language Processing', 'New York', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Presbyterian Church', 'Probability', 'Process', 'PubMed', 'Publications', 'Reaction', 'Reference Standards', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Factors', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Source', 'Structure', 'System', 'Techniques', 'United States Food and Drug Administration', 'Work', 'base', 'chemical property', 'conditioning', 'cost', 'data mining', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'prevent', 'racial/ethnic difference', 'research and development', 'text searching']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2013,440117,0.08254562480483084
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",8318253,R01LM010016,"['Adverse event', 'Affect', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Evaluation', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2012,327503,0.09579596233890268
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",8105502,R01LM010016,"['Adverse event', 'Affect', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Evaluation', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,333575,0.09579596233890268
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7779983,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,343397,0.09579596233890268
"Using medical records repositories to improve the alert system design    DESCRIPTION (provided by applicant):       Rapid and accurate alerting of concerning patient events and conditions remains an important problem in clinical practice. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into the monitoring and alerting systems. However, it is often time-consuming and costly to extract and codify such knowledge; hence such systems are typically built to cover only very specific conditions. In addition, it is difficult for an expert to foresee the performance of the deployed systems and their potential drawbacks, especially their false alarm rates. It is not uncommon that computer alerting systems are discarded or must undergo multiple costly modification cycles before they reach clinically acceptable levels of performance.    Electronic health record (EHR) repositories today provide an opportunity to test various theories and develop new computational solutions to various clinical problems. The objective of this project is to investigate methods for using the data in such repositories to assist in the development of alerting systems. The project goals include the building of an evidence-driven framework for the evaluation and optimization of alerting systems with the help of past data. The framework will be able to provide early feedback and future performance estimates of an alerting system before it is deployed, which is anticipated to decrease the expert effort required to design such a system and lead to a shorter alerting system design cycle. The evidence-driven framework will be tested and evaluated on multiple clinical conditions and compared to the performance of alerting rules currently deployed at the University of Pittsburgh Medical Center (UPMC). The project investigators consist of a multidisciplinary team with expertise in rule-based alerting in the hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, and knowledge based systems.           Project Narrative: There remain numerous opportunities to reduce medical errors by sending computer-based reminders and alerts to clinicians. This project investigates a novel combination of past patient data stored in electronic form and statistical machine-learning methods to help develop and refine computer-based alerts, which are expected to improve healthcare quality and reduce costs.",Using medical records repositories to improve the alert system design,7784403,R01LM010019,"['Amiodarone', 'Archives', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Data', 'Databases', 'Detection', 'Development', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Event', 'Expert Opinion', 'Feedback', 'Future', 'Goals', 'Gold', 'Heparin', 'Hospitals', 'Human', 'Information Systems', 'Knowledge', 'Knowledge acquisition', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Medical Errors', 'Medical Informatics', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Metric', 'Modeling', 'Modification', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Pharmacy facility', 'Physicians', 'Research', 'Research Personnel', 'Solutions', 'Source', 'Statistical Methods', 'Stream', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Universities', 'base', 'biomedical informatics', 'clinical practice', 'cost', 'design', 'evaluation/testing', 'flexibility', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'repository', 'response', 'statistics', 'success', 'theories', 'treatment response']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,370642,0.05857793344472488
"Using medical records repositories to improve the alert system design    DESCRIPTION (provided by applicant):       Rapid and accurate alerting of concerning patient events and conditions remains an important problem in clinical practice. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into the monitoring and alerting systems. However, it is often time-consuming and costly to extract and codify such knowledge; hence such systems are typically built to cover only very specific conditions. In addition, it is difficult for an expert to foresee the performance of the deployed systems and their potential drawbacks, especially their false alarm rates. It is not uncommon that computer alerting systems are discarded or must undergo multiple costly modification cycles before they reach clinically acceptable levels of performance.    Electronic health record (EHR) repositories today provide an opportunity to test various theories and develop new computational solutions to various clinical problems. The objective of this project is to investigate methods for using the data in such repositories to assist in the development of alerting systems. The project goals include the building of an evidence-driven framework for the evaluation and optimization of alerting systems with the help of past data. The framework will be able to provide early feedback and future performance estimates of an alerting system before it is deployed, which is anticipated to decrease the expert effort required to design such a system and lead to a shorter alerting system design cycle. The evidence-driven framework will be tested and evaluated on multiple clinical conditions and compared to the performance of alerting rules currently deployed at the University of Pittsburgh Medical Center (UPMC). The project investigators consist of a multidisciplinary team with expertise in rule-based alerting in the hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, and knowledge based systems.           Project Narrative: There remain numerous opportunities to reduce medical errors by sending computer-based reminders and alerts to clinicians. This project investigates a novel combination of past patient data stored in electronic form and statistical machine-learning methods to help develop and refine computer-based alerts, which are expected to improve healthcare quality and reduce costs.",Using medical records repositories to improve the alert system design,8139263,R01LM010019,"['Amiodarone', 'Archives', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Data', 'Databases', 'Detection', 'Development', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Event', 'Expert Opinion', 'Feedback', 'Future', 'Goals', 'Gold', 'Heparin', 'Hospitals', 'Human', 'Information Systems', 'Knowledge', 'Knowledge acquisition', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Medical Errors', 'Medical Informatics', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Metric', 'Modeling', 'Modification', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Pharmacy facility', 'Physicians', 'Research', 'Research Personnel', 'Solutions', 'Source', 'Statistical Methods', 'Stream', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Universities', 'base', 'biomedical informatics', 'clinical practice', 'cost', 'design', 'evaluation/testing', 'flexibility', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'repository', 'response', 'statistics', 'success', 'theories', 'treatment response']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,366808,0.05857793344472488
"Using medical records repositories to improve the alert system design    DESCRIPTION (provided by applicant):       Rapid and accurate alerting of concerning patient events and conditions remains an important problem in clinical practice. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into the monitoring and alerting systems. However, it is often time-consuming and costly to extract and codify such knowledge; hence such systems are typically built to cover only very specific conditions. In addition, it is difficult for an expert to foresee the performance of the deployed systems and their potential drawbacks, especially their false alarm rates. It is not uncommon that computer alerting systems are discarded or must undergo multiple costly modification cycles before they reach clinically acceptable levels of performance.    Electronic health record (EHR) repositories today provide an opportunity to test various theories and develop new computational solutions to various clinical problems. The objective of this project is to investigate methods for using the data in such repositories to assist in the development of alerting systems. The project goals include the building of an evidence-driven framework for the evaluation and optimization of alerting systems with the help of past data. The framework will be able to provide early feedback and future performance estimates of an alerting system before it is deployed, which is anticipated to decrease the expert effort required to design such a system and lead to a shorter alerting system design cycle. The evidence-driven framework will be tested and evaluated on multiple clinical conditions and compared to the performance of alerting rules currently deployed at the University of Pittsburgh Medical Center (UPMC). The project investigators consist of a multidisciplinary team with expertise in rule-based alerting in the hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, and knowledge based systems.           Project Narrative: There remain numerous opportunities to reduce medical errors by sending computer-based reminders and alerts to clinicians. This project investigates a novel combination of past patient data stored in electronic form and statistical machine-learning methods to help develop and refine computer-based alerts, which are expected to improve healthcare quality and reduce costs.",Using medical records repositories to improve the alert system design,7935413,R01LM010019,"['Amiodarone', 'Archives', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Data', 'Databases', 'Detection', 'Development', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Event', 'Expert Opinion', 'Feedback', 'Future', 'Goals', 'Gold', 'Heparin', 'Hospitals', 'Human', 'Information Systems', 'Knowledge', 'Knowledge acquisition', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Medical Errors', 'Medical Informatics', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Metric', 'Modeling', 'Modification', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Pharmacy facility', 'Physicians', 'Research', 'Research Personnel', 'Solutions', 'Source', 'Statistical Methods', 'Stream', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Universities', 'base', 'biomedical informatics', 'clinical practice', 'cost', 'design', 'evaluation/testing', 'flexibility', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'repository', 'response', 'statistics', 'success', 'theories', 'treatment response']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,377274,0.05857793344472488
"An NLP Approach to Generating Patient Record Summaries :  The long-term goal of this proposal is to enhance the manner in which physicians access, process and marshal medical information by providing them with an automatically generated, comprehensive, and up-to date summary of the information appearing in a patient record. At the point of patient care, physicians must often rapidly process a potentially overwhelming quantity of information pertaining to a patient. Failure to do so effectively may lead to provision of suboptimal care. Some electronic health record systems provide an automatically produced cover sheet geared to help physicians with a broad overview of a given patient, but the information is derived from the structured data fields in the patient record, ignoring the valuable narrative text entered by clinicians over time. We are building upon our prior work in summarization and natural language processing and leveraging our expertise in cognitive research studying information needs and decision making of clinicians to build a patient record summarizer that gathers information narrative (unstructured) as well as structured parts in the record. We focus on producing a summary for patients with kidney disease, as they often have a complex medical history with numerous conditions, procedures and medications. Providing a holistic, up-to-date summary of their chart would prove valuable to physicians in general and nephrologists in particular. The following three aims will be carried out: (1) conduct a formative study to determine how physicians prioritize and mentally represent relevant information when reviewing a patient chart; (2) create a set of automated methods to select salient pieces of information in the patient record and organize them into a coherent summary; and (3) evaluate the efficacy, efficiency and physician-user satisfaction associated with the use of the summarizer. A primary strength of this proposal is that we are addressing the problem of information overload, a bottleneck in the use of electronic health records, and evaluate the impact of our solution on clinicians actions and patients health outcomes. Furthermore, we propose to use novel natural language processing, knowledge-based and data mining methods to extract and organize salient information. Finally, we contribute to informatics research by extending the electronic health record functionalities to go beyond a simple documentation-entry system towards a useful reference and decision-making tool for physicians  Project Narrative We propose to design an automatically generated, comprehensive, and up-to-date summary of the information appearing in a patient record. Such a summary would enhance the manner in which both patients and their physicians access, process and marshal medical information.",An NLP Approach to Generating Patient Record Summaries,7925659,R01LM010027,"['Address', 'Allergic', 'Caring', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Decision Making', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation Studies', 'Face', 'Failure', 'Feasibility Studies', 'Goals', 'Hand', 'Health', 'Health Status', 'Informatics', 'Information Resources', 'Interview', 'Kidney Diseases', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Marshal', 'Medical', 'Medical History', 'MedlinePlus', 'Methods', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Personal Health Records', 'Pharmaceutical Preparations', 'Physicians', 'Procedures', 'Process', 'Records', 'Research', 'Resources', 'Solutions', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Visit', 'Work', 'data mining', 'design', 'health literacy', 'information gathering', 'knowledge base', 'literate', 'medical schools', 'meetings', 'novel', 'research study', 'satisfaction', 'stem', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,456856,0.06897596407910127
"An NLP Approach to Generating Patient Record Summaries :  The long-term goal of this proposal is to enhance the manner in which physicians access, process and marshal medical information by providing them with an automatically generated, comprehensive, and up-to date summary of the information appearing in a patient record. At the point of patient care, physicians must often rapidly process a potentially overwhelming quantity of information pertaining to a patient. Failure to do so effectively may lead to provision of suboptimal care. Some electronic health record systems provide an automatically produced cover sheet geared to help physicians with a broad overview of a given patient, but the information is derived from the structured data fields in the patient record, ignoring the valuable narrative text entered by clinicians over time. We are building upon our prior work in summarization and natural language processing and leveraging our expertise in cognitive research studying information needs and decision making of clinicians to build a patient record summarizer that gathers information narrative (unstructured) as well as structured parts in the record. We focus on producing a summary for patients with kidney disease, as they often have a complex medical history with numerous conditions, procedures and medications. Providing a holistic, up-to-date summary of their chart would prove valuable to physicians in general and nephrologists in particular. The following three aims will be carried out: (1) conduct a formative study to determine how physicians prioritize and mentally represent relevant information when reviewing a patient chart; (2) create a set of automated methods to select salient pieces of information in the patient record and organize them into a coherent summary; and (3) evaluate the efficacy, efficiency and physician-user satisfaction associated with the use of the summarizer. A primary strength of this proposal is that we are addressing the problem of information overload, a bottleneck in the use of electronic health records, and evaluate the impact of our solution on clinicians actions and patients health outcomes. Furthermore, we propose to use novel natural language processing, knowledge-based and data mining methods to extract and organize salient information. Finally, we contribute to informatics research by extending the electronic health record functionalities to go beyond a simple documentation-entry system towards a useful reference and decision-making tool for physicians  Project Narrative We propose to design an automatically generated, comprehensive, and up-to-date summary of the information appearing in a patient record. Such a summary would enhance the manner in which both patients and their physicians access, process and marshal medical information.",An NLP Approach to Generating Patient Record Summaries,7635002,R01LM010027,"['Address', 'Allergic', 'Caring', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Decision Making', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation Studies', 'Failure', 'Goals', 'Harvest', 'Health', 'Informatics', 'Information Resources', 'Interview', 'Kidney Diseases', 'Kidney Function Tests', 'Knowledge', 'Laboratories', 'Lead', 'Marshal', 'Medical', 'Medical History', 'Methods', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Procedures', 'Process', 'Research', 'Solutions', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Text', 'Time', 'Visit', 'Work', 'data mining', 'design', 'information gathering', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research study', 'satisfaction', 'stem', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,455605,0.06897596407910127
"Temporal relation discovery for clinical text     DESCRIPTION (provided by applicant):         The overarching long-term vision of our research is to create novel technologies for processing clinical free text. We will build upon the previous work of our ongoing project ""Temporal relation discovery for clinical text"" (R01LM010090) dubbed Temporal Histories of Your Medical Events (THYME; thyme.healthnlp.org) which has been focusing on methodology for event, temporal expressions and temporal relations discovery from the clinical text residing in the Electronic Health Records (EHR). We developed a comprehensive approach to temporality in the clinical text and innovated in computable temporal representations, methods for temporal relation discovery and their evaluation, rendering temporality to end users - resulting in over 35+ papers and presentations. Our dissemination is international and far-reaching as the best performing methods are released open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (ctakes.apache.org). The methods we developed are now being used in such nation-wide initiatives as the Electronic Medical Records and Genomics (eMERGE), Pharmacogenomics Network (PGRN), Informatics for Integrating the Biology and the Bedside (i2b2), Patient Centered Outcomes Research Institute and National Cancer Institute's Informatics Technology for Cancer Research (ITCR). Through our participation in organizing major international bakeoffs - CLEF/ShARe 2014, SemEval 2014 Analysis of Clinical Text Task 7, SemEval 2015 Analysis of Clinical Text Task 14, SemEval 2015 Clinical TempEval Task 6 - we further disseminated the THYME resources and challenged the international research community to explore new solutions to the unsolved temporality task. Through all these activities it became clear that computational approaches to temporality still present great challenges and usability of the output is still limited. Therefore, we propose to further innovate on methodologies and end user experience.             Specific Aim 1: Extract enhanced representations and novel features to support deriving timeline information.     Specific Aim 2: Develop methods to amalgamate individual patient episode timelines into an aggregate patient-level timeline.     Specific Aim 3: Mine the EHR - the unstructured clinical text and the structured codified information - for full patient-level temporality.     Specific Aim 4: Develop a comprehensive temporal visualization tool     Specific Aim 5: Develop methodology for and perform extrinsic evaluation on specific use case.     Specific Aim 6: (1) Evaluate state-of-the-art of temporal relations through organizing international challenges under the auspices of SemEval, (2) Disseminate the results through publications, presentations, and open source code in Apache cTAKES. Functional testing.             Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EHR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,8927274,R01LM010090,"['Apache Indians', 'Automobile Driving', 'Biology', 'Chronology', 'Clinical', 'Collection', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Evaluation', 'Event', 'Genomics', 'Goals', 'Human', 'Imagery', 'Individual', 'Informatics', 'Information Retrieval', 'International', 'Joints', 'Knowledge Extraction', 'Language', 'Life', 'Link', 'Machine Learning', 'Malignant neoplasm of brain', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Multiple Sclerosis', 'National Cancer Institute', 'Outcomes Research', 'Output', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Process', 'Publications', 'Recording of previous events', 'Records', 'Research', 'Research Institute', 'Resolution', 'Resources', 'Science', 'Semantics', 'Signs and Symptoms', 'Solutions', 'Source Code', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Thyme', 'Time', 'TimeLine', 'Translating', 'Translational Research', 'Trees', 'Vision', 'Work', 'abstracting', 'anticancer research', 'autism spectrum disorder', 'clinically relevant', 'data mining', 'experience', 'innovation', 'new technology', 'next generation', 'novel', 'open source', 'syntax', 'tool', 'usability']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2015,720481,0.05449312133866176
"Temporal relation discovery for clinical text    DESCRIPTION (provided by applicant): The overarching long-term vision of our research is to create novel technologies for processing clinical free text. Such technologies will enable sophisticated and efficient indexing, retrieval and data mining over the ever increasing amounts of electronic clinical data. Processing free text poses a number of challenges to which the fields of Artificial intelligence, natural language processing and computer science in general have made advances. Methods for processing free text are informed by linguistic theory combined with the power of statistical inferencing. A key component to the next step, natural language understanding, is discovering events and their relations on a timeline. Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles.        The goal of our current proposal is to discover temporal relations from clinical free text through achieving four specific aims:        Specific Aim 1: Develop (1) a temporal relation annotation schema and guidelines for clinical free text based on TimeML, which will require extensions to Treebank, PropBank and VerbNet annotation guidelines to the clinical domain, (2) an annotated corpus following the temporal relations schema with additions to Treebank, PropBank and VerbNet, (3) a descriptive study comparing temporal relations in the clinical and general domains.        Specific Aim 2: Extend and evaluate existing methods and/or develop new algorithms for temporal relation discovery in the clinical domain. Component-level evaluation        Specific Aim 3: Integrate best method and/or a variety of methods for temporal relation discovery into the open source Mayo Clinic IE pipeline and release as open source annotators in the pipeline. Functional testing. Dissemination activities.        Specific Aim 4: System-level evaluation. Test the functionality of the enhanced Mayo Clinic IE pipeline on translational research use cases, e.g. the progression of colon cancer as documented in clinical notes and pathology reports, the progression of brain tumor as documented in radiology reports.        The methods we will use for the temporal relation discovery are based on machine learning, e.g., Support Vector Machine technology. Such methods require the annotation of a reference standard from which the computations are derived. The best methods will be released as part of the Mayo Clinic Information Extraction System for the larger community to use and contribute to. We will test the methods against biomedical queries.           Relevance (max 2-3 sentences) Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and create a timeline.",Temporal relation discovery for clinical text,7983243,R01LM010090,"['Algorithms', 'Artificial Intelligence', 'Automated Annotation', 'Brain Neoplasms', 'Clinic', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Communities', 'Data', 'Development', 'Disease', 'Electronics', 'Evaluation', 'Event', 'Goals', 'Guidelines', 'Linguistics', 'Link', 'Machine Learning', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology Report', 'Performance', 'Process', 'Radiology Specialty', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Signs and Symptoms', 'System', 'Technology', 'Testing', 'Text', 'TimeLine', 'Translational Research', 'Vision', 'base', 'clinically relevant', 'computer science', 'data mining', 'indexing', 'new technology', 'next generation', 'open source', 'theories']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2010,775112,0.01446345130272201
"Temporal relation discovery for clinical text    DESCRIPTION (provided by applicant): The overarching long-term vision of our research is to create novel technologies for processing clinical free text. Such technologies will enable sophisticated and efficient indexing, retrieval and data mining over the ever increasing amounts of electronic clinical data. Processing free text poses a number of challenges to which the fields of Artificial intelligence, natural language processing and computer science in general have made advances. Methods for processing free text are informed by linguistic theory combined with the power of statistical inferencing. A key component to the next step, natural language understanding, is discovering events and their relations on a timeline. Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles.        The goal of our current proposal is to discover temporal relations from clinical free text through achieving four specific aims:        Specific Aim 1: Develop (1) a temporal relation annotation schema and guidelines for clinical free text based on TimeML, which will require extensions to Treebank, PropBank and VerbNet annotation guidelines to the clinical domain, (2) an annotated corpus following the temporal relations schema with additions to Treebank, PropBank and VerbNet, (3) a descriptive study comparing temporal relations in the clinical and general domains.        Specific Aim 2: Extend and evaluate existing methods and/or develop new algorithms for temporal relation discovery in the clinical domain. Component-level evaluation        Specific Aim 3: Integrate best method and/or a variety of methods for temporal relation discovery into the open source Mayo Clinic IE pipeline and release as open source annotators in the pipeline. Functional testing. Dissemination activities.        Specific Aim 4: System-level evaluation. Test the functionality of the enhanced Mayo Clinic IE pipeline on translational research use cases, e.g. the progression of colon cancer as documented in clinical notes and pathology reports, the progression of brain tumor as documented in radiology reports.        The methods we will use for the temporal relation discovery are based on machine learning, e.g., Support Vector Machine technology. Such methods require the annotation of a reference standard from which the computations are derived. The best methods will be released as part of the Mayo Clinic Information Extraction System for the larger community to use and contribute to. We will test the methods against biomedical queries.           Relevance (max 2-3 sentences) Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and create a timeline.",Temporal relation discovery for clinical text,8324662,R01LM010090,"['Algorithms', 'Artificial Intelligence', 'Automated Annotation', 'Brain Neoplasms', 'Clinic', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Communities', 'Data', 'Development', 'Disease', 'Electronics', 'Evaluation', 'Event', 'Goals', 'Guidelines', 'Linguistics', 'Link', 'Machine Learning', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology Report', 'Performance', 'Process', 'Radiology Specialty', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Signs and Symptoms', 'System', 'Technology', 'Testing', 'Text', 'TimeLine', 'Translational Research', 'Vision', 'base', 'clinically relevant', 'computer science', 'data mining', 'indexing', 'new technology', 'next generation', 'open source', 'theories']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2012,745770,0.01446345130272201
"Temporal relation discovery for clinical text    DESCRIPTION (provided by applicant): The overarching long-term vision of our research is to create novel technologies for processing clinical free text. Such technologies will enable sophisticated and efficient indexing, retrieval and data mining over the ever increasing amounts of electronic clinical data. Processing free text poses a number of challenges to which the fields of Artificial intelligence, natural language processing and computer science in general have made advances. Methods for processing free text are informed by linguistic theory combined with the power of statistical inferencing. A key component to the next step, natural language understanding, is discovering events and their relations on a timeline. Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles.        The goal of our current proposal is to discover temporal relations from clinical free text through achieving four specific aims:        Specific Aim 1: Develop (1) a temporal relation annotation schema and guidelines for clinical free text based on TimeML, which will require extensions to Treebank, PropBank and VerbNet annotation guidelines to the clinical domain, (2) an annotated corpus following the temporal relations schema with additions to Treebank, PropBank and VerbNet, (3) a descriptive study comparing temporal relations in the clinical and general domains.        Specific Aim 2: Extend and evaluate existing methods and/or develop new algorithms for temporal relation discovery in the clinical domain. Component-level evaluation        Specific Aim 3: Integrate best method and/or a variety of methods for temporal relation discovery into the open source Mayo Clinic IE pipeline and release as open source annotators in the pipeline. Functional testing. Dissemination activities.        Specific Aim 4: System-level evaluation. Test the functionality of the enhanced Mayo Clinic IE pipeline on translational research use cases, e.g. the progression of colon cancer as documented in clinical notes and pathology reports, the progression of brain tumor as documented in radiology reports.        The methods we will use for the temporal relation discovery are based on machine learning, e.g., Support Vector Machine technology. Such methods require the annotation of a reference standard from which the computations are derived. The best methods will be released as part of the Mayo Clinic Information Extraction System for the larger community to use and contribute to. We will test the methods against biomedical queries.           Relevance (max 2-3 sentences) Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and create a timeline.",Temporal relation discovery for clinical text,8138604,R01LM010090,"['Algorithms', 'Artificial Intelligence', 'Automated Annotation', 'Brain Neoplasms', 'Clinic', 'Clinical', 'Clinical Data', 'Colon Carcinoma', 'Communities', 'Data', 'Development', 'Disease', 'Electronics', 'Evaluation', 'Event', 'Goals', 'Guidelines', 'Linguistics', 'Link', 'Machine Learning', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology Report', 'Performance', 'Process', 'Radiology Specialty', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Signs and Symptoms', 'System', 'Technology', 'Testing', 'Text', 'TimeLine', 'Translational Research', 'Vision', 'base', 'clinically relevant', 'computer science', 'data mining', 'indexing', 'new technology', 'next generation', 'open source', 'theories']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2011,695125,0.01446345130272201
"Temporal relation discovery for clinical text Project Summary / Abstract The current proposal continues the investigation on the topic of temporal relation extraction from the Electronic Medical Records (EMR) clinical narrative funded by the NLM since 2010 (Temporal Histories of Your Medical Events, or THYME; thyme.healthnlp.org). Through our efforts so far, we have defined the topic as an active area of research attracting attention across the world. Since its inception, the project has pushed the boundaries of this highly challenging task by investigating new computational methods within the context of the latest developments in the fields of natural language processing (NLP), machine learning (ML), artificial intelligence (AI) and biomedical informatics (BMI) resulting in 60+ publications/presentations. We have made our best performing methods available to the community open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES; ctakes.apache.org). In 2015, 2016, 2017 and 2018, we organized an international shared task (Clinical TempEval) on the topic under the umbrella of the highly prestigious SemEval, thus inviting the international community to work with our THYME data and improve on our results. Clinical TempEval has been highly successful with many participants each year, resulting in new discoveries and many publications. We have made all our data along with our gold standard annotations available to the community through the hNLP Center (center.healthnlp.org).  The underlying theme of this renewal is novel methods for combining explicit domain knowledge (linguistic, semantic, biomedical ontological, clinical), readily available unlabeled data (health-related social media, EMRs), and modern machine learning techniques (e.g. neural networks) for temporal relation extraction from the EMR clinical narrative. Therefore, our renewal proposes a novel and much needed exploration of this line of research:  Specific Aim 1: Develop computational models for novel rich semantic representations such as the Abstract Meaning Representations to encapsulate a single, coherent, full-document graphical representation of meaning for temporal relation extraction  Specific Aim 2: Develop computational methods to infuse domain knowledge (linguistic, semantic, biomedical ontological, clinical) into modern machine learning techniques such as NNs for temporal relation extraction  through input representations, pre-trained vectors, or architectures  Specific Aim 3: Develop novel methods for combining labeled and unlabeled data from various sources (EMR, health-related social media, newswire) for temporal relation extraction from the clinical narrative  Specific Aim 4: Apply the best performing methods for temporal relation extraction developed in SA1-3 to temporally sensitive phenotypes for direct translational sciences studies. Dissemination efforts through publications and open source releases into Apache cTAKES. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EMR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,9949779,R01LM010090,"['Address', 'Apache', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Clinical', 'Cognitive', 'Communities', 'Complex', 'Computer Models', 'Computerized Medical Record', 'Computing Methodologies', 'Coupled', 'Data', 'Development', 'Disease', 'Encapsulated', 'Engineering', 'Event', 'Fostering', 'Foundations', 'Funding', 'Goals', 'Gold', 'Health', 'Image', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Label', 'Linguistics', 'Link', 'Machine Learning', 'Medical', 'Methods', 'Modernization', 'Natural Language Processing', 'Nature', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Publications', 'Recording of previous events', 'Research', 'Semantics', 'Signs and Symptoms', 'Solid', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Text', 'Thyme', 'Time', 'TimeLine', 'Training', 'Translational Research', 'Vision', 'Work', 'advanced disease', 'base', 'biomedical informatics', 'biomedical ontology', 'clinically relevant', 'cohesion', 'electronic data', 'electronic structure', 'epidemiology study', 'improved', 'individualized medicine', 'learning community', 'neural network', 'next generation', 'novel', 'open source', 'programs', 'relating to nervous system', 'social media', 'support vector machine', 'symptom treatment', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,545793,0.01925068229445715
"Temporal relation discovery for clinical text Project Summary / Abstract The current proposal continues the investigation on the topic of temporal relation extraction from the Electronic Medical Records (EMR) clinical narrative funded by the NLM since 2010 (Temporal Histories of Your Medical Events, or THYME; thyme.healthnlp.org). Through our efforts so far, we have defined the topic as an active area of research attracting attention across the world. Since its inception, the project has pushed the boundaries of this highly challenging task by investigating new computational methods within the context of the latest developments in the fields of natural language processing (NLP), machine learning (ML), artificial intelligence (AI) and biomedical informatics (BMI) resulting in 60+ publications/presentations. We have made our best performing methods available to the community open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES; ctakes.apache.org). In 2015, 2016, 2017 and 2018, we organized an international shared task (Clinical TempEval) on the topic under the umbrella of the highly prestigious SemEval, thus inviting the international community to work with our THYME data and improve on our results. Clinical TempEval has been highly successful with many participants each year, resulting in new discoveries and many publications. We have made all our data along with our gold standard annotations available to the community through the hNLP Center (center.healthnlp.org).  The underlying theme of this renewal is novel methods for combining explicit domain knowledge (linguistic, semantic, biomedical ontological, clinical), readily available unlabeled data (health-related social media, EMRs), and modern machine learning techniques (e.g. neural networks) for temporal relation extraction from the EMR clinical narrative. Therefore, our renewal proposes a novel and much needed exploration of this line of research:  Specific Aim 1: Develop computational models for novel rich semantic representations such as the Abstract Meaning Representations to encapsulate a single, coherent, full-document graphical representation of meaning for temporal relation extraction  Specific Aim 2: Develop computational methods to infuse domain knowledge (linguistic, semantic, biomedical ontological, clinical) into modern machine learning techniques such as NNs for temporal relation extraction  through input representations, pre-trained vectors, or architectures  Specific Aim 3: Develop novel methods for combining labeled and unlabeled data from various sources (EMR, health-related social media, newswire) for temporal relation extraction from the clinical narrative  Specific Aim 4: Apply the best performing methods for temporal relation extraction developed in SA1-3 to temporally sensitive phenotypes for direct translational sciences studies. Dissemination efforts through publications and open source releases into Apache cTAKES. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EMR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,9735964,R01LM010090,"['Address', 'Apache', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Clinical', 'Cognitive', 'Communities', 'Complex', 'Computer Simulation', 'Computerized Medical Record', 'Computing Methodologies', 'Coupled', 'Data', 'Development', 'Disease', 'Encapsulated', 'Engineering', 'Event', 'Fostering', 'Foundations', 'Funding', 'Goals', 'Gold', 'Health', 'Image', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Label', 'Linguistics', 'Link', 'Machine Learning', 'Medical', 'Methods', 'Modernization', 'Natural Language Processing', 'Nature', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Publications', 'Recording of previous events', 'Research', 'Semantics', 'Signs and Symptoms', 'Solid', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Text', 'Thyme', 'Time', 'TimeLine', 'Training', 'Translational Research', 'Vision', 'Work', 'advanced disease', 'base', 'biomedical informatics', 'biomedical ontology', 'clinically relevant', 'cohesion', 'electronic data', 'electronic structure', 'epidemiology study', 'improved', 'individualized medicine', 'learning community', 'neural network', 'next generation', 'novel', 'open source', 'programs', 'relating to nervous system', 'social media', 'symptom treatment', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,626851,0.01925068229445715
"Temporal relation discovery for clinical text     DESCRIPTION (provided by applicant):         The overarching long-term vision of our research is to create novel technologies for processing clinical free text. We will build upon the previous work of our ongoing project ""Temporal relation discovery for clinical text"" (R01LM010090) dubbed Temporal Histories of Your Medical Events (THYME; thyme.healthnlp.org) which has been focusing on methodology for event, temporal expressions and temporal relations discovery from the clinical text residing in the Electronic Health Records (EHR). We developed a comprehensive approach to temporality in the clinical text and innovated in computable temporal representations, methods for temporal relation discovery and their evaluation, rendering temporality to end users - resulting in over 35+ papers and presentations. Our dissemination is international and far-reaching as the best performing methods are released open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (ctakes.apache.org). The methods we developed are now being used in such nation-wide initiatives as the Electronic Medical Records and Genomics (eMERGE), Pharmacogenomics Network (PGRN), Informatics for Integrating the Biology and the Bedside (i2b2), Patient Centered Outcomes Research Institute and National Cancer Institute's Informatics Technology for Cancer Research (ITCR). Through our participation in organizing major international bakeoffs - CLEF/ShARe 2014, SemEval 2014 Analysis of Clinical Text Task 7, SemEval 2015 Analysis of Clinical Text Task 14, SemEval 2015 Clinical TempEval Task 6 - we further disseminated the THYME resources and challenged the international research community to explore new solutions to the unsolved temporality task. Through all these activities it became clear that computational approaches to temporality still present great challenges and usability of the output is still limited. Therefore, we propose to further innovate on methodologies and end user experience.             Specific Aim 1: Extract enhanced representations and novel features to support deriving timeline information.     Specific Aim 2: Develop methods to amalgamate individual patient episode timelines into an aggregate patient-level timeline.     Specific Aim 3: Mine the EHR - the unstructured clinical text and the structured codified information - for full patient-level temporality.     Specific Aim 4: Develop a comprehensive temporal visualization tool     Specific Aim 5: Develop methodology for and perform extrinsic evaluation on specific use case.     Specific Aim 6: (1) Evaluate state-of-the-art of temporal relations through organizing international challenges under the auspices of SemEval, (2) Disseminate the results through publications, presentations, and open source code in Apache cTAKES. Functional testing. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EHR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,9337497,R01LM010090,"['Apache', 'Automobile Driving', 'Biology', 'Chronology', 'Clinical', 'Collection', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Evaluation', 'Event', 'Genomics', 'Goals', 'Human', 'Informatics', 'Information Retrieval', 'International', 'Intuition', 'Joints', 'Knowledge Extraction', 'Language', 'Life', 'Link', 'Machine Learning', 'Malignant neoplasm of brain', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'National Cancer Institute', 'Output', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Publications', 'Recording of previous events', 'Records', 'Research', 'Research Institute', 'Resolution', 'Resources', 'Science', 'Semantics', 'Signs and Symptoms', 'Source Code', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Thyme', 'Time', 'TimeLine', 'Translational Research', 'Trees', 'Vision', 'Visualization software', 'Work', 'anticancer research', 'autism spectrum disorder', 'clinically relevant', 'data mining', 'electronic structure', 'experience', 'individual patient', 'innovation', 'new technology', 'next generation', 'novel', 'open source', 'symptom treatment', 'syntax', 'usability']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2017,643621,0.05449312133866176
"Temporal relation discovery for clinical text     DESCRIPTION (provided by applicant):         The overarching long-term vision of our research is to create novel technologies for processing clinical free text. We will build upon the previous work of our ongoing project ""Temporal relation discovery for clinical text"" (R01LM010090) dubbed Temporal Histories of Your Medical Events (THYME; thyme.healthnlp.org) which has been focusing on methodology for event, temporal expressions and temporal relations discovery from the clinical text residing in the Electronic Health Records (EHR). We developed a comprehensive approach to temporality in the clinical text and innovated in computable temporal representations, methods for temporal relation discovery and their evaluation, rendering temporality to end users - resulting in over 35+ papers and presentations. Our dissemination is international and far-reaching as the best performing methods are released open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (ctakes.apache.org). The methods we developed are now being used in such nation-wide initiatives as the Electronic Medical Records and Genomics (eMERGE), Pharmacogenomics Network (PGRN), Informatics for Integrating the Biology and the Bedside (i2b2), Patient Centered Outcomes Research Institute and National Cancer Institute's Informatics Technology for Cancer Research (ITCR). Through our participation in organizing major international bakeoffs - CLEF/ShARe 2014, SemEval 2014 Analysis of Clinical Text Task 7, SemEval 2015 Analysis of Clinical Text Task 14, SemEval 2015 Clinical TempEval Task 6 - we further disseminated the THYME resources and challenged the international research community to explore new solutions to the unsolved temporality task. Through all these activities it became clear that computational approaches to temporality still present great challenges and usability of the output is still limited. Therefore, we propose to further innovate on methodologies and end user experience.             Specific Aim 1: Extract enhanced representations and novel features to support deriving timeline information.     Specific Aim 2: Develop methods to amalgamate individual patient episode timelines into an aggregate patient-level timeline.     Specific Aim 3: Mine the EHR - the unstructured clinical text and the structured codified information - for full patient-level temporality.     Specific Aim 4: Develop a comprehensive temporal visualization tool     Specific Aim 5: Develop methodology for and perform extrinsic evaluation on specific use case.     Specific Aim 6: (1) Evaluate state-of-the-art of temporal relations through organizing international challenges under the auspices of SemEval, (2) Disseminate the results through publications, presentations, and open source code in Apache cTAKES. Functional testing. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EHR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,9146765,R01LM010090,"['Apache', 'Automobile Driving', 'Biology', 'Chronology', 'Clinical', 'Collection', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Evaluation', 'Event', 'Genomics', 'Goals', 'Human', 'Imagery', 'Informatics', 'Information Retrieval', 'International', 'Joints', 'Knowledge Extraction', 'Language', 'Life', 'Link', 'Machine Learning', 'Malignant neoplasm of brain', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Multiple Sclerosis', 'National Cancer Institute', 'Outcomes Research', 'Output', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Process', 'Publications', 'Recording of previous events', 'Records', 'Research', 'Research Institute', 'Resolution', 'Resources', 'Science', 'Semantics', 'Signs and Symptoms', 'Source Code', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Thyme', 'Time', 'TimeLine', 'Translating', 'Translational Research', 'Trees', 'Vision', 'Work', 'abstracting', 'anticancer research', 'autism spectrum disorder', 'clinically relevant', 'data mining', 'experience', 'individual patient', 'innovation', 'new technology', 'next generation', 'novel', 'open source', 'symptom treatment', 'syntax', 'tool', 'usability']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2016,643863,0.05449312133866176
"OAMiner: Integrative Knowledge Anchored Hypothesis Discovery    DESCRIPTION (provided by applicant):The objective of this proposal, which is designed to address the ever increasing need for integrated knowledge discovery in biology and medicine, is to enable the discovery, verification, and validation of hypotheses concerning interrelationships between image-based, phenotypic, and bio-molecular features in heterogeneous data sets by leveraging multiple conceptual knowledge sources - ultimately supporting ""high throughput"" knowledge-driven translational science. To provide for a manageable project scope, Osteoarthritis Initiative (OAI) data sets will be used as a primary, motivating use case for the development and evaluation of the projected research products. This project necessarily involves analysis of initial hypotheses by subject matter experts (SMEs) for system training and verification. However, the ultimate goal of our proposed approach is to minimize the need for human intervention to identify or validate knowledge-anchored hypotheses. In order to generate such hypotheses, four interrelated knowledge sources are used: 1) full-text published bio-medical literature accessed by both conventional text mining and NLP analyses of articles as found in the Medline database and associated full text repositories; 2) publically available ontologies included in the National Library of Medicine's Unified Medical Language System (UMLS); 3) one or more databases containing phenotypic and functional (e.g. quality of life, psychological, strength and performance measures) data; and 4) computerized-image analysis derived features (e.g. cross-sectional area of the quadriceps).            Project Narrative: Public Health Relevance Statement Clinical and translational studies produce heterogeneous sources of data. For example, the Cancer Genome Atlas (TCGA) project is collecting tumor biospecimens together with clinical and histopathological data in order to understand the molecular basis of cancer through the application of genome analysis technologies. Similarly, the Osteoarthritis Initiative (OAI), a multi-center, longitudinal study is designed to assess the incidence and progression of knee osteoarthritis (OA) by collecting anthropometric, biochemical, genetic, and imaging procedures from 4796 enrollees. In these and many other similar studies, the collected data are made publicly available, yet, there is an acute lack of sufficient biomedical informatics tools to effectively discover, verify and validate hypotheses based upon the contents of these heterogeneous data sources. Given these characteristics of the modern research environment, an essential biomedical informatics challenge is to apply knowledge-anchored reasoning to heterogeneous and multi-dimensional data sets in order to discover novel hypotheses concerning such data that may be tested in order to maximize clinical impact and ultimately support broad public health interventions.",OAMiner: Integrative Knowledge Anchored Hypothesis Discovery,7715205,R01LM010119,"['Acute', 'Address', 'Area', 'Atlases', 'Biochemical Genetics', 'Biology', 'Characteristics', 'Clinical', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Degenerative polyarthritis', 'Development', 'Environment', 'Evaluation', 'Expert Systems', 'Genome', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Intervention', 'Knee Osteoarthritis', 'Knowledge', 'Literature', 'Longitudinal Studies', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medicine', 'Molecular', 'Ontology', 'Performance', 'Public Health', 'Publishing', 'Quality of life', 'Research', 'Research Project Grants', 'Source', 'Technology', 'Testing', 'Text', 'Training', 'Translational Research', 'Unified Medical Language System', 'United States National Library of Medicine', 'base', 'biomedical informatics', 'cancer genome', 'computerized', 'design', 'novel', 'psychologic', 'public health relevance', 'repository', 'text searching', 'tool', 'translational study', 'tumor', 'verification and validation']",NLM,OHIO STATE UNIVERSITY,R01,2009,580358,-0.014460775815724067
"OAMiner: Integrative Knowledge Anchored Hypothesis Discovery    DESCRIPTION (provided by applicant):The objective of this proposal, which is designed to address the ever increasing need for integrated knowledge discovery in biology and medicine, is to enable the discovery, verification, and validation of hypotheses concerning interrelationships between image-based, phenotypic, and bio-molecular features in heterogeneous data sets by leveraging multiple conceptual knowledge sources - ultimately supporting ""high throughput"" knowledge-driven translational science. To provide for a manageable project scope, Osteoarthritis Initiative (OAI) data sets will be used as a primary, motivating use case for the development and evaluation of the projected research products. This project necessarily involves analysis of initial hypotheses by subject matter experts (SMEs) for system training and verification. However, the ultimate goal of our proposed approach is to minimize the need for human intervention to identify or validate knowledge-anchored hypotheses. In order to generate such hypotheses, four interrelated knowledge sources are used: 1) full-text published bio-medical literature accessed by both conventional text mining and NLP analyses of articles as found in the Medline database and associated full text repositories; 2) publically available ontologies included in the National Library of Medicine's Unified Medical Language System (UMLS); 3) one or more databases containing phenotypic and functional (e.g. quality of life, psychological, strength and performance measures) data; and 4) computerized-image analysis derived features (e.g. cross-sectional area of the quadriceps).            Project Narrative: Public Health Relevance Statement Clinical and translational studies produce heterogeneous sources of data. For example, the Cancer Genome Atlas (TCGA) project is collecting tumor biospecimens together with clinical and histopathological data in order to understand the molecular basis of cancer through the application of genome analysis technologies. Similarly, the Osteoarthritis Initiative (OAI), a multi-center, longitudinal study is designed to assess the incidence and progression of knee osteoarthritis (OA) by collecting anthropometric, biochemical, genetic, and imaging procedures from 4796 enrollees. In these and many other similar studies, the collected data are made publicly available, yet, there is an acute lack of sufficient biomedical informatics tools to effectively discover, verify and validate hypotheses based upon the contents of these heterogeneous data sources. Given these characteristics of the modern research environment, an essential biomedical informatics challenge is to apply knowledge-anchored reasoning to heterogeneous and multi-dimensional data sets in order to discover novel hypotheses concerning such data that may be tested in order to maximize clinical impact and ultimately support broad public health interventions.",OAMiner: Integrative Knowledge Anchored Hypothesis Discovery,7828221,R01LM010119,"['Acute', 'Address', 'Area', 'Atlases', 'Biochemical Genetics', 'Biology', 'Characteristics', 'Clinical', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Degenerative polyarthritis', 'Development', 'Environment', 'Evaluation', 'Expert Systems', 'Genome', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Intervention', 'Knee Osteoarthritis', 'Knowledge', 'Literature', 'Longitudinal Studies', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medicine', 'Molecular', 'Ontology', 'Performance', 'Public Health', 'Publishing', 'Quality of life', 'Research', 'Research Project Grants', 'Source', 'Technology', 'Testing', 'Text', 'Training', 'Translational Research', 'Unified Medical Language System', 'United States National Library of Medicine', 'base', 'biomedical informatics', 'cancer genome', 'computerized', 'design', 'novel', 'psychologic', 'public health relevance', 'quadriceps muscle', 'repository', 'text searching', 'tool', 'translational study', 'tumor', 'verification and validation']",NLM,OHIO STATE UNIVERSITY,R01,2010,584176,-0.014460775815724067
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,8142701,R01LM010140,"['Affect', 'Case Study', 'Curiosities', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Goals', 'Hand', 'Hospitals', 'Laboratories', 'Literature', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Persons', 'Population', 'Presbyterian Church', 'Rare Diseases', 'Reporting', 'Statistical Methods', 'Stream', 'System', 'Testing', 'blind', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'statistics', 'virology']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,10000,0.03968764849069745
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,7828239,R01LM010140,"['Affect', 'Case Study', 'Curiosities', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Goals', 'Hand', 'Hospitals', 'Laboratories', 'Literature', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Persons', 'Population', 'Presbyterian Church', 'Rare Diseases', 'Reporting', 'Statistical Methods', 'Stream', 'System', 'Testing', 'blind', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'statistics', 'virology']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,531496,0.03968764849069745
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,7727710,R01LM010140,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Case Study', 'Cells', 'Clinical', 'Code', 'Computer software', 'Curiosities', 'Data', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Electronics', 'Environmental Risk Factor', 'Evaluation', 'Frequencies', 'Goals', 'Hand', 'Hospitals', 'Immunocompromised Host', 'Incidence', 'Individual', 'Inequality', 'Informatics', 'Information Theory', 'Kaposi Sarcoma', 'Kidney Diseases', 'Laboratories', 'Link', 'Literature', 'Liver diseases', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Pattern', 'Persons', 'Population', 'Presbyterian Church', 'Process', 'PubMed', 'Rare Diseases', 'Records', 'Reporting', 'Research', 'Source', 'Statistical Methods', 'Stratification', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Text', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Virus', 'Work', 'Writing', 'abstracting', 'base', 'blind', 'data mining', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'novel', 'pathogen', 'repository', 'research study', 'statistics', 'text searching', 'tool', 'virology', 'web site']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,533007,0.03968764849069745
"Automated Detection of Anomalous Accesses to Electronic Health Records DESCRIPTION (provided by applicant): Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in is infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems. As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,9332474,R01LM010207,"['Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Dimensions', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Geography', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Interruption', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data access', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward', 'web portal']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,341475,0.08349468915772347
"Automated Detection of Anomalous Accesses to Electronic Health Records DESCRIPTION (provided by applicant): Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in is infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems. As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,9143798,R01LM010207,"['Accounting', 'Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Healthcare Systems', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data access', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward', 'web portal']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2016,341475,0.08349468915772347
"Automated Detection of Anomalous Accesses to Electronic Health Records DESCRIPTION (provided by applicant): Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in is infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems. As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,8882547,R01LM010207,"['Accounting', 'Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Healthcare Systems', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Internet', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward']",NLM,VANDERBILT UNIVERSITY,R01,2015,80,0.08349468915772347
"Automated Detection of Anomalous Accesses to Electronic Health Records  Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in its infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems.  As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,8694383,R01LM010207,"['Accounting', 'Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Healthcare Systems', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Internet', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Simulate', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward']",NLM,VANDERBILT UNIVERSITY,R01,2014,392500,0.08349468915772347
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,8318797,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly woman', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2012,383445,0.03337561071316652
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,8143550,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly woman', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2011,389385,0.03337561071316652
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,7940855,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2010,417999,0.03337561071316652
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,7767483,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2009,314000,0.03337561071316652
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach  Abstract The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The study design is prospective observational study. Scope is limited to cancer patients. There are three specific aims for this project. The first aim is to identify concepts that overlap between the electronic medical record's (EMR) clinical notes and the free text of clinical trial announcements. The PI will use the concepts to develop mapping frames that connect concepts in the text of trial announcements to those found in clinical notes in the medical record. When he has the mapping frames he will build the NLP module for the application. In the software development work he will utilize as many publicly available software components as possible. He will experiment with UIMA, GATE, MetaMap, Stanford Parser, NegEx algorithm and others. The PI will develop the tool around the National Library of Medicine's Unified Medical Language System knowledgebase. He will use Java for programming. The second aim is to create an algorithm that automatically generates questions to request information directly from the patient if the information is not available or accessible in the records. The third aim is to evaluate the in-vitro, laboratory performance of the application. For performance evaluation purposes the PI will recruit cancer care specialists to generate the gold standard lists of eligible clinical trials for study patients. He will publicly release the developed code at the end of the grant period. This K99/R00 project will serve the foundation for future R01 grant applications. The PI is fully committed to become faculty in the Clinical Research Informatics domain with a specialization in biomedical NLP. The support of the K99/R00 grant will enable him to acquire substantial formal training in Computational Linguistics while contributing to the body of knowledge of the Clinical Research Informatics field. The five-year grant support will ensure success in his endeavor. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, EMR based clinical trial recommendations directly to the patients. The results of this research will empower the patients and elevate their role in the decision making process.  Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,8331381,R00LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'abstracting', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'knowledge base', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,CINCINNATI CHILDRENS HOSP MED CTR,R00,2012,238944,0.0491716714814297
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach    DESCRIPTION (provided by applicant):       The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The study design is prospective observational study. Scope is limited to cancer patients. There are three specific aims for this project. The first aim is to identify concepts that overlap between the electronic medical record's (EMR) clinical notes and the free text of clinical trial announcements. The PI will use the concepts to develop mapping frames that connect concepts in the text of trial announcements to those found in clinical notes in the medical record. When he has the mapping frames he will build the NLP module for the application. In the software development work he will utilize as many publicly available software components as possible. He will experiment with UIMA, GATE, MetaMap, Stanford Parser, NegEx algorithm and others. The PI will develop the tool around the National Library of Medicine's Unified Medical Language System knowledgebase. He will use Java for programming. The second aim is to create an algorithm that automatically generates questions to request information directly from the patient if the information is not available or accessible in the records. The third aim is to evaluate the in-vitro, laboratory performance of the application. For performance evaluation purposes the PI will recruit cancer care specialists to generate the gold standard lists of eligible clinical trials for study patients. He will publicly release the developed code at the end of the grant period. This K99/R00 project will serve the foundation for future R01 grant applications. The PI is fully committed to become faculty in the Clinical Research Informatics domain with a specialization in biomedical NLP. The support of the K99/R00 grant will enable him to acquire substantial formal training in Computational Linguistics while contributing to the body of knowledge of the Clinical Research Informatics field. The five-year grant support will ensure success in his endeavor. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, EMR based clinical trial recommendations directly to the patients. The results of this research will empower the patients and elevate their role in the decision making process.           Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,7770648,K99LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Arts', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,UNIVERSITY OF WASHINGTON,K99,2009,84306,0.0491716714814297
"A Genotype-Phenotype Archiving and Communication System Despite major advances in genome sequencing and identification of the genetic basis of disease, clinical use of genomic analysis is limited in part by the costs and coordination associated with correlating genome results with phenotypic findings (Segal 2015). Clinicians are overwhelmed by the huge amounts of information needed to assess a genome, and laboratory scientists are hampered by getting sparse information about patient findings (phenotypic elements on physical examination, history, and testing). We have developed components of a process to address these issues. These components include the SimulConsult Genome-Phenome Analyzer (Segal et al. 2015), with its ad-hoc Electronic Health Record (EHR) integration (Segal et al. 2017). As part of a Geisinger-led team, we have demonstrated that Geisingers GenomeCOMPASS tool for Return of Genomic Results, integrated with the Genome-Phenome Analyzer, enhances understanding of those results by families and referring clinicians (Williams et al. 2016, 2017, Stuckey et al. 2015). Separately, Geisinger has developed methods for mining the findings in the EHR. However, lack of access to clinical genomic data and lack of standardization in genome analysis and frequent changes in capabilities have made it challenging to use such components. Accordingly, we propose to develop a prototype platform for a Genotype-Phenotype Archiving and Communication System (G-PACS), analogous to the radiology PACS, with archiving and communication of 2 types of information  patient findings and annotated genomic variants, enabling genome-phenome analysis using these components. AIM 1: Develop phenotype processing, archiving and communication. A Patient Finding List will be built in the G-PACS, distinct from the EHRs Problem List. The Patient Finding List will have a Candidate findings section populated by the Phenotype Builder EHR text mining program being implemented at Geisinger, and an Accepted findings section to which Candidate Findings can be accepted or be added using applications such as SimulConsult. Applications will save Session snapshots to the G-PACS, which can be used to re-launch using that data, or for a new analysis, using parts of the Patient Finding List. In all cases, the application will have access to the Candidate and Accepted Findings, and highlight information on SimulConsults Useful Findings screen to signal what information may already be known about the patient. AIM 2: Empower clinicians to use full data in genomic diagnosis. A pipeline will be built for annotating and combining variant files, with archival capability, optimized for speed. This and findings chosen using the Patient Finding List or Session snapshots, plus those entered with the Useful Findings feature of SimulConsult will enable the clinician to do a full Genome-Phenome analysis, and report using GenomeCOMPASS. Aim 3: Evaluate the end-to-end G-PACS solution. A mixed-methods approach will be used for 10 clinicians to test 3 de-identified cases with known diagnoses, using G-PACS and Epics development environment. This study aims to develop a prototype Genotype-Phenotype Archiving and Communication System (G-PACS). The rationale is that the current state of genome analysis and clinical use is lagging in part due to a situation of siloed information and capabilities, a situation that Clayton Christensen characterizes as requiring end-to-end integration to set the stage for a subsequent environment of interoperable standards. While analogous to the radiology PACS, the G-PACS will also have advanced analysis capabilities and sophisticated handling of 2 types of information  patient findings and annotated genomic variants to enable genome- phenome analysis by clinicians and laboratorians using these components.",A Genotype-Phenotype Archiving and Communication System,9621137,R43HG010322,"['Address', 'Age', 'Age of Onset', 'Archives', 'Clinical', 'Code', 'Communication', 'Copy Number Polymorphism', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Elements', 'Environment', 'Family', 'General Practitioners', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Materials', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Health system', 'Laboratory Scientists', 'Link', 'Methods', 'Mining', 'Patients', 'Phase', 'Phenotype', 'Physical Examination', 'Process', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Signal Transduction', 'Specialist', 'Speed', 'Standardization', 'Surface', 'System', 'Terminology', 'Testing', 'Time', 'Variant', 'clinical Diagnosis', 'clinical care', 'cost', 'data format', 'file format', 'genetic variant', 'genome analysis', 'genome sequencing', 'genomic data', 'improved', 'interoperability', 'non-genomic', 'phenome', 'programs', 'prototype', 'text searching', 'tool', 'usability', 'whole genome']",NHGRI,"PHENOSOLVE, LLC",R43,2018,299505,-0.011868507141883327
"Mining Internet Conversation For Evidence Of Herbal Association    DESCRIPTION (provided by applicant): Mining Internet Conversations for Evidence of Herbal-Associated Adverse Events Abstract This application addresses broad Challenge Area (10), Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-102: Informatics for Post- Marketing Surveillance. Often, users of online resources such as discussion boards seek advice about topics they are hesitant to discuss with providers. One such topic is the use of herbal supplements. Relatively little is known about the use and effects of these supplements, primarily due to patient and provider reticence, but also owing to the lack of a formal reporting mechanism. As a result, adverse events and interactions possibly related to herbal use are difficult to evaluate in a population-based investigation. The potential impact for monitoring side effects and adverse events associated with herbal use as well as prescription drug interactions with herbals is highly important. The goal of this project is to develop, apply, and evaluate computational intelligence tools for mining conversational text for evidence of adverse events and side effects of herbals and prescription drugs reported by users of online communication resources relating to breast and prostate cancer. This project will use these informatics tools as the cornerstone of a new approach to post-marketing surveillance, and has been determined by the National Library of Medicine to be responsive to the stated Challenge Topic. This project will be conducted at the University of Pennsylvania School of Medicine, which contributes substantially to the local economy. In 2008, the School created 37,000 jobs and $5.4 billion in regional economic activity. This project will create or retain eight jobs. The School's ability to fill these positions is evident: in 2008, Penn received more than 24,600 applications for just 840 open staff research positions. Mining Internet Conversations for Evidence of Herbal-Associated Adverse Events There has been increasing discussion about the use of herbals with the advent of online resources such as message boards, blogs, and chat rooms. In mining the text from such online, new information about side effects and adverse events associated with herbal use as well as prescription drug interactions with herbals will be discovered. This is highly important for the health of the public, as it stands to create the framework for an herbal sentinel network system.              Mining Internet Conversations for Evidence of Herbal-Associated Adverse Events There has been increasing discussion about the use of herbals with the advent of online resources such as message boards, blogs, and chat rooms. In mining the text from such online, new information about side effects and adverse events associated with herbal use as well as prescription drug interactions with herbals will be discovered. This is highly important for the health of the public, as it stands to create the framework for an herbal sentinel network system.",Mining Internet Conversation For Evidence Of Herbal Association,7820824,RC1LM010342,"['Address', 'Adverse effects', 'Adverse event', 'Area', 'Attention', 'Body of uterus', 'Breast', 'Clinical', 'Communication', 'Complementary and alternative medicine', 'Controlled Vocabulary', 'Data', 'Disease', 'Drug Interactions', 'Drug Prescriptions', 'Economics', 'Future', 'Goals', 'Healthcare', 'Heavy Metals', 'Herb', 'Informatics', 'Information Technology', 'Intelligence', 'Internet', 'Investigation', 'Malignant neoplasm of prostate', 'Medical', 'Medicine', 'Methods', 'Mining', 'Monitor', 'Occupations', 'Patients', 'Pennsylvania', 'Pharmacologic Substance', 'Positioning Attribute', 'Process', 'Provider', 'Public Health', 'Reporting', 'Research', 'Resources', 'Schools', 'Semantics', 'Sentinel', 'System', 'Text', 'Toxic effect', 'United States Food and Drug Administration', 'United States National Library of Medicine', 'Universities', 'abstracting', 'malignant breast neoplasm', 'medical schools', 'meetings', 'novel strategies', 'population based', 'post-market', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,RC1,2009,482925,0.037081017118864246
"Mining Internet Conversation For Evidence Of Herbal Association    DESCRIPTION (provided by applicant): Mining Internet Conversations for Evidence of Herbal-Associated Adverse Events Abstract This application addresses broad Challenge Area (10), Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-102: Informatics for Post- Marketing Surveillance. Often, users of online resources such as discussion boards seek advice about topics they are hesitant to discuss with providers. One such topic is the use of herbal supplements. Relatively little is known about the use and effects of these supplements, primarily due to patient and provider reticence, but also owing to the lack of a formal reporting mechanism. As a result, adverse events and interactions possibly related to herbal use are difficult to evaluate in a population-based investigation. The potential impact for monitoring side effects and adverse events associated with herbal use as well as prescription drug interactions with herbals is highly important. The goal of this project is to develop, apply, and evaluate computational intelligence tools for mining conversational text for evidence of adverse events and side effects of herbals and prescription drugs reported by users of online communication resources relating to breast and prostate cancer. This project will use these informatics tools as the cornerstone of a new approach to post-marketing surveillance, and has been determined by the National Library of Medicine to be responsive to the stated Challenge Topic. This project will be conducted at the University of Pennsylvania School of Medicine, which contributes substantially to the local economy. In 2008, the School created 37,000 jobs and $5.4 billion in regional economic activity. This project will create or retain eight jobs. The School's ability to fill these positions is evident: in 2008, Penn received more than 24,600 applications for just 840 open staff research positions. Mining Internet Conversations for Evidence of Herbal-Associated Adverse Events There has been increasing discussion about the use of herbals with the advent of online resources such as message boards, blogs, and chat rooms. In mining the text from such online, new information about side effects and adverse events associated with herbal use as well as prescription drug interactions with herbals will be discovered. This is highly important for the health of the public, as it stands to create the framework for an herbal sentinel network system.              Mining Internet Conversations for Evidence of Herbal-Associated Adverse Events There has been increasing discussion about the use of herbals with the advent of online resources such as message boards, blogs, and chat rooms. In mining the text from such online, new information about side effects and adverse events associated with herbal use as well as prescription drug interactions with herbals will be discovered. This is highly important for the health of the public, as it stands to create the framework for an herbal sentinel network system.",Mining Internet Conversation For Evidence Of Herbal Association,7936953,RC1LM010342,"['Address', 'Adverse effects', 'Adverse event', 'Area', 'Attention', 'Breast', 'Clinical', 'Communication', 'Complementary and alternative medicine', 'Controlled Vocabulary', 'Data', 'Disease', 'Drug Interactions', 'Drug Prescriptions', 'Economics', 'Future', 'Goals', 'Healthcare', 'Heavy Metals', 'Herb', 'Informatics', 'Information Technology', 'Intelligence', 'Internet', 'Investigation', 'Malignant neoplasm of prostate', 'Medical', 'Medicine', 'Methods', 'Mining', 'Monitor', 'Occupations', 'Patients', 'Pennsylvania', 'Pharmacologic Substance', 'Positioning Attribute', 'Process', 'Provider', 'Public Health', 'Reporting', 'Research', 'Resources', 'Schools', 'Semantics', 'Sentinel', 'System', 'Text', 'Toxic effect', 'United States Food and Drug Administration', 'United States National Library of Medicine', 'Universities', 'abstracting', 'malignant breast neoplasm', 'medical schools', 'meetings', 'novel strategies', 'population based', 'post-market', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,RC1,2010,496998,0.037081017118864246
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7834605,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'depression', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2009,499818,0.044654323039112834
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7936999,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Epidemiology', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Mental Depression', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2010,499697,0.044654323039112834
"Comprehensive Clinical Decision Support for the Primary Care of Premature Infants    DESCRIPTION (provided by applicant):   Premature infants are a vulnerable population with multiple inter-related health problems that put them at risk for poor outcomes. Electronic health records capture large amounts of information that may help guide decisions, but existing alert and reminder-based clinical decision support (CDS) frameworks do not adequately apply multiple overlapping care guidelines to complex patient histories to produce coherent clinical recommendations. Our proposed study directly addresses the broad challenge area of 10 Information Technology for Processing Health Care Data for Research and the specific challenge topic 10-LM-102 Advanced Decision Support for Complex Clinical Decisions. This study will use a rules-based expert system embedded in an electronic health record (EHR) to extract, interpret, and present salient facts and recommendations related to the healthcare of premature infants. This proposal also meets the challenge of providing an immediate stimulus to the economy through the retention or creation of jobs and increased spending in the Delaware Valley region. The Children's Hospital of Philadelphia (CHOP) contributes substantially to the local economy. In 2008, CHOP's operations created and supported over 16,882 jobs in the region, and CHOP's total economic impact was over $2.01 billion. Moreover, through a combination of private donations, NIH funding, and allocations from its hospital operations, CHOP receives more total research support than any other children's hospital in the United States-$180 million in fiscal year 2007-2008. The current proposal will create or retain 5 jobs. The care of premature infants is a rapidly growing public health concern in the United States, with over 60,000 infants born in 2006 with a birth weight under 1500 grams1. With recent advances in neonatal care, more premature infants are surviving to discharge from the neonatal intensive care unit (NICU). Even though this high-risk group of patients is particularly sensitive to the care they receive after discharge, efforts to ensure high quality post-discharge care are haphazardly implemented. Electronic health records with embedded clinical decision support tools such as rules-based expert systems provide a natural opportunity to favorably affect the healthcare for these vulnerable infants. The complex decision-making for these infants must consider large numbers of variables that change over time. The matrices of rules required to cover all possible combinations of variables are huge. To date no such decision support tools have been implemented or evaluated to handle the complexity of decision-making required for the healthcare of premature infants. This project will use a prospective cluster randomized design to evaluate the success of a health information technology intervention to improve care quality for low birth weight (LBW) and very low birth weight (VLBW) premature infants from the time of intensive care nursery discharge through 24 months of age. The intervention will consist of (1) a real-time data mining tool functioning in the EHR that will organize large amounts of health information visually in a succinct time-line format; (2) a rules-based expert system that will forecast a schedule for upcoming preventive health assessments and interventions appropriate for LBW and VLBW infants, and (3) a suite of problem focused expert systems to guide decision-making related to the most prevalent co-morbidities and complications experienced by this vulnerable population. Evaluation will focus on three areas: (1) usability of the automated data-mining tool and expert system pre-implementation; (2) change in clinician knowledge of standard care process for LBW and VLBW infants pre- and post-intervention; and (3) change in care process outcomes in the intervention practices compared to the control practices. The proposed work will improve the capacity for delivering clinical decision support (CDS) in complex clinical domains. Rigorous evaluation of both the design phase and intervention phase will support publications regarding best practices for future CDS development. The approach of a standards-based web-service model with a modest custom programming ""footprint"" in the electronic health record (EHR) will facilitate the distribution of this and future CDS interventions to other healthcare organizations and EHR vendors. The proposed work will improve the capacity for delivering clinical decision support (CDS) in complex clinical domains. Rigorous evaluation of both the design phase and intervention phase will support publications regarding best practices for future CDS development. The approach of a standards-based web-service model with a modest custom programming ""footprint"" in the electronic health record (EHR) will facilitate the distribution of this and future CDS interventions to other healthcare organizations and EHR vendors.               PROJECT NARRATIVE The proposed work will improve the capacity for delivering clinical decision support (CDS) in complex clinical domains. Rigorous evaluation of both the design phase and intervention phase will support publications regarding best practices for future CDS development. The approach of a standards-based web-service model with a modest custom programming ""footprint"" in the electronic health record (EHR) will facilitate the distribution of this and future CDS interventions to other healthcare organizations and EHR vendors.",Comprehensive Clinical Decision Support for the Primary Care of Premature Infants,7825848,RC1LM010471,"['Address', 'Affect', 'Age-Months', 'Area', 'Birth Weight', 'Caring', 'Clinical', 'Comorbidity', 'Complex', 'Custom', 'Data', 'Decision Making', 'Delaware', 'Development', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Expert Systems', 'Funding', 'Future', 'Gestational Age', 'Guidelines', 'Health', 'Healthcare', 'Hospitals', 'Infant', 'Information Technology', 'Intensive Care', 'Intervention', 'Knowledge', 'Low Birth Weight Infant', 'Modeling', 'Neonatal', 'Neonatal Intensive Care Units', 'Nurseries', 'Occupations', 'Online Systems', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Phase', 'Philadelphia', 'Premature Infant', 'Preventive', 'Primary Health Care', 'Process', 'Public Health', 'Publications', 'Quality of Care', 'Randomized', 'Recommendation', 'Recording of previous events', 'Research', 'Research Support', 'Risk', 'Schedule', 'Services', 'Stimulus', 'Time', 'United States', 'United States National Institutes of Health', 'Vendor', 'Very Low Birth Weight Infant', 'Vulnerable Populations', 'Work', 'base', 'cohort', 'data mining', 'design', 'economic impact', 'experience', 'follow-up', 'health information technology', 'high risk', 'high risk infant', 'improved', 'meetings', 'operation', 'post intervention', 'programs', 'prospective', 'standard care', 'success', 'tool', 'usability']",NLM,CHILDREN'S HOSP OF PHILADELPHIA,RC1,2010,822567,0.039048057019637344
"Multi-source clinical Question Answering system    DESCRIPTION (provided by applicant):   / Abstract (Limit: 1 page) Our proposal addresses the following challenge area: 06-LM-101* Intelligent Search Tool for Answering Clinical Questions. Develop new computational approaches to information retrieval that would allow a clinician or clinical researcher to pose a single query that would result in search of multiple data sources to produce a coherent response that highlights key relevant information which may signal new insights for clinical research or patient care. Information that could help a clinician diagnose or manage a health condition, or help a clinical researcher explore the significance of issues that arise during a clinical trial, is scattered across many different types of resources, such as paper or electronic charts, trial protocols, published biomedical articles, or best-practice guidelines for care. Develop artificial intelligence and information retrieval approaches that allow a clinician or researcher confronting complex patient problems to pose a single query that will result in a search that appears to ""understand"" the question, a search that inspects multiple databases and brings findings together into a useful answer. Clinical question answering (cQA) systems focus on the physician needs usually at the point of care, or the investigator in the lab. The questions usually asked either require information highly specific to their patient, e.g. the patient's lab results or previous history, answered by the patient's health record, or a more general type of information usually answered through generally available information sources. QA systems enhance the results of search engines by providing a concise summary of relevant information along with source hits. PubMed (http://www.ncbi.nlm.nih.gov/pubmed/) is the most ubiquitous biomedical search engine, however because it is a search engine the information retrieved is based on keyword searches and is not presented in a form for immediate consumption; the user has to drill down into the content of the webpages to find the facts/statements of interest. Moreover, the information that the clinician needs is likely to be of different types, for example a definition of a syndrome in combination with specific actions triggered by a particular diagnosis for a particular patient. Such information resides in different sources - encyclopedic and the EMR - and has to be dynamically accessed and presented to the user in an easily digestible format. We propose to develop a unified platform for clinical QA from multiple sources of clinical and biomedical narrative that implements semantic processing of the questions by fusing two existing technologies - the Mayo clinical Text Analysis and Knowledge Extraction System and the University of Colorado's Question Answering System. The specific research questions we are aiming to answer are: ""How much effort is required to port a general semantic QA system to the clinical domain? How much additional domain-specific training is required? ""What is the accuracy of such a system? Question Answering in the clinical domain is an emerging area of research. The challenges in the field are mainly attributed to the number of components that require domain specific training along with strict system requirements in terms of high precision and recall complemented by an accessible and user-friendly presentation. Our approach to overcome them is to re-use components already in place as part of Mayo clinical Text Analysis and Knowledge Extraction System and the University of Colorado's Question Answering System. Our approach is innovative in bringing together information from encyclopedic sources and the EMR to present it into a unified form to the clinician at the point of care or the investigator in the lab. The technology for that is based on semantic language processing which aims at ""understanding"" the meaning of the question and the narrative. Our proposed system holds the potential to impact quality of healthcare and translational research. Our approach is feasible because it uses content already in the EMR at the Mayo Clinic along with general medical knowledge from multiple readily-available resources. The proposed system will be built off mature and tested components allowing a fast and robust delivery cycle. Our unique integration of technologies together with sophisticated statistical machine learning algorithms applied to rich linguistic knowledge about events, contradictions, semantic structure, and question-types, will allow us to build a system which significantly extends the range of possible question types and responses available to clinicians, and seamlessly fuses these to generate a response. Our proposed work represents a high impact area that has the potential to improve healthcare delivery because it addresses needs that have been well-documented and studied (Ely et al., 2005). We aim to provide a unified multi-source solution for semantic retrieval, access and summarization of relevant information at the point of care or the lab. As such, the proposed cQA has the potential to play a vital and important decision- support role for the physician or the biomedical investigator. (max 2-3 sentences) Clinical question answering (cQA) systems focus on the physician needs usually at the point of care, or the investigator in the lab. The questions usually asked either require information highly specific to their patient, e.g. the patient's lab results or previous history, answered by the patient's health record, or a more general type of information usually answered through generally available information sources. Our proposed work to provide a unified multi-source solution for semantic retrieval, access and summarization of relevant information at the point of care or the lab, represents a high impact area that has the potential to improve healthcare delivery because it addresses needs that have been well-documented and studied.               Relevance (max 2-3 sentences) Clinical question answering (cQA) systems focus on the physician needs usually at the point of care, or the investigator in the lab. The questions usually asked either require information highly specific to their patient, e.g. the patient's lab results or previous history, answered by the patient's health record, or a more general type of information usually answered through generally available information sources. Our proposed work to provide a unified multi-source solution for semantic retrieval, access and summarization of relevant information at the point of care or the lab, represents a high impact area that has the potential to improve healthcare delivery because it addresses needs that have been well-documented and studied.",Multi-source clinical Question Answering system,7936991,RC1LM010608,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Caring', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Colorado', 'Complement', 'Complex', 'Consumption', 'Data Sources', 'Databases', 'Diagnosis', 'Electronics', 'Environment', 'Event', 'Health', 'Information Retrieval', 'Knowledge', 'Knowledge Extraction', 'Linguistics', 'Machine Learning', 'Medical', 'Paper', 'Patient Care', 'Patients', 'Physician&apos', 's Role', 'Physicians', 'Play', 'Practice Guidelines', 'Protocols documentation', 'PubMed', 'Publishing', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Semantics', 'Signal Transduction', 'Solutions', 'Source', 'Structure', 'Syndrome', 'System', 'Technology', 'Testing', 'Text', 'Training', 'Translational Research', 'Universities', 'Work', 'abstracting', 'base', 'clinically relevant', 'health care delivery', 'health care quality', 'health record', 'improved', 'innovation', 'insight', 'interest', 'language processing', 'point of care', 'response', 'semantic processing', 'tool', 'user-friendly']",NLM,BOSTON CHILDREN'S HOSPITAL,RC1,2010,491408,0.0321111143662796
"Multi-source clinical Question Answering system    DESCRIPTION (provided by applicant):   / Abstract (Limit: 1 page) Our proposal addresses the following challenge area: 06-LM-101* Intelligent Search Tool for Answering Clinical Questions. Develop new computational approaches to information retrieval that would allow a clinician or clinical researcher to pose a single query that would result in search of multiple data sources to produce a coherent response that highlights key relevant information which may signal new insights for clinical research or patient care. Information that could help a clinician diagnose or manage a health condition, or help a clinical researcher explore the significance of issues that arise during a clinical trial, is scattered across many different types of resources, such as paper or electronic charts, trial protocols, published biomedical articles, or best-practice guidelines for care. Develop artificial intelligence and information retrieval approaches that allow a clinician or researcher confronting complex patient problems to pose a single query that will result in a search that appears to ""understand"" the question, a search that inspects multiple databases and brings findings together into a useful answer. Clinical question answering (cQA) systems focus on the physician needs usually at the point of care, or the investigator in the lab. The questions usually asked either require information highly specific to their patient, e.g. the patient's lab results or previous history, answered by the patient's health record, or a more general type of information usually answered through generally available information sources. QA systems enhance the results of search engines by providing a concise summary of relevant information along with source hits. PubMed (http://www.ncbi.nlm.nih.gov/pubmed/) is the most ubiquitous biomedical search engine, however because it is a search engine the information retrieved is based on keyword searches and is not presented in a form for immediate consumption; the user has to drill down into the content of the webpages to find the facts/statements of interest. Moreover, the information that the clinician needs is likely to be of different types, for example a definition of a syndrome in combination with specific actions triggered by a particular diagnosis for a particular patient. Such information resides in different sources - encyclopedic and the EMR - and has to be dynamically accessed and presented to the user in an easily digestible format. We propose to develop a unified platform for clinical QA from multiple sources of clinical and biomedical narrative that implements semantic processing of the questions by fusing two existing technologies - the Mayo clinical Text Analysis and Knowledge Extraction System and the University of Colorado's Question Answering System. The specific research questions we are aiming to answer are: ""How much effort is required to port a general semantic QA system to the clinical domain? How much additional domain-specific training is required? ""What is the accuracy of such a system? Question Answering in the clinical domain is an emerging area of research. The challenges in the field are mainly attributed to the number of components that require domain specific training along with strict system requirements in terms of high precision and recall complemented by an accessible and user-friendly presentation. Our approach to overcome them is to re-use components already in place as part of Mayo clinical Text Analysis and Knowledge Extraction System and the University of Colorado's Question Answering System. Our approach is innovative in bringing together information from encyclopedic sources and the EMR to present it into a unified form to the clinician at the point of care or the investigator in the lab. The technology for that is based on semantic language processing which aims at ""understanding"" the meaning of the question and the narrative. Our proposed system holds the potential to impact quality of healthcare and translational research. Our approach is feasible because it uses content already in the EMR at the Mayo Clinic along with general medical knowledge from multiple readily-available resources. The proposed system will be built off mature and tested components allowing a fast and robust delivery cycle. Our unique integration of technologies together with sophisticated statistical machine learning algorithms applied to rich linguistic knowledge about events, contradictions, semantic structure, and question-types, will allow us to build a system which significantly extends the range of possible question types and responses available to clinicians, and seamlessly fuses these to generate a response. Our proposed work represents a high impact area that has the potential to improve healthcare delivery because it addresses needs that have been well-documented and studied (Ely et al., 2005). We aim to provide a unified multi-source solution for semantic retrieval, access and summarization of relevant information at the point of care or the lab. As such, the proposed cQA has the potential to play a vital and important decision- support role for the physician or the biomedical investigator. (max 2-3 sentences) Clinical question answering (cQA) systems focus on the physician needs usually at the point of care, or the investigator in the lab. The questions usually asked either require information highly specific to their patient, e.g. the patient's lab results or previous history, answered by the patient's health record, or a more general type of information usually answered through generally available information sources. Our proposed work to provide a unified multi-source solution for semantic retrieval, access and summarization of relevant information at the point of care or the lab, represents a high impact area that has the potential to improve healthcare delivery because it addresses needs that have been well-documented and studied.               Relevance (max 2-3 sentences) Clinical question answering (cQA) systems focus on the physician needs usually at the point of care, or the investigator in the lab. The questions usually asked either require information highly specific to their patient, e.g. the patient's lab results or previous history, answered by the patient's health record, or a more general type of information usually answered through generally available information sources. Our proposed work to provide a unified multi-source solution for semantic retrieval, access and summarization of relevant information at the point of care or the lab, represents a high impact area that has the potential to improve healthcare delivery because it addresses needs that have been well-documented and studied.",Multi-source clinical Question Answering system,7842799,RC1LM010608,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Caring', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Colorado', 'Complement', 'Complex', 'Consumption', 'Data Sources', 'Databases', 'Diagnosis', 'Electronics', 'Environment', 'Event', 'Health', 'Information Retrieval', 'Knowledge', 'Knowledge Extraction', 'Linguistics', 'Machine Learning', 'Medical', 'Paper', 'Patient Care', 'Patients', 'Physician&apos', 's Role', 'Physicians', 'Play', 'Practice Guidelines', 'Protocols documentation', 'PubMed', 'Publishing', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Semantics', 'Signal Transduction', 'Solutions', 'Source', 'Structure', 'Syndrome', 'System', 'Technology', 'Testing', 'Text', 'Training', 'Translational Research', 'Universities', 'Work', 'abstracting', 'base', 'clinically relevant', 'health care delivery', 'health care quality', 'health record', 'improved', 'innovation', 'insight', 'interest', 'language processing', 'point of care', 'response', 'semantic processing', 'tool', 'user-friendly']",NLM,MAYO CLINIC ROCHESTER,RC1,2009,497477,0.0321111143662796
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9337267,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face Processing', 'Goals', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability', 'word learning']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,463061,0.012816186255126944
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9132834,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model building', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,463405,0.012816186255126944
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8936515,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model building', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,448348,0.012816186255126944
"Interactive machine learning methods for clinical natural language processing     DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3.             Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8818096,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,558372,0.012816186255126944
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8305149,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2012,129035,0.08582531248137433
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8077875,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2011,374000,0.08582531248137433
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,7866149,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2010,387500,0.08582531248137433
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8589822,R01LM010681,[' '],NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2012,237877,0.08582531248137433
"Toward Intelligent Display of Health Data:  A Qualitative Study of Use Patterns    DESCRIPTION (provided by applicant): As capabilities for storing and sharing electronic health data expand, it becomes increasingly important to classify, prioritize, and contextually link patient health data. Providers using electronic health records complain that it is difficult for them to rapidly find the information they need and that key information can be missed. Different data is important depending on details associated with the patient, the clinician who is accessing the data, and the context in which data are accessed. In this project we will employ knowledge elicitation methods to study information access patterns and priorities of clinicians. Our approach involves the novel use of recorded eye-tracking data from true clinical environments to support retrospective verbal protocol analysis of information access. Specifically, researchers will interview providers and ask them to describe what they were doing and thinking while watching video-playback of what the provider looked at, did, and said during actual information seeking in the context of patient care. We will use qualitative data analysis methods (constant comparative analysis with open and axial coding) to identify emerging themes related to information seeking in the context of intensive care at two institutions with very different processes for storing and presenting electronic health data. Our primary goal is to use the results of this effort to generate principles to improve the organization and prioritization of data in electronic health records. A secondary goal is to identify specific criteria for ranking the importance of electronic health data for future development of advanced computational methods that will support alternative display techniques to make it easy for caregivers to find and interpret relevant and important information quickly. Previous research has focused on either (1) qualitative research in the form of interviews or focus groups that emphasizes information that the provider can easily recall and lacks a realistic representation of how providers use data in the field, or (2) field observations or techniques such as key press data capture that lack explanatory power. Integrating field observation data and rich commentary through retrospective verbal protocol in the context of an eye-tracking video record of actual data use is an innovative technique to capitalize on strengths of both approaches. Researchers, designers, and developers of electronic health records can use the results of this effort toward better-organized and perhaps intelligent display of patient data to support clinical decisions. This research project is significant in its potential to increase efficiency in patient care through faster access and analysis of data and to improve safety by reducing the chances that critical information is overlooked or misinterpreted.           Efficient access to important patient data is critical to both patient safety and cost effectiveness of the current and future health care system. This project proposes a unique approach to eliciting provider descriptions of the relative importance of specific health data in the context of their own data use activities. These descriptions will be analyzed to identify emerging themes related to information seeking and principles that can be applied to the organization and prioritization of clinical health data. This proposal has significant implications for the design of electronic health records to support faster information access and to ensure that critical information is not missed.",Toward Intelligent Display of Health Data:  A Qualitative Study of Use Patterns,8326621,R21LM010700,"['Access to Information', 'Advanced Development', 'Appetitive Behavior', 'Behavior', 'Caregivers', 'Caring', 'Categories', 'Clinical', 'Code', 'Computational algorithm', 'Computers', 'Computing Methodologies', 'Conscious', 'Critical Care', 'Data', 'Data Analyses', 'Data Display', 'Data Sources', 'Databases', 'Development', 'Electronic Health Record', 'Electronics', 'Ensure', 'Environment', 'Eye', 'Focus Groups', 'Future', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Inpatients', 'Institution', 'Intensive Care', 'Intensive Care Units', 'Interview', 'Knowledge', 'Link', 'Methods', 'Nurses', 'Outcome', 'Paper', 'Patient Care', 'Patients', 'Pattern', 'Perception', 'Physicians', 'Physiology', 'Process', 'Protocols documentation', 'Provider', 'Published Comment', 'Qualitative Methods', 'Qualitative Research', 'Records', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Safety', 'Series', 'Source', 'Subconscious', 'Techniques', 'Thinking', 'Time', 'Trust', 'United States Department of Veterans Affairs', 'University Hospitals', 'Video Recording', 'base', 'clinical care', 'clinically relevant', 'comparative', 'cost effectiveness', 'design', 'digital', 'experience', 'improved', 'information organization', 'innovation', 'novel', 'patient safety', 'theories', 'tool']",NLM,DUKE UNIVERSITY,R21,2012,223866,0.05996975724578637
"Toward intelligent display of health data:  A qualitative study of use patterns    DESCRIPTION (provided by applicant): As capabilities for storing and sharing electronic health data expand, it becomes increasingly important to classify, prioritize, and contextually link patient health data. Providers using electronic health records complain that it is difficult for them to rapidly find the information they need and that key information can be missed. Different data is important depending on details associated with the patient, the clinician who is accessing the data, and the context in which data are accessed. In this project we will employ knowledge elicitation methods to study information access patterns and priorities of clinicians. Our approach involves the novel use of recorded eye-tracking data from true clinical environments to support retrospective verbal protocol analysis of information access. Specifically, researchers will interview providers and ask them to describe what they were doing and thinking while watching video-playback of what the provider looked at, did, and said during actual information seeking in the context of patient care. We will use qualitative data analysis methods (constant comparative analysis with open and axial coding) to identify emerging themes related to information seeking in the context of intensive care at two institutions with very different processes for storing and presenting electronic health data. Our primary goal is to use the results of this effort to generate principles to improve the organization and prioritization of data in electronic health records. A secondary goal is to identify specific criteria for ranking the importance of electronic health data for future development of advanced computational methods that will support alternative display techniques to make it easy for caregivers to find and interpret relevant and important information quickly. Previous research has focused on either (1) qualitative research in the form of interviews or focus groups that emphasizes information that the provider can easily recall and lacks a realistic representation of how providers use data in the field, or (2) field observations or techniques such as key press data capture that lack explanatory power. Integrating field observation data and rich commentary through retrospective verbal protocol in the context of an eye-tracking video record of actual data use is an innovative technique to capitalize on strengths of both approaches. Researchers, designers, and developers of electronic health records can use the results of this effort toward better-organized and perhaps intelligent display of patient data to support clinical decisions. This research project is significant in its potential to increase efficiency in patient care through faster access and analysis of data and to improve safety by reducing the chances that critical information is overlooked or misinterpreted.           Efficient access to important patient data is critical to both patient safety and cost effectiveness of the current and future health care system. This project proposes a unique approach to eliciting provider descriptions of the relative importance of specific health data in the context of their own data use activities. These descriptions will be analyzed to identify emerging themes related to information seeking and principles that can be applied to the organization and prioritization of clinical health data. This proposal has significant implications for the design of electronic health records to support faster information access and to ensure that critical information is not missed.",Toward intelligent display of health data:  A qualitative study of use patterns,8048669,R21LM010700,"['Access to Information', 'Advanced Development', 'Appetitive Behavior', 'Behavior', 'Caregivers', 'Caring', 'Categories', 'Clinical', 'Code', 'Computational algorithm', 'Computers', 'Computing Methodologies', 'Conscious', 'Critical Care', 'Data', 'Data Analyses', 'Data Display', 'Data Sources', 'Databases', 'Development', 'Electronic Health Record', 'Electronics', 'Ensure', 'Environment', 'Eye', 'Focus Groups', 'Future', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Inpatients', 'Institution', 'Intensive Care', 'Intensive Care Units', 'Interview', 'Knowledge', 'Link', 'Methods', 'Nurses', 'Outcome', 'Paper', 'Patient Care', 'Patients', 'Pattern', 'Perception', 'Physicians', 'Physiology', 'Process', 'Protocols documentation', 'Provider', 'Published Comment', 'Qualitative Methods', 'Qualitative Research', 'Records', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Safety', 'Series', 'Source', 'Subconscious', 'Techniques', 'Thinking', 'Time', 'Trust', 'United States Department of Veterans Affairs', 'University Hospitals', 'Video Recording', 'base', 'clinical care', 'clinically relevant', 'comparative', 'cost effectiveness', 'design', 'digital', 'experience', 'improved', 'information organization', 'innovation', 'novel', 'patient safety', 'theories', 'tool']",NLM,DUKE UNIVERSITY,R21,2011,190363,0.05996975724578637
"Linking Text Mining and Data Mining for Biomedical Knowledge Discovery    DESCRIPTION (provided by applicant):       Systems integration is becoming the driving force for the 21st century biology. Researchers are systematically tackling gene functions and complex regulatory processes by studying organisms at different levels of organization, from genomes, transcriptomes and proteomes to metabolomes and interactomes. To fully realize the value of such high-throughput data requires advanced bioinformatics for integration, mining, comparative analysis, and functional interpretation. Furthermore, with an ever-increasing volume of biomedical literature now available electronically, there is both a pressing need and a great opportunity to fully utilize text mining tools for knowledge extraction. However, despite recent advancements, text mining tools are not being broadly used by biologists. Such a gap is partly due to the lack of close interactions between the text mining and the biological user communities. The goal of this application is to develop a digital research infrastructure that links text mining with data mining in the systems biology context for biomedical knowledge discovery, with a special focus on the utility and usability of the system for real world scientific applications. Building upon the bioinformatics framework we have already developed, as well as our close interactions with the biomedical research community, the specific aims are to: (i) integrate existing text mining tools to identify and extract protein and network information from scientific literature, (ii) connect text mining and data mining with omics data integration and web interface to capture and visualize network knowledge, and (iii) conduct user studies, develop scientific use cases, provide training and outreach, and disseminate the system to the broad biomedical user community. The digital information resource proposed herein will serve as an enabling environment for biomedical researchers to decipher knowledge from a plethora of information available in the literature and public databases, gaining a better understanding of biological and disease processes as a key to the basic understanding of human health and disease.           NARRATIVE The proposed digital information resource will serve as an enabling environment for biomedical researchers to gain a better understanding of biological and disease processes in the systems biology context, thereby facilitating target discovery and disease diagnosis, and translating ""bench"" knowledge into ""bedside"" benefits.",Linking Text Mining and Data Mining for Biomedical Knowledge Discovery,8318246,G08LM010720,"['Adopted', 'Architecture', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biology', 'Biomedical Research', 'Communities', 'Complex', 'Computer software', 'Controlled Vocabulary', 'Data', 'Data Quality', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Education and Outreach', 'Educational workshop', 'Environment', 'Evaluation', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Goals', 'Health', 'Human', 'Imagery', 'Informatics', 'Information Networks', 'Information Resources', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Link', 'Literature', 'Maps', 'Methods', 'Metric', 'Mining', 'Molecular', 'Names', 'Online Systems', 'Ontology', 'Organism', 'Pathway interactions', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteome', 'PubMed', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Signal Pathway', 'Standardization', 'Surveys', 'System', 'Systems Biology', 'Systems Integration', 'Training', 'Translating', 'base', 'comparative', 'data integration', 'data mining', 'digital', 'disease diagnosis', 'driving force', 'gene function', 'knowledge base', 'open source', 'outreach', 'protein protein interaction', 'text searching', 'therapeutic target', 'tool', 'usability', 'web interface']",NLM,UNIVERSITY OF DELAWARE,G08,2012,143942,-0.01687613073347121
"Linking Text Mining and Data Mining for Biomedical Knowledge Discovery    DESCRIPTION (provided by applicant):       Systems integration is becoming the driving force for the 21st century biology. Researchers are systematically tackling gene functions and complex regulatory processes by studying organisms at different levels of organization, from genomes, transcriptomes and proteomes to metabolomes and interactomes. To fully realize the value of such high-throughput data requires advanced bioinformatics for integration, mining, comparative analysis, and functional interpretation. Furthermore, with an ever-increasing volume of biomedical literature now available electronically, there is both a pressing need and a great opportunity to fully utilize text mining tools for knowledge extraction. However, despite recent advancements, text mining tools are not being broadly used by biologists. Such a gap is partly due to the lack of close interactions between the text mining and the biological user communities. The goal of this application is to develop a digital research infrastructure that links text mining with data mining in the systems biology context for biomedical knowledge discovery, with a special focus on the utility and usability of the system for real world scientific applications. Building upon the bioinformatics framework we have already developed, as well as our close interactions with the biomedical research community, the specific aims are to: (i) integrate existing text mining tools to identify and extract protein and network information from scientific literature, (ii) connect text mining and data mining with omics data integration and web interface to capture and visualize network knowledge, and (iii) conduct user studies, develop scientific use cases, provide training and outreach, and disseminate the system to the broad biomedical user community. The digital information resource proposed herein will serve as an enabling environment for biomedical researchers to decipher knowledge from a plethora of information available in the literature and public databases, gaining a better understanding of biological and disease processes as a key to the basic understanding of human health and disease.           NARRATIVE The proposed digital information resource will serve as an enabling environment for biomedical researchers to gain a better understanding of biological and disease processes in the systems biology context, thereby facilitating target discovery and disease diagnosis, and translating ""bench"" knowledge into ""bedside"" benefits.",Linking Text Mining and Data Mining for Biomedical Knowledge Discovery,8130991,G08LM010720,"['Adopted', 'Architecture', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biology', 'Biomedical Research', 'Communities', 'Complex', 'Computer software', 'Controlled Vocabulary', 'Data', 'Data Quality', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Education and Outreach', 'Educational workshop', 'Environment', 'Evaluation', 'Future', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Goals', 'Health', 'Human', 'Imagery', 'Informatics', 'Information Networks', 'Information Resources', 'Knowledge', 'Knowledge Discovery', 'Knowledge Extraction', 'Link', 'Literature', 'Maps', 'Methods', 'Metric', 'Mining', 'Molecular', 'Names', 'Online Systems', 'Ontology', 'Organism', 'Pathway interactions', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteome', 'PubMed', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Signal Pathway', 'Standardization', 'Surveys', 'System', 'Systems Biology', 'Systems Integration', 'Training', 'Translating', 'base', 'comparative', 'data integration', 'data mining', 'digital', 'disease diagnosis', 'driving force', 'gene function', 'knowledge base', 'open source', 'outreach', 'protein protein interaction', 'text searching', 'therapeutic target', 'tool', 'usability', 'web interface']",NLM,UNIVERSITY OF DELAWARE,G08,2011,144000,-0.01687613073347121
"Linking Text Mining and Data Mining for Biomedical Knowledge Discovery    DESCRIPTION (provided by applicant):       Systems integration is becoming the driving force for the 21st century biology. Researchers are systematically tackling gene functions and complex regulatory processes by studying organisms at different levels of organization, from genomes, transcriptomes and proteomes to metabolomes and interactomes. To fully realize the value of such high-throughput data requires advanced bioinformatics for integration, mining, comparative analysis, and functional interpretation. Furthermore, with an ever-increasing volume of biomedical literature now available electronically, there is both a pressing need and a great opportunity to fully utilize text mining tools for knowledge extraction. However, despite recent advancements, text mining tools are not being broadly used by biologists. Such a gap is partly due to the lack of close interactions between the text mining and the biological user communities. The goal of this application is to develop a digital research infrastructure that links text mining with data mining in the systems biology context for biomedical knowledge discovery, with a special focus on the utility and usability of the system for real world scientific applications. Building upon the bioinformatics framework we have already developed, as well as our close interactions with the biomedical research community, the specific aims are to: (i) integrate existing text mining tools to identify and extract protein and network information from scientific literature, (ii) connect text mining and data mining with omics data integration and web interface to capture and visualize network knowledge, and (iii) conduct user studies, develop scientific use cases, provide training and outreach, and disseminate the system to the broad biomedical user community. The digital information resource proposed herein will serve as an enabling environment for biomedical researchers to decipher knowledge from a plethora of information available in the literature and public databases, gaining a better understanding of biological and disease processes as a key to the basic understanding of human health and disease.           NARRATIVE The proposed digital information resource will serve as an enabling environment for biomedical researchers to gain a better understanding of biological and disease processes in the systems biology context, thereby facilitating target discovery and disease diagnosis, and translating ""bench"" knowledge into ""bedside"" benefits.",Linking Text Mining and Data Mining for Biomedical Knowledge Discovery,7886453,G08LM010720,"['Adopted', 'Architecture', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biology', 'Biomedical Research', 'Communities', 'Complex', 'Computer software', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Quality', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Education and Outreach', 'Educational workshop', 'Environment', 'Evaluation', 'Future', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Goals', 'Health', 'Human', 'Imagery', 'Informatics', 'Information Networks', 'Information Resources', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Maps', 'Methods', 'Metric', 'Mining', 'Molecular', 'Names', 'Online Systems', 'Ontology', 'Organism', 'Pathway interactions', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteome', 'PubMed', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Signal Pathway', 'Standardization', 'Surveys', 'System', 'Systems Biology', 'Systems Integration', 'Training', 'Translating', 'base', 'comparative', 'data integration', 'data mining', 'digital', 'disease diagnosis', 'driving force', 'gene function', 'knowledge base', 'open source', 'outreach', 'protein protein interaction', 'text searching', 'therapeutic target', 'tool', 'usability', 'web interface']",NLM,UNIVERSITY OF DELAWARE,G08,2010,150000,-0.01687613073347121
"Voice Based, Workflow Enhancing, Primary Care Medical Data Input System    DESCRIPTION (provided by applicant): The adoption of electronic health records (EHR) in hospitals and physician offices has been widely promoted as a single solution to a wide variety of health care issues. Yet 84% of small and medium business (SMB) physician practices in the US have not adopted EHR systems. Interventional Dynamics Corporation (IDC) has conducted more than 200 primary care physician interviews, finding that the major disincentives to adoption are workflow delay and expense. The single greatest factor in the reduction of workflow speed is the data input process. IDC's proposed project has this specific aim: Utilize an innovative voice entry technique and open source code systems to develop a low-cost, automated solution to allow primary care physicians to complete a primary care note entirely during the patient examination process. The narrative speech input will be analyzed in a context-sensitive, domain-restricted manner to produce structured clinical data that can be readily integrated into standards-compliant electronic medical records. By using speech inputs that are converted directly to relevant EHR entries, physicians can increase the accuracy of their notes, eliminate third party transcription errors and avoid workflow delays. The project approach will include:    Further testing and final development of DocTalk, the IDC patent pending speech system that allows accurate natural language processing of structured medical information; Development of a proof-of-concept data system that converts physician voice input from voice to text to structured text to EHR data using domain enhanced open source code; The evaluation of the effectiveness of the proof-of-concept system against traditional EHR  input methods with the following goals: Achieve 50% or more reduction in charting time,  achieve 90% or more accuracy in output, and score greater than 4 of 5 on subjective  metrics including learnability, workflow fit, usability, and overall satisfaction. Successful completion of the proposed program will provide IDC with a viable technology platform that can immediately be useful to primary care physicians in generating structured documents for use with their current EHR platforms. Furthermore, the technology developed and refined within this program can be expanded in multiple ways.      PUBLIC HEALTH RELEVANCE:  The IDC technology is designed to circumvent the normal barriers to adoption in the SMB market and allow for quick increases in workflow and quality of patient care at a minimal price point. IDC will provide physicians who currently use pen and paper a more natural and faster way to input clinical data, eliminating time spent on hunt-and-peck keyboard entry or complicated EHR screen navigation. The system will generate structured clinical data that enables the exchange of health information, the portability of patient records, billing, data analytics (both local practice and public health), marketing, and other benefits, resulting in the reduction of overall healthcare costs.           Narrative The IDC technology is designed to circumvent the normal barriers to adoption in the SMB market and allow for quick increases in workflow and quality of patient care at a minimal price point. IDC will provide physicians who currently use pen and paper a more natural and faster way to input clinical data, eliminating time spent on hunt-and-peck keyboard entry or complicated EHR screen navigation. The system will generate structured clinical data that enables the exchange of health information, the portability of patient records, billing, data analytics (both local practice and public health), marketing, and other benefits, resulting in the reduction of overall healthcare costs.","Voice Based, Workflow Enhancing, Primary Care Medical Data Input System",7924457,R43LM010750,"['Adopted', 'Adoption', 'Architecture', 'Businesses', 'Clinical', 'Clinical Data', 'Code', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Storage and Retrieval', 'Development', 'Disincentive', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Genetic Transcription', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitals', 'Industry', 'Information Systems', 'International', 'Interview', 'Legal patent', 'Marketing', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Natural Language Processing', 'Output', 'Paper', 'Patient Care', 'Patients', 'Pediatric Surgical Procedures', 'Physicians', 'Physicians&apos', ' Offices', 'Price', 'Primary Care Physician', 'Primary Health Care', 'Process', 'Public Health Practice', 'Records', 'Research', 'Research Project Grants', 'Services', 'Solutions', 'Source Code', 'Speech', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Universities', 'Voice', 'base', 'billing data', 'cost', 'design', 'flexibility', 'innovation', 'open source', 'portability', 'programs', 'public health relevance', 'satisfaction', 'speech recognition', 'usability']",NLM,"VMT, INC.",R43,2010,241875,0.01591389223494799
"Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine    DESCRIPTION (provided by applicant):  The Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine will combine important research in several areas of biomedical text mining that are necessary to enable much-needed improvements in the process of conducting systematic reviews via a text mining enhanced workflow. Our consortium will undertake three specific aims to support this work:        Aim 1. Study how to create a metasearch engine and database that collects information from important systematic review sources, indexes this information consistently, and provides a robust information retrieval system with high recall and precision for accessing this expanded literature collection.        Aim 2. Study how to create a literature classification and ranking system that is customizable and trainable for each user, systematic review group, and systematic review topic. This supervised learning based classification and ranking system takes as input the list of retrieved articles corresponding to a given query, and outputs them grouped by article type, in order of predicted probability of relevance to an individual writing a systematic review on the given topic.        Aim 3. Study how to create a study aggregator that collects together articles that refer to the same underlying clinical trial. This will save reviewers work and time as they will now have automated assistance in determining whether two articles are independent data sources, or derive their evidence from the same primary data.        Taken together, these results will inform construction of a text mining pipeline system that will decrease the manual burden of systematic reviewers during the literature collection and review process, and increase the proportion of reviewer time spent synthesizing evidence and performing meta-analyses. The system will lead to a real difference in the rate that high-quality evidence reports can be compiled. Ultimately, the coverage, dissemination, and acceptance of evidence- based medicine in the biomedical community will increase, resulting in better and more cost- effective clinical care.           This project will improve the process of summarizing the best available medical evidence for a wide range of medical conditions. These summaries are utilized by both medical practitioners and policy makers as an essential component of providing higher quality, more cost-effective medical care for everyone.",Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine,8325177,R01LM010817,"['Affect', 'Area', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Trials', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Editorial Policies', 'Evidence Based Medicine', 'Evolution', 'Gold', 'Gray unit of radiation dose', 'Guidelines', 'Individual', 'Information Retrieval Systems', 'Information Services', 'Lead', 'Learning', 'Literature', 'MEDLINE', 'Manuals', 'Medical', 'Meta-Analysis', 'Metadata', 'Modeling', 'Output', 'Peer Review', 'Performance', 'Policy Maker', 'Practice Guidelines', 'Principal Investigator', 'Probability', 'Process', 'PubMed', 'Publishing', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Support', 'Review Literature', 'Savings', 'Source', 'Specific qualifier value', 'System', 'Testing', 'Text', 'Time', 'Training', 'Validation', 'Work', 'Writing', 'abstracting', 'base', 'clinical care', 'control trial', 'cost effective', 'improved', 'indexing', 'performance tests', 'programs', 'systematic review', 'text searching', 'web site']",NLM,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2012,517925,-0.0052046859854591185
"Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine    DESCRIPTION (provided by applicant):  The Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine will combine important research in several areas of biomedical text mining that are necessary to enable much-needed improvements in the process of conducting systematic reviews via a text mining enhanced workflow. Our consortium will undertake three specific aims to support this work:        Aim 1. Study how to create a metasearch engine and database that collects information from important systematic review sources, indexes this information consistently, and provides a robust information retrieval system with high recall and precision for accessing this expanded literature collection.        Aim 2. Study how to create a literature classification and ranking system that is customizable and trainable for each user, systematic review group, and systematic review topic. This supervised learning based classification and ranking system takes as input the list of retrieved articles corresponding to a given query, and outputs them grouped by article type, in order of predicted probability of relevance to an individual writing a systematic review on the given topic.        Aim 3. Study how to create a study aggregator that collects together articles that refer to the same underlying clinical trial. This will save reviewers work and time as they will now have automated assistance in determining whether two articles are independent data sources, or derive their evidence from the same primary data.        Taken together, these results will inform construction of a text mining pipeline system that will decrease the manual burden of systematic reviewers during the literature collection and review process, and increase the proportion of reviewer time spent synthesizing evidence and performing meta-analyses. The system will lead to a real difference in the rate that high-quality evidence reports can be compiled. Ultimately, the coverage, dissemination, and acceptance of evidence- based medicine in the biomedical community will increase, resulting in better and more cost- effective clinical care.           This project will improve the process of summarizing the best available medical evidence for a wide range of medical conditions. These summaries are utilized by both medical practitioners and policy makers as an essential component of providing higher quality, more cost-effective medical care for everyone.",Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine,8142241,R01LM010817,"['Affect', 'Area', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Trials', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Editorial Policies', 'Evidence Based Medicine', 'Evolution', 'Gold', 'Gray unit of radiation dose', 'Guidelines', 'Individual', 'Information Retrieval Systems', 'Information Services', 'Lead', 'Learning', 'Literature', 'MEDLINE', 'Manuals', 'Medical', 'Meta-Analysis', 'Metadata', 'Modeling', 'Output', 'Peer Review', 'Performance', 'Policy Maker', 'Practice Guidelines', 'Principal Investigator', 'Probability', 'Process', 'PubMed', 'Publishing', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Support', 'Review Literature', 'Savings', 'Source', 'Specific qualifier value', 'System', 'Testing', 'Text', 'Time', 'Training', 'Validation', 'Work', 'Writing', 'abstracting', 'base', 'clinical care', 'control trial', 'cost effective', 'improved', 'indexing', 'performance tests', 'programs', 'systematic review', 'text searching', 'web site']",NLM,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2011,502655,-0.0052046859854591185
"Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine    DESCRIPTION (provided by applicant):  The Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine will combine important research in several areas of biomedical text mining that are necessary to enable much-needed improvements in the process of conducting systematic reviews via a text mining enhanced workflow. Our consortium will undertake three specific aims to support this work:        Aim 1. Study how to create a metasearch engine and database that collects information from important systematic review sources, indexes this information consistently, and provides a robust information retrieval system with high recall and precision for accessing this expanded literature collection.        Aim 2. Study how to create a literature classification and ranking system that is customizable and trainable for each user, systematic review group, and systematic review topic. This supervised learning based classification and ranking system takes as input the list of retrieved articles corresponding to a given query, and outputs them grouped by article type, in order of predicted probability of relevance to an individual writing a systematic review on the given topic.        Aim 3. Study how to create a study aggregator that collects together articles that refer to the same underlying clinical trial. This will save reviewers work and time as they will now have automated assistance in determining whether two articles are independent data sources, or derive their evidence from the same primary data.        Taken together, these results will inform construction of a text mining pipeline system that will decrease the manual burden of systematic reviewers during the literature collection and review process, and increase the proportion of reviewer time spent synthesizing evidence and performing meta-analyses. The system will lead to a real difference in the rate that high-quality evidence reports can be compiled. Ultimately, the coverage, dissemination, and acceptance of evidence- based medicine in the biomedical community will increase, resulting in better and more cost- effective clinical care.           This project will improve the process of summarizing the best available medical evidence for a wide range of medical conditions. These summaries are utilized by both medical practitioners and policy makers as an essential component of providing higher quality, more cost-effective medical care for everyone.",Text Mining Pipeline to Accelerate Systematic Reviews in Evidence-Based Medicine,7950308,R01LM010817,"['Affect', 'Area', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Trials', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Editorial Policies', 'Evidence Based Medicine', 'Evolution', 'Gold', 'Gray unit of radiation dose', 'Guidelines', 'Individual', 'Information Retrieval Systems', 'Information Services', 'Lead', 'Learning', 'Literature', 'Manuals', 'Medical', 'Meta-Analysis', 'Metadata', 'Modeling', 'Output', 'Peer Review', 'Performance', 'Policy Maker', 'Practice Guidelines', 'Principal Investigator', 'Probability', 'Process', 'PubMed', 'Publishing', 'Randomized Controlled Trials', 'Recording of previous events', 'Reporting', 'Research', 'Research Support', 'Review Literature', 'Savings', 'Source', 'Specific qualifier value', 'System', 'Testing', 'Text', 'Time', 'Training', 'Validation', 'Work', 'Writing', 'abstracting', 'base', 'clinical care', 'control trial', 'cost', 'cost effective', 'improved', 'indexing', 'performance tests', 'programs', 'systematic review', 'text searching']",NLM,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2010,576558,-0.0052046859854591185
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),8318247,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Systematized Nomenclature of Medicine', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2012,366912,0.041118749624553634
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),8145183,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Systematized Nomenclature of Medicine', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2011,374400,0.041118749624553634
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),7950411,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patient Care', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2010,388125,0.041118749624553634
"A Hybrid General Natural Language Processing Architecture    DESCRIPTION (provided by applicant): Electronic medical records and exchanges offer new opportunities for the analysis of population health data; however, new methods in natural language processing (NLP) must first be developed to structure and codify these records, since most medical data is in the form of free text which cannot be stored and manipulated by computers. Once this is accomplished, population health data can be analyzed which will lead to better treatment guidelines, targeted drug therapy, and more cost effective care. Logical Semantics, Inc. (LSI) proposes to develop new statistical NLP methods for analyzing large scale medical domains. These methods will leverage LSI's semantic annotation technology, which has created the largest semantically annotated clinical corpus in the world. LSI's goal is to semantically index large medical record repositories accurately against propositions arranged in knowledge ontologies and make these indices available for text mining applications. The phase one research is focused on three specific aims that will lead to breakthroughs in the science of NLP: (1) Develop new statistical NLP algorithms employing a large semantically annotated medical corpus, (2) Semi-automate knowledge ontology generation, and (3) Develop and combine rule based with statistical NLP algorithms to create a superior hybrid NLP system. The achievement of these aims will result in computer systems that can extract the meaning from free text medical records so researchers, policy makers, and clinicians can use health analytics to improve healthcare.      PUBLIC HEALTH RELEVANCE: Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.           Project Narrative Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.",A Hybrid General Natural Language Processing Architecture,7996937,R43LM010846,"['Achievement', 'Address', 'Algorithms', 'Architecture', 'Businesses', 'Caring', 'Clinical', 'Communities', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Diagnosis', 'Discipline', 'Generations', 'Goals', 'Guidelines', 'Health', 'Healthcare', 'Hybrids', 'Knowledge', 'Lead', 'Legal patent', 'Linguistics', 'Logic', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Mining', 'Natural Language Processing', 'Ontology', 'Pattern', 'Pharmacotherapy', 'Phase', 'Policy Maker', 'Process', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Work', 'abstracting', 'base', 'cost effective', 'improved', 'indexing', 'knowledge base', 'operation', 'phrases', 'population health', 'public health relevance', 'repository', 'stem', 'success', 'text searching', 'tool']",NLM,"LOGICAL SEMANTICS, INC.",R43,2010,148180,0.03526869066143555
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8536940,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2013,292186,0.08598627098971519
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8326648,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2012,318393,0.08598627098971519
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8182025,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2011,325163,0.08598627098971519
"Mapping the Drugome: predictive network approaches to drug safety surveillance    DESCRIPTION (provided by applicant):       This application for the K99/R00 ""Pathway to Independence"" program aims to support Dr. Aurel Cami's development into an independent investigator in the field of Biomedical Informatics. The proposed career development period consists of a two-year mentored phase and a three-year independent phase. During the first phase, mentored by Drs. Reis, Kohane, Szolovits, and Manzi, the applicant will obtain formal training in drug safety and in biostatistics/machine learning methods for developing advanced predictive network models. This training will provide the groundwork for the proposed research project. The overall goal of this project is to develop novel surveillance approaches that leverage the inherent network structure of drug safety relationships across the entire drugome in order to predict adverse events earlier and more accurately. The project has four specific aims: 1. Construct and characterize integrated Drug Safety Network representations of the drugome. 2. Develop predictive network models to identify unknown drug-AE associations. 3. Develop predictive network models to identify unknown drug-drug-AE interactions. 4. Systematically evaluate model performance, both retrospectively and prospectively. The preliminary research studies have shown that predictive network models can sensitively and specifically detect drug-AE associations and drug-drug interactions, providing strong motivation for the proposed research. With a background in predictive network modeling and public health drug surveillance, Dr. Cami is highly qualified to conduct the proposed research. This project brings together a broad, interdisciplinary team of mentor, co-mentors and advisors with extensive combined experience in every aspect of the proposed research.           Project Narrative  Some drugs that are approved for sale to the public may have dangerous unknown side-effects. It is important to detect these unknown side effects as soon as possible in order to prevent serious illness or death. This project will help protect the public health by improving the ability to detect unknown dangerous drug side effects earlier and more reliably.",Mapping the Drugome: predictive network approaches to drug safety surveillance,8661787,R00LM011014,"['Advanced Development', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Biological', 'Biometry', 'Boxing', 'Cessation of life', 'Data', 'Databases', 'Development', 'Drug Interactions', 'Electronics', 'Encapsulated', 'Evaluation', 'Event', 'Goals', 'Graph', 'Health', 'Hydrophobicity', 'Individual', 'Insurance Carriers', 'Knowledge', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motivation', 'Neighborhoods', 'Network-based', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Predictive Value', 'Principal Investigator', 'Process', 'Property', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Project Grants', 'Safety', 'Sales', 'Sensitivity and Specificity', 'Source', 'Speed', 'Surveillance Methods', 'Taxonomy', 'Testing', 'Time', 'Training', 'Translational Research', 'Validation', 'Work', 'base', 'biomedical informatics', 'body system', 'career development', 'design', 'drug mechanism', 'drug structure', 'drug withdrawal', 'experience', 'heuristics', 'improved', 'mortality', 'network models', 'novel', 'post-market', 'predictive modeling', 'prevent', 'programs', 'prospective', 'research study', 'research to practice', 'screening', 'software development']",NLM,BOSTON CHILDREN'S HOSPITAL,R00,2014,245479,0.03727757320476106
"Mapping the Drugome: predictive network approaches to drug safety surveillance    DESCRIPTION (provided by applicant):       This application for the K99/R00 ""Pathway to Independence"" program aims to support Dr. Aurel Cami's development into an independent investigator in the field of Biomedical Informatics. The proposed career development period consists of a two-year mentored phase and a three-year independent phase. During the first phase, mentored by Drs. Reis, Kohane, Szolovits, and Manzi, the applicant will obtain formal training in drug safety and in biostatistics/machine learning methods for developing advanced predictive network models. This training will provide the groundwork for the proposed research project. The overall goal of this project is to develop novel surveillance approaches that leverage the inherent network structure of drug safety relationships across the entire drugome in order to predict adverse events earlier and more accurately. The project has four specific aims: 1. Construct and characterize integrated Drug Safety Network representations of the drugome. 2. Develop predictive network models to identify unknown drug-AE associations. 3. Develop predictive network models to identify unknown drug-drug-AE interactions. 4. Systematically evaluate model performance, both retrospectively and prospectively. The preliminary research studies have shown that predictive network models can sensitively and specifically detect drug-AE associations and drug-drug interactions, providing strong motivation for the proposed research. With a background in predictive network modeling and public health drug surveillance, Dr. Cami is highly qualified to conduct the proposed research. This project brings together a broad, interdisciplinary team of mentor, co-mentors and advisors with extensive combined experience in every aspect of the proposed research.           Project Narrative  Some drugs that are approved for sale to the public may have dangerous unknown side-effects. It is important to detect these unknown side effects as soon as possible in order to prevent serious illness or death. This project will help protect the public health by improving the ability to detect unknown dangerous drug side effects earlier and more reliably.",Mapping the Drugome: predictive network approaches to drug safety surveillance,8588740,R00LM011014,"['Advanced Development', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Biological', 'Biometry', 'Boxing', 'Cessation of life', 'Data', 'Databases', 'Development', 'Drug Interactions', 'Electronics', 'Encapsulated', 'Evaluation', 'Event', 'Goals', 'Graph', 'Health', 'Hydrophobicity', 'Individual', 'Insurance Carriers', 'Knowledge', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motivation', 'Neighborhoods', 'Network-based', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Predictive Value', 'Principal Investigator', 'Process', 'Property', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Project Grants', 'Safety', 'Sales', 'Sensitivity and Specificity', 'Source', 'Speed', 'Surveillance Methods', 'Taxonomy', 'Testing', 'Time', 'Training', 'Translational Research', 'Validation', 'Work', 'base', 'biomedical informatics', 'body system', 'career development', 'design', 'drug mechanism', 'drug structure', 'drug withdrawal', 'experience', 'heuristics', 'improved', 'mortality', 'network models', 'novel', 'post-market', 'predictive modeling', 'prevent', 'programs', 'prospective', 'research study', 'research to practice', 'screening', 'software development']",NLM,BOSTON CHILDREN'S HOSPITAL,R00,2013,187020,0.03727757320476106
"Mapping the Drugome: predictive network approaches to drug safety surveillance    DESCRIPTION (provided by applicant):       This application for the K99/R00 ""Pathway to Independence"" program aims to support Dr. Aurel Cami's development into an independent investigator in the field of Biomedical Informatics. The proposed career development period consists of a two-year mentored phase and a three-year independent phase. During the first phase, mentored by Drs. Reis, Kohane, Szolovits, and Manzi, the applicant will obtain formal training in drug safety and in biostatistics/machine learning methods for developing advanced predictive network models. This training will provide the groundwork for the proposed research project. The overall goal of this project is to develop novel surveillance approaches that leverage the inherent network structure of drug safety relationships across the entire drugome in order to predict adverse events earlier and more accurately. The project has four specific aims: 1. Construct and characterize integrated Drug Safety Network representations of the drugome. 2. Develop predictive network models to identify unknown drug-AE associations. 3. Develop predictive network models to identify unknown drug-drug-AE interactions. 4. Systematically evaluate model performance, both retrospectively and prospectively. The preliminary research studies have shown that predictive network models can sensitively and specifically detect drug-AE associations and drug-drug interactions, providing strong motivation for the proposed research. With a background in predictive network modeling and public health drug surveillance, Dr. Cami is highly qualified to conduct the proposed research. This project brings together a broad, interdisciplinary team of mentor, co-mentors and advisors with extensive combined experience in every aspect of the proposed research.           Project Narrative  Some drugs that are approved for sale to the public may have dangerous unknown side-effects. It is important to detect these unknown side effects as soon as possible in order to prevent serious illness or death. This project will help protect the public health by improving the ability to detect unknown dangerous drug side effects earlier and more reliably.",Mapping the Drugome: predictive network approaches to drug safety surveillance,8231483,K99LM011014,"['Advanced Development', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Biological', 'Biometry', 'Boxing', 'Cessation of life', 'Data', 'Databases', 'Development', 'Drug Interactions', 'Electronics', 'Encapsulated', 'Evaluation', 'Event', 'Goals', 'Graph', 'Health', 'Hydrophobicity', 'Individual', 'Insurance Carriers', 'Knowledge', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motivation', 'Neighborhoods', 'Network-based', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Predictive Value', 'Principal Investigator', 'Process', 'Property', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Project Grants', 'Safety', 'Sales', 'Screening procedure', 'Sensitivity and Specificity', 'Source', 'Speed', 'Surveillance Methods', 'Taxonomy', 'Testing', 'Time', 'Training', 'Translational Research', 'Validation', 'Work', 'base', 'biomedical informatics', 'body system', 'career development', 'design', 'drug mechanism', 'drug structure', 'drug withdrawal', 'experience', 'heuristics', 'improved', 'mortality', 'network models', 'novel', 'post-market', 'predictive modeling', 'prevent', 'programs', 'prospective', 'research study', 'research to practice', 'software development']",NLM,BOSTON CHILDREN'S HOSPITAL,K99,2012,130845,0.03727757320476106
"Mapping the Drugome: predictive network approaches to drug safety surveillance    DESCRIPTION (provided by applicant):       This application for the K99/R00 ""Pathway to Independence"" program aims to support Dr. Aurel Cami's development into an independent investigator in the field of Biomedical Informatics. The proposed career development period consists of a two-year mentored phase and a three-year independent phase. During the first phase, mentored by Drs. Reis, Kohane, Szolovits, and Manzi, the applicant will obtain formal training in drug safety and in biostatistics/machine learning methods for developing advanced predictive network models. This training will provide the groundwork for the proposed research project. The overall goal of this project is to develop novel surveillance approaches that leverage the inherent network structure of drug safety relationships across the entire drugome in order to predict adverse events earlier and more accurately. The project has four specific aims: 1. Construct and characterize integrated Drug Safety Network representations of the drugome. 2. Develop predictive network models to identify unknown drug-AE associations. 3. Develop predictive network models to identify unknown drug-drug-AE interactions. 4. Systematically evaluate model performance, both retrospectively and prospectively. The preliminary research studies have shown that predictive network models can sensitively and specifically detect drug-AE associations and drug-drug interactions, providing strong motivation for the proposed research. With a background in predictive network modeling and public health drug surveillance, Dr. Cami is highly qualified to conduct the proposed research. This project brings together a broad, interdisciplinary team of mentor, co-mentors and advisors with extensive combined experience in every aspect of the proposed research.           Project Narrative  Some drugs that are approved for sale to the public may have dangerous unknown side-effects. It is important to detect these unknown side effects as soon as possible in order to prevent serious illness or death. This project will help protect the public health by improving the ability to detect unknown dangerous drug side effects earlier and more reliably.",Mapping the Drugome: predictive network approaches to drug safety surveillance,8090803,K99LM011014,"['Advanced Development', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Biological', 'Biometry', 'Boxing', 'Cessation of life', 'Data', 'Databases', 'Development', 'Drug Interactions', 'Electronics', 'Encapsulated', 'Evaluation', 'Event', 'Goals', 'Graph', 'Health', 'Hydrophobicity', 'Individual', 'Insurance Carriers', 'Knowledge', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motivation', 'Neighborhoods', 'Network-based', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Predictive Value', 'Principal Investigator', 'Process', 'Property', 'Public Health', 'Qualifying', 'Research', 'Research Personnel', 'Research Project Grants', 'Safety', 'Sales', 'Screening procedure', 'Sensitivity and Specificity', 'Source', 'Speed', 'Surveillance Methods', 'Taxonomy', 'Testing', 'Time', 'Training', 'Translational Research', 'Validation', 'Work', 'base', 'biomedical informatics', 'body system', 'career development', 'design', 'drug mechanism', 'drug structure', 'drug withdrawal', 'experience', 'heuristics', 'improved', 'mortality', 'network models', 'novel', 'post-market', 'predictive modeling', 'prevent', 'programs', 'prospective', 'research study', 'research to practice', 'software development']",NLM,BOSTON CHILDREN'S HOSPITAL,K99,2011,133515,0.03727757320476106
"An Information Fusion Approach to Longitudinal Health Records DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted. Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8906937,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved', 'screening']",NLM,OHIO STATE UNIVERSITY,R01,2015,297811,0.05378504425085493
"An Information Fusion Approach to Longitudinal Health Records     DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted.                  Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8722624,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved', 'screening']",NLM,OHIO STATE UNIVERSITY,R01,2014,300537,0.05378504425085493
"An Information Fusion Approach to Longitudinal Health Records     DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted.                  Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8532982,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved', 'screening']",NLM,OHIO STATE UNIVERSITY,R01,2013,312584,0.05378504425085493
"An Information Fusion Approach to Longitudinal Health Records     DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted.                  Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8373437,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved']",NLM,OHIO STATE UNIVERSITY,R01,2012,341342,0.05378504425085493
"Advancing Multi-Omics and Electronic Health Records Computational Methodologies PROJECT SUMMARY  Phenomic advances from large-scale electronic health records (EHR) linked to DNA biobanks have pioneered an efficient approach to genetic discovery that has transformed human genetic studies, with the enormous potential to provide constraints on relevant biological mechanisms on a wide spectrum of human phenotypes. Nevertheless, our understanding of the downstream molecular consequences of genetic associations remains limited and impedes our ability to develop novel therapeutic strategies for complex diseases. Given their enormous discovery potential for human genomics and precision medicine, genetic analyses in diverse populations offer unprecedented opportunities to identify causal genetic mechanisms underlying human trait variation.  This research proposal aims to address these convergent developments and critical gaps and to exert a powerful influence on efforts to expand our understanding of disease mechanisms and therapeutic possibilities. Here we hypothesize that a comprehensive multi- omic, phenomic, and trans-ethnic computational methodology will provide a robust and rigorous framework. This proposal thus has the following aims: AIM 1: Develop a regularized regression based methodology and a deep learning framework to improve characterization of the genetic architecture of gene expression and to build robust prediction models, extending a Transcriptome-Wide Association Study (TWAS) methodology (called PrediXcan) that we developed. AIM 2: Develop statistical causal modeling of trait-associated genetic variation through a convergent TWAS and Mendelian Randomization approach and apply it to thousands of human traits with available GWAS and EHR data. AIM 3: Develop analytic approaches and software tools to further genetic analyses in admixed and multi-ethnic populations and to lay the groundwork for trans-ethnic multi-omic methodologies, using EHR data (e.g., BioVU, UK Biobank, All of Us). PUBLIC HEALTH RELEVANCE We will develop a comprehensive multi-omic, phenomic, and trans-ethnic computational methodology that bridges the gap between Genetic Epidemiology and Functional Genomics. This research provides a rigorous framework for investigating relevant mechanisms underlying complex traits, including disease risk and quantitative traits. We will leverage and integrate high- dimensional molecular data, electronic health records, and genetic studies in diverse populations.",Advancing Multi-Omics and Electronic Health Records Computational Methodologies,9979509,R01HG011138,"['Address', 'Algorithms', 'All of Us Research Program', 'Alleles', 'Biological', 'Catalogs', 'Chromatin', 'Complex', 'Computing Methodologies', 'DNA', 'Data', 'Data Set', 'Development', 'Discipline', 'Disease', 'Electronic Health Record', 'Estrogen receptor positive', 'Expression Profiling', 'Gene Expression', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomic medicine', 'Genomics', 'Heterogeneity', 'Human', 'Human Genetics', 'Image', 'Link', 'Machine Learning', 'Methodological Studies', 'Methodology', 'Methylation', 'Modeling', 'Molecular', 'Molecular Analysis', 'Nature', 'Performance', 'Phenotype', 'Population', 'Population Heterogeneity', 'RNA', 'Randomized', 'Regulation', 'Regulatory Element', 'Research', 'Research Proposals', 'Resources', 'Robotics', 'Single Nucleotide Polymorphism', 'Software Tools', 'Therapeutic', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Populations', 'Variant', 'base', 'biobank', 'causal model', 'cell type', 'comorbidity', 'computerized tools', 'data warehouse', 'deep learning', 'disorder risk', 'functional genomics', 'genetic analysis', 'genetic architecture', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genomic data', 'high dimensionality', 'histone modification', 'human genomics', 'improved', 'multiple omics', 'novel therapeutics', 'phenome', 'phenomics', 'pleiotropism', 'precision medicine', 'predictive modeling', 'protein metabolite', 'public health relevance', 'recruit', 'repository', 'response', 'trait', 'transcriptome']",NHGRI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,330670,0.02195313383188226
"Applying NLP to Free Text as an EHR Data Capture Method to Improve EHR Usability     DESCRIPTION (provided by applicant): This proposal aims to ensure the ability of ""NLP-Standalone-or-Hybrid Documentation,"" a method of EHR data capture involving Natural Language Processing and possibly also standard EHR data capture, to improve the usability of EHR by reducing documentation time, increasing documentation quality, and increasing clinician satisfaction. Problem to be Addressed. Limited usability of the Electronic Health Record (""EHR"") and lack of standardized terminology impedes EHR adoption and optimal use, and therefore hinders realization of a universally interoperable and evidence-based reportable health care system. Large amounts of time required for documentation, low clinician satisfaction, and incomplete documentation are problems plaguing EHR. Innovation. Current research has demonstrated that NLP may be used for EHR data capture. ZyDoc is furthering the state of research by assessing the capability of NLP-Standalone-or-Hybrid Documentation to improve EHR usability along several criteria. Long Term Goal. By enabling interoperability and improving EHR usability, through improving clinician satisfaction, improving documentation quality, and reducing data capture time, MediSapien will encourage widespread EHR adoption and optimal use with structured data. Phase I Summary. The purpose of the first Specific Aim of this grant proposal is to ensure that NLP- Standalone-or-Hybrid Documentation is capable of improving clinician satisfaction, efficiency, and documentation quality, relative to standard EHR data capture methods. The purpose of the second Specific Aim is to improve the accuracy of MediSapien's coding. These Specific Aims will ensure the technical feasibility of NLP-Standalone-or-Hybrid Documentation and MediSapien for improving EHR usability. Phase II Objectives. In Phase II, ZyDoc will complete product development, beta test MediSapien at two hospitals, and measure the product's impact on clinical outcomes or documentation results. Commercial Opportunity. ZyDoc will offer MediSapien as a modular component by partnering with vendors that combine MediSapien in their own solutions, enabling their clients to meet EHR meaningful use standards.        PUBLIC HEALTH RELEVANCE: Limited usability of the Electronic Health Record (""EHR"") and lack of standardized terminology impedes EHR adoption and meaningful use, and therefore hinders realization of a universally interoperable and evidence- based reportable health care system. This proposal aims to prove that EHR usability can be increased by applying NLP and other technologies to convert dictated and transcribed unstructured text to structured data and inserting it into the EHR. Achievement of this result will encourage optimal EHR use with searchable, structured data that will enable interoperability.                  Limited usability of the Electronic Health Record (""EHR"") and lack of standardized terminology impedes EHR adoption and meaningful use, and therefore hinders realization of a universally interoperable and evidence- based reportable health care system. This proposal aims to prove that EHR usability can be increased by applying NLP and other technologies to convert dictated and transcribed unstructured text to structured data and inserting it into the EHR. Achievement of this result will encourage optimal EHR use with searchable, structured data that will enable interoperability.                ",Applying NLP to Free Text as an EHR Data Capture Method to Improve EHR Usability,8314587,R43LM011165,"['Achievement', 'Address', 'Adoption', 'Algorithms', 'Applications Grants', 'Client', 'Clinical', 'Code', 'Computer Assisted', 'Data', 'Documentation', 'Electronic Health Record', 'Ensure', 'Genetic Transcription', 'Goals', 'Health', 'Healthcare Systems', 'Hospitals', 'Hybrids', 'ICD-10-CM', 'ICD-9-CM', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Logical Observation Identifiers Names and Codes', 'Maps', 'Measures', 'Medical Informatics', 'Methods', 'Mus', 'Natural Language Processing', 'Outcome', 'Output', 'Patients', 'Phase', 'Physicians', 'Plague', 'Process', 'Provider', 'Records', 'Relative (related person)', 'Research', 'Risk', 'Solutions', 'Speech', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Teaching Hospitals', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Vendor', 'base', 'clinical care', 'commercial application', 'evidence base', 'expectation', 'improved', 'innovation', 'interoperability', 'medical specialties', 'meetings', 'novel', 'product development', 'prospective', 'research study', 'satisfaction', 'usability']",NLM,"ZYDOC MEDICAL TRANSCRIPTION, LLC",R43,2012,150000,0.09529042370861557
"Social Media Mining for Pharmacovigilance Project Summary Drugs undergo extensive testing in animals and clinical trials in humans before they are marketed for widespread use. Pre-market testing produces reasonably high quality information about the efficacy of the drug as a treatment for the condition for which it was approved, but gives a very incomplete picture of the drug's safety. It is only after a drug is marketed and used on a more widespread basis over longer periods of time that it is possible to identify other effects, such as rare but serious adverse effects, or those that are more common in the special subgroups excluded from the trial (such as pregnant women), or effects of long-term use of the drug, among others. Despite the increase in research in the past years exploring social media data for pharmacovigilance, and the evidence that it indeed can bring forward the patient perspective, there is no systematic approach to collect and annotate such data for research purposes. This renewal builds on our prior research and natural language processing (NLP) methods for social media mining in pharmacovigilance to make the collection of social media data about medication use precise and systematic enough to be useful to researchers and the public, alongside established sources such as the FDA's data and other public collections of drug adverse event data. It presents innovative methods to automatically collect and analyze longitudinal health data, piloting methods for interventions through the same media that can inform the public and help validate the automatic methods. As validation, we include a comparison to an existing reference standard for adverse effects that integrates FDA's data and HER data, as well as specific case studies focused on (Aim 3.1) the use of NSAIDs and anti-depressants in pregnancy and (Aim 3.2) factors for non-adherence. Project Narrative Pre-market testing of medications produces reasonably high quality information about the efficacy of the drug as a treatment for the condition for which it was approved, but gives a very incomplete picture of the drug's safety. It is only after a drug is marketed and used on a more widespread basis over longer periods of time that it is possible to identify other effects, such as rare but serious adverse effects, or those that are more common in the special subgroups excluded from the trial (such as pregnant women), or effects of long-term use of the drug, among others. This renewal application builds on our prior research and natural language processing (NLP), developing novel methods for data extraction that makes it possible to integrate information from social media with existing drug safety information and extract health data over time.",Social Media Mining for Pharmacovigilance,9933089,R01LM011176,"['Address', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Affect', 'Agreement', 'Alcohol consumption', 'Animals', 'Antidepressive Agents', 'Area', 'Behavior', 'Case Study', 'Case-Control Studies', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Collection', 'Complement', 'Congenital Abnormality', 'Consent', 'Control Groups', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Drug usage', 'Electronic Health Record', 'Evaluation', 'Event', 'Fetal Death', 'Funding', 'General Population', 'Goals', 'Health', 'Health Care Costs', 'Health Personnel', 'Hemorrhage', 'Hepatic', 'Human', 'Hypersensitivity', 'Intake', 'Intervention', 'Kidney', 'Kidney Failure', 'Label', 'Lead', 'Literature', 'Live Birth', 'Long-Term Effects', 'Low Birth Weight Infant', 'MEDLINE', 'Manuals', 'Marketing', 'Medical', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Natural Language Processing', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Pregnancy', 'Pregnancy Outcome', 'Pregnant Women', 'Premature Birth', 'Public Health', 'Publications', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Signal Transduction', 'Smoking', 'Source', 'Spontaneous abortion', 'Standardization', 'Subgroup', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Unified Medical Language System', 'Validation', 'Vocabulary', 'Work', 'cohort', 'dosage', 'drug efficacy', 'epidemiological model', 'epidemiology study', 'health data', 'indexing', 'innovation', 'interest', 'language processing', 'medication compliance', 'medication safety', 'novel', 'pharmacovigilance', 'side effect', 'social media', 'systematic review', 'treatment duration']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2020,610315,0.03779701380859509
"Social Media Mining for Pharmacovigilance Project Summary Drugs undergo extensive testing in animals and clinical trials in humans before they are marketed for widespread use. Pre-market testing produces reasonably high quality information about the efficacy of the drug as a treatment for the condition for which it was approved, but gives a very incomplete picture of the drug's safety. It is only after a drug is marketed and used on a more widespread basis over longer periods of time that it is possible to identify other effects, such as rare but serious adverse effects, or those that are more common in the special subgroups excluded from the trial (such as pregnant women), or effects of long-term use of the drug, among others. Despite the increase in research in the past years exploring social media data for pharmacovigilance, and the evidence that it indeed can bring forward the patient perspective, there is no systematic approach to collect and annotate such data for research purposes. This renewal builds on our prior research and natural language processing (NLP) methods for social media mining in pharmacovigilance to make the collection of social media data about medication use precise and systematic enough to be useful to researchers and the public, alongside established sources such as the FDA's data and other public collections of drug adverse event data. It presents innovative methods to automatically collect and analyze longitudinal health data, piloting methods for interventions through the same media that can inform the public and help validate the automatic methods. As validation, we include a comparison to an existing reference standard for adverse effects that integrates FDA's data and HER data, as well as specific case studies focused on (Aim 3.1) the use of NSAIDs and anti-depressants in pregnancy and (Aim 3.2) factors for non-adherence. Project Narrative Pre-market testing of medications produces reasonably high quality information about the efficacy of the drug as a treatment for the condition for which it was approved, but gives a very incomplete picture of the drug's safety. It is only after a drug is marketed and used on a more widespread basis over longer periods of time that it is possible to identify other effects, such as rare but serious adverse effects, or those that are more common in the special subgroups excluded from the trial (such as pregnant women), or effects of long-term use of the drug, among others. This renewal application builds on our prior research and natural language processing (NLP), developing novel methods for data extraction that makes it possible to integrate information from social media with existing drug safety information and extract health data over time.",Social Media Mining for Pharmacovigilance,9784901,R01LM011176,"['Address', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Affect', 'Agreement', 'Alcohol consumption', 'Animals', 'Antidepressive Agents', 'Area', 'Behavior', 'Case Study', 'Case-Control Studies', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Collection', 'Complement', 'Congenital Abnormality', 'Consent', 'Control Groups', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Drug usage', 'Evaluation', 'Event', 'Fetal Death', 'Funding', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hemorrhage', 'Hepatic', 'Human', 'Hypersensitivity', 'Intake', 'Intervention', 'Kidney', 'Kidney Failure', 'Label', 'Lead', 'Literature', 'Live Birth', 'Long-Term Effects', 'Low Birth Weight Infant', 'MEDLINE', 'Manuals', 'Marketing', 'Medical', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Natural Language Processing', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Pregnancy', 'Pregnancy Outcome', 'Pregnant Women', 'Premature Birth', 'Public Health', 'Publications', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Signal Transduction', 'Smoking', 'Source', 'Spontaneous abortion', 'Standardization', 'Subgroup', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Unified Medical Language System', 'Validation', 'Vocabulary', 'Work', 'cohort', 'dosage', 'drug efficacy', 'epidemiological model', 'epidemiology study', 'health data', 'indexing', 'innovation', 'interest', 'language processing', 'medication compliance', 'medication safety', 'novel', 'pharmacovigilance', 'side effect', 'social media', 'systematic review', 'treatment duration']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2019,630471,0.03779701380859509
"Social Media Mining for Pharmacovigilance Project Summary Drugs undergo extensive testing in animals and clinical trials in humans before they are marketed for widespread use. Pre-market testing produces reasonably high quality information about the efficacy of the drug as a treatment for the condition for which it was approved, but gives a very incomplete picture of the drug's safety. It is only after a drug is marketed and used on a more widespread basis over longer periods of time that it is possible to identify other effects, such as rare but serious adverse effects, or those that are more common in the special subgroups excluded from the trial (such as pregnant women), or effects of long-term use of the drug, among others. Despite the increase in research in the past years exploring social media data for pharmacovigilance, and the evidence that it indeed can bring forward the patient perspective, there is no systematic approach to collect and annotate such data for research purposes. This renewal builds on our prior research and natural language processing (NLP) methods for social media mining in pharmacovigilance to make the collection of social media data about medication use precise and systematic enough to be useful to researchers and the public, alongside established sources such as the FDA's data and other public collections of drug adverse event data. It presents innovative methods to automatically collect and analyze longitudinal health data, piloting methods for interventions through the same media that can inform the public and help validate the automatic methods. As validation, we include a comparison to an existing reference standard for adverse effects that integrates FDA's data and HER data, as well as specific case studies focused on (Aim 3.1) the use of NSAIDs and anti-depressants in pregnancy and (Aim 3.2) factors for non-adherence. Project Narrative Pre-market testing of medications produces reasonably high quality information about the efficacy of the drug as a treatment for the condition for which it was approved, but gives a very incomplete picture of the drug's safety. It is only after a drug is marketed and used on a more widespread basis over longer periods of time that it is possible to identify other effects, such as rare but serious adverse effects, or those that are more common in the special subgroups excluded from the trial (such as pregnant women), or effects of long-term use of the drug, among others. This renewal application builds on our prior research and natural language processing (NLP), developing novel methods for data extraction that makes it possible to integrate information from social media with existing drug safety information and extract health data over time.",Social Media Mining for Pharmacovigilance,9598270,R01LM011176,"['Address', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Affect', 'Agreement', 'Alcohol consumption', 'Animals', 'Antidepressive Agents', 'Area', 'Behavior', 'Case Study', 'Case-Control Studies', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Collection', 'Complement', 'Congenital Abnormality', 'Consent', 'Control Groups', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Drug usage', 'Evaluation', 'Event', 'Fetal Death', 'Funding', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hemorrhage', 'Hepatic', 'Human', 'Hypersensitivity', 'Intake', 'Intervention', 'Kidney', 'Kidney Failure', 'Label', 'Lead', 'Literature', 'Live Birth', 'Long-Term Effects', 'Low Birth Weight Infant', 'MEDLINE', 'Manuals', 'Marketing', 'Medical', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Natural Language Processing', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Pregnancy', 'Pregnancy Outcome', 'Pregnant Women', 'Premature Birth', 'Public Health', 'Publications', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Signal Transduction', 'Smoking', 'Source', 'Spontaneous abortion', 'Standardization', 'Subgroup', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Unified Medical Language System', 'Validation', 'Vocabulary', 'Work', 'cohort', 'dosage', 'drug efficacy', 'epidemiological model', 'epidemiology study', 'health data', 'indexing', 'innovation', 'interest', 'language processing', 'medication compliance', 'novel', 'social media', 'systematic review', 'treatment duration']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2018,660242,0.03779701380859509
"Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model DESCRIPTION (provided by applicant):          Managing information for safe care, especially in the new health IT environment, continues to be cognitively challenging work for care providers. Adequate cognitive support to providers when building health IT systems can increase provider effectiveness in their work by reducing workarounds and medical errors. To model information support, cognitive engineers traditionally have modeled the task-technology-people triad. But, preliminary work from the investigator suggests that low-level information really binds care tasks and how providers perform their tasks with technologies. The researcher has piloted an information-based cognitive work design technique for modeling low-level healthcare information providers create, use and share in their cognitive work. The technique, when extended to medical error modeling, will improve patient safety. However, for the extension to succeed, the researcher needs to enhance her skills in health informatics, and medical error modeling in addition to acquiring a comprehensive understanding of health outcomes modeling. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, a Post Doctoral Research Fellow in the Quality and Safety Research Group at Johns Hopkins School of Medicine to achieve these objectives. The training component will be carried out under the mentorship of Dr. H. Lehmann (JHU SOM, Health Informatics). Drs. Peter Pronovost (JHU SOM, Patient Safety), Ayse Gurses (JHU SOM, Patient Safety) and Ann Bisantz (SUNY, Buffalo, Cognitive Systems Engineering) will provide additional mentoring in their areas of expertise. The long-term goal of this Pathway to Independence (K99/R00) project is to design health IT systems for provider work based on low-level information they create and use for care. During the award period, research will be focused on the following specific aims: (1) Map provider process workflows corresponding to patient state changes; (2) Identify low-level information attributes providers create and use in care processes, and relate them to potential medical errors at each major care process step; and (3) demonstrate utility of low-level information attributes as design bases for health IT support systems. Project Narrative (Public Health Relevance) Project aims are to understand and model how health care providers create, use and transform health information in their work. When health IT support systems are designed based on information providers create or use in their work, workarounds will be avoided, so medical errors from poor health IT support systems can be reduced.","Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model",8899625,R00LM011309,"['Address', 'Adverse event', 'Age', 'Applications Grants', 'Area', 'Award', 'Awareness', 'Binding', 'Boxing', 'Buffaloes', 'Caring', 'Cognitive', 'Complex', 'Computer software', 'Cues', 'Data', 'Descriptor', 'Development Plans', 'Effectiveness', 'Engineering', 'Environment', 'Event', 'Focus Groups', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Hypersensitivity', 'Information Systems', 'Intervention', 'Interview', 'Knowledge', 'Link', 'Maps', 'Medical Errors', 'Mentors', 'Mentorship', 'Modeling', 'Names', 'Nature', 'Nurses', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patient Discharge', 'Patients', 'Phase', 'Physicians', 'Postdoctoral Fellow', 'Process', 'Property', 'Provider', 'Public Health Informatics', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Shadowing (Histology)', 'Software Engineering', 'Support System', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Triad Acrylic Resin', 'Work', 'base', 'career development', 'cognitive system', 'design', 'improved', 'information model', 'information organization', 'medical schools', 'patient safety', 'public health relevance', 'skills']",NLM,UNIVERSITY OF IOWA,R00,2015,217227,0.025410646552930863
"Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model     DESCRIPTION (provided by applicant):          Managing information for safe care, especially in the new health IT environment, continues to be cognitively challenging work for care providers. Adequate cognitive support to providers when building health IT systems can increase provider effectiveness in their work by reducing workarounds and medical errors. To model information support, cognitive engineers traditionally have modeled the task-technology-people triad. But, preliminary work from the investigator suggests that low-level information really binds care tasks and how providers perform their tasks with technologies. The researcher has piloted an information-based cognitive work design technique for modeling low-level healthcare information providers create, use and share in their cognitive work. The technique, when extended to medical error modeling, will improve patient safety. However, for the extension to succeed, the researcher needs to enhance her skills in health informatics, and medical error modeling in addition to acquiring a comprehensive understanding of health outcomes modeling. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, a Post Doctoral Research Fellow in the Quality and Safety Research Group at Johns Hopkins School of Medicine to achieve these objectives. The training component will be carried out under the mentorship of Dr. H. Lehmann (JHU SOM, Health Informatics). Drs. Peter Pronovost (JHU SOM, Patient Safety), Ayse Gurses (JHU SOM, Patient Safety) and Ann Bisantz (SUNY, Buffalo, Cognitive Systems Engineering) will provide additional mentoring in their areas of expertise. The long-term goal of this Pathway to Independence (K99/R00) project is to design health IT systems for provider work based on low-level information they create and use for care. During the award period, research will be focused on the following specific aims: (1) Map provider process workflows corresponding to patient state changes; (2) Identify low-level information attributes providers create and use in care processes, and relate them to potential medical errors at each major care process step; and (3) demonstrate utility of low-level information attributes as design bases for health IT support systems.                 Project Narrative (Public Health Relevance) Project aims are to understand and model how health care providers create, use and transform health information in their work. When health IT support systems are designed based on information providers create or use in their work, workarounds will be avoided, so medical errors from poor health IT support systems can be reduced.","Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model",8725229,R00LM011309,"['Address', 'Adverse event', 'Age', 'Applications Grants', 'Area', 'Award', 'Awareness', 'Binding', 'Boxing', 'Buffaloes', 'Caring', 'Cognitive', 'Complex', 'Computer software', 'Cues', 'Data', 'Descriptor', 'Development Plans', 'Effectiveness', 'Engineering', 'Environment', 'Event', 'Focus Groups', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Hypersensitivity', 'Information Systems', 'Intervention', 'Interview', 'Knowledge', 'Link', 'Maps', 'Medical Errors', 'Mentors', 'Mentorship', 'Modeling', 'Names', 'Nature', 'Nurses', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patient Discharge', 'Patients', 'Phase', 'Physicians', 'Postdoctoral Fellow', 'Process', 'Property', 'Provider', 'Public Health Informatics', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Shadowing (Histology)', 'Software Engineering', 'Support System', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Triad Acrylic Resin', 'Work', 'base', 'career development', 'cognitive system', 'design', 'improved', 'information model', 'information organization', 'medical schools', 'patient safety', 'public health relevance', 'skills']",NLM,UNIVERSITY OF IOWA,R00,2014,223831,0.025410646552930863
"Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model     DESCRIPTION (provided by applicant):          Managing information for safe care, especially in the new health IT environment, continues to be cognitively challenging work for care providers. Adequate cognitive support to providers when building health IT systems can increase provider effectiveness in their work by reducing workarounds and medical errors. To model information support, cognitive engineers traditionally have modeled the task-technology-people triad. But, preliminary work from the investigator suggests that low-level information really binds care tasks and how providers perform their tasks with technologies. The researcher has piloted an information-based cognitive work design technique for modeling low-level healthcare information providers create, use and share in their cognitive work. The technique, when extended to medical error modeling, will improve patient safety. However, for the extension to succeed, the researcher needs to enhance her skills in health informatics, and medical error modeling in addition to acquiring a comprehensive understanding of health outcomes modeling. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, a Post Doctoral Research Fellow in the Quality and Safety Research Group at Johns Hopkins School of Medicine to achieve these objectives. The training component will be carried out under the mentorship of Dr. H. Lehmann (JHU SOM, Health Informatics). Drs. Peter Pronovost (JHU SOM, Patient Safety), Ayse Gurses (JHU SOM, Patient Safety) and Ann Bisantz (SUNY, Buffalo, Cognitive Systems Engineering) will provide additional mentoring in their areas of expertise. The long-term goal of this Pathway to Independence (K99/R00) project is to design health IT systems for provider work based on low-level information they create and use for care. During the award period, research will be focused on the following specific aims: (1) Map provider process workflows corresponding to patient state changes; (2) Identify low-level information attributes providers create and use in care processes, and relate them to potential medical errors at each major care process step; and (3) demonstrate utility of low-level information attributes as design bases for health IT support systems.                  Project Narrative (Public Health Relevance) Project aims are to understand and model how health care providers create, use and transform health information in their work. When health IT support systems are designed based on information providers create or use in their work, workarounds will be avoided, so medical errors from poor health IT support systems can be reduced.","Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model",8589974,R00LM011309,"['Address', 'Adverse event', 'Age', 'Applications Grants', 'Area', 'Award', 'Awareness', 'Binding', 'Boxing', 'Buffaloes', 'Caring', 'Cognitive', 'Complex', 'Computer software', 'Cues', 'Data', 'Descriptor', 'Development Plans', 'Effectiveness', 'Engineering', 'Environment', 'Event', 'Focus Groups', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Hypersensitivity', 'Information Systems', 'Intervention', 'Interview', 'Knowledge', 'Link', 'Maps', 'Medical Errors', 'Mentors', 'Mentorship', 'Modeling', 'Names', 'Nature', 'Nurses', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patient Discharge', 'Patients', 'Phase', 'Physicians', 'Postdoctoral Fellow', 'Process', 'Property', 'Provider', 'Public Health Informatics', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Shadowing (Histology)', 'Software Engineering', 'Support System', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Triad Acrylic Resin', 'Work', 'base', 'career development', 'cognitive system', 'design', 'improved', 'information model', 'information organization', 'medical schools', 'patient safety', 'public health relevance', 'skills']",NLM,UNIVERSITY OF IOWA,R00,2013,223972,0.025410646552930863
"Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model     DESCRIPTION (provided by applicant):          Managing information for safe care, especially in the new health IT environment, continues to be cognitively challenging work for care providers. Adequate cognitive support to providers when building health IT systems can increase provider effectiveness in their work by reducing workarounds and medical errors. To model information support, cognitive engineers traditionally have modeled the task-technology-people triad. But, preliminary work from the investigator suggests that low-level information really binds care tasks and how providers perform their tasks with technologies. The researcher has piloted an information-based cognitive work design technique for modeling low-level healthcare information providers create, use and share in their cognitive work. The technique, when extended to medical error modeling, will improve patient safety. However, for the extension to succeed, the researcher needs to enhance her skills in health informatics, and medical error modeling in addition to acquiring a comprehensive understanding of health outcomes modeling. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, a Post Doctoral Research Fellow in the Quality and Safety Research Group at Johns Hopkins School of Medicine to achieve these objectives. The training component will be carried out under the mentorship of Dr. H. Lehmann (JHU SOM, Health Informatics). Drs. Peter Pronovost (JHU SOM, Patient Safety), Ayse Gurses (JHU SOM, Patient Safety) and Ann Bisantz (SUNY, Buffalo, Cognitive Systems Engineering) will provide additional mentoring in their areas of expertise. The long-term goal of this Pathway to Independence (K99/R00) project is to design health IT systems for provider work based on low-level information they create and use for care. During the award period, research will be focused on the following specific aims: (1) Map provider process workflows corresponding to patient state changes; (2) Identify low-level information attributes providers create and use in care processes, and relate them to potential medical errors at each major care process step; and (3) demonstrate utility of low-level information attributes as design bases for health IT support systems.                  Project Narrative (Public Health Relevance) Project aims are to understand and model how health care providers create, use and transform health information in their work. When health IT support systems are designed based on information providers create or use in their work, workarounds will be avoided, so medical errors from poor health IT support systems can be reduced.","Technology, Cognitive Work, and Patient Safety: A Information-Oriented Model",8279720,K99LM011309,"['Address', 'Adverse event', 'Age', 'Applications Grants', 'Area', 'Award', 'Awareness', 'Binding', 'Boxing', 'Buffaloes', 'Caring', 'Cognitive', 'Complex', 'Computer software', 'Cues', 'Data', 'Descriptor', 'Development Plans', 'Effectiveness', 'Engineering', 'Environment', 'Event', 'Focus Groups', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Hypersensitivity', 'Information Systems', 'Intervention', 'Interview', 'Knowledge', 'Link', 'Maps', 'Medical Errors', 'Mentors', 'Mentorship', 'Modeling', 'Names', 'Nature', 'Nurses', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patient Discharge', 'Patients', 'Phase', 'Physicians', 'Postdoctoral Fellow', 'Process', 'Property', 'Provider', 'Public Health Informatics', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Shadowing (Histology)', 'Software Engineering', 'Support System', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Triad Acrylic Resin', 'Work', 'base', 'career development', 'cognitive system', 'design', 'improved', 'information model', 'information organization', 'medical schools', 'patient safety', 'public health relevance', 'skills']",NLM,UNIVERSITY OF IOWA,K99,2012,90000,0.025410646552930863
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases. The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8917296,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,BROWN UNIVERSITY,R01,2015,342049,0.02860205217135839
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors     DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases.                  The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8532983,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R01,2013,303833,0.02860205217135839
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors     DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases.                  The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8727661,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R01,2014,320343,0.02860205217135839
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors     DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases.                  The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8344467,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R01,2012,392726,0.02860205217135839
"Scalable and Robust Clinical Text De-Identification Tools     DESCRIPTION (provided by applicant): Exploiting the full potential of information rich and rapidly growing repositories of patient clinical text is hampered by the absence of scalable and robust de-identification tools. Clinical text contains protected health information (PHI), and the Health Insurance Portability and Accountability Act (HIPAA) restricts research use of patient information containing PHI to specific, limited, IRB-approved projects. As a result, vast repositories of clinical text remain under-used by internal researchers, and are even less available for external transmission to outside collaborators or for centralized processing by state-of-the-art natural language processing (NLP) technologies. De-identification, which is the removal of PHI from clinical text, is challenging. Despite their availability for over a decade, commercially available automated systems are expensive, require local tailoring, and have not gained widespread market penetration. Manual methods are costly and do not scale, yet continue to be used despite the small amount of residual PHI they leave behind. Open source de-identification tools based on state-of-the-art machine learning technologies can perform at or above the level of manual approaches but also suffer from the residual PHI problem. Current de-identification approaches, then, also severely limit the use and mobility of clinical text while exposing patients to privacy risks. These approaches redact PHI, blacking it out or replacing it with symbols (e.g., ""Here for cardiac eval is Mr. **PT_NAME<AA>, a **AGE<60s> yo male with his son Doug ...""). Traditional approaches leave residual PHI (""Doug"" in this example) to be easily noticed by readers of the text, as it remains plainly visible among the prominent redactions. We developed and pilot tested an alternative approach we believe addresses the residual PHI problem. Our approach uses the strategy of concealing, rather than trying to eliminate, residual PHI. We call it the ""Hiding In Plain Sight"" (HIPS) approach. HIPS replaces all known PHI with ""surrogate"" PHI- fictional names, ages, etc.-that look real but do not refer to any actual patient. A HIPS version of the above text is: ""Here for cardiac eval is Mr. Jones, a 64 yo male with his son Doug ..."" where the name ""Jones"" and age ""64"" are fictional surrogates, but the name ""Doug"" is residual PHI. To a reader, the surrogates and the residual PHI are indistinguishable. This prevents the reader from detecting the latter, avoiding disclosure. Our preliminary studies suggest that HIPS can reduce the risk of disclosure of residual PHI by a factor of 10. This yields overall performance that far surpasses the performance attainable by manual methods, and is unlikely to be matched, we believe, by additional incremental improvements in PHI tagging models (i.e., efforts to reduce residual PHI). Our pilot studies indicate IRBs would welcome the HIPS approach if it were shown to be effective through rigorous evaluation. To expand usage of clinical text and enhance patient privacy, we propose to formalize rules of effective surrogate generation (Aim 1), extend related de-identification confidence scoring methods (Aim 2), and conduct rigorous efficacy testing of HIPS in diverse institutional settings (Aim 3).                  All known automated de-identification methods leave behind a small amount of residual protected health information (PHI), which presents a risk of disclosing patient privacy and creates barriers to more widespread internal use and external sharing of information-rich clinical text for broad research purpose. This project advances and evaluates the efficacy of a novel method, called the Hiding In Plain Sight (HIPS) approach, which conceals residual PHI by replacing all other instance of PHI found in a document with realistic appearing but fictitious surrogates. Rigorous efficacy testing is needed to confirm that HIPS surrogates effectively reduce risk of exposing patient privacy by concealing the small amount of residual PHI all known de-identification leave behind.",Scalable and Robust Clinical Text De-Identification Tools,8722030,R01LM011366,"['Address', 'Age', 'Applied Research', 'Cardiac', 'Clinical', 'Detection', 'Disclosure', 'Evaluation', 'Excision', 'Foundations', 'Generations', 'Health', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Information Theory', 'Institutional Review Boards', 'Left', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Patients', 'Penetration', 'Performance', 'Pilot Projects', 'Plant Roots', 'Privacy', 'Process', 'Publishing', 'Reader', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Risk', 'Scoring Method', 'Simulate', 'Son', 'Source', 'System', 'Technology', 'Testing', 'Text', 'Validation', 'Vision', 'Work', 'base', 'efficacy testing', 'male', 'novel', 'open source', 'patient privacy', 'prevent', 'programs', 'repository', 'software systems', 'tool', 'transmission process']",NLM,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,R01,2014,260727,0.03213191797874549
"Scalable and Robust Clinical Text De-Identification Tools     DESCRIPTION (provided by applicant): Exploiting the full potential of information rich and rapidly growing repositories of patient clinical text is hampered by the absence of scalable and robust de-identification tools. Clinical text contains protected health information (PHI), and the Health Insurance Portability and Accountability Act (HIPAA) restricts research use of patient information containing PHI to specific, limited, IRB-approved projects. As a result, vast repositories of clinical text remain under-used by internal researchers, and are even less available for external transmission to outside collaborators or for centralized processing by state-of-the-art natural language processing (NLP) technologies. De-identification, which is the removal of PHI from clinical text, is challenging. Despite their availability for over a decade, commercially available automated systems are expensive, require local tailoring, and have not gained widespread market penetration. Manual methods are costly and do not scale, yet continue to be used despite the small amount of residual PHI they leave behind. Open source de-identification tools based on state-of-the-art machine learning technologies can perform at or above the level of manual approaches but also suffer from the residual PHI problem. Current de-identification approaches, then, also severely limit the use and mobility of clinical text while exposing patients to privacy risks. These approaches redact PHI, blacking it out or replacing it with symbols (e.g., ""Here for cardiac eval is Mr. **PT_NAME<AA>, a **AGE<60s> yo male with his son Doug ...""). Traditional approaches leave residual PHI (""Doug"" in this example) to be easily noticed by readers of the text, as it remains plainly visible among the prominent redactions. We developed and pilot tested an alternative approach we believe addresses the residual PHI problem. Our approach uses the strategy of concealing, rather than trying to eliminate, residual PHI. We call it the ""Hiding In Plain Sight"" (HIPS) approach. HIPS replaces all known PHI with ""surrogate"" PHI- fictional names, ages, etc.-that look real but do not refer to any actual patient. A HIPS version of the above text is: ""Here for cardiac eval is Mr. Jones, a 64 yo male with his son Doug ..."" where the name ""Jones"" and age ""64"" are fictional surrogates, but the name ""Doug"" is residual PHI. To a reader, the surrogates and the residual PHI are indistinguishable. This prevents the reader from detecting the latter, avoiding disclosure. Our preliminary studies suggest that HIPS can reduce the risk of disclosure of residual PHI by a factor of 10. This yields overall performance that far surpasses the performance attainable by manual methods, and is unlikely to be matched, we believe, by additional incremental improvements in PHI tagging models (i.e., efforts to reduce residual PHI). Our pilot studies indicate IRBs would welcome the HIPS approach if it were shown to be effective through rigorous evaluation. To expand usage of clinical text and enhance patient privacy, we propose to formalize rules of effective surrogate generation (Aim 1), extend related de-identification confidence scoring methods (Aim 2), and conduct rigorous efficacy testing of HIPS in diverse institutional settings (Aim 3).                  All known automated de-identification methods leave behind a small amount of residual protected health information (PHI), which presents a risk of disclosing patient privacy and creates barriers to more widespread internal use and external sharing of information-rich clinical text for broad research purpose. This project advances and evaluates the efficacy of a novel method, called the Hiding In Plain Sight (HIPS) approach, which conceals residual PHI by replacing all other instance of PHI found in a document with realistic appearing but fictitious surrogates. Rigorous efficacy testing is needed to confirm that HIPS surrogates effectively reduce risk of exposing patient privacy by concealing the small amount of residual PHI all known de-identification leave behind.",Scalable and Robust Clinical Text De-Identification Tools,8532984,R01LM011366,"['Address', 'Age', 'Applied Research', 'Cardiac', 'Clinical', 'Detection', 'Disclosure', 'Evaluation', 'Excision', 'Foundations', 'Generations', 'Health', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Information Theory', 'Institutional Review Boards', 'Left', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Patients', 'Penetration', 'Performance', 'Pilot Projects', 'Plant Roots', 'Privacy', 'Process', 'Publishing', 'Reader', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Risk', 'Scoring Method', 'Simulate', 'Son', 'Source', 'System', 'Technology', 'Testing', 'Text', 'Validation', 'Vision', 'Work', 'base', 'efficacy testing', 'male', 'novel', 'open source', 'patient privacy', 'prevent', 'programs', 'repository', 'software systems', 'tool', 'transmission process']",NLM,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,R01,2013,247288,0.03213191797874549
"Scalable and Robust Clinical Text De-Identification Tools     DESCRIPTION (provided by applicant): Exploiting the full potential of information rich and rapidly growing repositories of patient clinical text is hampered by the absence of scalable and robust de-identification tools. Clinical text contains protected health information (PHI), and the Health Insurance Portability and Accountability Act (HIPAA) restricts research use of patient information containing PHI to specific, limited, IRB-approved projects. As a result, vast repositories of clinical text remain under-used by internal researchers, and are even less available for external transmission to outside collaborators or for centralized processing by state-of-the-art natural language processing (NLP) technologies. De-identification, which is the removal of PHI from clinical text, is challenging. Despite their availability for over a decade, commercially available automated systems are expensive, require local tailoring, and have not gained widespread market penetration. Manual methods are costly and do not scale, yet continue to be used despite the small amount of residual PHI they leave behind. Open source de-identification tools based on state-of-the-art machine learning technologies can perform at or above the level of manual approaches but also suffer from the residual PHI problem. Current de-identification approaches, then, also severely limit the use and mobility of clinical text while exposing patients to privacy risks. These approaches redact PHI, blacking it out or replacing it with symbols (e.g., ""Here for cardiac eval is Mr. **PT_NAME<AA>, a **AGE<60s> yo male with his son Doug ...""). Traditional approaches leave residual PHI (""Doug"" in this example) to be easily noticed by readers of the text, as it remains plainly visible among the prominent redactions. We developed and pilot tested an alternative approach we believe addresses the residual PHI problem. Our approach uses the strategy of concealing, rather than trying to eliminate, residual PHI. We call it the ""Hiding In Plain Sight"" (HIPS) approach. HIPS replaces all known PHI with ""surrogate"" PHI- fictional names, ages, etc.-that look real but do not refer to any actual patient. A HIPS version of the above text is: ""Here for cardiac eval is Mr. Jones, a 64 yo male with his son Doug ..."" where the name ""Jones"" and age ""64"" are fictional surrogates, but the name ""Doug"" is residual PHI. To a reader, the surrogates and the residual PHI are indistinguishable. This prevents the reader from detecting the latter, avoiding disclosure. Our preliminary studies suggest that HIPS can reduce the risk of disclosure of residual PHI by a factor of 10. This yields overall performance that far surpasses the performance attainable by manual methods, and is unlikely to be matched, we believe, by additional incremental improvements in PHI tagging models (i.e., efforts to reduce residual PHI). Our pilot studies indicate IRBs would welcome the HIPS approach if it were shown to be effective through rigorous evaluation. To expand usage of clinical text and enhance patient privacy, we propose to formalize rules of effective surrogate generation (Aim 1), extend related de-identification confidence scoring methods (Aim 2), and conduct rigorous efficacy testing of HIPS in diverse institutional settings (Aim 3).                  All known automated de-identification methods leave behind a small amount of residual protected health information (PHI), which presents a risk of disclosing patient privacy and creates barriers to more widespread internal use and external sharing of information-rich clinical text for broad research purpose. This project advances and evaluates the efficacy of a novel method, called the Hiding In Plain Sight (HIPS) approach, which conceals residual PHI by replacing all other instance of PHI found in a document with realistic appearing but fictitious surrogates. Rigorous efficacy testing is needed to confirm that HIPS surrogates effectively reduce risk of exposing patient privacy by concealing the small amount of residual PHI all known de-identification leave behind.",Scalable and Robust Clinical Text De-Identification Tools,8345041,R01LM011366,"['Address', 'Age', 'Applied Research', 'Cardiac', 'Clinical', 'Detection', 'Disclosure', 'Evaluation', 'Excision', 'Foundations', 'Generations', 'Health', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Information Theory', 'Institutional Review Boards', 'Left', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Patients', 'Penetration', 'Performance', 'Pilot Projects', 'Plant Roots', 'Privacy', 'Process', 'Publishing', 'Reader', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Risk', 'Scoring Method', 'Simulate', 'Son', 'Source', 'System', 'Technology', 'Testing', 'Text', 'Validation', 'Vision', 'Work', 'base', 'efficacy testing', 'male', 'novel', 'open source', 'patient privacy', 'prevent', 'programs', 'repository', 'software systems', 'tool', 'transmission process']",NLM,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,R01,2012,318849,0.03213191797874549
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,10000216,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Judgment', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'large datasets', 'machine learning algorithm', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2020,643304,0.08216456314640022
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,9759984,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2019,640832,0.08216456314640022
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,9535477,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2018,694405,0.08216456314640022
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,9365759,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2017,636560,0.08216456314640022
"Probabilistic Disease Surveillance     DESCRIPTION (provided by applicant):         The proposed research will further develop and evaluate a probabilistic approach to disease surveillance. In this approach, a probabilistic case detection system (CDS) uses Bayesian diagnostic networks to compute the likelihoods of patient findings for each of a set of infectious diseases for every patient in a monitored population. CDS computes these likelihoods from data in electronic medical records, including information derived from free-text reports by natural language processing. CDS makes those estimates available to a probabilistic outbreak detection and characterization component (ODCS).             ODCS also utilizes a Bayesian approach to compute the probability that an outbreak is ongoing for each of a set of infectious diseases of interest, given information from CDS. ODCS also computes probability distributions over the current and future size of a detected outbreak and other characteristics such as incubation period used by public health officials when responding to an outbreak.                        The proposed research will extend the approach, which we have already developed and evaluated for the disease influenza to six additional respiratory infectious diseases. The research will also extend the capabilities of ODCS to utilize non-EMR data, detect an unknown disease, and detect and characterize concurrent outbreaks. The planned evaluations will measure the accuracy of both CDS and ODCS using historical surveillance data from two regions and simulated outbreak data, which we will create by adding outbreak cases generated by an agent-based epidemic simulator to real baseline surveillance data from non-outbreak periods.                        The innovation being advanced by this research is a novel, integrated, Bayesian approach for the early and accurate detection of cases of diseases that threaten health and for the detection and characterization of outbreaks of diseases that threaten public health. The proposed approach has significant potential to improve the information available to public health officials and physicians, which can be expected to improve clinical and public health decision making, and ultimately to improve population health.                  Project Relevance  The proposed research will improve the ability of public health officials and physicians to estimate the current incidence of influenza and other infectious diseases and to predict the future course of epidemics of those diseases. The improved information will better support decisions made by health departments to control epidemics, which is expected to reduce morbidity and mortality from epidemic diseases.",Probabilistic Disease Surveillance,8578484,R01LM011370,"['Accident and Emergency department', 'Advanced Development', 'Area', 'Characteristics', 'Clinical', 'Code', 'Communicable Diseases', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'County', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Disease model', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Future', 'Health', 'Healthcare', 'Healthcare Systems', 'Incidence', 'Individual', 'Influenza', 'Intervention', 'Knowledge', 'Laboratories', 'Lung diseases', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Public Health', 'Public Health Practice', 'Publications', 'ROC Curve', 'Reporting', 'Research', 'Schools', 'Sensitivity and Specificity', 'Severities', 'Simulate', 'Sodium Chloride', 'Structure', 'Support System', 'System', 'Systems Integration', 'Testing', 'Text', 'Time', 'Topaz', 'Universities', 'Utah', 'Vaccination', 'advanced system', 'base', 'computer code', 'diagnostic accuracy', 'disorder control', 'follow-up', 'improved', 'influenza outbreak', 'innovation', 'interest', 'knowledge base', 'mortality', 'novel', 'novel strategies', 'operation', 'pandemic disease', 'population health', 'portability', 'reproductive', 'respiratory', 'surveillance data']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2013,590023,0.038037740092915696
"Probabilistic Disease Surveillance DESCRIPTION (provided by applicant):         The proposed research will further develop and evaluate a probabilistic approach to disease surveillance. In this approach, a probabilistic case detection system (CDS) uses Bayesian diagnostic networks to compute the likelihoods of patient findings for each of a set of infectious diseases for every patient in a monitored population. CDS computes these likelihoods from data in electronic medical records, including information derived from free-text reports by natural language processing. CDS makes those estimates available to a probabilistic outbreak detection and characterization component (ODCS).             ODCS also utilizes a Bayesian approach to compute the probability that an outbreak is ongoing for each of a set of infectious diseases of interest, given information from CDS. ODCS also computes probability distributions over the current and future size of a detected outbreak and other characteristics such as incubation period used by public health officials when responding to an outbreak.                        The proposed research will extend the approach, which we have already developed and evaluated for the disease influenza to six additional respiratory infectious diseases. The research will also extend the capabilities of ODCS to utilize non-EMR data, detect an unknown disease, and detect and characterize concurrent outbreaks. The planned evaluations will measure the accuracy of both CDS and ODCS using historical surveillance data from two regions and simulated outbreak data, which we will create by adding outbreak cases generated by an agent-based epidemic simulator to real baseline surveillance data from non-outbreak periods.                        The innovation being advanced by this research is a novel, integrated, Bayesian approach for the early and accurate detection of cases of diseases that threaten health and for the detection and characterization of outbreaks of diseases that threaten public health. The proposed approach has significant potential to improve the information available to public health officials and physicians, which can be expected to improve clinical and public health decision making, and ultimately to improve population health. Project Relevance  The proposed research will improve the ability of public health officials and physicians to estimate the current incidence of influenza and other infectious diseases and to predict the future course of epidemics of those diseases. The improved information will better support decisions made by health departments to control epidemics, which is expected to reduce morbidity and mortality from epidemic diseases.",Probabilistic Disease Surveillance,8875053,R01LM011370,"['Accident and Emergency department', 'Advanced Development', 'Area', 'Bayesian Method', 'Characteristics', 'Clinical', 'Code', 'Communicable Diseases', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'County', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Disease model', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Future', 'Health', 'Healthcare', 'Healthcare Systems', 'Incidence', 'Individual', 'Influenza', 'Intervention', 'Knowledge', 'Laboratories', 'Lung diseases', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Public Health', 'Public Health Practice', 'Publications', 'ROC Curve', 'Reporting', 'Research', 'Schools', 'Sensitivity and Specificity', 'Severities', 'Sodium Chloride', 'Structure', 'Support System', 'System', 'Systems Integration', 'Testing', 'Text', 'Time', 'Topaz', 'Universities', 'Utah', 'Vaccination', 'advanced system', 'base', 'computer code', 'diagnostic accuracy', 'disorder control', 'follow-up', 'improved', 'influenza outbreak', 'innovation', 'interest', 'knowledge base', 'mortality', 'novel', 'novel strategies', 'operation', 'pandemic disease', 'population health', 'portability', 'reproductive', 'respiratory', 'surveillance data']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,531035,0.038037740092915696
"Probabilistic Disease Surveillance     DESCRIPTION (provided by applicant):         The proposed research will further develop and evaluate a probabilistic approach to disease surveillance. In this approach, a probabilistic case detection system (CDS) uses Bayesian diagnostic networks to compute the likelihoods of patient findings for each of a set of infectious diseases for every patient in a monitored population. CDS computes these likelihoods from data in electronic medical records, including information derived from free-text reports by natural language processing. CDS makes those estimates available to a probabilistic outbreak detection and characterization component (ODCS).             ODCS also utilizes a Bayesian approach to compute the probability that an outbreak is ongoing for each of a set of infectious diseases of interest, given information from CDS. ODCS also computes probability distributions over the current and future size of a detected outbreak and other characteristics such as incubation period used by public health officials when responding to an outbreak.                        The proposed research will extend the approach, which we have already developed and evaluated for the disease influenza to six additional respiratory infectious diseases. The research will also extend the capabilities of ODCS to utilize non-EMR data, detect an unknown disease, and detect and characterize concurrent outbreaks. The planned evaluations will measure the accuracy of both CDS and ODCS using historical surveillance data from two regions and simulated outbreak data, which we will create by adding outbreak cases generated by an agent-based epidemic simulator to real baseline surveillance data from non-outbreak periods.                        The innovation being advanced by this research is a novel, integrated, Bayesian approach for the early and accurate detection of cases of diseases that threaten health and for the detection and characterization of outbreaks of diseases that threaten public health. The proposed approach has significant potential to improve the information available to public health officials and physicians, which can be expected to improve clinical and public health decision making, and ultimately to improve population health.                  Project Relevance  The proposed research will improve the ability of public health officials and physicians to estimate the current incidence of influenza and other infectious diseases and to predict the future course of epidemics of those diseases. The improved information will better support decisions made by health departments to control epidemics, which is expected to reduce morbidity and mortality from epidemic diseases.",Probabilistic Disease Surveillance,8708209,R01LM011370,"['Accident and Emergency department', 'Advanced Development', 'Area', 'Bayesian Method', 'Characteristics', 'Clinical', 'Code', 'Communicable Diseases', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'County', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Disease model', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Future', 'Health', 'Healthcare', 'Healthcare Systems', 'Incidence', 'Individual', 'Influenza', 'Intervention', 'Knowledge', 'Laboratories', 'Lung diseases', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Public Health', 'Public Health Practice', 'Publications', 'ROC Curve', 'Reporting', 'Research', 'Schools', 'Sensitivity and Specificity', 'Severities', 'Simulate', 'Sodium Chloride', 'Structure', 'Support System', 'System', 'Systems Integration', 'Testing', 'Text', 'Time', 'Topaz', 'Universities', 'Utah', 'Vaccination', 'advanced system', 'base', 'computer code', 'diagnostic accuracy', 'disorder control', 'follow-up', 'improved', 'influenza outbreak', 'innovation', 'interest', 'knowledge base', 'mortality', 'novel', 'novel strategies', 'operation', 'pandemic disease', 'population health', 'portability', 'reproductive', 'respiratory', 'surveillance data']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,535841,0.038037740092915696
"Improving the Efficiency and Efficacy in Authoring Essential Clinical FAQs     DESCRIPTION (provided by applicant):         Research plan: The use of clinical knowledge systems such as UpToDate that provide reliable information at the point of care has been shown to improve patient safety and decision-making. With similar content to UpToDate, Mayo Clinic's AskMayoExpert (AME) is an online knowledge system that primarily contains over 5000 (and increasing) specialist-vetted answers to FAQs for point of care use. However, because of the overabundance of clinical resources and guidelines, adding new answers manually to AME and ensuring that it is consistent with evidence is time consuming. This problem is also faced with other systems such as UpToDate. This career grant proposes to investigate the feasibility of using a novel text mining based informatics approach to semi-automate the management of a clinical knowledge system, using AME as the test bed. Although the methods will be applicable to any clinical knowledge system and any topic, they will be evaluated using two important test topics from cardiology (which has the biggest focus in AME) - atrial fibrillation (a topic exhaustively covered in AME) and congestive heart failure (a topic less covered, but is an increasingly complex vast field with knowledge from huge literature). While the existing content of AME is private, the methods and the code we develop to assist in generating the content will be released open-source as part of the Open Health Natural Language Processing (OHNLP) consortium in UIMA framework. Career plan: As most communication of information in clinical practice and biomedical research occurs through the medium of text, the development of methods to render this text computer-interpretable is a prerequisite to the use of this information to improve quality of care and support scientific discovery. The PI's long-term career goal is to become a leader in biomedical informatics (informatics applied to biomedical data), with focus on textual data such as scientific papers and clinical notes. He has BS in Computer Science, PhD in Biomedical Informatics and over a dozen of peer-reviewed publications in biomedical text mining. His career goal is to advance diverse methods and applications of text mining across biomedical informatics (BMI). He will focus on: a) discovering information needs and gaps that can be filled, b) adapting and extending existing text mining algorithms, and c) validating the utility of the applications in the biomedical environment. Rationale: Making the transition from a mentored researcher to an independent researcher requires three main facets of career growth: a) developing a working familiarity with clinical information systems and medical terminologies; b) understanding the information needs of clinicians; and c) training in clinical research. The proposal will translate the PI's knowledgeof the text mining methods to practical experience in an operation clinical environment. Courses listed in the ""Career Development/Training Activities"" will educate him more about the environment and train him on clinical research. He will continue sharpening his informatics expertise by attending scientific conferences.             Project Narrative Medical errors are one of the leading causes of death in the United States. It has been observed that point of care access to relevant clinical knowledge support decision making and decreases medical errors, thereby improving patient safety and healthcare costs. The proposed research aims to empower physicians specialized in the area (specialists) in quickly gathering evidence from literature or finding citations supporting or qualifying their expert opinion. It will also generate the answers and suggest updates to the existing answers for their perusal.",Improving the Efficiency and Efficacy in Authoring Essential Clinical FAQs,8727093,R00LM011389,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Beds', 'Biomedical Research', 'Calculi', 'Cardiology', 'Cause of Death', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Code', 'Communication', 'Complex', 'Computers', 'Congestive Heart Failure', 'Cross-Over Studies', 'Data', 'Decision Making', 'Doctor of Philosophy', 'Electronic Health Record', 'Ensure', 'Environment', 'Expert Opinion', 'Familiarity', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Grant', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Health Services Accessibility', 'Healthcare', 'Human', 'Informatics', 'Information Retrieval Systems', 'Journals', 'Knowledge', 'Language', 'Link', 'Literature', 'Medical', 'Medical Errors', 'Mentors', 'Methods', 'Natural Language Processing', 'Nurses', 'Paper', 'Peer Review', 'Physicians', 'Publications', 'Publishing', 'Qualifying', 'Quality of Care', 'Randomized', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Specialist', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Training', 'Training Activity', 'Translating', 'United States', 'Update', 'Validation', 'Vocabulary', 'Work', 'Workload', 'Writing', 'base', 'biomedical informatics', 'career', 'career development', 'clinical decision-making', 'clinical practice', 'computer science', 'empowered', 'evidence base', 'experience', 'improved', 'information gathering', 'medical information system', 'method development', 'novel', 'open source', 'operation', 'patient safety', 'point of care', 'statistics', 'symposium', 'text searching', 'usability']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R00,2014,223898,0.031453895668153264
"Improving the Efficiency and Efficacy in Authoring Essential Clinical FAQs     DESCRIPTION (provided by applicant):         Research plan: The use of clinical knowledge systems such as UpToDate that provide reliable information at the point of care has been shown to improve patient safety and decision-making. With similar content to UpToDate, Mayo Clinic's AskMayoExpert (AME) is an online knowledge system that primarily contains over 5000 (and increasing) specialist-vetted answers to FAQs for point of care use. However, because of the overabundance of clinical resources and guidelines, adding new answers manually to AME and ensuring that it is consistent with evidence is time consuming. This problem is also faced with other systems such as UpToDate. This career grant proposes to investigate the feasibility of using a novel text mining based informatics approach to semi-automate the management of a clinical knowledge system, using AME as the test bed. Although the methods will be applicable to any clinical knowledge system and any topic, they will be evaluated using two important test topics from cardiology (which has the biggest focus in AME) - atrial fibrillation (a topic exhaustively covered in AME) and congestive heart failure (a topic less covered, but is an increasingly complex vast field with knowledge from huge literature). While the existing content of AME is private, the methods and the code we develop to assist in generating the content will be released open-source as part of the Open Health Natural Language Processing (OHNLP) consortium in UIMA framework. Career plan: As most communication of information in clinical practice and biomedical research occurs through the medium of text, the development of methods to render this text computer-interpretable is a prerequisite to the use of this information to improve quality of care and support scientific discovery. The PI's long-term career goal is to become a leader in biomedical informatics (informatics applied to biomedical data), with focus on textual data such as scientific papers and clinical notes. He has BS in Computer Science, PhD in Biomedical Informatics and over a dozen of peer-reviewed publications in biomedical text mining. His career goal is to advance diverse methods and applications of text mining across biomedical informatics (BMI). He will focus on: a) discovering information needs and gaps that can be filled, b) adapting and extending existing text mining algorithms, and c) validating the utility of the applications in the biomedical environment. Rationale: Making the transition from a mentored researcher to an independent researcher requires three main facets of career growth: a) developing a working familiarity with clinical information systems and medical terminologies; b) understanding the information needs of clinicians; and c) training in clinical research. The proposal will translate the PI's knowledgeof the text mining methods to practical experience in an operation clinical environment. Courses listed in the ""Career Development/Training Activities"" will educate him more about the environment and train him on clinical research. He will continue sharpening his informatics expertise by attending scientific conferences.              Project Narrative Medical errors are one of the leading causes of death in the United States. It has been observed that point of care access to relevant clinical knowledge support decision making and decreases medical errors, thereby improving patient safety and healthcare costs. The proposed research aims to empower physicians specialized in the area (specialists) in quickly gathering evidence from literature or finding citations supporting or qualifying their expert opinion. It will also generate the answers and suggest updates to the existing answers for their perusal.",Improving the Efficiency and Efficacy in Authoring Essential Clinical FAQs,8442618,K99LM011389,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Beds', 'Biomedical Research', 'Calculi', 'Cardiology', 'Cause of Death', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Code', 'Communication', 'Complex', 'Computers', 'Congestive Heart Failure', 'Cross-Over Studies', 'Data', 'Decision Making', 'Doctor of Philosophy', 'Electronic Health Record', 'Ensure', 'Environment', 'Expert Opinion', 'Familiarity', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Grant', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Health Services Accessibility', 'Healthcare', 'Human', 'Informatics', 'Information Retrieval Systems', 'Journals', 'Knowledge', 'Language', 'Link', 'Literature', 'Medical', 'Medical Errors', 'Mentors', 'Methods', 'Natural Language Processing', 'Nurses', 'Paper', 'Peer Review', 'Physicians', 'Publications', 'Publishing', 'Qualifying', 'Quality of Care', 'Randomized', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Specialist', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Training', 'Training Activity', 'Translating', 'United States', 'Update', 'Validation', 'Vocabulary', 'Work', 'Workload', 'Writing', 'base', 'biomedical informatics', 'career', 'career development', 'clinical decision-making', 'clinical practice', 'computer science', 'empowered', 'evidence base', 'experience', 'improved', 'information gathering', 'medical information system', 'method development', 'novel', 'open source', 'operation', 'patient safety', 'point of care', 'statistics', 'symposium', 'text searching', 'usability']",NLM,MAYO CLINIC ROCHESTER,K99,2012,96552,0.031453895668153264
"Improving the Efficiency and Efficacy in Authoring Essential Clinical FAQs DESCRIPTION (provided by applicant):         Research plan: The use of clinical knowledge systems such as UpToDate that provide reliable information at the point of care has been shown to improve patient safety and decision-making. With similar content to UpToDate, Mayo Clinic's AskMayoExpert (AME) is an online knowledge system that primarily contains over 5000 (and increasing) specialist-vetted answers to FAQs for point of care use. However, because of the overabundance of clinical resources and guidelines, adding new answers manually to AME and ensuring that it is consistent with evidence is time consuming. This problem is also faced with other systems such as UpToDate. This career grant proposes to investigate the feasibility of using a novel text mining based informatics approach to semi-automate the management of a clinical knowledge system, using AME as the test bed. Although the methods will be applicable to any clinical knowledge system and any topic, they will be evaluated using two important test topics from cardiology (which has the biggest focus in AME) - atrial fibrillation (a topic exhaustively covered in AME) and congestive heart failure (a topic less covered, but is an increasingly complex vast field with knowledge from huge literature). While the existing content of AME is private, the methods and the code we develop to assist in generating the content will be released open-source as part of the Open Health Natural Language Processing (OHNLP) consortium in UIMA framework. Career plan: As most communication of information in clinical practice and biomedical research occurs through the medium of text, the development of methods to render this text computer-interpretable is a prerequisite to the use of this information to improve quality of care and support scientific discovery. The PI's long-term career goal is to become a leader in biomedical informatics (informatics applied to biomedical data), with focus on textual data such as scientific papers and clinical notes. He has BS in Computer Science, PhD in Biomedical Informatics and over a dozen of peer-reviewed publications in biomedical text mining. His career goal is to advance diverse methods and applications of text mining across biomedical informatics (BMI). He will focus on: a) discovering information needs and gaps that can be filled, b) adapting and extending existing text mining algorithms, and c) validating the utility of the applications in the biomedical environment. Rationale: Making the transition from a mentored researcher to an independent researcher requires three main facets of career growth: a) developing a working familiarity with clinical information systems and medical terminologies; b) understanding the information needs of clinicians; and c) training in clinical research. The proposal will translate the PI's knowledgeof the text mining methods to practical experience in an operation clinical environment. Courses listed in the ""Career Development/Training Activities"" will educate him more about the environment and train him on clinical research. He will continue sharpening his informatics expertise by attending scientific conferences. Project Narrative Medical errors are one of the leading causes of death in the United States. It has been observed that point of care access to relevant clinical knowledge support decision making and decreases medical errors, thereby improving patient safety and healthcare costs. The proposed research aims to empower physicians specialized in the area (specialists) in quickly gathering evidence from literature or finding citations supporting or qualifying their expert opinion. It will also generate the answers and suggest updates to the existing answers for their perusal.",Improving the Efficiency and Efficacy in Authoring Essential Clinical FAQs,8906938,R00LM011389,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Beds', 'Biomedical Research', 'Calculi', 'Cardiology', 'Cause of Death', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Code', 'Communication', 'Complex', 'Computers', 'Congestive Heart Failure', 'Cross-Over Studies', 'Data', 'Decision Making', 'Doctor of Philosophy', 'Electronic Health Record', 'Ensure', 'Environment', 'Expert Opinion', 'Familiarity', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Grant', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Health Services Accessibility', 'Healthcare', 'Human', 'Informatics', 'Information Retrieval Systems', 'Journals', 'Knowledge', 'Language', 'Link', 'Literature', 'Medical', 'Medical Errors', 'Mentors', 'Methods', 'Natural Language Processing', 'Nurses', 'Paper', 'Peer Review', 'Physicians', 'Publications', 'Publishing', 'Qualifying', 'Quality of Care', 'Randomized', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Specialist', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Training', 'Training Activity', 'Translating', 'United States', 'Update', 'Validation', 'Vocabulary', 'Work', 'Workload', 'Writing', 'base', 'biomedical informatics', 'career', 'career development', 'clinical decision-making', 'clinical practice', 'computer science', 'empowered', 'evidence base', 'experience', 'improved', 'information gathering', 'medical information system', 'method development', 'novel', 'open source', 'operation', 'patient safety', 'point of care', 'statistics', 'symposium', 'text searching', 'usability']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R00,2015,217378,0.031453895668153264
"Challenges in Natural Language Processing for Clinical Narratives DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges. Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8913773,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2015,19800,0.10748875399155434
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                 Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8722031,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2014,19998,0.10748875399155434
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                  Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8538500,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2013,18400,0.10748875399155434
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                  Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8400218,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2012,20000,0.10748875399155434
"Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries DESCRIPTION (provided by applicant): This project focuses on designing and evaluating methods to improve clinician decision-making by generating clinician-tailored and patient-specific knowledge summaries. Knowledge summaries will consist of semantic fragments (i.e., small units of text that provide meaningful information) that are relevant to a clinician's patient specific information needs. This kind of decision support is important because clinicians often raise information needs in the course of patient care and these needs are largely unmet. Unmet information needs are missed opportunities for self-directed learning and improved patient care.     Although answers to clinicians' questions can often be found in online health knowledge resources, significant barriers limit the use of these resources for patient care. An increasingly popular approach to lowering these barriers is to provide context-sensitive ""infobutton"" links within electronic health record (EHR) systems. Based on the clinical context, infobuttons anticipate clinicians' information needs and provide relevant links to knowledge resources. Infobuttons do a good job helping clinicians' meet simple information needs, but are less optimal when (i) answers cannot be easily found without substantial cognitive effort scanning the information retrieved; and (ii) the information need is associated with data not displayed on the EHR screen.     In the proposed study, we will address limitations of previous approaches leveraging significant preliminary research, state-of-the-art information extraction and text summarization tools, and increasingly adopted EHR standards. The research will be guided by a foundation of information-seeking behavior theories. The study has the following aims and hypotheses:     *	Generate knowledge summaries leveraging patients' EHR data. H1: Knowledge summaries are more efficacious and efficient than manual search for finding answers to patient-specific questions.     *	Identify contextual and cognitive factors that contribute to clinicians' information needs and information-seeking behavior. H1: (i) Contextual and cognitive factors are associated with the type of information need; and (ii) with the decision to pursue an information need.     *	Transform knowledge summaries into tailored knowledge summaries based on clinician's contextual and cognitive factors. H1: Clinician tailored knowledge summaries are more efficacious and efficient than knowledge summaries for meeting clinicians' information needs and improving decision-making. Narrative The proposed research addresses a significant problem related to the large frequency of information needs that clinicians raise in the course of care and are not met. Unmet information needs are among the main causes of medical errors and are missed opportunities for self-directed learning. In this study, we will address this problem by providing clinicians with patient-specific and clinician-tailored knowledge summaries. The proposed system will be developed with a set of open source tools and resources, in a standards-compliant software architecture. Thus, our research has the potential to be replicated on a national scale and to play a significant role in the overall improvement of health and health care.",Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries,9031148,R01LM011416,"['Address', 'Adopted', 'Architecture', 'Automated Abstracting', 'Behavior', 'Caring', 'Clinical', 'Cognitive', 'Computer software', 'Continuity of Patient Care', 'Data', 'Decision Making', 'Electronic Health Record', 'Environment', 'Foundations', 'Frequencies', 'Health', 'Health Status', 'Healthcare', 'Imagery', 'Information Resources', 'Knowledge', 'Link', 'Manuals', 'Medical Errors', 'Methods', 'Occupations', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Provider', 'PubMed', 'Randomized Controlled Trials', 'Research', 'Resources', 'Role', 'Scanning', 'Semantics', 'System', 'Text', 'Time', 'base', 'contextual factors', 'design', 'improved', 'information seeking behavior', 'meetings', 'novel strategies', 'open source', 'self-directed learning', 'text searching', 'theories', 'tool']",NLM,UNIVERSITY OF UTAH,R01,2016,324457,0.04854603254489053
"Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries DESCRIPTION (provided by applicant): This project focuses on designing and evaluating methods to improve clinician decision-making by generating clinician-tailored and patient-specific knowledge summaries. Knowledge summaries will consist of semantic fragments (i.e., small units of text that provide meaningful information) that are relevant to a clinician's patient specific information needs. This kind of decision support is important because clinicians often raise information needs in the course of patient care and these needs are largely unmet. Unmet information needs are missed opportunities for self-directed learning and improved patient care.     Although answers to clinicians' questions can often be found in online health knowledge resources, significant barriers limit the use of these resources for patient care. An increasingly popular approach to lowering these barriers is to provide context-sensitive ""infobutton"" links within electronic health record (EHR) systems. Based on the clinical context, infobuttons anticipate clinicians' information needs and provide relevant links to knowledge resources. Infobuttons do a good job helping clinicians' meet simple information needs, but are less optimal when (i) answers cannot be easily found without substantial cognitive effort scanning the information retrieved; and (ii) the information need is associated with data not displayed on the EHR screen.     In the proposed study, we will address limitations of previous approaches leveraging significant preliminary research, state-of-the-art information extraction and text summarization tools, and increasingly adopted EHR standards. The research will be guided by a foundation of information-seeking behavior theories. The study has the following aims and hypotheses:     *	Generate knowledge summaries leveraging patients' EHR data. H1: Knowledge summaries are more efficacious and efficient than manual search for finding answers to patient-specific questions.     *	Identify contextual and cognitive factors that contribute to clinicians' information needs and information-seeking behavior. H1: (i) Contextual and cognitive factors are associated with the type of information need; and (ii) with the decision to pursue an information need.     *	Transform knowledge summaries into tailored knowledge summaries based on clinician's contextual and cognitive factors. H1: Clinician tailored knowledge summaries are more efficacious and efficient than knowledge summaries for meeting clinicians' information needs and improving decision-making. Narrative The proposed research addresses a significant problem related to the large frequency of information needs that clinicians raise in the course of care and are not met. Unmet information needs are among the main causes of medical errors and are missed opportunities for self-directed learning. In this study, we will address this problem by providing clinicians with patient-specific and clinician-tailored knowledge summaries. The proposed system will be developed with a set of open source tools and resources, in a standards-compliant software architecture. Thus, our research has the potential to be replicated on a national scale and to play a significant role in the overall improvement of health and health care.",Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries,8830471,R01LM011416,"['Address', 'Adopted', 'Architecture', 'Automated Abstracting', 'Behavior', 'Caring', 'Clinical', 'Cognitive', 'Computer software', 'Continuity of Patient Care', 'Data', 'Decision Making', 'Electronic Health Record', 'Environment', 'Foundations', 'Frequencies', 'Health', 'Health Status', 'Healthcare', 'Imagery', 'Information Resources', 'Knowledge', 'Learning', 'Link', 'Manuals', 'Medical Errors', 'Methods', 'Occupations', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Provider', 'PubMed', 'Randomized Controlled Trials', 'Research', 'Resources', 'Role', 'Scanning', 'Semantics', 'System', 'Text', 'Time', 'base', 'contextual factors', 'design', 'improved', 'information seeking behavior', 'meetings', 'novel strategies', 'open source', 'text searching', 'theories', 'tool']",NLM,UNIVERSITY OF UTAH,R01,2015,315371,0.04854603254489053
"Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries     DESCRIPTION (provided by applicant): This project focuses on designing and evaluating methods to improve clinician decision-making by generating clinician-tailored and patient-specific knowledge summaries. Knowledge summaries will consist of semantic fragments (i.e., small units of text that provide meaningful information) that are relevant to a clinician's patient specific information needs. This kind of decision support is important because clinicians often raise information needs in the course of patient care and these needs are largely unmet. Unmet information needs are missed opportunities for self-directed learning and improved patient care.     Although answers to clinicians' questions can often be found in online health knowledge resources, significant barriers limit the use of these resources for patient care. An increasingly popular approach to lowering these barriers is to provide context-sensitive ""infobutton"" links within electronic health record (EHR) systems. Based on the clinical context, infobuttons anticipate clinicians' information needs and provide relevant links to knowledge resources. Infobuttons do a good job helping clinicians' meet simple information needs, but are less optimal when (i) answers cannot be easily found without substantial cognitive effort scanning the information retrieved; and (ii) the information need is associated with data not displayed on the EHR screen.     In the proposed study, we will address limitations of previous approaches leveraging significant preliminary research, state-of-the-art information extraction and text summarization tools, and increasingly adopted EHR standards. The research will be guided by a foundation of information-seeking behavior theories. The study has the following aims and hypotheses:     *	Generate knowledge summaries leveraging patients' EHR data. H1: Knowledge summaries are more efficacious and efficient than manual search for finding answers to patient-specific questions.     *	Identify contextual and cognitive factors that contribute to clinicians' information needs and information-seeking behavior. H1: (i) Contextual and cognitive factors are associated with the type of information need; and (ii) with the decision to pursue an information need.     *	Transform knowledge summaries into tailored knowledge summaries based on clinician's contextual and cognitive factors. H1: Clinician tailored knowledge summaries are more efficacious and efficient than knowledge summaries for meeting clinicians' information needs and improving decision-making.              Narrative The proposed research addresses a significant problem related to the large frequency of information needs that clinicians raise in the course of care and are not met. Unmet information needs are among the main causes of medical errors and are missed opportunities for self-directed learning. In this study, we will address this problem by providing clinicians with patient-specific and clinician-tailored knowledge summaries. The proposed system will be developed with a set of open source tools and resources, in a standards-compliant software architecture. Thus, our research has the potential to be replicated on a national scale and to play a significant role in the overall improvement of health and health care.",Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries,8643820,R01LM011416,"['Address', 'Adopted', 'Architecture', 'Automated Abstracting', 'Behavior', 'Caring', 'Clinical', 'Cognitive', 'Computer software', 'Continuity of Patient Care', 'Data', 'Decision Making', 'Electronic Health Record', 'Environment', 'Foundations', 'Frequencies', 'Health', 'Health Status', 'Healthcare', 'Imagery', 'Information Resources', 'Knowledge', 'Learning', 'Link', 'Manuals', 'Medical Errors', 'Methods', 'Occupations', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Provider', 'PubMed', 'Randomized Controlled Trials', 'Research', 'Resources', 'Role', 'Scanning', 'Semantics', 'Simulate', 'System', 'Text', 'Time', 'base', 'contextual factors', 'design', 'improved', 'information seeking behavior', 'meetings', 'novel strategies', 'open source', 'text searching', 'theories', 'tool']",NLM,UNIVERSITY OF UTAH,R01,2014,326496,0.04854603254489053
"Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries     DESCRIPTION (provided by applicant): This project focuses on designing and evaluating methods to improve clinician decision-making by generating clinician-tailored and patient-specific knowledge summaries. Knowledge summaries will consist of semantic fragments (i.e., small units of text that provide meaningful information) that are relevant to a clinician's patient specific information needs. This kind of decision support is important because clinicians often raise information needs in the course of patient care and these needs are largely unmet. Unmet information needs are missed opportunities for self-directed learning and improved patient care.     Although answers to clinicians' questions can often be found in online health knowledge resources, significant barriers limit the use of these resources for patient care. An increasingly popular approach to lowering these barriers is to provide context-sensitive ""infobutton"" links within electronic health record (EHR) systems. Based on the clinical context, infobuttons anticipate clinicians' information needs and provide relevant links to knowledge resources. Infobuttons do a good job helping clinicians' meet simple information needs, but are less optimal when (i) answers cannot be easily found without substantial cognitive effort scanning the information retrieved; and (ii) the information need is associated with data not displayed on the EHR screen.     In the proposed study, we will address limitations of previous approaches leveraging significant preliminary research, state-of-the-art information extraction and text summarization tools, and increasingly adopted EHR standards. The research will be guided by a foundation of information-seeking behavior theories. The study has the following aims and hypotheses:     *	Generate knowledge summaries leveraging patients' EHR data. H1: Knowledge summaries are more efficacious and efficient than manual search for finding answers to patient-specific questions.     *	Identify contextual and cognitive factors that contribute to clinicians' information needs and information-seeking behavior. H1: (i) Contextual and cognitive factors are associated with the type of information need; and (ii) with the decision to pursue an information need.     *	Transform knowledge summaries into tailored knowledge summaries based on clinician's contextual and cognitive factors. H1: Clinician tailored knowledge summaries are more efficacious and efficient than knowledge summaries for meeting clinicians' information needs and improving decision-making.              Narrative The proposed research addresses a significant problem related to the large frequency of information needs that clinicians raise in the course of care and are not met. Unmet information needs are among the main causes of medical errors and are missed opportunities for self-directed learning. In this study, we will address this problem by providing clinicians with patient-specific and clinician-tailored knowledge summaries. The proposed system will be developed with a set of open source tools and resources, in a standards-compliant software architecture. Thus, our research has the potential to be replicated on a national scale and to play a significant role in the overall improvement of health and health care.",Meeting Clinicians' Information Needs with Highly Tailored Knowledge Summaries,8417286,R01LM011416,"['Address', 'Adopted', 'Architecture', 'Automated Abstracting', 'Behavior', 'Caring', 'Clinical', 'Cognitive', 'Computer software', 'Continuity of Patient Care', 'Data', 'Decision Making', 'Electronic Health Record', 'Environment', 'Foundations', 'Frequencies', 'Health', 'Health Status', 'Healthcare', 'Imagery', 'Information Resources', 'Knowledge', 'Learning', 'Link', 'Manuals', 'Medical Errors', 'Methods', 'Occupations', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Provider', 'PubMed', 'Randomized Controlled Trials', 'Research', 'Resources', 'Role', 'Scanning', 'Semantics', 'Simulate', 'System', 'Text', 'Time', 'base', 'contextual factors', 'design', 'improved', 'information seeking behavior', 'meetings', 'novel strategies', 'open source', 'text searching', 'theories', 'tool']",NLM,UNIVERSITY OF UTAH,R01,2013,349820,0.04854603254489053
"Robust Inference from Observational Data with Distributed Representations of Conceptual Relations The need to monitor unintended effects of approved drugs has been highlighted by several recent high-profile events in which fatal side effects of drugs were detected after their release to market. Notoriously, the Cox-2 inhibitor rofecoxib (Vioxx) was withdrawn from market on account of evidence suggesting that treatment with the drug increased the rate of myocardial infarction. More recently, proton pump inhibitors have been identified with a host of previously undetected serious side effects, including chronic kidney disease. Statistical analyses of several sorts of data have been undertaken in an effort to mitigate the morbitidy and mortality resulting from such side effects by accelerating their detection. These include data from adverse event reporting systems, Electronic Health Records (EHR) and administrative claims data, social media communication and consumer search logs. Each of these sources presents challenges related to data completeness, accuracy, quality and representation, as well as the potential for bias. Though methods for combining multiple data sources show some promise as a way to address their particular inadequacies, strongly correlated drug-event pairs emerging from secondary analysis of observational data must ultimately be reviewed by domain experts to assess their implications. As the availability of the prerequisite expertise is limited, there is a pressing need for new methods to distinguish plausibly causal relationships from the large number of false positive associations that may emerge from large-scale analysis of observational data. In the proposed research, we will develop automated methods through which large amounts of knowledge extracted from the biomedical literature are used to constrain the parameterization of predictive models of large data sets. These methods will leverage high-dimensional distributed vector representations of conceptual relations extracted from the literature to integrate extracted knowledge into predictive models of observational data. Our hypothesis is that the predictions that result from such joint models will be both biologically plausible and strongly associated, resulting in more accurate predictions than those that can be obtained through estimation of correlation from observational data alone. The developed methods will be evaluated formatively for accuracy against a set of drug/side-effect reference standards, and summatively for their ability to to predict label changes such as black box warnings using historical data and knowledge to estimate their time-to-detection of safety concerns. In addition, we will develop and evaluate an interactive interface permitting users to explore the evidence used by the resulting models to make predictions, by retrieving supporting assertions from the literature and statistics from observational data. If successful, the proposed research will provide the means to identify plausible drug-event pairs for regulatory purposes, mitigating consequent morbidity and mortality. In addition, the methods will provide a generalizable approach that can be used to apply knowledge derived from the biomedical literature to draw robust inferences from observational clinical data. Project Narrative The need to monitor unintended effects of medications has been highlighted by several high-profile events in which fatal side effects of approved drugs were detected after their release to market. In the proposed research, we will develop and evaluate methods to identify biologically plausible adverse drug events using both observational data and knowledge extracted from the biomedical literature. If successful, these methods will provide the means for earlier detection of harmful drug effects, limiting consequent morbidity and mortality.",Robust Inference from Observational Data with Distributed Representations of Conceptual Relations,9928987,R01LM011563,"['Address', 'Adverse drug effect', 'Adverse drug event', 'Adverse event', 'Biological', 'Chronic Kidney Failure', 'Clinical Data', 'Cognitive', 'Communications Media', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Drug Monitoring', 'Early Diagnosis', 'Electronic Health Record', 'Engineering', 'Etiology', 'Evaluation', 'Event', 'Foundations', 'Generations', 'Infrastructure', 'Joints', 'Knowledge', 'Label', 'Literature', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Policies', 'Positioning Attribute', 'Procedures', 'Proton Pump Inhibitors', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Rofecoxib', 'Safety', 'Secure', 'Semantics', 'Source', 'Statistical Data Interpretation', 'Statistical Models', 'System', 'Time', 'Training', 'Work', 'data integration', 'high dimensionality', 'improved', 'information organization', 'inhibitor/antagonist', 'interest', 'large datasets', 'machine learning method', 'mortality', 'multiple data sources', 'patient safety', 'pharmacovigilance', 'predictive modeling', 'relating to nervous system', 'response', 'secondary analysis', 'side effect', 'social media', 'statistics', 'usability', 'vector']",NLM,UNIVERSITY OF WASHINGTON,R01,2020,505146,0.015134389444067272
"Robust Inference from Observational Data with Distributed Representations of Conceptual Relations The need to monitor unintended effects of approved drugs has been highlighted by several recent high-profile events in which fatal side effects of drugs were detected after their release to market. Notoriously, the Cox-2 inhibitor rofecoxib (Vioxx) was withdrawn from market on account of evidence suggesting that treatment with the drug increased the rate of myocardial infarction. More recently, proton pump inhibitors have been identified with a host of previously undetected serious side effects, including chronic kidney disease. Statistical analyses of several sorts of data have been undertaken in an effort to mitigate the morbitidy and mortality resulting from such side effects by accelerating their detection. These include data from adverse event reporting systems, Electronic Health Records (EHR) and administrative claims data, social media communication and consumer search logs. Each of these sources presents challenges related to data completeness, accuracy, quality and representation, as well as the potential for bias. Though methods for combining multiple data sources show some promise as a way to address their particular inadequacies, strongly correlated drug-event pairs emerging from secondary analysis of observational data must ultimately be reviewed by domain experts to assess their implications. As the availability of the prerequisite expertise is limited, there is a pressing need for new methods to distinguish plausibly causal relationships from the large number of false positive associations that may emerge from large-scale analysis of observational data. In the proposed research, we will develop automated methods through which large amounts of knowledge extracted from the biomedical literature are used to constrain the parameterization of predictive models of large data sets. These methods will leverage high-dimensional distributed vector representations of conceptual relations extracted from the literature to integrate extracted knowledge into predictive models of observational data. Our hypothesis is that the predictions that result from such joint models will be both biologically plausible and strongly associated, resulting in more accurate predictions than those that can be obtained through estimation of correlation from observational data alone. The developed methods will be evaluated formatively for accuracy against a set of drug/side-effect reference standards, and summatively for their ability to to predict label changes such as black box warnings using historical data and knowledge to estimate their time-to-detection of safety concerns. In addition, we will develop and evaluate an interactive interface permitting users to explore the evidence used by the resulting models to make predictions, by retrieving supporting assertions from the literature and statistics from observational data. If successful, the proposed research will provide the means to identify plausible drug-event pairs for regulatory purposes, mitigating consequent morbidity and mortality. In addition, the methods will provide a generalizable approach that can be used to apply knowledge derived from the biomedical literature to draw robust inferences from observational clinical data. Project Narrative The need to monitor unintended effects of medications has been highlighted by several high-profile events in which fatal side effects of approved drugs were detected after their release to market. In the proposed research, we will develop and evaluate methods to identify biologically plausible adverse drug events using both observational data and knowledge extracted from the biomedical literature. If successful, these methods will provide the means for earlier detection of harmful drug effects, limiting consequent morbidity and mortality.",Robust Inference from Observational Data with Distributed Representations of Conceptual Relations,9707917,R01LM011563,"['Address', 'Adverse drug effect', 'Adverse drug event', 'Adverse event', 'Biological', 'Chronic Kidney Failure', 'Clinical Data', 'Cognitive', 'Communications Media', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Drug Monitoring', 'Early Diagnosis', 'Electronic Health Record', 'Engineering', 'Etiology', 'Evaluation', 'Event', 'Foundations', 'Generations', 'Infrastructure', 'Joints', 'Knowledge', 'Label', 'Literature', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Policies', 'Positioning Attribute', 'Procedures', 'Proton Pump Inhibitors', 'Reference Standards', 'Reporting', 'Research', 'Retrieval', 'Rofecoxib', 'Safety', 'Secure', 'Semantics', 'Source', 'Statistical Data Interpretation', 'Statistical Models', 'System', 'Time', 'Training', 'Work', 'data integration', 'high dimensionality', 'improved', 'information organization', 'inhibitor/antagonist', 'interest', 'learning strategy', 'mortality', 'patient safety', 'pharmacovigilance', 'predictive modeling', 'relating to nervous system', 'response', 'secondary analysis', 'side effect', 'social media', 'statistics', 'usability', 'vector']",NLM,UNIVERSITY OF WASHINGTON,R01,2019,505078,0.015134389444067272
"Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance DESCRIPTION (provided by applicant): The need to monitor unintended effects of approved drugs has been highlighted by several recent high-profile events in which fatal side effects of drugs were detected after their release to market. Notoriously, the Cox-2 inhibitor Rofecoxib (Vioxx) was withdrawn from market on account of evidence suggesting that treatment with the drug increased the rate of coronary artery disease, and recently new evidence has emerged suggesting the commonly used antibiotic Azithromycin (Zithromax) may cause fatal arrythmias. In an effort to mitigate the morbidity and mortality resulting from such undetected side effects, regulatory bodies such as the Food and Drug Administration (FDA) have instituted spontaneous reporting systems to systematize post-marketing surveillance. However there is evidence that under-reporting of adverse drug events (ADEs) is widespread. Automated monitoring of events documented in the Electronic Health Record (EHR) as free text or structured data has been proposed as a path toward earlier identification of meaningfully correlated drug-event pairs. As these pairs must ultimately be reviewed by domain experts to assess their implications, there is a pressing need to develop methods to selectively identify plausible drug-event pairs within the large pool of correlations to be found in clinical data. In the proposed research, we will develop and evaluate models of biological plausibility, based on knowledge extracted from the biomedical literature and using methods of hyperdimensional computing for efficient search and inference across multiple concepts and relations simultaneously. These methods will be used to selectively identify plausible drug-event pairs found in structured clinical data, and extracted from unstructured data using natural language extraction. The developed methods will be evaluated formatively, for their ability to rediscover known side effects from the biomedical literature, and summatively for their ability to improve the precision of effects attributed to a st of known drugs using statistical methods alone. In addition we will evaluate their ability to predict recent FDA warnings, using historical data and knowledge. If successful, the proposed research will provide the means to identify automatically plausible drug-event pairs for regulatory purposes, mitigating consequent morbidity and mortality. In addition, the methods will provide a generalizable approach that can be used to apply knowledge derived from the biomedical literature to interpret clinical data. Project Narrative The need to monitor unintended effects of medications has been highlighted by several high-profile events in which fatal side effects of approved drugs were detected after their release to market. In the proposed research, we will develop and evaluate methods to identify automatically biologically plausible adverse drug events found within clinical patient records, using knowledge extracted from the biomedical literature. If successful, these methods will provide the means for earlier detection of harmful drug effects, limiting consequent morbidity and mortality.",Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance,8909187,R01LM011563,"['Accounting', 'Adverse drug effect', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Antibiotics', 'Azithromycin', 'Biological', 'Biological Models', 'Biometry', 'Clinical', 'Clinical Data', 'Computational Linguistics', 'Coronary Arteriosclerosis', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Healthcare', 'Human', 'Institutes', 'Knowledge', 'Label', 'Licensing', 'Literature', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Output', 'Package Insert', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Policies', 'Positioning Attribute', 'Procedures', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Rofecoxib', 'Secure', 'Signal Transduction', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Text', 'United States Food and Drug Administration', 'Work', 'base', 'biomedical informatics', 'improved', 'inhibitor/antagonist', 'mortality', 'natural language', 'novel', 'post-market', 'statistics', 'tool']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,293778,0.04075556599450062
"Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance DESCRIPTION (provided by applicant): The need to monitor unintended effects of approved drugs has been highlighted by several recent high-profile events in which fatal side effects of drugs were detected after their release to market. Notoriously, the Cox-2 inhibitor Rofecoxib (Vioxx) was withdrawn from market on account of evidence suggesting that treatment with the drug increased the rate of coronary artery disease, and recently new evidence has emerged suggesting the commonly used antibiotic Azithromycin (Zithromax) may cause fatal arrythmias. In an effort to mitigate the morbidity and mortality resulting from such undetected side effects, regulatory bodies such as the Food and Drug Administration (FDA) have instituted spontaneous reporting systems to systematize post-marketing surveillance. However there is evidence that under-reporting of adverse drug events (ADEs) is widespread. Automated monitoring of events documented in the Electronic Health Record (EHR) as free text or structured data has been proposed as a path toward earlier identification of meaningfully correlated drug-event pairs. As these pairs must ultimately be reviewed by domain experts to assess their implications, there is a pressing need to develop methods to selectively identify plausible drug-event pairs within the large pool of correlations to be found in clinical data. In the proposed research, we will develop and evaluate models of biological plausibility, based on knowledge extracted from the biomedical literature and using methods of hyperdimensional computing for efficient search and inference across multiple concepts and relations simultaneously. These methods will be used to selectively identify plausible drug-event pairs found in structured clinical data, and extracted from unstructured data using natural language extraction. The developed methods will be evaluated formatively, for their ability to rediscover known side effects from the biomedical literature, and summatively for their ability to improve the precision of effects attributed to a st of known drugs using statistical methods alone. In addition we will evaluate their ability to predict recent FDA warnings, using historical data and knowledge. If successful, the proposed research will provide the means to identify automatically plausible drug-event pairs for regulatory purposes, mitigating consequent morbidity and mortality. In addition, the methods will provide a generalizable approach that can be used to apply knowledge derived from the biomedical literature to interpret clinical data. Project Narrative The need to monitor unintended effects of medications has been highlighted by several high-profile events in which fatal side effects of approved drugs were detected after their release to market. In the proposed research, we will develop and evaluate methods to identify automatically biologically plausible adverse drug events found within clinical patient records, using knowledge extracted from the biomedical literature. If successful, these methods will provide the means for earlier detection of harmful drug effects, limiting consequent morbidity and mortality.",Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance,8914098,R01LM011563,"['Accounting', 'Adverse Drug Experience Report', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Antibiotics', 'Azithromycin', 'Biological', 'Biological Models', 'Biometry', 'Clinical', 'Clinical Data', 'Computational Linguistics', 'Coronary Arteriosclerosis', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Healthcare', 'Human', 'Institutes', 'Knowledge', 'Label', 'Licensing', 'Literature', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Output', 'Package Insert', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Policies', 'Positioning Attribute', 'Procedures', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Rofecoxib', 'Secure', 'Signal Transduction', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Text', 'United States Food and Drug Administration', 'Work', 'base', 'biomedical informatics', 'improved', 'inhibitor/antagonist', 'mortality', 'natural language', 'novel', 'post-market', 'statistics', 'tool']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,160000,0.04075556599450062
"Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance     DESCRIPTION (provided by applicant): The need to monitor unintended effects of approved drugs has been highlighted by several recent high-profile events in which fatal side effects of drugs were detected after their release to market. Notoriously, the Cox-2 inhibitor Rofecoxib (Vioxx) was withdrawn from market on account of evidence suggesting that treatment with the drug increased the rate of coronary artery disease, and recently new evidence has emerged suggesting the commonly used antibiotic Azithromycin (Zithromax) may cause fatal arrythmias. In an effort to mitigate the morbidity and mortality resulting from such undetected side effects, regulatory bodies such as the Food and Drug Administration (FDA) have instituted spontaneous reporting systems to systematize post-marketing surveillance. However there is evidence that under-reporting of adverse drug events (ADEs) is widespread. Automated monitoring of events documented in the Electronic Health Record (EHR) as free text or structured data has been proposed as a path toward earlier identification of meaningfully correlated drug-event pairs. As these pairs must ultimately be reviewed by domain experts to assess their implications, there is a pressing need to develop methods to selectively identify plausible drug-event pairs within the large pool of correlations to be found in clinical data. In the proposed research, we will develop and evaluate models of biological plausibility, based on knowledge extracted from the biomedical literature and using methods of hyperdimensional computing for efficient search and inference across multiple concepts and relations simultaneously. These methods will be used to selectively identify plausible drug-event pairs found in structured clinical data, and extracted from unstructured data using natural language extraction. The developed methods will be evaluated formatively, for their ability to rediscover known side effects from the biomedical literature, and summatively for their ability to improve the precision of effects attributed to a st of known drugs using statistical methods alone. In addition we will evaluate their ability to predict recent FDA warnings, using historical data and knowledge. If successful, the proposed research will provide the means to identify automatically plausible drug-event pairs for regulatory purposes, mitigating consequent morbidity and mortality. In addition, the methods will provide a generalizable approach that can be used to apply knowledge derived from the biomedical literature to interpret clinical data.             Project Narrative The need to monitor unintended effects of medications has been highlighted by several high-profile events in which fatal side effects of approved drugs were detected after their release to market. In the proposed research, we will develop and evaluate methods to identify automatically biologically plausible adverse drug events found within clinical patient records, using knowledge extracted from the biomedical literature. If successful, these methods will provide the means for earlier detection of harmful drug effects, limiting consequent morbidity and mortality.",Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance,8727094,R01LM011563,"['Accounting', 'Adverse Drug Experience Report', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Antibiotics', 'Azithromycin', 'Biological', 'Biological Models', 'Biometry', 'Clinical', 'Clinical Data', 'Computational Linguistics', 'Coronary Arteriosclerosis', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Healthcare', 'Human', 'Institutes', 'Knowledge', 'Label', 'Licensing', 'Literature', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Output', 'Package Insert', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Policies', 'Positioning Attribute', 'Procedures', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Rofecoxib', 'Secure', 'Signal Transduction', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Text', 'United States Food and Drug Administration', 'Work', 'base', 'biomedical informatics', 'improved', 'inhibitor/antagonist', 'mortality', 'natural language', 'novel', 'post-market', 'statistics', 'tool']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,302589,0.04075556599450062
"Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance     DESCRIPTION (provided by applicant): The need to monitor unintended effects of approved drugs has been highlighted by several recent high-profile events in which fatal side effects of drugs were detected after their release to market. Notoriously, the Cox-2 inhibitor Rofecoxib (Vioxx) was withdrawn from market on account of evidence suggesting that treatment with the drug increased the rate of coronary artery disease, and recently new evidence has emerged suggesting the commonly used antibiotic Azithromycin (Zithromax) may cause fatal arrythmias. In an effort to mitigate the morbidity and mortality resulting from such undetected side effects, regulatory bodies such as the Food and Drug Administration (FDA) have instituted spontaneous reporting systems to systematize post-marketing surveillance. However there is evidence that under-reporting of adverse drug events (ADEs) is widespread. Automated monitoring of events documented in the Electronic Health Record (EHR) as free text or structured data has been proposed as a path toward earlier identification of meaningfully correlated drug-event pairs. As these pairs must ultimately be reviewed by domain experts to assess their implications, there is a pressing need to develop methods to selectively identify plausible drug-event pairs within the large pool of correlations to be found in clinical data. In the proposed research, we will develop and evaluate models of biological plausibility, based on knowledge extracted from the biomedical literature and using methods of hyperdimensional computing for efficient search and inference across multiple concepts and relations simultaneously. These methods will be used to selectively identify plausible drug-event pairs found in structured clinical data, and extracted from unstructured data using natural language extraction. The developed methods will be evaluated formatively, for their ability to rediscover known side effects from the biomedical literature, and summatively for their ability to improve the precision of effects attributed to a st of known drugs using statistical methods alone. In addition we will evaluate their ability to predict recent FDA warnings, using historical data and knowledge. If successful, the proposed research will provide the means to identify automatically plausible drug-event pairs for regulatory purposes, mitigating consequent morbidity and mortality. In addition, the methods will provide a generalizable approach that can be used to apply knowledge derived from the biomedical literature to interpret clinical data.              Project Narrative The need to monitor unintended effects of medications has been highlighted by several high-profile events in which fatal side effects of approved drugs were detected after their release to market. In the proposed research, we will develop and evaluate methods to identify automatically biologically plausible adverse drug events found within clinical patient records, using knowledge extracted from the biomedical literature. If successful, these methods will provide the means for earlier detection of harmful drug effects, limiting consequent morbidity and mortality.",Using Biomedical Knowledge to Identify Plausible Signals for Pharmacovigilance,8630441,R01LM011563,"['Accounting', 'Adverse Drug Experience Report', 'Adverse drug effect', 'Adverse effects', 'Adverse event', 'Antibiotics', 'Azithromycin', 'Biological', 'Biological Models', 'Biometry', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Healthcare', 'Human', 'Institutes', 'Knowledge', 'Label', 'Licensing', 'Linguistics', 'Literature', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Output', 'Package Insert', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Policies', 'Positioning Attribute', 'Procedures', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Rofecoxib', 'Secure', 'Signal Transduction', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Text', 'United States Food and Drug Administration', 'Work', 'base', 'biomedical informatics', 'improved', 'inhibitor/antagonist', 'mortality', 'natural language', 'novel', 'post-market', 'statistics', 'tool']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2013,309937,0.04075556599450062
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,9187058,R00LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Structure', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'health care delivery', 'improved', 'learning strategy', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2016,251021,0.08969095257094191
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,8978947,K99LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Solutions', 'Structure', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'health care delivery', 'improved', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,K99,2015,83160,0.08969095257094191
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications  PROJECT SUMMARY Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develop a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery.  PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,8633838,K99LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Solutions', 'Structure', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'health care delivery', 'improved', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MAYO CLINIC ROCHESTER,K99,2014,96232,0.08969095257094191
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,9406887,R00LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Standardization', 'Structure', 'Supervision', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'electronic structure', 'health care delivery', 'health care quality', 'improved', 'learning strategy', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2018,248969,0.08969095257094191
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,9201329,R00LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Standardization', 'Structure', 'Supervision', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'electronic structure', 'health care delivery', 'health care quality', 'improved', 'learning strategy', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2017,248969,0.08969095257094191
"A Search Engine for Heterogeneous Information Needs in the Clinical Workflow     DESCRIPTION (provided by applicant): Modern clinical practices represent a prototypical information-intensive, distributed and collaborative environment, where physicians struggle to find the right information at the right time to make effective clinical decisions. The situation is exacerbated not only by federal guidelines and policies regarding compliance to clinical quality metrics and meaningful use, but also by fragmented information networks of hospital information systems, library resources and organizational intranet. As a result, physicians are often left with several unanswered questions that may affect the quality of care they provide to patients. In this application, we describe the deployment and evaluation of 1-Search, an electronic health record (EHR)-integrated, federated medical search engine that enables physicians to search, filter and retrieve both clinical and organizational information at the point of care. We will integrate 1-Search into the EHR at University of Illinois Health Science System (UI Health) academic medical centers at Chicago and Rockford. After deployment, our preliminary evaluation will focus on pilot testing with a small group of physicians to fine-tune 1-Search for use at a large academic setting. The purpose of this preliminary evaluation is to develop a consistent feedback loop to incorporate insights from users and also to fine-tune 1-Search within specific clinical domains and specialties. The second phase of the evaluation will involve in-depth analysis of search logs, search patterns and search efficiency. We will also conduct a user study with a sub-group of physicians to characterize their interactions with 1- Search and their perspectives on its use. This multi-phased evaluation will help us develop comprehensive insights on the deployment, use, sustainability and adoption of 1-Search that can be translated for other commercial deployment efforts. PUBLIC HEALTH RELEVANCE: Access to information at the point-of-care can help clinicians in their decision-making leading to potentially improved patient outcomes. In this project, we propose to expand on the results from a Phase I project by deploying MedSocket's medical search engine, 1-Search, in the Electronic Health Record of a large academic medical center. A multi- phased evaluation will be conducted to develop a consistent feedback loop to incorporate insights from clinicians, and also to fine-tune 1-Search within specific clinical domains and specialties that can be translated for other commercial deployment efforts.",A Search Engine for Heterogeneous Information Needs in the Clinical Workflow,9341388,R44LM011590,"['Academic Medical Centers', 'Access to Information', 'Adoption', 'Adverse event', 'Affect', 'Architecture', 'Chicago', 'Clinical', 'Cognitive', 'Communities', 'Custom', 'Decision Making', 'Development', 'Electronic Health Record', 'Environment', 'Evaluation', 'Face', 'Feedback', 'Future', 'Geography', 'Guidelines', 'Health', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Hospital Information Systems', 'Hospitals', 'Illinois', 'Information Networks', 'Information Technology', 'Inpatients', 'Insurance', 'Intervention', 'Interview', 'Intranet', 'Knowledge', 'Left', 'Libraries', 'Link', 'Medical', 'Memory', 'Modernization', 'Outcome', 'Outpatients', 'Patient Care', 'Patient Education', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perception', 'Phase', 'Physicians', 'Policies', 'Quality of Care', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Semantics', 'Subgroup', 'System', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Use Effectiveness', 'Visual', 'base', 'clinical practice', 'clinical research site', 'collaborative environment', 'commercialization', 'design', 'evidence base', 'flexibility', 'follow-up', 'health information technology', 'improved', 'information organization', 'innovation', 'insight', 'medical specialties', 'point of care', 'public health relevance', 'search engine', 'success', 'tool']",NLM,"MEDSOCKET OF MISSOURI, INC.",R44,2017,440098,0.04422578496258961
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6657426,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2003,369494,0.06064951274611473
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6528316,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2002,360015,0.06064951274611473
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6448720,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2001,356099,0.06064951274611473
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",9534182,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Caring', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Structure', 'Supervision', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'application programming interface', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'patient-clinician communication', 'personalized medicine', 'tool', 'trend analysis']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,335217,0.07329112234494056
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",9332464,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Caring', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Structure', 'Supervision', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'application programming interface', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'personalized medicine', 'tool', 'trend analysis']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,335217,0.07329112234494056
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",9115724,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patient Care', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Structure', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'application programming interface', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'personalized medicine', 'tool', 'trend analysis']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,335217,0.07329112234494056
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",8911361,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patient Care', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Solutions', 'Structure', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'personalized medicine', 'programs', 'tool', 'trend']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,325159,0.07329112234494056
"Patient Medical History Representation, Extraction, and Inference from EHR Data     DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported.                 Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",8760594,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Cancer Patient', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Medicine', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patient Care', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Solutions', 'Structure', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'base', 'clinical practice', 'cohort', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'programs', 'tool', 'trend']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,398307,0.07329112234494056
"Right Place, Right Time: Information Design to Support Decisions in Acute Care     DESCRIPTION (provided by applicant): Improving electronic health care information organization, prioritization, and presentation to support patient care is a crucial patient safety priority. Each year tens of thousands of patients are harmed because important information is missed, misunderstood, or identified too late. Providers complain that it is difficult for them to find the information they need quickly and that key information can be missed. Technological advances intended to help providers detect important patient changes or follow through with evidence-based care activities are underway in the form of intelligent surveillance and decision support tools. However, these tools are often perceived as simply adding more to the information load. The primary objective of this project is to implement a user-centered design process to establish design guidelines and evaluate design concepts to better organize, prioritize, and present acute care electronic patient information. Our approach begins by conducting knowledge elicitation activities including interviews, card sorting, and ranking to capture the way acute care information is organized and prioritized in the minds of critical care providers. To account for the importance of context and complexity in health care information organization and prioritization, we will conduct our activities in the context of realistic patientuse cases. We will use the findings from these activities to inform an iterative user-centered design process to create and evaluate conceptual designs for smarter, more effective patient information displays. In our recent qualitative study of information use in critical care settings, we identified a need to design information presentation to support prioritizing patients and tasks, monitoring patients for impending crises or risks, tracking patient status and progress toward goals, and rapid directed information access of dynamic patient data. Thus, our conceptual designs will have these goals as a primary focus. We will conduct interviews, implement heuristic inspection methods, and apply usability testing of design concepts to develop a functioning design prototype. Finally, we will use the findings of this effort to generate knowledge in the form of design guidelines for healthcare information presentation. We expect our work to result in highly effective critical care patient information presentation. In particula, we expect our work to inform: presentation of dynamic patient data, presentation of information generated or interpreted by intelligent systems, and means of identifying and conveying clinical relevance and urgency. Our innovative approach includes the use of rigorous user-centered design methods to identify meaningful schemes for organizing patient data. We will integrate these findings with novel techniques of conveying valuable data characteristics such as urgency and change over time. The results of this project can be applied to the design of future electronic health records so that important data are not missed and can be accessed easily and quickly. In intensive care units as well as other care settings, we expect the results of this effot to significantly reduce clinician workload and preventable adverse events. Narrative Improving electronic health care information presentation to support patient care is a crucial patient safety priority. This project proposes a user-centered approach to establish design guidelines and evaluate design concepts to better organize, prioritize, and present acute care electronic patient information. The results of this project can be applied to the design of future electronic health records so that important data are not missed and can be accessed more easily and quickly, resulting in a significant reduction of preventable adverse events in the intensive care unit and other care settings.","Right Place, Right Time: Information Design to Support Decisions in Acute Care",9119160,R56LM011925,"['Accounting', 'Acute', 'Adverse event', 'Algorithms', 'American', 'Attention', 'Awareness', 'Behavior', 'Caring', 'Categories', 'Characteristics', 'Clinical', 'Collection', 'Complex', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Sources', 'Decision Making', 'Decision Support Systems', 'Diagnosis', 'Economics', 'Electronic Health Record', 'Electronics', 'Elements', 'Environment', 'Equilibrium', 'Evaluation', 'Expert Systems', 'Future', 'Goals', 'Grouping', 'Guidelines', 'Health', 'Health Information System', 'Health system', 'Healthcare', 'Human', 'Intensive Care Units', 'Intervention', 'Interview', 'Journals', 'Knowledge', 'Management Information Systems', 'Medical Informatics', 'Methods', 'Mind', 'Monitor', 'Paper', 'Patient Care', 'Patient Monitoring', 'Patients', 'Phase', 'Process', 'Professional Organizations', 'Provider', 'Publications', 'Publishing', 'Qualifying', 'Quality of Care', 'Research', 'Review Literature', 'Risk', 'Saints', 'Scheme', 'Societies', 'Sorting - Cell Movement', 'Source', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Universities', 'Utah', 'Work', 'Workload', 'base', 'biomedical informatics', 'clinically relevant', 'computer human interaction', 'design', 'evidence base', 'health record', 'heuristics', 'high risk', 'human data', 'improved', 'information display', 'information organization', 'innovation', 'novel', 'patient safety', 'pressure', 'prototype', 'support tools', 'tool', 'usability', 'user centered design']",NLM,SAINT ALPHONSUS REGIONAL MEDICAL CENTER,R56,2016,280000,0.06403928388759779
"Right Place, Right Time: Information Design to Support Decisions in Acute Care     DESCRIPTION (provided by applicant): Improving electronic health care information organization, prioritization, and presentation to support patient care is a crucial patient safety priority. Each year tens of thousands of patients are harmed because important information is missed, misunderstood, or identified too late. Providers complain that it is difficult for them to find the information they need quickly and that key information can be missed. Technological advances intended to help providers detect important patient changes or follow through with evidence-based care activities are underway in the form of intelligent surveillance and decision support tools. However, these tools are often perceived as simply adding more to the information load. The primary objective of this project is to implement a user-centered design process to establish design guidelines and evaluate design concepts to better organize, prioritize, and present acute care electronic patient information. Our approach begins by conducting knowledge elicitation activities including interviews, card sorting, and ranking to capture the way acute care information is organized and prioritized in the minds of critical care providers. To account for the importance of context and complexity in health care information organization and prioritization, we will conduct our activities in the context of realistic patientuse cases. We will use the findings from these activities to inform an iterative user-centered design process to create and evaluate conceptual designs for smarter, more effective patient information displays. In our recent qualitative study of information use in critical care settings, we identified a need to design information presentation to support prioritizing patients and tasks, monitoring patients for impending crises or risks, tracking patient status and progress toward goals, and rapid directed information access of dynamic patient data. Thus, our conceptual designs will have these goals as a primary focus. We will conduct interviews, implement heuristic inspection methods, and apply usability testing of design concepts to develop a functioning design prototype. Finally, we will use the findings of this effort to generate knowledge in the form of design guidelines for healthcare information presentation. We expect our work to result in highly effective critical care patient information presentation. In particula, we expect our work to inform: presentation of dynamic patient data, presentation of information generated or interpreted by intelligent systems, and means of identifying and conveying clinical relevance and urgency. Our innovative approach includes the use of rigorous user-centered design methods to identify meaningful schemes for organizing patient data. We will integrate these findings with novel techniques of conveying valuable data characteristics such as urgency and change over time. The results of this project can be applied to the design of future electronic health records so that important data are not missed and can be accessed easily and quickly. In intensive care units as well as other care settings, we expect the results of this effot to significantly reduce clinician workload and preventable adverse events.             Narrative Improving electronic health care information presentation to support patient care is a crucial patient safety priority. This project proposes a user-centered approach to establish design guidelines and evaluate design concepts to better organize, prioritize, and present acute care electronic patient information. The results of this project can be applied to the design of future electronic health records so that important data are not missed and can be accessed more easily and quickly, resulting in a significant reduction of preventable adverse events in the intensive care unit and other care settings.","Right Place, Right Time: Information Design to Support Decisions in Acute Care",8888445,R56LM011925,"['Accounting', 'Acute', 'Adverse event', 'Algorithms', 'American', 'Attention', 'Awareness', 'Behavior', 'Caring', 'Categories', 'Characteristics', 'Clinical', 'Collection', 'Complex', 'Critical Care', 'Data', 'Data Element', 'Data Sources', 'Decision Making', 'Decision Support Systems', 'Diagnosis', 'Economics', 'Electronic Health Record', 'Electronics', 'Elements', 'Environment', 'Equilibrium', 'Evaluation', 'Expert Systems', 'Future', 'Goals', 'Grouping', 'Guidelines', 'Health', 'Health Information System', 'Health system', 'Healthcare', 'Human', 'Intensive Care Units', 'Intervention', 'Interview', 'Journals', 'Knowledge', 'Management Information Systems', 'Medical Informatics', 'Methods', 'Mind', 'Monitor', 'Paper', 'Patient Care', 'Patient Monitoring', 'Patients', 'Phase', 'Process', 'Provider', 'Publications', 'Publishing', 'Qualifying', 'Quality of Care', 'Research', 'Review Literature', 'Risk', 'Saints', 'Scheme', 'Societies', 'Sorting - Cell Movement', 'Source', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Universities', 'Utah', 'Work', 'Workload', 'base', 'biomedical informatics', 'clinically relevant', 'computer human interaction', 'design', 'evidence base', 'health record', 'heuristics', 'high risk', 'human data', 'improved', 'information display', 'information organization', 'innovation', 'novel', 'patient safety', 'pressure', 'prototype', 'tool', 'usability', 'user centered design']",NLM,SAINT ALPHONSUS REGIONAL MEDICAL CENTER,R56,2015,264168,0.06403928388759779
"Learning Patterns of Collaboration to Optimize the Management of Care Providers DESCRIPTION (provided by applicant): Health information systems (HIS), especially electronic health record (EHR) systems, can significantly improve efficiency and quality of healthcare because it enables the employees of Healthcare Organizations (HCOs) to coordinate and collaborate more effectively and on a large scale. At the same time, healthcare environments are composed of highly diverse and dynamic workflows and, as modern EHR systems increase in size and scope, they may exacerbate the complexity of HCOs. If organizational complexity is not managed appropriately, it could limit the benefits of EHR systems and significantly contribute to negative effects, such as longer waiting times for care, replication of diagnostics, and medical errors. We hypothesize that patterns of collaboration can assist in managing complexity and facilitating patient management and that such patterns can be discovered by data mining on the utilization of EHR systems. This work is timely because EHR adoption has grown significantly over the past several years and HCO employees are increasingly using such systems to document patient status and communicate with other providers. The quantity and detail of such data provides an opportunity for big data mining techniques to learn patterns of care that are not explicitly documented. We propose to develop methods to learn patterns of collaboration through the utilization of EHR systems to determine how the management of care providers can be optimized. This will be accomplished through three specific aims: (1) Discover effective teams of care providers tailored to specific types of disease through the analysis of utilization data. Based on such teams, HCO will be able to manage patients more efficiently by prepping team members in a more timely manner. (2) Learn dependencies between care providers, which will be critical for resource allocation and management of care teams. (3) Model disease-specific treatment workflows to assess which sequences of events lead to the most efficient and effective outcomes for patients. In doing so, this project aims to reduce the length of patients' hospital stay and, ultimately help patients (an HCOs) reduce costs. Project Narrative Health information systems (HIS) facilitate collaborative environments, through which healthcare teams can improve their efficiency and patients can receive more effective treatment. Yet, at the same time, complexity in the interactions of care providers, in combination with the dynamic nature of healthcare, could limit the realization of such benefits if coordination is not appropriately handled (e.g., longer waiting times and replication in diagnostics) and care is not personalized to the patient. In this research, we aim to develop data mining strategies to enable the optimization of care providers management by learn patterns of collaboration through the utilization of HIS; specifically, the goals of this project are to 1) model disease-specific treatment communities, 2) learn dependency patterns between care providers, and 3) infer disease-specific coordinate sequence patterns.",Learning Patterns of Collaboration to Optimize the Management of Care Providers,9477112,R00LM011933,"['Adoption', 'Algorithms', 'Behavior', 'Big Data', 'Blood Pressure', 'Body mass index', 'Caring', 'Catheterization', 'Cessation of life', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Community Healthcare', 'Complex', 'Data', 'Decentralization', 'Dependence', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Disease', 'Disease model', 'E-learning', 'Electronic Health Record', 'Employee', 'Environment', 'Evaluation', 'Event', 'Goals', 'Health Information System', 'Health Personnel', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Incentives', 'Knowledge', 'Lead', 'Learning', 'Length', 'Length of Stay', 'Medical Care Team', 'Medical Errors', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Patterns of Care', 'Principal Component Analysis', 'Procedures', 'Provider', 'Research', 'Resource Allocation', 'Route', 'Safety', 'Series', 'Social Network', 'Source', 'Standardization', 'Surveys', 'System', 'Techniques', 'Time', 'Wait Time', 'Work', 'base', 'care coordination', 'care providers', 'clinical decision support', 'collaborative care', 'collaborative environment', 'cost', 'data access', 'data mining', 'demographics', 'design', 'diabetes management', 'effective therapy', 'health care quality', 'health care settings', 'health information technology', 'improved', 'learning community', 'member', 'social']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R00,2018,241323,0.05913753249528885
"Learning Patterns of Collaboration to Optimize the Management of Care Providers DESCRIPTION (provided by applicant): Health information systems (HIS), especially electronic health record (EHR) systems, can significantly improve efficiency and quality of healthcare because it enables the employees of Healthcare Organizations (HCOs) to coordinate and collaborate more effectively and on a large scale. At the same time, healthcare environments are composed of highly diverse and dynamic workflows and, as modern EHR systems increase in size and scope, they may exacerbate the complexity of HCOs. If organizational complexity is not managed appropriately, it could limit the benefits of EHR systems and significantly contribute to negative effects, such as longer waiting times for care, replication of diagnostics, and medical errors. We hypothesize that patterns of collaboration can assist in managing complexity and facilitating patient management and that such patterns can be discovered by data mining on the utilization of EHR systems. This work is timely because EHR adoption has grown significantly over the past several years and HCO employees are increasingly using such systems to document patient status and communicate with other providers. The quantity and detail of such data provides an opportunity for big data mining techniques to learn patterns of care that are not explicitly documented. We propose to develop methods to learn patterns of collaboration through the utilization of EHR systems to determine how the management of care providers can be optimized. This will be accomplished through three specific aims: (1) Discover effective teams of care providers tailored to specific types of disease through the analysis of utilization data. Based on such teams, HCO will be able to manage patients more efficiently by prepping team members in a more timely manner. (2) Learn dependencies between care providers, which will be critical for resource allocation and management of care teams. (3) Model disease-specific treatment workflows to assess which sequences of events lead to the most efficient and effective outcomes for patients. In doing so, this project aims to reduce the length of patients' hospital stay and, ultimately help patients (an HCOs) reduce costs. Project Narrative Health information systems (HIS) facilitate collaborative environments, through which healthcare teams can improve their efficiency and patients can receive more effective treatment. Yet, at the same time, complexity in the interactions of care providers, in combination with the dynamic nature of healthcare, could limit the realization of such benefits if coordination is not appropriately handled (e.g., longer waiting times and replication in diagnostics) and care is not personalized to the patient. In this research, we aim to develop data mining strategies to enable the optimization of care providers management by learn patterns of collaboration through the utilization of HIS; specifically, the goals of this project are to 1) model disease-specific treatment communities, 2) learn dependency patterns between care providers, and 3) infer disease-specific coordinate sequence patterns.",Learning Patterns of Collaboration to Optimize the Management of Care Providers,9265940,R00LM011933,"['Adoption', 'Algorithms', 'Behavior', 'Big Data', 'Blood Pressure', 'Body mass index', 'Caring', 'Catheterization', 'Cessation of life', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Community Healthcare', 'Complex', 'Data', 'Decentralization', 'Dependency', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Disease', 'Disease model', 'E-learning', 'Electronic Health Record', 'Employee', 'Environment', 'Evaluation', 'Event', 'Goals', 'Health Information System', 'Health Personnel', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Incentives', 'Knowledge', 'Lead', 'Learning', 'Length', 'Length of Stay', 'Medical Care Team', 'Medical Errors', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Patterns of Care', 'Principal Component Analysis', 'Procedures', 'Provider', 'Research', 'Resource Allocation', 'Route', 'Safety', 'Series', 'Social Network', 'Source', 'Standardization', 'Surveys', 'System', 'Techniques', 'Time', 'Work', 'base', 'collaborative care', 'collaborative environment', 'cost', 'data access', 'data mining', 'demographics', 'design', 'diabetes management', 'effective therapy', 'health care quality', 'health information technology', 'improved', 'learning community', 'member', 'social']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R00,2017,245914,0.05913753249528885
"Learning Patterns of Collaboration to Optimize the Management of Care Providers DESCRIPTION (provided by applicant): Health information systems (HIS), especially electronic health record (EHR) systems, can significantly improve efficiency and quality of healthcare because it enables the employees of Healthcare Organizations (HCOs) to coordinate and collaborate more effectively and on a large scale. At the same time, healthcare environments are composed of highly diverse and dynamic workflows and, as modern EHR systems increase in size and scope, they may exacerbate the complexity of HCOs. If organizational complexity is not managed appropriately, it could limit the benefits of EHR systems and significantly contribute to negative effects, such as longer waiting times for care, replication of diagnostics, and medical errors. We hypothesize that patterns of collaboration can assist in managing complexity and facilitating patient management and that such patterns can be discovered by data mining on the utilization of EHR systems. This work is timely because EHR adoption has grown significantly over the past several years and HCO employees are increasingly using such systems to document patient status and communicate with other providers. The quantity and detail of such data provides an opportunity for big data mining techniques to learn patterns of care that are not explicitly documented. We propose to develop methods to learn patterns of collaboration through the utilization of EHR systems to determine how the management of care providers can be optimized. This will be accomplished through three specific aims: (1) Discover effective teams of care providers tailored to specific types of disease through the analysis of utilization data. Based on such teams, HCO will be able to manage patients more efficiently by prepping team members in a more timely manner. (2) Learn dependencies between care providers, which will be critical for resource allocation and management of care teams. (3) Model disease-specific treatment workflows to assess which sequences of events lead to the most efficient and effective outcomes for patients. In doing so, this project aims to reduce the length of patients' hospital stay and, ultimately help patients (an HCOs) reduce costs. Project Narrative Health information systems (HIS) facilitate collaborative environments, through which healthcare teams can improve their efficiency and patients can receive more effective treatment. Yet, at the same time, complexity in the interactions of care providers, in combination with the dynamic nature of healthcare, could limit the realization of such benefits if coordination is not appropriately handled (e.g., longer waiting times and replication in diagnostics) and care is not personalized to the patient. In this research, we aim to develop data mining strategies to enable the optimization of care providers management by learn patterns of collaboration through the utilization of HIS; specifically, the goals of this project are to 1) model disease-specific treatment communities, 2) learn dependency patterns between care providers, and 3) infer disease-specific coordinate sequence patterns.",Learning Patterns of Collaboration to Optimize the Management of Care Providers,9260987,R00LM011933,"['Adoption', 'Algorithms', 'Behavior', 'Big Data', 'Blood Pressure', 'Body mass index', 'Caring', 'Catheterization', 'Cessation of life', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Community Healthcare', 'Complex', 'Data', 'Dependency', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease model', 'Electronic Health Record', 'Employee', 'Environment', 'Evaluation', 'Event', 'Goals', 'Health Information System', 'Health Personnel', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Knowledge', 'Lead', 'Learning', 'Length', 'Length of Stay', 'Medical Care Team', 'Medical Errors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Patterns of Care', 'Principal Component Analysis', 'Procedures', 'Provider', 'Research', 'Resource Allocation', 'Safety', 'Series', 'Social Network', 'Source', 'Surveys', 'System', 'Techniques', 'Time', 'Work', 'base', 'collaborative environment', 'cost', 'data access', 'data mining', 'demographics', 'design', 'diabetes management', 'effective therapy', 'health care quality', 'health information technology', 'improved', 'learning community', 'member', 'social']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R00,2016,250586,0.05913753249528885
"Learning Patterns of Collaboration to Optimize the Management of Care Providers     DESCRIPTION (provided by applicant): Health information systems (HIS), especially electronic health record (EHR) systems, can significantly improve efficiency and quality of healthcare because it enables the employees of Healthcare Organizations (HCOs) to coordinate and collaborate more effectively and on a large scale. At the same time, healthcare environments are composed of highly diverse and dynamic workflows and, as modern EHR systems increase in size and scope, they may exacerbate the complexity of HCOs. If organizational complexity is not managed appropriately, it could limit the benefits of EHR systems and significantly contribute to negative effects, such as longer waiting times for care, replication of diagnostics, and medical errors. We hypothesize that patterns of collaboration can assist in managing complexity and facilitating patient management and that such patterns can be discovered by data mining on the utilization of EHR systems. This work is timely because EHR adoption has grown significantly over the past several years and HCO employees are increasingly using such systems to document patient status and communicate with other providers. The quantity and detail of such data provides an opportunity for big data mining techniques to learn patterns of care that are not explicitly documented. We propose to develop methods to learn patterns of collaboration through the utilization of EHR systems to determine how the management of care providers can be optimized. This will be accomplished through three specific aims: (1) Discover effective teams of care providers tailored to specific types of disease through the analysis of utilization data. Based on such teams, HCO will be able to manage patients more efficiently by prepping team members in a more timely manner. (2) Learn dependencies between care providers, which will be critical for resource allocation and management of care teams. (3) Model disease-specific treatment workflows to assess which sequences of events lead to the most efficient and effective outcomes for patients. In doing so, this project aims to reduce the length of patients' hospital stay and, ultimately help patients (an HCOs) reduce costs.             Project Narrative Health information systems (HIS) facilitate collaborative environments, through which healthcare teams can improve their efficiency and patients can receive more effective treatment. Yet, at the same time, complexity in the interactions of care providers, in combination with the dynamic nature of healthcare, could limit the realization of such benefits if coordination is not appropriately handled (e.g., longer waiting times and replication in diagnostics) and care is not personalized to the patient. In this research, we aim to develop data mining strategies to enable the optimization of care providers management by learn patterns of collaboration through the utilization of HIS; specifically, the goals of this project are to 1) model disease-specific treatment communities, 2) learn dependency patterns between care providers, and 3) infer disease-specific coordinate sequence patterns.",Learning Patterns of Collaboration to Optimize the Management of Care Providers,8820357,K99LM011933,"['Adoption', 'Algorithms', 'Behavior', 'Big Data', 'Blood Pressure', 'Body mass index', 'Caring', 'Catheterization', 'Cessation of life', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Community Healthcare', 'Complex', 'Data', 'Dependency', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease model', 'Electronic Health Record', 'Employee', 'Environment', 'Evaluation', 'Event', 'Goals', 'Health Information System', 'Health Personnel', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Knowledge', 'Lead', 'Learning', 'Length', 'Length of Stay', 'Medical Care Team', 'Medical Errors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Principal Component Analysis', 'Procedures', 'Provider', 'Relative (related person)', 'Research', 'Resource Allocation', 'Safety', 'Series', 'Social Network', 'Source', 'Surveys', 'System', 'Techniques', 'Time', 'Work', 'base', 'collaborative environment', 'cost', 'data mining', 'demographics', 'design', 'diabetes management', 'effective therapy', 'health care quality', 'health information technology', 'improved', 'member', 'social']",NLM,VANDERBILT UNIVERSITY,K99,2015,85959,0.05913753249528885
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9534183,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2018,387966,0.0433733281752161
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9325065,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2017,387966,0.0433733281752161
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9115996,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'profiles in patients', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2016,387966,0.0433733281752161
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8928647,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2015,376327,0.0433733281752161
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification     DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts.         PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.                ",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8811565,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'public health relevance', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2014,460688,0.0433733281752161
"Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical DESCRIPTION (provided by applicant): The proposed research aims to provide effective, large-scale means for obtaining reliable information about drug-drug interactions (DDIs), by focusing on and utilizing the multiple distinct types of evidence used in reporting DDIs. DDIs are a significant cause of adverse drug reactions, leading to emergency room visits and hospitalizations. DDI research aims to link between molecular mechanisms that underlie interactions and their actual clinical consequences, through several types of evidence. We distinguish three types of DDI evidence that are often provided in the literature: in vitro, in viv, and clinical. In vitro studies investigate molecular mechanisms of interaction; In vivo studies evaluate whether these interactions impact drug exposure in human subjects; Clinical studies test whether drug interactions change the actual response to drugs (e.g. drug-efficacy or adverse drug reactions). As such studies span several disciplines, typically the three types of evidence are not simultaneously available or reported. Missing evidence along any of the three types, creates a knowledge gap that can hinder translational research. For instance, if adverse interaction effects are clinically observed, but the molecular underpinnings are not yet reported, it is difficult to identify a safe, alternative drug treatment.      In this project we propose to develop and use large-scale text-mining methods and tools to mine drug- interaction information from PubMed abstracts and from FDA drug labels. These tools will be designed to explicitly identify gaps across the three levels of DDI evidence, and to help close such gaps. While automated discovery of DDI mentions in text is an active research area, no other text-based work is concerned with identifying explicit evidence for DDI, while separately taking into consideration the distinct types of interaction evidence. As a follow-up step, we also propose to conduct selective molecular pharmacology experiments to close the identified knowledge-gaps at the in vitro evidence level. Specifically: In Aim 1, we shall construct the needed lexica and new text corpora pertaining to in vitro, in vivo, and clinical DDI evidence; In Aim 2, a suite of text mining tools to separately identify the three types of DDI evidence will be developed, utilizing the corpora created in Aim 1; In Aim 3, clinically significant DDIs that have no sufficient in vitro evidence will be selected using the tools developed in Aim 2, and experiments will be conducted to evaluate in vitro metabolic enzyme- based DDI mechanisms. To the best of our knowledge we are the first group that sets out to distinguish among - and make use of - the different types of text-based DDI evidence in a systematic way. Following the text- based discovery with a selective molecular pharmacology experimental evaluation, is another unique interdisciplinary characteristic that adds to the significance of the proposed work. The successful completion of the proposed project will provide methods and tools for large-scale extraction of DDIs from the literature, along with their supporting evidence at the three distinct levels. Moreover, DDIs that will be reliably supported by one type of evidence but not another will be identified as strong candidates for future pharmacology research. Project Narrative: Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical Drug-drug interactions (DDIs) lead to adverse drug reactions, emergency room visits and hospitalization, thus posing a major challenge to public health. However, evidence for DDI is hard to gather, as it broadly varies from descriptions of molecular interactions in basic-science journals, to clinical descriptions of adverse-effects in a myriad of medical publications. The proposed research aims to develop tools that focus directly on identifying and gathering diverse types of reliable DDI evidence from diverse sources, and supply them to clinicians and biologists.","Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical",9336353,R01LM011945,"['Address', 'Adverse effects', 'Area', 'Basic Science', 'Binding', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Conflict (Psychology)', 'Development', 'Discipline', 'Drug Exposure', 'Drug Interactions', 'Drug Kinetics', 'Emergency department visit', 'Enzymes', 'Evaluation', 'FDA approved', 'Future', 'Health', 'Hospitalization', 'Human', 'In Vitro', 'Incidence', 'Journals', 'Knowledge', 'Label', 'Lead', 'Level of Evidence', 'Link', 'Literature', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Pharmacotherapy', 'Polypharmacy', 'PubMed', 'Public Health', 'Publications', 'Reaction', 'Reporting', 'Research', 'Research Design', 'Retrieval', 'Sampling', 'Source', 'Terminology', 'Testing', 'Text', 'Translational Research', 'Transportation', 'United States', 'Work', 'base', 'clinical effect', 'clinically significant', 'design', 'drug development', 'drug discovery', 'drug efficacy', 'evidence base', 'experimental study', 'follow-up', 'human subject', 'in vivo', 'novel therapeutics', 'prevent', 'response', 'statistics', 'text searching', 'tool']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2017,394297,0.012515820156780221
"Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical DESCRIPTION (provided by applicant): The proposed research aims to provide effective, large-scale means for obtaining reliable information about drug-drug interactions (DDIs), by focusing on and utilizing the multiple distinct types of evidence used in reporting DDIs. DDIs are a significant cause of adverse drug reactions, leading to emergency room visits and hospitalizations. DDI research aims to link between molecular mechanisms that underlie interactions and their actual clinical consequences, through several types of evidence. We distinguish three types of DDI evidence that are often provided in the literature: in vitro, in viv, and clinical. In vitro studies investigate molecular mechanisms of interaction; In vivo studies evaluate whether these interactions impact drug exposure in human subjects; Clinical studies test whether drug interactions change the actual response to drugs (e.g. drug-efficacy or adverse drug reactions). As such studies span several disciplines, typically the three types of evidence are not simultaneously available or reported. Missing evidence along any of the three types, creates a knowledge gap that can hinder translational research. For instance, if adverse interaction effects are clinically observed, but the molecular underpinnings are not yet reported, it is difficult to identify a safe, alternative drug treatment.      In this project we propose to develop and use large-scale text-mining methods and tools to mine drug- interaction information from PubMed abstracts and from FDA drug labels. These tools will be designed to explicitly identify gaps across the three levels of DDI evidence, and to help close such gaps. While automated discovery of DDI mentions in text is an active research area, no other text-based work is concerned with identifying explicit evidence for DDI, while separately taking into consideration the distinct types of interaction evidence. As a follow-up step, we also propose to conduct selective molecular pharmacology experiments to close the identified knowledge-gaps at the in vitro evidence level. Specifically: In Aim 1, we shall construct the needed lexica and new text corpora pertaining to in vitro, in vivo, and clinical DDI evidence; In Aim 2, a suite of text mining tools to separately identify the three types of DDI evidence will be developed, utilizing the corpora created in Aim 1; In Aim 3, clinically significant DDIs that have no sufficient in vitro evidence will be selected using the tools developed in Aim 2, and experiments will be conducted to evaluate in vitro metabolic enzyme- based DDI mechanisms. To the best of our knowledge we are the first group that sets out to distinguish among - and make use of - the different types of text-based DDI evidence in a systematic way. Following the text- based discovery with a selective molecular pharmacology experimental evaluation, is another unique interdisciplinary characteristic that adds to the significance of the proposed work. The successful completion of the proposed project will provide methods and tools for large-scale extraction of DDIs from the literature, along with their supporting evidence at the three distinct levels. Moreover, DDIs that will be reliably supported by one type of evidence but not another will be identified as strong candidates for future pharmacology research. Project Narrative: Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical Drug-drug interactions (DDIs) lead to adverse drug reactions, emergency room visits and hospitalization, thus posing a major challenge to public health. However, evidence for DDI is hard to gather, as it broadly varies from descriptions of molecular interactions in basic-science journals, to clinical descriptions of adverse-effects in a myriad of medical publications. The proposed research aims to develop tools that focus directly on identifying and gathering diverse types of reliable DDI evidence from diverse sources, and supply them to clinicians and biologists.","Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical",9119045,R01LM011945,"['Address', 'Adverse effects', 'Area', 'Basic Science', 'Binding', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Conflict (Psychology)', 'Development', 'Discipline', 'Drug Exposure', 'Drug Interactions', 'Drug Kinetics', 'Emergency department visit', 'Enzymes', 'Evaluation', 'FDA approved', 'Future', 'Health', 'Hospitalization', 'Human', 'In Vitro', 'Incidence', 'Journals', 'Knowledge', 'Label', 'Lead', 'Left', 'Level of Evidence', 'Link', 'Literature', 'Medical', 'Metabolic', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Polypharmacy', 'PubMed', 'Public Health', 'Publications', 'Reaction', 'Reporting', 'Research', 'Research Design', 'Retrieval', 'Sampling', 'Source', 'Terminology', 'Testing', 'Text', 'Translational Research', 'Transportation', 'United States', 'Work', 'abstracting', 'base', 'clinically significant', 'design', 'drug development', 'drug efficacy', 'epidemiology study', 'evidence base', 'follow-up', 'human subject', 'in vivo', 'novel therapeutics', 'prevent', 'research study', 'response', 'statistics', 'text searching', 'tool']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2016,397279,0.012515820156780221
"Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical DESCRIPTION (provided by applicant): The proposed research aims to provide effective, large-scale means for obtaining reliable information about drug-drug interactions (DDIs), by focusing on and utilizing the multiple distinct types of evidence used in reporting DDIs. DDIs are a significant cause of adverse drug reactions, leading to emergency room visits and hospitalizations. DDI research aims to link between molecular mechanisms that underlie interactions and their actual clinical consequences, through several types of evidence. We distinguish three types of DDI evidence that are often provided in the literature: in vitro, in viv, and clinical. In vitro studies investigate molecular mechanisms of interaction; In vivo studies evaluate whether these interactions impact drug exposure in human subjects; Clinical studies test whether drug interactions change the actual response to drugs (e.g. drug-efficacy or adverse drug reactions). As such studies span several disciplines, typically the three types of evidence are not simultaneously available or reported. Missing evidence along any of the three types, creates a knowledge gap that can hinder translational research. For instance, if adverse interaction effects are clinically observed, but the molecular underpinnings are not yet reported, it is difficult to identify a safe, alternative drug treatment.      In this project we propose to develop and use large-scale text-mining methods and tools to mine drug- interaction information from PubMed abstracts and from FDA drug labels. These tools will be designed to explicitly identify gaps across the three levels of DDI evidence, and to help close such gaps. While automated discovery of DDI mentions in text is an active research area, no other text-based work is concerned with identifying explicit evidence for DDI, while separately taking into consideration the distinct types of interaction evidence. As a follow-up step, we also propose to conduct selective molecular pharmacology experiments to close the identified knowledge-gaps at the in vitro evidence level. Specifically: In Aim 1, we shall construct the needed lexica and new text corpora pertaining to in vitro, in vivo, and clinical DDI evidence; In Aim 2, a suite of text mining tools to separately identify the three types of DDI evidence will be developed, utilizing the corpora created in Aim 1; In Aim 3, clinically significant DDIs that have no sufficient in vitro evidence will be selected using the tools developed in Aim 2, and experiments will be conducted to evaluate in vitro metabolic enzyme- based DDI mechanisms. To the best of our knowledge we are the first group that sets out to distinguish among - and make use of - the different types of text-based DDI evidence in a systematic way. Following the text- based discovery with a selective molecular pharmacology experimental evaluation, is another unique interdisciplinary characteristic that adds to the significance of the proposed work. The successful completion of the proposed project will provide methods and tools for large-scale extraction of DDIs from the literature, along with their supporting evidence at the three distinct levels. Moreover, DDIs that will be reliably supported by one type of evidence but not another will be identified as strong candidates for future pharmacology research. Project Narrative: Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical Drug-drug interactions (DDIs) lead to adverse drug reactions, emergency room visits and hospitalization, thus posing a major challenge to public health. However, evidence for DDI is hard to gather, as it broadly varies from descriptions of molecular interactions in basic-science journals, to clinical descriptions of adverse-effects in a myriad of medical publications. The proposed research aims to develop tools that focus directly on identifying and gathering diverse types of reliable DDI evidence from diverse sources, and supply them to clinicians and biologists.","Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical",8930729,R01LM011945,"['Address', 'Adverse effects', 'Area', 'Basic Science', 'Binding', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Conflict (Psychology)', 'Development', 'Discipline', 'Drug Exposure', 'Drug Interactions', 'Drug Kinetics', 'Emergency department visit', 'Enzymes', 'Evaluation', 'FDA approved', 'Future', 'Health', 'Hospitalization', 'Human', 'In Vitro', 'Incidence', 'Journals', 'Knowledge', 'Label', 'Lead', 'Left', 'Level of Evidence', 'Link', 'Literature', 'Medical', 'Metabolic', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Pharmacology', 'Polypharmacy', 'PubMed', 'Public Health', 'Publications', 'Reaction', 'Reporting', 'Research', 'Research Design', 'Retrieval', 'Sampling', 'Source', 'Terminology', 'Testing', 'Text', 'Translational Research', 'Transportation', 'United States', 'Work', 'abstracting', 'base', 'clinically significant', 'design', 'drug development', 'drug efficacy', 'epidemiology study', 'evidence base', 'follow-up', 'human subject', 'in vivo', 'prevent', 'research study', 'response', 'statistics', 'text searching', 'tool']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2015,481051,0.012515820156780221
"Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical     DESCRIPTION (provided by applicant): The proposed research aims to provide effective, large-scale means for obtaining reliable information about drug-drug interactions (DDIs), by focusing on and utilizing the multiple distinct types of evidence used in reporting DDIs. DDIs are a significant cause of adverse drug reactions, leading to emergency room visits and hospitalizations. DDI research aims to link between molecular mechanisms that underlie interactions and their actual clinical consequences, through several types of evidence. We distinguish three types of DDI evidence that are often provided in the literature: in vitro, in viv, and clinical. In vitro studies investigate molecular mechanisms of interaction; In vivo studies evaluate whether these interactions impact drug exposure in human subjects; Clinical studies test whether drug interactions change the actual response to drugs (e.g. drug-efficacy or adverse drug reactions). As such studies span several disciplines, typically the three types of evidence are not simultaneously available or reported. Missing evidence along any of the three types, creates a knowledge gap that can hinder translational research. For instance, if adverse interaction effects are clinically observed, but the molecular underpinnings are not yet reported, it is difficult to identify a safe, alternative drug treatment.      In this project we propose to develop and use large-scale text-mining methods and tools to mine drug- interaction information from PubMed abstracts and from FDA drug labels. These tools will be designed to explicitly identify gaps across the three levels of DDI evidence, and to help close such gaps. While automated discovery of DDI mentions in text is an active research area, no other text-based work is concerned with identifying explicit evidence for DDI, while separately taking into consideration the distinct types of interaction evidence. As a follow-up step, we also propose to conduct selective molecular pharmacology experiments to close the identified knowledge-gaps at the in vitro evidence level. Specifically: In Aim 1, we shall construct the needed lexica and new text corpora pertaining to in vitro, in vivo, and clinical DDI evidence; In Aim 2, a suite of text mining tools to separately identify the three types of DDI evidence will be developed, utilizing the corpora created in Aim 1; In Aim 3, clinically significant DDIs that have no sufficient in vitro evidence will be selected using the tools developed in Aim 2, and experiments will be conducted to evaluate in vitro metabolic enzyme- based DDI mechanisms. To the best of our knowledge we are the first group that sets out to distinguish among - and make use of - the different types of text-based DDI evidence in a systematic way. Following the text- based discovery with a selective molecular pharmacology experimental evaluation, is another unique interdisciplinary characteristic that adds to the significance of the proposed work. The successful completion of the proposed project will provide methods and tools for large-scale extraction of DDIs from the literature, along with their supporting evidence at the three distinct levels. Moreover, DDIs that will be reliably supported by one type of evidence but not another will be identified as strong candidates for future pharmacology research.              Project Narrative: Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical Drug-drug interactions (DDIs) lead to adverse drug reactions, emergency room visits and hospitalization, thus posing a major challenge to public health. However, evidence for DDI is hard to gather, as it broadly varies from descriptions of molecular interactions in basic-science journals, to clinical descriptions of adverse-effects in a myriad of medical publications. The proposed research aims to develop tools that focus directly on identifying and gathering diverse types of reliable DDI evidence from diverse sources, and supply them to clinicians and biologists.","Evidence-based Drug-Interaction Discovery: In-Vivo, In-Vitro and Clinical",8686117,R01LM011945,"['Accident and Emergency department', 'Address', 'Adverse effects', 'Area', 'Basic Science', 'Binding', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Conflict (Psychology)', 'Development', 'Discipline', 'Drug Exposure', 'Drug Interactions', 'Drug Kinetics', 'Enzymes', 'Evaluation', 'FDA approved', 'Future', 'Health', 'Hospitalization', 'Human', 'In Vitro', 'Incidence', 'Journals', 'Knowledge', 'Label', 'Lead', 'Left', 'Level of Evidence', 'Link', 'Literature', 'Medical', 'Metabolic', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Pharmacology', 'Polypharmacy', 'PubMed', 'Public Health', 'Publications', 'Reaction', 'Reporting', 'Research', 'Research Design', 'Retrieval', 'Sampling', 'Source', 'Terminology', 'Testing', 'Text', 'Translational Research', 'Transportation', 'United States', 'Visit', 'Work', 'abstracting', 'base', 'clinically significant', 'design', 'drug development', 'drug efficacy', 'epidemiology study', 'evidence base', 'follow-up', 'human subject', 'in vivo', 'prevent', 'research study', 'response', 'statistics', 'text searching', 'tool']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2014,483211,0.012515820156780221
"Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers     DESCRIPTION (provided by applicant): Lifespans continue to increase, chronic disease survival rates are drastically improved, and treatments are being discovered for a variety of illnesses. This rapidly changing scenario requires patients to participate in their recovery, understand written information and directions thereby calling upon patients to have increasingly more complex health literacy. However, time availability of practitioners or other resources to explain the required information has not increased to match. As a result, finding efficient means to improving patient health literacy is an increasingly important topic in healthcare. Increased health literacy may promote healthy lifestyle behaviors and increase access to health services by the population. It has been argued that for the Patient Protection and Affordable Care Act to be successful, more effort is needed to increase the health literacy of millions of Americans. Similarly, the Healthy People 2020 statement by the Department of Health and Human Services identified improving health literacy (HC/HIT-1) as an important national goal. The broad- long term objectives of this project are to contribute to increasing the health literacy of patients and health information consumers and provide caregivers an evidence-based tool for simplifying text. The most commonly used tool for estimating the difficulty of text is the readability formula. They are not sufficient, however, because there is no evidence to support a connection between their use and decreases in difficulty. This problem is addressed by using modern resources and techniques for discovering traits that make health-related text difficult and developing a tool to guide the simplification of text. . There are four specific aims of this project: 1) Identify differentiating features of easy versus difficult texts, 2) Design a simplification strategy using computer algorithms, 3) Measure the impact of simplification on perceived and actual text difficulty with online participants and a representative community sample, 4) Create free, online software that incorporates proven features algorithmically. Corpus analysis will be conducted to compare easy and difficult texts with each other and discover lexical, grammatical, semantic, and composition and discourse features typical for each. Then, simplification algorithms will be designed and developed relying on rule-based techniques to leverage available resources, e.g., vocabularies, or on machine learning approaches for discovering the best combinations of features for simplification. A representative writer will simplify text by relying on the suggestios provided by an online that tool that uses simplification algorithms. The effect of simplification wll be tested in comprehensive user studies to evaluate the effect on both actual and perceived difficulty. Features successfully shown to decrease text difficulty will be incorporated in an onlie software program designed to reduce text difficulty. PUBLIC HEALTH RELEVANCE: Improving health literacy is an important national goal and necessary trait for a healthy population. Providing understandable information is critical but few tools exist to help write understandable text. We aim to discover features indicative of difficult text, design translation algorithms and create a free, online software tool for rewriting health-related text with demonstrated impact on perceived and actual text difficulty",Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers,9521525,R01LM011975,"['Address', 'Advocate', 'Affect', 'Affordable Care Act', 'Algorithms', 'American', 'Arizona', 'Behavior', 'Caregivers', 'Chronic Disease', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Conflict (Psychology)', 'Data Set', 'Education', 'Education Projects', 'Ensure', 'Faculty', 'Feedback', 'Funding', 'Goals', 'Health', 'Health Promotion', 'Health Services Accessibility', 'Health behavior', 'Health education', 'Healthcare', 'Healthy People 2020', 'Longevity', 'Machine Learning', 'Measures', 'Medical', 'Medical Informatics', 'Medicine', 'Methods', 'Minority', 'Modernization', 'Natural Language Processing', 'Outcome', 'Participant', 'Patients', 'Pilot Projects', 'Population', 'Process', 'Public Health', 'Readability', 'Reader', 'Recovery', 'Research', 'Research Design', 'Resources', 'Sampling', 'Semantics', 'Software Tools', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Translations', 'Underserved Population', 'United States Dept. of Health and Human Services', 'Universities', 'Vocabulary', 'Work', 'Writing', 'base', 'college', 'combat', 'community based participatory research', 'cost effective', 'design', 'evidence base', 'health literacy', 'healthy lifestyle', 'improved', 'individual patient', 'lexical', 'programs', 'public health relevance', 'recruit', 'support tools', 'tool', 'trait', 'user-friendly', 'volunteer']",NLM,UNIVERSITY OF ARIZONA,R01,2018,356845,0.02502176501610786
"Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers     DESCRIPTION (provided by applicant): Lifespans continue to increase, chronic disease survival rates are drastically improved, and treatments are being discovered for a variety of illnesses. This rapidly changing scenario requires patients to participate in their recovery, understand written information and directions thereby calling upon patients to have increasingly more complex health literacy. However, time availability of practitioners or other resources to explain the required information has not increased to match. As a result, finding efficient means to improving patient health literacy is an increasingly important topic in healthcare. Increased health literacy may promote healthy lifestyle behaviors and increase access to health services by the population. It has been argued that for the Patient Protection and Affordable Care Act to be successful, more effort is needed to increase the health literacy of millions of Americans. Similarly, the Healthy People 2020 statement by the Department of Health and Human Services identified improving health literacy (HC/HIT-1) as an important national goal. The broad- long term objectives of this project are to contribute to increasing the health literacy of patients and health information consumers and provide caregivers an evidence-based tool for simplifying text. The most commonly used tool for estimating the difficulty of text is the readability formula. They are not sufficient, however, because there is no evidence to support a connection between their use and decreases in difficulty. This problem is addressed by using modern resources and techniques for discovering traits that make health-related text difficult and developing a tool to guide the simplification of text. . There are four specific aims of this project: 1) Identify differentiating features of easy versus difficult texts, 2) Design a simplification strategy using computer algorithms, 3) Measure the impact of simplification on perceived and actual text difficulty with online participants and a representative community sample, 4) Create free, online software that incorporates proven features algorithmically. Corpus analysis will be conducted to compare easy and difficult texts with each other and discover lexical, grammatical, semantic, and composition and discourse features typical for each. Then, simplification algorithms will be designed and developed relying on rule-based techniques to leverage available resources, e.g., vocabularies, or on machine learning approaches for discovering the best combinations of features for simplification. A representative writer will simplify text by relying on the suggestios provided by an online that tool that uses simplification algorithms. The effect of simplification wll be tested in comprehensive user studies to evaluate the effect on both actual and perceived difficulty. Features successfully shown to decrease text difficulty will be incorporated in an onlie software program designed to reduce text difficulty. PUBLIC HEALTH RELEVANCE: Improving health literacy is an important national goal and necessary trait for a healthy population. Providing understandable information is critical but few tools exist to help write understandable text. We aim to discover features indicative of difficult text, design translation algorithms and create a free, online software tool for rewriting health-related text with demonstrated impact on perceived and actual text difficulty",Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers,9306183,R01LM011975,"['Address', 'Advocate', 'Affect', 'Affordable Care Act', 'Algorithms', 'American', 'Arizona', 'Behavior', 'Caregivers', 'Chronic Disease', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Conflict (Psychology)', 'Data Set', 'Education', 'Education Projects', 'Ensure', 'Faculty', 'Feedback', 'Funding', 'Goals', 'Health', 'Health Promotion', 'Health Services Accessibility', 'Health behavior', 'Health education', 'Healthcare', 'Healthy People 2020', 'Longevity', 'Machine Learning', 'Measures', 'Medical', 'Medical Informatics', 'Medicine', 'Methods', 'Minority', 'Modernization', 'Natural Language Processing', 'Outcome', 'Participant', 'Patients', 'Pilot Projects', 'Population', 'Process', 'Public Health', 'Readability', 'Reader', 'Recovery', 'Recruitment Activity', 'Research', 'Research Design', 'Resources', 'Sampling', 'Semantics', 'Software Tools', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Translations', 'Underserved Population', 'United States Dept. of Health and Human Services', 'Universities', 'Vocabulary', 'Work', 'Writing', 'base', 'college', 'combat', 'community based participatory research', 'cost effective', 'design', 'evidence base', 'health literacy', 'healthy lifestyle', 'improved', 'individual patient', 'lexical', 'programs', 'public health relevance', 'support tools', 'tool', 'trait', 'user-friendly', 'volunteer']",NLM,UNIVERSITY OF ARIZONA,R01,2017,368201,0.02502176501610786
"Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers     DESCRIPTION (provided by applicant): Lifespans continue to increase, chronic disease survival rates are drastically improved, and treatments are being discovered for a variety of illnesses. This rapidly changing scenario requires patients to participate in their recovery, understand written information and directions thereby calling upon patients to have increasingly more complex health literacy. However, time availability of practitioners or other resources to explain the required information has not increased to match. As a result, finding efficient means to improving patient health literacy is an increasingly important topic in healthcare. Increased health literacy may promote healthy lifestyle behaviors and increase access to health services by the population. It has been argued that for the Patient Protection and Affordable Care Act to be successful, more effort is needed to increase the health literacy of millions of Americans. Similarly, the Healthy People 2020 statement by the Department of Health and Human Services identified improving health literacy (HC/HIT-1) as an important national goal. The broad- long term objectives of this project are to contribute to increasing the health literacy of patients and health information consumers and provide caregivers an evidence-based tool for simplifying text. The most commonly used tool for estimating the difficulty of text is the readability formula. They are not sufficient, however, because there is no evidence to support a connection between their use and decreases in difficulty. This problem is addressed by using modern resources and techniques for discovering traits that make health-related text difficult and developing a tool to guide the simplification of text. . There are four specific aims of this project: 1) Identify differentiating features of easy versus difficult texts, 2) Design a simplification strategy using computer algorithms, 3) Measure the impact of simplification on perceived and actual text difficulty with online participants and a representative community sample, 4) Create free, online software that incorporates proven features algorithmically. Corpus analysis will be conducted to compare easy and difficult texts with each other and discover lexical, grammatical, semantic, and composition and discourse features typical for each. Then, simplification algorithms will be designed and developed relying on rule-based techniques to leverage available resources, e.g., vocabularies, or on machine learning approaches for discovering the best combinations of features for simplification. A representative writer will simplify text by relying on the suggestios provided by an online that tool that uses simplification algorithms. The effect of simplification wll be tested in comprehensive user studies to evaluate the effect on both actual and perceived difficulty. Features successfully shown to decrease text difficulty will be incorporated in an onlie software program designed to reduce text difficulty. PUBLIC HEALTH RELEVANCE: Improving health literacy is an important national goal and necessary trait for a healthy population. Providing understandable information is critical but few tools exist to help write understandable text. We aim to discover features indicative of difficult text, design translation algorithms and create a free, online software tool for rewriting health-related text with demonstrated impact on perceived and actual text difficulty",Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers,9127807,R01LM011975,"['Address', 'Advocate', 'Affect', 'Affordable Care Act', 'Algorithms', 'American', 'Arizona', 'Behavior', 'Caregivers', 'Chronic Disease', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Conflict (Psychology)', 'Data Set', 'Education', 'Education Projects', 'Ensure', 'Faculty', 'Feedback', 'Funding', 'Goals', 'Health', 'Health Promotion', 'Health Services Accessibility', 'Health behavior', 'Health education', 'Healthcare', 'Healthy People 2020', 'Lead', 'Longevity', 'Machine Learning', 'Measures', 'Medical', 'Medical Informatics', 'Medicine', 'Methods', 'Minority', 'Mullerian duct inhibiting substance', 'Natural Language Processing', 'Outcome', 'Participant', 'Patients', 'Pilot Projects', 'Population', 'Process', 'Public Health', 'Readability', 'Reader', 'Recovery', 'Recruitment Activity', 'Research', 'Research Design', 'Resources', 'Sampling', 'Semantics', 'Software Tools', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Translations', 'Underserved Population', 'United States Dept. of Health and Human Services', 'Universities', 'Vocabulary', 'Work', 'Writing', 'base', 'college', 'combat', 'community based participatory research', 'cost effective', 'design', 'evidence base', 'health literacy', 'healthy lifestyle', 'improved', 'individual patient', 'lexical', 'programs', 'support tools', 'tool', 'trait', 'user-friendly', 'volunteer']",NLM,UNIVERSITY OF ARIZONA,R01,2016,362613,0.02502176501610786
"Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers     DESCRIPTION (provided by applicant): Lifespans continue to increase, chronic disease survival rates are drastically improved, and treatments are being discovered for a variety of illnesses. This rapidly changing scenario requires patients to participate in their recovery, understand written information and directions thereby calling upon patients to have increasingly more complex health literacy. However, time availability of practitioners or other resources to explain the required information has not increased to match. As a result, finding efficient means to improving patient health literacy is an increasingly important topic in healthcare. Increased health literacy may promote healthy lifestyle behaviors and increase access to health services by the population. It has been argued that for the Patient Protection and Affordable Care Act to be successful, more effort is needed to increase the health literacy of millions of Americans. Similarly, the Healthy People 2020 statement by the Department of Health and Human Services identified improving health literacy (HC/HIT-1) as an important national goal. The broad- long term objectives of this project are to contribute to increasing the health literacy of patients and health information consumers and provide caregivers an evidence-based tool for simplifying text. The most commonly used tool for estimating the difficulty of text is the readability formula. They are not sufficient, however, because there is no evidence to support a connection between their use and decreases in difficulty. This problem is addressed by using modern resources and techniques for discovering traits that make health-related text difficult and developing a tool to guide the simplification of text. . There are four specific aims of this project: 1) Identify differentiating features of easy versus difficult texts, 2) Design a simplification strategy using computer algorithms, 3) Measure the impact of simplification on perceived and actual text difficulty with online participants and a representative community sample, 4) Create free, online software that incorporates proven features algorithmically. Corpus analysis will be conducted to compare easy and difficult texts with each other and discover lexical, grammatical, semantic, and composition and discourse features typical for each. Then, simplification algorithms will be designed and developed relying on rule-based techniques to leverage available resources, e.g., vocabularies, or on machine learning approaches for discovering the best combinations of features for simplification. A representative writer will simplify text by relying on the suggestios provided by an online that tool that uses simplification algorithms. The effect of simplification wll be tested in comprehensive user studies to evaluate the effect on both actual and perceived difficulty. Features successfully shown to decrease text difficulty will be incorporated in an onlie software program designed to reduce text difficulty.         PUBLIC HEALTH RELEVANCE: Improving health literacy is an important national goal and necessary trait for a healthy population. Providing understandable information is critical but few tools exist to help write understandable text. We aim to discover features indicative of difficult text, design translation algorithms and create a free, online software tool for rewriting health-related text with demonstrated impact on perceived and actual text difficulty            ",Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers,8884888,R01LM011975,"['Address', 'Advocate', 'Affect', 'Algorithms', 'American', 'Arizona', 'Behavior', 'Caregivers', 'Caring', 'Chronic Disease', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Conflict (Psychology)', 'Data Set', 'Education', 'Education Projects', 'Ensure', 'Faculty', 'Feedback', 'Funding', 'Goals', 'Health', 'Health Promotion', 'Health Services Accessibility', 'Health behavior', 'Health education', 'Healthcare', 'Healthy People 2020', 'Individual', 'Lead', 'Longevity', 'Machine Learning', 'Measures', 'Medical', 'Medical Informatics', 'Medicine', 'Methods', 'Minority', 'Mullerian duct inhibiting substance', 'Natural Language Processing', 'Outcome', 'Participant', 'Patients', 'Pilot Projects', 'Population', 'Process', 'Public Health', 'Readability', 'Reader', 'Recovery', 'Recruitment Activity', 'Research', 'Research Design', 'Resources', 'Sampling', 'Semantics', 'Software Tools', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Translations', 'Underserved Population', 'United States Dept. of Health and Human Services', 'Universities', 'Vocabulary', 'Work', 'Writing', 'base', 'college', 'combat', 'cost effective', 'design', 'evidence base', 'health literacy', 'healthy lifestyle', 'improved', 'lexical', 'programs', 'public health relevance', 'tool', 'trait', 'user-friendly', 'volunteer']",NLM,UNIVERSITY OF ARIZONA,R01,2015,376917,0.02502176501610786
"InfoMediator: Weaving Clinical Expertise in Online Health Communities DESCRIPTION (provided by applicant): Chronic illness can be overwhelming to patients because it impacts many areas of their daily lives. Accordingly, many patients turn to online health support groups to get social support. In face-to-face patient support groups (F2F), health professional moderators provide clinical expertise within the context of peer-patients' sharing of experience. However, in online health community settings, because health professionals' time and resources are expensive, it is challenging to get health professionals' opinions for thousands of messages posted each day. To solve this problem, I propose to develop methods and techniques that maximize the use of already available clinical expertise online for online peer-patient conversation threads by developing a system, InfoMediator. The InfoMediator will semi-automatically weave health professionals' existing answers to patients' questions into peer-patient conversations by using Natural Language Processing (NLP) techniques complemented by user feedback. As the career development component of this proposal, I deepen my skills and knowledge in NLP necessary for proposed work and patient education. As I develop the NLP techniques and knowledge in patient education, I and my mentors will develop methods and techniques that address weaving clinical expertise within peer-patient conversations by designing, implementing, and evaluating socio-technical aspects of the InfoMediator. The training opportunities provided by this NIH NLM K01 grant, together with the supportive research environment at Michigan State University, will help further extend my existing expertise in human-computer interaction, design, and health informatics to establish my independent informatics research program in patient-centered technologies. Focusing on persons with diabetes, the outcomes of the proposed research will help us understand how to empower persons with diabetes to improve self- efficacy and self-care, while increasing the quality of online health information environment. 8. Project Narrative Because health professionals' time and resources are expensive, it is challenging for online health communities to engage health professionals in thousands of peer-patient conversations in the same way that health professionals moderate patient conversations in face-to-face patient support groups. To address this challenge I propose developing methods and techniques that maximize the use of already available health professionals' expertise online for online health communities and help patients improve self-efficacy and self-care toward managing chronic disease.",InfoMediator: Weaving Clinical Expertise in Online Health Communities,9145272,K01LM011980,"['Address', 'Area', 'Chronic Disease', 'Classification', 'Clinical', 'Community Health', 'Complement', 'Data', 'Data Sources', 'Databases', 'Diabetes Mellitus', 'Environment', 'Exposure to', 'Feedback', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Professional', 'Informatics', 'Interview', 'Knowledge', 'Medical', 'Mentors', 'Methods', 'Michigan', 'Natural Language Processing', 'Nursing Informatics', 'Outcome', 'Output', 'Paper', 'Participant', 'Patient Education', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Problem Solving', 'Public Health Informatics', 'Reading', 'Research', 'Resources', 'Retrieval', 'Self Care', 'Self Efficacy', 'Social support', 'Specific qualifier value', 'Support Groups', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'biomedical informatics', 'career', 'career development', 'community setting', 'computer human interaction', 'design', 'empowered', 'experience', 'follow-up', 'improved', 'online community', 'patient oriented', 'peer', 'programs', 'prototype', 'search engine', 'skills', 'training opportunity', 'user centered design']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K01,2016,156557,0.04148112308705863
"InfoMediator: Weaving Clinical Expertise in Online Health Communities DESCRIPTION (provided by applicant): Chronic illness can be overwhelming to patients because it impacts many areas of their daily lives. Accordingly, many patients turn to online health support groups to get social support. In face-to-face patient support groups (F2F), health professional moderators provide clinical expertise within the context of peer-patients' sharing of experience. However, in online health community settings, because health professionals' time and resources are expensive, it is challenging to get health professionals' opinions for thousands of messages posted each day. To solve this problem, I propose to develop methods and techniques that maximize the use of already available clinical expertise online for online peer-patient conversation threads by developing a system, InfoMediator. The InfoMediator will semi-automatically weave health professionals' existing answers to patients' questions into peer-patient conversations by using Natural Language Processing (NLP) techniques complemented by user feedback. As the career development component of this proposal, I deepen my skills and knowledge in NLP necessary for proposed work and patient education. As I develop the NLP techniques and knowledge in patient education, I and my mentors will develop methods and techniques that address weaving clinical expertise within peer-patient conversations by designing, implementing, and evaluating socio-technical aspects of the InfoMediator. The training opportunities provided by this NIH NLM K01 grant, together with the supportive research environment at Michigan State University, will help further extend my existing expertise in human-computer interaction, design, and health informatics to establish my independent informatics research program in patient-centered technologies. Focusing on persons with diabetes, the outcomes of the proposed research will help us understand how to empower persons with diabetes to improve self- efficacy and self-care, while increasing the quality of online health information environment. 8. Project Narrative Because health professionals' time and resources are expensive, it is challenging for online health communities to engage health professionals in thousands of peer-patient conversations in the same way that health professionals moderate patient conversations in face-to-face patient support groups. To address this challenge I propose developing methods and techniques that maximize the use of already available health professionals' expertise online for online health communities and help patients improve self-efficacy and self-care toward managing chronic disease.",InfoMediator: Weaving Clinical Expertise in Online Health Communities,8929297,K01LM011980,"['Address', 'Area', 'Chronic Disease', 'Classification', 'Clinical', 'Communities', 'Community Health', 'Complement', 'Data', 'Data Sources', 'Databases', 'Diabetes Mellitus', 'Environment', 'Exposure to', 'Feedback', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Professional', 'Informatics', 'Interview', 'Knowledge', 'Medical', 'Mentors', 'Methods', 'Michigan', 'Natural Language Processing', 'Nursing Informatics', 'Outcome', 'Output', 'Paper', 'Participant', 'Patient Education', 'Patients', 'Persons', 'Problem Solving', 'Public Health Informatics', 'Reading', 'Research', 'Resources', 'Retrieval', 'Self Care', 'Self Efficacy', 'Social support', 'Specific qualifier value', 'Support Groups', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'biomedical informatics', 'career', 'career development', 'community setting', 'computer human interaction', 'design', 'empowered', 'experience', 'follow-up', 'improved', 'patient oriented', 'peer', 'programs', 'prototype', 'skills', 'user centered design']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K01,2015,154413,0.04148112308705863
"InfoMediator: Weaving Clinical Expertise in Online Health Communities     DESCRIPTION (provided by applicant): Chronic illness can be overwhelming to patients because it impacts many areas of their daily lives. Accordingly, many patients turn to online health support groups to get social support. In face-to-face patient support groups (F2F), health professional moderators provide clinical expertise within the context of peer-patients' sharing of experience. However, in online health community settings, because health professionals' time and resources are expensive, it is challenging to get health professionals' opinions for thousands of messages posted each day. To solve this problem, I propose to develop methods and techniques that maximize the use of already available clinical expertise online for online peer-patient conversation threads by developing a system, InfoMediator. The InfoMediator will semi-automatically weave health professionals' existing answers to patients' questions into peer-patient conversations by using Natural Language Processing (NLP) techniques complemented by user feedback. As the career development component of this proposal, I deepen my skills and knowledge in NLP necessary for proposed work and patient education. As I develop the NLP techniques and knowledge in patient education, I and my mentors will develop methods and techniques that address weaving clinical expertise within peer-patient conversations by designing, implementing, and evaluating socio-technical aspects of the InfoMediator. The training opportunities provided by this NIH NLM K01 grant, together with the supportive research environment at Michigan State University, will help further extend my existing expertise in human-computer interaction, design, and health informatics to establish my independent informatics research program in patient-centered technologies. Focusing on persons with diabetes, the outcomes of the proposed research will help us understand how to empower persons with diabetes to improve self- efficacy and self-care, while increasing the quality of online health information environment.             8. Project Narrative Because health professionals' time and resources are expensive, it is challenging for online health communities to engage health professionals in thousands of peer-patient conversations in the same way that health professionals moderate patient conversations in face-to-face patient support groups. To address this challenge I propose developing methods and techniques that maximize the use of already available health professionals' expertise online for online health communities and help patients improve self-efficacy and self-care toward managing chronic disease.",InfoMediator: Weaving Clinical Expertise in Online Health Communities,8759393,K01LM011980,"['Address', 'Area', 'Chronic Disease', 'Classification', 'Clinical', 'Communities', 'Community Health', 'Complement', 'Data', 'Data Sources', 'Databases', 'Diabetes Mellitus', 'Environment', 'Exposure to', 'Feedback', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Professional', 'Informatics', 'Interview', 'Knowledge', 'Medical', 'Mentors', 'Methods', 'Michigan', 'Natural Language Processing', 'Nursing Informatics', 'Outcome', 'Output', 'Paper', 'Participant', 'Patient Education', 'Patients', 'Persons', 'Problem Solving', 'Public Health Informatics', 'Reading', 'Research', 'Resources', 'Retrieval', 'Self Care', 'Self Efficacy', 'Social support', 'Specific qualifier value', 'Support Groups', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'biomedical informatics', 'career', 'career development', 'community setting', 'computer human interaction', 'design', 'empowered', 'experience', 'follow-up', 'improved', 'patient oriented', 'peer', 'programs', 'prototype', 'skills', 'user centered design']",NLM,MICHIGAN STATE UNIVERSITY,K01,2014,155271,0.04148112308705863
"Detection of Potential Drug Effect Signals from Twitter Data     DESCRIPTION (provided by applicant): Patients, as the consumer of pharmaceutical products, are the most important contributor to drug safety surveillance. Yet studies show that the rate of patient participation is low when traditional methods of reporting drug effects-such as spontaneous reporting systems-are used. Studies have also documented that patients report their experiences in different ways and in more detail than healthcare professionals. Furthermore, traditional methods of collecting patient reports are typically slow and costly. The objective of the proposed research is to investigate whether patient experiences of drug effects can be detected directly from their posts on Twitter. We propose to retrieve and collect Twitter posts and conversations related to a list of 100 pre-selected drugs, to extract from the collection the posts that demonstrate patients' personal experiences, and to identify any effects mentioned in the drug-related personal experience Tweets. This data will be analyzed to assess the relationships between different drugs and reported beneficial or adverse effects, and to ascertain whether or not the effects have been previously reported. A data processing pipeline will be devised to automate many components of the data collection and analysis process which is expected to reduce the cost and speed up the discovery of any potential drug effects. A machine-learning-based method will be developed to identify the Twitter posts that demonstrate a user's experience. The National Library of Medicine's MetaMap software will be employed to map the word phrases identified in Twitter posts to UMLS semantic types, among which many are related drug effects. To assess the validity of our approach, healthcare professionals with knowledge and experience in drug safety surveillance will participate in verifying and annotating drug-related personal experience Twitter posts, and confirming the drug effect relationship.         PUBLIC HEALTH RELEVANCE: Adverse drug reactions are a leading cause of death in developing nations. Patient participation in reporting drug effects has been low, leading to under-reporting of many drug effects. This project will develop and test an innovative method to collect patient drug effect reports directly from their experience shared on Twitter, a general purpose social media platform, in a hope to improve upon traditional methods currently in practice.            ",Detection of Potential Drug Effect Signals from Twitter Data,8772447,R15LM011999,"['Adverse effects', 'Cause of Death', 'Collection', 'Communication', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Developing Countries', 'Health Professional', 'Knowledge', 'Machine Learning', 'Maps', 'Methods', 'Patient Participation', 'Patient Participation Rates', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Process', 'Reaction', 'Reporting', 'Research', 'Safety', 'Semantics', 'Signal Transduction', 'Speed', 'System', 'Testing', 'Unified Medical Language System', 'United States National Library of Medicine', 'base', 'computerized data processing', 'cost', 'experience', 'improved', 'innovation', 'phrases', 'public health relevance', 'social']",NLM,PURDUE UNIVERSITY,R15,2014,359922,0.033066990276012564
"Construction of Relation Detection Framework Empowered by Topic Modeling     DESCRIPTION (provided by applicant): The availability of large volume of EHRs enhances the possibility for using them for health services, EBM and clinical research. However such functionality is currently limited to narrow areas of clinical practice, as relation detections between medical events among unstructured EHRs still pose a big challenge, consequently leading to the inaccuracy of patient cohort identification, especially for cross-institutional environment. Preliminary work by the PI has shown that topic modeling can discover data semantics, which can then be employed as significant cues for diverse relation detections among EHRs. Among them, co-referring, temporal relations and domain semantics are intertwined and positively correlated. Up to now, not much research is done to combine the three relations to build a better patient cohort identification system. Therefore, the PI proposes to develop a relation detection framework for EHRs empowered with topic modeling for more accurate patient cohort identification. In the mentored phase, the PI will implement the relation detection framework under the guidance of my mentor team and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross-institutional portability of similar systems. Specifically, the PI will develo a hybrid design with ICD-9, RxNorm and MeSH ontologies for the data semantics discoveries from EHRs and MedLINE respectively and investigate categorization of data semantics aligning with medical ontologies (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources and more importantly to make corrections or adjustments on data semantics, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The independent phase will be in collaboration with both UTHealth and University of Maryland. The PI's career goal is to become a scientific leader in clinical informatics with a focus on relation detections among EHRs for efficient patient cohort identification. The PI has strong background in computational linguistics and rich experiences in medical clinical records processing and analyses, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, and Terry Therneau, who have complimentary areas of expertise. The mentored phase will be in Mayo Clinic Rochester where the PI will undertake courses in US healthcare system, health system engineering, clinical statistics and clinical epidemiology and will get mentored training in health informatics which is what he needs to continue to strengthen since he didn't get regular training in his PhD education. In the independent R00 phase, the PI will strive for making independent scientific contributions to the use of informatics for healthcare via the implementation of Aims 2 and 3 and via the independent collaborations internal and externally. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing the construction of medical knowledge systems and clinical practices as well as clinical research.             PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing accurate and real-time patient cohort identification is not fully realized, because corresponding relation detection systems for medical events among EHRs still need improvements. The proposed framework will enable patient cohort identification that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced relation detection functionality in the EHRs.",Construction of Relation Detection Framework Empowered by Topic Modeling,8804480,K99LM012021,"['Address', 'Area', 'Back', 'Categories', 'Chronic', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Engineering', 'Clinical Informatics', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Complement', 'Computational Linguistics', 'Computer software', 'Cues', 'Data', 'Dependency', 'Detection', 'Development', 'Diabetes Mellitus', 'Disease', 'Doctor of Philosophy', 'Education', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Environment', 'Event', 'Foundations', 'Funding', 'Future', 'Goals', 'Grant', 'Health Care Costs', 'Health Services', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hybrids', 'Hypertension', 'ICD-9', 'Informatics', 'Institution', 'International Classification of Disease Codes', 'Knowledge', 'Lead', 'Learning', 'Linguistics', 'Logic', 'Maryland', 'MeSH Thesaurus', 'Measures', 'Medical', 'Medical Informatics', 'Medical Research', 'Mental Depression', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nurses', 'Ontology', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Public Health', 'Public Health Informatics', 'Qualifier', 'Quality of Care', 'Records', 'Relative (related person)', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Schools', 'Semantics', 'Structure', 'System', 'Terminology', 'Text', 'Time', 'Training', 'Universities', 'Work', 'base', 'care delivery', 'career', 'clinical epidemiology', 'clinical practice', 'cohort', 'data mining', 'design', 'empowered', 'evidence base', 'experience', 'improved', 'informatics training', 'knowledge base', 'news', 'open source', 'operation', 'portability', 'public health relevance', 'statistics']",NLM,MAYO CLINIC ROCHESTER,K99,2015,93654,-0.0005681234401884508
"Semi-Automating Data Extraction for Systematic Reviews Summary Semi-Automating Data Extraction for Systematic Reviews (Renewal) Evidence-based Medicine (EBM) aims to inform patient care using all available evidence. Realizing this aim in practice would require access to concise, comprehensive, and up-to-date structured summaries of the evidence relevant to a particular clinical question. Systematic reviews of biomedical literature aim to provide such summaries, and are a critical component of the EBM arsenal and modern medicine more generally. However, such reviews are extremely laborious to conduct. Furthermore, owing to the rapid expansion of the biomedical literature base, they tend to go out of date quickly as new evidence emerges. These factors hinder the practice of evidence-based care. In this renewal proposal, we seek to continue our ground-breaking efforts on developing, evaluating, and deploying novel machine learning (ML) and natural language processing (NLP) methods to automate or semi-automate the evidence synthesis process. This will extend our innovative and successful efforts developing RobotReviewer and related technologies under the current grant. Concretely, for this renewal we propose to move from extraction of clinically salient data elements from individual trials to synthesis of these elements across trials. Our first aim is to extend our ML and NLP models to produce (as one deliverable) a publicly available, continuously and automatically updated semi-structured evidence database, comprising extracted data for all evidence, both published and unpublished. Unpublished trials will be identified via trial registries. Taking this up-to-date evidence repository as a starting point, we then propose cutting-edge ML and NLP models that will generate first drafts of evidence syntheses, automatically. More specifically we propose novel neural cross-document summarization models that will capitalize on the semi-structured information automatically extracted by our existing models, in addition to article texts. These models will be deployed in a new version of RobotReviewer, called RobotReviewerLive, intended to be a prototype for living systematic reviews. To rigorously evaluate the practical utility of the proposed methodological innovations, we will pilot their use to support real, ongoing, exemplar living reviews. Semi-Automating Data Extraction for Systematic Reviews (Renewal) Narrative We propose novel machine learning and natural language processing methods that will aid biomedical literature summarization and synthesis, and thereby support the conduct of evidence-based medicine (EBM). The proposed models and technologies will motivate core methodological innovations and support real-time, up-to-date, semi-automated biomedical evidence syntheses (systematic reviews). Such approaches are necessary if we are to have any hope of practicing evidence-based care in our era of information overload.",Semi-Automating Data Extraction for Systematic Reviews,9990898,R01LM012086,"['American', 'Automation', 'Caring', 'Clinical', 'Collection', 'Consumption', 'Data', 'Data Element', 'Databases', 'Development', 'Elements', 'Evaluation', 'Evidence Based Medicine', 'Evidence based practice', 'Feedback', 'Grant', 'Hybrids', 'Individual', 'Informatics', 'Internet', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical Informatics', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Modern Medicine', 'Natural Language Processing', 'Outcome', 'Output', 'Paper', 'Patient Care', 'Population Intervention', 'Process', 'PubMed', 'Publications', 'Publishing', 'Registries', 'Reporting', 'Research', 'Resources', 'Risk', 'Stroke', 'Structure', 'Surveillance Methods', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Vision', 'Work', 'base', 'cardiovascular health', 'database structure', 'design', 'evidence base', 'improved', 'indexing', 'innovation', 'machine learning method', 'natural language', 'neural network', 'novel', 'open source', 'programs', 'prospective', 'prototype', 'recruit', 'relating to nervous system', 'repository', 'search engine', 'structured data', 'study characteristics', 'study population', 'success', 'systematic review', 'tool', 'usability', 'working group']",NLM,NORTHEASTERN UNIVERSITY,R01,2020,291873,0.017157358396145832
"Semi-Automating Data Extraction for Systematic Reviews Summary Semi-Automating Data Extraction for Systematic Reviews (Renewal) Evidence-based Medicine (EBM) aims to inform patient care using all available evidence. Realizing this aim in practice would require access to concise, comprehensive, and up-to-date structured summaries of the evidence relevant to a particular clinical question. Systematic reviews of biomedical literature aim to provide such summaries, and are a critical component of the EBM arsenal and modern medicine more generally. However, such reviews are extremely laborious to conduct. Furthermore, owing to the rapid expansion of the biomedical literature base, they tend to go out of date quickly as new evidence emerges. These factors hinder the practice of evidence-based care. In this renewal proposal, we seek to continue our ground-breaking efforts on developing, evaluating, and deploying novel machine learning (ML) and natural language processing (NLP) methods to automate or semi-automate the evidence synthesis process. This will extend our innovative and successful efforts developing RobotReviewer and related technologies under the current grant. Concretely, for this renewal we propose to move from extraction of clinically salient data elements from individual trials to synthesis of these elements across trials. Our first aim is to extend our ML and NLP models to produce (as one deliverable) a publicly available, continuously and automatically updated semi-structured evidence database, comprising extracted data for all evidence, both published and unpublished. Unpublished trials will be identified via trial registries. Taking this up-to-date evidence repository as a starting point, we then propose cutting-edge ML and NLP models that will generate first drafts of evidence syntheses, automatically. More specifically we propose novel neural cross-document summarization models that will capitalize on the semi-structured information automatically extracted by our existing models, in addition to article texts. These models will be deployed in a new version of RobotReviewer, called RobotReviewerLive, intended to be a prototype for living systematic reviews. To rigorously evaluate the practical utility of the proposed methodological innovations, we will pilot their use to support real, ongoing, exemplar living reviews. Semi-Automating Data Extraction for Systematic Reviews (Renewal) Narrative We propose novel machine learning and natural language processing methods that will aid biomedical literature summarization and synthesis, and thereby support the conduct of evidence-based medicine (EBM). The proposed models and technologies will motivate core methodological innovations and support real-time, up-to-date, semi-automated biomedical evidence syntheses (systematic reviews). Such approaches are necessary if we are to have any hope of practicing evidence-based care in our era of information overload.",Semi-Automating Data Extraction for Systematic Reviews,9818711,R01LM012086,"['American', 'Automation', 'Caring', 'Clinical', 'Collection', 'Consumption', 'Data', 'Data Element', 'Databases', 'Development', 'Elements', 'Evaluation', 'Evidence Based Medicine', 'Evidence based practice', 'Feedback', 'Grant', 'Hybrids', 'Individual', 'Informatics', 'Internet', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical Informatics', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Modern Medicine', 'Natural Language Processing', 'Outcome', 'Output', 'Paper', 'Patient Care', 'Population Intervention', 'Process', 'PubMed', 'Publications', 'Publishing', 'Registries', 'Reporting', 'Research', 'Resources', 'Risk', 'Stroke', 'Structure', 'Surveillance Methods', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Vision', 'Work', 'base', 'cardiovascular health', 'database structure', 'design', 'evidence base', 'improved', 'indexing', 'innovation', 'learning strategy', 'natural language', 'neural network', 'novel', 'open source', 'programs', 'prospective', 'prototype', 'recruit', 'relating to nervous system', 'repository', 'search engine', 'study characteristics', 'study population', 'success', 'systematic review', 'tool', 'usability', 'working group']",NLM,NORTHEASTERN UNIVERSITY,R01,2019,320194,0.017157358396145832
"A research opportunity index to measure biomedical research disparities across the disease landscape.     DESCRIPTION (provided by applicant): Even as population health improves and longevity increases around the globe, there will always be more biomedical problems than solutions. Strategically prioritizing and allocating the limited societal resources to discover and develop cost-effective pharmaceuticals, medical devices and other diagnostics for diseases and medical conditions with the highest return on investment motivates many governmental and private funding agencies, pharmaceutical and biotech companies, clinicians and scientists. Unfortunately, due to the complexity of the biomedical research ecosystem and the scarcity of relevant data, no systematic studies have been done to comprehensively survey the past allocation of resources (i.e., funding, attention from the scientific community, clinical development) or guide the future redistribution of resources for maximal societal benefit.      The goal of this project is to create a disease-specific Research Opportunity Index (ROI) and a Public Health Index (PHI) to gauge the imbalance between the disease burden associated with a particular disease or all medical conditions as a whole and the associated resource allocation over time. The project has the following specific aims: 1) collect data on key measurable factors related to biomedical research resource allocation; 2) develop and evaluate quantitative models; and 3) build a visualization tool to represent and interpret high-dimensional data. More specifically, sophisticated text mining and terminology-mapping methods will be developed to identify and quantify several key factors in biomedical research ecosystem (i.e., burden of disease, focus of the scientific community, clinical development popularity, current availability o diagnostics and medicine, funding, and/or attention from public media and intellectual property protection). By integrating these data, the ROI and PHI will be calculated for about 1,400 medical conditions over a decade period, to identify ignored niches for future research. The high-dimensional data and results will be represented and delivered to various stakeholders along the healthcare value chain using an interactive visualization tool to facilitate their decisin making.     In addition to advancing the field of healthcare policy and management, this career development award will position the principal investigator as an independent researcher at the intersection of informatics and public health. PROJECT NARRATIVE: Today's world faces a growing population along with limited resources for healthcare and research, creating a need to better understand how these resources can be allocated to best benefit society. This project will create disease- specific Research Opportunity Index (ROI) and Public Health Index (PHI) that systematically examine multiple data sources over time. Our goal is quantify the (mis)alignment between biomedical research and disease burdens across the entire disease landscape in the US, and to enable stakeholders to better distribute resources and prioritize efforts. ",A research opportunity index to measure biomedical research disparities across the disease landscape.,9479285,K01LM012102,"['Address', 'Affect', 'Area', 'Attention', 'Attitude', 'Biomedical Research', 'Biotechnology', 'Budgets', 'Clinical Trials', 'Communities', 'Complex', 'Cost of Illness', 'Custom', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Developed Countries', 'Developing Countries', 'Development', 'Diagnostic', 'Disease', 'Drug Industry', 'Ecosystem', 'Equilibrium', 'Evaluation', 'Face', 'Feedback', 'Funding', 'Funding Agency', 'Future', 'Goals', 'Government', 'Guidelines', 'Health', 'Health Care Research', 'Health Policy', 'Healthcare', 'Human', 'Informatics', 'Institutes', 'Intellectual Property', 'Internet', 'Investments', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal patent', 'Literature', 'Longevity', 'Measurable', 'Measures', 'Medical', 'Medical Device', 'Medicine', 'Methods', 'Modeling', 'Outcome', 'Paper', 'Perception', 'Pharmacologic Substance', 'Plug-in', 'Population', 'Population Group', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Private Sector', 'Privatization', 'Public Health', 'Publishing', 'Reference Books', 'Reporting', 'Research', 'Research Personnel', 'Resource Allocation', 'Resources', 'Running', 'Rural', 'Scheme', 'Scientist', 'Societies', 'Specific qualifier value', 'Surveys', 'Terminology', 'Therapeutic', 'Time', 'Time trend', 'Treatment Cost', 'United States', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Visualization software', 'Weight', 'burden of illness', 'clinical development', 'cost effective', 'data visualization', 'health management', 'high dimensionality', 'improved', 'indexing', 'interest', 'news', 'novel therapeutics', 'population health', 'research and development', 'risk mitigation', 'social', 'text searching', 'tool', 'translational medicine', 'user-friendly', 'welfare']",NLM,MAYO CLINIC ROCHESTER,K01,2018,178482,0.022052903931014705
"A research opportunity index to measure biomedical research disparities across the disease landscape.     DESCRIPTION (provided by applicant): Even as population health improves and longevity increases around the globe, there will always be more biomedical problems than solutions. Strategically prioritizing and allocating the limited societal resources to discover and develop cost-effective pharmaceuticals, medical devices and other diagnostics for diseases and medical conditions with the highest return on investment motivates many governmental and private funding agencies, pharmaceutical and biotech companies, clinicians and scientists. Unfortunately, due to the complexity of the biomedical research ecosystem and the scarcity of relevant data, no systematic studies have been done to comprehensively survey the past allocation of resources (i.e., funding, attention from the scientific community, clinical development) or guide the future redistribution of resources for maximal societal benefit.      The goal of this project is to create a disease-specific Research Opportunity Index (ROI) and a Public Health Index (PHI) to gauge the imbalance between the disease burden associated with a particular disease or all medical conditions as a whole and the associated resource allocation over time. The project has the following specific aims: 1) collect data on key measurable factors related to biomedical research resource allocation; 2) develop and evaluate quantitative models; and 3) build a visualization tool to represent and interpret high-dimensional data. More specifically, sophisticated text mining and terminology-mapping methods will be developed to identify and quantify several key factors in biomedical research ecosystem (i.e., burden of disease, focus of the scientific community, clinical development popularity, current availability o diagnostics and medicine, funding, and/or attention from public media and intellectual property protection). By integrating these data, the ROI and PHI will be calculated for about 1,400 medical conditions over a decade period, to identify ignored niches for future research. The high-dimensional data and results will be represented and delivered to various stakeholders along the healthcare value chain using an interactive visualization tool to facilitate their decisin making.     In addition to advancing the field of healthcare policy and management, this career development award will position the principal investigator as an independent researcher at the intersection of informatics and public health. PROJECT NARRATIVE: Today's world faces a growing population along with limited resources for healthcare and research, creating a need to better understand how these resources can be allocated to best benefit society. This project will create disease- specific Research Opportunity Index (ROI) and Public Health Index (PHI) that systematically examine multiple data sources over time. Our goal is quantify the (mis)alignment between biomedical research and disease burdens across the entire disease landscape in the US, and to enable stakeholders to better distribute resources and prioritize efforts. ",A research opportunity index to measure biomedical research disparities across the disease landscape.,9265936,K01LM012102,"['Address', 'Affect', 'Area', 'Attention', 'Attitude', 'Biomedical Research', 'Biotechnology', 'Budgets', 'Clinical Trials', 'Communities', 'Complex', 'Cost of Illness', 'Custom', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Developed Countries', 'Developing Countries', 'Development', 'Diagnostic', 'Disease', 'Drug Industry', 'Ecosystem', 'Equilibrium', 'Evaluation', 'Face', 'Feedback', 'Funding', 'Funding Agency', 'Future', 'Goals', 'Government', 'Guidelines', 'Health', 'Health Care Research', 'Health Policy', 'Healthcare', 'Human', 'Informatics', 'Institutes', 'Intellectual Property', 'Internet', 'Investments', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal patent', 'Literature', 'Longevity', 'Measurable', 'Measures', 'Medical', 'Medical Device', 'Medicine', 'Methods', 'Modeling', 'Outcome', 'Paper', 'Perception', 'Pharmacologic Substance', 'Plug-in', 'Population', 'Population Group', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Private Sector', 'Privatization', 'Public Health', 'Publishing', 'Reference Books', 'Reporting', 'Research', 'Research Personnel', 'Resource Allocation', 'Resources', 'Running', 'Rural', 'Scheme', 'Scientist', 'Social Welfare', 'Societies', 'Specific qualifier value', 'Surveys', 'Terminology', 'Therapeutic', 'Time', 'Time trend', 'Treatment Cost', 'United States', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Visualization software', 'Weight', 'burden of illness', 'clinical development', 'cost effective', 'data visualization', 'high dimensionality', 'improved', 'indexing', 'interest', 'news', 'novel therapeutics', 'population health', 'research and development', 'risk mitigation', 'social', 'text searching', 'tool', 'translational medicine', 'user-friendly']",NLM,MAYO CLINIC ROCHESTER,K01,2017,178482,0.022052903931014705
"A research opportunity index to measure biomedical research disparities across the disease landscape.     DESCRIPTION (provided by applicant): Even as population health improves and longevity increases around the globe, there will always be more biomedical problems than solutions. Strategically prioritizing and allocating the limited societal resources to discover and develop cost-effective pharmaceuticals, medical devices and other diagnostics for diseases and medical conditions with the highest return on investment motivates many governmental and private funding agencies, pharmaceutical and biotech companies, clinicians and scientists. Unfortunately, due to the complexity of the biomedical research ecosystem and the scarcity of relevant data, no systematic studies have been done to comprehensively survey the past allocation of resources (i.e., funding, attention from the scientific community, clinical development) or guide the future redistribution of resources for maximal societal benefit.      The goal of this project is to create a disease-specific Research Opportunity Index (ROI) and a Public Health Index (PHI) to gauge the imbalance between the disease burden associated with a particular disease or all medical conditions as a whole and the associated resource allocation over time. The project has the following specific aims: 1) collect data on key measurable factors related to biomedical research resource allocation; 2) develop and evaluate quantitative models; and 3) build a visualization tool to represent and interpret high-dimensional data. More specifically, sophisticated text mining and terminology-mapping methods will be developed to identify and quantify several key factors in biomedical research ecosystem (i.e., burden of disease, focus of the scientific community, clinical development popularity, current availability o diagnostics and medicine, funding, and/or attention from public media and intellectual property protection). By integrating these data, the ROI and PHI will be calculated for about 1,400 medical conditions over a decade period, to identify ignored niches for future research. The high-dimensional data and results will be represented and delivered to various stakeholders along the healthcare value chain using an interactive visualization tool to facilitate their decisin making.     In addition to advancing the field of healthcare policy and management, this career development award will position the principal investigator as an independent researcher at the intersection of informatics and public health.           PROJECT NARRATIVE: Today's world faces a growing population along with limited resources for healthcare and research, creating a need to better understand how these resources can be allocated to best benefit society. This project will create disease- specific Research Opportunity Index (ROI) and Public Health Index (PHI) that systematically examine multiple data sources over time. Our goal is quantify the (mis)alignment between biomedical research and disease burdens across the entire disease landscape in the US, and to enable stakeholders to better distribute resources and prioritize efforts. ",A research opportunity index to measure biomedical research disparities across the disease landscape.,9103539,K01LM012102,"['Address', 'Affect', 'Area', 'Attention', 'Attitude', 'Biomedical Research', 'Biotechnology', 'Budgets', 'Clinical', 'Clinical Trials', 'Communities', 'Complex', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Developed Countries', 'Development', 'Diagnostic', 'Disease', 'Drug Industry', 'Ecosystem', 'Equilibrium', 'Evaluation', 'Face', 'Feedback', 'Funding', 'Funding Agency', 'Future', 'Goals', 'Government', 'Guidelines', 'Health', 'Health Care Research', 'Health Policy', 'Healthcare', 'Human', 'Imagery', 'Institutes', 'Intellectual Property', 'Internet', 'Investments', 'Journals', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Left', 'Legal patent', 'Literature', 'Longevity', 'Maps', 'Measurable', 'Measures', 'Medical', 'Medical Device', 'Medicine', 'Methods', 'Modeling', 'Outcome', 'Paper', 'Perception', 'Pharmacologic Substance', 'Plug-in', 'Population', 'Population Group', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Private Sector', 'Public Health', 'Public Health Informatics', 'Publishing', 'Reference Books', 'Reporting', 'Research', 'Research Personnel', 'Resource Allocation', 'Resources', 'Running', 'Rural', 'Scheme', 'Scientist', 'Social Welfare', 'Societies', 'Specific qualifier value', 'Surveys', 'Terminology', 'Therapeutic', 'Time', 'Treatment Cost', 'United States', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Weight', 'burden of illness', 'cost effective', 'data visualization', 'improved', 'indexing', 'interest', 'news', 'novel therapeutics', 'population health', 'research and development', 'risk mitigation', 'social', 'text searching', 'tool', 'translational medicine', 'trend', 'user-friendly']",NLM,UNIVERSITY OF NORTH CAROLINA CHARLOTTE,K01,2016,46079,0.022052903931014705
"Natural Language Question Understanding for Electronic Health Records     DESCRIPTION (provided by applicant): Patient information in the electronic health record (EHR) such as lab results, medications, and past medical history is the basis for physician decisions about patient care. It also helps patients better understand and manage their care. Efficient access to this patient information is thus essential. One of the most intuitive ways of accessing data is by asking natural language questions. A significant amount of work in medical question answering has been conducted, yet little work has been performed in question answering for EHRs. Natural language questions can be represented in logical forms, a standard structured knowledge representation technique. This project proposes to take natural language EHR questions, both for doctors and patients, and automatically convert them to a logical form. The logical forms can then be converted to a structured query such as those used by EHRs. A major obstacle to this approach is the lack of data containing questions annotated with logical forms. This project hypothesizes that a small set of questions can be manually annotated, and then paraphrases can be produced for each annotated question. Since paraphrasing is a simpler task than logical form annotation, crowd-sourcing techniques can be used to collect thousands of question paraphrases. This question paraphrase corpus will then be used to build a semantic grammar capable of recognizing the logical structure of EHR questions. To ensure a robust, generalizable grammar, existing NLP techniques will be used to pre-process questions, simplifying their syntactic structure and abstracting their medical concepts.     In order to develop such a method, the candidate, Dr. Kirk Roberts, requires additional training and mentoring in natural language processing and biomedical informatics. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Roberts to achieve the goals of this project as well as transition to a career as an independent researcher. He will be mentored by Dr. Dina Demner-Fushman, a leading medical NLP researcher, and co-mentored by Dr. Clement McDonald, a leading EHR and medical informatics researcher.     The specific aims of the project are: (1) Build a paraphrase collection of EHR questions, where each prototype question will have many unique paraphrases. The paraphrases encompass different lexical and syntactic means of conveying the same logical form. (2) Construct a semantic grammar for EHR questions. The grammar can then be used to convert a natural language question to a logical form. (3) Implement an end- to-end question analyzer that generalizes EHR questions for improved parsing, parses the question into a logical form using the grammar, and converts the logical form into a leading structured EHR query format. PROJECT NARRATIVE The proposed work aims to significantly improve the ability of both doctors and patients to find information within electronic health records (EHR). By providing an interface to EHRs where users can specify their information needs in the form of a natural language question, the proposed work provides a more intuitive means of finding patient data than is currently available.",Natural Language Question Understanding for Electronic Health Records,9479293,R00LM012104,"['Artificial Intelligence', 'Award', 'Blood Glucose', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Data', 'Databases', 'Development Plans', 'Electronic Health Record', 'Ensure', 'Glucose', 'Goals', 'Health', 'Intuition', 'Knowledge', 'Literature', 'Manuals', 'Medical', 'Medical History', 'Medical Informatics', 'Mentors', 'Methods', 'Natural Language Processing', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Work', 'abstracting', 'base', 'biomedical informatics', 'career', 'career development', 'crowdsourcing', 'data access', 'design', 'electronic structure', 'health data', 'illiterate', 'improved', 'information organization', 'lexical', 'natural language', 'open source', 'operation', 'patient portal', 'phrases', 'prototype', 'syntax']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2018,248999,0.1104680264365309
"Natural Language Question Understanding for Electronic Health Records     DESCRIPTION (provided by applicant): Patient information in the electronic health record (EHR) such as lab results, medications, and past medical history is the basis for physician decisions about patient care. It also helps patients better understand and manage their care. Efficient access to this patient information is thus essential. One of the most intuitive ways of accessing data is by asking natural language questions. A significant amount of work in medical question answering has been conducted, yet little work has been performed in question answering for EHRs. Natural language questions can be represented in logical forms, a standard structured knowledge representation technique. This project proposes to take natural language EHR questions, both for doctors and patients, and automatically convert them to a logical form. The logical forms can then be converted to a structured query such as those used by EHRs. A major obstacle to this approach is the lack of data containing questions annotated with logical forms. This project hypothesizes that a small set of questions can be manually annotated, and then paraphrases can be produced for each annotated question. Since paraphrasing is a simpler task than logical form annotation, crowd-sourcing techniques can be used to collect thousands of question paraphrases. This question paraphrase corpus will then be used to build a semantic grammar capable of recognizing the logical structure of EHR questions. To ensure a robust, generalizable grammar, existing NLP techniques will be used to pre-process questions, simplifying their syntactic structure and abstracting their medical concepts.     In order to develop such a method, the candidate, Dr. Kirk Roberts, requires additional training and mentoring in natural language processing and biomedical informatics. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Roberts to achieve the goals of this project as well as transition to a career as an independent researcher. He will be mentored by Dr. Dina Demner-Fushman, a leading medical NLP researcher, and co-mentored by Dr. Clement McDonald, a leading EHR and medical informatics researcher.     The specific aims of the project are: (1) Build a paraphrase collection of EHR questions, where each prototype question will have many unique paraphrases. The paraphrases encompass different lexical and syntactic means of conveying the same logical form. (2) Construct a semantic grammar for EHR questions. The grammar can then be used to convert a natural language question to a logical form. (3) Implement an end- to-end question analyzer that generalizes EHR questions for improved parsing, parses the question into a logical form using the grammar, and converts the logical form into a leading structured EHR query format. PROJECT NARRATIVE The proposed work aims to significantly improve the ability of both doctors and patients to find information within electronic health records (EHR). By providing an interface to EHRs where users can specify their information needs in the form of a natural language question, the proposed work provides a more intuitive means of finding patient data than is currently available.",Natural Language Question Understanding for Electronic Health Records,9254613,R00LM012104,"['Artificial Intelligence', 'Award', 'Blood Glucose', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Data', 'Databases', 'Development Plans', 'Electronic Health Record', 'Ensure', 'Glucose', 'Goals', 'Health', 'Intuition', 'Knowledge', 'Literature', 'Manuals', 'Medical', 'Medical History', 'Medical Informatics', 'Mentors', 'Methods', 'Natural Language Processing', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Work', 'abstracting', 'base', 'biomedical informatics', 'career', 'career development', 'crowdsourcing', 'data access', 'design', 'electronic structure', 'health data', 'illiterate', 'improved', 'information organization', 'lexical', 'natural language', 'open source', 'operation', 'phrases', 'prototype', 'syntax']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2017,248999,0.1104680264365309
"Natural Language Question Understanding for Electronic Health Records     DESCRIPTION (provided by applicant): Patient information in the electronic health record (EHR) such as lab results, medications, and past medical history is the basis for physician decisions about patient care. It also helps patients better understand and manage their care. Efficient access to this patient information is thus essential. One of the most intuitive ways of accessing data is by asking natural language questions. A significant amount of work in medical question answering has been conducted, yet little work has been performed in question answering for EHRs. Natural language questions can be represented in logical forms, a standard structured knowledge representation technique. This project proposes to take natural language EHR questions, both for doctors and patients, and automatically convert them to a logical form. The logical forms can then be converted to a structured query such as those used by EHRs. A major obstacle to this approach is the lack of data containing questions annotated with logical forms. This project hypothesizes that a small set of questions can be manually annotated, and then paraphrases can be produced for each annotated question. Since paraphrasing is a simpler task than logical form annotation, crowd-sourcing techniques can be used to collect thousands of question paraphrases. This question paraphrase corpus will then be used to build a semantic grammar capable of recognizing the logical structure of EHR questions. To ensure a robust, generalizable grammar, existing NLP techniques will be used to pre-process questions, simplifying their syntactic structure and abstracting their medical concepts.     In order to develop such a method, the candidate, Dr. Kirk Roberts, requires additional training and mentoring in natural language processing and biomedical informatics. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Roberts to achieve the goals of this project as well as transition to a career as an independent researcher. He will be mentored by Dr. Dina Demner-Fushman, a leading medical NLP researcher, and co-mentored by Dr. Clement McDonald, a leading EHR and medical informatics researcher.     The specific aims of the project are: (1) Build a paraphrase collection of EHR questions, where each prototype question will have many unique paraphrases. The paraphrases encompass different lexical and syntactic means of conveying the same logical form. (2) Construct a semantic grammar for EHR questions. The grammar can then be used to convert a natural language question to a logical form. (3) Implement an end- to-end question analyzer that generalizes EHR questions for improved parsing, parses the question into a logical form using the grammar, and converts the logical form into a leading structured EHR query format. PROJECT NARRATIVE The proposed work aims to significantly improve the ability of both doctors and patients to find information within electronic health records (EHR). By providing an interface to EHRs where users can specify their information needs in the form of a natural language question, the proposed work provides a more intuitive means of finding patient data than is currently available.",Natural Language Question Understanding for Electronic Health Records,9228509,R00LM012104,"['Artificial Intelligence', 'Award', 'Blood Glucose', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Data', 'Development Plans', 'Electronic Health Record', 'Ensure', 'Glucose', 'Goals', 'Health', 'Knowledge', 'Literature', 'Medical', 'Medical History', 'Medical Informatics', 'Mentors', 'Methods', 'Natural Language Processing', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Work', 'abstracting', 'base', 'biomedical informatics', 'career', 'career development', 'crowdsourcing', 'data access', 'database structure', 'design', 'health data', 'illiterate', 'improved', 'information organization', 'lexical', 'natural language', 'open source', 'operation', 'phrases', 'prototype', 'syntax']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2016,249000,0.1104680264365309
"Subgroup Analytics and Advanced Semantic Technologies to Enable Personalized Medicine     DESCRIPTION (provided by applicant): United States healthcare is embroiled in a crisis of inconsistent quality and overwhelming cost. Through two administrations, the national healthcare strategy has focused on using data and technology to control costs and improve care. Congress has enacted legislation to encourage measurement of quality, sharing of data, payment based on quality of care, and transparency within the healthcare system. While these goals are bipartisan and lofty, implementation requires both hard work from health systems and robust technology. Industry has developed technologies that incrementally further the national agenda, including electronic health records, computer assisted coding, and population health analytics. Each of these supports workflow within the healthcare system and improves profit margin for healthcare organizations. But, approaches that go beyond workflow, using data to better understand clinical care, are lacking. With newly available electronic health data and a massive increase in processing power, data-driven personalized medicine is just now becoming possible. It will require advanced semantic technologies to understand clinical care strategies that have been tried in the past, but that have unknown efficacy. It will pose informatics challenges in inferring inclusion criteria, interventions, and outcomes from incomplete and poorly structured data. It will require deep clinical understanding to run real-time pragmatic clinical trials based on real world data to understand complex patients. The goal, dependent on Phase I success, is to create the first commercial system to support healthcare in running real-time pragmatic clinical trials using full clinical data. This will augment the standard of care defined by randomized controlled trials to actually tailor therapy for those complex patients that account for the majority of healthcare spends, but for whom complexity precludes tailored randomized trials.         PUBLIC HEALTH RELEVANCE: If successful, the Phase I effort will represent a first step toward a revolutionary approach to leverage newly collected clinical data, rapidly evolving semantic technologies, and cutting edge clinical informatics to define best practices in healthcare. The overall project will target the complex patients that are poorly served by generalization of the randomized trial and currently account for the majority of healthcare spend. The goal is to leverage the national investment in clinical data to not just improve clinical workflow, but to actually transform medicine to achieve national goals of reducing costs and improving outcomes.            ",Subgroup Analytics and Advanced Semantic Technologies to Enable Personalized Medicine,8979535,R43LM012168,"['Accounting', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Trials', 'Code', 'Complex', 'Computer Assisted', 'Congresses', 'Cost Control', 'Data', 'Data Element', 'Electronic Health Record', 'Electronics', 'Exclusion Criteria', 'Goals', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Industry', 'Informatics', 'Intervention', 'Investments', 'Label', 'Maps', 'Measurement', 'Medicine', 'Modeling', 'Natural Language Processing', 'Outcome', 'Pathway interactions', 'Patients', 'Pharmacologic Substance', 'Phase', 'Process', 'Quality of Care', 'Randomized Controlled Trials', 'Rest', 'Running', 'Semantics', 'Small Business Innovation Research Grant', 'Statutes and Laws', 'Structure', 'Subgroup', 'System', 'Technology', 'Time', 'United States', 'Work', 'World Health', 'base', 'clinical care', 'clinical phenotype', 'cohort', 'commercialization', 'cost', 'data sharing', 'health data', 'improved', 'inclusion criteria', 'meetings', 'payment', 'personalized medicine', 'population health', 'public health relevance', 'randomized trial', 'standard of care', 'success']",NLM,"VMT, INC.",R43,2015,224712,0.04439106382600055
"From Syntactic Relations to Semantic Predications: Porting Open Information Extraction to Biomedicine     DESCRIPTION (provided by applicant):ABSTRACT Owing to exponential growth in scientic literature, it has become increasingly difcult for researchers to keep up with the latest developments in their elds of study. Hence, computational approaches that automatically mine large amounts of free text to extract essential information have gained popularity. This information is typically represented in the form of binary relations between different biomedical concepts. In this context, automatic extraction of meaningful relations from natural language narratives, a task often termed biomedical relation extraction (BRE), has garnered attention from informaticians. The relations extracted are used in high level applications including information retrieval (IR), literature based discovery (LBD), question answering, and text summarization. Most current BRE efforts tend to focus on a specic subdomain in biomedicine. For example, researchers built models that extract gene-protein or gene-gene interactions; in the clinical domain, recent results are focused on drug-drug and drug-disease interactions mentioned in clinical narratives. The only effort that extracts a broad set of relations adhering t a large standardized vocabulary is the rule based SemRep program being developed by researchers at the National Library of Medicine (NLM). SemRep extracts binary relations, called semantic predications, between biomedical entities from the UMLS Metathesaurus with predicates coming from an extension of the UMLS Semantic Network. Although SemRep achieves reasonable precision, its recall is very low on a gold standard dataset created for its evaluation. Given many applications in LBD and IR already use the predication database SemMedDB (obtained by running SemRep on all biomedical citations made available through PubMed), a predication extraction framework with a higher recall and a low acceptable loss in precision is more desirable especially if it can complement SemRep's extractions. We propose to build and evaluate a supervised BRE framework that converts syntactic relations obtained using the paradigm of open information extraction (OIE) to semantic predications by leveraging the existing database of predications in SemMedDB and relations from the UMLS Metathesaurus through distant supervision. We will conduct domain independent evaluation based on a gold standard dataset built by researchers at the NLM for evaluating SemRep. We will also conduct application oriented evaluations by simulating predication graph based document and passage retrieval using the Text REtrieval Conference (TREC) Genomics and OHSUMED datasets for IR experiments. We will also evaluate the quality of subgraphs resulting from LBD experiments to rediscover nine well known biomedical discoveries. We hypothesize that the predications extracted through our methods will complement those in SemMedDB and the combined predication dataset will result in improved overall performance compared with using SemMedDB alone. NARRATIVE Semantic predications are binary relations extracted from biomedical text by the SemRep program and connect biomedical entities with a xed set of relation types. Although SemRep extractions have reasonable precision, their recall is very low. We propose to build a supervised predication extraction framework whose results will complement SemRep's extractions in terms of improved performance in both direct gold standard evaluation and application oriented evaluation in the context of information retrieval and literature based discovery.",From Syntactic Relations to Semantic Predications: Porting Open Information Extraction to Biomedicine,9274042,R21LM012274,"['Area', 'Attention', 'Automated Abstracting', 'Classification', 'Clinical', 'Complement', 'Computer software', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Distant', 'Drug Interactions', 'Evaluation', 'Event', 'Explosion', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genomics', 'Gold', 'Graph', 'Growth', 'Ice', 'Information Retrieval', 'Literature', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Output', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Process', 'PubMed', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Running', 'Semantics', 'Standardization', 'Supervision', 'System', 'Testing', 'Text', 'Training', 'UML Entity', 'UMLS Metathesaurus', 'Unified Medical Language System', 'United States National Library of Medicine', 'Update', 'Vent', 'Vocabulary', 'Work', 'base', 'experimental study', 'field study', 'gene interaction', 'improved', 'indexing', 'metathesaurus', 'natural language', 'open source', 'programs', 'protein function', 'search engine', 'symposium', 'syntax', 'web services']",NLM,UNIVERSITY OF KENTUCKY,R21,2017,164263,-0.0015228836688572108
"From Syntactic Relations to Semantic Predications: Porting Open Information Extraction to Biomedicine     DESCRIPTION (provided by applicant):ABSTRACT Owing to exponential growth in scientic literature, it has become increasingly difcult for researchers to keep up with the latest developments in their elds of study. Hence, computational approaches that automatically mine large amounts of free text to extract essential information have gained popularity. This information is typically represented in the form of binary relations between different biomedical concepts. In this context, automatic extraction of meaningful relations from natural language narratives, a task often termed biomedical relation extraction (BRE), has garnered attention from informaticians. The relations extracted are used in high level applications including information retrieval (IR), literature based discovery (LBD), question answering, and text summarization. Most current BRE efforts tend to focus on a specic subdomain in biomedicine. For example, researchers built models that extract gene-protein or gene-gene interactions; in the clinical domain, recent results are focused on drug-drug and drug-disease interactions mentioned in clinical narratives. The only effort that extracts a broad set of relations adhering t a large standardized vocabulary is the rule based SemRep program being developed by researchers at the National Library of Medicine (NLM). SemRep extracts binary relations, called semantic predications, between biomedical entities from the UMLS Metathesaurus with predicates coming from an extension of the UMLS Semantic Network. Although SemRep achieves reasonable precision, its recall is very low on a gold standard dataset created for its evaluation. Given many applications in LBD and IR already use the predication database SemMedDB (obtained by running SemRep on all biomedical citations made available through PubMed), a predication extraction framework with a higher recall and a low acceptable loss in precision is more desirable especially if it can complement SemRep's extractions. We propose to build and evaluate a supervised BRE framework that converts syntactic relations obtained using the paradigm of open information extraction (OIE) to semantic predications by leveraging the existing database of predications in SemMedDB and relations from the UMLS Metathesaurus through distant supervision. We will conduct domain independent evaluation based on a gold standard dataset built by researchers at the NLM for evaluating SemRep. We will also conduct application oriented evaluations by simulating predication graph based document and passage retrieval using the Text REtrieval Conference (TREC) Genomics and OHSUMED datasets for IR experiments. We will also evaluate the quality of subgraphs resulting from LBD experiments to rediscover nine well known biomedical discoveries. We hypothesize that the predications extracted through our methods will complement those in SemMedDB and the combined predication dataset will result in improved overall performance compared with using SemMedDB alone.             NARRATIVE Semantic predications are binary relations extracted from biomedical text by the SemRep program and connect biomedical entities with a xed set of relation types. Although SemRep extractions have reasonable precision, their recall is very low. We propose to build a supervised predication extraction framework whose results will complement SemRep's extractions in terms of improved performance in both direct gold standard evaluation and application oriented evaluation in the context of information retrieval and literature based discovery.",From Syntactic Relations to Semantic Predications: Porting Open Information Extraction to Biomedicine,9021081,R21LM012274,"['Area', 'Attention', 'Automated Abstracting', 'Clinical', 'Complement', 'Computer software', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Distant', 'Drug Interactions', 'Evaluation', 'Event', 'Explosion', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genomics', 'Gold', 'Graph', 'Growth', 'Information Retrieval', 'Literature', 'Measures', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Output', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Process', 'PubMed', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Running', 'Semantics', 'Supervision', 'System', 'Testing', 'Text', 'Training', 'UMLS Metathesaurus', 'Unified Medical Language System', 'United States National Library of Medicine', 'Update', 'Vent', 'Vocabulary', 'Work', 'abstracting', 'base', 'gene interaction', 'improved', 'indexing', 'metathesaurus', 'model building', 'natural language', 'open source', 'programs', 'protein function', 'research study', 'search engine', 'symposium', 'syntax', 'web services']",NLM,UNIVERSITY OF KENTUCKY,R21,2016,209697,-0.0015228836688572108
"The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging     DESCRIPTION (provided by applicant): Limited health literacy (HL) places individuals at greater risk of type 2 diabetes (DM2) and its complications, is a marker of vulnerability, and presents a critical clinical and public health problem. To be health literate in the 21st century, patients will need a certain level of linguistic facility, in combination with technical skills, to access services via online patient portals. Our research has shown that DM2 patients with limited HL are actively using patient portals. However, as healthcare becomes increasingly dependent on electronic communications (e.g., secure messages via internet-based patient portals), patients with limited HL may have difficulty communicating electronically with their clinician or understanding their clinician's secure message responses or instructions. For clinicians to electronically provide meaningful and actionable information and support, their secure messages must be written in an easily comprehended style. Few studies have examined how patients with limited HL interact with their healthcare providers via patient portals. This trans-disciplinary proposal, involving a team of health services researchers, health communication scientists, and computational linguists, will focus on a population of ethnically diverse DM2 patients and their primary care providers from 1) a large, integrated group model HMO with a well-developed patient portal and 2) a county-run, integrated public (safety net) delivery system with a newly launched electronic health record and patient portal. Our study is designed around a conceptual framework promoted most recently by the Institute of Medicine: overcoming the challenges LHL patients face in managing DM2 requires that healthcare systems, and their clinicians, make accommodations to meet patients' communication needs. The degree of linguistic ""mismatch"" observed in secure message exchanges between DM2 patients and their providers, measured using computational linguistics, will serve as one indicator of the extent to which providers are, or are not, making such accommodations. Our specific aims are to (Aim 1) develop and validate a novel, automated linguistic complexity profile (LCP) to assess secure message content generated by DM2 patients and their providers via patient portals. We will employ natural language processing (NLP) to develop and validate the LCP, based on secure messages and data from >200,000 DM2 patients. The LCP will demonstrate construct validity with patient HL and patient reports of provider communication, and will be associated with DM2 outcomes; (Aim 2) examine whether concordance between provider and patient LCP is associated with adherence among DM2 patients newly prescribed insulin or antidepressants; (Aim 3) characterize the collaborative nature of exchanges between providers and low LCP patients, using mixed methods, to enhance our understanding of communication in the critical period surrounding initiation of insulin or antidepressants; (Aim 4) create an automated, LCP-based prototype to provide real-time feedback to providers while writing secure messages to reduce linguistic complexity and better accommodate DM2 patients' linguistic skills and HL. PUBLIC HEALTH RELEVANCE: Limited health literacy places individuals at greater risk of type 2 diabetes and its complications, making limited health literacy a critical clinical and publi health problem. As healthcare becomes increasingly dependent on electronic communications, patients with limited health literacy may have difficulty communicating by email with their clinician or understanding the clinician's emailed replies or instructions. This proposal will use computational linguistics to examine how diabetes patients with a variety of health literacy levels interact with their clinicians via patient portals, will explore whether linguistic gaps between patients and clinicians are associated with diabetes outcomes, and will create a feedback tool to assist clinicians to better accommodate diabetes patients' communication needs.",The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging,9521527,R01LM012355,"['Adherence', 'Advocate', 'Antidepressive Agents', 'Caring', 'Clinical', 'Communication', 'Computational Linguistics', 'Computer software', 'County', 'Data', 'Diabetes Mellitus', 'Electronic Health Record', 'Electronic Mail', 'Face', 'Feedback', 'Glycosylated hemoglobin A', 'Health', 'Health Communication', 'Health Personnel', 'Health Promotion', 'Health Services', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hypoglycemia', 'In Vitro', 'Individual', 'Information Services', 'Institute of Medicine (U.S.)', 'Instruction', 'Insulin', 'Integrated Health Care Systems', 'Internet', 'Linguistics', 'Measures', 'Mediator of activation protein', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Randomized Controlled Trials', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Secure', 'Series', 'System', 'Technical Expertise', 'Testing', 'Time', 'Visit', 'Writing', 'arm', 'base', 'care providers', 'communication aid', 'critical period', 'design', 'ethnic diversity', 'experimental study', 'frontier', 'health care delivery', 'health care service utilization', 'health literacy', 'improved', 'literate', 'novel', 'patient portal', 'profiles in patients', 'prototype', 'public health relevance', 'response', 'safety net', 'service utilization', 'simulation', 'skills', 'tool', 'uptake']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2018,784077,0.03648978808258806
"The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging     DESCRIPTION (provided by applicant): Limited health literacy (HL) places individuals at greater risk of type 2 diabetes (DM2) and its complications, is a marker of vulnerability, and presents a critical clinical and public health problem. To be health literate in the 21st century, patients will need a certain level of linguistic facility, in combination with technical skills, to access services via online patient portals. Our research has shown that DM2 patients with limited HL are actively using patient portals. However, as healthcare becomes increasingly dependent on electronic communications (e.g., secure messages via internet-based patient portals), patients with limited HL may have difficulty communicating electronically with their clinician or understanding their clinician's secure message responses or instructions. For clinicians to electronically provide meaningful and actionable information and support, their secure messages must be written in an easily comprehended style. Few studies have examined how patients with limited HL interact with their healthcare providers via patient portals. This trans-disciplinary proposal, involving a team of health services researchers, health communication scientists, and computational linguists, will focus on a population of ethnically diverse DM2 patients and their primary care providers from 1) a large, integrated group model HMO with a well-developed patient portal and 2) a county-run, integrated public (safety net) delivery system with a newly launched electronic health record and patient portal. Our study is designed around a conceptual framework promoted most recently by the Institute of Medicine: overcoming the challenges LHL patients face in managing DM2 requires that healthcare systems, and their clinicians, make accommodations to meet patients' communication needs. The degree of linguistic ""mismatch"" observed in secure message exchanges between DM2 patients and their providers, measured using computational linguistics, will serve as one indicator of the extent to which providers are, or are not, making such accommodations. Our specific aims are to (Aim 1) develop and validate a novel, automated linguistic complexity profile (LCP) to assess secure message content generated by DM2 patients and their providers via patient portals. We will employ natural language processing (NLP) to develop and validate the LCP, based on secure messages and data from >200,000 DM2 patients. The LCP will demonstrate construct validity with patient HL and patient reports of provider communication, and will be associated with DM2 outcomes; (Aim 2) examine whether concordance between provider and patient LCP is associated with adherence among DM2 patients newly prescribed insulin or antidepressants; (Aim 3) characterize the collaborative nature of exchanges between providers and low LCP patients, using mixed methods, to enhance our understanding of communication in the critical period surrounding initiation of insulin or antidepressants; (Aim 4) create an automated, LCP-based prototype to provide real-time feedback to providers while writing secure messages to reduce linguistic complexity and better accommodate DM2 patients' linguistic skills and HL. PUBLIC HEALTH RELEVANCE: Limited health literacy places individuals at greater risk of type 2 diabetes and its complications, making limited health literacy a critical clinical and publi health problem. As healthcare becomes increasingly dependent on electronic communications, patients with limited health literacy may have difficulty communicating by email with their clinician or understanding the clinician's emailed replies or instructions. This proposal will use computational linguistics to examine how diabetes patients with a variety of health literacy levels interact with their clinicians via patient portals, will explore whether linguistic gaps between patients and clinicians are associated with diabetes outcomes, and will create a feedback tool to assist clinicians to better accommodate diabetes patients' communication needs.",The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging,9614617,R01LM012355,"['Adherence', 'Advocate', 'Antidepressive Agents', 'Caring', 'Clinical', 'Communication', 'Computational Linguistics', 'Computer software', 'County', 'Data', 'Diabetes Mellitus', 'Electronic Health Record', 'Electronic Mail', 'Face', 'Feedback', 'Glycosylated hemoglobin A', 'Health', 'Health Communication', 'Health Personnel', 'Health Promotion', 'Health Services', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hypoglycemia', 'In Vitro', 'Individual', 'Information Services', 'Institute of Medicine (U.S.)', 'Instruction', 'Insulin', 'Integrated Health Care Systems', 'Internet', 'Linguistics', 'Measures', 'Mediator of activation protein', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Randomized Controlled Trials', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Secure', 'Series', 'System', 'Technical Expertise', 'Testing', 'Time', 'Visit', 'Writing', 'arm', 'base', 'care providers', 'communication aid', 'critical period', 'design', 'ethnic diversity', 'experimental study', 'frontier', 'health care delivery', 'health care service utilization', 'health literacy', 'improved', 'literate', 'novel', 'patient portal', 'profiles in patients', 'prototype', 'public health relevance', 'response', 'safety net', 'service utilization', 'simulation', 'skills', 'tool', 'uptake']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2018,55085,0.03648978808258806
"The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging     DESCRIPTION (provided by applicant): Limited health literacy (HL) places individuals at greater risk of type 2 diabetes (DM2) and its complications, is a marker of vulnerability, and presents a critical clinical and public health problem. To be health literate in the 21st century, patients will need a certain level of linguistic facility, in combination with technical skills, to access services via online patient portals. Our research has shown that DM2 patients with limited HL are actively using patient portals. However, as healthcare becomes increasingly dependent on electronic communications (e.g., secure messages via internet-based patient portals), patients with limited HL may have difficulty communicating electronically with their clinician or understanding their clinician's secure message responses or instructions. For clinicians to electronically provide meaningful and actionable information and support, their secure messages must be written in an easily comprehended style. Few studies have examined how patients with limited HL interact with their healthcare providers via patient portals. This trans-disciplinary proposal, involving a team of health services researchers, health communication scientists, and computational linguists, will focus on a population of ethnically diverse DM2 patients and their primary care providers from 1) a large, integrated group model HMO with a well-developed patient portal and 2) a county-run, integrated public (safety net) delivery system with a newly launched electronic health record and patient portal. Our study is designed around a conceptual framework promoted most recently by the Institute of Medicine: overcoming the challenges LHL patients face in managing DM2 requires that healthcare systems, and their clinicians, make accommodations to meet patients' communication needs. The degree of linguistic ""mismatch"" observed in secure message exchanges between DM2 patients and their providers, measured using computational linguistics, will serve as one indicator of the extent to which providers are, or are not, making such accommodations. Our specific aims are to (Aim 1) develop and validate a novel, automated linguistic complexity profile (LCP) to assess secure message content generated by DM2 patients and their providers via patient portals. We will employ natural language processing (NLP) to develop and validate the LCP, based on secure messages and data from >200,000 DM2 patients. The LCP will demonstrate construct validity with patient HL and patient reports of provider communication, and will be associated with DM2 outcomes; (Aim 2) examine whether concordance between provider and patient LCP is associated with adherence among DM2 patients newly prescribed insulin or antidepressants; (Aim 3) characterize the collaborative nature of exchanges between providers and low LCP patients, using mixed methods, to enhance our understanding of communication in the critical period surrounding initiation of insulin or antidepressants; (Aim 4) create an automated, LCP-based prototype to provide real-time feedback to providers while writing secure messages to reduce linguistic complexity and better accommodate DM2 patients' linguistic skills and HL. PUBLIC HEALTH RELEVANCE: Limited health literacy places individuals at greater risk of type 2 diabetes and its complications, making limited health literacy a critical clinical and publi health problem. As healthcare becomes increasingly dependent on electronic communications, patients with limited health literacy may have difficulty communicating by email with their clinician or understanding the clinician's emailed replies or instructions. This proposal will use computational linguistics to examine how diabetes patients with a variety of health literacy levels interact with their clinicians via patient portals, will explore whether linguistic gaps between patients and clinicians are associated with diabetes outcomes, and will create a feedback tool to assist clinicians to better accommodate diabetes patients' communication needs.",The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging,9296180,R01LM012355,"['Adherence', 'Advocate', 'Antidepressive Agents', 'Caring', 'Clinical', 'Communication', 'Computational Linguistics', 'Computer software', 'County', 'Data', 'Diabetes Mellitus', 'Electronic Health Record', 'Electronic Mail', 'Face', 'Feedback', 'Glycosylated hemoglobin A', 'Health', 'Health Communication', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hypoglycemia', 'In Vitro', 'Individual', 'Information Services', 'Institute of Medicine (U.S.)', 'Instruction', 'Insulin', 'Internet', 'Linguistics', 'Measures', 'Mediator of activation protein', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Primary Health Care', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Randomized Controlled Trials', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Secure', 'Series', 'System', 'Technical Expertise', 'Testing', 'Time', 'Visit', 'Writing', 'arm', 'base', 'communication aid', 'critical period', 'design', 'ethnic diversity', 'experimental study', 'frontier', 'health care delivery', 'health care service utilization', 'health literacy', 'improved', 'literate', 'novel', 'profiles in patients', 'prototype', 'public health relevance', 'response', 'safety net', 'service utilization', 'simulation', 'skills', 'tool', 'uptake']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2017,612234,0.03648978808258806
"The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging     DESCRIPTION (provided by applicant): Limited health literacy (HL) places individuals at greater risk of type 2 diabetes (DM2) and its complications, is a marker of vulnerability, and presents a critical clinical and public health problem. To be health literate in the 21st century, patients will need a certain level of linguistic facility, in combination with technical skills, to access services via online patient portals. Our research has shown that DM2 patients with limited HL are actively using patient portals. However, as healthcare becomes increasingly dependent on electronic communications (e.g., secure messages via internet-based patient portals), patients with limited HL may have difficulty communicating electronically with their clinician or understanding their clinician's secure message responses or instructions. For clinicians to electronically provide meaningful and actionable information and support, their secure messages must be written in an easily comprehended style. Few studies have examined how patients with limited HL interact with their healthcare providers via patient portals. This trans-disciplinary proposal, involving a team of health services researchers, health communication scientists, and computational linguists, will focus on a population of ethnically diverse DM2 patients and their primary care providers from 1) a large, integrated group model HMO with a well-developed patient portal and 2) a county-run, integrated public (safety net) delivery system with a newly launched electronic health record and patient portal. Our study is designed around a conceptual framework promoted most recently by the Institute of Medicine: overcoming the challenges LHL patients face in managing DM2 requires that healthcare systems, and their clinicians, make accommodations to meet patients' communication needs. The degree of linguistic ""mismatch"" observed in secure message exchanges between DM2 patients and their providers, measured using computational linguistics, will serve as one indicator of the extent to which providers are, or are not, making such accommodations. Our specific aims are to (Aim 1) develop and validate a novel, automated linguistic complexity profile (LCP) to assess secure message content generated by DM2 patients and their providers via patient portals. We will employ natural language processing (NLP) to develop and validate the LCP, based on secure messages and data from >200,000 DM2 patients. The LCP will demonstrate construct validity with patient HL and patient reports of provider communication, and will be associated with DM2 outcomes; (Aim 2) examine whether concordance between provider and patient LCP is associated with adherence among DM2 patients newly prescribed insulin or antidepressants; (Aim 3) characterize the collaborative nature of exchanges between providers and low LCP patients, using mixed methods, to enhance our understanding of communication in the critical period surrounding initiation of insulin or antidepressants; (Aim 4) create an automated, LCP-based prototype to provide real-time feedback to providers while writing secure messages to reduce linguistic complexity and better accommodate DM2 patients' linguistic skills and HL. PUBLIC HEALTH RELEVANCE: Limited health literacy places individuals at greater risk of type 2 diabetes and its complications, making limited health literacy a critical clinical and publi health problem. As healthcare becomes increasingly dependent on electronic communications, patients with limited health literacy may have difficulty communicating by email with their clinician or understanding the clinician's emailed replies or instructions. This proposal will use computational linguistics to examine how diabetes patients with a variety of health literacy levels interact with their clinicians via patient portals, will explore whether linguistic gaps between patients and clinicians are associated with diabetes outcomes, and will create a feedback tool to assist clinicians to better accommodate diabetes patients' communication needs.",The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging,9146397,R01LM012355,"['Adherence', 'Advocate', 'Antidepressive Agents', 'Caring', 'Clinical', 'Communication', 'Computational Linguistics', 'Computer software', 'County', 'Data', 'Diabetes Mellitus', 'Electronic Health Record', 'Electronic Mail', 'Face', 'Feedback', 'Glycosylated hemoglobin A', 'Health', 'Health Communication', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hypoglycemia', 'In Vitro', 'Individual', 'Information Services', 'Institute of Medicine (U.S.)', 'Instruction', 'Insulin', 'Internet', 'Linguistics', 'Measures', 'Mediator of activation protein', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Primary Health Care', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Randomized Controlled Trials', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Secure', 'Series', 'System', 'Technical Expertise', 'Testing', 'Time', 'Visit', 'Writing', 'arm', 'base', 'communication aid', 'critical period', 'design', 'ethnic diversity', 'frontier', 'health care delivery', 'health care service utilization', 'health literacy', 'improved', 'literate', 'meetings', 'novel', 'profiles in patients', 'prototype', 'research study', 'response', 'safety net', 'service utilization', 'simulation', 'skills', 'tool', 'uptake']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2016,628346,0.03648978808258806
"The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging     DESCRIPTION (provided by applicant): Limited health literacy (HL) places individuals at greater risk of type 2 diabetes (DM2) and its complications, is a marker of vulnerability, and presents a critical clinical and public health problem. To be health literate in the 21st century, patients will need a certain level of linguistic facility, in combination with technical skills, to access services via online patient portals. Our research has shown that DM2 patients with limited HL are actively using patient portals. However, as healthcare becomes increasingly dependent on electronic communications (e.g., secure messages via internet-based patient portals), patients with limited HL may have difficulty communicating electronically with their clinician or understanding their clinician's secure message responses or instructions. For clinicians to electronically provide meaningful and actionable information and support, their secure messages must be written in an easily comprehended style. Few studies have examined how patients with limited HL interact with their healthcare providers via patient portals. This trans-disciplinary proposal, involving a team of health services researchers, health communication scientists, and computational linguists, will focus on a population of ethnically diverse DM2 patients and their primary care providers from 1) a large, integrated group model HMO with a well-developed patient portal and 2) a county-run, integrated public (safety net) delivery system with a newly launched electronic health record and patient portal. Our study is designed around a conceptual framework promoted most recently by the Institute of Medicine: overcoming the challenges LHL patients face in managing DM2 requires that healthcare systems, and their clinicians, make accommodations to meet patients' communication needs. The degree of linguistic ""mismatch"" observed in secure message exchanges between DM2 patients and their providers, measured using computational linguistics, will serve as one indicator of the extent to which providers are, or are not, making such accommodations. Our specific aims are to (Aim 1) develop and validate a novel, automated linguistic complexity profile (LCP) to assess secure message content generated by DM2 patients and their providers via patient portals. We will employ natural language processing (NLP) to develop and validate the LCP, based on secure messages and data from >200,000 DM2 patients. The LCP will demonstrate construct validity with patient HL and patient reports of provider communication, and will be associated with DM2 outcomes; (Aim 2) examine whether concordance between provider and patient LCP is associated with adherence among DM2 patients newly prescribed insulin or antidepressants; (Aim 3) characterize the collaborative nature of exchanges between providers and low LCP patients, using mixed methods, to enhance our understanding of communication in the critical period surrounding initiation of insulin or antidepressants; (Aim 4) create an automated, LCP-based prototype to provide real-time feedback to providers while writing secure messages to reduce linguistic complexity and better accommodate DM2 patients' linguistic skills and HL.    PUBLIC HEALTH RELEVANCE: Limited health literacy places individuals at greater risk of type 2 diabetes and its complications, making limited health literacy a critical clinical and publi health problem. As healthcare becomes increasingly dependent on electronic communications, patients with limited health literacy may have difficulty communicating by email with their clinician or understanding the clinician's emailed replies or instructions. This proposal will use computational linguistics to examine how diabetes patients with a variety of health literacy levels interact with their clinicians via patient portals, will explore whether linguistic gaps between patients and clinicians are associated with diabetes outcomes, and will create a feedback tool to assist clinicians to better accommodate diabetes patients' communication needs.   ",The Next Frontier in Diabetes Communication: Promoting Health Literacy in the Era of Secure Messaging,9028433,R01LM012355,"['Adherence', 'Advocate', 'Antidepressive Agents', 'Caring', 'Clinical', 'Communication', 'Computational Linguistics', 'Computer software', 'County', 'Data', 'Diabetes Mellitus', 'Electronic Health Record', 'Electronic Mail', 'Electronics', 'Face', 'Feedback', 'Glycosylated hemoglobin A', 'Health', 'Health Communication', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hypoglycemia', 'In Vitro', 'Individual', 'Information Services', 'Institute of Medicine (U.S.)', 'Instruction', 'Insulin', 'Internet', 'Linguistics', 'Measures', 'Mediator of activation protein', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Population', 'Primary Health Care', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Randomized Controlled Trials', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Secure', 'Series', 'System', 'Testing', 'Time', 'Visit', 'Writing', 'arm', 'base', 'communication aid', 'critical period', 'design', 'frontier', 'health care delivery', 'health care service utilization', 'health literacy', 'improved', 'literate', 'meetings', 'novel', 'prototype', 'public health relevance', 'research study', 'response', 'safety net', 'service utilization', 'simulation', 'skills', 'tool', 'uptake']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2015,673033,0.03648978808258806
"Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare Project Summary As United States healthcare seeks to address inconsistent quality and overwhelming cost, data and technology have become central to all suggested approaches. With newly available electronic health data and massive growth in processing power, the hardest challenges in using clinical data are becoming clear. Big data holds the potential to enable personalized patient care, population health management, and value-based payment models. However, it also creates challenges in discriminating accurate data from inaccurate or incomplete information. One of the greatest areas of data inaccuracy is the patient phenotype, or clinical description of the patient. Every clinical decision support tool, population health management system, and payment reform product relies on accurate electronic patient descriptions as its source data. But, the descriptions are not accurate, most notably in terms of completeness and granularity. Recall often falls below 50% in describing a patients medical conditions, such as heart failure and cancer. Detailed descriptions such as low ejection fraction heart failure or stage III breast cancer, needed for downstream analytics, are lacking in the discrete record. Poor data puts care delivery, payment reform, and population health efforts in peril. The time is right for technology to proactively define the clinical phenotype from source data, without reliance on current manual approaches. This will necessitate overcoming challenges in harmonizing discrepant narrative and discrete data, inferring when a characteristic such as cough is a primary condition versus symptom of another condition, and screening noise from signal in robust narrative text. This Small Business Innovation Research (SBIR) Phase I project will include the following specific aims: 1. Create the components required to define an accurate and comprehensive clinical phenotype,  including: (i) extract problem, medication, procedure, and lab features from clinical data using  natural language processing (NLP) and ontologic mapping, (ii) build a large knowledge database  of associated clinical conditions, and (iii) assess extracted features against the knowledge  database to accurately distinguish symptoms from diseases and surface relevant active diseases  in a candidate problem list. 2. Validate the clinical phenotyping components using de-identified longitudinal clinical data for  10,000 patients The goal, dependent on Phase I success, is to create an automated, accurate, and robust clinical phenotyping engine to enable personalized patient care, population health management, and value- based payment models. Project Narrative Individual and global care improvement demands accurate phenotypes. This type of clinical phenotyping is extremely challenging, requiring full clinical data and advanced semantic technologies to develop a longitudinal patient map. The approach, if successful, offers an opportunity to empower national efforts to improve outcomes and reduce costs.",Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare,9199039,R43LM012357,"['Address', 'Area', 'Back', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Congresses', 'Coughing', 'Data', 'Data Sources', 'Databases', 'Disease', 'EFRAC', 'Electronics', 'Funding', 'Goals', 'Government', 'Growth', 'Health system', 'Healthcare', 'Heart failure', 'Individual', 'Industry', 'Investments', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Medical', 'Medical Technology', 'Modeling', 'Natural Language Processing', 'Noise', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Principal Investigator', 'Procedures', 'Process', 'Review Literature', 'Semantics', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Staging', 'Surface', 'Symptoms', 'System', 'Technology', 'Text', 'Time', 'United States', 'Work', 'base', 'care delivery', 'clinical phenotype', 'clinical practice', 'cost', 'discrete data', 'empowered', 'experience', 'falls', 'health data', 'high risk', 'improved', 'improved outcome', 'malignant breast neoplasm', 'payment', 'personalized care', 'population health', 'screening', 'success', 'support tools']",NLM,"VMT, INC.",R43,2016,222977,-0.0007280477080010186
"Uncovering Clinical Evidence in COVID-19 Publications: An Integrated Search via Text & Images Project Summary: Uncovering clinical evidence in COVID19 publications: An integrated search via text & images The proposed research aims to develop and advance tools for using image-data appearing in scientific publications, in addition to text, in order to expedite effective access to COVID-19 published information. Current efforts aiming to address the COVID-19 pandemic include devising treatment, understanding virus mechanisms, detecting infection and antibodies, and ultimately  developing a vaccine. All these efforts require effective access to biomedical information related to the virus. The Allen Institute has recently released the CORD-19 dataset  a large, continually updated collection of scientific literature pertaining to COVID-19 and Corona viruses. This dataset comprises tens of thousands full text articles, forming a basis for text-mining tools that will support access to information pertaining to COVID-19. Notably, much of the evidence within these publications is provided in the form of figures. Furthermore, regions where such evidential images occur are rich in information. While biomedical text-based mining tools are being quickly developed and offered for accessing this dataset, images, which contain key clinical and biological information, are not considered. Even outside the COVID-19 realm, little has been done so far to utilize images within publications, despite the fact that they provide important cues about the relevance of the information embedded in articles. Our premise, which is supported by our own and by other informaticians and clinicians experience, is that information derived from images can (and should) be directly incorporated into the biomedical  and specifically into the COVID-19  document retrieval and extraction. Doing so will improve accurate access to relevant articles, while pin-pointing significant evidence within them, and expediting access to much-needed critical information. The work on this project will result in methods and tools that take advantage of both image- and text-data, facilitating more effective and focused retrieval and mining, thus better supporting speedy data- intensive discovery in the context of COVID-19. Project Narrative: Uncovering clinical evidence in COVID19 publications: An integrated search via text & images Researchers and physicians looking to understand, treat and ultimately cure and vaccinate against the elusive and devastating COVID19, must search through vast amounts of published biomedical information. The proposed research aims to support and speed-up the search while improving effective access to the most relevant part of the COVID19 literature, by creating a tool that utilizes and searches for the highly-informative image data within publications. The successful outcome of this work will provide a well-targeted, effective search engine for finding information pertinent to the medical and research needs of scientists and physicians working to address COVID19, thus expediting discovery, and revealing potential complications, and their causes and their likely treatment.",Uncovering Clinical Evidence in COVID-19 Publications: An Integrated Search via Text & Images,10177479,R01LM012527,"['Access to Information', 'Address', 'Administrative Supplement', 'Antibodies', 'Biological', 'Biomedical Research', 'Blood', 'COVID-19', 'COVID-19 pandemic', 'Classification', 'Clinical', 'Collection', 'Computer Analysis', 'Coronavirus', 'Cues', 'Data', 'Data Set', 'Detection', 'Disease', 'Drug Targeting', 'Funding', 'Goals', 'Graph', 'Harvest', 'Image', 'Image Analysis', 'Image retrieval system', 'Individual', 'Infection', 'Information Retrieval', 'Institutes', 'Literature', 'Lung', 'MRI Scans', 'Medical Research', 'Methods', 'Mining', 'Modality', 'Molecular', 'Outcome', 'Oxygen', 'Physicians', 'Positioning Attribute', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Roentgen Rays', 'Scientist', 'Speed', 'System', 'Testing', 'Text', 'Update', 'Vaccinated', 'Vaccines', 'Virus', 'Visual', 'Visualization', 'Visualization software', 'Work', 'X-Ray Computed Tomography', 'base', 'experience', 'improved', 'indexing', 'information display', 'interest', 'microscopic imaging', 'search engine', 'text searching', 'therapy development', 'three dimensional structure', 'tool', 'vaccine development', 'visual search']",NLM,UNIVERSITY OF DELAWARE,R01,2020,74999,-0.00903541802227681
"Improved Disease Stratification Using Electronic Health Records ABSTRACT This Career Development Application describes targeted coursework and mentored research for progression to independent research in the use of electronic health record data for disease subtyping. Electronic health records have demonstrated great promise as a scalable source of data for biomedical research to enable precision medicine. Use of natural language processing techniques has enabled computational analysis of specific terms found in free text clinical notes. An improved ability to extract symptom information from clinical notes would improve researchers ability to use de-identified data from patient records for discovery of disease subtypes. Symptom-related terms are particularly important in the context of mental health, but also harder to detect in notes than other terms like diseases or drug names.  The research aims of this proposal present a novel approach to scalable extension of biomedical terminologies and improved detection of those terms and their modifiers (e.g. severe, familial, absent). The richer dataset that can be extracted using these enhanced approaches is then used to define patient cohorts and to detect disease subtypes and predictors of response to specific pharmaceutical intervention.  Resulting patient stratification will be compared to groupings made without the enriched data and validated on an independent data set. The overarching hypothesis of this work is that enhanced mining of clinical notes will enable statistically significant and clinically relevant symptom-based stratification of psychiatric disorders. In order to test this hypothesis, I will: Aim 1: Develop a semi-automated pipeline for domain-specific terminology extension Aim 2: Define and stratify patient cohorts through use of enhanced term extraction Aim 3: Evaluate the validity and utility of the richer set of data obtained through Aims 1 and 2  One area of greatest need for more evidence-based disease stratification, and also of greatest challenge for a number of reasons, is that of mental health. Mental health disorders account for 30% of non-fatal disease burden world-wide, and pose an economic burden of trillions of dollars and climbing. Moreover, mental health symptoms are generally subjective and self-reported, with few objectively measurable signs. The impact of this proposal is that it will dramatically improve our ability to use EHR data to stratify patients in this drastically underserved area of health and healthcare.  The major innovations of this project are the adaptation and application of a semi-supervised pattern learning pipeline to augment mental health terminologies, and a novel approach to disease stratification using a significantly underutilized source of biomedical data, namely clinical notes.  This work addresses a major challenge for mining clinical notes in rapidly evolving biomedical domains and leverages a valuable source of medical evidence that is largely untapped and underutilized. Together, these methods for enhanced use of clinical notes will enable identification of distinct patient subgroups using data that is sitting idle in EHRs. Project Narrative Electronic health records have demonstrated great promise as a scalable source of data for biomedical research to enable precision medicine. Natural language processing has enabled the use of information from clinical notes in addition to structured data like diagnoses and lab values. This work aims to improve our ability to extract useful information from electronic health records to enable disease subtyping, particularly in the area of mental health.",Improved Disease Stratification Using Electronic Health Records,9566983,K01LM012529,"['Address', 'Area', 'Biological', 'Biomedical Research', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease stratification', 'Economic Burden', 'Electrocardiogram', 'Electronic Health Record', 'Genotype', 'Grouping', 'Health', 'Healthcare', 'Intervention', 'Learning', 'Measurable', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Methods', 'Mining', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Self-Report', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phenotype', 'Records', 'Research', 'Research Personnel', 'Rheumatology', 'Severities', 'Source', 'Statistical Models', 'Stratification', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Terminology', 'Testing', 'Text', 'Work', 'base', 'burden of illness', 'career development', 'clinical decision-making', 'clinically actionable', 'clinically relevant', 'cohort', 'disease classification', 'disorder subtype', 'electronic data', 'evidence base', 'improved', 'innovation', 'novel strategies', 'patient stratification', 'patient subsets', 'phenotypic data', 'precision medicine', 'predicting response', 'response', 'treatment response']",NLM,DUKE UNIVERSITY,K01,2018,187483,0.004988646789740975
"Improved Disease Stratification Using Electronic Health Records ABSTRACT This Career Development Application describes targeted coursework and mentored research for progression to independent research in the use of electronic health record data for disease subtyping. Electronic health records have demonstrated great promise as a scalable source of data for biomedical research to enable precision medicine. Use of natural language processing techniques has enabled computational analysis of specific terms found in free text clinical notes. An improved ability to extract symptom information from clinical notes would improve researchers ability to use de-identified data from patient records for discovery of disease subtypes. Symptom-related terms are particularly important in the context of mental health, but also harder to detect in notes than other terms like diseases or drug names.  The research aims of this proposal present a novel approach to scalable extension of biomedical terminologies and improved detection of those terms and their modifiers (e.g. severe, familial, absent). The richer dataset that can be extracted using these enhanced approaches is then used to define patient cohorts and to detect disease subtypes and predictors of response to specific pharmaceutical intervention.  Resulting patient stratification will be compared to groupings made without the enriched data and validated on an independent data set. The overarching hypothesis of this work is that enhanced mining of clinical notes will enable statistically significant and clinically relevant symptom-based stratification of psychiatric disorders. In order to test this hypothesis, I will: Aim 1: Develop a semi-automated pipeline for domain-specific terminology extension Aim 2: Define and stratify patient cohorts through use of enhanced term extraction Aim 3: Evaluate the validity and utility of the richer set of data obtained through Aims 1 and 2  One area of greatest need for more evidence-based disease stratification, and also of greatest challenge for a number of reasons, is that of mental health. Mental health disorders account for 30% of non-fatal disease burden world-wide, and pose an economic burden of trillions of dollars and climbing. Moreover, mental health symptoms are generally subjective and self-reported, with few objectively measurable signs. The impact of this proposal is that it will dramatically improve our ability to use EHR data to stratify patients in this drastically underserved area of health and healthcare.  The major innovations of this project are the adaptation and application of a semi-supervised pattern learning pipeline to augment mental health terminologies, and a novel approach to disease stratification using a significantly underutilized source of biomedical data, namely clinical notes.  This work addresses a major challenge for mining clinical notes in rapidly evolving biomedical domains and leverages a valuable source of medical evidence that is largely untapped and underutilized. Together, these methods for enhanced use of clinical notes will enable identification of distinct patient subgroups using data that is sitting idle in EHRs. Project Narrative Electronic health records have demonstrated great promise as a scalable source of data for biomedical research to enable precision medicine. Natural language processing has enabled the use of information from clinical notes in addition to structured data like diagnoses and lab values. This work aims to improve our ability to extract useful information from electronic health records to enable disease subtyping, particularly in the area of mental health.",Improved Disease Stratification Using Electronic Health Records,9453180,K01LM012529,"['Address', 'Area', 'Biological', 'Biomedical Research', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computer Analysis', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease stratification', 'Economic Burden', 'Electrocardiogram', 'Electronic Health Record', 'Genotype', 'Grouping', 'Health', 'Healthcare', 'Intervention', 'Learning', 'Measurable', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Methods', 'Mining', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Self-Report', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phenotype', 'Records', 'Research', 'Research Personnel', 'Rheumatology', 'Severities', 'Source', 'Statistical Models', 'Stratification', 'Structure', 'Subgroup', 'Supervision', 'Symptoms', 'Techniques', 'Terminology', 'Testing', 'Text', 'Work', 'base', 'burden of illness', 'career development', 'clinical decision-making', 'clinically actionable', 'clinically relevant', 'cohort', 'disease classification', 'disorder subtype', 'electronic data', 'evidence base', 'improved', 'innovation', 'novel strategies', 'patient stratification', 'phenotypic data', 'precision medicine', 'predicting response', 'response', 'treatment response']",NLM,DUKE UNIVERSITY,K01,2017,189054,0.004988646789740975
"Bayesian Generative Methods for Extracting and Modeling Relations in EHR Narratives Project Summary Medicine has evolved into an era where the entire hospital progressively adopts more real-time monitoring for the patients and generates ICU like clinical data. The rapidly growing data makes ICU a snapshot for tomorrows standard of care that should benefit from computer-aided decision making. These data contain not only numerical or coded information, but also a large volume of unstructured narrative text such as physicians and nurses' notes, specialists' reports, and discharge summaries. Both types of data have been shown to be highly informative for tasks such as cohort selection, and work best in combination. However, to achieve this, specific bits of information must be extracted from the narrative reports and coded in formal representation. These bits include medical concepts such as symptoms, diseases, medications and procedures; characteristics such as certainty, severity, dose; assertions about these items, such as whether they pertain to the patient or a family member, etc.; relations among these mentions, including indications of what condition is treated by what action and its degree of success, the time sequence and duration of events, and interpretations of laboratory test results as relations among medical concepts such as cells and antigens (e.g., [large atypical cells] express [CD30]). Concepts and assertions can be regarded as simple relations, and our proposal focuses on modeling narrative relations to augment structured data for predicting patient outcomes. Most existing techniques for interpreting clinical narratives either rely on hand-crafted rule systems and large medical thesauri or are based on machine learning models that create classification or regression models from large annotated data sets. The former are difficult and laborious to generalize, whereas the latter require large volumes of human-labeled data and may result in models whose operation is difficult to interpret and is therefore considered unsuitable for computer-aided decision making. We propose to build on our previous work to use unsupervised learning methods that identify frequent patterns in un-annotated narratives and identify informative patterns by tensor factorization. Although existing methods can also identify patterns that are meaningful in a data-driven sense, these patterns are difficult for clinicians to understand. Our specific goal is to develop a novel method that uses a Bayesian generative model that integrates relation mining with tensor factorization to learn patterns that correspond to an understanding of the clinical domain and can be used for evidence based patient outcome prediction. Our framework represents relations in clinical narratives as graphs, then mines subgraphs for important relations. These relations are used as features in building up a tensor model in order to reduce dimensionality, discover coherent groups of relations, and explore the group interactions. We develop Bayesian formulation to integrate relation mining and tensor modeling in a generative model, to incorporate existing medical knowledge as probability priors, as well as to reliably estimate the posterior probabilities and confidence intervals of any findings from the model. Rapid growth in the hospital adoption of large volume of Electronic Health Records (EHRs) has led to an unprecedented availability of narrative dataset for clinical and translational research. We propose the development of a novel Bayesian generative framework to enable extraction of accurate and clinically meaningful patterns of EHR narratives in order to support evidence based diagnostic reasoning and outcome risk prediction.",Bayesian Generative Methods for Extracting and Modeling Relations in EHR Narratives,9535479,R21LM012618,"['Admission activity', 'Adopted', 'Adoption', 'Algorithms', 'Antigens', 'Appearance', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Cognitive', 'Computer Assisted', 'Confidence Intervals', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Dose', 'Electronic Health Record', 'Event', 'Family member', 'Formulation', 'Goals', 'Graph', 'Hand', 'Hodgkin Disease', 'Hospitals', 'Human', 'Individual', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Lymphoma', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Morphology', 'National Research Council', 'Nurses', 'Outcome', 'Output', 'Pathology Report', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Probability', 'Procedures', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Severities', 'Source', 'Specialist', 'Structure', 'Symptoms', 'System', 'TNFRSF8 gene', 'Techniques', 'Test Result', 'Text', 'Thesauri', 'Time', 'To specify', 'Translational Research', 'Work', 'adverse outcome', 'base', 'clinical decision support', 'cohort', 'data warehouse', 'diagnostic panel', 'evidence base', 'improved', 'learning strategy', 'mortality', 'novel', 'operation', 'outcome prediction', 'patient oriented', 'rapid growth', 'real time monitoring', 'standard of care', 'success', 'unsupervised learning']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2018,181755,0.04636487448094566
"Bayesian Generative Methods for Extracting and Modeling Relations in EHR Narratives Project Summary Medicine has evolved into an era where the entire hospital progressively adopts more real-time monitoring for the patients and generates ICU like clinical data. The rapidly growing data makes ICU a snapshot for tomorrows standard of care that should benefit from computer-aided decision making. These data contain not only numerical or coded information, but also a large volume of unstructured narrative text such as physicians and nurses' notes, specialists' reports, and discharge summaries. Both types of data have been shown to be highly informative for tasks such as cohort selection, and work best in combination. However, to achieve this, specific bits of information must be extracted from the narrative reports and coded in formal representation. These bits include medical concepts such as symptoms, diseases, medications and procedures; characteristics such as certainty, severity, dose; assertions about these items, such as whether they pertain to the patient or a family member, etc.; relations among these mentions, including indications of what condition is treated by what action and its degree of success, the time sequence and duration of events, and interpretations of laboratory test results as relations among medical concepts such as cells and antigens (e.g., [large atypical cells] express [CD30]). Concepts and assertions can be regarded as simple relations, and our proposal focuses on modeling narrative relations to augment structured data for predicting patient outcomes. Most existing techniques for interpreting clinical narratives either rely on hand-crafted rule systems and large medical thesauri or are based on machine learning models that create classification or regression models from large annotated data sets. The former are difficult and laborious to generalize, whereas the latter require large volumes of human-labeled data and may result in models whose operation is difficult to interpret and is therefore considered unsuitable for computer-aided decision making. We propose to build on our previous work to use unsupervised learning methods that identify frequent patterns in un-annotated narratives and identify informative patterns by tensor factorization. Although existing methods can also identify patterns that are meaningful in a data-driven sense, these patterns are difficult for clinicians to understand. Our specific goal is to develop a novel method that uses a Bayesian generative model that integrates relation mining with tensor factorization to learn patterns that correspond to an understanding of the clinical domain and can be used for evidence based patient outcome prediction. Our framework represents relations in clinical narratives as graphs, then mines subgraphs for important relations. These relations are used as features in building up a tensor model in order to reduce dimensionality, discover coherent groups of relations, and explore the group interactions. We develop Bayesian formulation to integrate relation mining and tensor modeling in a generative model, to incorporate existing medical knowledge as probability priors, as well as to reliably estimate the posterior probabilities and confidence intervals of any findings from the model. Rapid growth in the hospital adoption of large volume of Electronic Health Records (EHRs) has led to an unprecedented availability of narrative dataset for clinical and translational research. We propose the development of a novel Bayesian generative framework to enable extraction of accurate and clinically meaningful patterns of EHR narratives in order to support evidence based diagnostic reasoning and outcome risk prediction.",Bayesian Generative Methods for Extracting and Modeling Relations in EHR Narratives,9374626,R21LM012618,"['Admission activity', 'Adopted', 'Adoption', 'Algorithms', 'Antigens', 'Appearance', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Cognitive', 'Computer Assisted', 'Confidence Intervals', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Dose', 'Electronic Health Record', 'Event', 'Family member', 'Formulation', 'Goals', 'Graph', 'Hand', 'Hodgkin Disease', 'Hospitals', 'Human', 'Individual', 'Injectable', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Lymphoma', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Morphology', 'National Research Council', 'Nurses', 'Outcome', 'Output', 'Pathology Report', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Probability', 'Procedures', 'Reporting', 'Research', 'Risk', 'Risk Factors', 'Severities', 'Source', 'Specialist', 'Structure', 'Symptoms', 'System', 'TNFRSF8 gene', 'Techniques', 'Test Result', 'Text', 'Thesauri', 'Time', 'To specify', 'Translational Research', 'Work', 'adverse outcome', 'base', 'cohort', 'diagnostic panel', 'evidence base', 'improved', 'learning strategy', 'mortality', 'novel', 'operation', 'outcome prediction', 'patient oriented', 'rapid growth', 'standard of care', 'success']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2017,208272,0.04636487448094566
"Improving Specialty Care Delivery in the Safety Net with Natural Language Processing Project Summary  Safety net providers treat a substantial share of socioeconomically vulnerable patients in their communities, but struggle to provide timely access to high quality specialty care for their patients. Delayed access to specialty care is associated with worse health outcomes and potentially contributes to health disparities across socioeconomic groups. Given their limited resources, safety net providers must seek creative approaches to improve specialty access. However, to choose what programs to implement, safety net providers need to understand the specialty care needs of their populations. Fortunately, the adoption of eConsult systems by safety net providers across the US provides a valuable opportunity to systematically measure patterns of specialty care referrals for minority, underserved populations.  In this project, we propose using state-of-the-art methods in machine learning and natural language processing (NLP) to help safety net providers extract actionable, population wide data from their electronic consultation systems. We will do this in partnership with three of the most prominent safety net health systems in the US in Los Angeles, San Francisco and New York City. Using specialty request databases from our collaborators, we will build NLP systems to automatically classify specialty requests along two dimensions: the clinical issue motivating the request (e.g., chest pain), and the question type (e.g., request for a procedure, help with medication management). This automated classification of electronic specialty requests can enable identification of promising targets for interventions to improve specialty access and quality of care.  After developing these NLP systems, we will analyze >1 million specialty requests to describe trends in how safety net patients are referred to specialists and examine variation in referral patterns by clinic and individual provider. The goal is to identify the most impactful opportunities to improve specialty access and quality. For example, a high rate of referrals for esophageal reflux, which most PCPs can treat on their own with specialist guidance, could lead to new treatment algorithms, potentially reducing the need for these requests and improving access for other patients.  This proposal is a high-risk high-reward project that creates new research tools to identify and evaluate data-driven interventions to improve specialty care delivery for underserved populations. Project Narrative Access to timely, high-quality specialty care is a fundamental component of a well-functioning health system, yet safety net health care providers face persistent challenges delivering such care. Quality improvement efforts to improve specialty access have been thwarted in part because safety net providers lack the data to understand a basic question  why patients are referred for specialty care. Taking advantage of the growing use of electronic specialty referral systems by safety net providers, we propose using natural language processing to conduct automated analysis and classification of specialty requests in safety net populations, which will enable the design of targeted interventions to improve specialty care access and delivery.",Improving Specialty Care Delivery in the Safety Net with Natural Language Processing,9789060,R21MD012693,"['Acute', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Chest Pain', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Consultations', 'County', 'Data', 'Data Set', 'Databases', 'Education', 'Epidemiology', 'Face', 'Federally Qualified Health Center', 'Gastroesophageal reflux disease', 'Goals', 'Health', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Heart failure', 'Hospitals', 'Improve Access', 'Individual', 'Intervention', 'Lead', 'Los Angeles', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Education', 'Medical center', 'Medication Management', 'Methods', 'Minority', 'Morbidity - disease rate', 'Natural Language Processing', 'New York City', 'Online Systems', 'Ophthalmology', 'Outcome', 'Patients', 'Pattern', 'Play', 'Population', 'Primary Care Physician', 'Procedures', 'Provider', 'Public Hospitals', 'Quality of Care', 'Research', 'Resources', 'Retinal Diseases', 'Role', 'San Francisco', 'Specialist', 'System', 'Taxonomy', 'Telemedicine', 'Text', 'Time', 'Transplantation', 'Triage', 'Underserved Population', 'Variant', 'Visit', 'automated analysis', 'care delivery', 'design', 'diabetic', 'disease classification', 'ethnic minority population', 'follow-up', 'health disparity', 'high reward', 'high risk', 'improved', 'medical specialties', 'medically underserved', 'minority communities', 'mortality', 'performance tests', 'programs', 'racial and ethnic', 'safety net', 'screening', 'socioeconomic disadvantage', 'socioeconomics', 'tool', 'trend', 'two-dimensional']",NIMHD,BOSTON CHILDREN'S HOSPITAL,R21,2019,94263,0.04501488835713529
"Improving Specialty Care Delivery in the Safety Net with Natural Language Processing Project Summary  Safety net providers treat a substantial share of socioeconomically vulnerable patients in their communities, but struggle to provide timely access to high quality specialty care for their patients. Delayed access to specialty care is associated with worse health outcomes and potentially contributes to health disparities across socioeconomic groups. Given their limited resources, safety net providers must seek creative approaches to improve specialty access. However, to choose what programs to implement, safety net providers need to understand the specialty care needs of their populations. Fortunately, the adoption of eConsult systems by safety net providers across the US provides a valuable opportunity to systematically measure patterns of specialty care referrals for minority, underserved populations.  In this project, we propose using state-of-the-art methods in machine learning and natural language processing (NLP) to help safety net providers extract actionable, population wide data from their electronic consultation systems. We will do this in partnership with three of the most prominent safety net health systems in the US in Los Angeles, San Francisco and New York City. Using specialty request databases from our collaborators, we will build NLP systems to automatically classify specialty requests along two dimensions: the clinical issue motivating the request (e.g., chest pain), and the question type (e.g., request for a procedure, help with medication management). This automated classification of electronic specialty requests can enable identification of promising targets for interventions to improve specialty access and quality of care.  After developing these NLP systems, we will analyze >1 million specialty requests to describe trends in how safety net patients are referred to specialists and examine variation in referral patterns by clinic and individual provider. The goal is to identify the most impactful opportunities to improve specialty access and quality. For example, a high rate of referrals for esophageal reflux, which most PCPs can treat on their own with specialist guidance, could lead to new treatment algorithms, potentially reducing the need for these requests and improving access for other patients.  This proposal is a high-risk high-reward project that creates new research tools to identify and evaluate data-driven interventions to improve specialty care delivery for underserved populations. Project Narrative Access to timely, high-quality specialty care is a fundamental component of a well-functioning health system, yet safety net health care providers face persistent challenges delivering such care. Quality improvement efforts to improve specialty access have been thwarted in part because safety net providers lack the data to understand a basic question  why patients are referred for specialty care. Taking advantage of the growing use of electronic specialty referral systems by safety net providers, we propose using natural language processing to conduct automated analysis and classification of specialty requests in safety net populations, which will enable the design of targeted interventions to improve specialty care access and delivery.",Improving Specialty Care Delivery in the Safety Net with Natural Language Processing,9600732,R21MD012693,"['Acute', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Chest Pain', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Consultations', 'County', 'Data', 'Data Set', 'Databases', 'Education', 'Epidemiology', 'Face', 'Federally Qualified Health Center', 'Gastroesophageal reflux disease', 'Goals', 'Health', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Heart failure', 'Hospitals', 'Improve Access', 'Individual', 'Intervention', 'Lead', 'Los Angeles', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Education', 'Medical center', 'Medication Management', 'Methods', 'Minority', 'Morbidity - disease rate', 'Natural Language Processing', 'New York City', 'Online Systems', 'Ophthalmology', 'Outcome', 'Patients', 'Pattern', 'Play', 'Population', 'Primary Care Physician', 'Procedures', 'Provider', 'Public Hospitals', 'Quality of Care', 'Research', 'Resources', 'Retinal Diseases', 'Role', 'San Francisco', 'Specialist', 'System', 'Taxonomy', 'Telemedicine', 'Text', 'Time', 'Transplantation', 'Triage', 'Underserved Population', 'Variant', 'Visit', 'care delivery', 'design', 'diabetic', 'disease classification', 'ethnic minority population', 'follow-up', 'health disparity', 'high reward', 'high risk', 'improved', 'medical specialties', 'medically underserved', 'minority communities', 'mortality', 'performance tests', 'programs', 'racial and ethnic', 'safety net', 'screening', 'socioeconomic disadvantage', 'socioeconomics', 'tool', 'trend', 'two-dimensional']",NIMHD,BOSTON CHILDREN'S HOSPITAL,R21,2018,278902,0.04501488835713529
"Enabling value-based healthcare through automating risk assessment for episode-based care Project Summary Value-based healthcare implementation relies on understanding risk. 1 Early models, such as Medicare Advantage, use annual measures of risk under a risk adjustment factor (RAF) to offer financial incentive to payers and hospitals to work together. 2 More advanced models, such as bundled payments, target the periods of greatest quality variability, specifically episodes of care such as joint replacement, oncology diagnosis, and cardiac procedures. In these episodes, many types of providers, from hospitals to outpatient physical therapists, need to work together to reduce rates of complication and readmission. Risk levels are used to adjust payment for payer and providers and to determine which patients require additional resources in the hospital, clinic, or home. Unfortunately, existing risk models lack key features needed for episode-based care, which requires both financial alignment and accurate and immediate information to adjust clinical resources for a given case. 3 4 A better model would include all conditions relevant to an episode rather than just chronic conditions, addition of social determinants, and an automated approach to retrieve the information in hours rather than months. Thus, this Small Business Innovation Research (SBIR) Phase I program includes the following Specific Aims: 1. Create the phenotyping components required to define an accurate and comprehensive model  of episode-based risk, including: (i) extract clinical and social features from clinical data using  natural language processing (NLP), (ii) map concepts including social features to an ontology  that will support normalized data use, (iii) build a feature vector for each record that can be  used to feed a risk model that accounts for relevant clinical and social risk 2. Validate the phenotyping components using de-identified longitudinal clinical data for 10,000 patients In this research program, Phase I will tackle the most difficult challenges, including leveraging narrative text to recognize time-labeled social and clinical features influencing an episode of care. Success criteria will be accurate recognition of key underlying features that have not been available in risk models to date. Phase II will build upon the validated technology to create an episode-based risk model run on narrative and discrete clinical data and tested against actual patient outcomes. Success criteria will be a validated episode-based risk model to support value-based contracting and value-based clinical care. Project Narrative Advanced payment models in United States healthcare rely on accurate assessment of risk and quality. While quality has gained broad attention, risk models remain outdated and poorly suited to advanced payment models. CapsicoHealth proposes an effort to redefine risk models used for episode-based payments, using data sets across the continuum of care and clinical and social determinants of care that have previously been unavailable in computable form. If successful, this effort will impact financial and clinical approaches to value-based healthcare and significantly increase the chance that national efforts to improve cost and quality will be effective.",Enabling value-based healthcare through automating risk assessment for episode-based care,9464424,R43LM012798,"['Attention', 'Cardiac', 'Caring', 'Chronic', 'Clinic', 'Clinical', 'Clinical Data', 'Complication', 'Continuity of Patient Care', 'Contracts', 'Cost Control', 'Data', 'Data Collection', 'Data Quality', 'Data Set', 'Diagnosis', 'Foundations', 'Goals', 'Health Care Reform', 'Healthcare', 'Healthcare Systems', 'Home environment', 'Hospitals', 'Hour', 'Insurance', 'Label', 'Measurement', 'Measures', 'Medicare', 'Modeling', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Provider', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Adjustment', 'Risk Assessment', 'Running', 'Small Business Innovation Research Grant', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'Work', 'base', 'care episode', 'clinical care', 'clinically relevant', 'concept mapping', 'cost', 'feeding', 'financial incentive', 'improved', 'interest', 'oncology', 'payment', 'physical therapist', 'programs', 'social', 'success', 'vector']",NLM,"CAPSICOHEALTH, INC.",R43,2017,222588,0.025115464669795202
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9925807,R01LM012817,"['Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'comorbidity', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2020,335875,0.052037301688022966
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9794757,R01LM012817,"['Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Comorbidity', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,337238,0.052037301688022966
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9670540,R01LM012817,"['AIDS education', 'Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Comorbidity', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,370291,0.052037301688022966
"Developing data tools to reduce CVD disparities via Health Information Exchanges ABSTRACT CVD disparities across the race/ethnic and socioeconomic gradients are exacerbated by barriers to receiving guideline-based primary or secondary preventive treatmentsuch as appropriate blood pressure, dyslipidemia, and type 2 diabetes treatment.16 Most patients not receiving guideline-based treatment are actually insured and have seen a primary care provider in the past year.1 To reduce CVD disparities by better targeting disease prevention and treatment, healthcare administrators and county departments of public health have begun pooling data resources across healthcare and public health systemssuch as across clinics, emergency rooms and hospitals, pharmacies, laboratories, and administrative datasets.79 The idea behind pooling such datasets is to better identify persons most in need, and direct targeted interventions to them. Solano County, California, a medium-sized, diverse, low-income county, has developed one of the first, and most comprehensive health information exchanges (HIEs), including: (i) electronic health record data from all emergency rooms, hospitals, primary care and specialty clinics and care facilities in the county; (ii) labs from all laboratory service providers; (iii) prescription details from all pharmacies; (iv) validated social determinants of health surveys administered in clinics; and (v) administrative datasets, including welfare, disability, housing, and geocoded neighborhood features. While several other counties are following suit to develop large, secure HIEs across healthcare and public health systems, a key challenge remains: how to cheaply, accurately, and rapidly analyze HIEs to identify which persons should be targeted for interventions. Without reliable, user- friendly, cost-effective, and generalizable data analysis programs, counties are unable to use the massive data at their disposal to address preventable causes of morbidity and mortality. The objective of this application is to apply our unique machine-learning innovations to develop open-source programs that can enable counties to identify persons at high risk for preventable CVD events and deaths. We will test the hypothesis that electronic health record data alone are insufficient to provide accurate risk prediction for preventable CVD events and deaths. Rather, we believe that key survey and administrative data providing information on social determinants of health will improve identification of high-risk patients. To test our hypothesis, we will develop and validate open-source, generalizable programs to: (Aim 1) rapidly identify persons in need of improved primary and secondary prevention of CVD by systematically comparing the performance of three alternative machine learning approaches to read HIE data, as compared to human clinician chart reviewers; and (Aim 2) perform multi-level risk assessment by automatically calibrating and validating models of CVD event risk, utilization and cost to HIE data, to identify the added value of administrative and social determinants data as compared to clinical or claims-based data alone. Our work will produce generalizable software tools for counties across the country to analyze HIE data and reduce preventable CVD disparities. PROJECT NARRATIVE Cardiovascular disease (CVD) disparities are exacerbated by inadequate guideline-based treatment of CVD risk factors. Furthermore, risk adjustment models currently used to target interventions and pay for healthcare services only use claims-based data such as demographics and clinical diagnostic codes, ignoring social determinants of health. Our research will rigorously develop and test novel machine learning methods that incorporate social determinants data from large Health Information Exchanges, producing novel data tools that will enable health systems nationwide to better detect individuals who could use improvements in their preventive therapy for CVD, and improve risk adjustment models to identify persons at high risk for preventable healthcare utilization and cost.",Developing data tools to reduce CVD disparities via Health Information Exchanges,9766361,R21MD012867,"['Accident and Emergency department', 'Address', 'Administrator', 'Blood Pressure', 'California', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Case Management', 'Cessation of life', 'Clinic', 'Clinical', 'Code', 'Country', 'County', 'Data', 'Data Analyses', 'Data Set', 'Dyslipidemias', 'Electronic Health Record', 'Event', 'Funding', 'Goals', 'Gold', 'Guidelines', 'Health', 'Health Care Costs', 'Health Personnel', 'Health Surveys', 'Health care facility', 'Health system', 'Healthcare', 'Heart failure', 'Hospitalization', 'Hospitals', 'Housing', 'Human', 'Individual', 'Informatics', 'Information Systems', 'Insurance', 'Intervention', 'Laboratories', 'Literature', 'Low income', 'Machine Learning', 'Medical', 'Meta-Analysis', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Neighborhoods', 'Non-Insulin-Dependent Diabetes Mellitus', 'Patients', 'Performance', 'Persons', 'Pharmacologic Substance', 'Pharmacy facility', 'Phase', 'Physicians', 'Population', 'Population Surveillance', 'Preventive therapy', 'Preventive treatment', 'Primary Health Care', 'Primary Prevention', 'Public Health', 'Race', 'Research', 'Risk', 'Risk Adjustment', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Secondary Prevention', 'Secure', 'Social Work', 'Software Tools', 'Standardization', 'Stroke', 'Surveys', 'Techniques', 'Testing', 'Unemployment', 'United States', 'Validation', 'Vocabulary', 'Work', 'base', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'cardiovascular disorder therapy', 'care providers', 'clinical diagnostics', 'cost', 'cost effective', 'data exchange', 'data resource', 'deep learning', 'demographics', 'disability', 'disorder prevention', 'health care service', 'health care service utilization', 'high risk', 'improved', 'innovation', 'learning strategy', 'medical specialties', 'mortality', 'novel', 'open source', 'payment', 'programs', 'prospective', 'residence', 'risk prediction model', 'safety net', 'semiparametric', 'service providers', 'social', 'social health determinants', 'socioeconomics', 'tool', 'treatment disparity', 'user-friendly', 'welfare']",NIMHD,STANFORD UNIVERSITY,R21,2019,190864,0.025446599087859515
"Developing data tools to reduce CVD disparities via Health Information Exchanges ABSTRACT CVD disparities across the race/ethnic and socioeconomic gradients are exacerbated by barriers to receiving guideline-based primary or secondary preventive treatmentsuch as appropriate blood pressure, dyslipidemia, and type 2 diabetes treatment.16 Most patients not receiving guideline-based treatment are actually insured and have seen a primary care provider in the past year.1 To reduce CVD disparities by better targeting disease prevention and treatment, healthcare administrators and county departments of public health have begun pooling data resources across healthcare and public health systemssuch as across clinics, emergency rooms and hospitals, pharmacies, laboratories, and administrative datasets.79 The idea behind pooling such datasets is to better identify persons most in need, and direct targeted interventions to them. Solano County, California, a medium-sized, diverse, low-income county, has developed one of the first, and most comprehensive health information exchanges (HIEs), including: (i) electronic health record data from all emergency rooms, hospitals, primary care and specialty clinics and care facilities in the county; (ii) labs from all laboratory service providers; (iii) prescription details from all pharmacies; (iv) validated social determinants of health surveys administered in clinics; and (v) administrative datasets, including welfare, disability, housing, and geocoded neighborhood features. While several other counties are following suit to develop large, secure HIEs across healthcare and public health systems, a key challenge remains: how to cheaply, accurately, and rapidly analyze HIEs to identify which persons should be targeted for interventions. Without reliable, user- friendly, cost-effective, and generalizable data analysis programs, counties are unable to use the massive data at their disposal to address preventable causes of morbidity and mortality. The objective of this application is to apply our unique machine-learning innovations to develop open-source programs that can enable counties to identify persons at high risk for preventable CVD events and deaths. We will test the hypothesis that electronic health record data alone are insufficient to provide accurate risk prediction for preventable CVD events and deaths. Rather, we believe that key survey and administrative data providing information on social determinants of health will improve identification of high-risk patients. To test our hypothesis, we will develop and validate open-source, generalizable programs to: (Aim 1) rapidly identify persons in need of improved primary and secondary prevention of CVD by systematically comparing the performance of three alternative machine learning approaches to read HIE data, as compared to human clinician chart reviewers; and (Aim 2) perform multi-level risk assessment by automatically calibrating and validating models of CVD event risk, utilization and cost to HIE data, to identify the added value of administrative and social determinants data as compared to clinical or claims-based data alone. Our work will produce generalizable software tools for counties across the country to analyze HIE data and reduce preventable CVD disparities. PROJECT NARRATIVE Cardiovascular disease (CVD) disparities are exacerbated by inadequate guideline-based treatment of CVD risk factors. Furthermore, risk adjustment models currently used to target interventions and pay for healthcare services only use claims-based data such as demographics and clinical diagnostic codes, ignoring social determinants of health. Our research will rigorously develop and test novel machine learning methods that incorporate social determinants data from large Health Information Exchanges, producing novel data tools that will enable health systems nationwide to better detect individuals who could use improvements in their preventive therapy for CVD, and improve risk adjustment models to identify persons at high risk for preventable healthcare utilization and cost.",Developing data tools to reduce CVD disparities via Health Information Exchanges,9584874,R21MD012867,"['Accident and Emergency department', 'Address', 'Administrator', 'Blood Pressure', 'California', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Case Management', 'Cessation of life', 'Clinic', 'Clinical', 'Code', 'Country', 'County', 'Data', 'Data Analyses', 'Data Set', 'Dyslipidemias', 'Electronic Health Record', 'Event', 'Funding', 'Goals', 'Gold', 'Guidelines', 'Health', 'Health Care Costs', 'Health Personnel', 'Health Surveys', 'Health care facility', 'Health system', 'Healthcare', 'Heart failure', 'Hospitalization', 'Hospitals', 'Housing', 'Human', 'Individual', 'Informatics', 'Information Systems', 'Insurance', 'Intervention', 'Laboratories', 'Literature', 'Low income', 'Machine Learning', 'Medical', 'Meta-Analysis', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Neighborhoods', 'Non-Insulin-Dependent Diabetes Mellitus', 'Patient risk', 'Patients', 'Performance', 'Persons', 'Pharmacologic Substance', 'Pharmacy facility', 'Phase', 'Physicians', 'Population', 'Population Surveillance', 'Preventive therapy', 'Preventive treatment', 'Primary Health Care', 'Primary Prevention', 'Public Health', 'Race', 'Research', 'Risk', 'Risk Adjustment', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Secondary Prevention', 'Secure', 'Social Work', 'Software Tools', 'Standardization', 'Stroke', 'Surveys', 'Techniques', 'Testing', 'Unemployment', 'United States', 'Validation', 'Vocabulary', 'Work', 'base', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'cardiovascular disorder therapy', 'care providers', 'clinical diagnostics', 'cost', 'cost effective', 'data exchange', 'data resource', 'deep learning', 'demographics', 'disability', 'disorder prevention', 'health care service', 'health care service utilization', 'high risk', 'improved', 'innovation', 'learning strategy', 'medical specialties', 'mortality', 'novel', 'open source', 'payment', 'predictive modeling', 'programs', 'prospective', 'residence', 'safety net', 'semiparametric', 'service providers', 'social', 'social health determinants', 'socioeconomics', 'tool', 'treatment disparity', 'user-friendly', 'welfare']",NIMHD,STANFORD UNIVERSITY,R21,2018,229089,0.025446599087859515
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., j-shaped sella turcica and short stature) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9925808,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'ClinVar', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data standards', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'patient health information', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,399965,-0.03655253926873716
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., j-shaped sella turcica and short stature) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9786822,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,399965,-0.03655253926873716
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., j-shaped sella turcica and short stature) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9544417,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,399949,-0.03655253926873716
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9986899,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Information Retrieval', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'adaptation algorithm', 'base', 'case finding', 'improved', 'machine learning method', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'structured data', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,383874,0.07108569557332012
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9768545,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,383874,0.07108569557332012
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9579181,R01LM012918,"['Adult', 'Adverse drug event', 'Adverse effects', 'Algorithms', 'Apache', 'Area', 'Biological Neural Networks', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'Supervision', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'new technology', 'news', 'novel', 'open source', 'point of care', 'social media', 'software systems', 'statistics', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2018,416066,0.07108569557332012
"Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records Project Summary/Abstract This project proposes new methods for representing data in electronic health records (EHR) to improve pre- dictive modeling and interpretation of patient outcomes. EHR data offer a promising opportunity for advancing the understanding of how clinical decisions and patient conditions interact over time to inuence patient health. However, EHR data are difcult to use for predictive modeling due to the various data types they contain (con- tinuous, categorical, text, etc.), their longitudinal nature, the high amount of non-random missingness for certain measurements, and other concerns. Furthermore, patient outcomes often have heterogenous causes and re- quire information to be synthesized from several clinical lab measures and patient visits. The core challenge at hand is overcoming the mismatch between data representations in the EHR and the assumptions underly- ing commonly used statistical and machine learning (ML) methods. To this end, this project proposes novel wrapper-based methods for learning informative features from EHR data. Both methods propose specialized operators to handle sequential data, time delays, and variable interactions, and have the capacity to discover underlying clinical rules/decisions that affect patient outcomes. Importantly, both methods also produce archives of possible models that represent the best trade-offs between complexity and accuracy, which assists in model interpretation. These method advances are made possible by encoding a rich set of data operations as nodes in a directed acyclic graph, and optimizing the graph structures using multi-objective optimization. The central hypothesis of this research is that multi-objective optimization can learn effective data representations from the EHR to produce accurate, explanatory models of patient outcomes. Preliminary work has shown that these methods can effectively learn low-order data representations that improve the predictive ability of several state- of-the-art ML methods. This technique demonstrates good scaling properties with high-dimensional biomedical data. Aim 1 (K99) is to develop a multi-objective feature engineering method that pairs with existing ML methods to iteratively improve their performance by constructing new features from the raw data and using feedback from the trained model to guide feature construction. In Aim 2 (K99), this method is applied to form predictive models of the risk of heart disease and heart failure using longitudinal EHR data. The resultant models will be inter- preted with the help of mentors in order to translate predictions into clinical recommendations. For Aim 3 (R00), a second method is proposed that uses a similar framework to optimize existing neural network approaches in order to simplify their structure as much as possible while maintaining accuracy. The goal of Aim 4 (R00) is to identify hospital patients who are at risk of readmission and propose point-of-care strategies to mitigate that risk. This goal is facilitated through the application of the proposed methods to patient data collected from the Hospital of the University of Pennsylvania, the Geisinger Health System, and publicly available EHR databases. Project Narrative  Understanding how clinical decisions interact with a patient's health and environmental over time to inuence patient outcomes is central to the goals of enhancing health, reducing illness and improving quality of life. The proposed research provides important methodological advances for extracting these insights from widely available patient health records.",Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records,9936444,K99LM012926,"['Address', 'Affect', 'Archives', 'Area', 'Automobile Driving', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Communities', 'Complex', 'Couples', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Engineering', 'Feedback', 'Goals', 'Graph', 'Hand', 'Health', 'Health Sciences', 'Health system', 'Heart Diseases', 'Heart failure', 'Hospitals', 'Inpatients', 'Knowledge', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pennsylvania', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Process', 'Property', 'Protocols documentation', 'Quality of life', 'Recommendation', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'University Hospitals', 'Visit', 'Work', 'base', 'care costs', 'cluster computing', 'data archive', 'deep learning', 'deep neural network', 'design', 'disease diagnosis', 'disorder subtype', 'heart disease risk', 'high dimensionality', 'hospital readmission', 'improved', 'insight', 'learning strategy', 'machine learning method', 'network architecture', 'neural network', 'novel', 'open source', 'operation', 'patient health information', 'point of care', 'predictive modeling', 'readmission rates', 'readmission risk', 'statistical and machine learning', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,K99,2020,89401,0.0492833487465427
"Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records Project Summary/Abstract This project proposes new methods for representing data in electronic health records (EHR) to improve pre- dictive modeling and interpretation of patient outcomes. EHR data offer a promising opportunity for advancing the understanding of how clinical decisions and patient conditions interact over time to inuence patient health. However, EHR data are difcult to use for predictive modeling due to the various data types they contain (con- tinuous, categorical, text, etc.), their longitudinal nature, the high amount of non-random missingness for certain measurements, and other concerns. Furthermore, patient outcomes often have heterogenous causes and re- quire information to be synthesized from several clinical lab measures and patient visits. The core challenge at hand is overcoming the mismatch between data representations in the EHR and the assumptions underly- ing commonly used statistical and machine learning (ML) methods. To this end, this project proposes novel wrapper-based methods for learning informative features from EHR data. Both methods propose specialized operators to handle sequential data, time delays, and variable interactions, and have the capacity to discover underlying clinical rules/decisions that affect patient outcomes. Importantly, both methods also produce archives of possible models that represent the best trade-offs between complexity and accuracy, which assists in model interpretation. These method advances are made possible by encoding a rich set of data operations as nodes in a directed acyclic graph, and optimizing the graph structures using multi-objective optimization. The central hypothesis of this research is that multi-objective optimization can learn effective data representations from the EHR to produce accurate, explanatory models of patient outcomes. Preliminary work has shown that these methods can effectively learn low-order data representations that improve the predictive ability of several state- of-the-art ML methods. This technique demonstrates good scaling properties with high-dimensional biomedical data. Aim 1 (K99) is to develop a multi-objective feature engineering method that pairs with existing ML methods to iteratively improve their performance by constructing new features from the raw data and using feedback from the trained model to guide feature construction. In Aim 2 (K99), this method is applied to form predictive models of the risk of heart disease and heart failure using longitudinal EHR data. The resultant models will be inter- preted with the help of mentors in order to translate predictions into clinical recommendations. For Aim 3 (R00), a second method is proposed that uses a similar framework to optimize existing neural network approaches in order to simplify their structure as much as possible while maintaining accuracy. The goal of Aim 4 (R00) is to identify hospital patients who are at risk of readmission and propose point-of-care strategies to mitigate that risk. This goal is facilitated through the application of the proposed methods to patient data collected from the Hospital of the University of Pennsylvania, the Geisinger Health System, and publicly available EHR databases. Project Narrative  Understanding how clinical decisions interact with a patient's health and environmental over time to inuence patient outcomes is central to the goals of enhancing health, reducing illness and improving quality of life. The proposed research provides important methodological advances for extracting these insights from widely available patient health records.",Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records,9744166,K99LM012926,"['Address', 'Affect', 'Archives', 'Area', 'Automobile Driving', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Communities', 'Complex', 'Couples', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Engineering', 'Feedback', 'Goals', 'Graph', 'Hand', 'Health', 'Health Sciences', 'Health system', 'Heart Diseases', 'Heart failure', 'Hospitals', 'Inpatients', 'Knowledge', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Records', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pennsylvania', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Process', 'Property', 'Protocols documentation', 'Quality of life', 'Recommendation', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'University Hospitals', 'Visit', 'Work', 'base', 'care costs', 'cluster computing', 'data archive', 'deep learning', 'deep neural network', 'design', 'disease diagnosis', 'disorder subtype', 'health record', 'heart disease risk', 'high dimensionality', 'hospital readmission', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network', 'novel', 'open source', 'operation', 'point of care', 'predictive modeling', 'readmission rates', 'readmission risk', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,K99,2019,89260,0.0492833487465427
"Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization Project summary Intimate partner violence (IPV) is a significant public health and criminal justice problem that negatively impacts millions of victims yearly in the United States, primarily women (85%). Most IPV-related healthcare visits (83%) occurred in an emergency department (ED), and these clinical encounters are unique opportunities to identify IPV victims and potentially provide assistance. Although numerous health professional organizations have endorsed universal screening and counseling for IPV since 1992, actual screening rates, detection of IPV victims, and referrals to IPV services remain low in the ED. As a result, many IPV victims pass through the ED unidentified and untreated. Computerized screening tools have been developed and implemented in clinical settings in order to assist providers in screening and detecting IPV. However, these tools have a great limitation in that they rely on information collected from the patient and do not utilize the longitudinal data in electronic health records (EHR). Recently, researchers demonstrated that a history of IPV diagnoses and associated clinical symptoms highly predict current and future IPV (OR=7.8), and these important IPV data could serve as red flags that trigger providers to assess patients further for IPV. In order to enhance IPV screening in the ED, we propose to develop and assess an automatic clinical data summarizer that extracts, abstracts and synthesizes patient historical IPV data (structured and unstructured), and delivers patient historical IPV data to ED providers through an intuitive interface. The specific aims are: 1) develop and evaluate natural language processing (NLP) strategies to identify and extract patient historical IPV incidents and timelines from clinic notes; 2) develop and evaluate a web service-based summary tool (IPV-Summary-Service) that synthesizes patient- specific IPV information from both NLP-processed data elements and structured data; and 3) develop and pilot test an enhanced IPV screening strategy that delivers clinical evidence generated by the IPV-Summary- Service through a specific EHR (Epic) to providers during the patient universal IPV screening in the ED. This automatic clinical date summary for IPV will be piloted in one ED at MUSC. There are two major outcomes to be measured for the IPV-Summary enhanced screening for 6 months before and after the index date of pilot testing: 1) rate of successful referral to the IPV 24-hour dedicated IPV nurse; and 2) rate of initiation of referral and identification of persons at high risk of IPV. We will use mixed effect generalized linear regression models to estimate the effects of IPV-Summary on the referral rate and IPV case identification rate. Through survey studies, we will assess secondary outcomes including factors of system feasibility, usability, and providers' satisfaction. These analyses can identify potentially important correlates of the major outcomes and may help us improve the design of the intervention. The results from this study will form the foundation for a broader implementation in a regional health information exchange for EDs. Narrative Computer-based approaches for intimate partner violence (IPV) universal screening have led to significantly higher screening rate and detection rate, as well as receipt of IPV services in the emergency department (ED). However, these approaches rely on information collected from the patient and do not utilize the longitudinal IPV data existing in electronic health records (EHR), which have high predictive power of IPV risk. In order to enhance the effectiveness of IPV screening, we propose to develop and assess an automatic clinical data summary tool that extracts, abstracts, and synthesizes patient historical IPV information from EHR and then delivers that critical information to ED providers at the point of care.",Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization,9739347,R21LM012945,"['Accident and Emergency department', 'Acute', 'Address', 'Adopted', 'Adult', 'American', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Client', 'Clinic', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Counseling', 'Crime', 'Criminal Justice', 'Data', 'Data Element', 'Decision Making', 'Detection', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Emergency Department patient', 'Emergency department visit', 'Event', 'Face', 'Female', 'Foundations', 'Future', 'Health', 'Health Care Visit', 'Health Professional', 'Hour', 'Injury', 'Intuition', 'Linear Regressions', 'Link', 'Masks', 'Measures', 'Medical', 'Modeling', 'Natural Language Processing', 'Nurses', 'Outcome', 'Patient Self-Report', 'Patients', 'Persons', 'Process', 'Professional Organizations', 'Provider', 'Public Health', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Screening procedure', 'Services', 'South Carolina', 'Structure', 'Surveys', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Trauma', 'United States', 'Universities', 'Victimization', 'Violent injury', 'Woman', 'Work', 'base', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'experience', 'high risk', 'improved', 'indexing', 'intimate partner violence', 'point of care', 'pressure', 'satisfaction', 'screening', 'secondary outcome', 'therapy design', 'tool', 'usability', 'web services']",NLM,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R21,2019,168188,0.05066503350295946
"Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization Project summary Intimate partner violence (IPV) is a significant public health and criminal justice problem that negatively impacts millions of victims yearly in the United States, primarily women (85%). Most IPV-related healthcare visits (83%) occurred in an emergency department (ED), and these clinical encounters are unique opportunities to identify IPV victims and potentially provide assistance. Although numerous health professional organizations have endorsed universal screening and counseling for IPV since 1992, actual screening rates, detection of IPV victims, and referrals to IPV services remain low in the ED. As a result, many IPV victims pass through the ED unidentified and untreated. Computerized screening tools have been developed and implemented in clinical settings in order to assist providers in screening and detecting IPV. However, these tools have a great limitation in that they rely on information collected from the patient and do not utilize the longitudinal data in electronic health records (EHR). Recently, researchers demonstrated that a history of IPV diagnoses and associated clinical symptoms highly predict current and future IPV (OR=7.8), and these important IPV data could serve as red flags that trigger providers to assess patients further for IPV. In order to enhance IPV screening in the ED, we propose to develop and assess an automatic clinical data summarizer that extracts, abstracts and synthesizes patient historical IPV data (structured and unstructured), and delivers patient historical IPV data to ED providers through an intuitive interface. The specific aims are: 1) develop and evaluate natural language processing (NLP) strategies to identify and extract patient historical IPV incidents and timelines from clinic notes; 2) develop and evaluate a web service-based summary tool (IPV-Summary-Service) that synthesizes patient- specific IPV information from both NLP-processed data elements and structured data; and 3) develop and pilot test an enhanced IPV screening strategy that delivers clinical evidence generated by the IPV-Summary- Service through a specific EHR (Epic) to providers during the patient universal IPV screening in the ED. This automatic clinical date summary for IPV will be piloted in one ED at MUSC. There are two major outcomes to be measured for the IPV-Summary enhanced screening for 6 months before and after the index date of pilot testing: 1) rate of successful referral to the IPV 24-hour dedicated IPV nurse; and 2) rate of initiation of referral and identification of persons at high risk of IPV. We will use mixed effect generalized linear regression models to estimate the effects of IPV-Summary on the referral rate and IPV case identification rate. Through survey studies, we will assess secondary outcomes including factors of system feasibility, usability, and providers' satisfaction. These analyses can identify potentially important correlates of the major outcomes and may help us improve the design of the intervention. The results from this study will form the foundation for a broader implementation in a regional health information exchange for EDs. Narrative Computer-based approaches for intimate partner violence (IPV) universal screening have led to significantly higher screening rate and detection rate, as well as receipt of IPV services in the emergency department (ED). However, these approaches rely on information collected from the patient and do not utilize the longitudinal IPV data existing in electronic health records (EHR), which have high predictive power of IPV risk. In order to enhance the effectiveness of IPV screening, we propose to develop and assess an automatic clinical data summary tool that extracts, abstracts, and synthesizes patient historical IPV information from EHR and then delivers that critical information to ED providers at the point of care.",Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization,9520862,R21LM012945,"['Accident and Emergency department', 'Acute', 'Address', 'Adopted', 'Adult', 'American', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Client', 'Clinic', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Counseling', 'Crime', 'Criminal Justice', 'Data', 'Data Element', 'Decision Making', 'Detection', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Emergency Department patient', 'Emergency department visit', 'Event', 'Face', 'Female', 'Foundations', 'Future', 'Health', 'Health Care Visit', 'Health Professional', 'Hour', 'Injury', 'Intuition', 'Linear Regressions', 'Link', 'Masks', 'Measures', 'Medical', 'Modeling', 'Natural Language Processing', 'Nurses', 'Outcome', 'Patient Self-Report', 'Patients', 'Persons', 'Process', 'Professional Organizations', 'Provider', 'Public Health', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Screening procedure', 'Services', 'South Carolina', 'Structure', 'Surveys', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Trauma', 'United States', 'Universities', 'Victimization', 'Violent injury', 'Woman', 'Work', 'base', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'experience', 'high risk', 'improved', 'indexing', 'intimate partner violence', 'point of care', 'pressure', 'satisfaction', 'screening', 'secondary outcome', 'therapy design', 'tool', 'usability', 'web services']",NLM,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R21,2018,201825,0.05066503350295946
"Improving accreditation, certification and quality improvement programs through automated abstraction of electronic health data. ABSTRACT SBIR Phase I: Reduce the burden of data abstraction for certification, accreditation and quality improvement programs via a new platform to automate the abstraction of measures and a novel interface to improve human abstractor workflow. The broad impact/commercial potential of this SBIR Phase I project is to drive down the burden of participation in quality improvement programs, specifically, the resource intensive manual data abstraction process to derive and report quality measures that are instrumental to improving health outcomes and controlling costs. Patient Insight proposes improvements through automated abstraction methods and an interface for human abstractors to better visualize electronic health record (EHR) data and complete their work. The existing approach is a barrier to broader uptake of quality improvement initiatives such as accreditation. Patient Insights proposed solution consists of leveraging both proven and proprietary technologies to extract data via EHR agnostic application programming interfaces (APIs), better target eligible patients, and calculate measures via natural language processing (NLP) algorithms and custom queries. The core innovation is a novel data mining engine and user interface that improves the process of human data abstraction for clinical and quality documentation such as those required to achieve accreditation. The proposed project will allow Patient Insight, in partnership with the American College of Cardiology, a leader in the hospital based accreditation space, to develop a proof-of-concept pilot project at a select hospital and compare human and automated data abstraction methods for a pre-selected number of measures that are mandated as part of the ACCs Heart Failure Accreditation program. Once completed, Patient Insight will expand on the technology, design and user research data/requirements with a roadmap for product enhancements for Phase II that will enable the building of a commercially viable add-on service for sites participating in the ACCs suite of accreditation programs and eventually expand to additional ACC service lines as well as other accreditation and certifying bodies. Success will represent a transformative change in general-purpose abstraction and an interface that will support a broad array of accreditation measures and abstraction workflows thereby solving a critical inefficiency both clinically and financially for hospitals while improving patient health outcomes. PROJECT NARRATIVE Health service accreditation and certification programs are a critical mechanism to direct care quality improvements and ensure compliance with regulations. Reporting on requisite measures is a resource intensive and costly process requiring human data abstractors to interpret heterogeneous and disparately presented data elements from the electronic health record (EHR). Replacing human elements using evolving automated data abstraction methods and an interface for abstractors to better visualize EHR data and manage their workflow would solve an important, unmet need and offer a dramatic improvement over the status quo. Patient Insights commercial technology solution will facilitate efficiencies in automated data abstraction and human-to-computer interactions in quality improvement reporting.","Improving accreditation, certification and quality improvement programs through automated abstraction of electronic health data.",9622944,R43LM012955,"['Accreditation', 'Algorithms', 'American', 'Appointment', 'Back', 'Beds', 'Budgets', 'Cardiac rehabilitation', 'Cardiology', 'Caring', 'Certification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computers', 'Cost Control', 'Custom', 'Data', 'Data Element', 'Diuretics', 'Documentation', 'Electronic Health Record', 'Elements', 'Ensure', 'Event', 'Expenditure', 'Feedback', 'Hand', 'Health', 'Health Services', 'Health Services Accessibility', 'Health Status', 'Healthcare', 'Heart failure', 'Hospitals', 'Human', 'Information Technology', 'Investments', 'Licensing', 'Manuals', 'Measures', 'Methods', 'Mining', 'Natural Language Processing', 'Outcome', 'Outcome Measure', 'Paper', 'Patient Care', 'Patients', 'Phase', 'Pilot Projects', 'Population', 'Process', 'Quality of Care', 'Regulation', 'Reporting', 'Research', 'Resources', 'Schedule', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Work', 'application programming interface', 'base', 'cardiology service', 'certificate program', 'college', 'cost', 'data management', 'data mining', 'data visualization', 'design', 'exercise program', 'follow-up', 'health assessment', 'health data', 'human data', 'improved', 'innovation', 'insight', 'new technology', 'novel', 'product development', 'programs', 'readmission rates', 'success', 'tool', 'uptake', 'usability']",NLM,"PATIENT INSIGHT, INC.",R43,2018,259060,0.05145502822074504
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that big data clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9640372,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'comparative effectiveness', 'cost', 'deep learning', 'diagnosis standard', 'effectiveness research', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2018,347584,0.02992056350409419
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that big data clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9926311,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Comparative Effectiveness Research', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'cost', 'deep learning', 'diagnosis standard', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2020,348620,0.02992056350409419
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that big data clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9782996,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'comparative effectiveness', 'cost', 'deep learning', 'diagnosis standard', 'effectiveness research', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics\xa0tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2019,348107,0.02992056350409419
"Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks Project Summary In this project we develop new methods for extracting important information from electronic health records based on recurrent neural networks. These methods represent the hierarchical and sequential nature of human language, leverage large scale datasets to make learning sophisticated representations possible, and make use of novel sources of supervision that are available at this scale. The model architecture we propose is a hierarchical recurrent neural network (RNN). This architecture explicitly represents temporality at multiple different time scales, with stacked RNN layers representing words, sentences, paragraphs, and documents. At the word level, the model is trained to predict important pieces of clinical information, such as negation and temporality, using existing labeled data sets. Training for clinical information extraction at the lowest level ensures that the higher-level models have a foundation of medically relevant inputs. We are still left with the challenge of training higher-level networks, because these models require massive amounts of labeled training data to learn. We solve this problem by taking advantage of the temporal aspect of information in an EHR, and having each higher-level recurrent layer train getting supervision from the future. For example, the document RNN is trained to predict billing codes and NLP concept codes that were found in the subsequent document. This source of supervision is scalable, and our preliminary data shows that it is effective at learning how to generate generalizable patient representations. The patient representations that our model learns are shareable across multiple tasks, potentially streamlining EHR-based research by eliminating what was previously a manual step  designing text-based variables to represent patients. We demonstrate a new workflow for text-based EHR research, showing how the same representations can be used for two completely distinct phenotyping tasks. These phenotyping studies make use of high-quality datasets of patients with pulmonary hypertension and autism spectrum disorder at Boston Childrens Hospital. PH is relatively rare, so finding every patient with a phenotyping algorithm is important for clinical research. ASD has several sub-phenotypes, and finding large numbers of patients from each sub- phenotype can help to better understand the mechanisms of ASD. Along with demonstrating the applicability of our representations on these specific clinical research use cases, we incorporate our patient representations into the i2b2 clinical research software, making them available to all clinical investigators using this platform at Boston Childrens Hospital. Project Narrative This project develops methods for extracting universal patient representations from unstructured text in electronic health records. These methods leverage huge amounts of clinical data, recurrent neural network architectures, and novel training techniques to incorporate information at multiple time scales. These methods are evaluated using public datasets to promote reproducibility, and applied to clinical research tasks that extend the knowledge of patients with pulmonary hypertension and autism spectrum disorder at Boston Childrens Hospital.",Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks,9868326,R01LM012973,"['Architecture', 'Boston', 'Brain', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Computer software', 'Data', 'Data Set', 'Electronic Health Record', 'Ensure', 'Event', 'Face', 'Felis catus', 'Foundations', 'Future', 'Healthcare Systems', 'Human', 'Human Characteristics', 'Human Resources', 'Information Retrieval', 'Intensive Care Units', 'Israel', 'Knowledge', 'Label', 'Language', 'Learning', 'Left', 'Linguistics', 'Location', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Problem Solving', 'Process', 'Pulmonary Hypertension', 'Rare Diseases', 'Records', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Source', 'Statistical Methods', 'Supervision', 'System', 'Text', 'Time', 'Training', 'Training Technics', 'Uncertainty', 'autism spectrum disorder', 'base', 'clinically relevant', 'cohort', 'comorbidity', 'data resource', 'deep neural network', 'design', 'disease phenotype', 'large scale data', 'learning strategy', 'machine translation', 'neural network', 'neural network architecture', 'novel', 'phenotyping algorithm', 'recurrent neural network', 'relating to nervous system']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,367184,-0.018964429415015062
"Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks Project Summary In this project we develop new methods for extracting important information from electronic health records based on recurrent neural networks. These methods represent the hierarchical and sequential nature of human language, leverage large scale datasets to make learning sophisticated representations possible, and make use of novel sources of supervision that are available at this scale. The model architecture we propose is a hierarchical recurrent neural network (RNN). This architecture explicitly represents temporality at multiple different time scales, with stacked RNN layers representing words, sentences, paragraphs, and documents. At the word level, the model is trained to predict important pieces of clinical information, such as negation and temporality, using existing labeled data sets. Training for clinical information extraction at the lowest level ensures that the higher-level models have a foundation of medically relevant inputs. We are still left with the challenge of training higher-level networks, because these models require massive amounts of labeled training data to learn. We solve this problem by taking advantage of the temporal aspect of information in an EHR, and having each higher-level recurrent layer train getting supervision from the future. For example, the document RNN is trained to predict billing codes and NLP concept codes that were found in the subsequent document. This source of supervision is scalable, and our preliminary data shows that it is effective at learning how to generate generalizable patient representations. The patient representations that our model learns are shareable across multiple tasks, potentially streamlining EHR-based research by eliminating what was previously a manual step  designing text-based variables to represent patients. We demonstrate a new workflow for text-based EHR research, showing how the same representations can be used for two completely distinct phenotyping tasks. These phenotyping studies make use of high-quality datasets of patients with pulmonary hypertension and autism spectrum disorder at Boston Childrens Hospital. PH is relatively rare, so finding every patient with a phenotyping algorithm is important for clinical research. ASD has several sub-phenotypes, and finding large numbers of patients from each sub- phenotype can help to better understand the mechanisms of ASD. Along with demonstrating the applicability of our representations on these specific clinical research use cases, we incorporate our patient representations into the i2b2 clinical research software, making them available to all clinical investigators using this platform at Boston Childrens Hospital. Project Narrative This project develops methods for extracting universal patient representations from unstructured text in electronic health records. These methods leverage huge amounts of clinical data, recurrent neural network architectures, and novel training techniques to incorporate information at multiple time scales. These methods are evaluated using public datasets to promote reproducibility, and applied to clinical research tasks that extend the knowledge of patients with pulmonary hypertension and autism spectrum disorder at Boston Childrens Hospital.",Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks,9642922,R01LM012973,"['Algorithms', 'Architecture', 'Boston', 'Brain', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Comorbidity', 'Computer software', 'Data', 'Data Set', 'Electronic Health Record', 'Ensure', 'Event', 'Face', 'Felis catus', 'Foundations', 'Future', 'Healthcare Systems', 'Human', 'Human Characteristics', 'Human Resources', 'Intensive Care Units', 'Israel', 'Knowledge', 'Label', 'Language', 'Learning', 'Left', 'Linguistics', 'Location', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Problem Solving', 'Process', 'Pulmonary Hypertension', 'Rare Diseases', 'Records', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Source', 'Statistical Methods', 'Supervision', 'System', 'Text', 'Time', 'Training', 'Training Technics', 'Uncertainty', 'autism spectrum disorder', 'base', 'clinically relevant', 'cohort', 'data resource', 'deep neural network', 'design', 'disease phenotype', 'learning strategy', 'machine translation', 'neural network', 'neural network architecture', 'novel', 'recurrent neural network', 'relating to nervous system']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,386910,-0.018964429415015062
"Coupling Results DatafromClinicalTrials.govandBibliographic Databasesto Accelerate Evidence Synthesis Project Summary Clinical trials are foundational to evidence-based medicine, but results reporting from trials is incomplete and frequently delayed. It is estimated that as many as half of clinical trials are not published and as many as half of published trials underreport or misreport outcomes. This type of results reporting distorts the evidence available to cliniciansparticularly when it comes to assessing the safety of interventions like drugs and devicesand may place patients at unnecessary risk. There is a critical need for novel methods to identify and monitor drug safety data. Through the infrastructure provided by ClinicalTrials.gov, structured trial results (including safety findings) are now becoming available for an increasing number of trials in a comprehensive and timely fashion. However, access and use of these data in evidence synthesis tasks remain limited. ClinicalTrials.gov is the largest single registry for clinical studies worldwide and includes more than 260,000 registered studies. Of the 108,941 completed trials registered with the site, 20% have uploaded results data for a total of 7.85 million participants. Results data reported on ClinicalTrials.gov have the potential to fill gaps created by delays and biases in published articles and provide an earlier and more complete overview of available trial evidence. We propose to develop novel informatics approaches based on combinations of information retrieval and machine learning methods to facilitate access and analysis of trial results reported in this registry. Focusing on trials testing drug interventions in type 2 diabetes, obesity, and oncology, we perform this work in three specific aims: 1) Develop semi-automated trial screening for identifying and aggregating trials relevant to a clinical intervention; 2) Extract adverse event and safety outcomes data from results reported in the registry; and 3) Perform validation studies to assess detection of adverse events and performance of semi- automated meta-analyses of safety outcomes. Methods developed in this project will facilitate timely, broad- scale use of trial results reported on ClinicalTrials.gov in order to augment the availability of comprehensive and timely drug safety data. All methods will be made publicly available in order to support adverse event monitoring and systematic reviews of drug interventions. Project Narrative The availability of results from clinical trials is frequently incomplete or delayed, limiting the evidence available to clinicians making treatment decisions. When results on the safety of interventions, such as drugs, are not properly disseminated, patients may be exposed to harm. National policies require comprehensive and timely reporting of trial results in trial registries (e.g. ClinicalTrials.gov), representing a novel data type that could be used for drug safety surveillance. However, the use of these data has remained limited to date. We propose innovative informatics methods to enable access and analysis of this emerging data source in order to augment the availability of comprehensive and timely drug safety data.",Coupling Results DatafromClinicalTrials.govandBibliographic Databasesto Accelerate Evidence Synthesis,9882529,R01LM012976,"['Adverse drug event', 'Adverse event', 'Bibliographic Databases', 'Bibliography', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Coupling', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Devices', 'Drug Monitoring', 'Drug usage', 'Equilibrium', 'Evidence Based Medicine', 'Exposure to', 'Foundations', 'Goals', 'Health', 'Heterogeneity', 'Individual', 'Informatics', 'Information Retrieval', 'Infrastructure', 'International', 'Intervention', 'Learning', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Meta-Analysis', 'Methods', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Oncology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Procedures', 'Process', 'Public Health Informatics', 'Publishing', 'Records', 'Registries', 'Reporting', 'Research Personnel', 'Resources', 'Risk', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Standardization', 'Structure', 'Time', 'Unified Medical Language System', 'Validation', 'Work', 'adverse event monitoring', 'base', 'cluster trial', 'concept mapping', 'design', 'drug testing', 'innovation', 'machine learning method', 'medication safety', 'novel', 'rosiglitazone', 'safety outcomes', 'screening', 'supervised learning', 'systematic review', 'tool', 'treatment arm', 'trial design', 'validation studies', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,328000,0.04031904364498469
"Coupling Results DatafromClinicalTrials.govandBibliographic Databasesto Accelerate Evidence Synthesis Project Summary Clinical trials are foundational to evidence-based medicine, but results reporting from trials is incomplete and frequently delayed. It is estimated that as many as half of clinical trials are not published and as many as half of published trials underreport or misreport outcomes. This type of results reporting distorts the evidence available to cliniciansparticularly when it comes to assessing the safety of interventions like drugs and devicesand may place patients at unnecessary risk. There is a critical need for novel methods to identify and monitor drug safety data. Through the infrastructure provided by ClinicalTrials.gov, structured trial results (including safety findings) are now becoming available for an increasing number of trials in a comprehensive and timely fashion. However, access and use of these data in evidence synthesis tasks remain limited. ClinicalTrials.gov is the largest single registry for clinical studies worldwide and includes more than 260,000 registered studies. Of the 108,941 completed trials registered with the site, 20% have uploaded results data for a total of 7.85 million participants. Results data reported on ClinicalTrials.gov have the potential to fill gaps created by delays and biases in published articles and provide an earlier and more complete overview of available trial evidence. We propose to develop novel informatics approaches based on combinations of information retrieval and machine learning methods to facilitate access and analysis of trial results reported in this registry. Focusing on trials testing drug interventions in type 2 diabetes, obesity, and oncology, we perform this work in three specific aims: 1) Develop semi-automated trial screening for identifying and aggregating trials relevant to a clinical intervention; 2) Extract adverse event and safety outcomes data from results reported in the registry; and 3) Perform validation studies to assess detection of adverse events and performance of semi- automated meta-analyses of safety outcomes. Methods developed in this project will facilitate timely, broad- scale use of trial results reported on ClinicalTrials.gov in order to augment the availability of comprehensive and timely drug safety data. All methods will be made publicly available in order to support adverse event monitoring and systematic reviews of drug interventions. Project Narrative The availability of results from clinical trials is frequently incomplete or delayed, limiting the evidence available to clinicians making treatment decisions. When results on the safety of interventions, such as drugs, are not properly disseminated, patients may be exposed to harm. National policies require comprehensive and timely reporting of trial results in trial registries (e.g. ClinicalTrials.gov), representing a novel data type that could be used for drug safety surveillance. However, the use of these data has remained limited to date. We propose innovative informatics methods to enable access and analysis of this emerging data source in order to augment the availability of comprehensive and timely drug safety data.",Coupling Results DatafromClinicalTrials.govandBibliographic Databasesto Accelerate Evidence Synthesis,9641903,R01LM012976,"['Adverse drug event', 'Adverse event', 'Bibliographic Databases', 'Bibliography', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Coupling', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Devices', 'Drug Monitoring', 'Drug usage', 'Equilibrium', 'Evidence Based Medicine', 'Exposure to', 'Foundations', 'Goals', 'Health', 'Heterogeneity', 'Individual', 'Informatics', 'Information Retrieval', 'Infrastructure', 'International', 'Intervention', 'Learning', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Meta-Analysis', 'Methods', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Participant', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Procedures', 'Process', 'Public Health Informatics', 'Publishing', 'Records', 'Registries', 'Reporting', 'Research Personnel', 'Resources', 'Risk', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Standardization', 'Structure', 'Time', 'Unified Medical Language System', 'Validation', 'Work', 'adverse event monitoring', 'base', 'cluster trial', 'concept mapping', 'design', 'drug testing', 'innovation', 'learning strategy', 'medication safety', 'novel', 'oncology', 'rosiglitazone', 'screening', 'supervised learning', 'systematic review', 'tool', 'treatment arm', 'trial design', 'validation studies', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,347250,0.04031904364498469
"Integrative data science approaches for rare disease discovery in health records ABSTRACT: There are nearly 7,000 diseases that have a prevalence of only one in 2,000 individuals or less. Yet, such rare diseases are estimated to collectively affect over 300 million people worldwide, representing a significant healthcare concern. Although rare diseases have predominantly genetic origins, nearly half of them do not manifest symptoms until adulthood and frequently confound discovery and diagnosis. Even in the case of early onset disorders, the sheer number of possible diagnoses can often overwhelm clinicians. As a result, rare diseases are often diagnosed with delay, misdiagnosed or even remain undiagnosed, not only disrupting patient lives but also hindering progress on our understanding of such diseases. Data science methods that mine large-scale retrospective health record data for phenotypic information will aid in timely and accurate diagnoses of rare diseases, especially when combined with additional data types, thus, having significant real- world impact. This proposal will integrate electronic health record (EHR) data sets with publicly available vocabularies and ontologies, and genomic data for the improved identification and characterization of patients with rare diseases, using approaches from machine learning, natural language processing (NLP) and basic bioinformatics. The work has three specific aims and will be carried out in two phases. During the mentored phase, the principal investigator (PI) will develop data-driven methods to extract standardized concepts related to rare diseases from clinical notes and infer the occurrence of each disease (Aim 1). He will also develop data science approaches to compare and contrast longitudinal patterns associated with patients' journeys through the healthcare system when seeking a diagnosis for a rare disease, and aid in clinical decision-making by leveraging these patterns (Aim 2). During the independent phase (Aim 3), computational methods will be developed for the integrated modeling and analysis of genotypic (from Aim 3) and phenotypic information (from Aims 1 and 2). Cohorts to be sequenced will cover diseases for which causal genes or disease definitions are unclear (discovery), as well as those for which these are well known (validation). This work will be carried out under the mentorship of four faculty members with complementary expertise in biomedical informatics, data science, NLP, and rare disease genomics at the University of Washington, the largest medical system in the Pacific Northwest (four million EHRs), world-renowned researchers in medical genetics, and a robust data science environment. In addition, under the direction of the mentoring team, the PI will complete advanced coursework, receive training in translational bioinformatics and clinical research informatics, submit manuscripts, and seek an independent research position. This proposal will yield preliminary results for subsequent studies on data-driven phenotyping and enable the realization of the PI's career goals by providing him with the necessary training to build on his machine learning and basic bioinformatics expertise to transition into an independent investigator in biomedical data science. PROJECT NARRATIVE Rare genetic diseases are estimated to affect the lives of 25 to 30 million Americans and their families, and present a significant economic burden on the healthcare system. Currently, our knowledge of the broad spectrum of the 7,000 observed rare diseases is limited to a few well-studied ones, hindering our ability to make correct and timely diagnoses. The objective of this study is to improve the identification of patients with rare diseases in healthcare systems by developing data science approaches that automatically recognize rare disease-related patterns in patient health records and correlate them with genomic data, thus, aiding in diagnosis and discovery.",Integrative data science approaches for rare disease discovery in health records,9884791,K99LM012992,"['Adult', 'Affect', 'American', 'Award', 'Basic Science', 'Behavioral', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Research', 'Computing Methodologies', 'Consensus', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostics Research', 'Disease', 'Economic Burden', 'Electronic Health Record', 'Environment', 'Faculty', 'Family', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Manuscripts', 'Markov Chains', 'Medical', 'Medical Genetics', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Pacific Northwest', 'Patient Recruitments', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Rare Diseases', 'Recording of previous events', 'Research', 'Research Personnel', 'Standardization', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Vocabulary', 'Washington', 'Work', 'accurate diagnosis', 'base', 'biomedical data science', 'biomedical informatics', 'career', 'causal variant', 'clinical data warehouse', 'clinical decision-making', 'cohort', 'diagnostic accuracy', 'disease phenotype', 'early onset disorder', 'exome sequencing', 'gene discovery', 'genomic data', 'health care delivery', 'health data', 'health record', 'improved', 'member', 'multimodal data', 'novel', 'open source', 'patient health information', 'phenotypic data', 'prototype', 'psychologic', 'rare condition', 'rare genetic disorder', 'recruit', 'skills', 'software development', 'support tools', 'tool', 'trait']",NLM,UNIVERSITY OF WASHINGTON,K99,2020,92070,0.05393994474112232
"Integrative data science approaches for rare disease discovery in health records ABSTRACT: There are nearly 7,000 diseases that have a prevalence of only one in 2,000 individuals or less. Yet, such rare diseases are estimated to collectively affect over 300 million people worldwide, representing a significant healthcare concern. Although rare diseases have predominantly genetic origins, nearly half of them do not manifest symptoms until adulthood and frequently confound discovery and diagnosis. Even in the case of early onset disorders, the sheer number of possible diagnoses can often overwhelm clinicians. As a result, rare diseases are often diagnosed with delay, misdiagnosed or even remain undiagnosed, not only disrupting patient lives but also hindering progress on our understanding of such diseases. Data science methods that mine large-scale retrospective health record data for phenotypic information will aid in timely and accurate diagnoses of rare diseases, especially when combined with additional data types, thus, having significant real- world impact. This proposal will integrate electronic health record (EHR) data sets with publicly available vocabularies and ontologies, and genomic data for the improved identification and characterization of patients with rare diseases, using approaches from machine learning, natural language processing (NLP) and basic bioinformatics. The work has three specific aims and will be carried out in two phases. During the mentored phase, the principal investigator (PI) will develop data-driven methods to extract standardized concepts related to rare diseases from clinical notes and infer the occurrence of each disease (Aim 1). He will also develop data science approaches to compare and contrast longitudinal patterns associated with patients' journeys through the healthcare system when seeking a diagnosis for a rare disease, and aid in clinical decision-making by leveraging these patterns (Aim 2). During the independent phase (Aim 3), computational methods will be developed for the integrated modeling and analysis of genotypic (from Aim 3) and phenotypic information (from Aims 1 and 2). Cohorts to be sequenced will cover diseases for which causal genes or disease definitions are unclear (discovery), as well as those for which these are well known (validation). This work will be carried out under the mentorship of four faculty members with complementary expertise in biomedical informatics, data science, NLP, and rare disease genomics at the University of Washington, the largest medical system in the Pacific Northwest (four million EHRs), world-renowned researchers in medical genetics, and a robust data science environment. In addition, under the direction of the mentoring team, the PI will complete advanced coursework, receive training in translational bioinformatics and clinical research informatics, submit manuscripts, and seek an independent research position. This proposal will yield preliminary results for subsequent studies on data-driven phenotyping and enable the realization of the PI's career goals by providing him with the necessary training to build on his machine learning and basic bioinformatics expertise to transition into an independent investigator in biomedical data science. PROJECT NARRATIVE Rare genetic diseases are estimated to affect the lives of 25 to 30 million Americans and their families, and present a significant economic burden on the healthcare system. Currently, our knowledge of the broad spectrum of the 7,000 observed rare diseases is limited to a few well-studied ones, hindering our ability to make correct and timely diagnoses. The objective of this study is to improve the identification of patients with rare diseases in healthcare systems by developing data science approaches that automatically recognize rare disease-related patterns in patient health records and correlate them with genomic data, thus, aiding in diagnosis and discovery.",Integrative data science approaches for rare disease discovery in health records,9645433,K99LM012992,"['Adult', 'Affect', 'American', 'Award', 'Basic Science', 'Behavioral', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Research', 'Computing Methodologies', 'Consensus', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostics Research', 'Disease', 'Economic Burden', 'Electronic Health Record', 'Environment', 'Faculty', 'Family', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Manuscripts', 'Markov Chains', 'Medical', 'Medical Genetics', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Pacific Northwest', 'Patient Recruitments', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Rare Diseases', 'Recording of previous events', 'Research', 'Research Personnel', 'Standardization', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Vocabulary', 'Washington', 'Work', 'accurate diagnosis', 'base', 'biomedical informatics', 'career', 'causal variant', 'clinical data warehouse', 'clinical decision-making', 'cohort', 'diagnostic accuracy', 'disease phenotype', 'early onset disorder', 'exome sequencing', 'gene discovery', 'genomic data', 'health care delivery', 'health data', 'health record', 'improved', 'member', 'multimodal data', 'novel', 'open source', 'phenotypic data', 'prototype', 'psychologic', 'rare condition', 'rare genetic disorder', 'recruit', 'skills', 'software development', 'support tools', 'tool', 'trait']",NLM,UNIVERSITY OF WASHINGTON,K99,2019,92070,0.05393994474112232
"A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications PROJECT SUMMARY/ABSTRACT  In radiology practices, timely and accurate formulation of reports is closely linked to patient satisfaction, physician productivity, and reimbursement. While the American College of Radiology and the Radiological Soci- ety of North America have recommended implementation of structured reporting to facilitate clear and consistent communication between radiologists and referring clinicians, cumbersome nature of current structured reporting systems made them unpopular amongst their users. Recently, the emerging techniques of deep learning have been widely and successfully applied in many different natural language processing tasks (NLP). However, when adopted in a certain specic domain, such as radiology, these techniques should be combined with extensive domain knowledge to improve efciency and accuracy. There is, therefore, a critical need to take advantage of clinical NLP and deep learning to fundamentally change the radiology reporting. The long-term goal in this appli- cation is to improve the form, content, and quality of radiology reports and to facilitate rapid generation of radiol- ogy reports with consistent organization and standardized texts. The overall objective is to use radiology-specic ontology, NLP and computer vision techniques, and deep learning to construct a radiology-specic knowledge graph, which will then be used to build a reporting system that can assist radiologists to quickly generate struc- tured and standardized text reports. The rationale for this project is that through integration of new clinical NLP technologies, radiology-specic knowledge graphs, and development of new reporting system, we can build au- tomatous systems with a higher-level understanding of the radiological world. The specic aims of this project are to: (1) recognize and normalize named entities in radiology reports; (2) construct a radiology-specic knowledge graph from free-text and images; and (3) build a reporting system that can dynamically adjust templates based on radiologists' prior entries. The research proposed in this application is innovative, in the applicant's opinion, because it combines deep learning, NLP techniques, and domain knowledge in a single framework to construct comprehensive and accurate knowledge graphs that will enhance the workow of the current reporting systems. The proposed research is signicant because a novel reporting system can expedite radiologists' workow and acquire well-annotated datasets that facilitate machine learning and data science. To develop such a method, the candidate, Dr. Yifan Peng, requires additional training and mentoring in clinical NLP and radiology. During the K99 phase, Dr. Peng will conduct this research as a research fellow at the National Center for Biotechnology Information. He will be mentored by Dr. Zhiyong Lu, a leading text mining and deep learning researcher, and co- mentored by Dr. Ronald M. Summers, a leading radiologist and clinical informatics researcher. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Peng to achieve the career goals of becoming an independent investigator and leader in the study of clinical NLP. PROJECT NARRATIVE The proposed research is relevant to public health because it entails a new strategy to construct a radiology- specic knowledge graph to facilitate the development of a new reporting system that enables rapid generation of structured radiology reports. The proposed knowledge graph and reporting system will contribute to advancement in understanding of the radiological world, and promise to enhance clinical communication and patient-centric care. Thus, the proposed research is relevant to the part of the NLM's mission that pertains to applying deep knowledge of clinical terminology and natural language processing to improve clinical data science and health services.",A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications,10197509,R00LM013001,"['Address', 'Adopted', 'American College of Radiology', 'Award', 'Biotechnology', 'Caring', 'Client satisfaction', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Communication', 'Complex', 'Computer Vision Systems', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Formulation', 'Generations', 'Goals', 'Health Services', 'Hospitals', 'Hybrids', 'Image', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Mission', 'Modeling', 'Mus', 'Names', 'Natural Language Processing', 'Nature', 'Nomenclature', 'North America', 'Ontology', 'Outcome', 'Pathway interactions', 'Patients', 'Phase', 'Physicians', 'Picture Archiving and Communication System', 'Process', 'Productivity', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resort', 'Societies', 'Standardization', 'Structure', 'System', 'Systems Development', 'Techniques', 'Technology', 'Terminology', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Voice', 'Writing', 'base', 'career', 'career development', 'convolutional neural network', 'deep learning', 'deep neural network', 'impression', 'improved', 'innovation', 'knowledge graph', 'lexical', 'long short term memory', 'neural network', 'neural network architecture', 'novel', 'radiologist', 'repository', 'response', 'syntax', 'text searching']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,R00,2020,236549,0.04538149477367343
"Automatic Generation of Computer Interpretable Guidelines PROJECT SUMMARY / ABSTRACT Compliance with clinical practice guidelines (CPGs) has been demonstrated to markedly improve patient care, but the tools and processes available for physicians to rapidly and meaningfully leverage these guidelines are currently sub-optimal. Compliance improves greatly with the introduction of clinical decision support systems (CDSS), which implement guideline recommendations and are integrated into electronic health record (EHR) systems. Unfortunately, CPGs, as commonly distributed, contain recommendations for care of only a single disorder (or class of disorders) and are not easily consumable by computers for integration with CDSS. Recent work has focused on methods to resolve conflicts between guidelines, but only once they are in a computer interpretable form - a Computer Interpretable Guideline (CIG). We aim: to (1) develop a system for computational understanding of CPGs from the unstructured text; (2) to ground the clinical terms in each guideline in its definition so that the produced CIG can better integrate with electronic health record systems; (3) to generate CIGs in a format already developed which allows guidelines to be mediated with each other and allows the creation of CDSS. The project will focus on four clinical guidelines, relating to diabetes, heart disease, non-small cell lung and prostate cancers. Samples of each of the guidelines will be annotated by clinicians with the appropriate output of systems accomplishing each of the three aims. These samples will be split into datasets for testing and for evaluation, with the overall goal to achieve human levels of competence for each aim. PROJECT NARRATIVE Clinical practice guidelines are paramount to the goals of evidence-based medicine but, being unstructured free text, they are not well integrated with clinician workflows and are not consistently adhered to. We aim to automatically generate computer interpretable versions of textual guidelines in a format which allows for automatic mediation between guidelines for patients with multiple morbidities. Mediated computer interpretable guidelines could then be integrated with electronic medical record systems, providing immediate impact on population health.",Automatic Generation of Computer Interpretable Guidelines,9654971,R15LM013030,"['Belief', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Practice Guideline', 'Competence', 'Complex', 'Computational Linguistics', 'Computational Technique', 'Computer software', 'Computerized Medical Record', 'Computers', 'Conflict (Psychology)', 'Data', 'Data Set', 'Diabetes Mellitus', 'Disease', 'Drug Prescriptions', 'Electronic Health Record', 'Evaluation', 'Evidence Based Medicine', 'Frequencies', 'Generations', 'Goals', 'Graph', 'Guidelines', 'Heart Diseases', 'Human', 'Knowledge', 'Language', 'Level of Evidence', 'Link', 'Malignant neoplasm of prostate', 'Manuals', 'Maps', 'Mediating', 'Mediation', 'Medical', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Non-Small-Cell Lung Carcinoma', 'Ontology', 'Output', 'Patient Care', 'Patients', 'Physicians', 'Positioning Attribute', 'Process', 'Recommendation', 'Research', 'Risk Factors', 'Sampling', 'Semantics', 'Source', 'Structure', 'Students', 'System', 'Techniques', 'Terminology', 'Testing', 'Text', 'Work', 'clinical care', 'clinical practice', 'computer generated', 'design', 'electronic structure', 'evidence base', 'experience', 'improved', 'novel', 'phrases', 'population health', 'prescription procedure', 'syntax', 'tool', 'undergraduate student']",NLM,COLLEGE AT OSWEGO,R15,2018,325760,0.019240764077374503
"Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance PROJECT SUMMARY The Center for Medicare and Medicaid Services Quality Payment Program is designed to motivate healthcare providers to adhere to best practices in clinical healthcare and patient safety. Unfortunately, extracting quality measures data from the clinical record is burdensome and as such, participation among clinical healthcare providers is suboptimal. Our aim is to develop a system to facilitate automatic extraction of quality data. This will reduce the burden of data collection and help remove the barrier to participation that keeps more providers from participating in the program. The proposed project, titled Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. We envision this to be an effective research partnership that leverages the complementary assets of SaferMD, a small business unit, and the University of Michigan, a non-profit research institution, to develop and evaluate a prototype tool to extract clinical quality measures data, and increase participation in the Quality Payment Program. PROJECT NARRATIVE The proposed project, titled Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. The project will develop algorithms to identify fields relevant for quality measures and develop tools to extract and analyze these data elements from large sets of radiology reports. Finally, the proposed work will initiate the extracted measures into existing quality service offerings by SaferMD. Successful completion of this project will advance the tools available for CMS clients to achieve higher adherence and compliance to the quality payment initiatives and help public health officials and policy developers advance the meaningful use of electronic health records.",Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance,9677579,R41LM013050,"['Address', 'Adherence', 'Algorithms', 'Benchmarking', 'Businesses', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Development', 'Disease', 'Documentation', 'Electronic Health Record', 'Elements', 'Experimental Models', 'Funding', 'Goals', 'Guidelines', 'Health Personnel', 'Healthcare', 'Human', 'Incentives', 'Institution', 'Label', 'Leadership', 'Manuals', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Policies', 'Procedures', 'Process', 'Production', 'Provider', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Role', 'Running', 'Semantics', 'Services', 'System', 'Techniques', 'Technology', 'Telephone', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Work', 'analytical tool', 'base', 'clinical practice', 'clinically relevant', 'computerized data processing', 'dashboard', 'deep neural network', 'design', 'improved', 'interest', 'novel', 'novel strategies', 'patient safety', 'payment', 'programs', 'prototype', 'success', 'technological innovation', 'tool']",NLM,"SAFERMED, LLC",R41,2018,149953,0.0726299537805507
"Big Data Methods for Comprehensive Similarity based Risk Prediction Project Summary Electronic health records (EHR) provide rich source of data about representative populations and are yet to be fully utilized to enhance clinical decision-making. Conventional approaches in clinical decision-making start with the identification of relevant biomarkers based on subject-matter knowledge, followed by detailed but limited analysis using these biomarkers exclusively. As the current scientific literature indicates, many human disorders share a complex etiological basis and exhibit correlated disease progression. Therefore, it is desirable to use comprehensive patient data for patient similarity. This proposal focuses on deriving a comprehensive and integrated score of patient similarity from complete patient characteristics currently available, including but not limited to 1) demographic similarity; 2) genetic similarity; 3) clinical phenotype similarity; 4) treatment similarity; and 5) exposome similarity (here exposome defined as all available attributes of the living environment an individual is exposed to), when some of the aspects may overlap and interact. We will optimize information fusion and task-dependent feature selection for assessing patient similarity for clinical risk prediction. Since currently there does not exist a pipeline that is able to extract executable complete patient determinant data, to achieve the research goal described above, we propose first deliver an open- source data preparation pipeline that is based on a widely used clinical data standard, the OMOP (Observational Medical Outcomes Partnership) Common Data Model (CMD) version 5.2. Moreover, to mitigate common missingness and sparsity challenges in clinical data, we describe the first attempt to represent patients' sparse clinical information with missingness, including diagnosis information, medication data, treatment intervention, with a fixed-length feature vector (i.e. the Patient2Vec). This project has four specific aims. Aim 1 is to develop a clinical data processing pipeline for harmonizing patient information from multiple sources into a standards-based uniformed data representation and to evaluate its efficiency, interoperability, and accuracy. Aim 2 is to leverage a powerful machine learning technique, Document2Vec, from the natural language processing literature, to create an open-source Patient2Vec framework for the derivation of informative numerical representations of patients. Aim 3 is to develop a unified machine learning clinical- outcome-prediction framework for Optimized Patient Similarity Fusion (OptPSF) that integrates traditional medical covariates with the derived numerical patient representations from Patient2Vec (Aim 2) for improved clinical risk prediction. Aim 4 is to evaluate our similarity framework for predicting 1) the risk of end-stage kidney disease (ESKD) in general EHR patient population and 2) the risk of death among patients with chronic kidney disease (CKD). The project focus on developing a novel data science pipeline which includes a clinical data processing pipeline to format comprehensive patient health determinants from a variety of sources of clinical, genomic, socioenvironmental data, and a clinical-outcome-prediction framework that optimally fuses relevant patient health determinants to define patient similarity for improved clinical risk predictions.",Big Data Methods for Comprehensive Similarity based Risk Prediction,9870948,R01LM013061,"['Address', 'Automation', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biological Process', 'Biometry', 'Case Study', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Data', 'Data Reporting', 'Data Science', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronic Health Record', 'End stage renal failure', 'Environment', 'Etiology', 'Exhibits', 'Exposure to', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Professional', 'Healthcare', 'Heterogeneity', 'Human', 'Individual', 'Informatics', 'Interdisciplinary Study', 'Intervention', 'Knowledge', 'Length', 'Life', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preparation', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Social Environment', 'Source', 'Surveys', 'Techniques', 'base', 'biomedical informatics', 'clinical decision support', 'clinical decision-making', 'clinical phenotype', 'clinical risk', 'data analysis pipeline', 'data modeling', 'data standards', 'design', 'disease diagnosis', 'feature selection', 'health data', 'improved', 'interoperability', 'mortality risk', 'novel', 'open data', 'open source', 'outcome prediction', 'patient health information', 'patient population', 'precision medicine', 'predict clinical outcome', 'socioeconomics', 'support tools', 'vector']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,420434,0.04061081853243373
"Big Data Methods for Comprehensive Similarity based Risk Prediction Project Summary Electronic health records (EHR) provide rich source of data about representative populations and are yet to be fully utilized to enhance clinical decision-making. Conventional approaches in clinical decision-making start with the identification of relevant biomarkers based on subject-matter knowledge, followed by detailed but limited analysis using these biomarkers exclusively. As the current scientific literature indicates, many human disorders share a complex etiological basis and exhibit correlated disease progression. Therefore, it is desirable to use comprehensive patient data for patient similarity. This proposal focuses on deriving a comprehensive and integrated score of patient similarity from complete patient characteristics currently available, including but not limited to 1) demographic similarity; 2) genetic similarity; 3) clinical phenotype similarity; 4) treatment similarity; and 5) exposome similarity (here exposome defined as all available attributes of the living environment an individual is exposed to), when some of the aspects may overlap and interact. We will optimize information fusion and task-dependent feature selection for assessing patient similarity for clinical risk prediction. Since currently there does not exist a pipeline that is able to extract executable complete patient determinant data, to achieve the research goal described above, we propose first deliver an open- source data preparation pipeline that is based on a widely used clinical data standard, the OMOP (Observational Medical Outcomes Partnership) Common Data Model (CMD) version 5.2. Moreover, to mitigate common missingness and sparsity challenges in clinical data, we describe the first attempt to represent patients' sparse clinical information with missingness, including diagnosis information, medication data, treatment intervention, with a fixed-length feature vector (i.e. the Patient2Vec). This project has four specific aims. Aim 1 is to develop a clinical data processing pipeline for harmonizing patient information from multiple sources into a standards-based uniformed data representation and to evaluate its efficiency, interoperability, and accuracy. Aim 2 is to leverage a powerful machine learning technique, Document2Vec, from the natural language processing literature, to create an open-source Patient2Vec framework for the derivation of informative numerical representations of patients. Aim 3 is to develop a unified machine learning clinical- outcome-prediction framework for Optimized Patient Similarity Fusion (OptPSF) that integrates traditional medical covariates with the derived numerical patient representations from Patient2Vec (Aim 2) for improved clinical risk prediction. Aim 4 is to evaluate our similarity framework for predicting 1) the risk of end-stage kidney disease (ESKD) in general EHR patient population and 2) the risk of death among patients with chronic kidney disease (CKD). The project focus on developing a novel data science pipeline which includes a clinical data processing pipeline to format comprehensive patient health determinants from a variety of sources of clinical, genomic, socioenvironmental data, and a clinical-outcome-prediction framework that optimally fuses relevant patient health determinants to define patient similarity for improved clinical risk predictions.",Big Data Methods for Comprehensive Similarity based Risk Prediction,9687065,R01LM013061,"['Address', 'Automation', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biological Process', 'Biometry', 'Case Study', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Data', 'Data Reporting', 'Data Science', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronic Health Record', 'End stage renal failure', 'Environment', 'Etiology', 'Exhibits', 'Exposure to', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Professional', 'Healthcare', 'Heterogeneity', 'Human', 'Individual', 'Informatics', 'Interdisciplinary Study', 'Intervention', 'Knowledge', 'Length', 'Life', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preparation', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Source', 'Surveys', 'Techniques', 'base', 'biomedical informatics', 'clinical decision support', 'clinical decision-making', 'clinical phenotype', 'clinical risk', 'computerized data processing', 'data modeling', 'design', 'disease diagnosis', 'health data', 'improved', 'interoperability', 'mortality risk', 'novel', 'open data', 'open source', 'outcome prediction', 'patient population', 'precision medicine', 'predict clinical outcome', 'socioeconomics', 'support tools', 'vector']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,448622,0.04061081853243373
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,9930152,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2020,20000,0.08138302174504909
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,9759499,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2019,20000,0.08138302174504909
"Improve medical decision making in emergency medicine via a new interface to visualize and understand relevant prior history for complex patients at the point-of-care. PROJECT SUMMARY/ABSTRACT Patient Insight is working to drive more informed medical decisions by designing a real-time interface that dynamically captures and presents prior history for complex patients in less time and with more completeness than using their electronic health record (EHR) system. The company is developing proprietary data mining and natural language processing algorithms that show promise for identifying, aggregating, and displaying the most essential EHR data for patients with complex conditions while at the same time working with clinicians to design the visual interface to reduce the cognitive burden and support diagnosis and treatment decisions. The specific goals of this phase I project are to test the feasibility of developing Patient Insights core solution to (1) use advanced analytics and natural language processing to mine and prioritize the most relevant information for use by (ED) physicians and (2) develop an clinician-informed, visual display of that essential information to timely support clinical decision-making sufficient to reduce medical errors, improve health, and control costs. In phase I, Patient Insight will work with Universal Health Systems, the parent company of George Washington University Hospital, to co-develop and test the platform for efficacy in the ED as a precursor to continued development of this core solution/product. This will involve using EHR data to assess comprehensiveness to reconstruct history for five groups of chronically ill patients (e.g., advanced cancer, coronary heart disease, insulin-dependent diabetes, chronic pain, and schizophrenia) who are admitted with high-frequency chief complaints of abdominal pain, chest pain, and fever. This will include mining, prioritizing, and presenting information to clinicians using a total of 30 dimensions of data regarding patients prior ED and hospital visits including both structured (e.g., diagnosis, medications, labs, imaging test types, EKG date/time) and unstructured data (e.g., images, physician notes, consult notes) to establish physician consensus on the data most valuable to medical decision-making and co-design data visualization tools to render a clear patient history. Our aims include: (Aim 1) Establishing the feasibility of leveraging provider-as-user-centered design to guide development of a data visualization platform that enables providers to readily see the most complete patient record for the five groups of complex patients, and (Aim 2) Conducting usability testing and compare the completeness and efficiency of using the enhanced platform on the five patient categories with usual care. Success in phase I will enable the company to validate a proof of concept for developing its clinician-as-user-centered design process to inform a phase II research and development effort to design a commercially viable clinical decision support tool for hospitals and health systems. PROJECT NARRATIVE Patient Insight seeks to determine the feasibility of its proposed platform to aggregate and present the clearest picture possible of a patients history for time-constrained emergency department (ED) providers sufficient to drive improved medical decision-making, safety, and improved health outcomes for complex patients at the point-of-care and across disparate EHR systems. The strategy is to leverage our capability to extract discreet and unstructured data from select EHR systems and engage providers in the design of key elements of information display to reduce duplicate testing, lower medical errors related to misinformed treatment choices, and reduce unnecessary treatment and costs. Proving feasibility will enable Patient Insight to structure a partnership with Universal Health Services and inform further development and testing of its core solution across multiple ED facilities.",Improve medical decision making in emergency medicine via a new interface to visualize and understand relevant prior history for complex patients at the point-of-care.,9778547,R43LM013130,"['Abdominal Pain', 'Accident and Emergency department', 'Adoption', 'Advanced Malignant Neoplasm', 'Algorithms', 'Automated Clinical Decision Support', 'Award', 'Caring', 'Categories', 'Chest Pain', 'Chronically Ill', 'Clinical', 'Cognitive', 'Communities', 'Comorbidity', 'Complex', 'Consensus', 'Consult', 'Coronary heart disease', 'Cost Control', 'Critical Illness', 'Data', 'Data Display', 'Data Element', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Electrocardiogram', 'Electronic Health Record', 'Elements', 'Emergency Medicine', 'Environment', 'Event', 'Fever', 'Frequencies', 'Goals', 'Grant', 'Health', 'Health Services', 'Health system', 'Hospitalization', 'Hospitals', 'Iatrogenesis', 'Image', 'Imagery', 'Inpatients', 'Insulin-Dependent Diabetes Mellitus', 'Intuition', 'Medical', 'Medical Errors', 'Medical History', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Output', 'Parents', 'Patients', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Primary Health Care', 'Process', 'Provider', 'Psyche structure', 'Recording of previous events', 'Records', 'Research', 'Safety', 'Schizophrenia', 'Small Business Innovation Research Grant', 'Software Engineering', 'Structure', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Treatment Cost', 'Universities', 'University Hospitals', 'Visit', 'Visual', 'Visualization software', 'Washington', 'Work', 'chronic pain', 'clinical decision support', 'clinical decision-making', 'cognitive load', 'cost', 'cost effective', 'data mining', 'data visualization', 'design', 'health information technology', 'improved', 'information display', 'innovation', 'insight', 'interoperability', 'medical specialties', 'novel', 'opioid misuse', 'point of care', 'research and development', 'stem', 'success', 'support tools', 'tool', 'treatment as usual', 'treatment choice', 'unnecessary treatment', 'usability', 'user centered design']",NLM,"PATIENT INSIGHT, INC.",R43,2019,155520,-0.03880689981127768
"Developing scalable algorithms to incorporate unstructured electronic health records for causal inference based on real-world data Project Summary/Abstract The routine operation of the US Healthcare system produces an abundance of electronically-stored data that captures the care of patients as it is provided in settings outside of controlled research environments. The potential for utilizing these data to inform future treatment choices and improve patient care and outcomes of all patients in the very system that generates the data is widely acknowledged. Given these key properties of the routine-care data and the abundance of electronic healthcare databases covering millions of patients, it is critical to strengthen the rigor of analyses of such data. Our group has previously developed an analytic approach to reduce bias when analyzing routine-care databases, which has proven effective in more than 50 empirical research studies across a range of topics and data sources. However, this approach currently cannot incorporate free-text information that is recorded in electronic health records, such as clinical notes and reports. This limitation has left a large amount of rich patient information underutilized for clinical research. We thus aim to adapt and refine a set of established computerized natural language processing algorithms that can identify and extract useful information from the clinical notes and reports in electronic health records and incorporate them into our validated analytical approach for balancing background risks of different comparison groups, a key step to ensure fair evaluation when comparing different therapeutic options. To test this newly integrated and augmented approach, we will implement and adapt it in simulation studies where we can evaluate and improve the performance of these new analytic methods in a controlled but realistic fashion. In addition, we will assess the performance of our new approach in 8 practical studies comparing medical or surgical treatments that are highly relevant to patients. To ensure highest level of data completeness and quality, we have linked multiple healthcare utilization (claims) databases, spanning from 2007 to 2016, with 3 electronic health records systems, including one each in Massachusetts, North Carolina, and Texas. This data will allow testing of our newly integrated approach in a variety of care delivery systems and data environments, which will be very informative for the application of our products in the real-world settings. Narrative The project will yield a highly flexible and effective analytical method for reducing confounding bias in studies that utilize routine-care data to compare effects of medical or surgical treatments. This method will enable researchers to leverage a large amount of patient information recorded in the clinical notes and reports that are contained within electronic health records to adjust for differences in background risks of different comparison groups. Our proposal can improve the quality of evidence based on electronic healthcare data generated in the routine-care settings to better inform patient care and optimal prescribing.",Developing scalable algorithms to incorporate unstructured electronic health records for causal inference based on real-world data,9970594,R01LM013204,"['Address', 'Algorithms', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Comparative Effectiveness Research', 'Complex', 'Confounding Factors (Epidemiology)', 'Consumption', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Disease', 'Electronic Health Record', 'Elements', 'Empirical Research', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Future', 'Gold', 'Healthcare', 'Healthcare Systems', 'Influentials', 'Knowledge', 'Knowledge acquisition', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Massachusetts', 'Medical', 'Medicare/Medicaid', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'North Carolina', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Probability', 'Property', 'Proxy', 'Randomized Controlled Trials', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Risk Factors', 'Semantics', 'Severities', 'Specific qualifier value', 'Stratification', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Texas', 'Text', 'Therapeutic', 'Time', 'Training', 'Treatment outcome', 'Validation', 'Weight', 'Work', 'analytical method', 'base', 'care delivery', 'care outcomes', 'comparative effectiveness', 'comparison group', 'computerized', 'cost', 'disorder risk', 'evidence base', 'flexibility', 'health care service utilization', 'high dimensionality', 'improved', 'innovation', 'machine learning method', 'novel strategies', 'operation', 'outcome forecast', 'preservation', 'randomized trial', 'research study', 'routine care', 'safety study', 'simulation', 'sound', 'structured data', 'tool', 'treatment choice', 'unstructured data']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,469927,0.07733109342746292
"Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction Project Summary/Abstract Electronic Health Records (EHRs) contain significant information that can benefit many downstream uses. However, most of this information is in unstructured narrative form and is inaccessible to computerized methods that rely on structured representations for exploring, retrieving, and presenting the information. Natural language processing (NLP) and information extraction (IE) open this trove of information to studies that would otherwise be without. Over the past decades, many IE systems have been developed. These systems have typically focused on one task at a time. In addition, most have studied only specific types of records, e.g., discharge summaries, and addressed their task on data from a single institution. Performances achieved by the state-of-the-art IE systems developed under these conditions ranged from 44% F-measure to 99% F-measure. This observed variation can be attributed to the nature of the tasks: some target entities like dates tend to be better represented in the data and also more rigidly stick to known patterns of expression as opposed to reasons for medication administration which are relatively sparse in the data and can show wider linguistic diversity. However, this may not be the only reason: the data used can also explain the performance variation. Narratives of EHRs vary in their style, format, and content going from one department to another, from one hospital to another. Even the same record type in two different hospitals can be very different in narrative style and pose different challenges for IE. Understanding IE performance therefore requires studies of multiple tasks on multiple record types that come from multiple institutions. One major bottleneck for evaluation of IE systems on such a large scale is annotation. The same bottleneck also limits system development. This proposal aims to address this bottleneck for both evaluation and development. It first generates a multi-institution corpus consisting of multiple record types from five institutions. It studies four different IE tasks that broadly represent IE in clinical records and can inform the field of IE as a whole: de-identification, clinical concept extraction, medication extraction, and adverse drug event extraction. Within the context of these IE tasks, the proposal then puts forward methods that learn from unlabeled or pseudo data that can help alleviate reliance on annotated data for development. It evaluates these methods both for performance and generalizability on multiple types of records from multiple institutions. As a result of these activities, this proposal generates de-identified data, annotations, methods, software, and machine learning models which it then makes available to the research community. Project Narrative Information extraction (IE) systems, i.e., natural language processing (NLP) systems that enable creation of accurate semantic representations of narratives, rely heavily on the availability of gold standard annotated corpora and vary significantly in their performance from task to task, and from data set to data set. We propose methods that augment gold standard data with unlabeled data that are more easily available, and pseudo data which can be derived from gold standard data. We study IE within the context of four tasks and evaluate IE systems enhanced with unlabeled and pseudo data for generalizability on a heterogeneous data set consisting of multiple record types from five institutions.",Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction,9813134,R15LM013209,"['Accident and Emergency department', 'Address', 'Adverse drug event', 'Affect', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Discipline of Nursing', 'Electronic Health Record', 'Engineering', 'Evaluation', 'Frequencies', 'Gold', 'Growth', 'Healthcare', 'Hospitals', 'Institution', 'Israel', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nature', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Plant Roots', 'Procedures', 'Psychiatry', 'Publications', 'Records', 'Reporting', 'Research', 'Resources', 'Route', 'Sampling', 'Semantics', 'Signs and Symptoms', 'Social Work', 'Structure', 'Supervision', 'System', 'Systems Development', 'Task Performances', 'Telephone', 'Test Result', 'Testing', 'Text', 'Thinness', 'Time', 'Training', 'Universities', 'Variant', 'Virginia', 'Washington', 'computerized', 'deep learning', 'dosage', 'field study', 'improved', 'learning strategy', 'medication administration', 'novel', 'open source', 'response', 'supervised learning', 'tool']",NLM,GEORGE MASON UNIVERSITY,R15,2019,414798,0.023937426819986757
"Learning Health System Building Blocks: Filling Gaps to Enable a Real Time Physician-AI Partnership PROJECT SUMMARY/ABSTRACT Over 54% of doctors are experiencing burnout and the primary cause is documentation. Doctors spend up to two hours on clerical work for each hour of direct patient care. Documentation burden is the number one contributor to burnout, which costs the US health care system approximately $150 billion each year. Further, the largely free-text notes generated by healthcare providers are difficult to process and re-use for quality improvement and research. There is a significant opportunity to A) reduce clinicians' clerical burden via ambient data collection while B) enabling incorporation of machine learning into routine clinical care by structuring information in real-time from the patient-doctor conversation. We have built a service that saves each clinician hours per day by using remote human scribes, who we make more efficient with machine learning and natural language processing, to automatically document patient visits. The service runs on a laptop or mobile device and converts patient-clinician conversation audio to structured documentation. Our approach has already enabled the service to be priced at half the cost of a traditional in- person scribe. Finalized notes can be saved into all common electronic health record (EHR) systems via the Redox interoperability interface. We will use the human-curated audio-to-structured documentation dataset to further improve preprocessing, automating more of the scribing process, and reducing human effort over time. A time motion study and EHR click log analysis in a clinical setting demonstrated time savings of up to two hours per clinician per day. We have successfully generated documentation for over 1,700 patient visits and our dataset will double in size in 2 months. In Phase I, we address key impediments in the structure and timeliness of current EHR data, both of which can be improved with our novel system when coupled with the real-time generation of machine learning-ready inputs. In order to do so, we propose three aims: 1) extract machine learning-ready inputs from patient-doctor conversation audio; 2) extract machine learning-ready inputs from structured and unstructured EHR data; 3) further increase cost-efficiency and scale up the quality assurance process using machine learning inputs from conversation audio and historical EHR data. For Phase II we will apply our machine learning inputs to predict disease trajectory for multiple disease phenotypes with a focus on type 2 diabetes mellitus and hypertension. These diseases are ideal proofs-of- concept due to their high prevalence, morbidity, and inclusion in incentive programs for closing care gaps. The $6.3B in 2018 Medicare Advantage incentives supports a clear business case for leveraging machine learning to achieve value-based goals  improving patient care quality and efficiency.! PROJECT NARRATIVE PredictionHealth has built a service to reduce doctor burnout by automatically documenting patient visits by processing audio from the normal patient-doctor conversation - potentially reducing the $150 billion dollar cost of burnout on the US health system. We propose that integrating and facilitating the application of machine learning in routine clinical care can improve patient care outcomes and efficiency. The primary goal of this Phase I proposal is to further improve the service's cost-efficiency with real-time machine learning predictions based on structured inputs from the patient-doctor conversation and prepare to integrate machine learning as an integral element of each doctor's toolbox.",Learning Health System Building Blocks: Filling Gaps to Enable a Real Time Physician-AI Partnership,10009209,R43LM013215,"['Address', 'Affect', 'Age', 'Benchmarking', 'Blood Pressure', 'Businesses', 'Caregivers', 'Caring', 'Clinical', 'Complication', 'Cost efficiency', 'Coupled', 'Data', 'Data Collection', 'Data Set', 'Disease', 'Documentation', 'Electronic Health Record', 'Elements', 'Ensure', 'Foundations', 'Generations', 'Goals', 'Gold', 'Health Personnel', 'Health system', 'Healthcare Systems', 'High Prevalence', 'Hour', 'Human', 'Hypertension', 'Incentives', 'Individual', 'Infrastructure', 'Language', 'Learning', 'Link', 'Machine Learning', 'Manuals', 'Medical', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Outcome', 'Oxidation-Reduction', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Persons', 'Phase', 'Physicians', 'Population', 'Predictive Value', 'Price', 'Primary Health Care', 'Process', 'Quality of Care', 'Recording of previous events', 'Research', 'Resources', 'Rheumatoid Arthritis', 'Risk', 'Role', 'Running', 'Savings', 'Services', 'Structure', 'Surface', 'System', 'Text', 'Time', 'Time and Motion Studies', 'Training', 'Validation', 'Vision', 'Visit', 'Work', 'base', 'burnout', 'care outcomes', 'clinical care', 'clinical predictors', 'clinical risk', 'cost', 'cost effectiveness', 'direct patient care', 'disease phenotype', 'electronic structure', 'experience', 'handheld mobile device', 'improved', 'incentive program', 'insight', 'interoperability', 'laptop', 'novel', 'payment', 'phase 2 study', 'phenotyping algorithm', 'quality assurance', 'scale up', 'sex', 'social', 'treatment planning']",NLM,PREDICTION HEALTH INC.,R43,2020,222130,0.05461646105768252
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., proteinprotein interactions) to translational bioinformatics (e.g., genedisease associations), and eventually to clinical care (e.g., drugdrug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classication (RC) as subtasks. They typically suffer from error snowballing  errors in a component of the pipeline leading to more downstream errors  resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drugdisease treatment relations and another rst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are rst disclosed in textual narratives (scientic literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10052028,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2020,358691,0.014949885525007077
"Outcome-driven Order Set Content Development, Management, and Evaluation Project Summary Candidate Goals and Objectives: With a background in Information Systems and Management, and Biostatistics, Dr. Zhang has demonstrated research records on electronic health record data mining to identify patterns of healthcare delivery that may be used to inform patient-centered and evidence-based healthcare. The proposal will provide additional training for Dr. Zhang on advanced machine learning, statistics, and evaluation methods in biomedical informatics for applications on clinical decision support (CDS). Dr. Zhang's long-term goal is to bringing innovation CDS development and evaluation through novel biomedical informatics and data science techniques. Institutional Environment and Career Development: Weill Cornell Medicine (WCM) provides ideal research facilities and training environment for Dr. Zhang. Dr. Jyotishman Pathak, Chief of Division of Health Informatics at Department of Health Policy and Research, will lead a multidisciplinary team of mentors: Drs. Jessica Ancker and Fei Wang at WCM, and Dr. Adam Wright at Harvard Medical School. Dr. Zhang also has collaborators in WCM and NewYork-Presbyterian Hospital who will support her in her training and research activities and provide clinical expertise. Research Aims Order sets are a type of CDS in computerized provider order entry (CPOE) to standardize decision making in the ordering process and encourage compliance with clinical practice guidelines. Previous literature on order set use has focused its effect on usability, workload, and physician satisfaction, but a knowledge gap remains with respect to the effect of order sets on care outcomes. The overall goal of the research study is to create a continuous improvement cycle for order sets with respect to a care outcome by rigorously learning from data. Aim 1 of the study will apply computational phenotyping and subtyping algorithms to identify cohorts of heart failure (HF) subtypes. Aim 2 will evaluate an existing order set intended for the care of HF patients on a care outcome defined as 30-day all-cause, unplanned readmission with a hypothesis that the use of this order set is associated with a better outcome. This will be achieved by building a range of outcome prediction models and evaluating the strength of each order set order as a predictor. Aim 3 will optimize the existing order sets using a metaheuristic optimization method such that its content collectively may have the largest positive effect on the outcome of 30-day all-cause unplanned readmission. The effects of order set use on the care outcome is measured using a causal inference technique in each iteration. The expected outcome is a framework to develop and evaluate HF order sets which may eventually be generalized to other clinical areas. Training from this proposal may lead to multi-site R01 studies of outcome-driven HF order sets and actual implementations. Project Narrative In this study, we propose a continuous improvement cycle to develop, manage, and evaluate outcome-driven order sets, a type of clinical decision support (CDS) for computerized provider order entry (CPOE). Mentorship and training include advanced statistics, machine learning, and evaluation methods in biomedical informatics. The proposed research will leverage the principal investigator (PI)'s background in methodology development and health information systems to provide the PI with additional training to innovate outcome-driven CDS for CPOE.","Outcome-driven Order Set Content Development, Management, and Evaluation",10018097,K01LM013257,"['Address', 'Algorithms', 'Area', 'Biological Markers', 'Biometry', 'Caring', 'Clinical', 'Clinical Pathways', 'Clinical Practice Guideline', 'Data', 'Data Science', 'Decision Making', 'Development', 'Disease', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Goals', 'Health Information System', 'Health Policy', 'Healthcare', 'Heart failure', 'Hospitalization', 'Hospitals', 'Human', 'Information Management', 'Information Systems', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Logistic Regressions', 'Machine Learning', 'Management Information Systems', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Outcome Study', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Policy Research', 'Presbyterian Church', 'Principal Investigator', 'Procedures', 'Process', 'Provider', 'Public Health Informatics', 'Randomized Clinical Trials', 'Records', 'Reporting', 'Research', 'Research Activity', 'Research Training', 'Role', 'Site', 'Standardization', 'Structural Models', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Training Activity', 'Variant', 'Work', 'Workload', 'base', 'biomedical informatics', 'care outcomes', 'career development', 'clinical decision support', 'clinical decision-making', 'cohort', 'comorbidity', 'computerized', 'computerized physician order entry', 'data mining', 'demographics', 'design', 'evidence base', 'health care delivery', 'health care service organization', 'hospital readmission', 'improved', 'improved outcome', 'individual patient', 'innovation', 'inpatient service', 'long short term memory', 'medical schools', 'multidisciplinary', 'multilayer perceptron', 'neural network algorithm', 'novel', 'outcome prediction', 'patient oriented', 'patient subsets', 'personalized decision', 'phenotyping algorithm', 'predictive modeling', 'random forest', 'recurrent neural network', 'research facility', 'research study', 'satisfaction', 'social health determinants', 'statistical and machine learning', 'statistics', 'success', 'support vector machine', 'usability', 'validation studies']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,K01,2020,180368,0.028188374843641745
"Outcome-driven Order Set Content Development, Management, and Evaluation Project Summary Candidate Goals and Objectives: With a background in Information Systems and Management, and Biostatistics, Dr. Zhang has demonstrated research records on electronic health record data mining to identify patterns of healthcare delivery that may be used to inform patient-centered and evidence-based healthcare. The proposal will provide additional training for Dr. Zhang on advanced machine learning, statistics, and evaluation methods in biomedical informatics for applications on clinical decision support (CDS). Dr. Zhang's long-term goal is to bringing innovation CDS development and evaluation through novel biomedical informatics and data science techniques. Institutional Environment and Career Development: Weill Cornell Medicine (WCM) provides ideal research facilities and training environment for Dr. Zhang. Dr. Jyotishman Pathak, Chief of Division of Health Informatics at Department of Health Policy and Research, will lead a multidisciplinary team of mentors: Drs. Jessica Ancker and Fei Wang at WCM, and Dr. Adam Wright at Harvard Medical School. Dr. Zhang also has collaborators in WCM and NewYork-Presbyterian Hospital who will support her in her training and research activities and provide clinical expertise. Research Aims Order sets are a type of CDS in computerized provider order entry (CPOE) to standardize decision making in the ordering process and encourage compliance with clinical practice guidelines. Previous literature on order set use has focused its effect on usability, workload, and physician satisfaction, but a knowledge gap remains with respect to the effect of order sets on care outcomes. The overall goal of the research study is to create a continuous improvement cycle for order sets with respect to a care outcome by rigorously learning from data. Aim 1 of the study will apply computational phenotyping and subtyping algorithms to identify cohorts of heart failure (HF) subtypes. Aim 2 will evaluate an existing order set intended for the care of HF patients on a care outcome defined as 30-day all-cause, unplanned readmission with a hypothesis that the use of this order set is associated with a better outcome. This will be achieved by building a range of outcome prediction models and evaluating the strength of each order set order as a predictor. Aim 3 will optimize the existing order sets using a metaheuristic optimization method such that its content collectively may have the largest positive effect on the outcome of 30-day all-cause unplanned readmission. The effects of order set use on the care outcome is measured using a causal inference technique in each iteration. The expected outcome is a framework to develop and evaluate HF order sets which may eventually be generalized to other clinical areas. Training from this proposal may lead to multi-site R01 studies of outcome-driven HF order sets and actual implementations. Project Narrative In this study, we propose a continuous improvement cycle to develop, manage, and evaluate outcome-driven order sets, a type of clinical decision support (CDS) for computerized provider order entry (CPOE). Mentorship and training include advanced statistics, machine learning, and evaluation methods in biomedical informatics. The proposed research will leverage the principal investigator (PI)'s background in methodology development and health information systems to provide the PI with additional training to innovate outcome-driven CDS for CPOE.","Outcome-driven Order Set Content Development, Management, and Evaluation",9871053,K01LM013257,"['Address', 'Algorithms', 'Area', 'Biological Markers', 'Biometry', 'Caring', 'Clinical', 'Clinical Pathways', 'Clinical Practice Guideline', 'Comorbidity', 'Data', 'Data Science', 'Decision Making', 'Development', 'Disease', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Goals', 'Health Information System', 'Health Policy', 'Healthcare', 'Heart failure', 'Hospitalization', 'Hospitals', 'Human', 'Information Management', 'Information Systems', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Logistic Regressions', 'Machine Learning', 'Management Information Systems', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Outcome Study', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Policy Research', 'Presbyterian Church', 'Principal Investigator', 'Procedures', 'Process', 'Provider', 'Public Health Informatics', 'Randomized Clinical Trials', 'Records', 'Reporting', 'Research', 'Research Activity', 'Research Training', 'Role', 'Site', 'Standardization', 'Structural Models', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Training Activity', 'Variant', 'Work', 'Workload', 'base', 'biomedical informatics', 'care outcomes', 'career development', 'clinical decision support', 'clinical decision-making', 'cohort', 'computerized', 'computerized physician order entry', 'data mining', 'demographics', 'design', 'evidence base', 'health care delivery', 'health care service organization', 'hospital readmission', 'improved', 'improved outcome', 'individual patient', 'innovation', 'inpatient service', 'long short term memory', 'medical schools', 'multidisciplinary', 'multilayer perceptron', 'neural network algorithm', 'novel', 'outcome prediction', 'patient oriented', 'patient subsets', 'personalized decision', 'predictive modeling', 'random forest', 'recurrent neural network', 'research facility', 'research study', 'satisfaction', 'social health determinants', 'statistics', 'success', 'usability', 'validation studies']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,K01,2019,184191,0.028188374843641745
"Collaborative Research: Statistical Algorithms for Anomaly Detection and Patterns Recognition in Patient Care and Safety Event Reports Project Summary Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter is not constrained to limited categories or selection options and is able to freely describe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) Identifying document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. The COVID-19 pandemic has resulted in increased patient volumes and increased patient acuity, leading to an excessive burden on many healthcare facilities across the United States. This greatly increases the risk of patient safety consequences arising from malfunctioning medical equipment or adverse reaction to medication. To ensure patient safety and the highest quality of healthcare during this crisis, we need a rapid response system to model and analyze COVID-specific safety issues at scale, and quickly disseminate the results to healthcare facilities, so that these risks can be mitigated at the point of care. In this supplement, we propose to do this by (a) mining public databases and EHRs to identify devices/medication being used for treating COVID and (b) applying our methods (based on NLP, SPC, and SPM) to understand risks associated with these items. This information will be disseminated nationally to all healthcare facilities so that it can be integrated into the EHR at the point of care to alert clinicians. Project Narrative Estimates of preventable adverse events in healthcare are staggering, and the risk is particularly high for COVID patients due to the rapidly increasing burden on healthcare facilities. Using our algorithms to identify temporal trends and analyze free text narratives from reporting systems can ensure the safety and quality of care for COVID patients by exposing and mitigating possible weaknesses in the care process.",Collaborative Research: Statistical Algorithms for Anomaly Detection and Patterns Recognition in Patient Care and Safety Event Reports,10254593,R01LM013309,"['Address', 'Adverse event', 'Adverse reactions', 'Algorithms', 'Architecture', 'Behavior', 'COVID-19 pandemic', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Detection', 'Deterioration', 'Devices', 'Disease Outbreaks', 'English Language', 'Ensure', 'Equipment', 'Equipment Malfunction', 'Event', 'Goals', 'Health', 'Health care facility', 'Healthcare', 'Institute of Medicine (U.S.)', 'Interest Group', 'Intervention', 'Investigation', 'Lead', 'Length', 'Measures', 'Medical', 'Medical Errors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Natural Language Processing', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Prevalence', 'Process', 'Property', 'Quality of Care', 'Records', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Severities', 'Side', 'Site', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'Statistical Models', 'Supervision', 'System', 'Techniques', 'Text', 'Time', 'Time trend', 'United States', 'Variant', 'Vocabulary', 'adverse outcome', 'base', 'checkup examination', 'cluster computing', 'coronavirus disease', 'dosage', 'hazard', 'health care quality', 'health care service', 'health care service organization', 'improved', 'insight', 'interest', 'mathematical model', 'novel', 'open source', 'patient safety', 'point of care', 'response', 'service delivery', 'spatiotemporal', 'structured data', 'trend', 'unstructured data']",NLM,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2020,74963,0.07390029126246873
"Collaborative Research: Statistical algorithms for anomaly detection and patterns recognition in patient care and safety event reports Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. Numerous healthcare providers have adopted these systems, which provide a framework for healthcare provlder staff to report patient safety events. Public databases like MAUDE and VAERS have also been created to collect and trend safety events across healthcare systems. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter ls not constrained to limited categories or selection options and is able to freely descrlbe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) ldentifylng document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. An important advantage of our research team is the involvement of healthcare domain experts and access to frontline staff, and we will leverage this strength to develop our algorithms. A key feature of our work is the generalizability of our methods, which will be applicable to biomedical documents arising across a remarkable variety of areas, such as patient safety and equipment malfunction reports, electronic health records, adverse drug or vaccine reports, etc. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. Estimates of preventable adverse events in healthcare are staggering, despite the frequently cited Institute of Medicine (IOM) report that first brought attention to the problem over ten years ago. Identifying temporal trends and patterns in the data is particularly important to improving patient safety and patient care. Using our algorithms to effectively analyze documents from reporting systems has the potential to dramatically improve the safety and quality of care by exposing possible weaknesses in the care process.",Collaborative Research: Statistical algorithms for anomaly detection and patterns recognition in patient care and safety event reports,10211805,R01LM013309,"['Address', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Attention', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Deterioration', 'Electronic Health Record', 'Equipment Malfunction', 'Event', 'Goals', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Institute of Medicine (U.S.)', 'Interest Group', 'Intervention', 'Lead', 'Medical Errors', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Process', 'Quality of Care', 'Report (document)', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'System', 'Text', 'Time', 'Time trend', 'United States', 'Vaccines', 'Work', 'adverse outcome', 'hazard', 'improved', 'novel', 'open source', 'patient safety', 'spatiotemporal', 'structured data', 'trend', 'unstructured data']",NLM,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2020,278731,0.06953728278148658
"Collaborative Research: Statistical algorithms for anomaly  detection and patterns recognition in patient care and safety event reports     Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. Numerous healthcare providers have adopted these systems, which provide a framework for healthcare provlder staff to report patient safety events. Public databases like MAUDE and VAERS have also been created to collect and trend safety events across healthcare systems. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter ls not constrained to limited categories or selection options and is able to freely descrlbe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) ldentifylng document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. An important advantage of our research team is the involvement of healthcare domain experts and access to frontline staff, and we will leverage this strength to develop our algorithms. A key feature of our work is the generalizability of our methods, which will be applicable to biomedical documents arising across a remarkable variety of areas, such as patient safety and equipment malfunction reports, electronic health records, adverse drug or vaccine reports, etc. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. Estimates of preventable adverse events in healthcare are staggering, despite the frequently cited Institute of Medicine (IOM) report that first brought attention to the problem over ten years ago. Identifying temporal trends and patterns in the data is particularly important to improving patient safety and patient care. Using our algorithms to effectively analyze documents from reporting systems has the potential to dramatically improve the safety and quality of care by exposing possible weaknesses in the care process.",Collaborative Research: Statistical algorithms for anomaly  detection and patterns recognition in patient care and safety event reports    ,9914443,R01LM013309,"['Address', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Attention', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Deterioration', 'Electronic Health Record', 'Equipment Malfunction', 'Event', 'Goals', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Institute of Medicine (U.S.)', 'Instruction', 'Interest Group', 'Intervention', 'Lead', 'Medical Errors', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Process', 'Quality of Care', 'Report (document)', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'Structure', 'System', 'Text', 'Time', 'Time trend', 'United States', 'Vaccines', 'Work', 'adverse outcome', 'hazard', 'improved', 'novel', 'open source', 'patient safety', 'spatiotemporal', 'trend']",NLM,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2019,279001,0.06953728278148658
"SCH: INT Re-envisioned Chat-assessment for Real-time Investigating of Nursing and Guidance  Two decades have lapsed since the seminal publications of the National Academy of Medicine (formerly the Institute of Medicine), To Err Is Human and Crossing the Quality Chasm, cast a national spotlight on health-care safety and quality, yet US patient outcome indices continue to lag behind those in other industrialized countries. The 2009 American Recovery and Reinvestment Act mandated health-care providers adopt electronic health record (EHR) systems, leading to widespread EHR adoption, albeit primarily for billing purposes rather than research or quality improvement efforts. Thus EHR impact on health-care quality has tended to be in the domains of physician efficiency and guideline compliance. Despite a large body of evidence that nursing quality is directly related to patient outcomes in the acute care selling, nurses often lack timely information to use in improving individual patient outcomes, and indices of outcomes across patient populations are slow to budge over lime. Widespread adoption of EHRs in U.S. hospitals now allows determination of outcome quality indicators for all patients in a hospital for real-time feedback to nurses. Quality indicators are often only determined by piecing together other information to determine occurrence of an incident, e.g., exhuming information buried in nursing notes. The goal is to develop Chart-assessment for Real-lime Investigation of Nursing and Guidance (CARING), an automated machine learning system to report and predict nursing quality indicators in real-time for hospitalized patients to assist nurses in care planning. CARI NG will reflect algorithmic innovations to mine sequential patterns from multi-sourced, heterogeneous data including nursing narratives, yielding robust predictive models that are insensitive to uncertain labels and evolve with changes in health-care practices. CARING will represent EHR data using inter-connected tensors, capturing higher-order relations, temporal weighting, i.e., more recent data receives more weight, and incorporating domain expert feedback in development. Although CARING will be developed initially for the ten hospitals of our industry partner Emory Healthcare, its flexible refinement will enable adaptation at other health-care institutions. Outcomes of this project will give nurses actionable data in real time to improve nursing care quality that they do not receive now. Moreover, this system can be implemented into the health information infrastructure at an institutional level, integrating multi-scale and multi-level clinical, contextual, and organizational data surrounding each patient for real-time reporting and incorporation into predictive models. CARING supports the National Library of Medicine mission 1) by creating an innovative open source suite of tools for advancing patient safety; and 2) through educational efforts: training graduate students and fellows, and developing a Massive Open Online Course (MOOG), ""Big Data Analytics for Nursing,"" covering topics at the confluence of computer science, nursing, and patient outcome quality indicators. CARING will improve nursing care quality and make direct, positive impacts on patients, their families, and caregivers.",SCH: INT Re-envisioned Chat-assessment for Real-time Investigating of Nursing and Guidance ,10018103,R01LM013323,"['Academy', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Area', 'Big Data', 'Big Data Methods', 'Care given by nurses', 'Caring', 'Clinical', 'Clinical Pathways', 'Coupled', 'Data', 'Data Science', 'Decision Making', 'Developed Countries', 'Development', 'Dimensions', 'Discipline of Nursing', 'Documentation', 'Electronic Health Record', 'Equilibrium', 'Event', 'Evolution', 'Family Caregiver', 'Feedback', 'Fees', 'Goals', 'Guidelines', 'Health', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Institution', 'International', 'Investigation', 'Knowledge', 'Label', 'Lead', 'Learning', 'Limes', 'Machine Learning', 'Measures', 'Medical', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Nurse Administrator', 'Nurses', 'Nurses Performance Evaluations', 'Nursing Informatics', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physicians', 'Process', 'Publications', 'Quality Indicator', 'Recovery', 'Reporting', 'Research', 'Risk', 'Safety', 'School Nursing', 'Seminal', 'Source', 'Structure', 'System', 'Text', 'Time', 'Training', 'Uncertainty', 'United States Centers for Medicare and Medicaid Services', 'United States National Library of Medicine', 'Weight', 'Work', 'acute care', 'arm', 'base', 'clinical practice', 'computer science', 'data mining', 'data modeling', 'data standards', 'design', 'flexibility', 'graduate student', 'health care quality', 'heterogenous data', 'improved', 'indexing', 'individual patient', 'industry partner', 'innovation', 'learning algorithm', 'massive open online courses', 'multimodality', 'nursing care quality', 'open source', 'patient population', 'patient safety', 'phrases', 'predictive modeling', 'supervised learning', 'tool', 'vector']",NLM,EMORY UNIVERSITY,R01,2020,239104,0.05458303844511556
"SCH: INT Re-envisioned Chat-assessment for Real-time Investigating of Nursing and Guidance  Two decades have lapsed since the seminal publications of the National Academy of Medicine (formerly the Institute of Medicine), To Err Is Human and Crossing the Quality Chasm, cast a national spotlight on health-care safety and quality, yet US patient outcome indices continue to lag behind those in other industrialized countries. The 2009 American Recovery and Reinvestment Act mandated health-care providers adopt electronic health record (EHR) systems, leading to widespread EHR adoption, albeit primarily for billing purposes rather than research or quality improvement efforts. Thus EHR impact on health-care quality has tended to be in the domains of physician efficiency and guideline compliance. Despite a large body of evidence that nursing quality is directly related to patient outcomes in the acute care selling, nurses often lack timely information to use in improving individual patient outcomes, and indices of outcomes across patient populations are slow to budge over lime. Widespread adoption of EHRs in U.S. hospitals now allows determination of outcome quality indicators for all patients in a hospital for real-time feedback to nurses. Quality indicators are often only determined by piecing together other information to determine occurrence of an incident, e.g., exhuming information buried in nursing notes. The goal is to develop Chart-assessment for Real-lime Investigation of Nursing and Guidance (CARING), an automated machine learning system to report and predict nursing quality indicators in real-time for hospitalized patients to assist nurses in care planning. CARI NG will reflect algorithmic innovations to mine sequential patterns from multi-sourced, heterogeneous data including nursing narratives, yielding robust predictive models that are insensitive to uncertain labels and evolve with changes in health-care practices. CARING will represent EHR data using inter-connected tensors, capturing higher-order relations, temporal weighting, i.e., more recent data receives more weight, and incorporating domain expert feedback in development. Although CARING will be developed initially for the ten hospitals of our industry partner Emory Healthcare, its flexible refinement will enable adaptation at other health-care institutions. Outcomes of this project will give nurses actionable data in real time to improve nursing care quality that they do not receive now. Moreover, this system can be implemented into the health information infrastructure at an institutional level, integrating multi-scale and multi-level clinical, contextual, and organizational data surrounding each patient for real-time reporting and incorporation into predictive models. CARING supports the National Library of Medicine mission 1) by creating an innovative open source suite of tools for advancing patient safety; and 2) through educational efforts: training graduate students and fellows, and developing a Massive Open Online Course (MOOG), ""Big Data Analytics for Nursing,"" covering topics at the confluence of computer science, nursing, and patient outcome quality indicators. CARING will improve nursing care quality and make direct, positive impacts on patients, their families, and caregivers.",SCH: INT Re-envisioned Chat-assessment for Real-time Investigating of Nursing and Guidance ,9926403,R01LM013323,"['Academy', 'Acute', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Area', 'Big Data', 'Big Data Methods', 'Care given by nurses', 'Caring', 'Clinical', 'Clinical Pathways', 'Coupled', 'Data', 'Data Science', 'Decision Making', 'Developed Countries', 'Development', 'Dimensions', 'Discipline of Nursing', 'Documentation', 'Electronic Health Record', 'Equilibrium', 'Event', 'Evolution', 'Family Caregiver', 'Feedback', 'Fees', 'Goals', 'Guidelines', 'Health', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Institution', 'International', 'Investigation', 'Knowledge', 'Label', 'Lead', 'Learning', 'Limes', 'Machine Learning', 'Measures', 'Medical', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Nurse Administrator', 'Nurses', 'Nurses Performance Evaluations', 'Nursing Informatics', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physicians', 'Process', 'Publications', 'Quality Indicator', 'Recovery', 'Reporting', 'Research', 'Risk', 'Safety', 'School Nursing', 'Seminal', 'Source', 'Structure', 'System', 'Text', 'Time', 'Training', 'Uncertainty', 'United States Centers for Medicare and Medicaid Services', 'United States National Library of Medicine', 'Weight', 'Work', 'arm', 'base', 'clinical practice', 'computer science', 'data mining', 'data modeling', 'design', 'flexibility', 'graduate student', 'health care quality', 'improved', 'indexing', 'individual patient', 'industry partner', 'innovation', 'learning algorithm', 'massive open online courses', 'multimodality', 'nursing care quality', 'open source', 'patient population', 'patient safety', 'phrases', 'predictive modeling', 'supervised learning', 'tool', 'vector']",NLM,EMORY UNIVERSITY,R01,2019,248043,0.05458303844511556
"SCH: Leveraging Clinical Time Series to Learn Optimal Treatment of Acute Dyspnea  The ability to rapidly match the right patients to the right treatments at the right time is critical to ensuring patients  receive high quality care. The vast majority of machine learning applications in healthcare focus on diagnosing or  stratifying patients for a particular outcome. In contrast, reinforcement learning (RL) aims to learn how clinical states  (i.e., sets of signs, symptoms, and test results) respond to specific sequences of treatments, with the goal of optimizing clinical outcomes. RL does not aim to diagnose, but infers diagnosis based on a patient's response to  specific treatments--in many ways mimicking how clinicians operate in practice. This proposal will develop a novel  clinician-in-the-loop reinforcement learning (RL) framework that analyzes electronic health record (EHR) clinical time-series data to support physician decision making, iteratively providing physicians the estimated outcome of  potential treatment strategies. Our topic of focus for this work is the evaluation and treatment of patients hospitalized with acute dyspnea (shortness of breath) and signs of impending respiratory failure. Acute dyspnea is an ideal condition for an RL approach, since it can be due to three overlapping conditions: congestive heart failure, chronic obstructive pulmonary disease and pneumonia. Determining optimal treatment for these patients is clinically difficult, as a patient's presentation is frequently ambiguous, rapidly changing, and often due to multiple causes.  Inappropriate treatment may occur in up to a third of patients leading to increased mortality. While developing this  RL framework, we will also develop methods to learn more useful representations of high-dimensional clinical time-series data to improve the efficiency of RL model training. In addition, given the challenges of working with observational health data, we will develop new methods for evaluation of learned policies and develop new theory to better understand the limitations of RL using observational data. The project has four aims: 1) create a shareable, de-identified EHR time-series dataset of 35,000 patients with acute dyspnea, 2) develop techniques for exploiting invariances In tasks involving clinical time-series data to improve the efficiency of RL model training, 3) develop and evaluate an RL-based framework for learning optimal treatment policies for acute dyspnea, and 4) prospectively validate the learned treatment model. This research will result in new techniques for learning representations from time-series data and will study both the theoretical and practical limitations of RL using observational clinical data, leading to key advancements in ML and RL for clinical care. The tools developed for clinical decision support in this proposal have the potential for high impact because of their ability to generalize beyond the problem studied here to other conditions, laying the groundwork for clinical systems that directly impact society by aiding in the timely and appropriate treatment of patients. Hospitalization for sudden and severe shortness of breath (acute dyspnea) affects almost 2 million patients in the US each  year. Such patients can be difficult to treat, as their presentation may ambiguous, due to multiple causes that change over  time and require different types of therapies/treatments. In this proposal, we will develop novel reinforcement-learning  based approaches to quickly match patients to the best treatment based on his/her symptoms over time. The proposed  work could have a significant impact on health by shortening lhe time to appropriate treatments, leading to improved  patient outcomes.",SCH: Leveraging Clinical Time Series to Learn Optimal Treatment of Acute Dyspnea ,10015336,R01LM013325,"['Acute', 'Address', 'Affect', 'Algorithms', 'Blood Pressure', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Congestive Heart Failure', 'Data', 'Data Set', 'Decision Making', 'Diagnosis', 'Drops', 'Dyspnea', 'Electronic Health Record', 'Engineering', 'Ensure', 'Evaluation', 'Event', 'Goals', 'Health', 'Healthcare', 'Hospitalization', 'Hospitals', 'Image', 'Infrastructure', 'Learning', 'Linear Models', 'Machine Learning', 'Methods', 'Modeling', 'Morality', 'Outcome', 'Pathologic Processes', 'Patient Rights', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Pneumonia', 'Policies', 'Positioning Attribute', 'Protocols documentation', 'Psychological reinforcement', 'Quality of Care', 'Research', 'Research Personnel', 'Respiratory Failure', 'Rewards', 'Right to Treatments', 'Sample Size', 'Sampling', 'Selection for Treatments', 'Series', 'Shortness of Breath', 'Signal Transduction', 'Signs and Symptoms', 'Societies', 'Stream', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Theoretical Studies', 'Time', 'Training', 'Variant', 'Work', 'base', 'clinical care', 'clinical database', 'clinical decision support', 'clinical practice', 'clinically relevant', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'health data', 'high dimensionality', 'improved', 'innovation', 'interdisciplinary collaboration', 'learning algorithm', 'learning strategy', 'mortality', 'network architecture', 'novel', 'optimal treatments', 'patient response', 'patient stratification', 'prospective', 'success', 'supervised learning', 'support tools', 'theories', 'tool', 'treatment strategy']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,235205,0.011881896465882533
"SCH: Leveraging Clinical Time Series to Learn Optimal Treatment of Acute Dyspnea  The ability to rapidly match the right patients to the right treatments at the right time is critical to ensuring patients  receive high quality care. The vast majority of machine learning applications in healthcare focus on diagnosing or  stratifying patients for a particular outcome. In contrast, reinforcement learning (RL) aims to learn how clinical states  (i.e., sets of signs, symptoms, and test results) respond to specific sequences of treatments, with the goal of optimizing clinical outcomes. RL does not aim to diagnose, but infers diagnosis based on a patient's response to  specific treatments--in many ways mimicking how clinicians operate in practice. This proposal will develop a novel  clinician-in-the-loop reinforcement learning (RL) framework that analyzes electronic health record (EHR) clinical time-series data to support physician decision making, iteratively providing physicians the estimated outcome of  potential treatment strategies. Our topic of focus for this work is the evaluation and treatment of patients hospitalized with acute dyspnea (shortness of breath) and signs of impending respiratory failure. Acute dyspnea is an ideal condition for an RL approach, since it can be due to three overlapping conditions: congestive heart failure, chronic obstructive pulmonary disease and pneumonia. Determining optimal treatment for these patients is clinically difficult, as a patient's presentation is frequently ambiguous, rapidly changing, and often due to multiple causes.  Inappropriate treatment may occur in up to a third of patients leading to increased mortality. While developing this  RL framework, we will also develop methods to learn more useful representations of high-dimensional clinical time-series data to improve the efficiency of RL model training. In addition, given the challenges of working with observational health data, we will develop new methods for evaluation of learned policies and develop new theory to better understand the limitations of RL using observational data. The project has four aims: 1) create a shareable, de-identified EHR time-series dataset of 35,000 patients with acute dyspnea, 2) develop techniques for exploiting invariances In tasks involving clinical time-series data to improve the efficiency of RL model training, 3) develop and evaluate an RL-based framework for learning optimal treatment policies for acute dyspnea, and 4) prospectively validate the learned treatment model. This research will result in new techniques for learning representations from time-series data and will study both the theoretical and practical limitations of RL using observational clinical data, leading to key advancements in ML and RL for clinical care. The tools developed for clinical decision support in this proposal have the potential for high impact because of their ability to generalize beyond the problem studied here to other conditions, laying the groundwork for clinical systems that directly impact society by aiding in the timely and appropriate treatment of patients. Hospitalization for sudden and severe shortness of breath (acute dyspnea) affects almost 2 million patients in the US each  year. Such patients can be difficult to treat, as their presentation may ambiguous, due to multiple causes that change over  time and require different types of therapies/treatments. In this proposal, we will develop novel reinforcement-learning  based approaches to quickly match patients to the best treatment based on his/her symptoms over time. The proposed  work could have a significant impact on health by shortening lhe time to appropriate treatments, leading to improved  patient outcomes.",SCH: Leveraging Clinical Time Series to Learn Optimal Treatment of Acute Dyspnea ,9927810,R01LM013325,"['Acute', 'Affect', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Data', 'Congestive Heart Failure', 'Data', 'Data Set', 'Decision Making', 'Diagnosis', 'Dyspnea', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Goals', 'Health', 'Healthcare', 'Hospitalization', 'Instruction', 'Learning', 'Machine Learning', 'Methods', 'Modeling', 'Outcome', 'Patient Rights', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Pneumonia', 'Policies', 'Principal Investigator', 'Psychological reinforcement', 'Quality of Care', 'Research', 'Respiratory Failure', 'Right to Treatments', 'Series', 'Shortness of Breath', 'Signs and Symptoms', 'Societies', 'Symptoms', 'System', 'Techniques', 'Test Result', 'Time', 'Training', 'Work', 'base', 'clinical care', 'clinical decision support', 'health data', 'high dimensionality', 'improved', 'mortality', 'novel', 'optimal treatments', 'patient response', 'patient stratification', 'programs', 'prospective', 'theories', 'tool', 'treatment strategy']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,238522,0.011881896465882533
"Biases introduced by filtering electronic health records for patients with ""complete data"" PROJECT SUMMARY Nationwide adoption of electronic health records (EHRs) has led to the increasing availability of large clinical datasets. With statistical modeling and machine learning, these datasets have been be used in a wide range of applications, including diagnosis, decision support, cost reduction, and personalized medicine. However, because the same patient could be treated at multiple health care institutions, data from only a single EHR might not contain the complete medical history for that patient, with critical events potentially missing. A common approach to addressing this problem is to apply data checks that filter the EHR for patients whose data appear to be more complete. Examples of filters include requiring at least one visit per year or ensuring that age, sex, and race are all recorded. However, in a previous study using EHR data from seven institutions, we showed that these filters can greatly reduce the sample size and introduce unexpected biases by selecting sicker patients who seek care more often and changing the demographics of the resulting cohorts. This project extends this prior research by implementing an expanded set of data completeness filters and testing their accuracy and potential biases using a combination of national claims data and EHR data from dozens of hospitals and healthcare centers across the country. This will enable us to understand how data completeness varies in different EHRs and quantify the tradeoffs of different approaches to correcting for gaps in patients' records. First, we will develop and measure the accuracy of data completeness filters using national claims data. This provides a gold standard of longitudinal data where patients' complete medical histories are known during the periods in which they were enrolled in the insurance plan. After partitioning the data by provider groups to model gaps in EHR data, we will test how well data completeness filters, individually and in combined machine learning models, select patients with fewer gaps. We will then test whether the filters introduce biases by selecting sicker patients (more diagnoses, more visits, etc.) or changing their demographic characteristics (age, sex, and zip code). Then, we will test the filters on EHR data, first at a single large medical center, and then across a national network of 57 institutions, representing different geographic regions, patient populations, number of years of data, and types of health care facilities. We will evaluate the filters by measuring whether they improve the performance of a machine learning model for predicting hospital admissions. Our ultimate goals are to (a) help researchers balance the need for complete data with the biases this might introduce to their models and (b) help them predict how well models trained on one EHR dataset might work on other EHRs with different data completeness profiles. PROJECT NARRATIVE Nationwide adoption of electronic health records (EHRs) has led to the increasing availability of large clinical datasets. However, because the same patient could be treated at multiple health care institutions, data from only a single EHR might not contain the complete medical history for that patient, with critical events potentially missing. This study identifies biases that are introduced by selecting patients with fewer gaps in their record.","Biases introduced by filtering electronic health records for patients with ""complete data""",10121437,R01LM013345,"['Address', 'Adopted', 'Adoption', 'Age', 'Characteristics', 'Clinical', 'Clinical Trials', 'Clinical Trials Network', 'Clinical and Translational Science Awards', 'Code', 'Computer software', 'Country', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Equilibrium', 'Event', 'Funding', 'Geographic Locations', 'Goals', 'Gold', 'Health', 'Health care facility', 'Healthcare', 'Hospitalization', 'Hospitals', 'Individual', 'Institution', 'Insurance Carriers', 'Israel', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Medical History', 'Medical center', 'Modeling', 'Ontology', 'Patients', 'Performance', 'Probability', 'Procedures', 'Provider', 'Race', 'Recording of previous events', 'Records', 'Research', 'Research Personnel', 'Sample Size', 'Site', 'Statistical Models', 'System', 'Testing', 'Training', 'United States National Institutes of Health', 'Visit', 'Weight', 'Work', 'care seeking', 'clinical database', 'cohort', 'cost', 'demographics', 'improved', 'insurance plan', 'open source', 'patient health information', 'patient population', 'personalized medicine', 'predictive modeling', 'sex']",NLM,HARVARD MEDICAL SCHOOL,R01,2020,373990,0.07456655222129475
"Machine Learning Clinical Order Recommendations for Specialty Consultation Care Summary: Machine Learning Clinical Order Recommendations for Specialty Consultation Care  A future vision of clinical decision support must transcend constraints in scalability, maintainability, and adaptability. The shortage of 100,000 physicians by 2030 reflects unmet (and unlimited) demand for the scarcest healthcare resource, clinical expertise. Over 25 million in the US alone have deficient access to medical specialty care, with delays contributing to 20% higher mortality. There is no quality without access.  Our goal is to develop a radically different paradigm for outpatient specialty consultations by inductively learning clinical workups embedded in clinical data. We focus on predicting the concrete clinical orders for medications and diagnostic tests that result from specialty consultations. This can power a tier of fully automated guides that will enable clinicians to initiate care that would otherwise await in-person specialty visits, opening access for more patients.  The major scientific barriers are advances in data science and decision support methods for collating clinical knowledge, with continuous improvement through clinical experience, crowdsourcing, and machine learning. Our innovative approach is inspired by collaborative filtering algorithms that power Customers like you also bought this... recommender systems with the scalability to answer unlimited queries, maintainability through statistical learning, and adaptability to respond to evolving clinical practices.  Our team uniquely combines expertise in clinical medicine, electronic medical records, clinical decision support, statistics and machine learning to enhance medical specialty consultations through aims that seek to: (1) Develop methods to generate clinical decision support by predicting the clinical orders that will result from Endocrinology and Hematology specialty consultations; (2) Evaluate and iteratively design clinical collaborative filtering prototypes based on clinical user input on usability and acceptability; and (3) Determine which consult clinical order patterns are associated with better results through reinforcement learning and causal inference frameworks. Completion of these aims will yield a sustained, powerful impact on clinical information retrieval and knowledge discovery for synthesizing clinical practices from real-world data. By addressing grand challenges in clinical decision support, adoption of these methods will fulfill a vision that empowers clinicians to practice to the top of their license, making healthcare more scalable in reach, responsiveness, and reproducibility Project Narrative There can be no quality without access, and over 25 million in the US alone have deficient access to the scarcest healthcare resource: Human medical expertise. Building on methods analogous to commercial product recommender systems, the proposed research will automatically learn practice patterns from electronic medical records. Distributing predictable practices of medical specialty consultations can then enable healthcare systems to achieve broader patient access to timely and consistent care.",Machine Learning Clinical Order Recommendations for Specialty Consultation Care,10265158,R56LM013365,"['Active Learning', 'Acute', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Computerized Medical Record', 'Consult', 'Consultations', 'Data', 'Data Reporting', 'Data Science', 'Diagnosis', 'Diagnostic tests', 'Electronic Mail', 'Endocrinology', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Graph', 'Healthcare', 'Healthcare Systems', 'Hematology', 'Human', 'Human Resources', 'Hyperthyroidism', 'Individual', 'Industry', 'Information Retrieval', 'Inpatients', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Licensing', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Modern Medicine', 'Monitor', 'Outcome', 'Outpatients', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Primary Health Care', 'Psychological reinforcement', 'Recommendation', 'Records', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Running', 'Specialist', 'Suggestion', 'System', 'Test Result', 'Testing', 'Thrombocytopenia', 'Time', 'Training', 'Transcend', 'Vision', 'Visit', 'Work', 'base', 'clinical care', 'clinical decision support', 'clinical practice', 'clinical predictors', 'convolutional neural network', 'crowdsourcing', 'data streams', 'design', 'experience', 'individual patient', 'innovation', 'iterative design', 'medical specialties', 'mortality', 'novel', 'open source', 'outcome forecast', 'personalized decision', 'personalized predictions', 'predictive modeling', 'prototype', 'statistical learning', 'statistics', 'tool', 'usability']",NLM,STANFORD UNIVERSITY,R56,2020,394250,0.025195002312571883
"Scientific Questions: A New Target for Biomedical NLP Project Summary  Natural language processing (NLP) technology is now widespread (e.g. Google Translate) and has several important applications in biomedical research. We propose a new target for NLP: extraction of scientific questions stated in publications. A system that automatically captures and organizes scientific questions from across the biomedical literature could have a wide range of significant impacts, as attested to in our diverse collection of support letters from researchers, journal editors, educators and scientific foundations. Prior work focused on making binary (or probabilistic) assessments of whether a text is hedged or uncertain, with the goal of downgrading such statements in information extraction tasksnot computationally capturing what the uncertainty is about. In contrast, we propose an ambitious plan to identify, represent, integrate and reason about the content of scientific questions, and to demonstrate how this approach can be used to address two important new use cases in biomedical research: contextualizing experimental results and enhancing literature awareness. Contextualizing results is the task of linking elements of genome-scale results to open questions across all of biomedical research. Literature awareness is the ability to understand important characteristics of large, dynamic collections of research publications as a whole. We propose to produce rich computational representations of the dynamic evolution of research questions, and to prototype textual and visual interfaces to help students and researchers explore and develop a detailed understanding of key open scientific questions in any area of biomedical research. Project Narrative The scientific literature is full of statements of important unsolved questions. By using artificial intelligence systems to identify and categorize these questions, the proposed work would help other researchers discover when their findings might address an important question in another scientific area. This work would also make it easier for students, journal editors, conference organizers and others understand where science is headed by tracking the evolution of scientific questions.",Scientific Questions: A New Target for Biomedical NLP,10069773,R01LM013400,"['Address', 'Area', 'Artificial Intelligence', 'Awareness', 'Biomedical Research', 'Characteristics', 'Collection', 'Computerized Patient Records', 'Cues', 'Data', 'Elements', 'Environment', 'Evolution', 'Expert Systems', 'Foundations', 'Genes', 'Goals', 'Gold', 'Information Retrieval', 'Journals', 'Letters', 'Link', 'Literature', 'Manuals', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Phenotype', 'Proteomics', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Semantics', 'Services', 'Signal Transduction', 'Source', 'Students', 'System', 'Taxonomy', 'Technology', 'Text', 'Time', 'Translating', 'Uncertainty', 'Update', 'Visual', 'Work', 'design', 'dynamical evolution', 'experimental study', 'genome wide association study', 'genome-wide', 'graduate student', 'high throughput screening', 'innovation', 'journal article', 'news', 'novel', 'pharmacovigilance', 'prototype', 'symposium', 'text searching', 'tool', 'transcriptome sequencing', 'trend']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2020,462393,0.008782941271007767
"Health Inequality and a Machine Learning-Based Tool for Emergency Department Triage: A Mixed Methods Approach Project Summary There is growing evidence that artificial intelligence (AI) technologies like machine learning (ML) can perpetuate or even worsen social inequalities when deployed into real-world settings. This has been demonstrated in many realms, including policing, the court system, banking, social services provision, and there is growing concern the same is true in medicine. At the same time, there has been an outpouring of new AI-based interventions, with a ten-fold increase in the number of Food and Drug Administration (FDA) approvals for AI-based technologies since 2017. However, little research empirically examines the health equity implications of ML-based clinical decision-making tools. One clinical arena in which ML-based tools are already in use is emergency department (ED) triage, as an alternative to the common Emergency Severity Index (ESI) system. Despite its widespread popularity, evidence has shown that ESI-based triage has many problems, including poor acuity discrimination, with up to 50% of patients triaged at the midpoint of the scale, and is associated with racial inequalities, with African-American patients experiencing longer wait-times and lower triage levels controlling for illness severity. This study will use an ML-based ED triage tool that is already in use at a major academic medical center in the United States to explore the extent to which several factors are associated with inequality in predictive performance across patient racial/ethnic groups. This research will take a mixed methods approach to concurrently examine both human and machine elements that affect the triage tools final impact on patients. Aim 1 will be a qualitative study involving ethnographic observation and semi-structured interviewing of triage nurses, to develop a conceptual framework for clinicians understanding of and interaction with an ML-based tool. Aim 2 will examine label bias, a type of measurement bias. The Applicant will use synthetic and real electronic health record (EHR) data and simulate different levels of label bias, then examine predictive performance of the triage tool across patient racial/ethnic groups. Aim 3 will explore different methods for imputing missing EHR data. The Applicant will deploy common, simplistic deletion-based methods as well as a promising new ML-based imputation method called an autoencoder, apply the triage model to generate predictions and examine performance across patient racial/ethnic groups. This project is innovative because it contributes to the development of a life cycle model of ML-based tools and their health equity implications using a mixed methods approach that integrates both human and computational elements, while also providing a rigorous training plan for the Applicant, an MD-PhD student in epidemiology. This training plan is rigorous, synergistic yet diverse, and will include advanced coursework, dedicated 1-on-1 and group mentoring with experts in the field, attendance at seminars and targeted conferences, integration with clinical education and professional development. This project will be an essential step toward the Applicants maturation into an independent physician-scientist. Project Narrative This proposal represents a significant contribution to public health in that it seeks to improve upon current emergency department (ED) triage processes, which are associated with racial inequalities in wait time and triage severity. Specifically, this research will evaluate the performance of an alternative machine learning (ML) -based tool for ED triage across racial/ethnic groups, contributing to a more accurate and equitable triaging of patients and directly improving patient health outcomes. More broadly, this project will enhance the ability of many stakeholders, including data scientists, clinicians, researchers and health policy-makers to evaluate the health equity impacts of any proposed ML-based interventions for health.",Health Inequality and a Machine Learning-Based Tool for Emergency Department Triage: A Mixed Methods Approach,9992378,F31LM013403,"['Academic Medical Centers', 'Accident and Emergency department', 'Address', 'Adjuvant', 'Affect', 'African American', 'Algorithms', 'Artificial Intelligence', 'Characteristics', 'Clinical', 'Collaborations', 'Critiques', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Data Sources', 'Decision Making', 'Demographic Factors', 'Development', 'Diagnosis', 'Discrimination', 'Education', 'Electronic Health Record', 'Elements', 'Emergency Medicine', 'Emergency Situation', 'Emergency department visit', 'Empirical Research', 'Epidemiology', 'Ethnic Origin', 'Ethnic group', 'Ethnography', 'Generations', 'Health', 'Health Policy', 'Healthcare', 'Human', 'Inequality', 'Intervention', 'Interview', 'Label', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Measurement', 'Medicine', 'Mentors', 'Methods', 'Minority Groups', 'Modeling', 'Nurses', 'Outcome', 'Patient Triage', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Police', 'Policy Maker', 'Process', 'Provider', 'Public Health', 'Qualitative Methods', 'Race', 'Research', 'Research Personnel', 'Scientist', 'Service provision', 'Severities', 'Severity of illness', 'Social Work', 'Socioeconomic Status', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Treatment outcome', 'Triage', 'United States', 'United States Food and Drug Administration', 'Universities', 'University Hospitals', 'Variant', 'Wait Time', 'Work', 'algorithm training', 'artificial neural network', 'autoencoder', 'base', 'clinical decision-making', 'computer science', 'court', 'deep learning', 'doctoral student', 'ethnic minority population', 'experience', 'health care settings', 'health equity', 'health inequalities', 'improved', 'indexing', 'innovation', 'learning strategy', 'machine learning algorithm', 'racial and ethnic', 'racial bias', 'social', 'social bias', 'social inequality', 'symposium', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,F31,2020,50520,0.02008840457174893
"Operationalizing Machine Learning and Discrete Event Simulation Models to Improve Clinic Efficiency PROJECT SUMMARY Physicians often report feeling pressured to see more patients to maintain revenue, while having less available time for patient care. Systematic data-driven methods for efficiently scheduling patients are important as physicians are pressured to see more and more patients. We propose that real time prediction models of patient visit lengths, the likelihood of missing appointments, and of patient wait times will help schedule patients more efficiently. Clinics will be able to safely overbook to avoid empty slots from missed appointments, have guidance for scheduling urgent add-on patients, and provide wait time estimates for patients when there are delays. We will develop methodologies for accessing data needed for these predictions in real time and propose that the integration of these models into workflows will improve scheduling accuracy, patient wait time, and patient satisfaction, while also increasing clinic volumes. PROJECT NARRATIVE Physicians report feeling pressured to see more patients to maintain revenue, while having less available time for patient care. Machine learning and discrete event simulation model predictions can help schedule patients more efficiently, but need to be integrated into the EHR and scheduling workflows to be effective. This study will develop methodologies for accessing real time data in the electronic health record (EHR) for research applications and predictive models so they can be integrated into scheduling workflows, and then will evaluate their effectiveness for clinic efficiency and patient satisfaction.",Operationalizing Machine Learning and Discrete Event Simulation Models to Improve Clinic Efficiency,10030242,R01LM013426,"['Affect', 'Ambulatory Care Facilities', 'Appointment', 'Books', 'Childhood', 'Client satisfaction', 'Clinic', 'Clinical', 'Data', 'Data Set', 'Effectiveness', 'Electronic Health Record', 'Event', 'Face', 'Fast Healthcare Interoperability Resources', 'Feeling', 'Glaucoma', 'Length', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Ophthalmology', 'Outpatients', 'Patient Care', 'Patient Schedules', 'Patients', 'Physicians', 'Production', 'Provider', 'Quality of Care', 'Regulation', 'Reporting', 'Research', 'Resources', 'Schedule', 'Testing', 'Time', 'Visit', 'Wait Time', 'Work', 'application programming interface', 'barrier to care', 'base', 'burnout', 'data access', 'effectiveness evaluation', 'electronic data', 'follow-up', 'improved', 'individual patient', 'models and simulation', 'novel', 'predictive modeling', 'pressure', 'prospective', 'tool']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,327250,0.04007002023385328
"Enhanced Metadata Design, Architecture, and Learning (MeDAL) for Development of Generalizable Deep Learning-based Predictive Analytics from Electronic Health Records Sepsis, Septic Shock, and Acute Kidney Injury (AKI) are among the top causes of hospital mortality, morbidity, and an increase in duration and cost of hospitalization. Successful prevention and management of these conditions rely on the ability of clinicians to estimate the risk, and ideally, to anticipate and prevent these events. Acute care settings and in particular intensive care units (ICUs) provide an environment where an immense amount of data is acquired, and it is expected that with the advent of wearables and biometric patches even more data will be available in such settings. But at present, very little of these data are used effectively to prognosticate, and the existing predictive analytics risk scores suffer from lack of generalizability across institutions and performance degradation within the same institution over time. The PIs on this proposal recently demonstrated that a Deep Learning-based algorithm can reliably predict new sepsis cases in the emergency departments, general hospital wards, and ICUs by as much as 4-6 hours in advance and an area under the curve (ROC) of 0.85-0.90. Furthermore, through a 2-year pilot study funded via Biomedical Advanced Research and Development Authority (BARDA), we recently joined forces in a multicenter academic consortium to retrospectively validate this algorithm at each site. Our collaboration has resulted in a multi-center longitudinal EHR dataset of critically ill patients and has generated several important questions and findings related to design of portable and generalizable predictive analytics algorithms that are robust to problems arising from gaps, errors, and biases in electronic health records (EHRs) due to workflow-related factors (e.g. staffing-level), and heterogeneity of patient populations and measurement devices. We propose to continue our prior work by designing new deep learning architectures that are more robust to data missingness and biases introduced through the variability in process of care, 2) development of new learning methodologies to improve generalizability of the proposed models under data/population drifts (aka distributional changes), 3) enhanced metadata design to assist in quantifying conditions for use of such algorithms via algorithmic controls, and 4) HL7 and FHIR-based prospective implementation and testing of these methodologies to provide real-world evidence for the effectiveness of the proposed approaches. Ultimately, these novel methodologies and tools will enhance our ability to use EHR and other types of continuously measured longitudinal data to predict adverse events, assess patients response to therapy, and optimize and personalize care at the beside. The proposed project is making use of computers to analyze data from sickest patients in hospitals. We want to develop methods that work across different demographics groups and hospital settings to identify patterns in the patient data which predict who is at risk for life- threatening conditions such as Sepsis and Acute Kidney Injury (AKI), and who might respond to various medications which could make them better. We have a very strong team of doctors and researchers who work closely together, covering all aspects of the proposed research, which we hope will help us improve the lives of the sickest patients in the hospitals.","Enhanced Metadata Design, Architecture, and Learning (MeDAL) for Development of Generalizable Deep Learning-based Predictive Analytics from Electronic Health Records",10265157,R56LM013517,"['Accident and Emergency department', 'Acute Renal Failure with Renal Papillary Necrosis', 'Adverse event', 'Algorithms', 'Antibiotics', 'Architecture', 'Area Under Curve', 'Artificial Intelligence', 'Biometry', 'Calibration', 'Caring', 'Cessation of life', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computers', 'Confidence Intervals', 'Critical Illness', 'Data', 'Data Element', 'Data Provenance', 'Data Set', 'Data Sources', 'Development', 'Devices', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Expenditure', 'Fast Healthcare Interoperability Resources', 'Frequencies', 'Funding', 'General Hospitals', 'Goals', 'Health', 'Health Expenditures', 'Heterogeneity', 'Hospital Costs', 'Hospital Mortality', 'Hospitalization', 'Hospitals', 'Hour', 'Incidence', 'Individual', 'Infection', 'Inflammation', 'Institution', 'Intensive Care Units', 'Learning', 'Length of Stay', 'Life', 'Measurement', 'Measures', 'Medical', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Organ failure', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pilot Projects', 'Population', 'Predictive Analytics', 'Prevention', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Savings', 'Sepsis', 'Septic Shock', 'Site', 'Source', 'Standardization', 'Testing', 'Time', 'Training', 'Uncertainty', 'Variant', 'Work', 'acute care', 'aging population', 'authority', 'base', 'cloud based', 'deep learning', 'demographics', 'design', 'improved', 'interest', 'novel', 'patient population', 'patient response', 'personalized care', 'portability', 'prediction algorithm', 'predictive modeling', 'pressure', 'prevent', 'prospective', 'research and development', 'response', 'septic patients', 'theories', 'tool', 'treatment optimization', 'ward']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2020,393958,0.04191800135965694
"Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2)     DESCRIPTION (provided by applicant): Patients in step-down units (SDU) undergo continuous noninvasive vital sign (VS) monitoring to facilitate nurse detection of cardiorespiratory instability (CRI) in need of a diagnostic and/or therapeutic response. Yet, our data and others show nurses do not readily identify CRI nor necessarily react in a timely fashion. Further, 75% of monitored SDU patients never become unstable, diffusing surveillance away from those in need. Current nursing surveillance strategies are imprecise and untargeted, leading to failure to detect CRI, and failure to rescue patients needing intervention. Smart clinical decision support systems (SDSS) that continuously process complex data from disparate sources can apply detection algorithms to alert clinicians of ongoing events (nowcasting) and those developing in future (forecasting) to refocus clinicians on high-risk patients, and apply supportive care earlier, or even care to prevent the CRI. In our prior R01 we developed a prototype SDSS using machine learning (ML) to process time series data and learn data patterns systematically preceding events in the near or far term. In that study, we: 1) assembled a complex expert-annotated multidimensional dataset from our existing 1/20 Hz physiologic monitoring data as the learning platform; 2) developed and validated ML models for dynamic CRI prediction, tested which were most effective in CRI nowcasting; and 3) used the SDSS to develop an early prototype CRI prediction graphical user interface (GUI) for nurses. Importantly, our models were also able to discriminate between real CRI and artifact in real-time with high sensitivity and specificity. We now propose to build on this work and enhance our models by: 1) prospectively collecting a multidimensional high-resolution (100-250Hz) dataset of non-invasive physiologic monitoring and electronic health record (EHR) data from two different medical center SDUs to create enhanced and generalizable CRI nowcasting capability, 2) using our existing and the expanding multicenter clinical datasets to precisely forecast CRI events and online artifact discrimination, and 3) create a robust SDSS platform for real-time precision CRI nowcast and forecast alerting; present alerts in a graphical user interface (GUI), iteratively develop the GUI in the simulation setting; and then pilot its use in a SDU. Permitting nurses to move toward SDSS-supported precision nursing surveillance, and know who will become unstable, when they will do so, and why-all in advance of overt instability manifestation-can shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific, parsimonious and clinically practical means to predict patient instability has important implications for reducing preventable morbidity and mortality, eliminating alarm fatigue, improving patient safety, nursing care (monitoring frequency, case load and mixture, staff allocation) and care delivery systems (triage, bed allocation, prevention of adverse events). PUBLIC HEALTH RELEVANCE: It is very difficult for nurses using current monitoring standards to know who will develop cardiorespiratory instability (CRI), when they will do so, and why, leading to imprecise nursing surveillance, and failure-to-rescue. We propose to expand on our prior machine learning (ML) techniques that continuously process complex data from disparate sources, and further develop a smart clinical decision support system (SDSS) to apply CRI detection algorithms to alert nurses to ongoing CRI events (nowcasting) and those developing in future (forecasting). Study findings will enable a tangible move toward precision nursing surveillance (knowing who, when, why in advance of overt CRI), so that nurses can detect CRI better, intervene sooner, and shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific and parsimonious means to nowcast and forecast CRI also has important implications for improving nursing care processes (case load mixture, workload, staff allocation) and delivery systems (patient triage to monitored or non-monitored units, higher vs. lower cost bed allocation, adverse events prevention).",Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2),9502383,R01NR013912,"['Active Learning', 'Acute respiratory failure', 'Adverse event', 'Algorithms', 'Beds', 'California', 'Care given by nurses', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Communities', 'Comparative Study', 'Complex', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Diagnostic', 'Diffuse', 'Discipline of Nursing', 'Discrimination', 'Electronic Health Record', 'Environment', 'Evaluation', 'Event', 'Failure', 'Fatigue', 'Frequencies', 'Future', 'Human', 'Hypovolemia', 'Income', 'Intervention', 'Intuition', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Measurement', 'Medical center', 'Modality', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Nurses', 'Patient Triage', 'Patient risk', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Physiologic Monitoring', 'Physiological', 'Prevention', 'Process', 'Real-Time Systems', 'Resolution', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Series', 'Site', 'Source', 'Specificity', 'Supervision', 'Support System', 'Supportive care', 'System', 'Techniques', 'Testing', 'Time', 'Triage', 'Universities', 'Visual', 'Work', 'Workload', 'base', 'care delivery', 'cost', 'graphical user interface', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'novel', 'patient safety', 'prevent', 'prognostic', 'prospective', 'prototype', 'public health relevance', 'screening', 'simulation', 'surveillance strategy', 'temporal measurement', 'treatment response']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,658069,0.02871542786078268
"Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2)     DESCRIPTION (provided by applicant): Patients in step-down units (SDU) undergo continuous noninvasive vital sign (VS) monitoring to facilitate nurse detection of cardiorespiratory instability (CRI) in need of a diagnostic and/or therapeutic response. Yet, our data and others show nurses do not readily identify CRI nor necessarily react in a timely fashion. Further, 75% of monitored SDU patients never become unstable, diffusing surveillance away from those in need. Current nursing surveillance strategies are imprecise and untargeted, leading to failure to detect CRI, and failure to rescue patients needing intervention. Smart clinical decision support systems (SDSS) that continuously process complex data from disparate sources can apply detection algorithms to alert clinicians of ongoing events (nowcasting) and those developing in future (forecasting) to refocus clinicians on high-risk patients, and apply supportive care earlier, or even care to prevent the CRI. In our prior R01 we developed a prototype SDSS using machine learning (ML) to process time series data and learn data patterns systematically preceding events in the near or far term. In that study, we: 1) assembled a complex expert-annotated multidimensional dataset from our existing 1/20 Hz physiologic monitoring data as the learning platform; 2) developed and validated ML models for dynamic CRI prediction, tested which were most effective in CRI nowcasting; and 3) used the SDSS to develop an early prototype CRI prediction graphical user interface (GUI) for nurses. Importantly, our models were also able to discriminate between real CRI and artifact in real-time with high sensitivity and specificity. We now propose to build on this work and enhance our models by: 1) prospectively collecting a multidimensional high-resolution (100-250Hz) dataset of non-invasive physiologic monitoring and electronic health record (EHR) data from two different medical center SDUs to create enhanced and generalizable CRI nowcasting capability, 2) using our existing and the expanding multicenter clinical datasets to precisely forecast CRI events and online artifact discrimination, and 3) create a robust SDSS platform for real-time precision CRI nowcast and forecast alerting; present alerts in a graphical user interface (GUI), iteratively develop the GUI in the simulation setting; and then pilot its use in a SDU. Permitting nurses to move toward SDSS-supported precision nursing surveillance, and know who will become unstable, when they will do so, and why-all in advance of overt instability manifestation-can shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific, parsimonious and clinically practical means to predict patient instability has important implications for reducing preventable morbidity and mortality, eliminating alarm fatigue, improving patient safety, nursing care (monitoring frequency, case load and mixture, staff allocation) and care delivery systems (triage, bed allocation, prevention of adverse events). PUBLIC HEALTH RELEVANCE: It is very difficult for nurses using current monitoring standards to know who will develop cardiorespiratory instability (CRI), when they will do so, and why, leading to imprecise nursing surveillance, and failure-to-rescue. We propose to expand on our prior machine learning (ML) techniques that continuously process complex data from disparate sources, and further develop a smart clinical decision support system (SDSS) to apply CRI detection algorithms to alert nurses to ongoing CRI events (nowcasting) and those developing in future (forecasting). Study findings will enable a tangible move toward precision nursing surveillance (knowing who, when, why in advance of overt CRI), so that nurses can detect CRI better, intervene sooner, and shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific and parsimonious means to nowcast and forecast CRI also has important implications for improving nursing care processes (case load mixture, workload, staff allocation) and delivery systems (patient triage to monitored or non-monitored units, higher vs. lower cost bed allocation, adverse events prevention).",Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2),9357725,R01NR013912,"['Active Learning', 'Acute respiratory failure', 'Adverse event', 'Algorithms', 'Beds', 'California', 'Care given by nurses', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Communities', 'Comparative Study', 'Complex', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Diagnostic', 'Diffuse', 'Discipline of Nursing', 'Discrimination', 'Electronic Health Record', 'Environment', 'Evaluation', 'Event', 'Failure', 'Fatigue', 'Frequencies', 'Future', 'Human', 'Hypovolemia', 'Income', 'Intervention', 'Intuition', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Measurement', 'Medical center', 'Modality', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Nurses', 'Patient Triage', 'Patient risk', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Physiologic Monitoring', 'Physiological', 'Prevention', 'Process', 'Real-Time Systems', 'Resolution', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Series', 'Site', 'Source', 'Specificity', 'Supervision', 'Support System', 'Supportive care', 'System', 'Techniques', 'Testing', 'Time', 'Triage', 'Universities', 'Visual', 'Work', 'Workload', 'base', 'care delivery', 'cost', 'graphical user interface', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'novel', 'patient safety', 'prevent', 'prognostic', 'prospective', 'prototype', 'public health relevance', 'screening', 'simulation', 'surveillance strategy', 'temporal measurement', 'treatment response']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,687081,0.02871542786078268
"Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2)     DESCRIPTION (provided by applicant): Patients in step-down units (SDU) undergo continuous noninvasive vital sign (VS) monitoring to facilitate nurse detection of cardiorespiratory instability (CRI) in need of a diagnostic and/or therapeutic response. Yet, our data and others show nurses do not readily identify CRI nor necessarily react in a timely fashion. Further, 75% of monitored SDU patients never become unstable, diffusing surveillance away from those in need. Current nursing surveillance strategies are imprecise and untargeted, leading to failure to detect CRI, and failure to rescue patients needing intervention. Smart clinical decision support systems (SDSS) that continuously process complex data from disparate sources can apply detection algorithms to alert clinicians of ongoing events (nowcasting) and those developing in future (forecasting) to refocus clinicians on high-risk patients, and apply supportive care earlier, or even care to prevent the CRI. In our prior R01 we developed a prototype SDSS using machine learning (ML) to process time series data and learn data patterns systematically preceding events in the near or far term. In that study, we: 1) assembled a complex expert-annotated multidimensional dataset from our existing 1/20 Hz physiologic monitoring data as the learning platform; 2) developed and validated ML models for dynamic CRI prediction, tested which were most effective in CRI nowcasting; and 3) used the SDSS to develop an early prototype CRI prediction graphical user interface (GUI) for nurses. Importantly, our models were also able to discriminate between real CRI and artifact in real-time with high sensitivity and specificity. We now propose to build on this work and enhance our models by: 1) prospectively collecting a multidimensional high-resolution (100-250Hz) dataset of non-invasive physiologic monitoring and electronic health record (EHR) data from two different medical center SDUs to create enhanced and generalizable CRI nowcasting capability, 2) using our existing and the expanding multicenter clinical datasets to precisely forecast CRI events and online artifact discrimination, and 3) create a robust SDSS platform for real-time precision CRI nowcast and forecast alerting; present alerts in a graphical user interface (GUI), iteratively develop the GUI in the simulation setting; and then pilot its use in a SDU. Permitting nurses to move toward SDSS-supported precision nursing surveillance, and know who will become unstable, when they will do so, and why-all in advance of overt instability manifestation-can shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific, parsimonious and clinically practical means to predict patient instability has important implications for reducing preventable morbidity and mortality, eliminating alarm fatigue, improving patient safety, nursing care (monitoring frequency, case load and mixture, staff allocation) and care delivery systems (triage, bed allocation, prevention of adverse events). PUBLIC HEALTH RELEVANCE: It is very difficult for nurses using current monitoring standards to know who will develop cardiorespiratory instability (CRI), when they will do so, and why, leading to imprecise nursing surveillance, and failure-to-rescue. We propose to expand on our prior machine learning (ML) techniques that continuously process complex data from disparate sources, and further develop a smart clinical decision support system (SDSS) to apply CRI detection algorithms to alert nurses to ongoing CRI events (nowcasting) and those developing in future (forecasting). Study findings will enable a tangible move toward precision nursing surveillance (knowing who, when, why in advance of overt CRI), so that nurses can detect CRI better, intervene sooner, and shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific and parsimonious means to nowcast and forecast CRI also has important implications for improving nursing care processes (case load mixture, workload, staff allocation) and delivery systems (patient triage to monitored or non-monitored units, higher vs. lower cost bed allocation, adverse events prevention).",Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2),9722313,R01NR013912,"['Active Learning', 'Acute respiratory failure', 'Adverse event', 'Algorithms', 'Beds', 'California', 'Care given by nurses', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Communities', 'Comparative Study', 'Complex', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Diagnostic', 'Diffuse', 'Discipline of Nursing', 'Discrimination', 'Electronic Health Record', 'Environment', 'Evaluation', 'Event', 'Failure', 'Fatigue', 'Frequencies', 'Future', 'Human', 'Hypovolemia', 'Intervention', 'Intuition', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Measurement', 'Medical center', 'Modality', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Nurses', 'Patient Triage', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Physiologic Monitoring', 'Physiological', 'Prevention', 'Process', 'Real-Time Systems', 'Resolution', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Series', 'Site', 'Source', 'Specificity', 'Supervision', 'Support System', 'Supportive care', 'System', 'Techniques', 'Testing', 'Time', 'Triage', 'Universities', 'Visual', 'Work', 'Workload', 'base', 'care delivery', 'cost', 'graphical user interface', 'high risk', 'improved', 'machine learning algorithm', 'mortality', 'multidisciplinary', 'novel', 'patient safety', 'prevent', 'prognostic', 'prospective', 'prototype', 'public health relevance', 'screening', 'simulation', 'surveillance strategy', 'temporal measurement', 'treatment response']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,658069,0.02871542786078268
"Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2)     DESCRIPTION (provided by applicant): Patients in step-down units (SDU) undergo continuous noninvasive vital sign (VS) monitoring to facilitate nurse detection of cardiorespiratory instability (CRI) in need of a diagnostic and/or therapeutic response. Yet, our data and others show nurses do not readily identify CRI nor necessarily react in a timely fashion. Further, 75% of monitored SDU patients never become unstable, diffusing surveillance away from those in need. Current nursing surveillance strategies are imprecise and untargeted, leading to failure to detect CRI, and failure to rescue patients needing intervention. Smart clinical decision support systems (SDSS) that continuously process complex data from disparate sources can apply detection algorithms to alert clinicians of ongoing events (nowcasting) and those developing in future (forecasting) to refocus clinicians on high-risk patients, and apply supportive care earlier, or even care to prevent the CRI. In our prior R01 we developed a prototype SDSS using machine learning (ML) to process time series data and learn data patterns systematically preceding events in the near or far term. In that study, we: 1) assembled a complex expert-annotated multidimensional dataset from our existing 1/20 Hz physiologic monitoring data as the learning platform; 2) developed and validated ML models for dynamic CRI prediction, tested which were most effective in CRI nowcasting; and 3) used the SDSS to develop an early prototype CRI prediction graphical user interface (GUI) for nurses. Importantly, our models were also able to discriminate between real CRI and artifact in real-time with high sensitivity and specificity. We now propose to build on this work and enhance our models by: 1) prospectively collecting a multidimensional high-resolution (100-250Hz) dataset of non-invasive physiologic monitoring and electronic health record (EHR) data from two different medical center SDUs to create enhanced and generalizable CRI nowcasting capability, 2) using our existing and the expanding multicenter clinical datasets to precisely forecast CRI events and online artifact discrimination, and 3) create a robust SDSS platform for real-time precision CRI nowcast and forecast alerting; present alerts in a graphical user interface (GUI), iteratively develop the GUI in the simulation setting; and then pilot its use in a SDU. Permitting nurses to move toward SDSS-supported precision nursing surveillance, and know who will become unstable, when they will do so, and why-all in advance of overt instability manifestation-can shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific, parsimonious and clinically practical means to predict patient instability has important implications for reducing preventable morbidity and mortality, eliminating alarm fatigue, improving patient safety, nursing care (monitoring frequency, case load and mixture, staff allocation) and care delivery systems (triage, bed allocation, prevention of adverse events).         PUBLIC HEALTH RELEVANCE: It is very difficult for nurses using current monitoring standards to know who will develop cardiorespiratory instability (CRI), when they will do so, and why, leading to imprecise nursing surveillance, and failure-to-rescue. We propose to expand on our prior machine learning (ML) techniques that continuously process complex data from disparate sources, and further develop a smart clinical decision support system (SDSS) to apply CRI detection algorithms to alert nurses to ongoing CRI events (nowcasting) and those developing in future (forecasting). Study findings will enable a tangible move toward precision nursing surveillance (knowing who, when, why in advance of overt CRI), so that nurses can detect CRI better, intervene sooner, and shift CRI nursing care from reactive to preemptive. Developing a sensitive, specific and parsimonious means to nowcast and forecast CRI also has important implications for improving nursing care processes (case load mixture, workload, staff allocation) and delivery systems (patient triage to monitored or non-monitored units, higher vs. lower cost bed allocation, adverse events prevention).            ",Predicting Patient Instability Noninvasively for Nursing Care-Two (PPINNC-2),9103405,R01NR013912,"['Active Learning', 'Acute respiratory failure', 'Adverse event', 'Algorithms', 'Beds', 'Boxing', 'California', 'Care given by nurses', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Communities', 'Comparative Study', 'Complex', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Diagnostic', 'Diffuse', 'Discipline of Nursing', 'Discrimination', 'Electronic Health Record', 'Environment', 'Evaluation', 'Event', 'Failure', 'Fatigue', 'Frequencies', 'Future', 'Human', 'Hypovolemia', 'Intervention', 'Intuition', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Measurement', 'Medical center', 'Modality', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Nurses', 'Patient Triage', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Physiologic Monitoring', 'Physiological', 'Prevention', 'Process', 'Qualifying', 'Resolution', 'Running', 'Sampling', 'Sensitivity and Specificity', 'Sepsis', 'Series', 'Site', 'Source', 'Specificity', 'Staff Work Load', 'Supportive care', 'System', 'Techniques', 'Testing', 'Time', 'Triage', 'Universities', 'Visual', 'Work', 'base', 'care delivery', 'cost', 'graphical user interface', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'novel', 'patient safety', 'prevent', 'prognostic', 'prototype', 'public health relevance', 'screening', 'simulation', 'surveillance strategy', 'temporal measurement', 'treatment response']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,656467,0.02871542786078268
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a providers ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,9906653,F31MD014941,"['Address', 'Alcohol or Other Drugs use', 'Anxiety', 'Awareness', 'Behavior', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2020,45016,0.024326690613702434
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8804856,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2015,217500,0.04501288412331679
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8635902,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2014,257300,0.04501288412331679
"Communicating narrative Concerns entered by RNs (CONCERN) PROJECT SUMMARY/ABSTRACT Annually, more than 200,000 patients die in U.S. hospitals from cardiac arrest1 and over 130,000 patients inpatients deaths are attributed to sepsis.2 These deaths are preventable if patients who are at risk are detected earlier. Our prior work found that nursing documentation within electronic health records (EHRs) contains information that could contribute to early detection and treatment, but these data are not being analyzed and exposed by EHRs to clinicians to initiate interventions quickly enough to save patients.36 We defined a new source of predictive data by analyzing the frequency and types of nursing documentation that indicated nurses' increased surveillance and level of concern for a patient. These data documented in the 48 hours preceding a cardiac arrest and hospital mortality were predictive of the event.3 While clinicians strive to provide the best care, there is a systematic problem within hospital settings of non-optimal communication between nurses and doctors leading to delays in care for patient at risk.68,9 Well-designed and tested EHRs are able to trend data and support communication and decision making, but too often fall short of these goals and actually increase clinician cognitive load through fragmented information displays, note bloat, and information overload.10 Substitutable Medical Applications & Reusable Technologies (SMARTapps) using Fast Health Interoperability Resource (FHIR) standard allow for open sharing and use of innovations across EHR systems. The aim of this project is to design and evaluate a SMARTapp on FHIR used across two large academic medical centers that exposes to physicians and nurses our new predictive data source from nursing documentation to increase care team situational awareness of at risk patients to decrease preventable adverse outcomes. The SMARTapp we will design and evaluate is the Communicating Narrative Concerns Entered by RNs (CONCERN) Clinical Decision Support (CDS) system. This will be integrated at four hospitals part of two health systems, Brigham and Women's Hospital (BWH) and Newton Wellesley Hospital (NWH), part of Partners Healthcare System (PHS) in Boston, and NewYork-Presbyterian Hospital-Columbia University Medical Center (NYP-CUMC) and The Allen Hospital, part of New York Presbyterian Health System (NYP) in New York. Specifically, we will: 1) validate desired thresholds for the CONCERN SMARTapp, 2) integrate the CONCERN SMARTapp for early warning of risky patient states within CDS tools, 3) evaluate the CONCERN SMARTapp on primary outcomes of in-hospital mortality and length of stay and secondary outcomes of cardiac arrest, unanticipated transfers to the intensive care unit, and 30-day hospital readmission rates. The methods we will use include: data-mining and natural language processing, factorial design surveys, simulation testing for evaluating team-based situational awareness, and outcomes evaluation in the Medical Intensive Care Units and Acute Care Units (non-ICU) at our study sites. Project narrative There are patients who die or have a bad outcome in the hospital and this could be prevented. Data in the nurses' notes could be used by computers and Apps to tell the care team that a patient is not doing well and that they should act more quickly. This project will build an App that makes it easier for the care team to see and understand that data and act quickly to save patients.",Communicating narrative Concerns entered by RNs (CONCERN),9869048,R01NR016941,"['Academic Medical Centers', 'Acute', 'Adverse event', 'Algorithms', 'Awareness', 'Big Data Methods', 'Boston', 'Cardiac', 'Cardiac Death', 'Caring', 'Cause of Death', 'Cessation of life', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Computers', 'Critical Care', 'Data', 'Data Analyses', 'Data Sources', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Electronic Health Record', 'Electronic Mail', 'Evaluation', 'Event', 'Exhibits', 'Exposure to', 'Foundations', 'Frequencies', 'Goals', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart Arrest', 'Hospital Mortality', 'Hospitals', 'Hour', 'Inpatients', 'Intensive Care Units', 'Intervention', 'Length of Stay', 'Medical', 'Methods', 'Natural Language Processing', 'New York', 'Notification', 'Nurses', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physicians', 'Physiological', 'Predictive Value', 'Presbyterian Church', 'Process', 'Proxy', 'Published Comment', 'Research', 'Resources', 'Rest', 'Risk', 'Sepsis', 'Signal Transduction', 'Site', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Woman', 'Work', 'acute care', 'adverse outcome', 'base', 'clinical decision support', 'clinically relevant', 'clinically significant', 'cognitive load', 'computerized', 'data mining', 'design', 'experience', 'falls', 'information display', 'innovation', 'interoperability', 'meetings', 'member', 'mortality', 'patient safety', 'patient subsets', 'point of care', 'prevent', 'preventable death', 'primary outcome', 'readmission rates', 'secondary outcome', 'simulation', 'software systems', 'support tools', 'tool', 'trend', 'user-friendly']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,595773,-0.007537095985086622
"Communicating narrative Concerns entered by RNs (CONCERN) PROJECT SUMMARY/ABSTRACT Annually, more than 200,000 patients die in U.S. hospitals from cardiac arrest1 and over 130,000 patients inpatients deaths are attributed to sepsis.2 These deaths are preventable if patients who are at risk are detected earlier. Our prior work found that nursing documentation within electronic health records (EHRs) contains information that could contribute to early detection and treatment, but these data are not being analyzed and exposed by EHRs to clinicians to initiate interventions quickly enough to save patients.36 We defined a new source of predictive data by analyzing the frequency and types of nursing documentation that indicated nurses' increased surveillance and level of concern for a patient. These data documented in the 48 hours preceding a cardiac arrest and hospital mortality were predictive of the event.3 While clinicians strive to provide the best care, there is a systematic problem within hospital settings of non-optimal communication between nurses and doctors leading to delays in care for patient at risk.68,9 Well-designed and tested EHRs are able to trend data and support communication and decision making, but too often fall short of these goals and actually increase clinician cognitive load through fragmented information displays, note bloat, and information overload.10 Substitutable Medical Applications & Reusable Technologies (SMARTapps) using Fast Health Interoperability Resource (FHIR) standard allow for open sharing and use of innovations across EHR systems. The aim of this project is to design and evaluate a SMARTapp on FHIR used across two large academic medical centers that exposes to physicians and nurses our new predictive data source from nursing documentation to increase care team situational awareness of at risk patients to decrease preventable adverse outcomes. The SMARTapp we will design and evaluate is the Communicating Narrative Concerns Entered by RNs (CONCERN) Clinical Decision Support (CDS) system. This will be integrated at four hospitals part of two health systems, Brigham and Women's Hospital (BWH) and Newton Wellesley Hospital (NWH), part of Partners Healthcare System (PHS) in Boston, and NewYork-Presbyterian Hospital-Columbia University Medical Center (NYP-CUMC) and The Allen Hospital, part of New York Presbyterian Health System (NYP) in New York. Specifically, we will: 1) validate desired thresholds for the CONCERN SMARTapp, 2) integrate the CONCERN SMARTapp for early warning of risky patient states within CDS tools, 3) evaluate the CONCERN SMARTapp on primary outcomes of in-hospital mortality and length of stay and secondary outcomes of cardiac arrest, unanticipated transfers to the intensive care unit, and 30-day hospital readmission rates. The methods we will use include: data-mining and natural language processing, factorial design surveys, simulation testing for evaluating team-based situational awareness, and outcomes evaluation in the Medical Intensive Care Units and Acute Care Units (non-ICU) at our study sites. Project narrative There are patients who die or have a bad outcome in the hospital and this could be prevented. Data in the nurses' notes could be used by computers and Apps to tell the care team that a patient is not doing well and that they should act more quickly. This project will build an App that makes it easier for the care team to see and understand that data and act quickly to save patients.",Communicating narrative Concerns entered by RNs (CONCERN),9693333,R01NR016941,"['Academic Medical Centers', 'Acute', 'Adverse event', 'Algorithms', 'Awareness', 'Big Data Methods', 'Boston', 'Cardiac', 'Cardiac Death', 'Caring', 'Cause of Death', 'Cessation of life', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Computers', 'Critical Care', 'Data', 'Data Analyses', 'Data Sources', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Electronic Health Record', 'Electronic Mail', 'Evaluation', 'Event', 'Exhibits', 'Exposure to', 'Foundations', 'Frequencies', 'Goals', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart Arrest', 'Hospital Mortality', 'Hospitals', 'Hour', 'Inpatients', 'Intensive Care Units', 'Intervention', 'Length of Stay', 'Medical', 'Methods', 'Natural Language Processing', 'New York', 'Notification', 'Nurses', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physicians', 'Physiological', 'Predictive Value', 'Presbyterian Church', 'Process', 'Proxy', 'Published Comment', 'Research', 'Resources', 'Rest', 'Risk', 'Sepsis', 'Signal Transduction', 'Site', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Woman', 'Work', 'adverse outcome', 'base', 'clinical decision support', 'clinically relevant', 'clinically significant', 'cognitive load', 'computerized', 'data mining', 'design', 'experience', 'falls', 'information display', 'innovation', 'interoperability', 'meetings', 'member', 'mortality', 'patient safety', 'patient subsets', 'point of care', 'prevent', 'preventable death', 'primary outcome', 'readmission rates', 'secondary outcome', 'simulation', 'software systems', 'support tools', 'tool', 'trend', 'user-friendly']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,646418,-0.007537095985086622
"Communicating narrative Concerns entered by RNs (CONCERN) PROJECT SUMMARY/ABSTRACT Annually, more than 200,000 patients die in U.S. hospitals from cardiac arrest1 and over 130,000 patients inpatients deaths are attributed to sepsis.2 These deaths are preventable if patients who are at risk are detected earlier. Our prior work found that nursing documentation within electronic health records (EHRs) contains information that could contribute to early detection and treatment, but these data are not being analyzed and exposed by EHRs to clinicians to initiate interventions quickly enough to save patients.36 We defined a new source of predictive data by analyzing the frequency and types of nursing documentation that indicated nurses' increased surveillance and level of concern for a patient. These data documented in the 48 hours preceding a cardiac arrest and hospital mortality were predictive of the event.3 While clinicians strive to provide the best care, there is a systematic problem within hospital settings of non-optimal communication between nurses and doctors leading to delays in care for patient at risk.68,9 Well-designed and tested EHRs are able to trend data and support communication and decision making, but too often fall short of these goals and actually increase clinician cognitive load through fragmented information displays, note bloat, and information overload.10 Substitutable Medical Applications & Reusable Technologies (SMARTapps) using Fast Health Interoperability Resource (FHIR) standard allow for open sharing and use of innovations across EHR systems. The aim of this project is to design and evaluate a SMARTapp on FHIR used across two large academic medical centers that exposes to physicians and nurses our new predictive data source from nursing documentation to increase care team situational awareness of at risk patients to decrease preventable adverse outcomes. The SMARTapp we will design and evaluate is the Communicating Narrative Concerns Entered by RNs (CONCERN) Clinical Decision Support (CDS) system. This will be integrated at four hospitals part of two health systems, Brigham and Women's Hospital (BWH) and Newton Wellesley Hospital (NWH), part of Partners Healthcare System (PHS) in Boston, and NewYork-Presbyterian Hospital-Columbia University Medical Center (NYP-CUMC) and The Allen Hospital, part of New York Presbyterian Health System (NYP) in New York. Specifically, we will: 1) validate desired thresholds for the CONCERN SMARTapp, 2) integrate the CONCERN SMARTapp for early warning of risky patient states within CDS tools, 3) evaluate the CONCERN SMARTapp on primary outcomes of in-hospital mortality and length of stay and secondary outcomes of cardiac arrest, unanticipated transfers to the intensive care unit, and 30-day hospital readmission rates. The methods we will use include: data-mining and natural language processing, factorial design surveys, simulation testing for evaluating team-based situational awareness, and outcomes evaluation in the Medical Intensive Care Units and Acute Care Units (non-ICU) at our study sites. Project narrative There are patients who die or have a bad outcome in the hospital and this could be prevented. Data in the nurses' notes could be used by computers and Apps to tell the care team that a patient is not doing well and that they should act more quickly. This project will build an App that makes it easier for the care team to see and understand that data and act quickly to save patients.",Communicating narrative Concerns entered by RNs (CONCERN),9678555,R01NR016941,"['Academic Medical Centers', 'Acute', 'Adverse event', 'Algorithms', 'Awareness', 'Big Data', 'Boston', 'Cardiac', 'Cardiac Death', 'Caring', 'Cause of Death', 'Cessation of life', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Computers', 'Critical Care', 'Data', 'Data Analyses', 'Data Analytics', 'Data Sources', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Electronic Health Record', 'Electronic Mail', 'Evaluation', 'Event', 'Exhibits', 'Exposure to', 'Foundations', 'Frequencies', 'Goals', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart Arrest', 'Hospital Mortality', 'Hospitals', 'Hour', 'Inpatients', 'Intensive Care Units', 'Intervention', 'Length of Stay', 'Medical', 'Methods', 'Natural Language Processing', 'New York', 'Notification', 'Nurses', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physicians', 'Physiological', 'Predictive Value', 'Presbyterian Church', 'Process', 'Proxy', 'Published Comment', 'Research', 'Resources', 'Rest', 'Risk', 'Sepsis', 'Signal Transduction', 'Site', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Woman', 'Work', 'adverse outcome', 'base', 'clinical decision support', 'clinically relevant', 'clinically significant', 'cognitive load', 'computerized', 'data mining', 'design', 'experience', 'falls', 'information display', 'innovation', 'interoperability', 'meetings', 'member', 'mortality', 'patient safety', 'patient subsets', 'point of care', 'prevent', 'preventable death', 'primary outcome', 'readmission rates', 'secondary outcome', 'simulation', 'software systems', 'support tools', 'tool', 'trend', 'user-friendly']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,658716,-0.007537095985086622
"Communicating narrative Concerns entered by RNs (CONCERN) PROJECT SUMMARY/ABSTRACT Annually, more than 200,000 patients die in U.S. hospitals from cardiac arrest1 and over 130,000 patients inpatients deaths are attributed to sepsis.2 These deaths are preventable if patients who are at risk are detected earlier. Our prior work found that nursing documentation within electronic health records (EHRs) contains information that could contribute to early detection and treatment, but these data are not being analyzed and exposed by EHRs to clinicians to initiate interventions quickly enough to save patients.36 We defined a new source of predictive data by analyzing the frequency and types of nursing documentation that indicated nurses' increased surveillance and level of concern for a patient. These data documented in the 48 hours preceding a cardiac arrest and hospital mortality were predictive of the event.3 While clinicians strive to provide the best care, there is a systematic problem within hospital settings of non-optimal communication between nurses and doctors leading to delays in care for patient at risk.68,9 Well-designed and tested EHRs are able to trend data and support communication and decision making, but too often fall short of these goals and actually increase clinician cognitive load through fragmented information displays, note bloat, and information overload.10 Substitutable Medical Applications & Reusable Technologies (SMARTapps) using Fast Health Interoperability Resource (FHIR) standard allow for open sharing and use of innovations across EHR systems. The aim of this project is to design and evaluate a SMARTapp on FHIR used across two large academic medical centers that exposes to physicians and nurses our new predictive data source from nursing documentation to increase care team situational awareness of at risk patients to decrease preventable adverse outcomes. The SMARTapp we will design and evaluate is the Communicating Narrative Concerns Entered by RNs (CONCERN) Clinical Decision Support (CDS) system. This will be integrated at four hospitals part of two health systems, Brigham and Women's Hospital (BWH) and Newton Wellesley Hospital (NWH), part of Partners Healthcare System (PHS) in Boston, and NewYork-Presbyterian Hospital-Columbia University Medical Center (NYP-CUMC) and The Allen Hospital, part of New York Presbyterian Health System (NYP) in New York. Specifically, we will: 1) validate desired thresholds for the CONCERN SMARTapp, 2) integrate the CONCERN SMARTapp for early warning of risky patient states within CDS tools, 3) evaluate the CONCERN SMARTapp on primary outcomes of in-hospital mortality and length of stay and secondary outcomes of cardiac arrest, unanticipated transfers to the intensive care unit, and 30-day hospital readmission rates. The methods we will use include: data-mining and natural language processing, factorial design surveys, simulation testing for evaluating team-based situational awareness, and outcomes evaluation in the Medical Intensive Care Units and Acute Care Units (non-ICU) at our study sites. Project narrative There are patients who die or have a bad outcome in the hospital and this could be prevented. Data in the nurses' notes could be used by computers and Apps to tell the care team that a patient is not doing well and that they should act more quickly. This project will build an App that makes it easier for the care team to see and understand that data and act quickly to save patients.",Communicating narrative Concerns entered by RNs (CONCERN),9284760,R01NR016941,"['Academic Medical Centers', 'Acute', 'Adverse event', 'Algorithms', 'Awareness', 'Big Data', 'Boston', 'Cardiac', 'Cardiac Death', 'Caring', 'Cause of Death', 'Cessation of life', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Computers', 'Critical Care', 'Data', 'Data Analyses', 'Data Analytics', 'Data Sources', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Electronic Health Record', 'Electronic Mail', 'Evaluation', 'Event', 'Exhibits', 'Foundations', 'Frequencies', 'Goals', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart Arrest', 'Hospital Mortality', 'Hospitals', 'Hour', 'Inpatients', 'Intensive Care Units', 'Intervention', 'Length of Stay', 'Medical', 'Methods', 'Natural Language Processing', 'New York', 'Notification', 'Nurses', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physicians', 'Physiological', 'Predictive Value', 'Presbyterian Church', 'Process', 'Proxy', 'Published Comment', 'Research', 'Resources', 'Rest', 'Risk', 'Sepsis', 'Signal Transduction', 'Site', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Woman', 'Work', 'adverse outcome', 'base', 'clinically relevant', 'clinically significant', 'cognitive load', 'computerized', 'data mining', 'design', 'experience', 'falls', 'hospital readmission', 'information display', 'innovation', 'interoperability', 'meetings', 'member', 'mortality', 'patient safety', 'patient subsets', 'point of care', 'prevent', 'primary outcome', 'secondary outcome', 'simulation', 'software systems', 'support tools', 'tool', 'trend', 'user-friendly']",NINR,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,516245,-0.007537095985086622
"Data Mining to Enhance Medical Research of Clincal Data    DESCRIPTION (provided by applicant):    The purpose of this proposal is to develop the use of text mining and data mining tools to investigate the relationship between physician practice and health outcomes. In the absence of specific guidelines, there remains substantial variability in physician practice for patients with similar diagnoses. It is possible to investigate that variability to find an optimal practice pattern. Since much of the information concerning patient outcomes is written as chart notes, text mining must be used to extract useful intelligence from those notes.   Aim I. To develop an algorithm to extract useful information from clinical records. This includes abstract  information from databases, physician notes in patient records, and text data electronically recorded in  pharmacy, nursing, and care management databases. This will enable to automatic extraction of meaningful intelligence from patient charts when the current method is primarily by using coders who perform manual extraction.   Aim II. To apply the developed tools to longitudinal data collected during pharmacist-consultant review of patient databases to determine the extent of polypharmacy in patients in long-term and hospital care who were treated for cardiovascular conditions and other co-morbid diseases. Standard statistical techniques cannot generally be used to examine polypharmacy because of the complexity of the data. Text mining can be used to automatically relate similar medications into meaningful clusters so that the relationship between drug interaction and medical outcome can be examined.   Aim III.To explore the relationship between treatment and disease. Data mining tools can be used to examine the relationship between physician treatment and quality. Text mining can be used to categorize descriptive measures of patient quality.   Aim IV. To provide a series of workshops to present the results to medical researchers to demonstrate the benefits of data mining techniques in analyzing clinical outcomes and to build a program of medical internships for students enrolled in the recently approved PhD program in Industrial and Applied Mathematics. The PhD program has a mandatory application requirement and internship.         n/a",Data Mining to Enhance Medical Research of Clincal Data,6700108,R15RR017285,"['abstracting', 'clinical research', 'computer program /software', 'data management', 'health care facility information system', 'health care quality', 'hospital utilization', 'human data', 'information retrieval', 'mathematics', 'medical records', 'nursing care', 'pharmacy']",NCRR,UNIVERSITY OF LOUISVILLE,R15,2004,146916,0.017372818009254797
"Understanding Figures & Captions for Location Proteomics    DESCRIPTION (provided by applicant):     This proposal is for mentored training in the molecular biosciences of an established computer scientist. The training plan includes basic and advanced course work in modern biology, interactions with biological research groups, attendance at seminars and conferences, and laboratory training. Mentoring on the culture and practices of biomedical research will be provided by the sponsor. The training institution has a longstanding tradition of interdisciplinary research and specific expertise in cutting edge proteomics methods. The candidate will be fully committed to a combination of training and research. The research plan is based on the critical need to organize and summarize the knowledge in the vast biomedical literature. Curated databases are expensive to create and maintain; do not estimate confidence of assertions; and do not allow for divergence of opinions. Information extraction (IE) methods can be used to partially overcome these limitations by automatically extracting certain types of information from biomedical text.       In most genres of scientific publication, the most important results in a paper are illustrated in non-textual forms, such as images and graphs. The broad thesis underlying our proposed research is that one can provide better access to the information in online scientific publications by extracting information jointly from figure images and their accompanying captions. With the exception of certain previous work by the Murphy group, previous biomedical IE systems have not attempted to extract information from image data, only text.      This proposal addresses these issues in the specific context of fluorescence microscope images depicting the subcellular localization of proteins. This goal is consonant with a major focus of current biomedical research: the identification of expressed genes and the description of the proteins they encode. Motivated by recent large-scale projects which major focus of current biomedical research is the identification of expressed genes and the description (or annotation) of the proteins they encode, the Murphy group has developed automated systems for recognizing subcellular structures in 2D and 3D images. Automated image analysis techniques have also been applied to images harvested from online biomedical journal articles. This system will be extended to create a robust, comprehensive toolset for extracting, verifying and querying biologically relevant information from the text and images found in online journals. Based on this toolkit, a set of tools will be developed for aiding researchers to identify and locate information found in online journals. Upon completion of the proposed training, the candidate will be well placed to take a leadership position in machine learning applications to the range of experimental methods used in biomedical research.               n/a",Understanding Figures & Captions for Location Proteomics,7033080,K25DA017357,"['bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'fluorescence microscopy', 'gene expression', 'image processing', 'online computer', 'protein localization', 'proteomics', 'publications', 'training']",NIDA,CARNEGIE-MELLON UNIVERSITY,K25,2006,133459,-0.019329535924030843
"Understanding Figures & Captions for Location Proteomics    DESCRIPTION (provided by applicant):     This proposal is for mentored training in the molecular biosciences of an established computer scientist. The training plan includes basic and advanced course work in modern biology, interactions with biological research groups, attendance at seminars and conferences, and laboratory training. Mentoring on the culture and practices of biomedical research will be provided by the sponsor. The training institution has a longstanding tradition of interdisciplinary research and specific expertise in cutting edge proteomics methods. The candidate will be fully committed to a combination of training and research. The research plan is based on the critical need to organize and summarize the knowledge in the vast biomedical literature. Curated databases are expensive to create and maintain; do not estimate confidence of assertions; and do not allow for divergence of opinions. Information extraction (IE) methods can be used to partially overcome these limitations by automatically extracting certain types of information from biomedical text.       In most genres of scientific publication, the most important results in a paper are illustrated in non-textual forms, such as images and graphs. The broad thesis underlying our proposed research is that one can provide better access to the information in online scientific publications by extracting information jointly from figure images and their accompanying captions. With the exception of certain previous work by the Murphy group, previous biomedical IE systems have not attempted to extract information from image data, only text.      This proposal addresses these issues in the specific context of fluorescence microscope images depicting the subcellular localization of proteins. This goal is consonant with a major focus of current biomedical research: the identification of expressed genes and the description of the proteins they encode. Motivated by recent large-scale projects which major focus of current biomedical research is the identification of expressed genes and the description (or annotation) of the proteins they encode, the Murphy group has developed automated systems for recognizing subcellular structures in 2D and 3D images. Automated image analysis techniques have also been applied to images harvested from online biomedical journal articles. This system will be extended to create a robust, comprehensive toolset for extracting, verifying and querying biologically relevant information from the text and images found in online journals. Based on this toolkit, a set of tools will be developed for aiding researchers to identify and locate information found in online journals. Upon completion of the proposed training, the candidate will be well placed to take a leadership position in machine learning applications to the range of experimental methods used in biomedical research.               n/a",Understanding Figures & Captions for Location Proteomics,6865478,K25DA017357,"['bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'fluorescence microscopy', 'gene expression', 'image processing', 'online computer', 'protein localization', 'proteomics', 'publications', 'training']",NIDA,CARNEGIE-MELLON UNIVERSITY,K25,2005,162750,-0.019329535924030843
"Understanding Figures & Captions for Location Proteomics    DESCRIPTION (provided by applicant):     This proposal is for mentored training in the molecular biosciences of an established computer scientist. The training plan includes basic and advanced course work in modern biology, interactions with biological research groups, attendance at seminars and conferences, and laboratory training. Mentoring on the culture and practices of biomedical research will be provided by the sponsor. The training institution has a longstanding tradition of interdisciplinary research and specific expertise in cutting edge proteomics methods. The candidate will be fully committed to a combination of training and research. The research plan is based on the critical need to organize and summarize the knowledge in the vast biomedical literature. Curated databases are expensive to create and maintain; do not estimate confidence of assertions; and do not allow for divergence of opinions. Information extraction (IE) methods can be used to partially overcome these limitations by automatically extracting certain types of information from biomedical text.       In most genres of scientific publication, the most important results in a paper are illustrated in non-textual forms, such as images and graphs. The broad thesis underlying our proposed research is that one can provide better access to the information in online scientific publications by extracting information jointly from figure images and their accompanying captions. With the exception of certain previous work by the Murphy group, previous biomedical IE systems have not attempted to extract information from image data, only text.      This proposal addresses these issues in the specific context of fluorescence microscope images depicting the subcellular localization of proteins. This goal is consonant with a major focus of current biomedical research: the identification of expressed genes and the description of the proteins they encode. Motivated by recent large-scale projects which major focus of current biomedical research is the identification of expressed genes and the description (or annotation) of the proteins they encode, the Murphy group has developed automated systems for recognizing subcellular structures in 2D and 3D images. Automated image analysis techniques have also been applied to images harvested from online biomedical journal articles. This system will be extended to create a robust, comprehensive toolset for extracting, verifying and querying biologically relevant information from the text and images found in online journals. Based on this toolkit, a set of tools will be developed for aiding researchers to identify and locate information found in online journals. Upon completion of the proposed training, the candidate will be well placed to take a leadership position in machine learning applications to the range of experimental methods used in biomedical research.               n/a",Understanding Figures & Captions for Location Proteomics,6709988,K25DA017357,"['bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'fluorescence microscopy', 'gene expression', 'image processing', 'online computer', 'protein localization', 'proteomics', 'publications', 'training']",NIDA,CARNEGIE-MELLON UNIVERSITY,K25,2004,161668,-0.019329535924030843
"ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis PROJECT SUMMARY Cognitive impairment, physical disability and progressive disease are common but understudied clinical outcomes that substantially impact employment and overall quality of life for individuals with multiple sclerosis (MS). We have recently developed and validated an assisted, web-based tool (ICLIC-MS) for systematic and longitudinal clinical outcomes data collection of MS-validated cognitive function measures, physical disability and progressive disease measures that are not reliably captured in the electronic health record (EHR). In response to FOA# PA-17-010, Use of Technology to Enhance Patient Outcomes and Prevent Illness, our team proposes the study of MS outcomes in a large, multi-ethnic population representative sample of more than 3,000 female and male MS cases from the Kaiser Permanente Northern California Health Plan Membership. We will integrate other EHR data such as important comorbid conditions, use of disease modifying therapy, MRI reports, as well as quality of life measures and employment histories. Our goals include: 1) comprehensively characterizing clinical outcomes in a large MS patient cohort; 2) developing and utilizing an integrated MS health report to enhance patient care; and 3) establishing a resource for clinical outcomes research in MS that also includes whole genomic and environmental exposure data. Findings from our proposed study represent an extraordinary opportunity to facilitate effective long-term management of MS, accelerate progress in the understanding of disease pathogenesis, predict patient trajectories and inform prevention strategies. We have assembled a team with strong expertise in clinical neurology/MS neurology, advanced epidemiologic methods, EHR structure and clinical care within a health maintenance organization, human genomics, biostatistics, and big data approaches. PROJECT NARRATIVE Our team has developed and validated an assisted web-based interface for longitudinal clinical data collection of cognitive function measures, physical disability and depression measures that are not reliably captured in the electronic health record (EHR) of multiple sclerosis (MS) patients. We will integrate several sources of patient data including genomic, clinical and EHR for 3,000 individuals to facilitate research and improve clinical care.",ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis,9952424,R01NR017431,"['Address', 'Area', 'Big Data', 'Biological', 'Biology', 'Biometry', 'California', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Clinical assessments', 'Cognition', 'Cognitive', 'Collection', 'Consumption', 'Data', 'Data Collection', 'Development', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Employment', 'Employment Status', 'Environmental Exposure', 'Epidemiologic Methods', 'Ethnic Origin', 'Family', 'Female', 'Funding Opportunities', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Maintenance Organizations', 'Impaired cognition', 'Individual', 'Internet', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mental Depression', 'Methods', 'Multiple Sclerosis', 'Neurologist', 'Neurology', 'Outcome', 'Outcome Measure', 'Outcome Study', 'Outcomes Research', 'Pathogenesis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Pilot Projects', 'Population', 'Predictive Factor', 'Preparation', 'Prevention strategy', 'Primary Health Care', 'Progressive Disease', 'Quality of life', 'Race', 'Recording of previous events', 'Reporting', 'Research', 'Resources', 'Risk Factors', 'Sampling', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Unemployment', 'Validity and Reliability', 'Visit', 'Work', 'base', 'clinical care', 'cognitive function', 'cohort', 'comorbidity', 'disability', 'electronic data', 'health plan', 'human genomics', 'improved', 'male', 'member', 'multidisciplinary', 'multiple sclerosis patient', 'new technology', 'physically handicapped', 'prevent', 'programs', 'response', 'sex', 'web based interface', 'web-based tool']",NINR,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2020,575200,0.04351686679363324
"ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis PROJECT SUMMARY Cognitive impairment, physical disability and progressive disease are common but understudied clinical outcomes that substantially impact employment and overall quality of life for individuals with multiple sclerosis (MS). We have recently developed and validated an assisted, web-based tool (ICLIC-MS) for systematic and longitudinal clinical outcomes data collection of MS-validated cognitive function measures, physical disability and progressive disease measures that are not reliably captured in the electronic health record (EHR). In response to FOA# PA-17-010, Use of Technology to Enhance Patient Outcomes and Prevent Illness, our team proposes the study of MS outcomes in a large, multi-ethnic population representative sample of more than 3,000 female and male MS cases from the Kaiser Permanente Northern California Health Plan Membership. We will integrate other EHR data such as important comorbid conditions, use of disease modifying therapy, MRI reports, as well as quality of life measures and employment histories. Our goals include: 1) comprehensively characterizing clinical outcomes in a large MS patient cohort; 2) developing and utilizing an integrated MS health report to enhance patient care; and 3) establishing a resource for clinical outcomes research in MS that also includes whole genomic and environmental exposure data. Findings from our proposed study represent an extraordinary opportunity to facilitate effective long-term management of MS, accelerate progress in the understanding of disease pathogenesis, predict patient trajectories and inform prevention strategies. We have assembled a team with strong expertise in clinical neurology/MS neurology, advanced epidemiologic methods, EHR structure and clinical care within a health maintenance organization, human genomics, biostatistics, and big data approaches. PROJECT NARRATIVE Our team has developed and validated an assisted web-based interface for longitudinal clinical data collection of cognitive function measures, physical disability and depression measures that are not reliably captured in the electronic health record (EHR) of multiple sclerosis (MS) patients. We will integrate several sources of patient data including genomic, clinical and EHR for 3,000 individuals to facilitate research and improve clinical care.",ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis,9763663,R01NR017431,"['Address', 'Area', 'Big Data', 'Biological', 'Biology', 'Biometry', 'California', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Clinical assessments', 'Cognition', 'Cognitive', 'Collection', 'Comorbidity', 'Consumption', 'Data', 'Data Collection', 'Development', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Employment', 'Employment Status', 'Environmental Exposure', 'Epidemiologic Methods', 'Ethnic Origin', 'Family', 'Female', 'Funding Opportunities', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Maintenance Organizations', 'Impaired cognition', 'Individual', 'Internet', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mental Depression', 'Methods', 'Multiple Sclerosis', 'Neurologist', 'Neurology', 'Outcome', 'Outcome Measure', 'Outcome Study', 'Outcomes Research', 'Pathogenesis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physically Handicapped', 'Physicians', 'Pilot Projects', 'Population', 'Predictive Factor', 'Preparation', 'Prevention strategy', 'Primary Health Care', 'Progressive Disease', 'Quality of life', 'Race', 'Recording of previous events', 'Reporting', 'Research', 'Resources', 'Risk Factors', 'Sampling', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Unemployment', 'Validity and Reliability', 'Visit', 'Work', 'base', 'clinical care', 'cognitive function', 'cohort', 'disability', 'electronic data', 'health plan', 'human genomics', 'improved', 'male', 'member', 'multidisciplinary', 'multiple sclerosis patient', 'new technology', 'prevent', 'programs', 'response', 'sex', 'web based interface', 'web-based tool']",NINR,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2019,606029,0.04351686679363324
"ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis PROJECT SUMMARY Cognitive impairment, physical disability and progressive disease are common but understudied clinical outcomes that substantially impact employment and overall quality of life for individuals with multiple sclerosis (MS). We have recently developed and validated an assisted, web-based tool (ICLIC-MS) for systematic and longitudinal clinical outcomes data collection of MS-validated cognitive function measures, physical disability and progressive disease measures that are not reliably captured in the electronic health record (EHR). In response to FOA# PA-17-010, Use of Technology to Enhance Patient Outcomes and Prevent Illness, our team proposes the study of MS outcomes in a large, multi-ethnic population representative sample of more than 3,000 female and male MS cases from the Kaiser Permanente Northern California Health Plan Membership. We will integrate other EHR data such as important comorbid conditions, use of disease modifying therapy, MRI reports, as well as quality of life measures and employment histories. Our goals include: 1) comprehensively characterizing clinical outcomes in a large MS patient cohort; 2) developing and utilizing an integrated MS health report to enhance patient care; and 3) establishing a resource for clinical outcomes research in MS that also includes whole genomic and environmental exposure data. Findings from our proposed study represent an extraordinary opportunity to facilitate effective long-term management of MS, accelerate progress in the understanding of disease pathogenesis, predict patient trajectories and inform prevention strategies. We have assembled a team with strong expertise in clinical neurology/MS neurology, advanced epidemiologic methods, EHR structure and clinical care within a health maintenance organization, human genomics, biostatistics, and big data approaches. PROJECT NARRATIVE Our team has developed and validated an assisted web-based interface for longitudinal clinical data collection of cognitive function measures, physical disability and depression measures that are not reliably captured in the electronic health record (EHR) of multiple sclerosis (MS) patients. We will integrate several sources of patient data including genomic, clinical and EHR for 3,000 individuals to facilitate research and improve clinical care.",ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis,9596197,R01NR017431,"['Address', 'Area', 'Big Data', 'Biological', 'Biology', 'Biometry', 'California', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Clinical assessments', 'Cognition', 'Cognitive', 'Collection', 'Comorbidity', 'Data', 'Data Collection', 'Development', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Employment', 'Employment Status', 'Environmental Exposure', 'Epidemiologic Methods', 'Ethnic Origin', 'Family', 'Female', 'Funding Opportunities', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Maintenance Organizations', 'Impaired cognition', 'Individual', 'Internet', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mental Depression', 'Methods', 'Multiple Sclerosis', 'Neurologist', 'Neurology', 'Outcome', 'Outcome Measure', 'Outcome Study', 'Outcomes Research', 'Pathogenesis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physically Handicapped', 'Physicians', 'Pilot Projects', 'Population', 'Predictive Factor', 'Preparation', 'Prevention strategy', 'Primary Health Care', 'Progressive Disease', 'Quality of life', 'Race', 'Recording of previous events', 'Reporting', 'Research', 'Resources', 'Risk Factors', 'Sampling', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Unemployment', 'Validity and Reliability', 'Visit', 'Work', 'base', 'clinical care', 'cognitive function', 'cohort', 'disability', 'electronic data', 'health plan', 'human genomics', 'improved', 'male', 'member', 'multidisciplinary', 'multiple sclerosis patient', 'new technology', 'prevent', 'programs', 'response', 'sex', 'web based interface', 'web-based tool']",NINR,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2018,566927,0.04351686679363324
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8852613,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,213115,0.004734544747098566
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8664845,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,214609,0.004734544747098566
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8599843,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,224942,0.004734544747098566
"Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques Despite their adverse impact on patient quality of life and healthcare utilization and costs, symptom clusters (SCs) in common adult chronic conditions such as cancer, heart failure (HF), type 2 diabetes mellitus (T2DM), and chronic obstructive pulmonary disease (COPD) are understudied and poorly understood. The lack of access to real world, longitudinal patient symptom data sets and inability to adequately model the complexity of SCs has greatly limited research. Based on our previous work, we propose that these gaps can be addressed in an innovative way using electronic health records (EHRs) and data science techniques. Our overall objective is to develop, apply and refine, and implement an optimized data processing and analysis pipeline for the characterization of SCs in common adult chronic conditions for use with EHR data. We hypothesize that a core set of SCs is shared among all common adult chronic conditions and that distinct SCs characterize specific conditions and/or treatments. The long term training goal of this project is to assist Dr. Koleck in becoming an independent investigator conducting a program of research dedicated to mitigating symptom burden in patients with chronic conditions through use of informatics and omics (e.g., genomics and proteomics), the focus of her pre-doctoral work. Using exceptional resources available from Columbia University, the K99 phase of this project will focus on the development of a rigorous pipeline; essential competencies in SC analysis and interpretation; and the data science techniques of clinical data mining, natural language processing, machine learning, and data visualization. In the R00 phase, Dr. Koleck will independently implement the pipeline in another medical center to determine the reproducibility of identified SCs and begin to explore clinical predictors (e.g., socio-demographics, laboratory results, and medications) of SCs. The specific aims are to 1) develop a data-driven pipeline for the characterization of SCs from EHRs using a cohort of adult patients diagnosed with cancer, as SCs have been most systematically characterized in this condition; 2) apply the pipeline to three other common adult chronic conditions that share biological and behavioral risk factors with cancer, i.e., HF, T2DM, and COPD, and evaluate SCs in these conditions; and 3) determine if SCs differ for cancer, HF, T2DM, and COPD when implementing the pipeline within another medical center and explore clinically relevant, EHR- documented predictors of identified SCs. To accomplish research aims and training goals, an interdisciplinary team of scientists with expertise in symptom science, biomedical informatics, data science, pertinent clinical domains, and career development mentorship has been assembled. This research is significant because a pipeline that accommodates the format in which symptom data is already being documented in EHRs has the potential to greatly accelerate the acquisition of SC knowledge and expedite clinical translation of symptom mitigation strategies. Given the array of new competencies to be developed, this K99/R00 award is necessary for achieving the candidates career goal of advancing chronic condition symptom science. The proposed research is relevant to public health because adult patients diagnosed with chronic conditions are frequently burdened by two or more co-occurring, related symptoms. Development of an optimized process to study multiple symptoms collected in patient electronic health records has the potential to lead to new knowledge and improved symptom management. The proposed research addresses the NINR theme of symptom science and a key area in the NINR Strategic Plan, taking advantage of innovations in data science in order to develop interventions to promote health and wellness that are leading-edge, effective, and translatable to clinical practice.",Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques,10118580,R00NR017651,"['18 year old', 'Academic Medical Centers', 'Address', 'Adult', 'Advance Directives', 'American', 'Anxiety', 'Area', 'Award', 'Behavioral', 'Biological', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical assessments', 'Cluster Analysis', 'Code', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Detection', 'Development', 'Diagnosis', 'Dyspnea', 'Electronic Health Record', 'Equipment and supply inventories', 'Ethnic Origin', 'Fatigue', 'Funding', 'Future', 'Genetic', 'Genomics', 'Goals', 'Health Care Costs', 'Health Promotion', 'Healthcare Systems', 'Heart failure', 'Impaired cognition', 'Informatics', 'Intervention', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Lead', 'Life', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mastectomy', 'Medical Genetics', 'Medical center', 'Mentorship', 'Modeling', 'Natural Language Processing', 'Nausea', 'Nausea and Vomiting', 'Neurobehavioral Manifestations', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncology', 'Pain', 'Pathologic', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Postoperative Nausea and Vomiting', 'Procedures', 'Proteomics', 'Pruritus', 'Public Health', 'Quality of life', 'Race', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk Factors', 'Science', 'Scientist', 'Signs and Symptoms', 'Sleep disturbances', 'Strategic Planning', 'Structure', 'Symptoms', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Validation', 'Woman', 'Work', 'Xerostomia', 'base', 'biomarker discovery', 'biomedical informatics', 'career', 'career development', 'clinical data warehouse', 'clinical practice', 'clinical predictors', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'data analysis pipeline', 'data mining', 'data visualization', 'data warehouse', 'electronic data', 'experience', 'health care service utilization', 'health data', 'innovation', 'knowledge translation', 'malignant breast neoplasm', 'patient oriented', 'pre-doctoral', 'process optimization', 'programs', 'sociodemographics', 'statistics', 'symptom cluster', 'symptom management', 'symptom science', 'symptomatic improvement', 'unsupervised learning']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2020,248966,0.013127572516549257
"Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques Despite their adverse impact on patient quality of life and healthcare utilization and costs, symptom clusters (SCs) in common adult chronic conditions such as cancer, heart failure (HF), type 2 diabetes mellitus (T2DM), and chronic obstructive pulmonary disease (COPD) are understudied and poorly understood. The lack of access to real world, longitudinal patient symptom data sets and inability to adequately model the complexity of SCs has greatly limited research. Based on our previous work, we propose that these gaps can be addressed in an innovative way using electronic health records (EHRs) and data science techniques. Our overall objective is to develop, apply and refine, and implement an optimized data processing and analysis pipeline for the characterization of SCs in common adult chronic conditions for use with EHR data. We hypothesize that a core set of SCs is shared among all common adult chronic conditions and that distinct SCs characterize specific conditions and/or treatments. The long term training goal of this project is to assist Dr. Koleck in becoming an independent investigator conducting a program of research dedicated to mitigating symptom burden in patients with chronic conditions through use of informatics and omics (e.g., genomics and proteomics), the focus of her pre-doctoral work. Using exceptional resources available from Columbia University, the K99 phase of this project will focus on the development of a rigorous pipeline; essential competencies in SC analysis and interpretation; and the data science techniques of clinical data mining, natural language processing, machine learning, and data visualization. In the R00 phase, Dr. Koleck will independently implement the pipeline in another medical center to determine the reproducibility of identified SCs and begin to explore clinical predictors (e.g., socio-demographics, laboratory results, and medications) of SCs. The specific aims are to 1) develop a data-driven pipeline for the characterization of SCs from EHRs using a cohort of adult patients diagnosed with cancer, as SCs have been most systematically characterized in this condition; 2) apply the pipeline to three other common adult chronic conditions that share biological and behavioral risk factors with cancer, i.e., HF, T2DM, and COPD, and evaluate SCs in these conditions; and 3) determine if SCs differ for cancer, HF, T2DM, and COPD when implementing the pipeline within another medical center and explore clinically relevant, EHR- documented predictors of identified SCs. To accomplish research aims and training goals, an interdisciplinary team of scientists with expertise in symptom science, biomedical informatics, data science, pertinent clinical domains, and career development mentorship has been assembled. This research is significant because a pipeline that accommodates the format in which symptom data is already being documented in EHRs has the potential to greatly accelerate the acquisition of SC knowledge and expedite clinical translation of symptom mitigation strategies. Given the array of new competencies to be developed, this K99/R00 award is necessary for achieving the candidates career goal of advancing chronic condition symptom science. The proposed research is relevant to public health because adult patients diagnosed with chronic conditions are frequently burdened by two or more co-occurring, related symptoms. Development of an optimized process to study multiple symptoms collected in patient electronic health records has the potential to lead to new knowledge and improved symptom management. The proposed research addresses the NINR theme of symptom science and a key area in the NINR Strategic Plan, taking advantage of innovations in data science in order to develop interventions to promote health and wellness that are leading-edge, effective, and translatable to clinical practice.",Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques,9673231,K99NR017651,"['18 year old', 'Academic Medical Centers', 'Address', 'Adult', 'Advance Directives', 'American', 'Anxiety', 'Area', 'Award', 'Behavioral', 'Biological', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical assessments', 'Cluster Analysis', 'Code', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Detection', 'Development', 'Diagnosis', 'Dyspnea', 'Electronic Health Record', 'Equipment and supply inventories', 'Ethnic Origin', 'Fatigue', 'Funding', 'Future', 'Genetic', 'Genomics', 'Goals', 'Health Care Costs', 'Health Promotion', 'Healthcare Systems', 'Heart failure', 'Impaired cognition', 'Informatics', 'Intervention', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Lead', 'Life', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mastectomy', 'Medical Genetics', 'Medical center', 'Mentorship', 'Modeling', 'Natural Language Processing', 'Nausea', 'Nausea and Vomiting', 'Neurobehavioral Manifestations', 'Non-Insulin-Dependent Diabetes Mellitus', 'Pain', 'Pathologic', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Postoperative Nausea and Vomiting', 'Procedures', 'Proteomics', 'Pruritus', 'Public Health', 'Quality of life', 'Race', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk Factors', 'Science', 'Scientist', 'Signs and Symptoms', 'Sleep disturbances', 'Strategic Planning', 'Structure', 'Symptoms', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Validation', 'Woman', 'Work', 'Xerostomia', 'analysis pipeline', 'base', 'biomarker discovery', 'biomedical informatics', 'career', 'career development', 'clinical data warehouse', 'clinical practice', 'clinical predictors', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'data mining', 'data visualization', 'data warehouse', 'electronic data', 'experience', 'health care service utilization', 'health data', 'innovation', 'knowledge translation', 'malignant breast neoplasm', 'oncology', 'patient oriented', 'pre-doctoral', 'process optimization', 'programs', 'sociodemographics', 'statistics', 'symptom cluster', 'symptom management', 'symptom science', 'symptomatic improvement', 'unsupervised learning']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2019,90185,0.013127572516549257
"Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques Despite their adverse impact on patient quality of life and healthcare utilization and costs, symptom clusters (SCs) in common adult chronic conditions such as cancer, heart failure (HF), type 2 diabetes mellitus (T2DM), and chronic obstructive pulmonary disease (COPD) are understudied and poorly understood. The lack of access to real world, longitudinal patient symptom data sets and inability to adequately model the complexity of SCs has greatly limited research. Based on our previous work, we propose that these gaps can be addressed in an innovative way using electronic health records (EHRs) and data science techniques. Our overall objective is to develop, apply and refine, and implement an optimized data processing and analysis pipeline for the characterization of SCs in common adult chronic conditions for use with EHR data. We hypothesize that a core set of SCs is shared among all common adult chronic conditions and that distinct SCs characterize specific conditions and/or treatments. The long term training goal of this project is to assist Dr. Koleck in becoming an independent investigator conducting a program of research dedicated to mitigating symptom burden in patients with chronic conditions through use of informatics and omics (e.g., genomics and proteomics), the focus of her pre-doctoral work. Using exceptional resources available from Columbia University, the K99 phase of this project will focus on the development of a rigorous pipeline; essential competencies in SC analysis and interpretation; and the data science techniques of clinical data mining, natural language processing, machine learning, and data visualization. In the R00 phase, Dr. Koleck will independently implement the pipeline in another medical center to determine the reproducibility of identified SCs and begin to explore clinical predictors (e.g., socio-demographics, laboratory results, and medications) of SCs. The specific aims are to 1) develop a data-driven pipeline for the characterization of SCs from EHRs using a cohort of adult patients diagnosed with cancer, as SCs have been most systematically characterized in this condition; 2) apply the pipeline to three other common adult chronic conditions that share biological and behavioral risk factors with cancer, i.e., HF, T2DM, and COPD, and evaluate SCs in these conditions; and 3) determine if SCs differ for cancer, HF, T2DM, and COPD when implementing the pipeline within another medical center and explore clinically relevant, EHR- documented predictors of identified SCs. To accomplish research aims and training goals, an interdisciplinary team of scientists with expertise in symptom science, biomedical informatics, data science, pertinent clinical domains, and career development mentorship has been assembled. This research is significant because a pipeline that accommodates the format in which symptom data is already being documented in EHRs has the potential to greatly accelerate the acquisition of SC knowledge and expedite clinical translation of symptom mitigation strategies. Given the array of new competencies to be developed, this K99/R00 award is necessary for achieving the candidates career goal of advancing chronic condition symptom science. The proposed research is relevant to public health because adult patients diagnosed with chronic conditions are frequently burdened by two or more co-occurring, related symptoms. Development of an optimized process to study multiple symptoms collected in patient electronic health records has the potential to lead to new knowledge and improved symptom management. The proposed research addresses the NINR theme of symptom science and a key area in the NINR Strategic Plan, taking advantage of innovations in data science in order to develop interventions to promote health and wellness that are leading-edge, effective, and translatable to clinical practice.",Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques,9504168,K99NR017651,"['18 year old', 'Academic Medical Centers', 'Address', 'Adult', 'Advance Directives', 'American', 'Anxiety', 'Area', 'Award', 'Behavioral', 'Biological', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical assessments', 'Cluster Analysis', 'Code', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Detection', 'Development', 'Diagnosis', 'Dyspnea', 'Electronic Health Record', 'Equipment and supply inventories', 'Ethnic Origin', 'Fatigue', 'Funding', 'Future', 'Genetic', 'Genomics', 'Goals', 'Health Care Costs', 'Health Promotion', 'Healthcare Systems', 'Heart failure', 'Impaired cognition', 'Informatics', 'Intervention', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Lead', 'Life', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mastectomy', 'Medical Genetics', 'Medical center', 'Mentorship', 'Modeling', 'Natural Language Processing', 'Nausea', 'Nausea and Vomiting', 'Neurobehavioral Manifestations', 'Non-Insulin-Dependent Diabetes Mellitus', 'Pain', 'Pathologic', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Postoperative Nausea and Vomiting', 'Procedures', 'Proteomics', 'Pruritus', 'Public Health', 'Quality of life', 'Race', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk Factors', 'Science', 'Scientist', 'Signs and Symptoms', 'Sleep disturbances', 'Strategic Planning', 'Structure', 'Symptoms', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Validation', 'Woman', 'Work', 'Xerostomia', 'base', 'biomarker discovery', 'biomedical informatics', 'career', 'career development', 'clinical data warehouse', 'clinical practice', 'clinical predictors', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'data mining', 'data visualization', 'data warehouse', 'demographics', 'electronic data', 'experience', 'health care service utilization', 'health data', 'innovation', 'knowledge translation', 'malignant breast neoplasm', 'oncology', 'patient oriented', 'pre-doctoral', 'process optimization', 'programs', 'statistics', 'symptom cluster', 'symptom management', 'symptom science', 'symptomatic improvement', 'unsupervised learning']",NINR,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2018,90050,0.013127572516549257
"TECTONICS (Telemedicine Control Tower for the OR: Navigating Information, Care and Safety) trial Abstract Adverse outcomes, including death, respiratory failure and renal failure, are common after surgery, and represent a serious public health challenge. Such adverse outcomes can be mitigated through integrated, collaborative health information technology solutions that provide clinicians cognitive and computational support. The chief motivation for the TECTONICS (Telemedicine Control Tower for the OR: Navigating Information, Care and Safety) trial is that a multi-faceted telemedicine solution has the potential to facilitate the dynamic assessment of risk, diagnose negative patient trajectories, and implement evidence-based practices. The net result for patients would be improved safety and outcomes. Our telemedicine solution, called the Anesthesiology Control Tower (ACT), encompasses real-time patient data integration from the electronic health record, clinician decision support, machine learning algorithms that predict adverse outcomes, and remote monitoring for the operating room (OR). This conceptualization of sophisticated remote monitoring for the OR is somewhat analogous to an air traffic control tower for a busy airport. The innovative TECTONICS trial will build on a series of preliminary studies (funded by the Agency for Healthcare Research and Quality, and the National Science Foundation) that have (i) established the usefulness and usability of a prototype telemedicine ACT; (ii) customized and enhanced decision-support alerts for the ACT, based on clinician user feedback; (iii) designed, developed, and tested machine learning algorithms that predict adverse postoperative outcomes; and (iv) established the feasibility of conducing a real-world randomized trial of the prototype ACT. The TECTONICS trial builds logically on these preliminary studies. Aim 1 is to show that we can implement and sustain an integrated ACT system. As part of this, we will iteratively assess the accuracy of our machine learning algorithms and modify them to improve their ability to predict in real time when patients are at high risk for experiencing negative outcomes. Aim 2 is to understand how the ACT system affects clinicians (anesthesiologists and certified registered nurse anesthetists [CRNAs]) thinking, decision-making and behavior. This understanding will help us to enhance the ACT system, improve workflow processes in the ACT and in the OR, and improve collaborative interactions between anesthesiologists and CRNAs. Aim 3 is to conduct a rigorous clinical trial. We will evaluate the impact of the ACT system on the quality of care in the OR, and clinical outcomes such as intraoperative awareness, and postoperative delirium, renal failure, respiratory failure, and 30-day mortality. TECTONICS will be the first practical and scientifically rigorous trial of a telemedicine solution for the operating room, and will inform the usefulness of incorporating such technology in routine care of surgical patients, including under-resourced healthcare settings. With many millions undergoing surgery yearly, this feasible application of technology could signal a major shift in the safety and quality of perioperative care, and translate into substantial societal gain. Narrative Adverse outcomes, including death, are common after surgery and represent a public health challenge. There is an urgent need to assess the potential usefulness of a remote technology-based control center for the operating room to dynamically assess risk, diagnose negative patient trajectories, implement evidence-based practices, and improve outcomes. This innovative study will rigorously assess whether the implementation of an 'anesthesiology control tower', with sophisticated decision-support tools, improves the care, safety and outcomes of surgical patients.","TECTONICS (Telemedicine Control Tower for the OR: Navigating Information, Care and Safety) trial",9930157,R01NR017916,"['Address', 'Adherence', 'Affect', 'Air', 'Algorithms', 'Anesthesia procedures', 'Anesthesiology', 'Anesthetics', 'Area', 'Awareness', 'Behavior', 'Caring', 'Certified registered nurse anesthetist', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Cognitive', 'Collaborations', 'Computer software', 'Consent', 'Custom', 'Data', 'Data Science', 'Decision Making', 'Delirium', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Enabling Factors', 'Engineering', 'Evidence based practice', 'Failure', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Funding Agency', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'Informatics', 'Institutes', 'Institution', 'Kidney Failure', 'Machine Learning', 'Measures', 'Monitor', 'Motivation', 'Network-based', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patient Monitoring', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Perioperative', 'Perioperative Care', 'Perioperative complication', 'Postoperative Period', 'Process', 'Public Health', 'Quality of Care', 'Randomized', 'Resources', 'Respiratory Failure', 'Risk', 'Risk Assessment', 'Safety', 'Science', 'Series', 'Signal Transduction', 'System', 'Technology', 'Telemedicine', 'Testing', 'Thinking', 'Time', 'Training', 'Translating', 'United States Agency for Healthcare Research and Quality', 'Update', 'adverse outcome', 'algorithm development', 'base', 'clinical decision support', 'clinically relevant', 'cognitive process', 'computer science', 'data integration', 'design', 'evidence base', 'experience', 'health care settings', 'health information technology', 'high risk', 'implementation science', 'improved', 'improved outcome', 'innovation', 'machine learning algorithm', 'modifiable risk', 'mortality', 'neural network', 'novel', 'patient oriented', 'postoperative delirium', 'prediction algorithm', 'prevent', 'prototype', 'randomized trial', 'routine care', 'safety outcomes', 'support tools', 'surgery outcome', 'usability', 'user-friendly', 'waiver']",NINR,WASHINGTON UNIVERSITY,R01,2020,644350,0.015616499993525115
"TECTONICS (Telemedicine Control Tower for the OR: Navigating Information, Care and Safety) trial Abstract Adverse outcomes, including death, respiratory failure and renal failure, are common after surgery, and represent a serious public health challenge. Such adverse outcomes can be mitigated through integrated, collaborative health information technology solutions that provide clinicians cognitive and computational support. The chief motivation for the TECTONICS (Telemedicine Control Tower for the OR: Navigating Information, Care and Safety) trial is that a multi-faceted telemedicine solution has the potential to facilitate the dynamic assessment of risk, diagnose negative patient trajectories, and implement evidence-based practices. The net result for patients would be improved safety and outcomes. Our telemedicine solution, called the Anesthesiology Control Tower (ACT), encompasses real-time patient data integration from the electronic health record, clinician decision support, machine learning algorithms that predict adverse outcomes, and remote monitoring for the operating room (OR). This conceptualization of sophisticated remote monitoring for the OR is somewhat analogous to an air traffic control tower for a busy airport. The innovative TECTONICS trial will build on a series of preliminary studies (funded by the Agency for Healthcare Research and Quality, and the National Science Foundation) that have (i) established the usefulness and usability of a prototype telemedicine ACT; (ii) customized and enhanced decision-support alerts for the ACT, based on clinician user feedback; (iii) designed, developed, and tested machine learning algorithms that predict adverse postoperative outcomes; and (iv) established the feasibility of conducing a real-world randomized trial of the prototype ACT. The TECTONICS trial builds logically on these preliminary studies. Aim 1 is to show that we can implement and sustain an integrated ACT system. As part of this, we will iteratively assess the accuracy of our machine learning algorithms and modify them to improve their ability to predict in real time when patients are at high risk for experiencing negative outcomes. Aim 2 is to understand how the ACT system affects clinicians (anesthesiologists and certified registered nurse anesthetists [CRNAs]) thinking, decision-making and behavior. This understanding will help us to enhance the ACT system, improve workflow processes in the ACT and in the OR, and improve collaborative interactions between anesthesiologists and CRNAs. Aim 3 is to conduct a rigorous clinical trial. We will evaluate the impact of the ACT system on the quality of care in the OR, and clinical outcomes such as intraoperative awareness, and postoperative delirium, renal failure, respiratory failure, and 30-day mortality. TECTONICS will be the first practical and scientifically rigorous trial of a telemedicine solution for the operating room, and will inform the usefulness of incorporating such technology in routine care of surgical patients, including under-resourced healthcare settings. With many millions undergoing surgery yearly, this feasible application of technology could signal a major shift in the safety and quality of perioperative care, and translate into substantial societal gain. Narrative Adverse outcomes, including death, are common after surgery and represent a public health challenge. There is an urgent need to assess the potential usefulness of a remote technology-based control center for the operating room to dynamically assess risk, diagnose negative patient trajectories, implement evidence-based practices, and improve outcomes. This innovative study will rigorously assess whether the implementation of an 'anesthesiology control tower', with sophisticated decision-support tools, improves the care, safety and outcomes of surgical patients.","TECTONICS (Telemedicine Control Tower for the OR: Navigating Information, Care and Safety) trial",9738886,R01NR017916,"['Address', 'Adherence', 'Affect', 'Air', 'Algorithms', 'Anesthesia procedures', 'Anesthesiology', 'Anesthetics', 'Area', 'Awareness', 'Behavior', 'Caring', 'Certified registered nurse anesthetist', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Cognitive', 'Collaborations', 'Computer software', 'Consent', 'Custom', 'Data', 'Data Science', 'Decision Making', 'Delirium', 'Development', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Enabling Factors', 'Engineering', 'Evidence based practice', 'Failure', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Funding Agency', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'Informatics', 'Institutes', 'Institution', 'Kidney Failure', 'Machine Learning', 'Measures', 'Monitor', 'Motivation', 'Network-based', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patient Monitoring', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Perioperative', 'Perioperative Care', 'Perioperative complication', 'Postoperative Period', 'Process', 'Public Health', 'Quality of Care', 'Randomized', 'Resources', 'Respiratory Failure', 'Risk', 'Risk Assessment', 'Safety', 'Science', 'Series', 'Signal Transduction', 'System', 'Technology', 'Telemedicine', 'Testing', 'Thinking', 'Time', 'Training', 'Translating', 'United States Agency for Healthcare Research and Quality', 'Update', 'adverse outcome', 'base', 'clinical decision support', 'clinically relevant', 'cognitive process', 'computer science', 'data integration', 'design', 'evidence base', 'experience', 'health care settings', 'health information technology', 'high risk', 'implementation science', 'improved', 'improved outcome', 'innovation', 'machine learning algorithm', 'modifiable risk', 'mortality', 'neural network', 'novel', 'patient oriented', 'postoperative delirium', 'prediction algorithm', 'prevent', 'prototype', 'randomized trial', 'routine care', 'support tools', 'surgery outcome', 'usability', 'user-friendly', 'waiver']",NINR,WASHINGTON UNIVERSITY,R01,2019,640937,0.015616499993525115
"Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients Failure to rescue (FTR), a nurse-sensitive national metric of health care quality, refers to death of a hospitalized patient from a treatable complication, and is potentiated by failure to recognize and appropriately respond to early signs of complications. There is a paucity of research examining patient features predictive of FTR complications. Such information could shift the current paradigm of nursing surveillance to earlier recognition, prevention and treatment of FTR complications, thereby saving lives. New-onset venous thromboembolism (VTE), an FTR complication occurring as either a deep vein thrombosis (DVT) or a pulmonary embolism (PE), is the leading cause of preventable hospital death, carrying a high risk of mortality and a national cost burden of $7 billion annually. VTE is a complex disease process involving interactions between clinical risk factors and acquired and/or inherited susceptibilities to thrombosis. Although biomarkers and clinical factors associated with VTE have been identified, clinical manifestations are subtle, presenting gradually over hours to days. Current VTE risk assessment models (RAM), the cornerstone of prevention, have limited utility due to their complexity and lack of reliability, generalizability and external validation. A critical gap in VTE risk modeling research is that while new-onset VTE pathology evolves over the course of hospitalization, no current models incorporate the progressive accrual of dynamic patient data and pattern evolution over time in their modeling approaches. The totality of routinely collected electronic health record (EHR) data is massive in terms of volume, variety, and production at a rapid velocity in real-time. Such big data could be used in machine learning (ML) analytic approaches to process time series clinical data to identify subtle, evolving feature patterns predictive of new-onset VTE and address this gap. This study proposes to assemble a large scale, multi-source, multi-dimensional VTE study dataset, and in tandem, systematically define the EHR data elements associated with a new-onset VTE diagnosis for computable phenotype algorithm development. We will then apply machine learning analytic approaches to baseline and accruing intensive time series clinical data in the curated dataset to develop models identifying data patterns and features predictive of dynamically evolving new-onset VTE in adult hospitalized patients. This proposal aligns with NINRs strategic vision for nurse scientists to employ new strategies for collecting and analyzing complex big data sets to permit better understanding of the biological underpinnings of health, and improve ways nurses prevent and manage illness. This innovative study and individualized training plan under a strong and well- established team, represents initial steps in the applicants research trajectory focused on data science approaches to predict FTR complication risk, and develop, implement and test dynamic RAMs to inform targeted prevention and treatment decisions. Discovering new knowledge informing real-time decision making, nursing surveillance practices and care delivery systems can improve nurse sensitive patient outcomes. PROJECT NARRATIVE Venous thromboembolism (VTE) is the leading cause of preventable hospital death. This study first proposes to develop a reproducible computable phenotype definition for new-onset VTE cohort ascertainment from the electronic health record, and then develop dynamic models for VTE risk assessment through the application of machine learning algorithms to massive electronic health record clinical data repositories. Such models can inform the mechanisms underlying this complex disease and identify subtle pattern changes in a patients condition forecasting a VTE event, enabling earlier nurse identification and intervention, and decreasing the development of complications and failure to rescue in hospitalized patients.",Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients,10219195,F31NR018102,"['Address', 'Adult', 'Adverse event', 'Big Data', 'Biological', 'Biological Markers', 'Censuses', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Cohort Studies', 'Complex', 'Complication', 'Data', 'Data Element', 'Data Science', 'Data Set', 'Decision Making', 'Deep Vein Thrombosis', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Electronic Health Record', 'Event', 'Evolution', 'Failure', 'Frequencies', 'Future', 'Genetic Predisposition to Disease', 'Gold', 'Health', 'Hospitalization', 'Hospitals', 'Hour', 'Human', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Pathology', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Prevention', 'Process', 'Production', 'Pulmonary Embolism', 'Quality of Care', 'Readability', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Savings', 'Scientist', 'Selection for Treatments', 'Sensitivity and Specificity', 'Series', 'Signs and Symptoms', 'Source', 'Standardization', 'System', 'Testing', 'Thrombosis', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Venous', 'Vision', 'algorithm development', 'base', 'care delivery', 'classification algorithm', 'clinical data warehouse', 'clinical decision-making', 'clinical risk', 'cohort', 'computable phenotypes', 'cost', 'disease phenotype', 'health care quality', 'high risk', 'improved', 'innovation', 'interest', 'machine learning algorithm', 'mortality risk', 'multidimensional data', 'prevent', 'venous thromboembolism']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2020,17002,0.04258501733118291
"Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients Failure to rescue (FTR), a nurse-sensitive national metric of health care quality, refers to death of a hospitalized patient from a treatable complication, and is potentiated by failure to recognize and appropriately respond to early signs of complications. There is a paucity of research examining patient features predictive of FTR complications. Such information could shift the current paradigm of nursing surveillance to earlier recognition, prevention and treatment of FTR complications, thereby saving lives. New-onset venous thromboembolism (VTE), an FTR complication occurring as either a deep vein thrombosis (DVT) or a pulmonary embolism (PE), is the leading cause of preventable hospital death, carrying a high risk of mortality and a national cost burden of $7 billion annually. VTE is a complex disease process involving interactions between clinical risk factors and acquired and/or inherited susceptibilities to thrombosis. Although biomarkers and clinical factors associated with VTE have been identified, clinical manifestations are subtle, presenting gradually over hours to days. Current VTE risk assessment models (RAM), the cornerstone of prevention, have limited utility due to their complexity and lack of reliability, generalizability and external validation. A critical gap in VTE risk modeling research is that while new-onset VTE pathology evolves over the course of hospitalization, no current models incorporate the progressive accrual of dynamic patient data and pattern evolution over time in their modeling approaches. The totality of routinely collected electronic health record (EHR) data is massive in terms of volume, variety, and production at a rapid velocity in real-time. Such big data could be used in machine learning (ML) analytic approaches to process time series clinical data to identify subtle, evolving feature patterns predictive of new-onset VTE and address this gap. This study proposes to assemble a large scale, multi-source, multi-dimensional VTE study dataset, and in tandem, systematically define the EHR data elements associated with a new-onset VTE diagnosis for computable phenotype algorithm development. We will then apply machine learning analytic approaches to baseline and accruing intensive time series clinical data in the curated dataset to develop models identifying data patterns and features predictive of dynamically evolving new-onset VTE in adult hospitalized patients. This proposal aligns with NINRs strategic vision for nurse scientists to employ new strategies for collecting and analyzing complex big data sets to permit better understanding of the biological underpinnings of health, and improve ways nurses prevent and manage illness. This innovative study and individualized training plan under a strong and well- established team, represents initial steps in the applicants research trajectory focused on data science approaches to predict FTR complication risk, and develop, implement and test dynamic RAMs to inform targeted prevention and treatment decisions. Discovering new knowledge informing real-time decision making, nursing surveillance practices and care delivery systems can improve nurse sensitive patient outcomes. PROJECT NARRATIVE Venous thromboembolism (VTE) is the leading cause of preventable hospital death. This study first proposes to develop a reproducible computable phenotype definition for new-onset VTE cohort ascertainment from the electronic health record, and then develop dynamic models for VTE risk assessment through the application of machine learning algorithms to massive electronic health record clinical data repositories. Such models can inform the mechanisms underlying this complex disease and identify subtle pattern changes in a patients condition forecasting a VTE event, enabling earlier nurse identification and intervention, and decreasing the development of complications and failure to rescue in hospitalized patients.",Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients,9794015,F31NR018102,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Big Data', 'Biological', 'Biological Markers', 'Censuses', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Cohort Studies', 'Complex', 'Complication', 'Data', 'Data Element', 'Data Science', 'Data Set', 'Decision Making', 'Deep Vein Thrombosis', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Electronic Health Record', 'Event', 'Evolution', 'Failure', 'Frequencies', 'Future', 'Genetic Predisposition to Disease', 'Gold', 'Health', 'Hospitalization', 'Hospitals', 'Hour', 'Human', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Pathology', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Prevention', 'Process', 'Production', 'Pulmonary Embolism', 'Quality of Care', 'Readability', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Savings', 'Scientist', 'Selection for Treatments', 'Sensitivity and Specificity', 'Series', 'Signs and Symptoms', 'Source', 'Standardization', 'System', 'Testing', 'Thromboembolism', 'Thrombosis', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Venous', 'Vision', 'base', 'care delivery', 'classification algorithm', 'clinical data warehouse', 'clinical decision-making', 'clinical risk', 'cohort', 'cost', 'disease phenotype', 'health care quality', 'high risk', 'improved', 'innovation', 'interest', 'machine learning algorithm', 'mortality risk', 'multidimensional data', 'prevent']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2019,45016,0.04258501733118291
"Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients Failure to rescue (FTR), a nurse-sensitive national metric of health care quality, refers to death of a hospitalized patient from a treatable complication, and is potentiated by failure to recognize and appropriately respond to early signs of complications. There is a paucity of research examining patient features predictive of FTR complications. Such information could shift the current paradigm of nursing surveillance to earlier recognition, prevention and treatment of FTR complications, thereby saving lives. New-onset venous thromboembolism (VTE), an FTR complication occurring as either a deep vein thrombosis (DVT) or a pulmonary embolism (PE), is the leading cause of preventable hospital death, carrying a high risk of mortality and a national cost burden of $7 billion annually. VTE is a complex disease process involving interactions between clinical risk factors and acquired and/or inherited susceptibilities to thrombosis. Although biomarkers and clinical factors associated with VTE have been identified, clinical manifestations are subtle, presenting gradually over hours to days. Current VTE risk assessment models (RAM), the cornerstone of prevention, have limited utility due to their complexity and lack of reliability, generalizability and external validation. A critical gap in VTE risk modeling research is that while new-onset VTE pathology evolves over the course of hospitalization, no current models incorporate the progressive accrual of dynamic patient data and pattern evolution over time in their modeling approaches. The totality of routinely collected electronic health record (EHR) data is massive in terms of volume, variety, and production at a rapid velocity in real-time. Such big data could be used in machine learning (ML) analytic approaches to process time series clinical data to identify subtle, evolving feature patterns predictive of new-onset VTE and address this gap. This study proposes to assemble a large scale, multi-source, multi-dimensional VTE study dataset, and in tandem, systematically define the EHR data elements associated with a new-onset VTE diagnosis for computable phenotype algorithm development. We will then apply machine learning analytic approaches to baseline and accruing intensive time series clinical data in the curated dataset to develop models identifying data patterns and features predictive of dynamically evolving new-onset VTE in adult hospitalized patients. This proposal aligns with NINRs strategic vision for nurse scientists to employ new strategies for collecting and analyzing complex big data sets to permit better understanding of the biological underpinnings of health, and improve ways nurses prevent and manage illness. This innovative study and individualized training plan under a strong and well- established team, represents initial steps in the applicants research trajectory focused on data science approaches to predict FTR complication risk, and develop, implement and test dynamic RAMs to inform targeted prevention and treatment decisions. Discovering new knowledge informing real-time decision making, nursing surveillance practices and care delivery systems can improve nurse sensitive patient outcomes. PROJECT NARRATIVE Venous thromboembolism (VTE) is the leading cause of preventable hospital death. This study first proposes to develop a reproducible computable phenotype definition for new-onset VTE cohort ascertainment from the electronic health record, and then develop dynamic models for VTE risk assessment through the application of machine learning algorithms to massive electronic health record clinical data repositories. Such models can inform the mechanisms underlying this complex disease and identify subtle pattern changes in a patients condition forecasting a VTE event, enabling earlier nurse identification and intervention, and decreasing the development of complications and failure to rescue in hospitalized patients.",Machine Learning to Determine Dynamically Evolving New-Onset Venous Thromboembolic (VTE) Event Risk in Hospitalized Patients,9610301,F31NR018102,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Big Data', 'Biological', 'Biological Markers', 'Censuses', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Cohort Studies', 'Complex', 'Complication', 'Data', 'Data Element', 'Data Science', 'Data Set', 'Decision Making', 'Deep Vein Thrombosis', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Electronic Health Record', 'Event', 'Evolution', 'Failure', 'Frequencies', 'Future', 'Genetic Predisposition to Disease', 'Gold', 'Health', 'Hospitalization', 'Hospitals', 'Hour', 'Human', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Pathology', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Prevention', 'Process', 'Production', 'Pulmonary Embolism', 'Quality of Care', 'Readability', 'Reproducibility', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Savings', 'Scientist', 'Selection for Treatments', 'Sensitivity and Specificity', 'Series', 'Signs and Symptoms', 'Source', 'Standardization', 'System', 'Testing', 'Thromboembolism', 'Thrombosis', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Venous', 'Vision', 'base', 'care delivery', 'clinical data warehouse', 'clinical decision-making', 'clinical risk', 'cohort', 'cost', 'disease phenotype', 'health care quality', 'high risk', 'improved', 'innovation', 'interest', 'mortality', 'prevent']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2018,44524,0.04258501733118291
"Automating assessment of obesity care quality    DESCRIPTION (provided by applicant): Current trends suggest that obesity prevalence will continue to rise and that costs of treating obesity-related disease will dramatically increase as the population ages. Despite NHLBI guidelines for preventing, diagnosing, and treating obesity among adults, most health care systems have been slow to respond to this looming public health problem. This slow response is partly due to the inability to assess adherence to obesity diagnosis and treatment guidelines. In particular, the lack of appropriate Health IT for integrating diverse clinical data on obesity, even within state-of-the-art electronic medical record systems (EMRs), makes it difficult to evaluate the quality of care, measure the effectiveness of new intervention programs, and make rational decisions at system, organization, and individual patient levels. EMRs offer the potential to efficiently assess large populations, however much of the data necessary for obesity care assessment are unavailable to automated methods because they reside in the text clinical notes of the EMR. Previous studies have shown that although some data of interest are recorded in easily retrievable fields (e.g., body weights recorded as a vital sign; standard diagnosis codes), much of the treatment information is found only in free-text clinical notes. This research aims to develop, validate, apply, and evaluate a scalable method for routine and comprehensive measurement of outpatient obesity care quality. To accomplish this, we will extend MediClass (a ""Medical Classifier""), which is a proven technology for extracting care quality data from both coded data and free-text clinical notes in the EMR. This research will perform retrospective analysis of adult primary care from the EMR data of two distinct health systems: a   mid-sized HMO (Kaiser Permanente Northwest, KPNW) and a consortium of public health clinics (OCHIN) including a diverse sample of patients, providers, and health care practices of the West Coast states (primarily Oregon, but also Washington and California). We propose to use Health IT to integrate diverse data and knowledge that advance quality improvement for both insured and the indigent, uninsured, and underinsured populations of this region. We will first develop obesity care quality (OCQ) measures using up to-date NHLBI guidelines for diagnosis and treatment of obesity. Next, we will develop and validate an automated method for applying these measures to comprehensive EMR data. At each study site, the Medi Class system will extract coded data and use natural language processing (NLP) on free-text clinical notes to identify OCQ-relevant clinical events in the EMR. Then we will apply the OCQ measures to assess current levels of obesity care quality in the two health systems. Finally, we will evaluate the associations between OCQ measures of recommended obesity care and provider characteristics as well as clinical outcomes for patients, including change in weight.           PROJECT NARRATIVE This study will improve care for obese and overweight patients by improving the technology we use for measuring the quality of care for these populations. This study will use specialized computer programs to analyze the electronic medical records of obese and overweight patients. The results of this work will help us determine if patients from two different health care systems are receiving recommended care, and how to better monitor the delivery of care for obese and overweight patients.",Automating assessment of obesity care quality,8136907,R18HS018157,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R18,2011,247887,0.052794219183235805
"Automating assessment of obesity care quality    DESCRIPTION (provided by applicant): Current trends suggest that obesity prevalence will continue to rise and that costs of treating obesity-related disease will dramatically increase as the population ages. Despite NHLBI guidelines for preventing, diagnosing, and treating obesity among adults, most health care systems have been slow to respond to this looming public health problem. This slow response is partly due to the inability to assess adherence to obesity diagnosis and treatment guidelines. In particular, the lack of appropriate Health IT for integrating diverse clinical data on obesity, even within state-of-the-art electronic medical record systems (EMRs), makes it difficult to evaluate the quality of care, measure the effectiveness of new intervention programs, and make rational decisions at system, organization, and individual patient levels. EMRs offer the potential to efficiently assess large populations, however much of the data necessary for obesity care assessment are unavailable to automated methods because they reside in the text clinical notes of the EMR. Previous studies have shown that although some data of interest are recorded in easily retrievable fields (e.g., body weights recorded as a vital sign; standard diagnosis codes), much of the treatment information is found only in free-text clinical notes. This research aims to develop, validate, apply, and evaluate a scalable method for routine and comprehensive measurement of outpatient obesity care quality. To accomplish this, we will extend MediClass (a ""Medical Classifier""), which is a proven technology for extracting care quality data from both coded data and free-text clinical notes in the EMR. This research will perform retrospective analysis of adult primary care from the EMR data of two distinct health systems: a   mid-sized HMO (Kaiser Permanente Northwest, KPNW) and a consortium of public health clinics (OCHIN) including a diverse sample of patients, providers, and health care practices of the West Coast states (primarily Oregon, but also Washington and California). We propose to use Health IT to integrate diverse data and knowledge that advance quality improvement for both insured and the indigent, uninsured, and underinsured populations of this region. We will first develop obesity care quality (OCQ) measures using up to-date NHLBI guidelines for diagnosis and treatment of obesity. Next, we will develop and validate an automated method for applying these measures to comprehensive EMR data. At each study site, the Medi Class system will extract coded data and use natural language processing (NLP) on free-text clinical notes to identify OCQ-relevant clinical events in the EMR. Then we will apply the OCQ measures to assess current levels of obesity care quality in the two health systems. Finally, we will evaluate the associations between OCQ measures of recommended obesity care and provider characteristics as well as clinical outcomes for patients, including change in weight.           PROJECT NARRATIVE This study will improve care for obese and overweight patients by improving the technology we use for measuring the quality of care for these populations. This study will use specialized computer programs to analyze the electronic medical records of obese and overweight patients. The results of this work will help us determine if patients from two different health care systems are receiving recommended care, and how to better monitor the delivery of care for obese and overweight patients.",Automating assessment of obesity care quality,7941068,R18HS018157,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R18,2010,496075,0.052794219183235805
"Automating assessment of obesity care quality    DESCRIPTION (provided by applicant): Current trends suggest that obesity prevalence will continue to rise and that costs of treating obesity-related disease will dramatically increase as the population ages. Despite NHLBI guidelines for preventing, diagnosing, and treating obesity among adults, most health care systems have been slow to respond to this looming public health problem. This slow response is partly due to the inability to assess adherence to obesity diagnosis and treatment guidelines. In particular, the lack of appropriate Health IT for integrating diverse clinical data on obesity, even within state-of-the-art electronic medical record systems (EMRs), makes it difficult to evaluate the quality of care, measure the effectiveness of new intervention programs, and make rational decisions at system, organization, and individual patient levels. EMRs offer the potential to efficiently assess large populations, however much of the data necessary for obesity care assessment are unavailable to automated methods because they reside in the text clinical notes of the EMR. Previous studies have shown that although some data of interest are recorded in easily retrievable fields (e.g., body weights recorded as a vital sign; standard diagnosis codes), much of the treatment information is found only in free-text clinical notes. This research aims to develop, validate, apply, and evaluate a scalable method for routine and comprehensive measurement of outpatient obesity care quality. To accomplish this, we will extend MediClass (a ""Medical Classifier""), which is a proven technology for extracting care quality data from both coded data and free-text clinical notes in the EMR. This research will perform retrospective analysis of adult primary care from the EMR data of two distinct health systems: a   mid-sized HMO (Kaiser Permanente Northwest, KPNW) and a consortium of public health clinics (OCHIN) including a diverse sample of patients, providers, and health care practices of the West Coast states (primarily Oregon, but also Washington and California). We propose to use Health IT to integrate diverse data and knowledge that advance quality improvement for both insured and the indigent, uninsured, and underinsured populations of this region. We will first develop obesity care quality (OCQ) measures using up to-date NHLBI guidelines for diagnosis and treatment of obesity. Next, we will develop and validate an automated method for applying these measures to comprehensive EMR data. At each study site, the Medi Class system will extract coded data and use natural language processing (NLP) on free-text clinical notes to identify OCQ-relevant clinical events in the EMR. Then we will apply the OCQ measures to assess current levels of obesity care quality in the two health systems. Finally, we will evaluate the associations between OCQ measures of recommended obesity care and provider characteristics as well as clinical outcomes for patients, including change in weight.           PROJECT NARRATIVE This study will improve care for obese and overweight patients by improving the technology we use for measuring the quality of care for these populations. This study will use specialized computer programs to analyze the electronic medical records of obese and overweight patients. The results of this work will help us determine if patients from two different health care systems are receiving recommended care, and how to better monitor the delivery of care for obese and overweight patients.",Automating assessment of obesity care quality,7761795,R18HS018157,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R18,2009,447671,0.052794219183235805
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7478824,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2008,177729,-0.05067884533779837
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7305430,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2007,229030,-0.05067884533779837
"Human Subject Research Enhancements Program We propose to enhance the data consistency and integrity of oversight and tracking systems for human subjects research at Mayo Foundation. Our specific aims include: 1) a comprehensive information modeling exercise to understand the interrelationships and dependencies of administrative and clinical data elements related to human subjects research oversight; 2) building common application components that will simplify the creation of research protocols, IRB application, research subject enrollment and consent, and administrative tracking; 3) providing full text and natural language processing based indices to project abstracts, applications, minutes, and administrative notes, to facilitate the authorized searching and retrieval of materials human subject related to human subject review; and 4) coordinating the information model, modular software tools, and textual indexing, as preliminary work for a competitive informatics proposal for adverse event recognition, pattern detection, and the consistent recording of drugs, devices and outcomes measures. n/a",Human Subject Research Enhancements Program,6591449,S07RR018225,"['abstracting', ' behavioral /social science research tag', ' clinical research', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' health science research support', ' human rights', ' information systems']",NCRR,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",S07,2002,183410,0.045244330394856126
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7935475,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2010,50100,0.041421035956311525
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7774682,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2009,48782,0.041421035956311525
"Modernizing Emergency Department Nurse Triage via Big Data Analytics PROJECT SUMMARY/ ABSTRACT Emergency department (ED) nurses triage over 136 million patients each year in the United States. The goal of triage is to assess and identify clinical conditions in order to prioritize those with the most significant risk of morbidity and mortality. Current practice uses the Emergency Severity Index (ESI) score to group patients by resource utilization. ESI has significant limitations including: racial bias, poor relation to patient-centered outcomes, subjectivity, and failure to differentiate acute patients (poor specificity). As such, the ESI tool fails to identify patient-specific factors, that are present at the time of triage, to accurately predict critical conditions requiring life-saving treatments. Due to its time sensitivity, complex symptomology, variable outcomes, and a national cost burden of $21 billion, acute coronary syndrome (ACS) will be used as an exemplar time-sensitive condition to develop a new predictive machine learning algorithm to be used for ED triage. Of 800,000 new annual ACS cases in the United States, nurses fail to identify approximately 50% during triage. This suggests an urgent need to develop triage tools, specifically ones that correctly identify ACS early, which could potentially reduce mortality by 10%-20%. This project proposes to use big data analytics to address the critical gaps of the ESI tool and nurse failure to identify ACS at triage. A large cohort of patients presenting to 17 different EDs with symptoms suspicious of ACS will be used to create a multidimensional database, extracting routinely collected patient factors from the electronic health record data acquired at initial nurse triage. This project will use state-of-the-art machine learning approaches that incorporate the complex interactions between patient factors to identify patients with true critical coronary occlusion that require time dependent treatment. The innovation of this study stems from having access to a world renowned academic medical center that is able to conduct full-scale studies using electronic health records of over 4.2 million patient encounters. This project aligns with the NINRs strategic vision for nurses to use emerging technologies (big data) to predict patient trajectories, inform interventions and support real time clinical decision making. By using advanced machine learning concepts, we will translate our final machine model into a robust clinical tool to assist nurses in making real time clinical decisions to accurately identity ACS events and initiate timely treatment, thereby improving patient outcomes. Study findings have potential to change the paradigm of ED nurse triage to be more objective and data-driven, thereby recognizing critical conditions at initial triage and eliminating unnecessary morbidity and mortality. PROJECT NARRATIVE Emergency department nurses triage over 136 million patients a year, using the Emergency Severity Index score that has significant limitations and often fails to identify patients with critical time-sensitive conditions such as acute coronary syndrome (ACS) approximately 50% of the time. To address these gaps, this project aims to develop a predictive algorithm using state-of-the-art machine learning concepts that incorporates the complex interactions between medical data available at nurse triage in order to identify patients with true critical coronary occlusion that requires time dependent treatment. Such a model can be translated into a robust clinical decision support tool to assist nurses in making real time clinical decisions to accurately identify ACS events and initiate timely treatment, thereby improving patient outcomes.",Modernizing Emergency Department Nurse Triage via Big Data Analytics,10051328,F31NR018589,"['Academic Medical Centers', 'Accident and Emergency department', 'Acute', 'Address', 'Algorithms', 'Area', 'Area Under Curve', 'Big Data', 'Big Data Methods', 'Chest Pain', 'Clinical', 'Complex', 'Coronary Occlusions', 'Data', 'Data Aggregation', 'Data Science', 'Data Set', 'Databases', 'Dyspepsia', 'Dyspnea', 'Electronic Health Record', 'Emergency Medicine', 'Emergency Nursing', 'Emergency Situation', 'Emerging Technologies', 'Event', 'Failure', 'Goals', 'Hospitalization', 'Interdisciplinary Study', 'Intervention', 'Life', 'Machine Learning', 'Manuals', 'Medical', 'Medical History', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Nature', 'Nausea and Vomiting', 'Nurses', 'Nursing Models', 'Outcome', 'Outcome Study', 'Output', 'Palpitations', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'ROC Curve', 'Research', 'Resources', 'Retrospective cohort', 'Risk', 'Sampling', 'Savings', 'Severities', 'Specificity', 'Suggestion', 'Symptoms', 'Syncope', 'Techniques', 'Time', 'Training', 'Translating', 'Triage', 'United States', 'Universities', 'Validation', 'Vision', 'Work', 'acute coronary syndrome', 'advanced analytics', 'base', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'follow-up', 'health record', 'improved', 'indexing', 'innovation', 'machine learning algorithm', 'mathematical model', 'mortality', 'pain patient', 'prediction algorithm', 'predictive modeling', 'primary outcome', 'racial bias', 'routine care', 'stem', 'support tools', 'symptomatology', 'tool']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2020,14320,0.013490961328730417
"Patients Perceptions of Electronic Health Record use during initial oncology outpatient clinic visits Project Summary It is estimated there will be nearly 1.7 million newly diagnosed cancer patients this year in the U.S. The initial oncology visits for a newly diagnosed cancer patient represent a critical focus for provider-patient communication. This communication involves complex decision-making and emotions, which directly impact patient self-efficacy, confidence, trust, understanding of the disease process and treatment options, and ultimately choice of and adherence to treatment. It has been reported that some newly diagnosed patients leave their oncology appointments with a suboptimal understanding of their disease process, care plan and treatment options, which may influence their decision-making and adherence to recommended therapies. The use of the electronic health record (EHR) during clinic visits has changed the dynamics of patient-provider communication. Increasingly, research has focused on how to use EHR in a patient-centered way to enhance patient-provider communication and patient engagement during a clinic visit. To date, most such research has been conducted in the primary care setting. However, the primary care setting focuses on chronic disease management, acute minor illness, and healthy lifestyle/prevention. The situation is different for the initial oncology visits, where typically multiple different treatment options (some potentially toxic), their associated risks and side effects and impact on survival and disease progression or recurrence are discussed for curable to potentially rapidly fatal diseases. Therefore, it is important to extend the existing knowledge base to better understand how the EHR use in the oncology setting impact communication, trust and address patient's information needs about the specific cancer, extent of disease, treatment options and prognosis. In addition, mental workload, defined as the total amount of mental effort being used in the working memory, is a well- studied human factors phenomenon. How people process information is influenced by mental workload, which is a critical aspect of doctor-patient communication, especially in highly demanding situations, like new patient oncology visits. Using technologies such as EHRs have introduced additional cognitive workload to providers during clinic visits. However, no studies have examined the mental workload of a patient during a clinic visit. To address this gap in the literature, we propose to study the following specific aims study aims in this study: 1): Assess the patient perception of the impact of EHR use on patient-doctor communication, trust and cognitive workload in new patient oncology visits. 2): Identify and cluster patterns of doctor-patient communication with regards to EHR use in the visit using systems engineering tools. The results from our investigation will have necessary data for future funding applications that will further determine how to best incorporate and design requirements for patient-centered EHR use in outpatient oncology settings. Project Narrative This proposed pilot study addresses the perception of newly diagnosed cancer patients on their initial consultations with oncology providers. Results from these analyses will provide important patient-centered insights into determining how best to incorporate EHR use in oncology settings to improve patient-provider communication of information that is essential for delivering high-quality, patient-centered care. This pilot study will also provide important initial findings and necessary data for future funding applications that will further determine how to best incorporate and design requirements for patient-centered EHR use in outpatient oncology settings with the ultimate goal of enhancing patient-provider communication to optimize patient understanding, trust, engagement of their treatment decisions and ensure the delivery of high-quality, patient- centered cancer care.",Patients Perceptions of Electronic Health Record use during initial oncology outpatient clinic visits,9880792,R15NR018965,"['Acute', 'Address', 'Adherence', 'Affect', 'Ambulatory Care Facilities', 'Appointment', 'Cancer Patient', 'Caring', 'Cessation of life', 'Chronic Disease', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinics and Hospitals', 'Clip', 'Cognitive', 'Communication', 'Complex', 'Consultations', 'Consumption', 'Data', 'Decision Making', 'Depersonalization', 'Disadvantaged', 'Disease', 'Disease Management', 'Disease Progression', 'Electronic Health Record', 'Emotions', 'Engineering', 'Ensure', 'Funding', 'Future', 'Goals', 'Human', 'Interview', 'Investigation', 'Label', 'Literature', 'Malignant Neoplasms', 'Medical', 'Methods', 'Minor', 'Modernization', 'Newly Diagnosed', 'Oncology', 'Outcome', 'Outcome Measure', 'Outpatients', 'Participant', 'Patient-Centered Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perception', 'Physicians', 'Pilot Projects', 'Prevention', 'Primary Health Care', 'Process', 'Professional Burnout', 'Provider', 'Psyche structure', 'Recurrence', 'Reporting', 'Research', 'Risk', 'Self Efficacy', 'Short-Term Memory', 'Surveys', 'Symptoms', 'System', 'Techniques', 'Technology', 'Time', 'Transcript', 'Trust', 'Video Recording', 'Visit', 'Workload', 'base', 'burnout', 'cancer care', 'computerized', 'design', 'healthy lifestyle', 'improved', 'information processing', 'insight', 'knowledge base', 'outcome forecast', 'patient engagement', 'patient oriented', 'patient-clinician communication', 'primary care setting', 'racial diversity', 'shared decision making', 'side effect', 'text searching', 'tool', 'trend']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R15,2020,430999,0.03539548139392936
"Data-driven shared decision-making to reduce symptom burden in atrial fibrillation PROJECT SUMMARY Atrial fibrillation (AF) is the most common cardiac arrhythmia with symptoms that directly impair health-related quality of life (HRQoL). While catheter ablation is routinely performed to reduce AF symptoms and improve HRQoL, we lack evidence about which symptoms are likely to improve and for which patients. Ablations themselves may cause complications that lead to lower HRQoL. Shared decision-making (SDM) is a widely encouraged practice to navigate such complex choices by aligning treatment benefits and risks with the patient's stated values. However, no SDM interventions have focused explicitly on AF symptoms due to a lack of rigorous evidence about post-ablation symptom patterns and the decision aids necessary to communicate those findings. In this K99/R00 application, we propose to use data from electronic health records (EHRs) to characterize post-ablation symptom patterns, and display them in decision-aid visualizations to support personalized SDM about the best treatment modalities for an individual's patient's AF symptoms. In the K99 phase, we will use natural language processing (NLP) and machine learning (ML) to extract and analyze symptom data from narrative notes in EHRs. We will also employ a rigorous, user-centered design protocol created during my postdoctoral work to develop decision-aid visualizations. In the R00 phase, we will conduct a feasibility study in which the interactive decision-aid visualizations are introduced during consultations about ablation in clinical electrophysiology practices. Our specific aims are: (1) identify common symptom patterns in patients with paroxysmal AF post-catheter ablation (n>32,014); (2) develop and evaluate decision-aid visualizations of common AF symptom patterns (n=50); and (3) evaluate the feasibility of implementing the decision-aid visualizations in clinical practice (n=75). The training objectives of this project include mastering competencies in NLP, ML, human-computer interaction, symptom science, and implementation science. The long-term training goal is to assist Dr. Reading Turchioe to become a faculty member with an independent program of research. She seeks to lead an interdisciplinary team of scientists and clinicians committed to improving symptom management and HRQoL for individuals living with AF and other chronic cardiovascular conditions, with an eye towards health equity. To ensure success for the planned research and training activities, a multidisciplinary team of mentors with complementary expertise, established, well-funded programs of research, and a record of mentoring high-quality trainees will advise her. Moreover, this research will be conducted in a world-class academic medical center with exceptional resources for building and implementing technology and data science methods using EHR data. The proposed research is both significant and innovative: NLP and ML methods to extract EHR data for decision-aid visualizations are a novel approach to SDM in the understudied area of AF symptoms. Together, these techniques promise to enhance HRQoL for other AF treatment modalities (e.g. medications, lifestyle changes) and other chronic cardiovascular conditions. ! ! PROJECT NARRATIVE Our research has public health significance because atrial fibrillation is the most common cardiac arrhythmia and expected to double in prevalence in the next decade as the population ages. Real-world evidence from electronic health record data displayed in personalized decision-aid visualizations can enable patients and providers to choose together the optimal treatments for symptom reduction. Our proposal addresses NINR's key areas of Symptom Science: Promoting Personalized Health Strategies and Promoting Innovation: Technology to Improve Health by leveraging innovative technologies to deliver personalized interventions that reduce symptom burden and improve quality of life for individuals with chronic conditions. !",Data-driven shared decision-making to reduce symptom burden in atrial fibrillation,9953270,K99NR019124,"['Ablation', 'Academic Medical Centers', 'Address', 'Affect', 'Age', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Award', 'Benefits and Risks', 'Cardiac ablation', 'Cardiovascular system', 'Caring', 'Characteristics', 'Chronic', 'Clinical', 'Competence', 'Complex', 'Consultations', 'Data', 'Data Display', 'Data Reporting', 'Data Science', 'Decision Aid', 'Devices', 'Dyspnea', 'Electronic Health Record', 'Electrophysiology (science)', 'Enabling Factors', 'Ensure', 'Eye', 'Faculty', 'Fatigue', 'Feasibility Studies', 'Funding', 'Goals', 'Gold', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Impaired health', 'Impairment', 'Individual', 'International', 'Intervention', 'Interview', 'Investigation', 'Lead', 'Learning', 'Life Style', 'Machine Learning', 'Measures', 'Mentors', 'Methods', 'Mobile Health Application', 'Modality', 'Monitor', 'Natural Language Processing', 'Nursing Informatics', 'Outcome', 'Palpitations', 'Patient Outcomes Assessments', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Positioning Attribute', 'Predisposing Factor', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Provider', 'Public Health', 'Quality of life', 'Reading', 'Reinforcing Factor', 'Reporting', 'Research', 'Research Activity', 'Resources', 'Risk', 'Sampling', 'Scientist', 'Site', 'Symptoms', 'Techniques', 'Technology', 'Training', 'Training Activity', 'Validation', 'Visualization', 'Work', 'associated symptom', 'biomedical informatics', 'career', 'clinical practice', 'common symptom', 'comorbidity', 'computer human interaction', 'data visualization', 'electronic data', 'experience', 'health equity', 'health related quality of life', 'implementation science', 'improved', 'individual patient', 'innovation', 'innovative technologies', 'insight', 'instrument', 'mHealth', 'machine learning method', 'member', 'minimally invasive', 'multidisciplinary', 'novel strategies', 'optimal treatments', 'personalized decision', 'personalized intervention', 'pre-doctoral', 'programs', 'reduce symptoms', 'shared decision making', 'statistics', 'success', 'symptom management', 'symptom science', 'symptomatic improvement', 'treatment risk', 'user centered design']",NINR,WEILL MEDICAL COLL OF CORNELL UNIV,K99,2020,87632,0.015182035778068828
"Improving Ethical Care for Patients who are Incapacitated with No Evident Advance Directives or Surrogates (INEADS) Most Americans do not have advance directives or appointed surrogates to guide their medical care in the event that they lose the capacity to make decisions for themselves. Healthcare teams are sometimes able to identify default surrogates, i.e., family or friends who can provide information about the patient's values, goals, preferences, and beliefs. However, a growing number of patients become decisionally incapacitated without any advance directives, appointed surrogates, or default surrogates, which leaves them vulnerable to receiving care that is unaligned with these tenets. Currently there is almost no data describing the prevalence of patients who are Incapacitated with No Evident Advance Directives or Surrogates (INEADS) or how clinical decisions are made for them. The proposed study will address this gap with two specific aims.  In Aim 1 we will determine (1a) what are the prevalence and characteristics of adults who are INEADS or at risk of becoming INEADS, and (1b) how clinical decisions are currently made for patients who are INEADS. For this aim we will retrospectively review electronic health records from an acute care database of ~40,000 hospitalizations and a home healthcare care database of ~89,000 community dwelling patients using a combination of structured data, natural language processing, and content analysis to answer the following questions: (i) What is the prevalence of patients who are currently INEADS and at risk of becoming INEADS in acute care and homecare settings; (ii) Who are the hospital and community personnel and policies involved, (iii) How do patient characteristics and diagnoses influence decisions, and (iv) What is the timeline for making decisions and how expeditiously are decisions reached?  In Aim 2 we will qualitatively explore the phenomenon of INEADS from clinical and patient perspectives. For this aim we will conduct: (1) focus groups with hospital- and community-based healthcare providers and hospital ethics boards, and (2) interviews with community-dwelling patients at risk of becoming INEADS. Sample questions to be explored include (i) What are the barriers and facilitators to formalizing and standardizing the clinical decision-making process for INEADS patients, and (ii) What are the barriers and facilitators to completing advance directives and designating surrogate decision makers among patients at risk of becoming INEADS?  The long-term goal of this project is to provide vulnerable INEADS patients with ethical care that is concordant with their goals and preferences. Knowledge gained from this pilot will inform (1) an intervention study to increase advance directive completion and surrogate designation among patients at risk of becoming INEADS, (2) the development, implementation, and evaluation of formalized decision-making processes for INEADS patients, and (3) the design, delivery, and testing of clinician education on best practices for caring for INEADS patients and patients at risk of becoming INEADS. PROJECT NARRATIVE  The majority of Americans do not have advance directives or healthcare proxies, and more adults are living independently without the support of family or friends. As a result, patients who lose the ability to make healthcare decisions for themselves may not have any voice in deciding what types of treatments they will receive. This study will investigate (1) how many patients in the hospital and community have no advance directives, surrogate decision makers, or ability to make decisions for themselves, and (2) how clinical teams make decisions for these patients.",Improving Ethical Care for Patients who are Incapacitated with No Evident Advance Directives or Surrogates (INEADS),10038963,R21NR019319,"['Address', 'Adult', 'Advance Directives', 'Advocate', 'American', 'Area', 'Belief', 'Bioethics', 'Caring', 'Characteristics', 'Clinical', 'Communities', 'Complex', 'Data', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Education', 'Electronic Health Record', 'Ethics', 'Evaluation', 'Event', 'Family', 'Focus Groups', 'Friends', 'Geriatrics', 'Goals', 'Health Personnel', 'Healthcare', 'Home Care Services', 'Hospital Ethics', 'Hospitalization', 'Hospitals', 'Human Resources', 'Independent Living', 'Institutional Policy', 'Intervention Studies', 'Interview', 'Knowledge', 'Literature', 'Measures', 'Medical', 'Medical Care Team', 'National Institute of Nursing Research', 'Natural Language Processing', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pilot Projects', 'Policies', 'Population', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Proxy', 'Publishing', 'Recommendation', 'Research', 'Risk', 'Sampling', 'Societies', 'Standardization', 'Statutes and Laws', 'Strategic Planning', 'Testing', 'TimeLine', 'Update', 'Voice', 'Work', 'acute care', 'base', 'care preference', 'clinical decision-making', 'cohort', 'court', 'design', 'end of life', 'end of life care', 'experience', 'family support', 'high risk', 'improved', 'patient population', 'preference', 'prevent', 'programs', 'social', 'structured data', 'surrogate decision maker']",NINR,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R21,2020,284481,0.004773363174244733
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9476980,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'base', 'clinical decision support', 'clinical implementation', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2018,300000,0.07742053348256837
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9251814,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2017,300000,0.07742053348256837
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9050675,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'abstracting', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'meetings', 'patient safety', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2016,300000,0.07742053348256837
"Secondary use of EMRs for surgical complication surveillance     DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.                ",Secondary use of EMRs for surgical complication surveillance,8798027,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'abstracting', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'meetings', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2015,299888,0.07742053348256837
"Enhancing Clinical Effectiveness Research with Natural Language Processing of EMR    DESCRIPTION (provided by applicant): To successfully use large linked clinical databases for comparative effectiveness research (CER) requires addressing some key informatics challenges associated with distributed, heterogeneous clinical data. Electronic networks of researchers are part of the solution because they can bridge the physical and organizational divides created by distinct health systems' individual electronic medical records (EMRs). In addition, informatics research has demonstrated the feasibility of automatically coding clinical text, enhancing the capacity to integrate both unstructured and non-standardized clinical data from EMRs. With this study, we propose to develop CER infrastructure, make broadly available the proven MediClass technology for automated classification of EMRs containing both coded data and text clinical notes, and demonstrate the potential of this infrastructure for addressing CER questions within the asthma and tobacco-using patient populations of 6 diverse health systems. Asthma and smoking each impose huge and modifiable burdens on the healthcare system, and multiple morbidities related to asthma and smoking have been targeted by the IOM and AHRQ as priority areas in efforts to improve the healthcare system through comparative effectiveness research. We propose to develop, deploy, operate and evaluate the CER HUB, an Internet-based platform for conducting CER, and to demonstrate its utility in studying clinical interventions in asthma and smoking. Researchers who register to use the HUB, beginning with the research team from the 6 participating study sites, will be able to use a secure website to configure and download MediClass applications addressing CER questions within their respective healthcare organizations, to contribute these IRB-approved, processed datasets back to a centralized data coordinating center to be pooled with data similarly processed from other healthcare organizations, and to use the pooled database to answer diverse comparative effectiveness questions of large, real-world populations. A central function of the CER HUB will be facilitating (through online, interactive tools) development of a shared library of MediClass knowledge modules that afford uniform, standardized coding of EMR data. This shared library of knowledge modules could permit researchers to assess effectiveness in multiple areas of healthcare and gain access to data otherwise locked away in text clinical notes. A goal of the CER HUB is to accelerate creation of standardized knowledge used to normalize heterogeneous EMR data as representations of clinical events for CER. During the project period we will conduct 2 studies using this infrastructure to address the effectiveness of interventions for asthmatics and tobacco users across the 6 participating health systems. As an ongoing resource, the HUB will provide a collaborative development platform for enhancing comparative effectiveness research in potentially any health care domain.      CER researchers can build software applications that will process their EMRs, creating standardized datasets permitting CER using a secure website to configure and download MediClass applications addressing CER questions within their respective healthcare organizations, to contribute these IRB-approved, processed datasets back to a centralized data coordinating center to be pooled with data similarly processed from other healthcare organizations, and to use the pooled database to answer diverse comparative effectiveness questions of large, real-world populations      PUBLIC HEALTH RELEVANCE: Comparative effectiveness research (CER) requires that clinical data be in standard forms allowing multiple, large databases to be efficiently combined, and requires that all of the data be coded so that automated summarization of the data is possible. However, much of the clinical data necessary for CER is in the text clinical notes written by clinicians when caring for patients. We will build a centralized website where CER researchers can build software applications that will process their electronic medical records, including both the text and coded data, creating standardized datasets permitting comparative effectiveness research. We will demonstrate the utility of this infrastructure by conducting CER studies investigating the effectiveness of interventions in asthma and smoking, across the 6 participating health systems.           PROJECT NARRATIVE Comparative effectiveness research (CER) requires that clinical data be in standard forms allowing multiple, large databases to be efficiently combined, and requires that all of the data be coded so that automated summarization of the data is possible. However, much of the clinical data necessary for CER is in the text clinical notes written by clinicians when caring for patients. We will build a centralized website where CER researchers can build software applications that will process their electronic medical records, including both the text and coded data, creating standardized datasets permitting comparative effectiveness research. We will demonstrate the utility of this infrastructure by conducting CER studies investigating the effectiveness of interventions in asthma and smoking, across the 6 participating health systems.",Enhancing Clinical Effectiveness Research with Natural Language Processing of EMR,8032928,R01HS019828,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2010,8696942,0.03654208811221893
"Multi-institutional Consortium for CER in Diabetes Treatment and Prevention    DESCRIPTION (provided by applicant): Project Summary /Abstract: The HMO Research Network's (HMORN) Diabetes Multi-Center Research Consortium (DMCRC) Coordinating Center proposes to build a national research network and a multi-system distributed database for conducting comparative effectiveness research (CER) in the treatment and prevention of diabetes mellitus. The network is comprised of 31 investigators from 12 integrated healthcare delivery systems and academic institutions who study diabetes mellitus, gestational diabetes mellitus, childhood and adult obesity, weight management, medical informatics and biostatistics. The network has broad experience conducting system-based interventions to improve treatment of diabetes or to support lifestyle changes to prevent diabetes, as well as broad experience conducting CER. The 12-system database will capture and standardize detailed demographic and longitudinal electronic health record (EHR)-derived clinical data on more than 750,000 persons with diabetes and a much larger membership without diabetes. Once constructed, the database will be used to conduct and publish surveillance data on trends (2005- 2012) in the incidence, prevalence, treatment and outcomes of diabetes in this population. It will also be used to conduct two CER studies. The first is a cluster randomized, multi-system intervention that will rapidly identify diabetes patients with ""early nonadherence"" to newly prescribed anti-diabetic, antihypertensive, and lipid-lowering medications. Early nonadherence refers to patient failure to fill either the first prescription of a new medication or the first refill, and has been shown to be more frequent than ""ongoing"" nonadherence. This information will be provided to population management outreach teams in 3-5 health systems via the EHR or other electronic database, along with training in counseling patients on adherence problems. Study outcomes of subsequent risk factor change and adherence to the new medication will be compared within each system to those for patients on teams that do not receive the new information. The second CER study is an observational evaluation of various communication, counseling and referral strategies as provided to women who have had an abnormal glucose test (fasting glucose or oral glucose tolerance test) in the first 6 months after a pregnancy complicated by gestational diabetes mellitus (GDM) and who are therefore at very high risk for developing Type 2 diabetes. Study outcomes include weight change over one year and self-reported physical activity four months after the abnormal test. In each study, we will collect process of care data by applying natural language processing (NLP) to clinical text in EHRs and survey patients for information on demographic, clinical, and behavioral variables. These NLP-derived and patient-reported variables will be studied as possible mediators of treatment effectiveness or as potential modifiers of effectiveness (i.e. variables that identify patient subgroups that benefit less from usual interventions. Variables that prove to be important as mediators or modifiers may be good candidates for routine collection and incorporation into EHR's and/or future diabetes registries.      PUBLIC HEALTH RELEVANCE: A network of 32 health services and intervention scientists affiliated with the HMO Research Network propose to build a national database for conducting comparative effectiveness research on treatment and on approaches to preventing diabetes mellitus. The database will include information on more than 750,000 persons with diabetes. It will be used to generate ongoing information on the occurrence, treatments and outcomes of diabetes and to conduct 2 studies of approaches to treating and preventing this condition.           Project Narrative A network of 32 health services and intervention scientists affiliated with the HMO Research Network propose to build a national database for conducting comparative effectiveness research on treatment and on approaches to preventing diabetes mellitus. The database will include information on more than 750,000 persons with diabetes. It will be used to generate ongoing information on the occurrence, treatments and outcomes of diabetes and to conduct 2 studies of approaches to treating and preventing this condition.",Multi-institutional Consortium for CER in Diabetes Treatment and Prevention,8033060,R01HS019859,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2010,8920115,0.022612890438646706
"Resolving Biological Entity References (Text/Databases)    DESCRIPTION (provided by applicant): The ""Big Idea"" driving this project is that human memory is small, the body of scientific knowledge is vast and that breakthroughs are possible if software can do a better job of connecting researchers with knowledge in text and databases. The first step is to stop looking for words (as a search engine does) in data but instead try to find facts in data. A fact is something claimed in text or a database explicitly. A fact may not be true but we want to develop software that finds those facts. What does a fact look like? Consider the following sentence from MEDLINE: ""Recently, we have found that Htt is an antiapoptotic protein in striatal cells and acts by preventing caspase-3 activity."" It contains the fact that the gene id 6532 (in the Entrez Gene database) regulates gene id 836. Software can extract such facts from a sentence like this. But the current state-of-the-art is not doing a great job of it. The reason is simple-current systems are focused on not making mistakes which means that they miss a lot of opportunities to find facts. The best reported performance is around 40% of the facts being found which we think is severely compromising the usefulness of text mining technologies in bioinformatics. This is where we are trying a different approach-we are focused on finding all the facts. We call this ""total recall"" which we demonstrated was possible in Phase I but total recall comes with a price: we make lots of mistakes. The key innovation is that we keep score of how confident we are of any given fact which gives us an important point of leverage in sifting good from bad facts. Our Phase II proposal focuses on developing techniques to reason over such fact heavy analysis by exploring soft clustering approaches, structured classification and effective user interface design. We have partnered with Harvard, Columbia and Pfizer to keep our research effort focused on problems that actually matter for genomics experiments and early phase drug discovery. In addition we fit into the NIH's data sharing policy by making our software free (with source code) to organizations who make their data free too. We, as do many others, believe that many great scientific discoveries lay implicit and just below the surface of the research literature. All that is required is for the right researcher to see the right sentence or database entry to form a novel hypothesis and cure a disease. Total recall approaches to fact extraction make that all the more likely an outcome. The dominant paradigm in text mining is to treat the text like a database. But researchers would be better served with a more ""search"" like approach to extracting and correlating facts in text and databases. We are committed to making all the facts, or total recall, available to scientists which is currently not available.          n/a",Resolving Biological Entity References (Text/Databases),7475803,R44RR020259,"['Address', 'Algorithms', 'Apoptosis', 'Arts', 'Autistic Disorder', 'Automobile Driving', 'Binding', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological databases', 'Biology', 'Cations', 'Cells', 'Classification', 'Clinical', 'Commit', 'Computer software', 'Corpus striatum structure', 'Data', 'Databases', 'Disease', 'Epigenetic Process', 'Genes', 'Genomics', 'Graph', 'Human', 'Internet', 'Joints', 'Knowledge', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Memory', 'Mental disorders', 'Methylation', 'Modality', 'Modeling', 'Occupations', 'Ontology', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Policy Making', 'Price', 'Probability', 'Proteins', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Scientist', 'Score', 'Source', 'Source Code', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Text', 'Thinking', 'Training', 'Variant', 'Walking', 'Work', 'abstracting', 'base', 'caspase-3', 'design', 'drug discovery', 'high throughput analysis', 'innovation', 'novel', 'open source', 'prevent', 'prototype', 'research and development', 'research study', 'software development', 'systems research', 'text searching', 'tool', 'uptake']",NCRR,ALIAS-I,R44,2008,373278,0.0028560148571579657
"Resolving Biological Entity References (Text/Databases)    DESCRIPTION (provided by applicant): The ""Big Idea"" driving this project is that human memory is small, the body of scientific knowledge is vast and that breakthroughs are possible if software can do a better job of connecting researchers with knowledge in text and databases. The first step is to stop looking for words (as a search engine does) in data but instead try to find facts in data. A fact is something claimed in text or a database explicitly. A fact may not be true but we want to develop software that finds those facts. What does a fact look like? Consider the following sentence from MEDLINE: ""Recently, we have found that Htt is an antiapoptotic protein in striatal cells and acts by preventing caspase-3 activity."" It contains the fact that the gene id 6532 (in the Entrez Gene database) regulates gene id 836. Software can extract such facts from a sentence like this. But the current state-of-the-art is not doing a great job of it. The reason is simple-current systems are focused on not making mistakes which means that they miss a lot of opportunities to find facts. The best reported performance is around 40% of the facts being found which we think is severely compromising the usefulness of text mining technologies in bioinformatics. This is where we are trying a different approach-we are focused on finding all the facts. We call this ""total recall"" which we demonstrated was possible in Phase I but total recall comes with a price: we make lots of mistakes. The key innovation is that we keep score of how confident we are of any given fact which gives us an important point of leverage in sifting good from bad facts. Our Phase II proposal focuses on developing techniques to reason over such fact heavy analysis by exploring soft clustering approaches, structured classification and effective user interface design. We have partnered with Harvard, Columbia and Pfizer to keep our research effort focused on problems that actually matter for genomics experiments and early phase drug discovery. In addition we fit into the NIH's data sharing policy by making our software free (with source code) to organizations who make their data free too. We, as do many others, believe that many great scientific discoveries lay implicit and just below the surface of the research literature. All that is required is for the right researcher to see the right sentence or database entry to form a novel hypothesis and cure a disease. Total recall approaches to fact extraction make that all the more likely an outcome. The dominant paradigm in text mining is to treat the text like a database. But researchers would be better served with a more ""search"" like approach to extracting and correlating facts in text and databases. We are committed to making all the facts, or total recall, available to scientists which is currently not available.          n/a",Resolving Biological Entity References (Text/Databases),7327948,R44RR020259,"['Address', 'Algorithms', 'Apoptosis', 'Arts', 'Autistic Disorder', 'Automobile Driving', 'Binding', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological databases', 'Biology', 'Cations', 'Cells', 'Classification', 'Clinical', 'Commit', 'Computer software', 'Corpus striatum structure', 'Data', 'Databases', 'Disease', 'Epigenetic Process', 'Genes', 'Genomics', 'Graph', 'Human', 'Internet', 'Joints', 'Knowledge', 'Literature', 'MEDLINE', 'MeSH Thesaurus', 'Memory', 'Mental disorders', 'Methylation', 'Modality', 'Modeling', 'Occupations', 'Ontology', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Policy Making', 'Price', 'Probability', 'Proteins', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Scientist', 'Score', 'Source', 'Source Code', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Text', 'Thinking', 'Training', 'Variant', 'Walking', 'Work', 'abstracting', 'base', 'caspase-3', 'design', 'drug discovery', 'high throughput analysis', 'innovation', 'novel', 'open source', 'prevent', 'prototype', 'research and development', 'research study', 'software development', 'systems research', 'text searching', 'tool', 'uptake']",NCRR,ALIAS-I,R44,2007,374415,0.0028560148571579657
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a tool to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,9110716,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Assistant', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Underrepresented Students', 'Validity and Reliability', 'Work', 'computer science', 'curriculum enhancement', 'falls', 'forging', 'high risk', 'improved', 'interest', 'learning strategy', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social media', 'tool', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2016,245338,0.06621545809259226
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a tool to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,9349080,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Assistant', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Underrepresented Students', 'Validity and Reliability', 'Work', 'computer science', 'curriculum enhancement', 'falls', 'forging', 'high risk', 'improved', 'interest', 'learning strategy', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social media', 'tool', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2016,25000,0.06621545809259226
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a tool to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,8932003,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Educational Curriculum', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Underrepresented Students', 'Validity and Reliability', 'Work', 'computer science', 'falls', 'forging', 'high risk', 'improved', 'interest', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social', 'tool', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2015,248507,0.06621545809259226
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)      DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a top! to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.                 n/a",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,8894220,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Educational Curriculum', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Principal Investigator', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Validity and Reliability', 'Work', 'computer science', 'falls', 'forging', 'high risk', 'improved', 'interest', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2014,251572,0.06621545809259226
"Integration of an NLP-based application to support medication management     DESCRIPTION (provided by applicant): An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. Stage 1 of Meaningful Use requires certified EHRs to be capable of providing a user with the ability to perform medication reconciliation. However, most previous studies have taken place in the inpatient setting, while medication reconciliation in the outpatient setting is importnt and challenging. In addition, clinical notes contain critical medication information that also need to be reconciled. Our goal of this study is to develop novel methods and a system using natural language processing (NLP) and other technologies to facilitate the medication reconciliation process in the ambulatory setting. Our specific aims are to : 1) identify the requirements, use cases, work flow issues, barriers to and facilitators of using clinical notes and a NLP-based system in the medication reconciliation process; 2) design a generic system architecture and an application that integrates an NLP system and a web-based user interface within an existing medication reconciliation system; 3) pilot this study in two primary care clinics and measure the utilization, usability, performance and feasibility of the proposed methods and the tool; and 4) distribute our methods and the tool and to make them widely available to other researchers and healthcare institutions for non-commercial use.          An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.            ",Integration of an NLP-based application to support medication management,8496045,R21HS021544,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R21,2013,148223,0.060713901335243625
"Integration of an NLP-based application to support medication management     DESCRIPTION (provided by applicant): An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. Stage 1 of Meaningful Use requires certified EHRs to be capable of providing a user with the ability to perform medication reconciliation. However, most previous studies have taken place in the inpatient setting, while medication reconciliation in the outpatient setting is importnt and challenging. In addition, clinical notes contain critical medication information that also need to be reconciled. Our goal of this study is to develop novel methods and a system using natural language processing (NLP) and other technologies to facilitate the medication reconciliation process in the ambulatory setting. Our specific aims are to : 1) identify the requirements, use cases, work flow issues, barriers to and facilitators of using clinical notes and a NLP-based system in the medication reconciliation process; 2) design a generic system architecture and an application that integrates an NLP system and a web-based user interface within an existing medication reconciliation system; 3) pilot this study in two primary care clinics and measure the utilization, usability, performance and feasibility of the proposed methods and the tool; and 4) distribute our methods and the tool and to make them widely available to other researchers and healthcare institutions for non-commercial use.        PUBLIC HEALTH RELEVANCE: An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.              An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.            ",Integration of an NLP-based application to support medication management,8354008,R21HS021544,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R21,2012,149342,0.06650993162635357
"From genomics to natural language processing: A protected environment for research computing in the health science NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Health sciences researchers are often required to manage, mine, and analyze restricted patient data (Protected Health Information, PHI) to facilitate and advance their research aims. They are often required to do this without access to central information technology expertise or resources to facilitate their research aims. These researchers are often left to their own devices to solve their research compute and data needs and are challenged due to lack of available resources, barriers from central IT, and/or lack of knowledge of available resources. A further challenge is that small data sets data that researchers could formerly handle on office resourceshave morphed and grown into the big data domain through the explosion of technical advances and significant expansion in various research directions. Examples include: genomics research, image analysis, simulation, natural language processing, and mining of EMRs. Therefore, the need exists to develop a framework for managing and processing this data securely and reliably. This S10 equipment proposal is to replace the protected environment (PE) prototype the University of Utahs Center for High Performance Computing (CHPC) and Department of Biomedical Informatics built six years ago and has operated since. The PE consists of both high performance computing and virtual machine (VM) components and associated storage sufficient to manage, protect and analyze HIPAA protected health information. This environment has been very successful and has grown significantly in scope. CHPC isolated this protected environment in the secured University of Utah Downtown Data Center and setup a network protected logical partition that provided research groups specific access to individual data sets. As the environment and technology developed, CHPC added additional security features such as two-factor authentication for entry and audit/monitoring. Unfortunately, the prototype has reached the point where demand is surpassing capability and all the hardware is aged and off-warranty. To give an idea of users of the virtual machine farm component, the Biomedical Informatics Core (BMIC) REDCap (Research Electronic Data Capture) environment for data collection has over 2,500 users in 1,500 projects supporting over $25M in NIH funding at the University of Utah, including support for more than 25 active NIH R-01 grants. Moreover, the HIPAA compliant protected environment was a key factor that aided passing the recent University of Utah HIPAA audit. The protected environment also helped the University of Utah Health Sciences Center and the BMIC justify the NCATS Center Clinical and Translational Science award (1ULTR001067). NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Project Narrative: The proposed Protected Environment instrument will provide research computing and data management capabilities for health sciences researchers to properly manage, secure, and analyze HIPAA regulated protected health information. The technology will not only support a large number of clinical trials, but also enable research in Human Genetics and Natural Language Processing of electronic health records.",From genomics to natural language processing: A protected environment for research computing in the health science,9274445,S10OD021644,"['Award', 'Big Data', 'Clinical Sciences', 'Data', 'Data Collection', 'Data Set', 'Devices', 'Environment', 'Equipment', 'Explosion', 'Farming environment', 'Funding', 'Genomics', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'High Performance Computing', 'Image Analysis', 'Individual', 'Information Technology', 'Knowledge', 'Left', 'Mining', 'Monitor', 'Natural Language Processing', 'Patients', 'Research', 'Research Personnel', 'Resources', 'Secure', 'Security', 'Technology', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Utah', 'aged', 'biomedical informatics', 'computerized data processing', 'electronic data', 'prototype', 'simulation', 'virtual']",OD,UNIVERSITY OF UTAH,S10,2017,493595,0.03428019547468106
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),10003116,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Retrieval', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissue Banks', 'Update', 'Validation', 'Work', 'alcohol research', 'clinical decision support', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'multiple data sources', 'recruit', 'therapy design', 'tool', 'treatment optimization']",NIAAA,YALE UNIVERSITY,U24,2020,279784,0.009398241775749251
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9768293,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'clinical decision support', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'recruit', 'repository', 'therapy design', 'tool', 'treatment optimization']",NIAAA,YALE UNIVERSITY,U24,2019,279784,0.009398241775749251
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9545635,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'clinical decision support', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'recruit', 'repository', 'therapy design', 'tool', 'treatment optimization']",NIAAA,YALE UNIVERSITY,U24,2018,279784,0.009398241775749251
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9338098,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Recruitment Activity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'repository', 'therapy design', 'tool']",NIAAA,YALE UNIVERSITY,U24,2017,282773,0.009398241775749251
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9206595,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'repository', 'therapy design', 'tool']",NIAAA,YALE UNIVERSITY,U24,2016,311314,0.009398241775749251
"Encoding and Processing Patient Allergy Information in EHRs DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use. PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.",Encoding and Processing Patient Allergy Information in EHRs,9142280,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,491053,0.10867954925126358
"Encoding and Processing Patient Allergy Information in EHRs DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use. PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.",Encoding and Processing Patient Allergy Information in EHRs,8920540,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,488893,0.10867954925126358
"Encoding and Processing Patient Allergy Information in EHRs     DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use.         PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.            ",Encoding and Processing Patient Allergy Information in EHRs,8741955,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2014,489854,0.10867954925126358
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9567932,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,249135,0.04896303351500878
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9352770,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,249135,0.04896303351500878
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9144757,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,249135,0.04896303351500878
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,8928596,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,249655,0.04896303351500878
"Learning from patient safety events: A case base tool kit     DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture.         PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.            ",Learning from patient safety events: A case base tool kit,8818528,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,249655,0.04896303351500878
"NLP-enabled decision support for cervical cancer screening and surveillance DESCRIPTION (provided by applicant): Although cervical cancer is preventable, it still continues to be a leading cause of death. Following the evidence- based guidelines for cervical cancer prevention is challenging for healthcare providers, due to which many patients do not receive the optimal preventive care. Clinical decision support (CDS) systems can potentially improve the care delivery. However, the current CDS systems only identify patients overdue for screening, and do not suggest the optimal screening interval. Moreover they do not help with surveillance of patients with abnormal screening results. This is because the existing systems lack the capability to process free- text clinical reports that contain information needed for applying the guidelines. Hence there is a critical need for natural language processing (NLP)-enabled CDS systems that can utilize discrete as well as free-text patient information for enhancing the decision support. Our long-term goal is to improve healthcare delivery of cervical cancer prevention with guideline based reminders. The central hypothesis is that NLP- enabled CDS system will significantly improve the quality of care delivery for cervical cancer prevention. The rationale is that use of NLP will improve granularity of the guideline implementation, which will in-turn enhance care delivery. As preliminary work we have developed an NLP-enabled CDS system that automatically interprets the patient information from the electronic health record and applies the national guidelines to compute the optimal recommendation for screening and surveillance. We have performed validation of the system in a non-clinical setting.1 In this application we will proceed towards deployment of the system in the clinical setting, and will carry out studies for measuring the impact on the quality of care delivery. In ai one, we will validate the system in the clinical setting and will optimize its usability and workflw integration. In aim two, we will test the hypothesis that reminders from the NLP-enabled CDS system to primary care providers will improve the quality of care delivery, by performing a one year intervention control study across four sites of a primary care practice. In aim three, we will test the hypothesis that reminders to non-adherent high-risk patients will improve their surveillance rates, by performing a randomized intervention study for three months. In this study, care coordinators will utilize the CDS system for sending reminders to patients that are non-adherent and at high risk due to abnormal screenings. The main contribution of this project will be knowledge about the effectiveness of NLP in enhancing the impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This project is innovative because the CDS system will utilize NLP to generate screening reminders for normal patients and surveillance reminders for patients with abnormal findings. This is a major advancement over existing systems that can only identify patients for screening. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because it will yield knowledge about the effectiveness of natural language processing (NLP) to enhance impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This research will foster implementation of similar CDS systems across the nation for cervical cancer prevention and for other decision problems, which will improve the quality of healthcare delivery. Thus, the proposed research is relevant to AHRQ's mission to improve the quality, safety, efficiency, and effectiveness of health care for all Americans.",NLP-enabled decision support for cervical cancer screening and surveillance,8934087,R21HS022911,[' '],AHRQ,MAYO CLINIC ROCHESTER,R21,2015,145229,0.05986688336955753
"NLP-enabled decision support for cervical cancer screening and surveillance     DESCRIPTION (provided by applicant): Although cervical cancer is preventable, it still continues to be a leading cause of death. Following the evidence- based guidelines for cervical cancer prevention is challenging for healthcare providers, due to which many patients do not receive the optimal preventive care. Clinical decision support (CDS) systems can potentially improve the care delivery. However, the current CDS systems only identify patients overdue for screening, and do not suggest the optimal screening interval. Moreover they do not help with surveillance of patients with abnormal screening results. This is because the existing systems lack the capability to process free- text clinical reports that contain information needed for applying the guidelines. Hence there is a critical need for natural language processing (NLP)-enabled CDS systems that can utilize discrete as well as free-text patient information for enhancing the decision support. Our long-term goal is to improve healthcare delivery of cervical cancer prevention with guideline based reminders. The central hypothesis is that NLP- enabled CDS system will significantly improve the quality of care delivery for cervical cancer prevention. The rationale is that use of NLP will improve granularity of the guideline implementation, which will in-turn enhance care delivery. As preliminary work we have developed an NLP-enabled CDS system that automatically interprets the patient information from the electronic health record and applies the national guidelines to compute the optimal recommendation for screening and surveillance. We have performed validation of the system in a non-clinical setting.1 In this application we will proceed towards deployment of the system in the clinical setting, and will carry out studies for measuring the impact on the quality of care delivery. In ai one, we will validate the system in the clinical setting and will optimize its usability and workflw integration. In aim two, we will test the hypothesis that reminders from the NLP-enabled CDS system to primary care providers will improve the quality of care delivery, by performing a one year intervention control study across four sites of a primary care practice. In aim three, we will test the hypothesis that reminders to non-adherent high-risk patients will improve their surveillance rates, by performing a randomized intervention study for three months. In this study, care coordinators will utilize the CDS system for sending reminders to patients that are non-adherent and at high risk due to abnormal screenings. The main contribution of this project will be knowledge about the effectiveness of NLP in enhancing the impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This project is innovative because the CDS system will utilize NLP to generate screening reminders for normal patients and surveillance reminders for patients with abnormal findings. This is a major advancement over existing systems that can only identify patients for screening.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because it will yield knowledge about the effectiveness of natural language processing (NLP) to enhance impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This research will foster implementation of similar CDS systems across the nation for cervical cancer prevention and for other decision problems, which will improve the quality of healthcare delivery. Thus, the proposed research is relevant to AHRQ's mission to improve the quality, safety, efficiency, and effectiveness of health care for all Americans.            ",NLP-enabled decision support for cervical cancer screening and surveillance,8678798,R21HS022911,[' '],AHRQ,MAYO CLINIC ROCHESTER,R21,2014,145229,0.05986688336955753
"Outpatient Adverse Drug Effect Alerting System Using Admission H&P Notes     DESCRIPTION (provided by applicant): This project will create, test, implement, and evaluate a real-time Adverse Drug Effect (ADE) alerting system at Vanderbilt University Hospital (VUH). Utilizing information extracted from admission history and physical examination notes (H&Ps) stored in the electronic medical record (EMR), our system will detect adult inpatients' previously unrecognized symptomatic ADEs and alert appropriate care providers. The project will create an ADE knowledge base, mined from multiple publically available sources including MEDLINE, RxNorm, and the product labels for human prescription drugs. Next, we will apply natural language processing (NLP) to EMR-based H&P texts to identify mentions of patients' current medications and dosages. We will similarly detect EMR-based H&P documentation of patients' clinical manifestations (CMs - diseases, symptoms, findings, etc.), and then represent them using the Unified Medical Language System's (UMLS) Concept Unique Identifiers (CUIs). The system will then compare each patient's recognized medications and CMs against the aforementioned ADE knowledgebase, generating appropriate patient-specific alerts for potential adverse effects related to the patient's current medications. Each alert will identify the offendin medication, the suspected nature of the ADE, and evidence supporting the assertion. We will independently evaluate the accuracy of the ADE knowledgebase using expert manual review and comparison to multiple other sources. Before implementing the real-time ADE monitoring system, we will conduct a pilot implementation using retrospective EMR data from the Vanderbilt Synthetic Derivative (SD), a de-identified version of the Vanderbilt EMR. After successful testing and any necessary iterative improvements, we will implement the real-time detection system at VUH, initially monitoring newly admitted inpatients presenting to the Internal Medicine service. Using the methods described above, the system will detect potential ADEs each time a new inpatient H&P is generated, and alert appropriate clinicians via additions to an existing dashboard that the clinicians already utilize. We will survey clinicians immediately upon receipt of an ADE alert to determine if the alerting condition was already known or not, whether the alert seems plausible, and whether it requires intervention. Then we will compare discharge medications to admission medications to determine what actions occurred post-alert, independent of physician survey results. We will thus evaluate both the effectiveness of the system in improving ADE recognition and its perceived usefulness according to the physician-subjects. We hypothesize that our system will improve clinicians' awareness of ADEs in a manner applicable to any facility that stores admission H&Ps electronically. Addressing previously unrecognized ADEs has the potential to reduce costs and improve patient care.         PUBLIC HEALTH RELEVANCE: Unrecognized adverse drug effects (ADEs), a serious clinical problem, cause preventable hospitalizations, increase healthcare costs, and worsen health outcomes. To potentially improve quality of care, my dissertation project will develop and evaluate a novel system to detect adult inpatients' previously unrecognized symptomatic ADEs and alert appropriate care providers. Using automated natural language processing of clinician-generated electronic admission history and physical exam (H&P) notes and a locally-developed ADE knowledgebase derived from publically available sources, the system, once validated, could improve both recognition and treatment of ADEs in a generalizable manner - applicable in hospital environments using electronic medical records.            ",Outpatient Adverse Drug Effect Alerting System Using Admission H&P Notes,8796404,R36HS023485,[' '],AHRQ,VANDERBILT UNIVERSITY,R36,2015,41626,0.04973646819780143
"Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach DESCRIPTION (provided by applicant): Physician progress notes contain information essential to patient care, including findings from history and physical exam, interpretation of tests, assessment and treatment plans. However in the transition from paper to electronic physician notes, many physicians spend more time creating them, which has led to the use of time-saving measures such as copy/paste and templates that have degraded note accuracy and quality. This threatens the usefulness of notes not only for their most important use-patient care-but also for research, quality improvement, and in supporting reimbursement. To address these problems, we propose a project with the following specific aims: 1. To refine and implement a new voice-generated enhanced electronic note system (VGEENS) integrating voice recognition with natural language processing and links to the electronic medical record (EMR) to improve note accuracy and timeliness. 2. To evaluate VGEENS using a randomized trial with 30 internal medicine physicians in each arm to assess electronic note accuracy, quality, timeliness, and user satisfaction. Intervention physicians will use VGEENS, while the control physicians will continue with note creation as they normally would. This novel approach has the potential to improve note accuracy while reducing delays in making progress notes in EMRs available to other clinicians. It leverages rapidly improving voice recognition and NLP technologies to permit physicians to use a natural, fast method-human voice-to convey their observation and thoughts into the EMR record. PUBLIC HEALTH RELEVANCE: Physician documentation of a patient visit contains information that is used in that patient's care. This information includes findings from a patient' history and physical exam, interpretation of necessary tests, the problem assessment and treatment plan. However, in the transition from paper to electronic physician notes, many physicians are spending more time creating these notes. This has led to use of time-saving measures that have degraded the accuracy and ease of use of patient notes. By the end of this project, we expect to have developed, used and evaluated a new method for creating electronic physician notes that both improve accuracy and timely availability of inpatient progress notes.","Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach",8928601,R21HS023631,[' '],AHRQ,UNIVERSITY OF WASHINGTON,R21,2015,139245,0.036870079320588535
"Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach     DESCRIPTION (provided by applicant): Physician progress notes contain information essential to patient care, including findings from history and physical exam, interpretation of tests, assessment and treatment plans. However in the transition from paper to electronic physician notes, many physicians spend more time creating them, which has led to the use of time-saving measures such as copy/paste and templates that have degraded note accuracy and quality. This threatens the usefulness of notes not only for their most important use-patient care-but also for research, quality improvement, and in supporting reimbursement. To address these problems, we propose a project with the following specific aims: 1. To refine and implement a new voice-generated enhanced electronic note system (VGEENS) integrating voice recognition with natural language processing and links to the electronic medical record (EMR) to improve note accuracy and timeliness. 2. To evaluate VGEENS using a randomized trial with 30 internal medicine physicians in each arm to assess electronic note accuracy, quality, timeliness, and user satisfaction. Intervention physicians will use VGEENS, while the control physicians will continue with note creation as they normally would. This novel approach has the potential to improve note accuracy while reducing delays in making progress notes in EMRs available to other clinicians. It leverages rapidly improving voice recognition and NLP technologies to permit physicians to use a natural, fast method-human voice-to convey their observation and thoughts into the EMR record.         PUBLIC HEALTH RELEVANCE: Physician documentation of a patient visit contains information that is used in that patient's care. This information includes findings from a patient' history and physical exam, interpretation of necessary tests, the problem assessment and treatment plan. However, in the transition from paper to electronic physician notes, many physicians are spending more time creating these notes. This has led to use of time-saving measures that have degraded the accuracy and ease of use of patient notes. By the end of this project, we expect to have developed, used and evaluated a new method for creating electronic physician notes that both improve accuracy and timely availability of inpatient progress notes.            ","Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach",8805997,R21HS023631,[' '],AHRQ,UNIVERSITY OF WASHINGTON,R21,2014,154347,0.036870079320588535
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability     DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9750002,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2019,234158,0.033704227331081714
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability     DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9535837,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2018,243172,0.033704227331081714
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability     DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9322409,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2017,248917,0.033704227331081714
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability     DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9145193,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2016,248974,0.033704227331081714
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability     DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy.         PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.            ",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9030048,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2015,249752,0.033704227331081714
"Identification of Patients with Low Life Expectancy     DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9481256,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2018,227899,0.042147356135103196
"Identification of Patients with Low Life Expectancy     DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9275946,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,227900,0.042147356135103196
"Identification of Patients with Low Life Expectancy     DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9115065,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,227891,0.042147356135103196
"Identification of Patients with Low Life Expectancy     DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death.         PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.            ",Identification of Patients with Low Life Expectancy,8942806,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,232521,0.042147356135103196
"NLP to Improve Accuracy and Quality of Dictated Medical Documents     DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005). PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9352296,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,249995,-0.0037333442851367224
"NLP to Improve Accuracy and Quality of Dictated Medical Documents     DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005). PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9146893,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,249994,-0.0037333442851367224
"NLP to Improve Accuracy and Quality of Dictated Medical Documents     DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005).         PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.            ",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9004939,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,250000,-0.0037333442851367224
"Sci-Score, a tool to support rigor and transparency guidelines Project Summary While standards in reporting of scientific methods are absolutely critical to producing reproducible science, meeting such standards is difficult. Checklists and instructions are tough to follow often resulting in low andinconsistent compliance. Scientific journals and societies as well as the National Institutes of Health are now activelyproposinggeneralguidelinestoaddressreproducibilityissues,particularlyinthereportingofmethods (e.g., http://www.cell.com/star-methods), but the trickier part will be to train the biomedical community to usethesestandardstoeffectivelyimprovehowscientificmethodsarecommunicated. Tosupportnewstandardsinmethodsreporting,specificallytheRRIDstandardforRigorandTransparencyof KeyBiologicalResources,weproposetobuildSci-Scoreatextminingbasedtoolsuitetohelpauthorsmeetthe standard. Sci-Score will provide an automated check on compliance with the RRID standard already implementedbyover100journalsincludingCell,JournalofNeuroscience,andeLife.TheinnovationbehindSci- scoreistheprovisionofascore,whichcanbeobtainedbyindividualinvestigators,whichreflectsanumerical validationofthequalityoftheirmethodsreporting.Wepositthatthescorewillserveasatoolthatinvestigators andjournalscanusetocompetewiththemselvesandeachother,orintheveryleastallowthemtoseehow closetheyaretotheaverageinmeetingqualityrequirements. Recently, our group has developed a text mining algorithm that has now been successfully been used to detect software tools and databases from the SciCrunch Registry in published papers. Digital tools are one of four resource types that the RRID standard identifies. We propose to extend this approach to the other types of entities: antibodies, cell lines and model organisms. Resource identification along with other quality metrics twill be used to train an algorithm to score the overall quality of the methods document. If successful, the tool could be used by editors, reviewers, and investigators to improve the number of RRIDs, therefore the quality of descriptors of key biological resources in published papers. This SBIR project will build a set of algorithms similar to the resource finding pipeline and develop it into an industrial robust and reconfigurable software system. Our Phase I specific aims include to 1) creating gold sets of data for each resource type and training a set of algorithms for each resource type; 2) designing and evaluating the scoring system; 3) designing and evaluating a report generating system based on the previous aims. In Phase II, we will develop a scalable backend infrastructure to serve the needs of scientific publishers and research community. Standardsforscientificmethodsreportingareabsolutelycriticaltoproducingreproduciblescience,butmeeting suchstandardsisdifficult.Checklistsandinstructionsaretoughtofollowoftenresultinginlowandinconsistent compliance.Tosupportnewstandardsinmethodsreporting,specificallytheRRIDstandardforRigorandTransparency,weproposetobuildSci-Score textminingbasedtoolsuitetohelpauthorsmeetthestandard.Sci-Score willprovideanautomatedcheckoncompliancewiththeRRIDstandardimplementedbyover100journalsincludingCell,JournalofNeuroscience,andeLife.Sci-Scorewillprovideascoreratingthequalityof methodsreportinginsubmittedarticles,whichprovidesfeedbacktoauthors,reviewersandeditorsonhowtoimprovecompliancewithRRIDsandotherstandards.","Sci-Score, a tool to support rigor and transparency guidelines",9345707,R43OD024432,"['Address', 'Agreement', 'Algorithms', 'Animal Model', 'Antibodies', 'Area', 'Big Data', 'Biological', 'California', 'Cell Line', 'Cell model', 'Cells', 'Communities', 'Data Set', 'Databases', 'Descriptor', 'Elements', 'Ensure', 'Evaluation', 'Feedback', 'Funding', 'Glare', 'Gold', 'Guidelines', 'Habits', 'Human', 'Individual', 'Industrialization', 'Instruction', 'Journals', 'Learning', 'Literature', 'Machine Learning', 'Manuscripts', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Neurosciences', 'Organism', 'Paper', 'Performance', 'Phase', 'Plagiarism', 'Process', 'Publications', 'Publishing', 'Readability', 'Reader', 'Reading', 'Reagent', 'Registries', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Running', 'Sales', 'Science', 'Scoring Method', 'Services', 'Small Business Innovation Research Grant', 'Societies', 'Software Tools', 'System', 'Technology', 'Text', 'To specify', 'Training', 'United States National Institutes of Health', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'biological systems', 'computerized tools', 'design', 'digital', 'improved', 'innovation', 'interest', 'meetings', 'prototype', 'software systems', 'sound', 'text searching', 'tool', 'vigilance', 'web site']",OD,"SCICRUNCH, INC.",R43,2017,221865,0.010338307690963989
"NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department Summary Timely identification of relevant or need to know clinical information about a patients history in the acute care setting can be critical for patient safety and medical decision-making. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. Currently, it is estimated that over 50% of the EHR is free-text. EHR search tools today are often inefficient, simplistic, and unable to rank or evoke the relevance of information for a particular problem or complaint. This is compounded by the fact that EHRs are amassing clinical information at an exponential rate. While the benefits of having a wealth of information at a providers fingertips seem obvious, the time and energy cost of culling through enormous amounts of data creates new issues of decreased efficiency and information overload for providers seeking to identify the most pertinent and relevant information about their patients. In the emergency department, where patients can present with life threatening conditions, timely unlocking of clinically relevant information for a patients problem or complaint at the point of care can be critical to medical decision-making and patient safety. In this study, we plan to address this challenge through the development of a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information based on the patients presenting complaint. We will accomplish this through the following specific aims: 1) identify and define complaint- specific information elements within a patients history and 2) develop and test an NLP-based information retrieval tool. Narrative Patient safety hinges on having right information about the right patient and the right time. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. The purpose of this study is to develop and evaluate a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information from EHRs that providers rely upon to make medical decisions for their patients. This study comes at an important time where data in the EHRs is increasing at an exponential rate, creating a new problem for clinicians, that of finding all the relevant information for patients particular problem. This is particularly true in the emergency department setting where providers have limited if any prior relationship and often have to make quick decisions for patients with life threatening conditions. This search tool will provide a snapshot of clinically relevant information that the providers can view alongside the structured information already in the EHR. We believe this approach has the potential to increase clinician efficiency, decrease healthcare costs by avoiding duplicate diagnostic tests, and provide clinicians with the tools they need to make well-informed medical decisions, thereby improving patient safety and reducing suffering.",NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department,9342692,R21HS024541,[' '],AHRQ,UNIVERSITY OF COLORADO DENVER,R21,2017,148922,0.09949973903721782
"NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department Summary Timely identification of relevant or need to know clinical information about a patients history in the acute care setting can be critical for patient safety and medical decision-making. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. Currently, it is estimated that over 50% of the EHR is free-text. EHR search tools today are often inefficient, simplistic, and unable to rank or evoke the relevance of information for a particular problem or complaint. This is compounded by the fact that EHRs are amassing clinical information at an exponential rate. While the benefits of having a wealth of information at a providers fingertips seem obvious, the time and energy cost of culling through enormous amounts of data creates new issues of decreased efficiency and information overload for providers seeking to identify the most pertinent and relevant information about their patients. In the emergency department, where patients can present with life threatening conditions, timely unlocking of clinically relevant information for a patients problem or complaint at the point of care can be critical to medical decision-making and patient safety. In this study, we plan to address this challenge through the development of a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information based on the patients presenting complaint. We will accomplish this through the following specific aims: 1) identify and define complaint- specific information elements within a patients history and 2) develop and test an NLP-based information retrieval tool. Narrative Patient safety hinges on having right information about the right patient and the right time. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. The purpose of this study is to develop and evaluate a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information from EHRs that providers rely upon to make medical decisions for their patients. This study comes at an important time where data in the EHRs is increasing at an exponential rate, creating a new problem for clinicians, that of finding all the relevant information for patients particular problem. This is particularly true in the emergency department setting where providers have limited if any prior relationship and often have to make quick decisions for patients with life threatening conditions. This search tool will provide a snapshot of clinically relevant information that the providers can view alongside the structured information already in the EHR. We believe this approach has the potential to increase clinician efficiency, decrease healthcare costs by avoiding duplicate diagnostic tests, and provide clinicians with the tools they need to make well-informed medical decisions, thereby improving patient safety and reducing suffering.",NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department,9245525,R21HS024541,[' '],AHRQ,UNIVERSITY OF COLORADO DENVER,R21,2016,148922,0.09949973903721782
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7554153,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'clinical care', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2009,422728,0.04410346484141426
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7394699,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Reporting', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Thinking', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2008,429955,0.04410346484141426
"Towards the Building of a Comprehensive Searchable Biological Experiment Database    DESCRIPTION (provided by applicant):       The rapid growth of the biomedical literature and the expansion in disciplinary biomedical research, heralded by high-throughput genome sciences and technologies, have overwhelmed scientists who attempt to assimilate information necessary for their research. The widespread adoption of title/abstract word searches, such as highly desirable the National Library of Medicine's PubMed system, has provided the first major advance in the way bioscientists find relevant publications since the origin of Index Medicus in 1879 (Hunter and Cohen 2006). The importance of developing valid information retrieval systems for bioscientists has led to the development of information systems worldwide (e.g., Arrowsmith (Smalheiser and Swanson 1998), BioText (Hearst 2003), GeneWays (Friedman et al. 2001; Rzhetsky et al. 2004), iHOP (Hoffmann and Valencia 2005), and BioMedQA (Lee et al. 2006a), and annotated databases (e.g., SWISSPROT, OMIM (Hamosh et al. 2005) and BIND (Alfarano et al. 2005)).      However, most of information systems target only text information and fail to provide access to other important data such as images (e.g., figures). More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biological articles nearly always incorporate figures/images that are the crucial content of the biomedical literature. Our examination of biological articles in the Proceedings of the National Academy of Sciences (PNAS) revealed the occurrence of 5.2 images per article on average (Yu and Lee 2006a). Biologists need to access image data to validate research facts and to formulate or to test novel research hypotheses. It has been evaluated that textual statements reported in literature frequently are noisy (i.e., containing ""false facts"") (Krauthammer et al. 2002). Capturing images that are experimental ""evidence"" to support the textual ""fact"" will benefit bioscience information systems, databases, and bioscientists.      Unfortunately, this wealth of information remains virtually inaccessible without automatic systems to organize these images. We propose the development of advanced natural language processing (NLP) tools to semantically organize images. We hypothesize that text that associated with images semantically entails the image content and natural language processing techniques can be developed to accurately associate the text to their images. Furthermore, we hypothesize that images can be semantically organized by categories specified by standard biological ontology, and that natural language processing approaches can accurately assign the ontological categories to images.      Our specific aims are:      Aim 1: To develop and evaluate NLP techniques for identifying textual statements that correspond to images in full-text articles. We will develop different approaches for two types of the associations. We will first propose rule-based and statistical approaches to identify the associated text that appears in the full-text articles. We will then develop hybrid approaches to link sentences in abstracts to images in the body of the articles.      Aim 2: To develop and evaluate NLP techniques for automatic classification of experimental results into categories (e.g., Western-Blot, PCR verification, etc) specified in the experimental protocol Protocol-Online.      We will explore the use of dictionary-based, rule-based, image classification, and machine-learning approaches for accomplishing this aim.      Aim 3: To develop and evaluate NLP techniques for automatic assignment of Gene Ontology categories to experiments, which will provide a knowledge-based organization of experiments according to biological properties (e.g., catalytic activity). We will develop statistical and machine-learning approaches for accomplishing this aim.      We found that most of the images that appear in full-text biological articles are figure images (Yu and Lee 2006a) and we therefore focus on figure images only in this proposal. The deliverable of Specific Aim 1 will be an effective user-interface BioEx from which bioscientists can access images directly from sentences in the abstracts. BioEx has the promise of improvement over the traditional single-document-per-article format that has dominated bioscience publications since the first scientific article appeared in 1665 (Gross 2002). The deliverables of Specific Aim 2 and 3 will be open-source algorithms and tools that accurately map images to categories specified by the Gene Ontology and the Protocol Online. Those algorithms and tools will enhance bioscience information retrieval, information extraction, summarization, and question answering.          n/a",Towards the Building of a Comprehensive Searchable Biological Experiment Database,7534822,R21RR024933,"['Adoption', 'Advanced Development', 'Algorithms', 'Binding', 'Biological', 'Biomedical Research', 'Categories', 'Classification', 'Data', 'Databases', 'Development', 'Dictionary', 'Documentation', 'Flowcharts', 'Genes', 'Genome', 'Hybrids', 'Image', 'Index Medicus', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Principal Investigator', 'Property', 'Protocols documentation', 'PubMed', 'Publications', 'Reporting', 'Research', 'Science', 'Scientist', 'Specific qualifier value', 'SwissProt', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'United States National Academy of Sciences', 'United States National Library of Medicine', 'Western Blotting', 'abstracting', 'base', 'knowledge base', 'novel', 'open source', 'programs', 'rapid growth', 'research study', 'tool']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2009,179517,-0.02503622622053124
"Towards the Building of a Comprehensive Searchable Biological Experiment Database    DESCRIPTION (provided by applicant):       The rapid growth of the biomedical literature and the expansion in disciplinary biomedical research, heralded by high-throughput genome sciences and technologies, have overwhelmed scientists who attempt to assimilate information necessary for their research. The widespread adoption of title/abstract word searches, such as highly desirable the National Library of Medicine's PubMed system, has provided the first major advance in the way bioscientists find relevant publications since the origin of Index Medicus in 1879 (Hunter and Cohen 2006). The importance of developing valid information retrieval systems for bioscientists has led to the development of information systems worldwide (e.g., Arrowsmith (Smalheiser and Swanson 1998), BioText (Hearst 2003), GeneWays (Friedman et al. 2001; Rzhetsky et al. 2004), iHOP (Hoffmann and Valencia 2005), and BioMedQA (Lee et al. 2006a), and annotated databases (e.g., SWISSPROT, OMIM (Hamosh et al. 2005) and BIND (Alfarano et al. 2005)).      However, most of information systems target only text information and fail to provide access to other important data such as images (e.g., figures). More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biological articles nearly always incorporate figures/images that are the crucial content of the biomedical literature. Our examination of biological articles in the Proceedings of the National Academy of Sciences (PNAS) revealed the occurrence of 5.2 images per article on average (Yu and Lee 2006a). Biologists need to access image data to validate research facts and to formulate or to test novel research hypotheses. It has been evaluated that textual statements reported in literature frequently are noisy (i.e., containing ""false facts"") (Krauthammer et al. 2002). Capturing images that are experimental ""evidence"" to support the textual ""fact"" will benefit bioscience information systems, databases, and bioscientists.      Unfortunately, this wealth of information remains virtually inaccessible without automatic systems to organize these images. We propose the development of advanced natural language processing (NLP) tools to semantically organize images. We hypothesize that text that associated with images semantically entails the image content and natural language processing techniques can be developed to accurately associate the text to their images. Furthermore, we hypothesize that images can be semantically organized by categories specified by standard biological ontology, and that natural language processing approaches can accurately assign the ontological categories to images.      Our specific aims are:      Aim 1: To develop and evaluate NLP techniques for identifying textual statements that correspond to images in full-text articles. We will develop different approaches for two types of the associations. We will first propose rule-based and statistical approaches to identify the associated text that appears in the full-text articles. We will then develop hybrid approaches to link sentences in abstracts to images in the body of the articles.      Aim 2: To develop and evaluate NLP techniques for automatic classification of experimental results into categories (e.g., Western-Blot, PCR verification, etc) specified in the experimental protocol Protocol-Online.      We will explore the use of dictionary-based, rule-based, image classification, and machine-learning approaches for accomplishing this aim.      Aim 3: To develop and evaluate NLP techniques for automatic assignment of Gene Ontology categories to experiments, which will provide a knowledge-based organization of experiments according to biological properties (e.g., catalytic activity). We will develop statistical and machine-learning approaches for accomplishing this aim.      We found that most of the images that appear in full-text biological articles are figure images (Yu and Lee 2006a) and we therefore focus on figure images only in this proposal. The deliverable of Specific Aim 1 will be an effective user-interface BioEx from which bioscientists can access images directly from sentences in the abstracts. BioEx has the promise of improvement over the traditional single-document-per-article format that has dominated bioscience publications since the first scientific article appeared in 1665 (Gross 2002). The deliverables of Specific Aim 2 and 3 will be open-source algorithms and tools that accurately map images to categories specified by the Gene Ontology and the Protocol Online. Those algorithms and tools will enhance bioscience information retrieval, information extraction, summarization, and question answering.          n/a",Towards the Building of a Comprehensive Searchable Biological Experiment Database,7314689,R21RR024933,"['Adoption', 'Advanced Development', 'Algorithms', 'Binding', 'Biological', 'Biomedical Research', 'Categories', 'Classification', 'Data', 'Databases', 'Development', 'Dictionary', 'Documentation', 'Flowcharts', 'Genes', 'Genome', 'Hybrids', 'Image', 'Index Medicus', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Polymerase Chain Reaction', 'Principal Investigator', 'Property', 'Protocols documentation', 'PubMed', 'Publications', 'Reporting', 'Research', 'Science', 'Scientist', 'Specific qualifier value', 'Standards of Weights and Measures', 'SwissProt', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Title', 'United States National Academy of Sciences', 'United States National Library of Medicine', 'Western Blotting', 'abstracting', 'base', 'knowledge base', 'novel', 'open source', 'programs', 'rapid growth', 'research study', 'tool']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2008,230085,-0.02503622622053124
"Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients Project Summary Epilepsy is one of the leading neurological disorders in the United States, affecting more than 479,000 children and over 2 million adults. Approximately 30% of epileptic patients have poor seizure control despite antiepileptic medications and are potential candidates for neurosurgical intervention. Early identification and referral of children who are potential surgical candidates is complex and while relevant guidelines exist, there is no standard process to efficiently identify those patients meeting criteria for neurosurgical intervention. Given the large corpus of note-based data available in the electronic health record (EHR), it is challenging for providers to efficiently retain and process all the pertinent patient information. Natural Language Processing (NLP) and machine learning techniques have been successfully used to evaluate clinical notes and make recommendations in the research setting. However, NLP techniques are rarely integrated into practice to provide real-time clinical decision support. We developed and retrospectively evaluated a NLP system to help identify those patients who meet neurosurgical criteria and therefore enable surgical consults and evaluations to occur sooner. Knowing clinical decision support can improve outcomes of care, our proposed research will implement NLP into clinical practice and develop a decision support mechanism to improve the time to surgery for eligible patients. The objective of this project is to implement NLP directly into clinical care and determine the most effective decision support mechanism for provider adherence to epilepsy surgical consult recommendations. The long- term goal of this project is to reduce the time to initial surgery evaluation for patients with intractable epilepsy by integrating NLP-classification criteria into clinical practice. This project is one of the first in the field to study the integration of NLP recommendations into clinical care. We will use a human factors engineering framework to design and to analyze two different alerting methodologies for the best-fit for clinical workflow to produce the optimum provider adherence while reducing alert fatigue. Epilepsy progress notes can be classified across hospitals, and if successful, the system will be implemented in additional pediatric institutions around the United States. Project Narrative Epilepsy affects more than 479,000 children; 30% of those are not controlled with medication and may require surgery. We developed a novel Natural Language Processing (NLP) algorithm that can be integrated into neurology practice to detect patients who may be eligible for epilepsy surgical consults. Once implemented, this research can help to drive successful implementations of NLP and identify and use ideal alerting mechanisms in neurological care.",Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients,9355161,R21HS024977,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2017,159334,0.045204346317932645
"Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients Project Summary Epilepsy is one of the leading neurological disorders in the United States, affecting more than 479,000 children and over 2 million adults. Approximately 30% of epileptic patients have poor seizure control despite antiepileptic medications and are potential candidates for neurosurgical intervention. Early identification and referral of children who are potential surgical candidates is complex and while relevant guidelines exist, there is no standard process to efficiently identify those patients meeting criteria for neurosurgical intervention. Given the large corpus of note-based data available in the electronic health record (EHR), it is challenging for providers to efficiently retain and process all the pertinent patient information. Natural Language Processing (NLP) and machine learning techniques have been successfully used to evaluate clinical notes and make recommendations in the research setting. However, NLP techniques are rarely integrated into practice to provide real-time clinical decision support. We developed and retrospectively evaluated a NLP system to help identify those patients who meet neurosurgical criteria and therefore enable surgical consults and evaluations to occur sooner. Knowing clinical decision support can improve outcomes of care, our proposed research will implement NLP into clinical practice and develop a decision support mechanism to improve the time to surgery for eligible patients. The objective of this project is to implement NLP directly into clinical care and determine the most effective decision support mechanism for provider adherence to epilepsy surgical consult recommendations. The long- term goal of this project is to reduce the time to initial surgery evaluation for patients with intractable epilepsy by integrating NLP-classification criteria into clinical practice. This project is one of the first in the field to study the integration of NLP recommendations into clinical care. We will use a human factors engineering framework to design and to analyze two different alerting methodologies for the best-fit for clinical workflow to produce the optimum provider adherence while reducing alert fatigue. Epilepsy progress notes can be classified across hospitals, and if successful, the system will be implemented in additional pediatric institutions around the United States. Project Narrative Epilepsy affects more than 479,000 children; 30% of those are not controlled with medication and may require surgery. We developed a novel Natural Language Processing (NLP) algorithm that can be integrated into neurology practice to detect patients who may be eligible for epilepsy surgical consults. Once implemented, this research can help to drive successful implementations of NLP and identify and use ideal alerting mechanisms in neurological care.",Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients,9222109,R21HS024977,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2016,137233,0.045204346317932645
"Using the electronic health record to identify children likely to suffer last-minute surgery cancellation PROJECT SUMMARY/ABSTRACT Last-minute cancellation of surgery frequently leads to psychological stress and financial hardships that disproportionately affect individuals of low socioeconomic status. Moreover, cancellation leaves unutilized healthcare resources valued as high as $1 per second. Machine learning can uncover patterns in historical data to identify predictors, and captures relationships among many factors to allow assessment of risk associated with a particular set of conditions. There is a critical need to develop a model system through machine learning both to understand and to predict cancellation. The long-term goal is to develop evidence- based strategies for improved perioperative resource utilization and efficiency. The overall objective in this application is to develop and deploy an analytical model for predicting last-minute surgical cancellations. The central hypothesis is that a predictive model based on patient-specific and contextual factors will accurately determine the probability of cancellation. The hypothesis has been formulated on the basis of preliminary data showing that risk of cancellation varies substantially with respect to data extracted from the electronic health record (EHR). The rationale for the proposed research is that development of a model that can accurately predict the probability of last-minute cancellation of surgical procedures is likely to provide new opportunities for improving healthcare costs and efficiency. The hypothesis will be tested by pursuing three specific aims: 1) Develop computerized models for predicting surgery cancellation; 2) Identify key predictors of last-minute cancelation of surgery from the EHR and online data resources; and 3) Establish a scalable last-minute surgery cancellation prediction system. Under the first aim, using a pre-existing database and machine- learning techniques already established as feasible in the applicants' hands, patient-specific and contextual data from two pediatric surgical sites in a large Midwest conurbation will be mined. Under the second aim, these predictive models will be interrogated to generate actionable advice. Under the third aim, the optimal model will be identified and integrated into the clinical workflow to direct cancellation prevention and mitigation strategies. The approach is innovative, in the applicants' opinion, because it represents a substantial departure from the status quo by employing machine-learning techniques on large and detailed datasets drawing from the modern EHR and publicly available contextual data. The proposed research is significant because it will both have broad translational importance in perioperative management and also elucidate the etiology of cancellation. The positive impact is expected to be in facilitating quality improvement projects and operating room management strategies to increase utilization of expensive perioperative resources. Successful completion of the proposed research is also expected to lead to more timely surgeries at lower cost for hundreds of thousands of patients, which is of vital importance at a time when the cost of healthcare is ever increasing. PROJECT NARRATIVE The proposed research is relevant to public health because a clinically useful approach to decreasing last- minute cancellations of surgery will provide new opportunities to reduce healthcare expenditures and improve overall efficiency. The project is relevant to AHRQ's mission by making surgical care more accessible, equitable, and affordable.",Using the electronic health record to identify children likely to suffer last-minute surgery cancellation,9338140,R21HS024983,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2017,174567,0.03604377312321582
"Using the electronic health record to identify children likely to suffer last-minute surgery cancellation PROJECT SUMMARY/ABSTRACT Last-minute cancellation of surgery frequently leads to psychological stress and financial hardships that disproportionately affect individuals of low socioeconomic status. Moreover, cancellation leaves unutilized healthcare resources valued as high as $1 per second. Machine learning can uncover patterns in historical data to identify predictors, and captures relationships among many factors to allow assessment of risk associated with a particular set of conditions. There is a critical need to develop a model system through machine learning both to understand and to predict cancellation. The long-term goal is to develop evidence- based strategies for improved perioperative resource utilization and efficiency. The overall objective in this application is to develop and deploy an analytical model for predicting last-minute surgical cancellations. The central hypothesis is that a predictive model based on patient-specific and contextual factors will accurately determine the probability of cancellation. The hypothesis has been formulated on the basis of preliminary data showing that risk of cancellation varies substantially with respect to data extracted from the electronic health record (EHR). The rationale for the proposed research is that development of a model that can accurately predict the probability of last-minute cancellation of surgical procedures is likely to provide new opportunities for improving healthcare costs and efficiency. The hypothesis will be tested by pursuing three specific aims: 1) Develop computerized models for predicting surgery cancellation; 2) Identify key predictors of last-minute cancelation of surgery from the EHR and online data resources; and 3) Establish a scalable last-minute surgery cancellation prediction system. Under the first aim, using a pre-existing database and machine- learning techniques already established as feasible in the applicants' hands, patient-specific and contextual data from two pediatric surgical sites in a large Midwest conurbation will be mined. Under the second aim, these predictive models will be interrogated to generate actionable advice. Under the third aim, the optimal model will be identified and integrated into the clinical workflow to direct cancellation prevention and mitigation strategies. The approach is innovative, in the applicants' opinion, because it represents a substantial departure from the status quo by employing machine-learning techniques on large and detailed datasets drawing from the modern EHR and publicly available contextual data. The proposed research is significant because it will both have broad translational importance in perioperative management and also elucidate the etiology of cancellation. The positive impact is expected to be in facilitating quality improvement projects and operating room management strategies to increase utilization of expensive perioperative resources. Successful completion of the proposed research is also expected to lead to more timely surgeries at lower cost for hundreds of thousands of patients, which is of vital importance at a time when the cost of healthcare is ever increasing. PROJECT NARRATIVE The proposed research is relevant to public health because a clinically useful approach to decreasing last- minute cancellations of surgery will provide new opportunities to reduce healthcare expenditures and improve overall efficiency. The project is relevant to AHRQ's mission by making surgical care more accessible, equitable, and affordable.",Using the electronic health record to identify children likely to suffer last-minute surgery cancellation,9223041,R21HS024983,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2016,119761,0.03604377312321582
"Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding Project Summary/Abstract  With increasing use of electronic medical records for a variety of patients, a large investment is being made in a resource still vastly underused. Especially in mental health, where problems are highly individualized, requiring personalized intervention, and often accompanied by rich data not easily captured in structured templates, the need for extracting information from free text in existing records for use as large-scale stand- alone datasets or in combination with other data is real. Without scalable and effective computational approaches to capture this data, much time, effort and money is used to create limited-use records that instead could be leveraged into precious data sources to inform existing research and lead to new insights, progress and treatments. Our broad, long-term goal is processing free text in EHR in mental health. We focus on Autism Spectrum Disorders (ASD), a particularly interesting example of both shortcomings and opportunities.  ASDs prevalence has increased over the years, and estimates range from 1 in 150 in 2000 to 1 in 68 in 2010(1-5). These numbers are based on surveillance using electronic health records. The increasing prevalence is not well understood, and hypotheses range from changing diagnostic criteria to environmental factors. The lines of inquiry used to find cures are similarly broad and range from brain scans and genetics, resulting in large structured datasets, to highly individualized therapies, resulting in rich but unstructured data. Currently the text information in the electronic records is not being leveraged on a large scale.  The proposed project continues our preliminary work and uses a data-driven approach to create human- interpretable models that allow automated extraction of relevant structured data from free text. The Diagnostic and Statistical Manual of Mental Disorders (DSM) is the starting point for identifying features. A database of thousands of records is leveraged to design and test the algorithms. The two specific aims are: 1) design and test natural language processing (NLP) algorithms to detect DSM criteria for ASD in free text in EHR, and 2) demonstrate feasibility and usefulness of the models for large-scale analysis of ASD cases, which is inconceivable today with current approaches. Our methods include analysis of free text in electronic records and end-user annotations to create a large gold standard of instances of DSM criteria for ASD, application of machine learning and rule-based approaches to create human-interpretable models for automated annotation of diagnostic patterns in textual records, and demonstrate usefulness with new research (e.g., Automatically detect ASD vs. no-ASD status for challenging cases; evaluate prevalence of symptoms over time). Through NLP algorithms, this project has the potential to significantly shift away from the current paradigm of attempting to understand ASD by relying on small-scale data from individual interventions and lack of integration between different data sources, to leveraging information from existing large-scale data sources to propose novel analyses and hypotheses. Project Narrative  Lack of sophisticated tools to extract relevant diagnostic patterns from free text from the increasingly large number of electronic medical/health records is a critical barrier in the field of mental health to leverage and utilize the already available data. Natural language processing (NLP) algorithms designed specifically for mental health can make new data analysis and integration with other sources possible at a scale previously unseen. Using a data-driven process, this project will design NLP algorithms to annotate free text with criteria from the Diagnostic and Statistical Manual of Mental Disorders (DSM) and demonstrate scope, feasibility and usefulness by focusing on Autism Spectrum Disorders (ASD) where prevalence is increasing and much rich clinical text is stored in electronic health records (EHR).",Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding,9547263,R21HS024988,[' '],AHRQ,UNIVERSITY OF ARIZONA,R21,2018,146202,0.0206669241869746
"Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding Project Summary/Abstract  With increasing use of electronic medical records for a variety of patients, a large investment is being made in a resource still vastly underused. Especially in mental health, where problems are highly individualized, requiring personalized intervention, and often accompanied by rich data not easily captured in structured templates, the need for extracting information from free text in existing records for use as large-scale stand- alone datasets or in combination with other data is real. Without scalable and effective computational approaches to capture this data, much time, effort and money is used to create limited-use records that instead could be leveraged into precious data sources to inform existing research and lead to new insights, progress and treatments. Our broad, long-term goal is processing free text in EHR in mental health. We focus on Autism Spectrum Disorders (ASD), a particularly interesting example of both shortcomings and opportunities.  ASDs prevalence has increased over the years, and estimates range from 1 in 150 in 2000 to 1 in 68 in 2010(1-5). These numbers are based on surveillance using electronic health records. The increasing prevalence is not well understood, and hypotheses range from changing diagnostic criteria to environmental factors. The lines of inquiry used to find cures are similarly broad and range from brain scans and genetics, resulting in large structured datasets, to highly individualized therapies, resulting in rich but unstructured data. Currently the text information in the electronic records is not being leveraged on a large scale.  The proposed project continues our preliminary work and uses a data-driven approach to create human- interpretable models that allow automated extraction of relevant structured data from free text. The Diagnostic and Statistical Manual of Mental Disorders (DSM) is the starting point for identifying features. A database of thousands of records is leveraged to design and test the algorithms. The two specific aims are: 1) design and test natural language processing (NLP) algorithms to detect DSM criteria for ASD in free text in EHR, and 2) demonstrate feasibility and usefulness of the models for large-scale analysis of ASD cases, which is inconceivable today with current approaches. Our methods include analysis of free text in electronic records and end-user annotations to create a large gold standard of instances of DSM criteria for ASD, application of machine learning and rule-based approaches to create human-interpretable models for automated annotation of diagnostic patterns in textual records, and demonstrate usefulness with new research (e.g., Automatically detect ASD vs. no-ASD status for challenging cases; evaluate prevalence of symptoms over time). Through NLP algorithms, this project has the potential to significantly shift away from the current paradigm of attempting to understand ASD by relying on small-scale data from individual interventions and lack of integration between different data sources, to leveraging information from existing large-scale data sources to propose novel analyses and hypotheses. Project Narrative  Lack of sophisticated tools to extract relevant diagnostic patterns from free text from the increasingly large number of electronic medical/health records is a critical barrier in the field of mental health to leverage and utilize the already available data. Natural language processing (NLP) algorithms designed specifically for mental health can make new data analysis and integration with other sources possible at a scale previously unseen. Using a data-driven process, this project will design NLP algorithms to annotate free text with criteria from the Diagnostic and Statistical Manual of Mental Disorders (DSM) and demonstrate scope, feasibility and usefulness by focusing on Autism Spectrum Disorders (ASD) where prevalence is increasing and much rich clinical text is stored in electronic health records (EHR).",Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding,9381416,R21HS024988,[' '],AHRQ,UNIVERSITY OF ARIZONA,R21,2017,146202,0.0206669241869746
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,9912124,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2020,398492,0.0449769158757411
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,9731456,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2019,399999,0.0449769158757411
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,9447854,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2018,400000,0.0449769158757411
"Evaluating National Sepsis Policy Using the Electronic Health Record Project Summary/Abstract Sepsis is a critical illness syndrome characterized by infection leading to life-threatening organ failure. Affecting over 200,000 individuals in the United States each year, sepsis accounts for nearly half of all hospital deaths and over $20 billion in yearly US hospital costs. Despite the development and dissemination of evidence-based guidelines, most patients with sepsis do not consistently receive recommended care, resulting in preventable morbidity and mortality. Consequently, there is increasing interest in implementing health policies designed to incentivize quality improvement at the hospital level. The largest and most prominent of these policies to date is the new Centers for Medicare and Medicaid Services (CMS) quality reporting initiative, known as SEP-1. SEP-1 requires hospitals to report their compliance with a variety of evidence-based care processes, including timely antibiotic administration, timely volume resuscitation, and routine monitoring of the clinical response to therapy. SEP-1 is unique among quality measures in the CMS Inpatient Quality Reporting Program, both because it is the only measure based on a critical illness syndrome and because it is of unparalleled complexity, requiring the coordinated efforts of multiple health care providers across the acute care spectrum. As a consequence, it is essential to understand how SEP-1 has affected patient care and clinical outcomes. To address this need, we propose to comprehensively evaluate the impact of the SEP-1 measure using the electronic health record (EHR) of a large multihospital health system. An EHR-based approach will allow us to understand the impact of the policy in exceptional detail, yielding actionable data not only for policy makers seeking to refine SEP-1 but also for health systems seeking to respond to SEP-1 in a way that maximizes the potential benefits. First, we will analyze the impact of the program on sepsis recognition and documentation using natural language processing of clinical notes. Second, we will analyze the impact of the program on sepsis care processes using structured data elements such as vital signs, laboratory values, and medication administration. Third, we will evaluate the impact of the program on patient mortality, length of stay, and requirement for organ support. In all aims we will examine both overall effects and hospital-specific effects, providing an understanding of how hospitals and health systems implement quality improvement in the context of a novel reporting mandate. Together, these aims will yield important new insights into how clinicians and hospitals implement new quality reporting programs. At the same time, through a program of structured mentorship, career development, and stakeholder involvement, this project will provide the principal investigator with new skills in the use of the EHR to evaluate health care quality and the impact of system-level health policies, uniquely positioning him to lead future efforts to develop, implement, evaluate, and disseminate EHR-based performance interventions for critically ill patients. NARRATIVE Sepsis is a life-threatening response to infection and accounts for significant morbidity, mortality, and hospital costs in the United States. In this proposal, we will use data from the electronic health record of a large health system to evaluate the effects of a novel sepsis quality reporting program on sepsis recognition, treatment, and outcomes. Our findings will yield important early information on the quality reporting programs impact, helping to guide policy makers as they seek to refine the program and yielding novel insights into strategies to improve sepsis quality in US hospitals.",Evaluating National Sepsis Policy Using the Electronic Health Record,9936306,K08HS025455,[' '],AHRQ,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K08,2020,146065,0.018590449474108355
"Evaluating National Sepsis Policy Using the Electronic Health Record Project Summary/Abstract Sepsis is a critical illness syndrome characterized by infection leading to life-threatening organ failure. Affecting over 200,000 individuals in the United States each year, sepsis accounts for nearly half of all hospital deaths and over $20 billion in yearly US hospital costs. Despite the development and dissemination of evidence-based guidelines, most patients with sepsis do not consistently receive recommended care, resulting in preventable morbidity and mortality. Consequently, there is increasing interest in implementing health policies designed to incentivize quality improvement at the hospital level. The largest and most prominent of these policies to date is the new Centers for Medicare and Medicaid Services (CMS) quality reporting initiative, known as SEP-1. SEP-1 requires hospitals to report their compliance with a variety of evidence-based care processes, including timely antibiotic administration, timely volume resuscitation, and routine monitoring of the clinical response to therapy. SEP-1 is unique among quality measures in the CMS Inpatient Quality Reporting Program, both because it is the only measure based on a critical illness syndrome and because it is of unparalleled complexity, requiring the coordinated efforts of multiple health care providers across the acute care spectrum. As a consequence, it is essential to understand how SEP-1 has affected patient care and clinical outcomes. To address this need, we propose to comprehensively evaluate the impact of the SEP-1 measure using the electronic health record (EHR) of a large multihospital health system. An EHR-based approach will allow us to understand the impact of the policy in exceptional detail, yielding actionable data not only for policy makers seeking to refine SEP-1 but also for health systems seeking to respond to SEP-1 in a way that maximizes the potential benefits. First, we will analyze the impact of the program on sepsis recognition and documentation using natural language processing of clinical notes. Second, we will analyze the impact of the program on sepsis care processes using structured data elements such as vital signs, laboratory values, and medication administration. Third, we will evaluate the impact of the program on patient mortality, length of stay, and requirement for organ support. In all aims we will examine both overall effects and hospital-specific effects, providing an understanding of how hospitals and health systems implement quality improvement in the context of a novel reporting mandate. Together, these aims will yield important new insights into how clinicians and hospitals implement new quality reporting programs. At the same time, through a program of structured mentorship, career development, and stakeholder involvement, this project will provide the principal investigator with new skills in the use of the EHR to evaluate health care quality and the impact of system-level health policies, uniquely positioning him to lead future efforts to develop, implement, evaluate, and disseminate EHR-based performance interventions for critically ill patients. NARRATIVE Sepsis is a life-threatening response to infection and accounts for significant morbidity, mortality, and hospital costs in the United States. In this proposal, we will use data from the electronic health record of a large health system to evaluate the effects of a novel sepsis quality reporting program on sepsis recognition, treatment, and outcomes. Our findings will yield important early information on the quality reporting programs impact, helping to guide policy makers as they seek to refine the program and yielding novel insights into strategies to improve sepsis quality in US hospitals.",Evaluating National Sepsis Policy Using the Electronic Health Record,9731455,K08HS025455,[' '],AHRQ,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K08,2019,148308,0.018590449474108355
"Evaluating National Sepsis Policy Using the Electronic Health Record Project Summary/Abstract Sepsis is a critical illness syndrome characterized by infection leading to life-threatening organ failure. Affecting over 200,000 individuals in the United States each year, sepsis accounts for nearly half of all hospital deaths and over $20 billion in yearly US hospital costs. Despite the development and dissemination of evidence-based guidelines, most patients with sepsis do not consistently receive recommended care, resulting in preventable morbidity and mortality. Consequently, there is increasing interest in implementing health policies designed to incentivize quality improvement at the hospital level. The largest and most prominent of these policies to date is the new Centers for Medicare and Medicaid Services (CMS) quality reporting initiative, known as SEP-1. SEP-1 requires hospitals to report their compliance with a variety of evidence-based care processes, including timely antibiotic administration, timely volume resuscitation, and routine monitoring of the clinical response to therapy. SEP-1 is unique among quality measures in the CMS Inpatient Quality Reporting Program, both because it is the only measure based on a critical illness syndrome and because it is of unparalleled complexity, requiring the coordinated efforts of multiple health care providers across the acute care spectrum. As a consequence, it is essential to understand how SEP-1 has affected patient care and clinical outcomes. To address this need, we propose to comprehensively evaluate the impact of the SEP-1 measure using the electronic health record (EHR) of a large multihospital health system. An EHR-based approach will allow us to understand the impact of the policy in exceptional detail, yielding actionable data not only for policy makers seeking to refine SEP-1 but also for health systems seeking to respond to SEP-1 in a way that maximizes the potential benefits. First, we will analyze the impact of the program on sepsis recognition and documentation using natural language processing of clinical notes. Second, we will analyze the impact of the program on sepsis care processes using structured data elements such as vital signs, laboratory values, and medication administration. Third, we will evaluate the impact of the program on patient mortality, length of stay, and requirement for organ support. In all aims we will examine both overall effects and hospital-specific effects, providing an understanding of how hospitals and health systems implement quality improvement in the context of a novel reporting mandate. Together, these aims will yield important new insights into how clinicians and hospitals implement new quality reporting programs. At the same time, through a program of structured mentorship, career development, and stakeholder involvement, this project will provide the principal investigator with new skills in the use of the EHR to evaluate health care quality and the impact of system-level health policies, uniquely positioning him to lead future efforts to develop, implement, evaluate, and disseminate EHR-based performance interventions for critically ill patients. NARRATIVE Sepsis is a life-threatening response to infection and accounts for significant morbidity, mortality, and hospital costs in the United States. In this proposal, we will use data from the electronic health record of a large health system to evaluate the effects of a novel sepsis quality reporting program on sepsis recognition, treatment, and outcomes. Our findings will yield important early information on the quality reporting programs impact, helping to guide policy makers as they seek to refine the program and yielding novel insights into strategies to improve sepsis quality in US hospitals.",Evaluating National Sepsis Policy Using the Electronic Health Record,9526083,K08HS025455,[' '],AHRQ,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K08,2018,148403,0.018590449474108355
"Rheumatology Informatics System for Effectiveness Patient-Reported Outcome (RISE-PRO) Dissemination Project PROJECT SUMMARY Patient-reported outcomes (PROs) are important in rheumatoid arthritis (RA), a condition that affects 1.3 million Americans and is a leading cause of disability. Among chronic conditions, RA has many decades of robust scientific evidence around the validity of PROs. PROs are key outcome measures in RA clinical trials and studies, are responsive to therapy changes, are strong predictors of future disability and mortality, and play a central role in facilitating shared decision-making and treatment. Advances in health information technology (IT), like electronic health record-enabled Qualified Clinical Data Registries (QCDRs), provide an opportunity to scale and spread of use of PRO measures nationally. The Rheumatology Informatics System for Effectiveness (RISE) registry is a QCDR that was established in 2014 to improve the quality of care for patients seen in rheumatology practices. The RISE informatics platform aggregates electronic health record data from participating practices, analyzes these data centrally and feeds performance on quality measures back to clinicians using a web-based dashboard. RISE currently includes one the largest PRO measurement efforts for ambulatory patients with a chronic disease in the United States. However, as the registry matures, several critical gaps remain in our national PRO measurement efforts, including the lack of representation of public hospital systems and at-risk populations, the challenges faced by some practices in creating structured data fields in electronic health records to capture PRO measure scores, and the need to evaluate the impact of the PRO collection efforts through RISE. The overarching goal of this proposal is to systematically address each of these issues by 1) creating an evidence-based clinical learning network to support the participation of public hospital systems in PRO measurement and improvement efforts through RISE, 2) developing and scaling a natural language processing system to extract PRO measures from unstructured data in clinical notes, and 3) analyzing the impact of PRO measurement through RISE on quality of care and health outcomes in RA. This proposal builds on the novel informatics platform of the RISE registry to scale, spread and evaluate PRO implementation across a nationwide network of rheumatology practices, with the ultimate goal of improving functional status outcomes for those with RA. PROJECT NARRATIVE The RISE-PRO project aims to use the novel health IT platform of the RISE patient registry to scale, spread and evaluate the collection of patient-reported outcomes across a nationwide network of rheumatology practices. Collecting and using patient-reported outcomes in clinical practice has the potential to transform health care for individuals with rheumatoid arthritis by making care more patient-centered and by providing tools to facilitate shared decision-making, disease monitoring, and population health management.",Rheumatology Informatics System for Effectiveness Patient-Reported Outcome (RISE-PRO) Dissemination Project,9912121,R18HS025638,[' '],AHRQ,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R18,2020,493891,0.061855951540212735
"Rheumatology Informatics System for Effectiveness Patient-Reported Outcome (RISE-PRO) Dissemination Project PROJECT SUMMARY Patient-reported outcomes (PROs) are important in rheumatoid arthritis (RA), a condition that affects 1.3 million Americans and is a leading cause of disability. Among chronic conditions, RA has many decades of robust scientific evidence around the validity of PROs. PROs are key outcome measures in RA clinical trials and studies, are responsive to therapy changes, are strong predictors of future disability and mortality, and play a central role in facilitating shared decision-making and treatment. Advances in health information technology (IT), like electronic health record-enabled Qualified Clinical Data Registries (QCDRs), provide an opportunity to scale and spread of use of PRO measures nationally. The Rheumatology Informatics System for Effectiveness (RISE) registry is a QCDR that was established in 2014 to improve the quality of care for patients seen in rheumatology practices. The RISE informatics platform aggregates electronic health record data from participating practices, analyzes these data centrally and feeds performance on quality measures back to clinicians using a web-based dashboard. RISE currently includes one the largest PRO measurement efforts for ambulatory patients with a chronic disease in the United States. However, as the registry matures, several critical gaps remain in our national PRO measurement efforts, including the lack of representation of public hospital systems and at-risk populations, the challenges faced by some practices in creating structured data fields in electronic health records to capture PRO measure scores, and the need to evaluate the impact of the PRO collection efforts through RISE. The overarching goal of this proposal is to systematically address each of these issues by 1) creating an evidence-based clinical learning network to support the participation of public hospital systems in PRO measurement and improvement efforts through RISE, 2) developing and scaling a natural language processing system to extract PRO measures from unstructured data in clinical notes, and 3) analyzing the impact of PRO measurement through RISE on quality of care and health outcomes in RA. This proposal builds on the novel informatics platform of the RISE registry to scale, spread and evaluate PRO implementation across a nationwide network of rheumatology practices, with the ultimate goal of improving functional status outcomes for those with RA. PROJECT NARRATIVE The RISE-PRO project aims to use the novel health IT platform of the RISE patient registry to scale, spread and evaluate the collection of patient-reported outcomes across a nationwide network of rheumatology practices. Collecting and using patient-reported outcomes in clinical practice has the potential to transform health care for individuals with rheumatoid arthritis by making care more patient-centered and by providing tools to facilitate shared decision-making, disease monitoring, and population health management.",Rheumatology Informatics System for Effectiveness Patient-Reported Outcome (RISE-PRO) Dissemination Project,9735244,R18HS025638,[' '],AHRQ,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R18,2019,494501,0.061855951540212735
"Rheumatology Informatics System for Effectiveness Patient-Reported Outcome (RISE-PRO) Dissemination Project PROJECT SUMMARY Patient-reported outcomes (PROs) are important in rheumatoid arthritis (RA), a condition that affects 1.3 million Americans and is a leading cause of disability. Among chronic conditions, RA has many decades of robust scientific evidence around the validity of PROs. PROs are key outcome measures in RA clinical trials and studies, are responsive to therapy changes, are strong predictors of future disability and mortality, and play a central role in facilitating shared decision-making and treatment. Advances in health information technology (IT), like electronic health record-enabled Qualified Clinical Data Registries (QCDRs), provide an opportunity to scale and spread of use of PRO measures nationally. The Rheumatology Informatics System for Effectiveness (RISE) registry is a QCDR that was established in 2014 to improve the quality of care for patients seen in rheumatology practices. The RISE informatics platform aggregates electronic health record data from participating practices, analyzes these data centrally and feeds performance on quality measures back to clinicians using a web-based dashboard. RISE currently includes one the largest PRO measurement efforts for ambulatory patients with a chronic disease in the United States. However, as the registry matures, several critical gaps remain in our national PRO measurement efforts, including the lack of representation of public hospital systems and at-risk populations, the challenges faced by some practices in creating structured data fields in electronic health records to capture PRO measure scores, and the need to evaluate the impact of the PRO collection efforts through RISE. The overarching goal of this proposal is to systematically address each of these issues by 1) creating an evidence-based clinical learning network to support the participation of public hospital systems in PRO measurement and improvement efforts through RISE, 2) developing and scaling a natural language processing system to extract PRO measures from unstructured data in clinical notes, and 3) analyzing the impact of PRO measurement through RISE on quality of care and health outcomes in RA. This proposal builds on the novel informatics platform of the RISE registry to scale, spread and evaluate PRO implementation across a nationwide network of rheumatology practices, with the ultimate goal of improving functional status outcomes for those with RA. PROJECT NARRATIVE The RISE-PRO project aims to use the novel health IT platform of the RISE patient registry to scale, spread and evaluate the collection of patient-reported outcomes across a nationwide network of rheumatology practices. Collecting and using patient-reported outcomes in clinical practice has the potential to transform health care for individuals with rheumatoid arthritis by making care more patient-centered and by providing tools to facilitate shared decision-making, disease monitoring, and population health management.",Rheumatology Informatics System for Effectiveness Patient-Reported Outcome (RISE-PRO) Dissemination Project,9571470,R18HS025638,[' '],AHRQ,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R18,2018,492523,0.061855951540212735
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,9928343,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2020,160164,0.04016523309331119
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,9731453,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2019,160164,0.04016523309331119
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,9599186,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2018,160164,0.04016523309331119
"Consumer Assessment of Healthcare Providers and Systems V (CAHPS V) Consumers, providers and health care purchasers need high-quality information to help them compare and evaluate their health care options. The CAHPS V project will advance the AHRQ CAHPS mission of improving patients' experiences with health care by developing and evaluating strategies for survey measurement, reporting and quality improvement (QI). We propose a 5-year effort to advance the science and practice of patient experience assessment, continue innovation to ensure relevance to health service delivery and implement best survey practices, further the science of reporting, and evaluate CAHPS QI efforts. We will develop program communication strategies, and disseminate and promote use of CAHPS products. In particular, we will develop a survey to assess patient experiences with end-of-life care; develop new items to assess shared decision-making, care coordination, patient engagement, and patient safety; test alternatives to the standard CAHPS modes of data collection), explore the feasibility of administering a short-form survey dividing CG-CAHPS composites among respondents to reduce response burden, elicit stakeholder feedback about the value of different CAHPS supplement item sets, evaluate The Your CAHPS Survey that was designed to help users of the CAHPS surveys compile a survey tailed to their specific needs, and evaluate existing Spanish translations of CAHPS surveys. In addition, we will gather input from stakeholders on best practices for narrative data analysis, develop an approach for using automated Natural Language Processing for analyses of narratives, and construct an algorithm approach to select representative narratives that reflect and illustrate overall provider ratings. Finally, we will evaluate the contribution of patient narratives to quality improvement efforts in hospital care for children, characterize primary care practices use of the CG-CAHPS survey and patient-centered medical home items during PCMH transformation, assess the impact of pay- for-performance for care delivered by primary and specialty care safety net providers on CAHPS survey responses, explore the value of new shared decision-making, patient engagement, communication and patient safety items for QI and identify QI strategies that improve patient experience across various settings. We will also advance analytic methods for CAHPS data. The project team is well suited to achieving the study objectives given its prior accomplishments and established working relationships. The work is innovative and designed to facilitate the use of CAHPS surveys and improve response rates to them, enhance reporting and use of CAHPS survey data, and improve health care QI efforts. PROJECT NARRATIVE This project will advance public health by developing new CAHPS survey items for end-of-life care, shared decision-making, care coordination, patient engagement, and patient safety, promoting use of CAHPS surveys by implementing and evaluating an interactive database tool designed to assist with the assembly of CAHPS surveys, creating parsimonious variants of CAHPS surveys, evaluating alternative methods of data collection designed to improve response rates, enhancing the collection and use of patient narrative data in reports about health care, and assessing the impact of CAHPS surveys and reports on quality improvement efforts and patient experiences with care.",Consumer Assessment of Healthcare Providers and Systems V (CAHPS V),10018010,U18HS025920,[' '],AHRQ,RAND CORPORATION,U18,2020,1080541,0.027479161426560678
"Consumer Assessment of Healthcare Providers and Systems V (CAHPS V) Consumers, providers and health care purchasers need high-quality information to help them compare and evaluate their health care options. The CAHPS V project will advance the AHRQ CAHPS mission of improving patients' experiences with health care by developing and evaluating strategies for survey measurement, reporting and quality improvement (QI). We propose a 5-year effort to advance the science and practice of patient experience assessment, continue innovation to ensure relevance to health service delivery and implement best survey practices, further the science of reporting, and evaluate CAHPS QI efforts. We will develop program communication strategies, and disseminate and promote use of CAHPS products. In particular, we will develop a survey to assess patient experiences with end-of-life care; develop new items to assess shared decision-making, care coordination, patient engagement, and patient safety; test alternatives to the standard CAHPS modes of data collection), explore the feasibility of administering a short-form survey dividing CG-CAHPS composites among respondents to reduce response burden, elicit stakeholder feedback about the value of different CAHPS supplement item sets, evaluate The Your CAHPS Survey that was designed to help users of the CAHPS surveys compile a survey tailed to their specific needs, and evaluate existing Spanish translations of CAHPS surveys. In addition, we will gather input from stakeholders on best practices for narrative data analysis, develop an approach for using automated Natural Language Processing for analyses of narratives, and construct an algorithm approach to select representative narratives that reflect and illustrate overall provider ratings. Finally, we will evaluate the contribution of patient narratives to quality improvement efforts in hospital care for children, characterize primary care practices use of the CG-CAHPS survey and patient-centered medical home items during PCMH transformation, assess the impact of pay- for-performance for care delivered by primary and specialty care safety net providers on CAHPS survey responses, explore the value of new shared decision-making, patient engagement, communication and patient safety items for QI and identify QI strategies that improve patient experience across various settings. We will also advance analytic methods for CAHPS data. The project team is well suited to achieving the study objectives given its prior accomplishments and established working relationships. The work is innovative and designed to facilitate the use of CAHPS surveys and improve response rates to them, enhance reporting and use of CAHPS survey data, and improve health care QI efforts. PROJECT NARRATIVE This project will advance public health by developing new CAHPS survey items for end-of-life care, shared decision-making, care coordination, patient engagement, and patient safety, promoting use of CAHPS surveys by implementing and evaluating an interactive database tool designed to assist with the assembly of CAHPS surveys, creating parsimonious variants of CAHPS surveys, evaluating alternative methods of data collection designed to improve response rates, enhancing the collection and use of patient narrative data in reports about health care, and assessing the impact of CAHPS surveys and reports on quality improvement efforts and patient experiences with care.",Consumer Assessment of Healthcare Providers and Systems V (CAHPS V),9787477,U18HS025920,[' '],AHRQ,RAND CORPORATION,U18,2019,1125617,0.027479161426560678
"Consumer Assessment of Healthcare Providers and Systems V (CAHPS V) Consumers, providers and health care purchasers need high-quality information to help them compare and evaluate their health care options. The CAHPS V project will advance the AHRQ CAHPS mission of improving patients' experiences with health care by developing and evaluating strategies for survey measurement, reporting and quality improvement (QI). We propose a 5-year effort to advance the science and practice of patient experience assessment, continue innovation to ensure relevance to health service delivery and implement best survey practices, further the science of reporting, and evaluate CAHPS QI efforts. We will develop program communication strategies, and disseminate and promote use of CAHPS products. In particular, we will develop a survey to assess patient experiences with end-of-life care; develop new items to assess shared decision-making, care coordination, patient engagement, and patient safety; test alternatives to the standard CAHPS modes of data collection), explore the feasibility of administering a short-form survey dividing CG-CAHPS composites among respondents to reduce response burden, elicit stakeholder feedback about the value of different CAHPS supplement item sets, evaluate The Your CAHPS Survey that was designed to help users of the CAHPS surveys compile a survey tailed to their specific needs, and evaluate existing Spanish translations of CAHPS surveys. In addition, we will gather input from stakeholders on best practices for narrative data analysis, develop an approach for using automated Natural Language Processing for analyses of narratives, and construct an algorithm approach to select representative narratives that reflect and illustrate overall provider ratings. Finally, we will evaluate the contribution of patient narratives to quality improvement efforts in hospital care for children, characterize primary care practices use of the CG-CAHPS survey and patient-centered medical home items during PCMH transformation, assess the impact of pay- for-performance for care delivered by primary and specialty care safety net providers on CAHPS survey responses, explore the value of new shared decision-making, patient engagement, communication and patient safety items for QI and identify QI strategies that improve patient experience across various settings. We will also advance analytic methods for CAHPS data. The project team is well suited to achieving the study objectives given its prior accomplishments and established working relationships. The work is innovative and designed to facilitate the use of CAHPS surveys and improve response rates to them, enhance reporting and use of CAHPS survey data, and improve health care QI efforts. PROJECT NARRATIVE This project will advance public health by developing new CAHPS survey items for end-of-life care, shared decision-making, care coordination, patient engagement, and patient safety, promoting use of CAHPS surveys by implementing and evaluating an interactive database tool designed to assist with the assembly of CAHPS surveys, creating parsimonious variants of CAHPS surveys, evaluating alternative methods of data collection designed to improve response rates, enhancing the collection and use of patient narrative data in reports about health care, and assessing the impact of CAHPS surveys and reports on quality improvement efforts and patient experiences with care.",Consumer Assessment of Healthcare Providers and Systems V (CAHPS V),9569636,U18HS025920,[' '],AHRQ,RAND CORPORATION,U18,2018,1149018,0.027479161426560678
"Consumer Assessment of Healthcare Providers and Systems V (CAHPS V) Consumers, providers and health care purchasers need high-quality information to help them compare and evaluate their health care options. The CAHPS V project will advance the AHRQ CAHPS mission of improving patients' experiences with health care by developing and evaluating strategies for survey measurement, reporting and quality improvement (QI). We propose a 5-year effort to advance the science and practice of patient experience assessment, continue innovation to ensure relevance to health service delivery and implement best survey practices, further the science of reporting, and evaluate CAHPS QI efforts. We will develop program communication strategies, and disseminate and promote use of CAHPS products. In particular, we will develop a survey to assess patient experiences with end-of-life care; develop new items to assess shared decision-making, care coordination, patient engagement, and patient safety; test alternatives to the standard CAHPS modes of data collection), explore the feasibility of administering a short-form survey dividing CG-CAHPS composites among respondents to reduce response burden, elicit stakeholder feedback about the value of different CAHPS supplement item sets, evaluate The Your CAHPS Survey that was designed to help users of the CAHPS surveys compile a survey tailed to their specific needs, and evaluate existing Spanish translations of CAHPS surveys. In addition, we will gather input from stakeholders on best practices for narrative data analysis, develop an approach for using automated Natural Language Processing for analyses of narratives, and construct an algorithm approach to select representative narratives that reflect and illustrate overall provider ratings. Finally, we will evaluate the contribution of patient narratives to quality improvement efforts in hospital care for children, characterize primary care practices use of the CG-CAHPS survey and patient-centered medical home items during PCMH transformation, assess the impact of pay- for-performance for care delivered by primary and specialty care safety net providers on CAHPS survey responses, explore the value of new shared decision-making, patient engagement, communication and patient safety items for QI and identify QI strategies that improve patient experience across various settings. We will also advance analytic methods for CAHPS data. The project team is well suited to achieving the study objectives given its prior accomplishments and established working relationships. The work is innovative and designed to facilitate the use of CAHPS surveys and improve response rates to them, enhance reporting and use of CAHPS survey data, and improve health care QI efforts. PROJECT NARRATIVE This project will advance public health by developing new CAHPS survey items for end-of-life care, shared decision-making, care coordination, patient engagement, and patient safety, promoting use of CAHPS surveys by implementing and evaluating an interactive database tool designed to assist with the assembly of CAHPS surveys, creating parsimonious variants of CAHPS surveys, evaluating alternative methods of data collection designed to improve response rates, enhancing the collection and use of patient narrative data in reports about health care, and assessing the impact of CAHPS surveys and reports on quality improvement efforts and patient experiences with care.",Consumer Assessment of Healthcare Providers and Systems V (CAHPS V),9491282,U18HS025920,[' '],AHRQ,RAND CORPORATION,U18,2017,1182529,0.027479161426560678
"TREAT ECARDS: Translating Evidence into Action: Electronic Clinical Decision Support in ARDS PROJECT SUMMARY With an associated mortality of 35%, Acute Respiratory Distress Syndrome (ARDS) contributes to the morbidity and mortality seen in many acute conditions such as pneumonia, influenza, sepsis, trauma and aspiration. Yet studies consistently show that ARDS is under-recognized in up to 40% of patients with generally low and variable adoption of practices shown to improve mortality in ARDS. The overall goal of this proposed project is to improve care delivered to ARDS patients by promoting accurate identification of patients with ARDS and increasing adoption of evidence-based interventions shown to improve outcomes in ARDS. With the recent publication of a multi-professional Clinical Practice Guideline (CPG) on mechanical ventilation in ARDS, this proposal specifically aims: 1) To increase identification of ARDS patients with an automated electronic tool (ARDS Sniffer 2.0) powered by the predictive analytics of machine learning algorithms and natural language processing. 2) To translate the recently published multi-professional Clinical Practice Guideline (CPG) on mechanical ventilation in ARDS into an evidence-based, context-appropriate, Electronic Clinical decision support system in ARDS (ECARDS) for the management of ARDS. This process will be informed by an expert panel from the CPG committee as well as a semi-qualitative analysis of the cognitive decision making process, data needs and workflow of users in a series of Think-Aloud studies and focus group interviews. ARDS Sniffer 2.0, ECARDS and an ARDS Dashboard to show near real-time data on the incidence of ARDS and rate of utilization of best care will then be incorporated within the hospital EMR for useability testing with another series of Think-Aloud and semi-qualitative studies. 3) To evaluate the effectiveness of ARDS Sniffer 2.0, ARDS Dashboard, and ECARDS in a stepped-wedge, cluster randomized control trial of 3 hospitals within the Montefiore Healthcare System to increase utilization of recommended interventions in ARDS and improve outcomes. 4) To promote the dissemination of the clinical decision support system through our partner professional organizations of American Thoracic Society, Society of Critical Care Medicine, and American Association of Respiratory Care and Program for Emergency Preparedness. Because of the high pressure, high acuity, and rapidly changing status of the acutely ill ARDS patient, clinical decision making often defaults to the automated, pattern-driven cognitive processes which are particularly prone to unconscious biases and errors and cognitive overload from large volumes of shifting data. As such, this proposal is the ideal research demonstration project to develop a new clinical decision support tool that will harness the power of big data and predictive analytics to identify ARDS in the hospital and deliver an evidenced-based, expert and user informed clinical decision support tool to clinicians at the right point during their clinical interaction and workflow with these patients in order to promote the right interventions to the right patients at the right time. PROJECT NARRATIVE Even as Acute Respiratory Distress Syndrome constitutes the most severe form of respiratory failure in the hospital with an associated mortality of 35%, it is consistently under-recognized and proven treatments are underutilized. This proposal aims to harness the power of big data in the hospital information system to identify patients with ARDS and prompt clinicians with the evidence-based best management of this condition. By developing a computerized decision support system whose design is informed by the experts and the clinicians themselves, this proposal aims to bring the right care to the right patient at the right time to save lives and promote recovery from this devastating condition.",TREAT ECARDS: Translating Evidence into Action: Electronic Clinical Decision Support in ARDS,9965913,R18HS026188,[' '],AHRQ,ALBERT EINSTEIN COLLEGE OF MEDICINE,R18,2020,397809,0.028839878618779888
"TREAT ECARDS: Translating Evidence into Action: Electronic Clinical Decision Support in ARDS PROJECT SUMMARY With an associated mortality of 35%, Acute Respiratory Distress Syndrome (ARDS) contributes to the morbidity and mortality seen in many acute conditions such as pneumonia, influenza, sepsis, trauma and aspiration. Yet studies consistently show that ARDS is under-recognized in up to 40% of patients with generally low and variable adoption of practices shown to improve mortality in ARDS. The overall goal of this proposed project is to improve care delivered to ARDS patients by promoting accurate identification of patients with ARDS and increasing adoption of evidence-based interventions shown to improve outcomes in ARDS. With the recent publication of a multi-professional Clinical Practice Guideline (CPG) on mechanical ventilation in ARDS, this proposal specifically aims: 1) To increase identification of ARDS patients with an automated electronic tool (ARDS Sniffer 2.0) powered by the predictive analytics of machine learning algorithms and natural language processing. 2) To translate the recently published multi-professional Clinical Practice Guideline (CPG) on mechanical ventilation in ARDS into an evidence-based, context-appropriate, Electronic Clinical decision support system in ARDS (ECARDS) for the management of ARDS. This process will be informed by an expert panel from the CPG committee as well as a semi-qualitative analysis of the cognitive decision making process, data needs and workflow of users in a series of Think-Aloud studies and focus group interviews. ARDS Sniffer 2.0, ECARDS and an ARDS Dashboard to show near real-time data on the incidence of ARDS and rate of utilization of best care will then be incorporated within the hospital EMR for useability testing with another series of Think-Aloud and semi-qualitative studies. 3) To evaluate the effectiveness of ARDS Sniffer 2.0, ARDS Dashboard, and ECARDS in a stepped-wedge, cluster randomized control trial of 3 hospitals within the Montefiore Healthcare System to increase utilization of recommended interventions in ARDS and improve outcomes. 4) To promote the dissemination of the clinical decision support system through our partner professional organizations of American Thoracic Society, Society of Critical Care Medicine, and American Association of Respiratory Care and Program for Emergency Preparedness. Because of the high pressure, high acuity, and rapidly changing status of the acutely ill ARDS patient, clinical decision making often defaults to the automated, pattern-driven cognitive processes which are particularly prone to unconscious biases and errors and cognitive overload from large volumes of shifting data. As such, this proposal is the ideal research demonstration project to develop a new clinical decision support tool that will harness the power of big data and predictive analytics to identify ARDS in the hospital and deliver an evidenced-based, expert and user informed clinical decision support tool to clinicians at the right point during their clinical interaction and workflow with these patients in order to promote the right interventions to the right patients at the right time. PROJECT NARRATIVE Even as Acute Respiratory Distress Syndrome constitutes the most severe form of respiratory failure in the hospital with an associated mortality of 35%, it is consistently under-recognized and proven treatments are underutilized. This proposal aims to harness the power of big data in the hospital information system to identify patients with ARDS and prompt clinicians with the evidence-based best management of this condition. By developing a computerized decision support system whose design is informed by the experts and the clinicians themselves, this proposal aims to bring the right care to the right patient at the right time to save lives and promote recovery from this devastating condition.",TREAT ECARDS: Translating Evidence into Action: Electronic Clinical Decision Support in ARDS,9763432,R18HS026188,[' '],AHRQ,ALBERT EINSTEIN COLLEGE OF MEDICINE,R18,2019,397898,0.028839878618779888
"TREAT ECARDS: Translating Evidence into Action: Electronic Clinical Decision Support in ARDS PROJECT SUMMARY With an associated mortality of 35%, Acute Respiratory Distress Syndrome (ARDS) contributes to the morbidity and mortality seen in many acute conditions such as pneumonia, influenza, sepsis, trauma and aspiration. Yet studies consistently show that ARDS is under-recognized in up to 40% of patients with generally low and variable adoption of practices shown to improve mortality in ARDS. The overall goal of this proposed project is to improve care delivered to ARDS patients by promoting accurate identification of patients with ARDS and increasing adoption of evidence-based interventions shown to improve outcomes in ARDS. With the recent publication of a multi-professional Clinical Practice Guideline (CPG) on mechanical ventilation in ARDS, this proposal specifically aims: 1) To increase identification of ARDS patients with an automated electronic tool (ARDS Sniffer 2.0) powered by the predictive analytics of machine learning algorithms and natural language processing. 2) To translate the recently published multi-professional Clinical Practice Guideline (CPG) on mechanical ventilation in ARDS into an evidence-based, context-appropriate, Electronic Clinical decision support system in ARDS (ECARDS) for the management of ARDS. This process will be informed by an expert panel from the CPG committee as well as a semi-qualitative analysis of the cognitive decision making process, data needs and workflow of users in a series of Think-Aloud studies and focus group interviews. ARDS Sniffer 2.0, ECARDS and an ARDS Dashboard to show near real-time data on the incidence of ARDS and rate of utilization of best care will then be incorporated within the hospital EMR for useability testing with another series of Think-Aloud and semi-qualitative studies. 3) To evaluate the effectiveness of ARDS Sniffer 2.0, ARDS Dashboard, and ECARDS in a stepped-wedge, cluster randomized control trial of 3 hospitals within the Montefiore Healthcare System to increase utilization of recommended interventions in ARDS and improve outcomes. 4) To promote the dissemination of the clinical decision support system through our partner professional organizations of American Thoracic Society, Society of Critical Care Medicine, and American Association of Respiratory Care and Program for Emergency Preparedness. Because of the high pressure, high acuity, and rapidly changing status of the acutely ill ARDS patient, clinical decision making often defaults to the automated, pattern-driven cognitive processes which are particularly prone to unconscious biases and errors and cognitive overload from large volumes of shifting data. As such, this proposal is the ideal research demonstration project to develop a new clinical decision support tool that will harness the power of big data and predictive analytics to identify ARDS in the hospital and deliver an evidenced-based, expert and user informed clinical decision support tool to clinicians at the right point during their clinical interaction and workflow with these patients in order to promote the right interventions to the right patients at the right time. PROJECT NARRATIVE Even as Acute Respiratory Distress Syndrome constitutes the most severe form of respiratory failure in the hospital with an associated mortality of 35%, it is consistently under-recognized and proven treatments are underutilized. This proposal aims to harness the power of big data in the hospital information system to identify patients with ARDS and prompt clinicians with the evidence-based best management of this condition. By developing a computerized decision support system whose design is informed by the experts and the clinicians themselves, this proposal aims to bring the right care to the right patient at the right time to save lives and promote recovery from this devastating condition.",TREAT ECARDS: Translating Evidence into Action: Electronic Clinical Decision Support in ARDS,9571335,R18HS026188,[' '],AHRQ,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R18,2018,397326,0.028839878618779888
"Improving missing data analysis in distributed research networks ABSTRACT Electronic health record (EHR) databases collect data that reflect routine clinical care. These databases are increasingly used in comparative effectiveness research, patient-centered outcomes research, quality improvement assessment, and public health surveillance to generate actionable evidence that improves patient care. It is often necessary to analyze multiple databases that cover large and diverse populations to improve the statistical power of the study or generalizability of the findings. A common approach to analyzing multiple databases is the use of a distributed research network (DRN) architecture, in which data remains under the physical control of data partners. Although EHRs are generally thought to contain rich clinical information, the information is not uniformly collected. Certain information is available only for some patients, and only at some time points for a given patient. There are generally two types of missing information in EHRs. The first is the conventionally understood and obvious missing data in which some data fields (e.g., body mass index) are not complete for various reasons, e.g., the clinician does not collect the information or the patient chooses not to provide the information. The second is less obvious because the data field is not empty but the recorded value may be incorrect due to missing data. For example, EHRs generally do not have complete data for care that occurs in a different delivery system. A medical condition (e.g., asthma) may be coded as no but the true value would have been yes if more complete data had been available, e.g., from claims data as the other delivery system would submit a claim to the patients health plan for the care provided. In other words, one may incorrectly treat absence of evidence as evidence of absence. EHRs hold great promise but we must address several outstanding methodological challenges inherent in the databases, specifically missing data. Addressing missing data is more challenging in DRNs due to different missing data mechanisms across databases. The specific aims of the study are: (1) Apply and assess missing data methods developed in single-database settings to handle obvious and well-recognized missing data in DRNs; (2) Apply and assess machine learning and predictive modeling techniques to address less obvious and under-recognized missing data for select variables in DRNs; and (3) Apply and assess a comprehensive analytic approach that combines conventional missing data methods and machine learning techniques to address missing data in DRNs. The analytic methods developed in this project, including the extension of existing missing data methods to DRNs, the innovative use of machine learning techniques to address missing data, and their integration with privacy- protecting analytic methods, will have direct impact on the design and analysis of future comparative effectiveness and safety studies, and patient-centered outcomes research conducted in DRNs. PROJECT NARRATIVE The proposed project will refine existing methods and develop new methods to address missing data issues in electronic health record databases.",Improving missing data analysis in distributed research networks,10007887,R01HS026214,[' '],AHRQ,"HARVARD PILGRIM HEALTH CARE, INC.",R01,2020,398881,0.048132362318467806
"Improving missing data analysis in distributed research networks ABSTRACT Electronic health record (EHR) databases collect data that reflect routine clinical care. These databases are increasingly used in comparative effectiveness research, patient-centered outcomes research, quality improvement assessment, and public health surveillance to generate actionable evidence that improves patient care. It is often necessary to analyze multiple databases that cover large and diverse populations to improve the statistical power of the study or generalizability of the findings. A common approach to analyzing multiple databases is the use of a distributed research network (DRN) architecture, in which data remains under the physical control of data partners. Although EHRs are generally thought to contain rich clinical information, the information is not uniformly collected. Certain information is available only for some patients, and only at some time points for a given patient. There are generally two types of missing information in EHRs. The first is the conventionally understood and obvious missing data in which some data fields (e.g., body mass index) are not complete for various reasons, e.g., the clinician does not collect the information or the patient chooses not to provide the information. The second is less obvious because the data field is not empty but the recorded value may be incorrect due to missing data. For example, EHRs generally do not have complete data for care that occurs in a different delivery system. A medical condition (e.g., asthma) may be coded as no but the true value would have been yes if more complete data had been available, e.g., from claims data as the other delivery system would submit a claim to the patients health plan for the care provided. In other words, one may incorrectly treat absence of evidence as evidence of absence. EHRs hold great promise but we must address several outstanding methodological challenges inherent in the databases, specifically missing data. Addressing missing data is more challenging in DRNs due to different missing data mechanisms across databases. The specific aims of the study are: (1) Apply and assess missing data methods developed in single-database settings to handle obvious and well-recognized missing data in DRNs; (2) Apply and assess machine learning and predictive modeling techniques to address less obvious and under-recognized missing data for select variables in DRNs; and (3) Apply and assess a comprehensive analytic approach that combines conventional missing data methods and machine learning techniques to address missing data in DRNs. The analytic methods developed in this project, including the extension of existing missing data methods to DRNs, the innovative use of machine learning techniques to address missing data, and their integration with privacy- protecting analytic methods, will have direct impact on the design and analysis of future comparative effectiveness and safety studies, and patient-centered outcomes research conducted in DRNs. PROJECT NARRATIVE The proposed project will refine existing methods and develop new methods to address missing data issues in electronic health record databases.",Improving missing data analysis in distributed research networks,9783740,R01HS026214,[' '],AHRQ,"HARVARD PILGRIM HEALTH CARE, INC.",R01,2019,399886,0.048132362318467806
"Improving missing data analysis in distributed research networks ABSTRACT Electronic health record (EHR) databases collect data that reflect routine clinical care. These databases are increasingly used in comparative effectiveness research, patient-centered outcomes research, quality improvement assessment, and public health surveillance to generate actionable evidence that improves patient care. It is often necessary to analyze multiple databases that cover large and diverse populations to improve the statistical power of the study or generalizability of the findings. A common approach to analyzing multiple databases is the use of a distributed research network (DRN) architecture, in which data remains under the physical control of data partners. Although EHRs are generally thought to contain rich clinical information, the information is not uniformly collected. Certain information is available only for some patients, and only at some time points for a given patient. There are generally two types of missing information in EHRs. The first is the conventionally understood and obvious missing data in which some data fields (e.g., body mass index) are not complete for various reasons, e.g., the clinician does not collect the information or the patient chooses not to provide the information. The second is less obvious because the data field is not empty but the recorded value may be incorrect due to missing data. For example, EHRs generally do not have complete data for care that occurs in a different delivery system. A medical condition (e.g., asthma) may be coded as no but the true value would have been yes if more complete data had been available, e.g., from claims data as the other delivery system would submit a claim to the patients health plan for the care provided. In other words, one may incorrectly treat absence of evidence as evidence of absence. EHRs hold great promise but we must address several outstanding methodological challenges inherent in the databases, specifically missing data. Addressing missing data is more challenging in DRNs due to different missing data mechanisms across databases. The specific aims of the study are: (1) Apply and assess missing data methods developed in single-database settings to handle obvious and well-recognized missing data in DRNs; (2) Apply and assess machine learning and predictive modeling techniques to address less obvious and under-recognized missing data for select variables in DRNs; and (3) Apply and assess a comprehensive analytic approach that combines conventional missing data methods and machine learning techniques to address missing data in DRNs. The analytic methods developed in this project, including the extension of existing missing data methods to DRNs, the innovative use of machine learning techniques to address missing data, and their integration with privacy- protecting analytic methods, will have direct impact on the design and analysis of future comparative effectiveness and safety studies, and patient-centered outcomes research conducted in DRNs. PROJECT NARRATIVE The proposed project will refine existing methods and develop new methods to address missing data issues in electronic health record databases.",Improving missing data analysis in distributed research networks,9575484,R01HS026214,[' '],AHRQ,"HARVARD PILGRIM HEALTH CARE, INC.",R01,2018,400000,0.048132362318467806
"Patient Safety Event Surveillance Using Machine Learning and Free Text Clinical Notes PROJECT SUMMARY/ABSTRACT The proposed project aims to make healthcare safer through collection of patient-centered outcomes as the input data to support a safety and improvement model of the Learning Health System (LHS). The project will accomplish these aims by leveraging existing machine learning methods to classify free text documents, such as clinician notes, for the presence or absence of specific events of interest. The project shares this focus with two long-term objectives. The first broad project goal is to collect important data to address knowledge gaps in the incidence and clinical epidemiology of 5 serious pediatric inpatient healthcare acquired conditions (HACs). These 5 HACs are: peripheral IV infiltrates, venous thromboembolisms (VTEs), pressure injuries, patient falls, and incidents involving harm to providers. The second goal is to evaluate a novel approach to routine patient safety event surveillance that is scalable, transferrable, adaptable to other conditions and settings, and with low cost of sustainable ongoing operation. The project has two specific aims to achieve these goals:  Aim 1: Implement enhanced surveillance for 5 pediatric HACs. Compare characteristics  of previously and newly identified cases. Describe high-risk populations.  Aim 2: Estimate completeness of existing systems. Evaluate effects of enhanced  surveillance on quality improvement activities; incidence of HACs; and cost to operate  system, including staff time and resources. The project team has developed a machine learning interface implemented in open license Windows software. The team has a lengthy track record making these methods accessible to clinicians and lay users in research, clinical operations, quality improvement, and injury prevention settings. The current project proposes an innovative application of these technologies, methods, and tools to the important problem of patient safety surveillance. An expected outcome of this project will be substantial advance in knowledge for each of the 5 pediatric HACs proposed for enhanced surveillance. Results will be reported in terms of existing data completeness and clinical epidemiology. Findings will directly address concerns over limitations of existing data sources and thereby drive patient safety improvement activities. An additional expected outcome will be the rigorous evaluation of a novel approach to patient safety surveillance. This will include analysis of the costs and benefits of enhanced surveillance with machine learning versus current approaches, and the cost-effectiveness of the approach compared to reliance on existing data, and external validation at a partner community hospital. PROJECT NARRATIVE This project addresses important challenges to reduce common sources of harm in pediatric healthcare, namely the Healthcare-Acquired Conditions (HACs) monitored by the National Solutions for Patient Safety quality improvement initiative. It uses a new approach to identify previously unreported safety events that affect hospitalized pediatric patients. The findings from these studies will identify high-risk patient populations and new approaches for quality improvement to reduce the frequency of these events of harm among hospitalized children.",Patient Safety Event Surveillance Using Machine Learning and Free Text Clinical Notes,10003310,R01HS026246,[' '],AHRQ,BOSTON CHILDREN'S HOSPITAL,R01,2020,390145,0.040809520762944716
"Patient Safety Event Surveillance Using Machine Learning and Free Text Clinical Notes PROJECT SUMMARY/ABSTRACT The proposed project aims to make healthcare safer through collection of patient-centered outcomes as the input data to support a safety and improvement model of the Learning Health System (LHS). The project will accomplish these aims by leveraging existing machine learning methods to classify free text documents, such as clinician notes, for the presence or absence of specific events of interest. The project shares this focus with two long-term objectives. The first broad project goal is to collect important data to address knowledge gaps in the incidence and clinical epidemiology of 5 serious pediatric inpatient healthcare acquired conditions (HACs). These 5 HACs are: peripheral IV infiltrates, venous thromboembolisms (VTEs), pressure injuries, patient falls, and incidents involving harm to providers. The second goal is to evaluate a novel approach to routine patient safety event surveillance that is scalable, transferrable, adaptable to other conditions and settings, and with low cost of sustainable ongoing operation. The project has two specific aims to achieve these goals:  Aim 1: Implement enhanced surveillance for 5 pediatric HACs. Compare characteristics  of previously and newly identified cases. Describe high-risk populations.  Aim 2: Estimate completeness of existing systems. Evaluate effects of enhanced  surveillance on quality improvement activities; incidence of HACs; and cost to operate  system, including staff time and resources. The project team has developed a machine learning interface implemented in open license Windows software. The team has a lengthy track record making these methods accessible to clinicians and lay users in research, clinical operations, quality improvement, and injury prevention settings. The current project proposes an innovative application of these technologies, methods, and tools to the important problem of patient safety surveillance. An expected outcome of this project will be substantial advance in knowledge for each of the 5 pediatric HACs proposed for enhanced surveillance. Results will be reported in terms of existing data completeness and clinical epidemiology. Findings will directly address concerns over limitations of existing data sources and thereby drive patient safety improvement activities. An additional expected outcome will be the rigorous evaluation of a novel approach to patient safety surveillance. This will include analysis of the costs and benefits of enhanced surveillance with machine learning versus current approaches, and the cost-effectiveness of the approach compared to reliance on existing data, and external validation at a partner community hospital. PROJECT NARRATIVE This project addresses important challenges to reduce common sources of harm in pediatric healthcare, namely the Healthcare-Acquired Conditions (HACs) monitored by the National Solutions for Patient Safety quality improvement initiative. It uses a new approach to identify previously unreported safety events that affect hospitalized pediatric patients. The findings from these studies will identify high-risk patient populations and new approaches for quality improvement to reduce the frequency of these events of harm among hospitalized children.",Patient Safety Event Surveillance Using Machine Learning and Free Text Clinical Notes,9738559,R01HS026246,[' '],AHRQ,BOSTON CHILDREN'S HOSPITAL,R01,2019,397831,0.040809520762944716
"Developing Evidence for Safety Surveillance from Device Adverse Event Reports Title: Developing Evidence for Safety Surveillance from Device Adverse Event Reports Project Summary/Abstract Population level studies have shown that the device-based hysteroscopic sterilization was associated with increased risks of reoperation during follow-up, when compared to traditional laparoscopic sterilization. However, secondary data sources often lack the granularity to understand the nature of patient and device complications related to the device removal and additional surgery. The Manufacturer and User Facility Device Experience (MAUDE) database houses medical device reports submitted to the FDA by mandatory and voluntary reporters. These reports contain detailed information of patient and device adverse events. But due to its narrative structure, research with the reports has been limited, partially due to the restrictions of keyword search and manual review. The proposed study will innovatively apply natural language processing (NLP) to analyze MAUDE reports of device removals. NLP is a powerful tool capable of extracting information efficiently from documents such as medical notes, allowing the summarization of thousands of adverse event reports in a cost-effective way. The primary aim is to develop an NLP program to extract and summarize patient- and device-specific complications associated with device removal and additional surgeries following hysteroscopic sterilization. Secondary objective is to evaluate the impact of regulatory activities on adverse event reporting behavior and structure. The hypotheses are that the majority of reported removals were associated with device-related complications as opposed to persistent symptoms only, and that after the FDA convened a panel discussion in September 2015, adverse event reports were more likely to be submitted by mandatory reporters, with improvement in structured presentation. Adverse event reports related to device removal will be selected from the MAUDE database using keyword search first, and 1,000 reports will be annotated and used to develop and validate the NLP tool. Applying the developed NLP to all reports, extracted information will be used for the analysis, and comparisons will be made before and after September 2015. The significance of the proposed research is that it will develop a method to better utilize adverse event reports to obtain crucial device safety information supplemental to regular population-level studies. By achieving this, the long term goal is to create a useful tool for future medical device safety surveillance to understand the nature of adverse events. The immediate next step will be to use the tool to investigate device safety in other areas. The comprehension of the nature of device adverse events and the elucidation of the crucial role of regulatory activity in facilitating reliable adverse event reporting will help promote patient safety evaluation and monitoring. Project Narrative The proposed research will focus on device adverse event reports and develop a powerful tool to analyze reports to understand the nature of patient and device complications related to device removals and additional surgeries. The study will also elucidate the impact of regulatory activities on adverse event reporting. Thus, the proposed research is relevant to part of AHRQ's mission to make health care safer.",Developing Evidence for Safety Surveillance from Device Adverse Event Reports,9586941,R03HS026291,[' '],AHRQ,WEILL MEDICAL COLL OF CORNELL UNIV,R03,2018,96907,0.03892048263809308
"Transforming Patient Safety Event Data into Actionable Insights through Advanced Analytics Abstract The objective of the proposed research is to develop an innovative algorithms and a software tool to reduce the burden of safety event report classification and analysis so that report data can be transformed to actionable insights. Making safety event data more actionable will support the proactive identification of safety hazards before patients are harmed. We will achieve our research objective through (1) the development of natural language processing algorithms to classify safety event reports into actionable medication error categories; (2) the development of prototype software that will automatically categorize and visualize safety event reports to support trend identification; and (3) the pilot testing of prototype software with hospital and patient safety organization safety analysts. This project utilizes the extensive expertise of the research team in human factors and safety science, including computer science, specifically regarding information retrieval and data classification. Our research team includes patient safety organizations and collaboration with the computer science department at Georgetown University. The proposal is directly aligned with AHRQs priority area of making health care safer. Contributions from this research will include an expansion of our understanding of natural language processing and its application to categorizing clinical text, advances in visual analytics, and the development of a software tool to support patient safety analysts. The outputs of this research will serve both healthcare organizations and patient safety organizations allowing them to more efficiently and effectively analyze safety report data. Project Narrative This project is relevant to public health because it applies human factors and computer science to develop software to improve the analysis of patient safety event report data to reduce safety hazards and prevent patient harm. Patient safety event report data will be analyzed using natural language processing algorithms to more efficiently classify events into error categories. Based on these algorithms, prototype software will be developed, tested, and disseminated with the goal of automatic categorization and visualization of safety event reports to identify important safety hazards.",Transforming Patient Safety Event Data into Actionable Insights through Advanced Analytics,9962801,R01HS026481,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2020,398080,0.05163269867918549
"Data-Mining Clinical Decision Support from Electronic Health Records     DESCRIPTION (provided by applicant)    Data-Mining Clinical Decision Support from Electronic Health Records Public Health Motivation: National healthcare quality is compromised by undesirable variability, reflected in different locales having anywhere from 20-80% compliance with evidence-based guidelines. Much of this is due to uncertainty, with half of clinical practice guidelines lacking adequate evidence to confirm their efficacy. This is unsurprising when clinical trials cost >$15 million to answer individual clinical questions. The result is medical practice routinely driven by individual opinio and anecdotal experience. While Big Data has revolutionized how society processes internet scale information, the status quo in clinical decision making remains the manual interpretation of literature and isolated decision aids. The adoption of electronic health records (EHR) creates a new opportunity to answer a ""grand challenge in clinical decision support (CDS)."" In a learning health system, we could automatically adapt knowledge from the collective expertise embedded in the EHR practices of real clinicians and close the loop by disseminating that knowledge back as executable decision support. Candidate Goals and Objectives: The unifying goal of this BD2K K01 proposal is the mentored career development of Jonathan H. Chen, MD, PhD. This proposal will accelerate his transition into an independent physician scientist, towards his long-term goals to produce Big Data technologies that answer such grand challenges in clinical decision support. His near-term objective is developing methods to translate EHR data into useful knowledge in the form of patient- specific, point-of-care clinical order recommendations for acute medical hospitalizations. His doctoral background in computer science gives him the technical capability to achieve these objectives, while his medical training will ensure clinically meaningful results. His preliminary work to build an order recommender, analogous to commercial product recommenders, demonstrates the proposal's overall feasibility. Institutional Environment and Career Development: The research facilities and training opportunities at Stanford University provide the ideal environment to achieve these objectives, with established and growing Centers for Biomedical Informatics Research, the Biomedical Data Science Initiative, and the first Clinical Informatics Fellowship accredited in the nation. Prof. Russ Altman, Director of the Biomedical Informatics Training Program, will lead a collaborative team of mentors with expertise in clinical decision support (Mary Goldstein), implementation science (Steven Asch), data-mining electronic health records (Nigam Shah), statistical learning algorithms (Lester Mackey), and healthcare statistics (Michael Baiocchi). Combined with respective didactic training, this mentorship will enable Dr. Chen to achieve his objectives through a series of research aims. Research Aims: The overriding hypothesis of the proposal is that clinical knowledge reflected in clinical order patterns from historical EHR data can improve medical decision making when adapted into functional clinical decision support. The specific aims each address components of this concept, as they seek to: (1) Develop the algorithms to learn clinical order patterns from historical EHR data, building on a preliminary recommender system; (2) Assess how underlying clinician proficiency affects the quality of those learned clinical order patterns through observational data inference against external standards; and (3) Determine the impact of automatically learned clinical decision support (CDS) on (simulated) clinical workflows through a randomized controlled crossover trial of human-computer interfaces with real clinicians. Expected Results and General Significance: By the completion of the proposed work, Dr. Chen will answer the grand challenge in clinical decision support (CDS) by automating much of the CDS production process, and have direct translational impact with a prototype system. This will advance the field with new paradigms of generating and disseminating clinical knowledge, which can then improve the consistency and quality of healthcare delivery. Additional benefits will include methods to identify and monitor areas of high practice variability for targeted optimization and improve predictive models that inform precision medicine. With this applied research experience and career development, Dr. Chen can compete for R01 funding and become an independent physician scientist developing Big Data approaches to solve national healthcare problems in clinical decision making. PUBLIC HEALTH RELEVANCE    National healthcare quality is compromised by undesirable practice variability and medical uncertainty, with most medical practice routinely driven by individual opinions and anecdotal experience. With methods analogous to commercial product recommender systems, the proposed project will automatically learn patterns in raw clinical transaction data to capture the undocumented knowledge of real-world clinicians, and close the loop in a learning health system by disseminating that knowledge back as clinical decision support to improve patient care.",Data-Mining Clinical Decision Support from Electronic Health Records,9749154,K01ES026837,"['Accreditation', 'Achievement', 'Acute', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Algorithms', 'Applied Research', 'Area', 'Automated Clinical Decision Support', 'Back', 'Big Data', 'Big Data to Knowledge', 'Caring', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Practice Guideline', 'Clinical Trials', 'Cost efficiency', 'Cross-Over Trials', 'Crowding', 'Data', 'Data Science', 'Decision Aid', 'Decision Making', 'Diagnosis', 'Doctor of Philosophy', 'Educational process of instructing', 'Electronic Health Record', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Failure', 'Fellowship', 'Funding', 'Future', 'Goals', 'Health system', 'Healthcare', 'Hospitalization', 'Hospitals', 'Image', 'Individual', 'Institute of Medicine (U.S.)', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Locales', 'Machine Learning', 'Manuals', 'Medical', 'Medical Residency', 'Mentors', 'Mentorship', 'Methods', 'Monitor', 'Motivation', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Privatization', 'Process', 'Production', 'Public Health', 'Quality of Care', 'Randomized', 'Recommendation', 'Research', 'Research Training', 'Scientist', 'Series', 'Services', 'Societies', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Training', 'Training Programs', 'Transact', 'Translating', 'Uncertainty', 'Universities', 'User-Computer Interface', 'Validation', 'Weight', 'Work', 'base', 'biomedical informatics', 'career development', 'clinical care', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinical predictors', 'computer science', 'cost', 'data mining', 'design', 'evidence based guidelines', 'experience', 'health care delivery', 'health care quality', 'implementation science', 'improved', 'learning algorithm', 'multidisciplinary', 'point of care', 'precision medicine', 'predictive modeling', 'prototype', 'public health relevance', 'research facility', 'routine practice', 'statistics', 'support tools', 'training opportunity', 'translational impact']",NIEHS,STANFORD UNIVERSITY,K01,2019,178606,0.06544251716528297
"Data-Mining Clinical Decision Support from Electronic Health Records     DESCRIPTION (provided by applicant)    Data-Mining Clinical Decision Support from Electronic Health Records Public Health Motivation: National healthcare quality is compromised by undesirable variability, reflected in different locales having anywhere from 20-80% compliance with evidence-based guidelines. Much of this is due to uncertainty, with half of clinical practice guidelines lacking adequate evidence to confirm their efficacy. This is unsurprising when clinical trials cost >$15 million to answer individual clinical questions. The result is medical practice routinely driven by individual opinio and anecdotal experience. While Big Data has revolutionized how society processes internet scale information, the status quo in clinical decision making remains the manual interpretation of literature and isolated decision aids. The adoption of electronic health records (EHR) creates a new opportunity to answer a ""grand challenge in clinical decision support (CDS)."" In a learning health system, we could automatically adapt knowledge from the collective expertise embedded in the EHR practices of real clinicians and close the loop by disseminating that knowledge back as executable decision support. Candidate Goals and Objectives: The unifying goal of this BD2K K01 proposal is the mentored career development of Jonathan H. Chen, MD, PhD. This proposal will accelerate his transition into an independent physician scientist, towards his long-term goals to produce Big Data technologies that answer such grand challenges in clinical decision support. His near-term objective is developing methods to translate EHR data into useful knowledge in the form of patient- specific, point-of-care clinical order recommendations for acute medical hospitalizations. His doctoral background in computer science gives him the technical capability to achieve these objectives, while his medical training will ensure clinically meaningful results. His preliminary work to build an order recommender, analogous to commercial product recommenders, demonstrates the proposal's overall feasibility. Institutional Environment and Career Development: The research facilities and training opportunities at Stanford University provide the ideal environment to achieve these objectives, with established and growing Centers for Biomedical Informatics Research, the Biomedical Data Science Initiative, and the first Clinical Informatics Fellowship accredited in the nation. Prof. Russ Altman, Director of the Biomedical Informatics Training Program, will lead a collaborative team of mentors with expertise in clinical decision support (Mary Goldstein), implementation science (Steven Asch), data-mining electronic health records (Nigam Shah), statistical learning algorithms (Lester Mackey), and healthcare statistics (Michael Baiocchi). Combined with respective didactic training, this mentorship will enable Dr. Chen to achieve his objectives through a series of research aims. Research Aims: The overriding hypothesis of the proposal is that clinical knowledge reflected in clinical order patterns from historical EHR data can improve medical decision making when adapted into functional clinical decision support. The specific aims each address components of this concept, as they seek to: (1) Develop the algorithms to learn clinical order patterns from historical EHR data, building on a preliminary recommender system; (2) Assess how underlying clinician proficiency affects the quality of those learned clinical order patterns through observational data inference against external standards; and (3) Determine the impact of automatically learned clinical decision support (CDS) on (simulated) clinical workflows through a randomized controlled crossover trial of human-computer interfaces with real clinicians. Expected Results and General Significance: By the completion of the proposed work, Dr. Chen will answer the grand challenge in clinical decision support (CDS) by automating much of the CDS production process, and have direct translational impact with a prototype system. This will advance the field with new paradigms of generating and disseminating clinical knowledge, which can then improve the consistency and quality of healthcare delivery. Additional benefits will include methods to identify and monitor areas of high practice variability for targeted optimization and improve predictive models that inform precision medicine. With this applied research experience and career development, Dr. Chen can compete for R01 funding and become an independent physician scientist developing Big Data approaches to solve national healthcare problems in clinical decision making. PUBLIC HEALTH RELEVANCE    National healthcare quality is compromised by undesirable practice variability and medical uncertainty, with most medical practice routinely driven by individual opinions and anecdotal experience. With methods analogous to commercial product recommender systems, the proposed project will automatically learn patterns in raw clinical transaction data to capture the undocumented knowledge of real-world clinicians, and close the loop in a learning health system by disseminating that knowledge back as clinical decision support to improve patient care.",Data-Mining Clinical Decision Support from Electronic Health Records,9537252,K01ES026837,"['Accreditation', 'Achievement', 'Acute', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Algorithms', 'Applied Research', 'Area', 'Back', 'Big Data', 'Big Data to Knowledge', 'Caring', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Practice Guideline', 'Clinical Trials', 'Cost efficiency', 'Cross-Over Trials', 'Crowding', 'Data', 'Data Science', 'Decision Aid', 'Decision Making', 'Diagnosis', 'Doctor of Philosophy', 'Educational process of instructing', 'Electronic Health Record', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Failure', 'Fellowship', 'Funding', 'Future', 'Goals', 'Health system', 'Healthcare', 'Hospitalization', 'Hospitals', 'Image', 'Individual', 'Institute of Medicine (U.S.)', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Locales', 'Machine Learning', 'Manuals', 'Medical', 'Medical Residency', 'Mentors', 'Mentorship', 'Methods', 'Monitor', 'Motivation', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Privatization', 'Process', 'Production', 'Public Health', 'Quality of Care', 'Randomized', 'Recommendation', 'Research', 'Research Training', 'Scientist', 'Series', 'Services', 'Societies', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Training', 'Training Programs', 'Transact', 'Translating', 'Uncertainty', 'Universities', 'User-Computer Interface', 'Validation', 'Weight', 'Work', 'base', 'biomedical informatics', 'career development', 'clinical care', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinical predictors', 'computer science', 'cost', 'data mining', 'design', 'evidence based guidelines', 'experience', 'health care delivery', 'health care quality', 'implementation science', 'improved', 'multidisciplinary', 'point of care', 'precision medicine', 'predictive modeling', 'prototype', 'public health relevance', 'research facility', 'routine practice', 'statistics', 'support tools', 'training opportunity', 'translational impact']",NIEHS,STANFORD UNIVERSITY,K01,2018,178606,0.06544251716528297
"Data-Mining Clinical Decision Support from Electronic Health Records     DESCRIPTION (provided by applicant)    Data-Mining Clinical Decision Support from Electronic Health Records Public Health Motivation: National healthcare quality is compromised by undesirable variability, reflected in different locales having anywhere from 20-80% compliance with evidence-based guidelines. Much of this is due to uncertainty, with half of clinical practice guidelines lacking adequate evidence to confirm their efficacy. This is unsurprising when clinical trials cost >$15 million to answer individual clinical questions. The result is medical practice routinely driven by individual opinio and anecdotal experience. While Big Data has revolutionized how society processes internet scale information, the status quo in clinical decision making remains the manual interpretation of literature and isolated decision aids. The adoption of electronic health records (EHR) creates a new opportunity to answer a ""grand challenge in clinical decision support (CDS)."" In a learning health system, we could automatically adapt knowledge from the collective expertise embedded in the EHR practices of real clinicians and close the loop by disseminating that knowledge back as executable decision support. Candidate Goals and Objectives: The unifying goal of this BD2K K01 proposal is the mentored career development of Jonathan H. Chen, MD, PhD. This proposal will accelerate his transition into an independent physician scientist, towards his long-term goals to produce Big Data technologies that answer such grand challenges in clinical decision support. His near-term objective is developing methods to translate EHR data into useful knowledge in the form of patient- specific, point-of-care clinical order recommendations for acute medical hospitalizations. His doctoral background in computer science gives him the technical capability to achieve these objectives, while his medical training will ensure clinically meaningful results. His preliminary work to build an order recommender, analogous to commercial product recommenders, demonstrates the proposal's overall feasibility. Institutional Environment and Career Development: The research facilities and training opportunities at Stanford University provide the ideal environment to achieve these objectives, with established and growing Centers for Biomedical Informatics Research, the Biomedical Data Science Initiative, and the first Clinical Informatics Fellowship accredited in the nation. Prof. Russ Altman, Director of the Biomedical Informatics Training Program, will lead a collaborative team of mentors with expertise in clinical decision support (Mary Goldstein), implementation science (Steven Asch), data-mining electronic health records (Nigam Shah), statistical learning algorithms (Lester Mackey), and healthcare statistics (Michael Baiocchi). Combined with respective didactic training, this mentorship will enable Dr. Chen to achieve his objectives through a series of research aims. Research Aims: The overriding hypothesis of the proposal is that clinical knowledge reflected in clinical order patterns from historical EHR data can improve medical decision making when adapted into functional clinical decision support. The specific aims each address components of this concept, as they seek to: (1) Develop the algorithms to learn clinical order patterns from historical EHR data, building on a preliminary recommender system; (2) Assess how underlying clinician proficiency affects the quality of those learned clinical order patterns through observational data inference against external standards; and (3) Determine the impact of automatically learned clinical decision support (CDS) on (simulated) clinical workflows through a randomized controlled crossover trial of human-computer interfaces with real clinicians. Expected Results and General Significance: By the completion of the proposed work, Dr. Chen will answer the grand challenge in clinical decision support (CDS) by automating much of the CDS production process, and have direct translational impact with a prototype system. This will advance the field with new paradigms of generating and disseminating clinical knowledge, which can then improve the consistency and quality of healthcare delivery. Additional benefits will include methods to identify and monitor areas of high practice variability for targeted optimization and improve predictive models that inform precision medicine. With this applied research experience and career development, Dr. Chen can compete for R01 funding and become an independent physician scientist developing Big Data approaches to solve national healthcare problems in clinical decision making. PUBLIC HEALTH RELEVANCE    National healthcare quality is compromised by undesirable practice variability and medical uncertainty, with most medical practice routinely driven by individual opinions and anecdotal experience. With methods analogous to commercial product recommender systems, the proposed project will automatically learn patterns in raw clinical transaction data to capture the undocumented knowledge of real-world clinicians, and close the loop in a learning health system by disseminating that knowledge back as clinical decision support to improve patient care.",Data-Mining Clinical Decision Support from Electronic Health Records,9325317,K01ES026837,"['Accreditation', 'Achievement', 'Acute', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Algorithms', 'Applied Research', 'Area', 'Back', 'Big Data', 'Big Data to Knowledge', 'Caring', 'Chiroptera', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Practice Guideline', 'Clinical Trials', 'Cross-Over Trials', 'Crowding', 'Data', 'Data Science', 'Decision Aid', 'Decision Making', 'Diagnosis', 'Doctor of Philosophy', 'Educational process of instructing', 'Electronic Health Record', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Failure', 'Fellowship', 'Funding', 'Future', 'Goals', 'Health system', 'Healthcare', 'Hospitalization', 'Hospitals', 'Image', 'Individual', 'Institute of Medicine (U.S.)', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Locales', 'Machine Learning', 'Manuals', 'Medical', 'Medical Residency', 'Mentors', 'Mentorship', 'Methods', 'Monitor', 'Motivation', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Privatization', 'Process', 'Production', 'Public Health', 'Quality of Care', 'Randomized', 'Recommendation', 'Research', 'Research Training', 'Scientist', 'Series', 'Services', 'Societies', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Training', 'Training Programs', 'Transact', 'Translating', 'Uncertainty', 'Universities', 'User-Computer Interface', 'Validation', 'Weight', 'Work', 'base', 'biomedical informatics', 'career development', 'clinical care', 'clinical decision-making', 'clinical practice', 'clinical predictors', 'computer science', 'cost', 'data mining', 'design', 'evidence based guidelines', 'experience', 'health care delivery', 'health care quality', 'implementation science', 'improved', 'multidisciplinary', 'point of care', 'precision medicine', 'predictive modeling', 'prototype', 'public health relevance', 'research facility', 'routine practice', 'statistics', 'support tools', 'training opportunity', 'translational impact']",NIEHS,STANFORD UNIVERSITY,K01,2017,178606,0.06544251716528297
"Data-Mining Clinical Decision Support from Electronic Health Records     DESCRIPTION (provided by applicant)    Data-Mining Clinical Decision Support from Electronic Health Records Public Health Motivation: National healthcare quality is compromised by undesirable variability, reflected in different locales having anywhere from 20-80% compliance with evidence-based guidelines. Much of this is due to uncertainty, with half of clinical practice guidelines lacking adequate evidence to confirm their efficacy. This is unsurprising when clinical trials cost >$15 million to answer individual clinical questions. The result is medical practice routinely driven by individual opinio and anecdotal experience. While Big Data has revolutionized how society processes internet scale information, the status quo in clinical decision making remains the manual interpretation of literature and isolated decision aids. The adoption of electronic health records (EHR) creates a new opportunity to answer a ""grand challenge in clinical decision support (CDS)."" In a learning health system, we could automatically adapt knowledge from the collective expertise embedded in the EHR practices of real clinicians and close the loop by disseminating that knowledge back as executable decision support. Candidate Goals and Objectives: The unifying goal of this BD2K K01 proposal is the mentored career development of Jonathan H. Chen, MD, PhD. This proposal will accelerate his transition into an independent physician scientist, towards his long-term goals to produce Big Data technologies that answer such grand challenges in clinical decision support. His near-term objective is developing methods to translate EHR data into useful knowledge in the form of patient- specific, point-of-care clinical order recommendations for acute medical hospitalizations. His doctoral background in computer science gives him the technical capability to achieve these objectives, while his medical training will ensure clinically meaningful results. His preliminary work to build an order recommender, analogous to commercial product recommenders, demonstrates the proposal's overall feasibility. Institutional Environment and Career Development: The research facilities and training opportunities at Stanford University provide the ideal environment to achieve these objectives, with established and growing Centers for Biomedical Informatics Research, the Biomedical Data Science Initiative, and the first Clinical Informatics Fellowship accredited in the nation. Prof. Russ Altman, Director of the Biomedical Informatics Training Program, will lead a collaborative team of mentors with expertise in clinical decision support (Mary Goldstein), implementation science (Steven Asch), data-mining electronic health records (Nigam Shah), statistical learning algorithms (Lester Mackey), and healthcare statistics (Michael Baiocchi). Combined with respective didactic training, this mentorship will enable Dr. Chen to achieve his objectives through a series of research aims. Research Aims: The overriding hypothesis of the proposal is that clinical knowledge reflected in clinical order patterns from historical EHR data can improve medical decision making when adapted into functional clinical decision support. The specific aims each address components of this concept, as they seek to: (1) Develop the algorithms to learn clinical order patterns from historical EHR data, building on a preliminary recommender system; (2) Assess how underlying clinician proficiency affects the quality of those learned clinical order patterns through observational data inference against external standards; and (3) Determine the impact of automatically learned clinical decision support (CDS) on (simulated) clinical workflows through a randomized controlled crossover trial of human-computer interfaces with real clinicians. Expected Results and General Significance: By the completion of the proposed work, Dr. Chen will answer the grand challenge in clinical decision support (CDS) by automating much of the CDS production process, and have direct translational impact with a prototype system. This will advance the field with new paradigms of generating and disseminating clinical knowledge, which can then improve the consistency and quality of healthcare delivery. Additional benefits will include methods to identify and monitor areas of high practice variability for targeted optimization and improve predictive models that inform precision medicine. With this applied research experience and career development, Dr. Chen can compete for R01 funding and become an independent physician scientist developing Big Data approaches to solve national healthcare problems in clinical decision making. PUBLIC HEALTH RELEVANCE    National healthcare quality is compromised by undesirable practice variability and medical uncertainty, with most medical practice routinely driven by individual opinions and anecdotal experience. With methods analogous to commercial product recommender systems, the proposed project will automatically learn patterns in raw clinical transaction data to capture the undocumented knowledge of real-world clinicians, and close the loop in a learning health system by disseminating that knowledge back as clinical decision support to improve patient care.",Data-Mining Clinical Decision Support from Electronic Health Records,9147612,K01ES026837,"['Achievement', 'Acute', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Algorithms', 'Applied Research', 'Area', 'Back', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Practice Guideline', 'Clinical Trials', 'Cross-Over Trials', 'Crowding', 'Data', 'Data Science', 'Decision Aid', 'Decision Making', 'Diagnosis', 'Doctor of Philosophy', 'Educational process of instructing', 'Electronic Health Record', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Failure', 'Fellowship', 'Funding', 'Future', 'Goals', 'Health', 'Health system', 'Healthcare', 'Hospitalization', 'Hospitals', 'Image', 'Individual', 'Institute of Medicine (U.S.)', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Locales', 'Machine Learning', 'Manuals', 'Medical', 'Medical Residency', 'Mentors', 'Mentorship', 'Methods', 'Monitor', 'Motivation', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Production', 'Public Health', 'Quality of Care', 'Randomized', 'Recommendation', 'Research', 'Research Training', 'Scientist', 'Series', 'Services', 'Societies', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Training', 'Training Programs', 'Translating', 'Uncertainty', 'Universities', 'User-Computer Interface', 'Validation', 'Weight', 'Work', 'base', 'biomedical informatics', 'career development', 'clinical decision-making', 'clinical practice', 'computer science', 'cost', 'data mining', 'design', 'evidence based guidelines', 'experience', 'health care delivery', 'health care quality', 'implementation science', 'improved', 'informatics training', 'point of care', 'precision medicine', 'predictive modeling', 'prototype', 'research facility', 'statistics', 'support tools', 'training opportunity']",NIEHS,STANFORD UNIVERSITY,K01,2016,178606,0.06544251716528297
"Data-Mining Clinical Decision Support from Electronic Health Records     DESCRIPTION (provided by applicant)    Data-Mining Clinical Decision Support from Electronic Health Records Public Health Motivation: National healthcare quality is compromised by undesirable variability, reflected in different locales having anywhere from 20-80% compliance with evidence-based guidelines. Much of this is due to uncertainty, with half of clinical practice guidelines lacking adequate evidence to confirm their efficacy. This is unsurprising when clinical trials cost >$15 million to answer individual clinical questions. The result is medical practice routinely driven by individual opinio and anecdotal experience. While Big Data has revolutionized how society processes internet scale information, the status quo in clinical decision making remains the manual interpretation of literature and isolated decision aids. The adoption of electronic health records (EHR) creates a new opportunity to answer a ""grand challenge in clinical decision support (CDS)."" In a learning health system, we could automatically adapt knowledge from the collective expertise embedded in the EHR practices of real clinicians and close the loop by disseminating that knowledge back as executable decision support. Candidate Goals and Objectives: The unifying goal of this BD2K K01 proposal is the mentored career development of Jonathan H. Chen, MD, PhD. This proposal will accelerate his transition into an independent physician scientist, towards his long-term goals to produce Big Data technologies that answer such grand challenges in clinical decision support. His near-term objective is developing methods to translate EHR data into useful knowledge in the form of patient- specific, point-of-care clinical order recommendations for acute medical hospitalizations. His doctoral background in computer science gives him the technical capability to achieve these objectives, while his medical training will ensure clinically meaningful results. His preliminary work to build an order recommender, analogous to commercial product recommenders, demonstrates the proposal's overall feasibility. Institutional Environment and Career Development: The research facilities and training opportunities at Stanford University provide the ideal environment to achieve these objectives, with established and growing Centers for Biomedical Informatics Research, the Biomedical Data Science Initiative, and the first Clinical Informatics Fellowship accredited in the nation. Prof. Russ Altman, Director of the Biomedical Informatics Training Program, will lead a collaborative team of mentors with expertise in clinical decision support (Mary Goldstein), implementation science (Steven Asch), data-mining electronic health records (Nigam Shah), statistical learning algorithms (Lester Mackey), and healthcare statistics (Michael Baiocchi). Combined with respective didactic training, this mentorship will enable Dr. Chen to achieve his objectives through a series of research aims. Research Aims: The overriding hypothesis of the proposal is that clinical knowledge reflected in clinical order patterns from historical EHR data can improve medical decision making when adapted into functional clinical decision support. The specific aims each address components of this concept, as they seek to: (1) Develop the algorithms to learn clinical order patterns from historical EHR data, building on a preliminary recommender system; (2) Assess how underlying clinician proficiency affects the quality of those learned clinical order patterns through observational data inference against external standards; and (3) Determine the impact of automatically learned clinical decision support (CDS) on (simulated) clinical workflows through a randomized controlled crossover trial of human-computer interfaces with real clinicians. Expected Results and General Significance: By the completion of the proposed work, Dr. Chen will answer the grand challenge in clinical decision support (CDS) by automating much of the CDS production process, and have direct translational impact with a prototype system. This will advance the field with new paradigms of generating and disseminating clinical knowledge, which can then improve the consistency and quality of healthcare delivery. Additional benefits will include methods to identify and monitor areas of high practice variability for targeted optimization and improve predictive models that inform precision medicine. With this applied research experience and career development, Dr. Chen can compete for R01 funding and become an independent physician scientist developing Big Data approaches to solve national healthcare problems in clinical decision making.         PUBLIC HEALTH RELEVANCE    National healthcare quality is compromised by undesirable practice variability and medical uncertainty, with most medical practice routinely driven by individual opinions and anecdotal experience. With methods analogous to commercial product recommender systems, the proposed project will automatically learn patterns in raw clinical transaction data to capture the undocumented knowledge of real-world clinicians, and close the loop in a learning health system by disseminating that knowledge back as clinical decision support to improve patient care.                ",Data-Mining Clinical Decision Support from Electronic Health Records,9044538,K01ES026837,"['Achievement', 'Acute', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Algorithms', 'Applied Research', 'Area', 'Back', 'Big Data', 'Biomedical Research', 'Caring', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Practice Guideline', 'Clinical Trials', 'Cross-Over Trials', 'Crowding', 'Data', 'Decision Aid', 'Decision Making', 'Diagnosis', 'Doctor of Philosophy', 'Educational process of instructing', 'Electronic Health Record', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Failure', 'Fellowship', 'Funding', 'Future', 'Goals', 'Health system', 'Healthcare', 'Hospitalization', 'Hospitals', 'Image', 'Individual', 'Institute of Medicine (U.S.)', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Locales', 'Machine Learning', 'Manuals', 'Medical', 'Medical Residency', 'Mentors', 'Mentorship', 'Methods', 'Monitor', 'Motivation', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Production', 'Public Health', 'Quality of Care', 'Randomized', 'Recommendation', 'Relative (related person)', 'Research', 'Research Training', 'Science', 'Scientist', 'Series', 'Services', 'Societies', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Training', 'Training Programs', 'Translating', 'Uncertainty', 'Universities', 'User-Computer Interface', 'Validation', 'Weight', 'Work', 'base', 'biomedical informatics', 'career development', 'clinical decision-making', 'clinical practice', 'computer science', 'cost', 'data mining', 'design', 'evidence based guidelines', 'experience', 'health care delivery', 'health care quality', 'implementation science', 'improved', 'informatics training', 'point of care', 'precision medicine', 'predictive modeling', 'prototype', 'public health relevance', 'research facility', 'statistics', 'tool']",NIEHS,STANFORD UNIVERSITY,K01,2015,178606,0.06544251716528297
"Adaptation and pilot implementation of a validated, electronic real time clinical decision support tool for care of Pneumonia patients in 12 Utah Urgent Care Centers Project Summary Clinicians ability to accurately diagnose pneumonia and choose appropriate treatment is enhanced by well- designed clinical decision support (CDS), thereby increasing patient safety. Pneumonia CDS has historically been focused on inpatient settings, but ambulatory care settings with high pneumonia patient volumes and different care processes also need CDS. We propose to adapt and evaluate an innovative, validated electronic clinical decision support (CDS) tool based on consensus guidelines for pneumonia (ePNa) to urgent care centers (UCC). The proposal supports four aims: 1) Adapt ePNa for UCC and after in silico testing, pilot it among super user clinicians during UCC shifts and assess its usability. ePNa needs adaptation for the limited patient data available in UCC, calibration of severity measures for lower observed mortality, and a chest imaging prompt in patients with pneumonia signs and symptoms. ePNa for UCC will incorporate the artificial intelligence CheXpert model to provide real-time (within seconds) electronic classification of chest images for elements of pneumonia diagnosis and treatment (radiographic pneumonia, single vs multiple lobes, and pleural effusion). 2) Use the CFIR framework, a focus group of UCC clinicians, and workflow observations to identify barriers and facilitators to adaptation and implementation of ePNa to UCC. 3) Test the implementation strategy by deploying ePNa at one of two randomly chosen Intermountain Healthcare UCC clusters each with about 800 annual pneumonia patients - the other a usual care control. 4) Co-primary outcomes are a) Patients diagnosed with pneumonia without chest imaging will be 50% lower in the ePNa cluster. b) Antibiotic prescribing for treatment of pneumonia will be 90% consistent with consensus guidelines and higher in the ePNa cluster. Safety measures will be unplanned subsequent 7-day ED visits/hospitalizations and 30-day mortality. Based on this rigorous pilot study, we anticipate a subsequent multi-system cluster-randomized trial including Cerner systems outside Utah. Our work incorporates the Five Rights of CDS to ensure that the strengths of this technology are optimized in the clinical environment. We will leverage experience in innovative pneumonia research, pioneering CDS, and implementation science available at Intermountain to successfully complete this proposal. The proposal will be facilitated by and disseminated through Intermountain relationships with the PCORnet Learning Health Systems Network, PCOR CDS Learning Network, the Healthcare Services Platform Consortium, Cerner, and clinicaltrials.gov. Our innovative proposal promises to advance safety for patients suspected of pneumonia in an understudied, high-volume ambulatory care setting. Project Narrative Pneumonia is the most common serious infection among adults, but diagnosis and treatment decisions vary between different clinicians. We will adapt for free standing urgent care clinics a validated, real-time, emergency department deployed, electronic pneumonia clinical decision support tool (ePNa). We hypothesize successful implementation of ePNa using the Consolidated Framework for Implementation Research into a cluster of urgent care clinics which treat about 800 pneumonia patients annually will improve care processes and patient outcomes compared to a similar cluster of usual care clinics.","Adaptation and pilot implementation of a validated, electronic real time clinical decision support tool for care of Pneumonia patients in 12 Utah Urgent Care Centers",9932165,R18HS026886,[' '],AHRQ,"IHC HEALTH SERVICES, INC.",R18,2020,443454,0.024563543295982728
"Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings Project Summary (Abstract) With little change in incidence for over 50 years, pneumonia remains the top cause for morbid hospitalization1 in the USA, and is associated with healthcare costs exceeding $10 billion annually2. This study proposes to mine big data captured in an intergrated medical/dental record (iEHR) and enterprise data warehouse (EDW) of a large midwestern medical-dental integrated healthcare system and will test the hypothesis that poor oral health is an independent risk for subtypes of community-acquired and hospital-acquired pneumonia. Proposed specific aims include: 1) electronic identification and characterization of pneumonia types and 2) evaluation of the association of oral health status with risk of pneumonia. Tasks to achieve study aims are to: a) develop electronic, phenotype-based algorithm(s) to classify and characterize pneumonia by subtype and relative frequency of events; b) characterize impact of immediate and longitudinal oral health status on emergent pneumonia stratified by subtype; and c) evaluate relative risk contributed by medical and dental factors. Innovative application of natural language processing (NLP) to support evaluation of unstructured data and machine learning (ML) to identify as-yet unknown potential risk factors is proposed. These aims will be accomplished by established investigators including dentists and researchers with extensive research track records in oral and systemic health including pneumonia, clinical pulmonologist/intensivist to provide clinical expertise to inform data mining, biomedical informaticians with expertise in data mining, ML and NLP and data modeling, and experienced biostatisticians who will apply appropriate statistical approaches and traditional data modeling to big data. This team will collaboratively create and deliver a unique, well-defined, pneumonia- specific, oral health data registry resource and validated phenotype-based algorithm to classify pneumonia, stratified by subtypes, which will support future interrogation for additional permutations of medical and dental factors. Study outcomes are expected to leverage immediate translational value within the health system with high potential for relevance and portability to other settings. The project is expected to define risk factors which may represent actionable targets for reduction of pneumonia risk across various settings. Project Narrative- Relevance to public health: Pneumonia continues as a leading public health problem in hospitals, healthcare facilities and community settings. Pneumonia is the top disease-related cause for hospitalization. This study proposes to use data in electronic health records to classify pneumonia type and describe risk factors that may make individual susceptible to different types of pneumonia, including impact of diseases of the mouth, gums and teeth. The project expects to create models that can identify patients at risk for pneumonia based on information in their medical record so that those risks may be recognized and reduced.",Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings,9784789,R03DE027020,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Aspiration Pneumonia', 'Big Data', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Climate', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Comorbidity', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Dental', 'Dental Care', 'Dental Hygiene', 'Dental Records', 'Dentists', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Electronic Health Record', 'Environmental Risk Factor', 'Evaluation', 'Event', 'Frequencies', 'Future', 'General Hospitals', 'Health', 'Health Care Costs', 'Health Status', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Inpatients', 'Integrated Health Care Systems', 'Intervention Studies', 'Investigation', 'Knowledge', 'Laboratories', 'Link', 'Logic', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Care Costs', 'Medical Records', 'Modeling', 'Mouth Diseases', 'Natural Language Processing', 'Nosocomial pneumonia', 'Oral', 'Oral health', 'Outcome Study', 'Outpatients', 'Pathogenesis', 'Patients', 'Periodontitis', 'Pharmaceutical Preparations', 'Phenotype', 'Pneumococcal vaccine', 'Pneumonia', 'Population Study', 'Prevalence', 'Prevention', 'Public Health', 'Pulmonology', 'Recording of previous events', 'Records', 'Recurrence', 'Relative Risks', 'Research', 'Research Institute', 'Research Personnel', 'Resolution', 'Resources', 'Respiratory Signs and Symptoms', 'Retrospective cohort', 'Risk', 'Risk Factors', 'Role', 'Scoring Method', 'Site', 'Smoking', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tooth structure', 'Translational Research', 'Update', 'Ventilator', 'Visit', 'base', 'burden of illness', 'case finding', 'clinically relevant', 'community setting', 'cost', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'demographics', 'experience', 'follow-up', 'health care delivery', 'health record', 'healthcare community', 'high risk', 'innovation', 'member', 'mortality risk', 'novel', 'outreach', 'patient population', 'patient screening', 'pneumonia model', 'portability', 'secondary analysis', 'systems research', 'ventilator-associated pneumonia']",NIDCR,MARSHFIELD CLINIC RESEARCH FOUNDATION,R03,2019,159914,0.0638051557523369
"Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings Project Summary (Abstract) With little change in incidence for over 50 years, pneumonia remains the top cause for morbid hospitalization1 in the USA, and is associated with healthcare costs exceeding $10 billion annually2. This study proposes to mine big data captured in an intergrated medical/dental record (iEHR) and enterprise data warehouse (EDW) of a large midwestern medical-dental integrated healthcare system and will test the hypothesis that poor oral health is an independent risk for subtypes of community-acquired and hospital-acquired pneumonia. Proposed specific aims include: 1) electronic identification and characterization of pneumonia types and 2) evaluation of the association of oral health status with risk of pneumonia. Tasks to achieve study aims are to: a) develop electronic, phenotype-based algorithm(s) to classify and characterize pneumonia by subtype and relative frequency of events; b) characterize impact of immediate and longitudinal oral health status on emergent pneumonia stratified by subtype; and c) evaluate relative risk contributed by medical and dental factors. Innovative application of natural language processing (NLP) to support evaluation of unstructured data and machine learning (ML) to identify as-yet unknown potential risk factors is proposed. These aims will be accomplished by established investigators including dentists and researchers with extensive research track records in oral and systemic health including pneumonia, clinical pulmonologist/intensivist to provide clinical expertise to inform data mining, biomedical informaticians with expertise in data mining, ML and NLP and data modeling, and experienced biostatisticians who will apply appropriate statistical approaches and traditional data modeling to big data. This team will collaboratively create and deliver a unique, well-defined, pneumonia- specific, oral health data registry resource and validated phenotype-based algorithm to classify pneumonia, stratified by subtypes, which will support future interrogation for additional permutations of medical and dental factors. Study outcomes are expected to leverage immediate translational value within the health system with high potential for relevance and portability to other settings. The project is expected to define risk factors which may represent actionable targets for reduction of pneumonia risk across various settings. Project Narrative- Relevance to public health: Pneumonia continues as a leading public health problem in hospitals, healthcare facilities and community settings. Pneumonia is the top disease-related cause for hospitalization. This study proposes to use data in electronic health records to classify pneumonia type and describe risk factors that may make individual susceptible to different types of pneumonia, including impact of diseases of the mouth, gums and teeth. The project expects to create models that can identify patients at risk for pneumonia based on information in their medical record so that those risks may be recognized and reduced.",Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings,9599192,R03DE027020,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Aspiration Pneumonia', 'Big Data', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Climate', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Comorbidity', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Dental', 'Dental Care', 'Dental Hygiene', 'Dental Records', 'Dentists', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Electronic Health Record', 'Environmental Risk Factor', 'Evaluation', 'Event', 'Frequencies', 'Future', 'General Hospitals', 'Health', 'Health Care Costs', 'Health Status', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Inpatients', 'Integrated Health Care Systems', 'Intervention Studies', 'Investigation', 'Knowledge', 'Laboratories', 'Link', 'Logic', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Care Costs', 'Medical Records', 'Modeling', 'Mouth Diseases', 'Natural Language Processing', 'Nosocomial pneumonia', 'Oral', 'Oral health', 'Outcome Study', 'Outpatients', 'Pathogenesis', 'Patients', 'Periodontitis', 'Pharmaceutical Preparations', 'Phenotype', 'Pneumococcal vaccine', 'Pneumonia', 'Population Study', 'Prevalence', 'Prevention', 'Public Health', 'Pulmonology', 'Recording of previous events', 'Records', 'Recurrence', 'Relative Risks', 'Research', 'Research Institute', 'Research Personnel', 'Resolution', 'Resources', 'Respiratory Signs and Symptoms', 'Retrospective cohort', 'Risk', 'Risk Factors', 'Role', 'Scoring Method', 'Site', 'Smoking', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tooth structure', 'Translational Research', 'Update', 'Ventilator', 'Visit', 'base', 'burden of illness', 'case finding', 'clinically relevant', 'community setting', 'cost', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'demographics', 'experience', 'follow-up', 'health care delivery', 'health record', 'healthcare community', 'high risk', 'innovation', 'member', 'mortality', 'novel', 'outreach', 'patient population', 'patient screening', 'pneumonia model', 'portability', 'secondary analysis', 'systems research', 'ventilator-associated pneumonia']",NIDCR,MARSHFIELD CLINIC RESEARCH FOUNDATION,R03,2018,174917,0.0638051557523369
"Application of a Machine Learning to Enhance e-Triggers to Detect and Learn from Diagnostic Safety Events The frequency of diagnostic errors in emergency departments (ED) is largely unknown but likely to be significant. There is a compelling need to create measurement methods that provide diagnostic safety data to clinicians and leaders who in turn can act upon these data to prevent diagnostic harm. Electronic trigger (e- trigger) tools mine vast amounts of clinical and administrative data to identify signals for likely adverse events and have demonstrated capability to identify diagnostic errors. Such tools are more efficient and effective than other methods and can reduce the number of records requiring human review to those at highest risk of harm.  In prior work, we used rules-based e-trigger algorithms to identify patterns of care suggestive of missed or delayed diagnoses in primary care and inpatient settings. For instance, a clinic visit followed several days later by an unplanned hospitalization could be indicative of potential problems with the diagnostic process at the clinic visit. We also proposed a knowledge discovery framework, the Safer Dx Trigger Tools Framework, to enable health care organizations (HCOs) to develop and implement e-trigger tools to measure diagnostic errors using comprehensive electronic health record (EHR) data. Review and analysis of these cases can uncover safety concerns and provide information on diagnostic process breakdowns and related contributory factors, which in turn could generate learning and feedback for improvement purposes.  Sophisticated techniques from machine learning (ML) and data science could help inform second generation e-trigger algorithms that better identify diagnostic errors and/or harm than rules-based e-triggers that require substantial manual effort and chart reviews. In contrast to rules-based systems, ML techniques could help learn from examples and accurately retrieve charts with diagnostic error without the need for hand crafting of an e-trigger. We will apply e-triggers to comprehensive EHRs that contain longitudinal patient care data (progress notes, tests, referrals) that provide an extensive picture of patients diagnostic journeys. Using national VA data, including data from 9 million veterans, and data from Geisinger health system, a pioneer HCO that serves approximately 3 million patients, we propose the following aims: Aim 1  To develop, refine, test, and apply Safer Dx e-triggers to enable detection, measurement, and learning from diagnostic errors in diverse emergency department (ED) settings. We will calculate the frequency of diagnostic errors in the ED based on these e-triggers and describe the burden of preventable diagnostic harm. Aim 2 - To explore machine learning techniques that yield robust, accurate models to predict diagnostic errors using EHR-enriched data derived from expert-labeled patient records containing diagnostic errors (from Aim 1).  To our knowledge this is the first ML application in diagnostic error measurement, which could help scale up expert-driven e-trigger development and refinement. Newly developed e-triggers can be pilot tested and implemented at other HCOs, enabling them to create actionable safety-related insights from digital data. Narrative The process of making a diagnosis in emergency departments can be vulnerable to error. To study the risks involved, we will develop strategies to better identify electronic medical records of patients who may have had a diagnostic error in their care. We will test the use of human-derived rule-based algorithms and data-driven machine learning methods that can more accurately and efficiently identify these medical records than other currently available methods used in measurement of patient safety.",Application of a Machine Learning to Enhance e-Triggers to Detect and Learn from Diagnostic Safety Events,10018015,R01HS027363,[' '],AHRQ,BAYLOR COLLEGE OF MEDICINE,R01,2020,498859,0.04189240423075032
"Application of a Machine Learning to Enhance e-Triggers to Detect and Learn from Diagnostic Safety Events The frequency of diagnostic errors in emergency departments (ED) is largely unknown but likely to be significant. There is a compelling need to create measurement methods that provide diagnostic safety data to clinicians and leaders who in turn can act upon these data to prevent diagnostic harm. Electronic trigger (e- trigger) tools mine vast amounts of clinical and administrative data to identify signals for likely adverse events and have demonstrated capability to identify diagnostic errors. Such tools are more efficient and effective than other methods and can reduce the number of records requiring human review to those at highest risk of harm.  In prior work, we used rules-based e-trigger algorithms to identify patterns of care suggestive of missed or delayed diagnoses in primary care and inpatient settings. For instance, a clinic visit followed several days later by an unplanned hospitalization could be indicative of potential problems with the diagnostic process at the clinic visit. We also proposed a knowledge discovery framework, the Safer Dx Trigger Tools Framework, to enable health care organizations (HCOs) to develop and implement e-trigger tools to measure diagnostic errors using comprehensive electronic health record (EHR) data. Review and analysis of these cases can uncover safety concerns and provide information on diagnostic process breakdowns and related contributory factors, which in turn could generate learning and feedback for improvement purposes.  Sophisticated techniques from machine learning (ML) and data science could help inform second generation e-trigger algorithms that better identify diagnostic errors and/or harm than rules-based e-triggers that require substantial manual effort and chart reviews. In contrast to rules-based systems, ML techniques could help learn from examples and accurately retrieve charts with diagnostic error without the need for hand crafting of an e-trigger. We will apply e-triggers to comprehensive EHRs that contain longitudinal patient care data (progress notes, tests, referrals) that provide an extensive picture of patients diagnostic journeys. Using national VA data, including data from 9 million veterans, and data from Geisinger health system, a pioneer HCO that serves approximately 3 million patients, we propose the following aims: Aim 1  To develop, refine, test, and apply Safer Dx e-triggers to enable detection, measurement, and learning from diagnostic errors in diverse emergency department (ED) settings. We will calculate the frequency of diagnostic errors in the ED based on these e-triggers and describe the burden of preventable diagnostic harm. Aim 2 - To explore machine learning techniques that yield robust, accurate models to predict diagnostic errors using EHR-enriched data derived from expert-labeled patient records containing diagnostic errors (from Aim 1).  To our knowledge this is the first ML application in diagnostic error measurement, which could help scale up expert-driven e-trigger development and refinement. Newly developed e-triggers can be pilot tested and implemented at other HCOs, enabling them to create actionable safety-related insights from digital data. Narrative The process of making a diagnosis in emergency departments can be vulnerable to error. To study the risks involved, we will develop strategies to better identify electronic medical records of patients who may have had a diagnostic error in their care. We will test the use of human-derived rule-based algorithms and data-driven machine learning methods that can more accurately and efficiently identify these medical records than other currently available methods used in measurement of patient safety.",Application of a Machine Learning to Enhance e-Triggers to Detect and Learn from Diagnostic Safety Events,9938114,R01HS027363,[' '],AHRQ,BAYLOR COLLEGE OF MEDICINE,R01,2019,496121,0.04189240423075032
"An expert-guided machine-learning approach to estimate the incidence, risk and harms associated with diagnostic delays for infectious diseases. Project Summary / Abstract Diagnostic errors are increasingly recognized as a cause of pain, suffering and increased healthcare costs. Diagnostic delays are an important class of diagnostic errors. While many diagnostic errors occur in hospital settings, emergency departments visits may be especially important to consider because they treat critically ill patients and because most decisions to admit patients to the hospital are made in emergency departments. Thus, to enable a more complete understanding of diagnostic delays requires consideration of healthcare visits across a range of healthcare settings including clinic visits, emergency department visits and hospitalizations. Delays in diagnosing infectious diseases are important to consider. For contagious infectious diseases, diagnostic delays increase the risk of additional exposures, potentially generating more cases. Second, many infectious diseases can be effectively treated, but even short delays in treatment lead to worse clinical outcomes. However, with the exception of a few infectious diseases (e.g., tuberculosis), diagnostic delays for infectious diseases are understudied. Thus, there is a critical need to investigate the incidence, risk factors and clinical impact for diagnostic delays for infectious diseases. The overarching goal of our research is to investigate diagnostic delays associated with infectious diseases using existing data along with methods from the fields of computer science and statistics. While our research relies upon big data, we will also use clinical experts to review and contribute to all of our results. Our subject matter experts incorporate expertise in infectious diseases, emergency medicine, acute care, medical education, diagnostic reasoning, healthcare epidemiology, public health, industry, and professional infectious disease societies. Specifically, we will 1) determine the incidence of diagnostic delays for a wide range of infectious diseases; 2) identify the risk factors associated with diagnostic delays for infectious diseases that are frequently delayed or have serious outcomes; and 3) estimate the impact of diagnostic delays in terms of healthcare costs and mortality. With our data, methods and clinical experts, we will be able to translate our results into future interventions designed to decrease diagnostic delays and improve healthcare outcomes. In addition, while our proposal focuses on infectious diseases, the methods and approaches that we will develop can be adopted to investigate non-infectious diseases and conditions. Project Narrative Diagnostic delays for infectious diseases contribute to worse clinical outcomes, increased healthcare costs and, for some infectious diseases, outbreaks of great public health importance. We will use existing large data sets along with machine-learning techniques and expert clinical guidance to detect patterns of healthcare visits representing diagnostic delays. Our goal is to characterize the incidence, risk factors and clinical impact of diagnostic delays for a wide range of infectious diseases to inform future interventions.","An expert-guided machine-learning approach to estimate the incidence, risk and harms associated with diagnostic delays for infectious diseases.",10017203,R01HS027375,[' '],AHRQ,UNIVERSITY OF IOWA,R01,2020,496235,-0.008414080037178608
"An expert-guided machine-learning approach to estimate the incidence, risk and harms associated with diagnostic delays for infectious diseases. Project Summary / Abstract Diagnostic errors are increasingly recognized as a cause of pain, suffering and increased healthcare costs. Diagnostic delays are an important class of diagnostic errors. While many diagnostic errors occur in hospital settings, emergency departments visits may be especially important to consider because they treat critically ill patients and because most decisions to admit patients to the hospital are made in emergency departments. Thus, to enable a more complete understanding of diagnostic delays requires consideration of healthcare visits across a range of healthcare settings including clinic visits, emergency department visits and hospitalizations. Delays in diagnosing infectious diseases are important to consider. For contagious infectious diseases, diagnostic delays increase the risk of additional exposures, potentially generating more cases. Second, many infectious diseases can be effectively treated, but even short delays in treatment lead to worse clinical outcomes. However, with the exception of a few infectious diseases (e.g., tuberculosis), diagnostic delays for infectious diseases are understudied. Thus, there is a critical need to investigate the incidence, risk factors and clinical impact for diagnostic delays for infectious diseases. The overarching goal of our research is to investigate diagnostic delays associated with infectious diseases using existing data along with methods from the fields of computer science and statistics. While our research relies upon big data, we will also use clinical experts to review and contribute to all of our results. Our subject matter experts incorporate expertise in infectious diseases, emergency medicine, acute care, medical education, diagnostic reasoning, healthcare epidemiology, public health, industry, and professional infectious disease societies. Specifically, we will 1) determine the incidence of diagnostic delays for a wide range of infectious diseases; 2) identify the risk factors associated with diagnostic delays for infectious diseases that are frequently delayed or have serious outcomes; and 3) estimate the impact of diagnostic delays in terms of healthcare costs and mortality. With our data, methods and clinical experts, we will be able to translate our results into future interventions designed to decrease diagnostic delays and improve healthcare outcomes. In addition, while our proposal focuses on infectious diseases, the methods and approaches that we will develop can be adopted to investigate non-infectious diseases and conditions. Project Narrative Diagnostic delays for infectious diseases contribute to worse clinical outcomes, increased healthcare costs and, for some infectious diseases, outbreaks of great public health importance. We will use existing large data sets along with machine-learning techniques and expert clinical guidance to detect patterns of healthcare visits representing diagnostic delays. Our goal is to characterize the incidence, risk factors and clinical impact of diagnostic delays for a wide range of infectious diseases to inform future interventions.","An expert-guided machine-learning approach to estimate the incidence, risk and harms associated with diagnostic delays for infectious diseases.",9938200,R01HS027375,[' '],AHRQ,UNIVERSITY OF IOWA,R01,2019,497273,-0.008414080037178608
"Homecare-CONCERN: Building risk models for preventable hospitalizations and emergency department visits in homecare Project Summary/Abstract Every year, more than 11,000 homecare agencies across the United States provide care to more than 5 million older adults. Currently, about one in three homecare patients are hospitalized or visit an emergency department (ED) during the 30-60 day homecare episode. Up to 40% of these events are preventable with appropriate and timely care. In our pilot work, we developed a risk prediction model (called Homecare- CONCERN) that accurately identified patients at risk for hospital admission and ED visits solely from homecare clinical notes using NLP. This study brings together an interdisciplinary team of experts in homecare, data science, nursing and risk model development to explore whether cutting-edge data science approaches can improve timely identification of patients at risk in homecare. Our specific aims are to: 1. Further develop and validate a preventable hospitalization or ED visit risk prediction model (Homecare-  CONCERN). We will apply traditional (time varying Cox regression) and cutting-edge time-sensitive  analytical methods (Deep Survival Analysis and Long-Short Term Memory Neural Network) for risk model development. 2. Prepare Homecare-CONCERN for clinical trial via pilot testing. We will apply user centered design to  develop Homecare-CONCERN clinical decision support tool and pilot test the tool for clinical validity and acceptability. 3. Inform the future implementation of Homecare-CONCERN clinical decision support tool in the homecare  setting. We will examine if all risk elements can be mapped to a data standard (Fast Healthcare  Interoperability Resources - FHIR) and conduct interviews with key informants across the US about current  readiness, barriers and facilitators, and implementation strategies for adopting such tools in homecare setting. This proposal addresses the AHRQ program announcement (PA-18-795) to harness data to improve healthcare quality and patient outcomes. The study will build a first-of-a-kind clinical decision support system to trigger timely and personalized alerts about concerning patient trends that activate appropriate and timely care to prevent avoidable hospitalizations and ED visits from homecare. Project Narrative Our previous work has shown that clinician documentation patterns and content are proxy for patient risk. Concerning documentation patterns can be used to identify patients who are deteriorating so clinical team can intervene before it is too late. Although several previous studies attempted to create models predicting patients risk in homecare, no studies to date used all available data (clinical notes and electronic health record data). This study aims to use all available clinical data on homecare patients to create personalized models of risk for preventable hospitalization and emergency department visit. We will also explore the feasibility and readiness of homecare agencies to adopt such predictive tools. Study results will catalyze a paradigm shift in homecare by making it possible to develop a first-of-its-kind data-driven clinical decision support system.",Homecare-CONCERN: Building risk models for preventable hospitalizations and emergency department visits in homecare,10092444,R01HS027742,[' '],AHRQ,VISITING NURSE SERVICE OF NEW YORK,R01,2020,400000,-0.012640622477364399
"Multicenter Study of the Emergency Department Trigger Tool Existing methods for surveillance of patient harm in the ED setting are inadequate, without any meaningful change in decades. Trigger tools, popularized by the Institute for Healthcare Improvements Global Trigger Tool, have been developed for multiple clinical areas and are used across the world, outperform traditional approaches for surveillance of adverse events. These tools use a two-tiered review process where a nurse screens records for triggers (predefined findings that make the presence of an AE more likely) and reviews records with triggers for AEs, discarding those without triggers. We developed a consensus-based ED trigger tool (EDTT) using a multicenter, transdisciplinary modified Delphi approach, subsequently pilot testing this in a multicenter fashion with encouraging results. This was followed by a recently completed, AHRQ-funded single center study to automate, refine and validate this tool. This study demonstrated that the EDTT is a high-yield and efficient instrument for identifying adverse events in the ED. The present study will evaluate the refined, automated EDTT), in a multicenter study. We will evaluate the EDTTs generalizability and robustness at three sites with large emergency departments, with a planned in-depth review of 9,000 ED admissions. We will use natural language processing of electronic medical record narratives and machine learning to improve the EDTT efficiency in trigger detection and AE discovery. We will establish the basis for a wider use and prepare for scalability and usability of the tool, creating standardized, streamlined and free online training materials, and by evaluating the tool in a real-world manner consistent with intended use. Project Narrative Commonly used approaches in Emergency Departments to detect adverse events are low yield and have not changed in decades, providing inadequate surveillance for patient harm. The need for improved methodology is critical, given the evolving role of the emergency department in the health care system. Trigger tools, developed for use in many healthcare settings across the world, detect all-cause harm, helping direct resources by identifying areas of risk and allowing an assessment of the effectiveness of quality improvement efforts over time. Trigger tools involve screening of records by a nurse for triggers (findings that make an adverse event more likely) and a review of only records with triggers searching for adverse events. Any events identified undergo confirmatory physician review. We developed a trigger tool for the ED, applying rigorous methods to identify predictive triggers, to computerize the screen for triggers eliminating manual review and improving record selection to enhance yield and efficiency. This tool demonstrates superior performance for detecting adverse events. We will now test this tool in a multicenter project to evaluate its broad application, confirming its utility and to continue to improve its yield and efficiency in adverse event detection by applying natural language processing and machine learning techniques.",Multicenter Study of the Emergency Department Trigger Tool,10098792,R01HS027811,[' '],AHRQ,WASHINGTON UNIVERSITY,R01,2020,398528,0.044716641240870325
"Development and Validation of a Prediction Model to Address Physician Burnout PROJECT SUMMARY Professional burnout is a growing epidemic with symptoms affecting over 500,000 US physicians at any given time and carries significant adverse consequences for physician mental health, health care value, quality of care, and patient safety. There is an urgent need to develop reliable methods to proactively identify work environments at high risk for physician burnout, and tailor process improvements accordingly. The objective of this proposal is to develop and validate a real-time prediction model that uses operational data in primary care practices to identify high-risk clinics for physician burnout, enabling timely and tailored process improvements. The central hypothesis is that routinely-collected electronic health record (EHR) usage metrics coupled with practice-specific metrics can predict physicians risk for burnout and inform process improvement. The rationale for the proposed research is that early identification of high-risk clinics will allow organizations to tailor interventions to those clinics before burnout and its individual or health system consequences arise. This would be an innovative approach that prevents burnout rather than reacting to it. This project capitalizes on routinely-collect data from Stanford primary care clinics to create a database encompassing EHR usage metrics and practice-specific metrics. The specific aims are: Aim 1: Develop a prediction model to quantify risk for physician burnout. The working hypothesis is that real-time metrics of practice efficiency tracked by the EHR and other practice-specific metrics can predict physician burnout using a machine learning approach. Aim 2: Refine the prediction model using qualitative methods. The working hypothesis is that qualitative assessment will inform refinements to the prediction model created in Aim 1, and will demonstrate the face validity of the model. Aim 3: Validate the use of the prediction model to identify high-risk clinics. The working hypothesis is that quality of care metrics will demonstrate the concurrent validity, that subsequent routinely administered burnout surveys will demonstrate the predictive validity of the prediction model created in Aims 1 and 2, when aggregated at the clinic level. This proposal is significant because physician burnout is a growing problem with important implications for patient safety. It is also innovative in deploying machine learning and mixed methods to identify physicians at increased risk for burnout which will enable testing interventions to reverse this trend. In combination with formal training in quantitative and qualitative methods, expert mentorship, and participation in selected scholarly activities at Stanford, the experience gained through this project will facilitate progress toward a long-term goal to become an academic leader advancing evidence-based reform of the health care delivery system to optimize human factors that improve quality and safety. PROJECT NARRATIVE There is an urgent need to develop reliable methods to proactively identify and improve work environments with high risk for physician burnout, and doing so will have broad public health relevance by reducing risk for burnout and its negative effects on quality and safety of care. Addressing physician burnout in primary care carries relevance for AHRQs priority populations of women, children, the elderly, and low-income patients, who are particularly dependent on high quality primary care. This project will support AHRQs mission of producing evidence to make health care safer and higher quality by developing and validating a prediction model to identify high-risk primary care clinics for physician burnout in order to 1) inform resource allocation to clinics with the highest need, 2) tailor process improvements to reduce risk for burnout and poor quality of care, and 3) lay the groundwork for expanding this model to other high-risk practice settings and provider types.",Development and Validation of a Prediction Model to Address Physician Burnout,10105225,K08HS027837,[' '],AHRQ,STANFORD UNIVERSITY,K08,2020,152582,0.027519589963035586
"Epidemiology and clinical outcomes of diabetic macular edema Approximately 25% of the millions of veterans (est. 8.92 million FY 2013) enrolled for care in Veterans Health Administration (VHA) have diabetes mellitus, and diabetic macular edema (DME) is the leading cause of vision loss in the adult diabetic population world-wide. Although diabetic retinopathy has been well-studied, comparatively little is known about the burden of DME. In fact, only two national prevalence studies and no national study on the incidence of DME in persons with type 2 diabetes have been conducted. Similarly many risk factors have been characterized for DR, but no large studies have established predictors for DME.  Beyond the Medicare claims database, the VHA National Patient Care Database (NPCD) contains standardized administrative data for several aspects of patient care including diagnoses, procedures, medications, lab test results, vital signs, clinical text notes, and mortality. Because the VA uses teleretinal screening as routine clinical care for all patients with diabetes with these results included in the NPCD, the NPCD is an ideal source for studying the epidemiology of and risk factors for DME.  This study proposes to determine the burden of diabetic macular edema, establish risk factors, and examine treatment outcomes in a previously extracted dataset on 1.98 million veterans who have undergone diabetic retinopathy screening at least once since 2004. Currently invaluable ophthalmic data are encoded in unstructured clinical encounter notes in the Computerized Patient Record System (CPRS), and no validated automated extraction method exists to capture these data elements. An automated extraction method using natural language processing will be created and validated to unlock key ophthalmic variables. These text extraction methods will be applicable to extracting ophthalmology data from not only notes of patients with DME but also any ophthalmology clinical note. This will enable future large scale studies in ophthalmology using NPCD and be immediately valuable to the research community at large.  The candidate, Dr. Aaron Lee, MD MSCI, is an ophthalmologist with subspecialty training in retina surgery with a strong background in computer science and epidemiology. His career goal is to become an independent clinician scientist studying diabetic eye disease with large-scale electronic medical record extracted data. While he possesses the foundational skills, he seeks to gain training in advanced statistics and natural language processing to unlock the data captured in unstructured clinical encounter notes. He has assembled an outstanding mentorship team under the primary mentor, Dr. Edward Boyko, MD MPH. This mentorship team includes renowned experts in clinical epidemiology, health informatics, ophthalmology, and natural language processing. This K23 will provide Dr. Lee the structured coursework, mentorship, and applied learning needed to acquire new research skills. He will leverage key local resources to carry out the proposed research at the University of Washington and the VA Seattle Epidemiologic Research and Information Center. Despite the significant visual loss associated with diabetic macular edema, little is known about the frequency of its occurrence, its risk factors, and the real-world effectiveness of existing treatments. The purpose of this proposed research is to utilize the VA National Patient Care Database to extract relevant data elements to examine these three clinical questions: 1) what is the incidence and prevalence of diabetic macular edema, 2) what are the risk factors associated with its development, and 3) what is the comparative real-world effectiveness of its treatments, including intravitreal anti-VEGF therapy, intravitreal corticosteroid therapy and macular laser. The methods developed in this research proposal will not only further our understanding of DME but also generalize and enable future large-scale ophthalmic studies.",Epidemiology and clinical outcomes of diabetic macular edema,9995499,K23EY029246,"['Adopted', 'Adrenal Cortex Hormones', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anemia', 'Blindness', 'Cardiovascular Diseases', 'Caring', 'Cataract Extraction', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Computerized Medical Record', 'Computerized Patient Records', 'Data', 'Data Element', 'Data Set', 'Databases', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Dyslipidemias', 'Effectiveness', 'Enrollment', 'Epidemiology', 'Ethnic Origin', 'Exclusion Criteria', 'Eye', 'Eye diseases', 'Foundational Skills', 'Frequencies', 'Future', 'Goals', 'Handedness', 'Hypertension', 'Incidence', 'Information Centers', 'Injections', 'Intervention', 'Lasers', 'Lead', 'Light Coagulation', 'Manuals', 'Masks', 'Measures', 'Medicare claim', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Prevalence Study', 'Procedures', 'Protocols documentation', 'Public Health Informatics', 'Randomized Controlled Trials', 'Regimen', 'Research', 'Research Proposals', 'Resources', 'Retina', 'Risk Factors', 'Scientist', 'Severities', 'Sleep Apnea Syndromes', 'Smoking Status', 'Source', 'Standardization', 'Structure', 'System', 'Test Result', 'Text', 'Time', 'Training', 'Treatment Protocols', 'Treatment outcome', 'Universities', 'Use Effectiveness', 'Validation', 'Vascular Endothelial Growth Factors', 'Veterans', 'Visual', 'Visual Acuity', 'Washington', 'automated algorithm', 'bevacizumab', 'career', 'clinical care', 'clinical encounter', 'clinical epidemiology', 'cohort', 'comparative', 'computer science', 'diabetes management', 'diabetic', 'epidemiology study', 'hands-on learning', 'health administration', 'intravitreal injection', 'kidney dysfunction', 'laser photocoagulation', 'macula', 'macular edema', 'mortality', 'proliferative diabetic retinopathy', 'screening', 'skills', 'statistics', 'therapy outcome', 'traditional therapy', 'treatment optimization', 'unstructured data']",NEI,UNIVERSITY OF WASHINGTON,K23,2020,238049,0.04173543026485504
"Epidemiology and clinical outcomes of diabetic macular edema Approximately 25% of the millions of veterans (est. 8.92 million FY 2013) enrolled for care in Veterans Health Administration (VHA) have diabetes mellitus, and diabetic macular edema (DME) is the leading cause of vision loss in the adult diabetic population world-wide. Although diabetic retinopathy has been well-studied, comparatively little is known about the burden of DME. In fact, only two national prevalence studies and no national study on the incidence of DME in persons with type 2 diabetes have been conducted. Similarly many risk factors have been characterized for DR, but no large studies have established predictors for DME.  Beyond the Medicare claims database, the VHA National Patient Care Database (NPCD) contains standardized administrative data for several aspects of patient care including diagnoses, procedures, medications, lab test results, vital signs, clinical text notes, and mortality. Because the VA uses teleretinal screening as routine clinical care for all patients with diabetes with these results included in the NPCD, the NPCD is an ideal source for studying the epidemiology of and risk factors for DME.  This study proposes to determine the burden of diabetic macular edema, establish risk factors, and examine treatment outcomes in a previously extracted dataset on 1.98 million veterans who have undergone diabetic retinopathy screening at least once since 2004. Currently invaluable ophthalmic data are encoded in unstructured clinical encounter notes in the Computerized Patient Record System (CPRS), and no validated automated extraction method exists to capture these data elements. An automated extraction method using natural language processing will be created and validated to unlock key ophthalmic variables. These text extraction methods will be applicable to extracting ophthalmology data from not only notes of patients with DME but also any ophthalmology clinical note. This will enable future large scale studies in ophthalmology using NPCD and be immediately valuable to the research community at large.  The candidate, Dr. Aaron Lee, MD MSCI, is an ophthalmologist with subspecialty training in retina surgery with a strong background in computer science and epidemiology. His career goal is to become an independent clinician scientist studying diabetic eye disease with large-scale electronic medical record extracted data. While he possesses the foundational skills, he seeks to gain training in advanced statistics and natural language processing to unlock the data captured in unstructured clinical encounter notes. He has assembled an outstanding mentorship team under the primary mentor, Dr. Edward Boyko, MD MPH. This mentorship team includes renowned experts in clinical epidemiology, health informatics, ophthalmology, and natural language processing. This K23 will provide Dr. Lee the structured coursework, mentorship, and applied learning needed to acquire new research skills. He will leverage key local resources to carry out the proposed research at the University of Washington and the VA Seattle Epidemiologic Research and Information Center. Despite the significant visual loss associated with diabetic macular edema, little is known about the frequency of its occurrence, its risk factors, and the real-world effectiveness of existing treatments. The purpose of this proposed research is to utilize the VA National Patient Care Database to extract relevant data elements to examine these three clinical questions: 1) what is the incidence and prevalence of diabetic macular edema, 2) what are the risk factors associated with its development, and 3) what is the comparative real-world effectiveness of its treatments, including intravitreal anti-VEGF therapy, intravitreal corticosteroid therapy and macular laser. The methods developed in this research proposal will not only further our understanding of DME but also generalize and enable future large-scale ophthalmic studies.",Epidemiology and clinical outcomes of diabetic macular edema,9756410,K23EY029246,"['Adopted', 'Adrenal Cortex Hormones', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anemia', 'Blindness', 'Cardiovascular Diseases', 'Caring', 'Cataract Extraction', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Computerized Medical Record', 'Computerized Patient Records', 'Data', 'Data Element', 'Data Set', 'Databases', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Dyslipidemias', 'Effectiveness', 'Enrollment', 'Epidemiology', 'Ethnic Origin', 'Exclusion Criteria', 'Expressed Sequence Tags', 'Eye', 'Eye diseases', 'Foundational Skills', 'Frequencies', 'Future', 'Goals', 'Handedness', 'Hypertension', 'Incidence', 'Information Centers', 'Injections', 'Intervention', 'Lasers', 'Lead', 'Light Coagulation', 'Manuals', 'Masks', 'Measures', 'Medicare claim', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Prevalence Study', 'Procedures', 'Protocols documentation', 'Public Health Informatics', 'Randomized Controlled Trials', 'Regimen', 'Research', 'Research Proposals', 'Resources', 'Retina', 'Retinal', 'Risk Factors', 'Scientist', 'Severities', 'Sleep Apnea Syndromes', 'Smoking Status', 'Source', 'Standardization', 'Structure', 'System', 'Test Result', 'Text', 'Time', 'Training', 'Treatment Protocols', 'Treatment outcome', 'Universities', 'Use Effectiveness', 'Validation', 'Vascular Endothelial Growth Factors', 'Veterans', 'Visual', 'Visual Acuity', 'Washington', 'bevacizumab', 'career', 'clinical care', 'clinical epidemiology', 'cohort', 'comparative', 'computer science', 'diabetes management', 'diabetic', 'epidemiology study', 'hands-on learning', 'health administration', 'intravitreal injection', 'kidney dysfunction', 'laser photocoagulation', 'macula', 'macular edema', 'mortality', 'proliferative diabetic retinopathy', 'screening', 'skills', 'statistics', 'therapy outcome', 'traditional therapy', 'treatment optimization']",NEI,UNIVERSITY OF WASHINGTON,K23,2019,233078,0.04173543026485504
"Epidemiology and clinical outcomes of diabetic macular edema Approximately 25% of the millions of veterans (est. 8.92 million FY 2013) enrolled for care in Veterans Health Administration (VHA) have diabetes mellitus, and diabetic macular edema (DME) is the leading cause of vision loss in the adult diabetic population world-wide. Although diabetic retinopathy has been well-studied, comparatively little is known about the burden of DME. In fact, only two national prevalence studies and no national study on the incidence of DME in persons with type 2 diabetes have been conducted. Similarly many risk factors have been characterized for DR, but no large studies have established predictors for DME.  Beyond the Medicare claims database, the VHA National Patient Care Database (NPCD) contains standardized administrative data for several aspects of patient care including diagnoses, procedures, medications, lab test results, vital signs, clinical text notes, and mortality. Because the VA uses teleretinal screening as routine clinical care for all patients with diabetes with these results included in the NPCD, the NPCD is an ideal source for studying the epidemiology of and risk factors for DME.  This study proposes to determine the burden of diabetic macular edema, establish risk factors, and examine treatment outcomes in a previously extracted dataset on 1.98 million veterans who have undergone diabetic retinopathy screening at least once since 2004. Currently invaluable ophthalmic data are encoded in unstructured clinical encounter notes in the Computerized Patient Record System (CPRS), and no validated automated extraction method exists to capture these data elements. An automated extraction method using natural language processing will be created and validated to unlock key ophthalmic variables. These text extraction methods will be applicable to extracting ophthalmology data from not only notes of patients with DME but also any ophthalmology clinical note. This will enable future large scale studies in ophthalmology using NPCD and be immediately valuable to the research community at large.  The candidate, Dr. Aaron Lee, MD MSCI, is an ophthalmologist with subspecialty training in retina surgery with a strong background in computer science and epidemiology. His career goal is to become an independent clinician scientist studying diabetic eye disease with large-scale electronic medical record extracted data. While he possesses the foundational skills, he seeks to gain training in advanced statistics and natural language processing to unlock the data captured in unstructured clinical encounter notes. He has assembled an outstanding mentorship team under the primary mentor, Dr. Edward Boyko, MD MPH. This mentorship team includes renowned experts in clinical epidemiology, health informatics, ophthalmology, and natural language processing. This K23 will provide Dr. Lee the structured coursework, mentorship, and applied learning needed to acquire new research skills. He will leverage key local resources to carry out the proposed research at the University of Washington and the VA Seattle Epidemiologic Research and Information Center. Despite the significant visual loss associated with diabetic macular edema, little is known about the frequency of its occurrence, its risk factors, and the real-world effectiveness of existing treatments. The purpose of this proposed research is to utilize the VA National Patient Care Database to extract relevant data elements to examine these three clinical questions: 1) what is the incidence and prevalence of diabetic macular edema, 2) what are the risk factors associated with its development, and 3) what is the comparative real-world effectiveness of its treatments, including intravitreal anti-VEGF therapy, intravitreal corticosteroid therapy and macular laser. The methods developed in this research proposal will not only further our understanding of DME but also generalize and enable future large-scale ophthalmic studies.",Epidemiology and clinical outcomes of diabetic macular edema,9574973,K23EY029246,"['Adopted', 'Adrenal Cortex Hormones', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anemia', 'Blindness', 'Cardiovascular Diseases', 'Caring', 'Cataract Extraction', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Computerized Medical Record', 'Computerized Patient Records', 'Data', 'Data Element', 'Data Set', 'Databases', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Dyslipidemias', 'Effectiveness', 'Enrollment', 'Epidemiology', 'Ethnic Origin', 'Exclusion Criteria', 'Expressed Sequence Tags', 'Eye', 'Eye diseases', 'Foundational Skills', 'Frequencies', 'Functional disorder', 'Future', 'Goals', 'Handedness', 'Hypertension', 'Incidence', 'Information Centers', 'Injections', 'Intervention', 'Kidney', 'Lasers', 'Lead', 'Light Coagulation', 'Manuals', 'Masks', 'Measures', 'Medicare claim', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Prevalence Study', 'Procedures', 'Protocols documentation', 'Public Health Informatics', 'Randomized Controlled Trials', 'Regimen', 'Research', 'Research Proposals', 'Resources', 'Retina', 'Retinal', 'Risk Factors', 'Scientist', 'Severities', 'Sleep Apnea Syndromes', 'Smoking Status', 'Source', 'Standardization', 'Structure', 'System', 'Test Result', 'Text', 'Time', 'Training', 'Treatment Protocols', 'Treatment outcome', 'Universities', 'Use Effectiveness', 'Validation', 'Vascular Endothelial Growth Factors', 'Veterans', 'Visual', 'Visual Acuity', 'Washington', 'bevacizumab', 'career', 'clinical care', 'clinical epidemiology', 'cohort', 'comparative', 'computer science', 'diabetes management', 'diabetic', 'epidemiology study', 'hands-on learning', 'health administration', 'intravitreal injection', 'laser photocoagulation', 'macula', 'macular edema', 'mortality', 'proliferative diabetic retinopathy', 'screening', 'skills', 'statistics', 'therapy outcome', 'traditional therapy', 'treatment optimization']",NEI,UNIVERSITY OF WASHINGTON,K23,2018,237398,0.04173543026485504
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for traininga typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training dataa typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,9957898,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2020,271250,0.017992684865153385
"Biomedical Informatics Tools for Applied Perioperative Physiology Project Summary / Abstract Even though US hospitals have widely adopted electronic health record (EHR) documentation of patient care, interoperability of these systems remains an issue, leading to challenges in data integration. In the operating room (OR) setting, during surgery, physiological waveforms (arterial pressure, EKG, SpO2, central venous pressure, etc.) represent a large source of information used by clinical monitors to extract and display information in order for healthcare providers to make clinical decisions. Integration and synchronization of high-quality EHR and physiological waveform data in large datasets of surgical patients would allow machine learning and deep learning approaches to plumb these datasets for clinically relevant signatures that would promote advanced OR patient monitoring systems to define present state, predict state trajectory, suggest effective counter measures to minimize patients decompensated states, and define the usefulness and efficacy of new monitoring devices. The objective of this proposal is to focus the resources of an interdisciplinary team from academia (University of California Los Angeles (UCLA), University of California Irvine (UCI), and Carnegie Mellon University Computer Sciences), industry (Edwards Lifesciences Critical Care), and clinical medicine (anesthesiology, surgery, and critical care at UCLA, UCI, Beth Israel, and University of Pittsburgh Medical Center) to create, develop, and organize large surgical datasets combining EHR and high fidelity physiological waveform data, to make these datasets freely accessible, and to develop new predictive/forecasting monitoring systems for the surgical patients. The study will begin with the development of a machine learning algorithm to predict cardiovascular collapse during surgery. This algorithm development will be based on physiological signatures predictive of cardiovascular collapse identified in the animal models of shock. The study hypothesis is that the combination of two separate OR databases containing EHR and physiological waveforms will allow for training and development of monitoring solutions, predictive and/or prescriptive analytics tools, clinical decision support, and validate them on an independent, external validation database. The surgical setting is relevant because although 5.7 million Americans are admitted annually to an Intensive Care Unit, more than 50 million undergo surgery. OR databases are unique in medicine because: 1) Changes occur quickly and the lead-time before an event is compressed; 2) Knowledge of baseline/pre-stress status of surgical patients allows normalization, calibration, and markedly enhances prediction; 3) Continuous and immediate presence of dense skilled acute care practitioners allows faster implementation of complex treatment algorithms in the OR; and 4) Defined stages, procedures, and stressors allow building large common relational database registries. By helping to focus the provider's attention on significant events and changes in the patient's state and by suggesting physiological interpretations of that state, such systems will permit early detection of complex problems and provide guidance on therapeutic interventions improving patient outcomes. Project Narrative The objective of this proposal is to focus the resources of an interdisciplinary team from academia (University of California Los Angeles (UCLA), University of California Irvine (UCI), and Carnegie Mellon University Computer Sciences), industry (Edwards Lifesciences Critical Care), and clinical medicine (anesthesiology, surgery, and critical care at UCLA, UCI, Beth Israel, and University of Pittsburgh Medical Center) to create, develop, and organize large surgical datasets combining electronic health record and high-fidelity physiological waveform data, to make these datasets freely accessible, and to develop new predictive/forecasting monitoring systems for the surgical patients. We hypothesize that the combination of two separate OR databases containing electronic health record and physiological waveforms will allow us and other investigators to train and develop monitoring solutions, predictive and/or prescriptive analytics tools, clinical decision support, and validate them on an independent, external validation database. We will use these datasets to develop a new physiological predictive tool of cardiovascular collapse during surgery and to validate the new data's potential utility to a broader community of researchers.",Biomedical Informatics Tools for Applied Perioperative Physiology,9971901,R01EB029751,"['Academia', 'Address', 'Adopted', 'Agreement', 'Algorithms', 'American', 'Anesthesia procedures', 'Anesthesiology', 'Animal Model', 'Area', 'Attention', 'Biological', 'Calibration', 'California', 'Cause of Death', 'Central venous pressure', 'Certified registered nurse anesthetist', 'Characteristics', 'Clinical', 'Clinical Medicine', 'Communities', 'Complex', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Dimensions', 'Documentation', 'Early Diagnosis', 'Electrocardiogram', 'Electronic Health Record', 'Event', 'Future', 'Gender', 'Goals', 'Hand', 'Health Personnel', 'Heart Arrest', 'Hospitals', 'Human', 'Incidence', 'Industry', 'Ingestion', 'Inpatients', 'Intensive Care Units', 'Israel', 'Knowledge', 'Lead', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Medicine', 'Melons', 'Minority', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring System', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perioperative', 'Physiologic Monitoring', 'Physiological', 'Physiology', 'Population', 'Population Heterogeneity', 'Postoperative Period', 'Procedures', 'Process', 'Provider', 'Registries', 'Research', 'Research Personnel', 'Resources', 'Series', 'Shock', 'Source', 'Stress', 'System', 'Technology', 'Therapeutic Intervention', 'Time', 'Training', 'Twin Multiple Birth', 'Universities', 'Validation', 'Work', 'acute care', 'algorithm development', 'analytical tool', 'base', 'biomedical informatics', 'cardiovascular collapse', 'clinical decision support', 'clinical decision-making', 'clinically relevant', 'cloud based', 'computer science', 'data archive', 'data integration', 'data streams', 'deep learning', 'density', 'human data', 'human subject', 'improved', 'informatics tool', 'information display', 'interest', 'interoperability', 'large datasets', 'learning algorithm', 'machine learning algorithm', 'monitoring device', 'mortality', 'novel', 'predictive modeling', 'predictive signature', 'predictive tools', 'pressure', 'relational database', 'sex', 'stressor', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,672624,0.023934977353936484
"Quantifying Microbial Keratitis to Predict Outcomes: An Imaging and Epidemiologic Approach PROJECT SUMMARY/ABSTRACT For epidemiological studies, future clinical trials, and personalized patient care, there is a critical need to create a risk-stratification system for microbial keratitis. Microbial keratitis (MK), a debilitating, infectious corneal disease, is estimated to be the fourth-leading cause of blindness worldwide. MK severity depends on a complex interaction of patient, organism, and environment, resulting in a spectrum of clinical presentations and responses to treatment. Clinical presentations manifest with unique morphology features and clinical symptoms. Morphology features are visible in the cornea, and symptoms are measurable. But most patients are treated with non-specific broad-spectrum antimicrobials, an approach that increases antimicrobial resistance. This non-specific treatment approach lacks congruence with the unique MK presentations. There is a critical need for a new strategy to personalize treatments for MK and measure treatment efficacy. With quantified MK morphologic and clinical features, clinicians will have the tools to risk-stratify patients. The long-term goal is to develop rapid, objective, personalized treatment plans for patients with MK. This proposals objective is to quantify dynamic morphologic and clinical MK features using image and electronic health record (EHR) analyses and then build a risk-stratification scoring system associated with MK outcomes. The proposed research will test the hypothesis that morphologic and clinical features accurately risk- stratify patients for corneal and vision outcomes. Our premise is supported by preliminary data demonstrating that: (1) different organisms generate distinct morphologic and clinical features; (2) clinicians quantify morphology less precisely than image-analysis methods, (3) an expert is able to use MK features to tailor treatments; (4) the use of quantified features has improved outcomes in other diseases, such as diabetic retinopathy, by helping providers to tailor treatments; (5) EHR data can be used to quantify and classify clinical disease features accurately; and (6) EHR data can be used effectively to risk-stratify patients. Aim 1 will develop objective image analysis tools to measure features of MK with existing clinical equipment. Aim 2 will evaluate MK treatment efficacy using morphologic image analysis and clinical features from prospective surveys. Aim 3 will risk-stratify patients with MK by combining image analysis and EHR extracted data. The expected outcomes are: (1) characterized databases of MK images and linked clinical data, (2) quantified MK features across a spectrum of clinical presentations, (3) performance-tested, open-source imaging algorithms and surveys to measure MK markers dynamically, and (4) a novel risk stratification model and scoring system. The resultant work will have significant value to clinicians. Clinicians can use practical, low-cost technologies and readily-available EHR data to quantify MK features and risk-stratify patients in order to tailor treatments. NARRATIVE The clinical management of microbial keratitis is imprecise and dependent on the expertise of the treating physician. Our innovative strategies will quantify corneal features using image analysis and available clinical data from the electronic health record. Quantified image features will be linked to health outcomes to give physicians new tools to risk-stratify patients and to tailor their management to optimize outcomes.",Quantifying Microbial Keratitis to Predict Outcomes: An Imaging and Epidemiologic Approach,9865483,R01EY031033,"['Algorithms', 'Antimicrobial Resistance', 'Blindness', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complex', 'Control Groups', 'Cornea', 'Corneal Diseases', 'Data', 'Data Collection', 'Databases', 'Diabetic Retinopathy', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Enrollment', 'Environment', 'Epidemiology', 'Equipment', 'Evaluation', 'Eye', 'Future', 'Goals', 'Health', 'Image', 'Image Analysis', 'Inflammatory', 'Keratitis', 'Link', 'Measurable', 'Measurement', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Morphology', 'National Eye Institute', 'Organism', 'Outcome', 'Participant', 'Patient Outcomes Assessments', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Provider', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Self-Examination', 'Severities', 'Standardization', 'Strategic Planning', 'Surveys', 'Symptoms', 'System', 'Technology', 'Testing', 'Treatment Efficacy', 'Universities', 'Virulence', 'Vision', 'Visual Acuity', 'Work', 'antimicrobial', 'automated algorithm', 'base', 'care systems', 'case control', 'clinical risk', 'cost', 'deep learning', 'epidemiology study', 'healing', 'improved outcome', 'individualized medicine', 'innovation', 'microbial', 'novel', 'open source', 'outcome prediction', 'patient stratification', 'performance tests', 'personalized care', 'personalized medicine', 'primary outcome', 'prospective', 'slit lamp imaging', 'tool', 'treatment planning', 'treatment response']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,410000,0.058284434785957406
"Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics PROJECT SUMMARY The widespread adoption of EHRs has enabled the collection of massive amounts of digital ophthalmic data which have great potential for secondary use in research, quality improvement, and clinical decision support. While the amount of digital ophthalmic data recorded in the EHR is substantial and could be analyzed using the latest techniques for big data, questions about the quality of the data are a barrier to its reuse. Now that the American Academy of Ophthalmology has aggregated digital ophthalmic data from the EHR into the IRIS Registry, data quality is even more imperative for reaching the potential of the registry. To date, there has not be a comprehensive evaluation of the data quality of digital ophthalmic data, nor have there been any solutions for improving its quality. These are important gaps that will limit the utility of EHR data as a tool for knowledge discovery in ophthalmology. The goal of this grant is to assess the quality of digital ophthalmic exam data in order to improve its ability to be reused for research. Our hypothesis is that studying the variability of data quality in large datasets will provide insights into improving its quality. The first aim employs an established framework for data quality analysis to assess the intrinsic quality of a single institutions EHR data as well as its fitness for use--the ability to be applied to a particular research scenario. In this proposal, we are evaluating the datas ability to identify patient cohorts for clinical trials and to accurately calculate outcome based clinical quality measures. The variability in datas quality and fitness among providers, subspecialties, diagnoses, and visit types will be analyzed. The second aim validates the analysis of the first aim by repeating it for all of the ophthalmic data in the IRIS Registry. For this analysis, the differences in quality and fitness between institutions and EHR vendors will also be assessed, along with the barriers to data quality and reuse. For both aims, ophthalmology experts will review the results to make recommendations for improving data quality and utility for digital ophthalmic data. In the future, these recommendations will provide a direction for correcting these quality issues and for ultimately advancing knowledge discovery in ophthalmic care. PROJECT NARRATIVE Electronic health records (EHRs) have not yet reached their potential for transforming healthcare, particularly for reusing clinical data for research. The American Academy of Ophthalmology has aggregated ophthalmic data from the EHR into the IRIS Registry, and data quality is even more imperative to achieve to reach the potential of this registry. Using methodological data quality analysis, we will analyze the quality of a single institutions ophthalmic data and again for multiple institutions ophthalmic data in the IRIS Registry, documenting barriers for data quality and reuse that will lead to improving knowledge discovery from this data.",Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics,9953684,R21EY031443,"['Academy', 'Adoption', 'Age related macular degeneration', 'American', 'Big Data', 'Big Data Methods', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Collection', 'Complex', 'Data', 'Data Discovery', 'Diabetic Retinopathy', 'Diagnosis', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Exfoliation Syndrome', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Hand', 'Health Sciences', 'Healthcare', 'Human', 'Image', 'Individual', 'Informatics', 'Institutes', 'Institution', 'Intelligence', 'Iris', 'Knowledge Discovery', 'Manuals', 'Measurement', 'Measures', 'Medical Informatics', 'Medicine', 'Methodology', 'Methods', 'Ophthalmology', 'Oregon', 'Outcome', 'Patients', 'Process', 'Provider', 'Recommendation', 'Registries', 'Research', 'Research Personnel', 'Retinopathy of Prematurity', 'Secondary to', 'Source', 'Structure', 'System', 'Techniques', 'Terminology', 'Treatment outcome', 'Universities', 'Vendor', 'Vision', 'Visit', 'base', 'clinical decision support', 'clinical encounter', 'cohort', 'data framework', 'data harmonization', 'data quality', 'data registry', 'data reuse', 'data submission', 'deep learning', 'digital', 'electronic data', 'experience', 'fitness', 'improved', 'insight', 'large datasets', 'large scale data', 'research study', 'tool', 'treatment comparison']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2020,231000,0.05901687425157658
"Integrating an Open Repository of Polygenic Risk Scores for Major Cancer Sites with a Visual Catalog PROJECT SUMMARY The current proposal, submitted to the special funding opportunity for Administrative Supplements for Integrative Data Analysis to Extend Research in Cancer Control and Population Sciences (NOT-CA-18-087), leverages the unique and rich data resource of the Michigan Genomics Initiative (MGI) comprising of >55,000 patients recruited at Michigan Medicine with complete array-based whole-genome genotyping data that are connected to rich longitudinal data retrieved from their electronic health records. In addition, we have access to information on behavioural data collected through a detailed questionnaire and geocoded residence information. These diverse sources of data allow us the possibility of creating novel and more accurate measures of exposures using questionnaire responses, structured and unstructured component of the electronic health record including clinical notes and the geocoded residential information. A key aspect of MGI is its enrichment for cancer outcomes. About 50% of the participants recruited so far have at least one neoplasm diagnosis in their health record. This is due to the recruitment of MGI participants from a perioperative setting. This cancer enrichment sets it apart from other biobanks and presents a unique opportunity at the University of Michigan Rogel Cancer Center for cancer control and population sciences research. Our proposal aspires to establish an analytical framework to distil summary statistics of published genome- wide association studies for cancer into polygenic risk scores, to construct known and novel cancer-related exposures from clinical free text and data mining of geocoded residential data, and to utilize them in a screen for associations across the catalogued medical phenome, the ensemble of clinical diagnoses and biomarkers that are derived from routinely ordered lab tests in MGI. Correlated co-morbidities could, if pre-symptomatic, be used to improve cancer risk prediction, while associated exposures could inform on targeted strategies for cancer prevention and risk stratification. Novel findings will be replicated (when feasible) in the publicly accessible data of the UK Biobank, a population-based study of up to half a million participants. To differentiate between pre-symptomatic and post-treatment features, we will probe the existing time- stamped data of MGI that permit retrospective insights of up to ten years into a participants electronic medical records. Since there is an urgent need to better communicate results from such big data exploration with a broad and multi-disciplinary audience, e.g. to inspire follow-up replication and new hypothesis generation in cancer epidemiology and furthering our understanding of susceptibility mechanisms for cancer, we will develop a webpage to allow intuitive and interactive result browsing and open sharing. The proposal showcases the advantage of harmonization, integration of large and complex databases towards impactful research and powerful discovery tools in cancer control and population sciences. PROJECT NARRATIVE Leveraging and harnessing the rich data resource of the cancer-enriched cohort of the Michigan Genomics Initiative (MGI), a longitudinal biorepository effort at Michigan Medicine, this unique integrative data analysis proposal attempts to integrate genes, exposure and health history information as archived in an individuals electronic medical records under a unifying analytic and scientific discovery framework. The ultimate goal is to give shape and structure to disparate sources of data towards principled discovery, inference and prediction. Through the proposed research we hope to achieve improved risk prediction, risk stratification and targeted prevention of cancer. Tools will be developed for wider dissemination of the results via an online visual catalog and make the results from massive, complex and heterogeneous sources of data accessible to other researchers, stakeholders and community participants. The proposal will showcase the potential for discoveries in cancer population-studies using unique data features from MGI, a medical center-based biobank and simultaneously leverage our access to the large population-based biobank, namely the UK Biobank, for replication and confirmation studies. In that sense, the proposal carries out integrative data analysis in two directions: (a) integrated analysis of diverse sources of data within MGI and (b) integrated use of MGI in concert with data from a large publicly available biobank, the UK Biobank.",Integrating an Open Repository of Polygenic Risk Scores for Major Cancer Sites with a Visual Catalog,9765877,P30CA046592,"['Access to Information', 'Administrative Supplement', 'Aftercare', 'Alcohol consumption', 'Anesthesia procedures', 'Archives', 'Authorization documentation', 'Behavioral', 'Big Data', 'Biological Markers', 'Biometry', 'Cancer Center', 'Cancer Control', 'Catalogs', 'Clinical', 'Communities', 'Comorbidity', 'Complex', 'Computerized Medical Record', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Early Diagnosis', 'Electronic Health Record', 'Enrollment', 'Environment', 'Faculty', 'Funding Opportunities', 'Future', 'Generations', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Health Sciences', 'Hospitals', 'Individual', 'Informatics', 'Information Dissemination', 'Inherited', 'International Classification of Disease Codes', 'Intuition', 'Learning', 'Light', 'Longitudinal cohort', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical center', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Michigan', 'Neoplasms', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patient Recruitments', 'Patients', 'Performance', 'Perioperative', 'Phenotype', 'Population', 'Population Sciences', 'Population Study', 'Predisposition', 'Prevention', 'Prevention Measures', 'Publishing', 'Questionnaires', 'Randomized', 'Recording of previous events', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Risk Factors', 'Risk stratification', 'Role', 'Screening for cancer', 'Shapes', 'Smoking', 'Source', 'Stratification', 'Structure', 'Surveys', 'Testing', 'Text', 'Time', 'Universities', 'Validation', 'Variant', 'Visual', 'Visualization software', 'analytical tool', 'base', 'biobank', 'cancer epidemiology', 'cancer genetics', 'cancer genome', 'cancer prevention', 'cancer risk', 'cancer site', 'clinical Diagnosis', 'clinical biomarkers', 'cohort', 'data archive', 'data mining', 'data resource', 'data warehouse', 'disease phenotype', 'follow-up', 'genetic association', 'genetic risk factor', 'genome wide association study', 'genome-wide', 'genomic data', 'health record', 'improved', 'insight', 'multidisciplinary', 'neoplasm registry', 'neoplasm resource', 'novel', 'phenome', 'phenotypic biomarker', 'population based', 'recruit', 'repository', 'residence', 'response', 'statistics', 'symptom treatment', 'text searching', 'tool', 'trait', 'user-friendly', 'web interface', 'web page', 'whole genome']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,P30,2018,149955,-0.029916733669941274
"DAT- Implementing routine screening for cannabis and other drug use disorders in primary care: impact on diagnosis and treatment in a randomized pragmatic trial in 22 clinics PROJECT SUMMARY DAT18-06 The personal, social, and public health burdens of substance use disorders (SUDs) in the United States have been compounded by the opioid epidemic and legalization of recreational and medical cannabis use. Traditionally, healthcare systems have referred patients with SUDs to specialists. Although SUD treatment is associated with improved outcomes, most people with SUDs remain unidentified and untreated. The magnitude of unmet need has led experts to recommend incorporating screening and assessment for SUDs into routine primary care (PC), to increase rates of diagnosis and treatment of SUDs. Despite extensive observational research, to our knowledge no randomized controlled trial has evaluated the impact of PC-based programs of screening and assessment on new SUD treatment. The proposed study takes advantage of a unique and fortuitous opportunity to evaluate the impact of a PC program of screening and assessment for SUDs on new diagnosis and treatment of SUDs. The Sustained Patient-centered Alcohol Related Care (SPARC) trial, completed in July 2018, was a rigorously-designed randomized implementation trial testing a multifaceted approach to improving care for unhealthy alcohol use. However, at the request of clinical leaders at Kaiser Permanente Washington (KPWA) where the SPARC program was implemented, routine screening and assessment for opioid, cannabis, and other drug use disorders (CUD, OUD, and DUD, respectively) were added before the trial was launched in 22 KPWA PC clinics. As a result, the SPARC trial's implementation programconsisting of practice coaching, electronic health record (EHR) support, performance monitoring and feedback, and provider trainingalso targeted SUDs. Data from health system monitoring reports indicate the trial achieved high, sustained rates of screening for SUDs, exceeding the target of 80% of patients with PC visits. However, the SPARC trial was only funded to evaluate alcohol-related outcomes. The proposed study will rigorously evaluate the SPARC program's impact on the clinically meaningful primary outcome of new SUD treatment within 90 days of a primary care visit (Aim 1). To illuminate potential continued gaps in the quality of SUD care (Aim 2), we will use natural language processing (NLP) to extract and quantify reasons why: 1) patients reporting 4 DSM-5 symptoms of SUDs do not receive formal coded diagnoses of OUD, CUD, or DUD, and 2) why patients with newly diagnosed OUDs, CUDs, and DUDs do not received treatment. Most people with OUDs, CUDs, and other DUDs are never treated. An estimated 2.5-3.9% of US adults have past-year SUDs, and nearly 90% report no SUD treatment. Yet >84% of US adults have outpatient visits annually, and over half of these visits are in PC. If the proposed innovative study demonstrates that screening and assessment in PC increase SUD treatment, it would provide support for a widely endorsed yet previously untested approach to addressing a critically important gap in the quality of care for SUDs. PROJECT NARRATIVE Drug use disorders associated with unhealthy opioid, cannabis, and other drug use are major public health concerns but most people with these disorders remain untreated. Experts recommend systematic screening and assessment in primary care as a way to improve SUD treatment, but the effectiveness of such programs is unknown. This study rigorously evaluates such a program through an opportunity created when screening and assessment for drug use disorders were unexpectedly added to a randomized, stepped wedge, 22-clinic trial originally planned to focus exclusively on alcohol use disorders.",DAT- Implementing routine screening for cannabis and other drug use disorders in primary care: impact on diagnosis and treatment in a randomized pragmatic trial in 22 clinics,9884229,R01DA047312,"['Address', 'Adult', 'Alcohols', 'Cannabis', 'Caring', 'Cessation of life', 'Clinic', 'Clinical', 'Code', 'DSM-IV', 'DSM-V', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Drug Screening', 'Drug Use Disorder', 'Drug usage', 'Effectiveness', 'Electronic Health Record', 'Feedback', 'Funding', 'Health system', 'Healthcare Systems', 'Individual', 'Institute of Medicine (U.S.)', 'International Classification of Disease Codes', 'Knowledge', 'Legal', 'Medical', 'Medical Marijuana', 'Methods', 'Monitor', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Opioid', 'Outcome', 'Outpatients', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Preventive screening', 'Primary Health Care', 'Provider', 'Public Health', 'Quality of Care', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Reporting', 'Risk', 'Shame', 'Site', 'Specialist', 'Substance Use Disorder', 'Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment outcome', 'United States', 'Visit', 'Washington', 'addiction', 'alcohol misuse', 'alcohol use disorder', 'base', 'brief intervention', 'care providers', 'design', 'disability', 'health data', 'high risk', 'implementation strategy', 'implementation trial', 'improved', 'improved outcome', 'innovation', 'insurance claims', 'marijuana use', 'neglect', 'opioid epidemic', 'opioid use', 'patient oriented', 'pragmatic trial', 'primary outcome', 'programs', 'routine screening', 'screening', 'screening guidelines', 'screening program', 'social', 'social stigma', 'therapy design']",NIDA,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2020,323000,-0.007265612189959831
"Investigating the documentation of E-cigarette use in the VA EHR PROJECT SUMMARY Electronic cigarettes were developed in China in the early 2000s and first introduced to the US market in 2007. Once established in the US, the product experienced explosive growth, with the number of electronic cigarette users doubling every year between 2008 and 2012. In 2012, it was estimated that 75% of US adults had heard of electronic cigarettes, and 8% had tried them. While electronic cigarettes have been studied over the last sev- eral years, no scientific consensus has emerged regarding either the safety of electronic cigarettes, or their po- tential as a smoking cessation aid. With this proposal, we will investigate how electronic cigarette use is documented in the Veterans Association Electronic Health Record, focusing specifically on the relationship between electronic cigarette use and com- bustible tobacco use, with the goal of understanding both how electronic cigarette use is documented in the context of the United States only nationwide health system, and how electronic cigarette related information can be reliably extracted from narrative clinical text using fully automated Natural Language Processing meth- ods. PROJECT NARRATIVE The proposed research focuses on the use of Natural Language Processing methods to automatically extract mentions of electronic cigarette use from the Veterans Association Electronic Health Record. The research will provide insight into important, currently unresolved questions regarding how clinicians record electronic cigarette use in the context of a nationwide health system, and whether patients report the use of electronic cigarettes as a smoking cessation aid or use the devices in conjunction with combustible tobacco.",Investigating the documentation of E-cigarette use in the VA EHR,9852435,R03DA047577,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'China', 'Cities', 'Clinical', 'Consensus', 'Dangerousness', 'Data', 'Data Set', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Environment', 'Epidemiology', 'Evaluation', 'Geography', 'Goals', 'Government', 'Growth', 'Health', 'Health system', 'Healthcare Systems', 'Hearing', 'Individual', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Professional Organizations', 'Public Health', 'Public Health Applications Research', 'Reporting', 'Research', 'Risk', 'Safety', 'Scheme', 'Smoking', 'Sodium Chloride', 'Source', 'Technology', 'Text', 'Tobacco', 'Tobacco use', 'United States', 'Universities', 'Utah', 'Variant', 'Veterans', 'Work', 'authority', 'electronic cigarette use', 'electronic cigarette user', 'electronic hookah', 'evidence base', 'experience', 'information model', 'innovation', 'insight', 'smoking cessation', 'structured data', 'success', 'systems research', 'tobacco control', 'tool', 'vape pens']",NIDA,UNIVERSITY OF UTAH,R03,2020,76250,0.0838836772672231
"Investigating the documentation of E-cigarette use in the VA EHR PROJECT SUMMARY Electronic cigarettes were developed in China in the early 2000s and first introduced to the US market in 2007. Once established in the US, the product experienced explosive growth, with the number of electronic cigarette users doubling every year between 2008 and 2012. In 2012, it was estimated that 75% of US adults had heard of electronic cigarettes, and 8% had tried them. While electronic cigarettes have been studied over the last sev- eral years, no scientific consensus has emerged regarding either the safety of electronic cigarettes, or their po- tential as a smoking cessation aid. With this proposal, we will investigate how electronic cigarette use is documented in the Veterans Association Electronic Health Record, focusing specifically on the relationship between electronic cigarette use and com- bustible tobacco use, with the goal of understanding both how electronic cigarette use is documented in the context of the United States only nationwide health system, and how electronic cigarette related information can be reliably extracted from narrative clinical text using fully automated Natural Language Processing meth- ods. PROJECT NARRATIVE The proposed research focuses on the use of Natural Language Processing methods to automatically extract mentions of electronic cigarette use from the Veterans Association Electronic Health Record. The research will provide insight into important, currently unresolved questions regarding how clinicians record electronic cigarette use in the context of a nationwide health system, and whether patients report the use of electronic cigarettes as a smoking cessation aid or use the devices in conjunction with combustible tobacco.",Investigating the documentation of E-cigarette use in the VA EHR,9652537,R03DA047577,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'China', 'Cities', 'Clinical', 'Consensus', 'Dangerousness', 'Data', 'Data Set', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Environment', 'Epidemiology', 'Evaluation', 'Geography', 'Goals', 'Government', 'Growth', 'Health', 'Health system', 'Healthcare Systems', 'Hearing', 'Individual', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Professional Organizations', 'Public Health', 'Public Health Applications Research', 'Reporting', 'Research', 'Risk', 'Safety', 'Scheme', 'Smoking', 'Sodium Chloride', 'Source', 'Structure', 'Technology', 'Text', 'Tobacco', 'Tobacco use', 'Tweens', 'United States', 'Universities', 'Utah', 'Variant', 'Veterans', 'Work', 'authority', 'electronic cigarette use', 'electronic cigarette user', 'electronic hookah', 'evidence base', 'experience', 'information model', 'innovation', 'insight', 'men', 'smoking cessation', 'success', 'systems research', 'tobacco control', 'tool', 'vaping']",NIDA,UNIVERSITY OF UTAH,R03,2019,76250,0.0838836772672231
"Online Evidence of Withdrawal Self-Medication PROJECT SUMMARY/ABSTRACT Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with remedies that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing (NLP) and human expertise to examine over 50,000 recent posts in two Reddit forums OpiatesRecovery and Opiates to assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation. We will create a curated database of user-reported remedies. Information will be semiautomatically extracted from the online, self-reported use of alternative treatments (i.e., other prescription drugs, over the counter medications, food supplements, activities such as meditation and yoga). A team of a pharmacologist, physician, and ethnographer will evaluate database entries to uncover (1) potential harm associated with uncontrolled and unsupervised experimentation, (2) potentially effective available treatments (e.g., traditional medicine), (3) potentially promising compound leads, and (4) patients' needs and issues that are most important to them. Aim 1. To assemble an extensive database of opioid withdrawal and remedy-associated terminology from posts on OpiatesRecovery and Opiates Reddit communities. NLP will be used to build a language model that understands how words are used in context (word2vec). Aim 2. To develop a dataset of instances of self-reported remedy use from Reddit and conduct a bipartite network analysis of remedies and users. Using NLP tools and the word embedding model we will develop an exclusive dataset containing extracted information associated with remedies targeting withdrawal and craving. This aim will use elements of artificial intelligence and close human supervision to extract remedies, including variations of spelling, from the texts. The result of this aim will be a remedy database that includes spelling variations and slang references and a network analysis linking remedies and users. Aim 3. To organize, aggregate, and systematically assess information from mentions of remedy use. Potential compounds and other remedies will be classified to provide an initial assessment of their potential relevance to the opioid treatment process. This process will require the most human oversight and assessment. Network analysis tools will be used to assess and identify the relationships between the types of remedies and potential therapeutic effect and will create the benchmarks for similar future studies. PROJECT NARRATIVE Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with remedies that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing and human expertise to examine over 50,000 recent posts in two Reddit forums OpiatesRecovery and Opiatesto assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation.",Online Evidence of Withdrawal Self-Medication,9979829,R21DA048739,"['Acupuncture Therapy', 'Adult', 'Artificial Intelligence', 'Automation', 'Belief', 'Benchmarking', 'Categories', 'Cluster Analysis', 'Collaborations', 'Communities', 'Data', 'Data Set', 'Databases', 'Drug Prescriptions', 'Effectiveness', 'Elements', 'Epidemiologist', 'Epidemiology', 'Food', 'Food Additives', 'Food Supplements', 'Future', 'Habits', 'Harm Reduction', 'Herb', 'Herbal Medicine', 'Human', 'Information Retrieval', 'Knowledge', 'Language', 'Life', 'Link', 'Marijuana', 'Medical', 'Meditation', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Prescription Drugs', 'Opioid', 'Pathway Analysis', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Pilot Projects', 'Process', 'Published Comment', 'Relapse', 'Reporting', 'Research', 'Resources', 'Self Medication', 'Supervision', 'Terminology', 'Therapeutic Effect', 'Traditional Medicine', 'Twitter', 'United States Food and Drug Administration', 'Variant', 'Vitamins', 'Withdrawal', 'Withdrawal Symptom', 'Yoga', 'alternative treatment', 'cost', 'craving', 'dietary supplements', 'epidemiology study', 'experience', 'experimental study', 'interest', 'non-opioid analgesic', 'novel', 'off-label drug', 'off-label use', 'online community', 'opioid misuse', 'opioid use', 'opioid user', 'opioid withdrawal', 'patient population', 'self help', 'social media', 'spelling', 'tool', 'trend']",NIDA,RESEARCH TRIANGLE INSTITUTE,R21,2020,268226,0.03170562644663065
"Online Evidence of Withdrawal Self-Medication PROJECT SUMMARY/ABSTRACT Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with remedies that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing (NLP) and human expertise to examine over 50,000 recent posts in two Reddit forums OpiatesRecovery and Opiates to assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation. We will create a curated database of user-reported remedies. Information will be semiautomatically extracted from the online, self-reported use of alternative treatments (i.e., other prescription drugs, over the counter medications, food supplements, activities such as meditation and yoga). A team of a pharmacologist, physician, and ethnographer will evaluate database entries to uncover (1) potential harm associated with uncontrolled and unsupervised experimentation, (2) potentially effective available treatments (e.g., traditional medicine), (3) potentially promising compound leads, and (4) patients' needs and issues that are most important to them. Aim 1. To assemble an extensive database of opioid withdrawal and remedy-associated terminology from posts on OpiatesRecovery and Opiates Reddit communities. NLP will be used to build a language model that understands how words are used in context (word2vec). Aim 2. To develop a dataset of instances of self-reported remedy use from Reddit and conduct a bipartite network analysis of remedies and users. Using NLP tools and the word embedding model we will develop an exclusive dataset containing extracted information associated with remedies targeting withdrawal and craving. This aim will use elements of artificial intelligence and close human supervision to extract remedies, including variations of spelling, from the texts. The result of this aim will be a remedy database that includes spelling variations and slang references and a network analysis linking remedies and users. Aim 3. To organize, aggregate, and systematically assess information from mentions of remedy use. Potential compounds and other remedies will be classified to provide an initial assessment of their potential relevance to the opioid treatment process. This process will require the most human oversight and assessment. Network analysis tools will be used to assess and identify the relationships between the types of remedies and potential therapeutic effect and will create the benchmarks for similar future studies. PROJECT NARRATIVE Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with remedies that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing and human expertise to examine over 50,000 recent posts in two Reddit forums OpiatesRecovery and Opiatesto assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation.",Online Evidence of Withdrawal Self-Medication,9786868,R21DA048739,"['Acupuncture Therapy', 'Adult', 'Artificial Intelligence', 'Automation', 'Belief', 'Benchmarking', 'Categories', 'Cluster Analysis', 'Collaborations', 'Communities', 'Data', 'Data Set', 'Databases', 'Drug Prescriptions', 'Effectiveness', 'Elements', 'Epidemiologist', 'Epidemiology', 'Food', 'Food Additives', 'Food Supplements', 'Future', 'Habits', 'Harm Reduction', 'Herb', 'Herbal Medicine', 'Human', 'Knowledge', 'Language', 'Life', 'Link', 'Marijuana', 'Medical', 'Meditation', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Prescription Drugs', 'Opioid', 'Opioid user', 'Pathway Analysis', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Pilot Projects', 'Process', 'Published Comment', 'Relapse', 'Reporting', 'Research', 'Resources', 'Self Medication', 'Supervision', 'Terminology', 'Text', 'Therapeutic Effect', 'Traditional Medicine', 'Twitter', 'United States Food and Drug Administration', 'Variant', 'Vitamins', 'Withdrawal', 'Withdrawal Symptom', 'Yoga', 'alternative treatment', 'cost', 'craving', 'dietary supplements', 'epidemiology study', 'experience', 'experimental study', 'interest', 'non-opioid analgesic', 'novel', 'off-label drug', 'off-label use', 'online community', 'opioid misuse', 'opioid use', 'opioid withdrawal', 'patient population', 'self help', 'social media', 'spelling', 'tool', 'trend']",NIDA,RESEARCH TRIANGLE INSTITUTE,R21,2019,228384,0.03170562644663065
"Great Lakes Node of the Drug Abuse Clinical Trials Network PROJECT SUMMARY  Individuals with substance use disorders are disproportionately experiencing homelessness, poverty, and chronic medical conditions (diabetes and hypertension), which are emerging risk factors for contracting SARS-CoV-2 (official name for the virus that causes COVID-19). Different types of substance use have been associated with development of respiratory infections and progression to severe respiratory failure, also known as Acute Respiratory Distress Syndrome (ARDS). However, complex syndromes like ARDS and behavioral conditions like substance misuse are difficult to identify from the electronic health record. Clinical notes and radiology reports provide a rich source of information that may be used to identify cases of substance misuse and ARDS. This information is routinely recorded during hospital care, and automated, data-driven solutions with natural language processing (NLP) can extract semantics and important risk factors from the unstructured data of clinical notes. The computational methods of NLP derive meaning from clinical notes, from which machine learning can predict risk factors for patients leaving AMA or progressing to respiratory failure. Our team developed tools with >80% sensitivity/specificity to identify individual types of substance misuse using NLP with machine learning (ML). Our single-center models delineated risk factors embedded in the notes (e.g., mental health conditions, socioeconomic indicators). Further, we have developed and externally validated a machine learning tool to identify cases of ARDS with high accuracy for early treatment. We aim to expand this work by pooling data across health systems and build a generalizable and comprehensive classifier that captures multiple types of substance misuse for use in risk stratification and prognostication during the COVID pandemic.  We hypothesize that a single-model NLP substance misuse classifier will provide a standardized, interoperable, and accurate approach for universal analysis of hospitalized patients, and that such information can be used to identify those at risk for disrupted care and those at risk for respiratory failure. We aim to train and test our substance misuse classifiers at Rush in a retrospective dataset of over 60,000 hospitalizations that have been manually screened with the universal screen, AUDIT, and DAST. This Administrative Supplement will allow us to examine the correlations between substances of misuse and risk for COVID-19 as well as development of Acute Respiratory Distress Syndrome (ARDS) in the context of these phenomena. PROJECT NARRATIVE We anticipate that the research proposed will provide novel and critically important tools in artificial intelligence for the detection of substance misuse and COVID-19 from the electronic health record (EHR). Development and validation of a digital classifier would enable a standardized approach to perform screening on all patient encounters on a daily basis in health systems. We will rigorously develop and test the classifier retrospectively on an existing dataset of 60,000 patients. This will serve as the first step towards a comprehensive universal screener that leverages available data in the EHR.",Great Lakes Node of the Drug Abuse Clinical Trials Network,10173503,UG1DA049467,"['2019-nCoV', 'Accident and Emergency department', 'Administrative Supplement', 'Adult', 'Adult Respiratory Distress Syndrome', 'Affect', 'Alcohol or Other Drugs use', 'Artificial Intelligence', 'Behavioral', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Chronic', 'Cities', 'Clinical', 'Clinical Data', 'Clinical Trials Network', 'Communities', 'Complex', 'Computing Methodologies', 'Consumption', 'Contracts', 'Data', 'Data Pooling', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Disasters', 'Drug abuse', 'Drug usage', 'Early treatment', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Equipment', 'Felis catus', 'General Population', 'Health', 'Health Services', 'Health Status', 'Health system', 'Heart Diseases', 'Home environment', 'Homelessness', 'Hospitalization', 'Hospitals', 'Hurricane', 'Hypertension', 'Illicit Drugs', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Medical', 'Mental Health', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Outcome', 'Overdose', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Poverty', 'Prevention', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resources', 'Respiratory Failure', 'Respiratory Tract Infections', 'Risk', 'Risk Factors', 'Risk stratification', 'Semantics', 'Sensitivity and Specificity', 'Social support', 'Source', 'Standardization', 'Sterility', 'Substance Use Disorder', 'Syndrome', 'Testing', 'Training', 'Treatment outcome', 'Triage', 'Validation', 'Virus', 'Visit', 'Vulnerable Populations', 'Withdrawal', 'Work', 'behavioral health', 'cohort', 'comorbidity', 'coronavirus disease', 'digital', 'drug market', 'experience', 'high risk', 'improved', 'individual patient', 'interoperability', 'machine learning method', 'marijuana use', 'mortality risk', 'non-opioid analgesic', 'novel', 'opioid misuse', 'overdose death', 'pandemic disease', 'predictive modeling', 'prognostic', 'screening', 'social', 'social exclusion', 'social stigma', 'socioeconomics', 'substance misuse', 'success', 'tool', 'transmission process', 'unstructured data']",NIDA,RUSH UNIVERSITY MEDICAL CENTER,UG1,2020,139752,0.023387757141618185
"Understanding the role of community determinants in opioid use disorder and program implementation factors influencing patient adherence to opioid agonist therapy PROJECT SUMMARY/ABSTRACT  To inform an effective response to the opioid epidemic, understanding the multilevel factors that influence risk of opioid use disorder (OUD) is critical. In addition, although the efficacy of medication-assisted treatment (MAT) for OUD is proven, long-term retention in treatment has been a challenge. Thus, efforts are needed to identify program implementation factors that can be strengthened to improve OUD treatment outcomes. The K01 Award will provide the candidate the requisite skills and mentored research experience necessary to meet her long-term goal of conducting independent, innovative research on OUD and its treatment that can guide strategic investment to prevent OUD and inform implementation of MAT programs to increase patient adherence. This proposal comprises a 5-year plan that includes mentorship by Wade Berrettini, MD, PhD, Brian Schwartz, MD, MS, H. Lester Kirchner, PhD, MS, Danielle Mowery, PhD, MS, and Alanna Kulchak Rahm, PhD, MS; didactic training activities to meet the candidate's training goals; and conduct of a two-phase research project that will provide the candidate with substantive experience leading epidemiologic research using electronic health record (EHR) data and in implementation science. The proposed research will be conducted at Geisinger, an integrated healthcare system serving a large geographically diverse region of Pennsylvania, leveraging its research assetsincluding a wealth of health-related EHR data and linked genetic dataand the ability to integrate research into the clinical environment. The aims of the research are twofold. Aim 1 centers on the social determinants that engender vulnerability to OUD, evaluating associations of community contextual factors related to socioeconomic, social, and physical conditions with OUD, and the role individual-level genetic risk factors, healthcare factors, and comorbid medical conditions play in these relations. Aim 1 will utilize EHR and genetic data from Geisinger patients (n = 18,728) coupled with secondary data characterizing community factors to conduct a nested case-control study. Aim 2 seeks to understand program implementation factors that impact patient adherence to MAT for OUD. Aim 2 is a mixed methods study that will involve interviews with key informants (n  30) to identify multilevel barriers and facilitators influencing MAT success, followed by a survey of adult patients (n = 500) in Geisinger's MAT clinics to quantify factors influencing MAT adherence from a patient perspective. Completion of this research will fulfill the candidate's short-term goals by providing training in: (1) OUD, its treatment, and substance use disorder research; (2) natural language processing; (3) measurement of contextual factors; (4) statistical analysis including multilevel modeling and mediation analysis; (5) gene-environment interaction research; and (6) implementation science. The proposed research will generate evidence to understand novel, understudied risk factors for OUD, with implications for investment in community-level prevention interventions, and how health systems can improve treatment retention among individuals with OUD. PROJECT NARRATIVE  The proposed research will elucidate how community contextual factors related to economic, social, and physical conditions work in conjunction with individual-level genetic risk factors, healthcare factors, and comorbid medical conditions in generating or mitigating risk for opioid use disorder. It will also identify program implementation factors at the individual, interpersonal, and organizational levels that influence adherence to medication-assisted treatment among patients with opioid use disorder. The research results will inform investment in preventive interventions where community conditions may increase risk for opioid use disorder as well as how health systems can increase retention in treatment programs for opioid use disorder.",Understanding the role of community determinants in opioid use disorder and program implementation factors influencing patient adherence to opioid agonist therapy,10054517,K01DA049903,"['Abate', 'Adherence', 'Administrator', 'Adult', 'Buprenorphine', 'Characteristics', 'Chronic', 'Clinic', 'Clinical', 'Communities', 'County', 'Coupled', 'Data', 'Death Rate', 'Doctor of Philosophy', 'Dropout', 'Economics', 'Electronic Health Record', 'Environment', 'Epidemiologist', 'Genetic', 'Genetic Risk', 'Genotype', 'Geography', 'Goals', 'Grant', 'Health', 'Health Status', 'Health system', 'Healthcare', 'Individual', 'Integrated Health Care Systems', 'Interview', 'Investments', 'Knowledge acquisition', 'Link', 'Measurement', 'Mediating', 'Mediation', 'Medical', 'Medicine', 'Mental disorders', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Nested Case-Control Study', 'Opioid', 'Outpatients', 'Overdose', 'PF4 Gene', 'Patients', 'Pattern', 'Pennsylvania', 'Pharmacogenetics', 'Pharmacotherapy', 'Phase', 'Play', 'Preventive Intervention', 'Program Effectiveness', 'Qualitative Research', 'Relapse', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'Risk Factors', 'Role', 'Statistical Data Interpretation', 'Substance Use Disorder', 'Surveys', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'base', 'biobank', 'buprenorphine treatment', 'case control', 'community intervention', 'comorbidity', 'compliance behavior', 'contextual factors', 'deprivation', 'design', 'disorder risk', 'epidemiology study', 'exome sequencing', 'experience', 'gene environment interaction', 'genetic risk factor', 'health data', 'illicit opioid', 'implementation science', 'improved', 'informant', 'innovation', 'medication-assisted treatment', 'mortality', 'multilevel analysis', 'novel', 'opioid agonist therapy', 'opioid epidemic', 'opioid mortality', 'opioid overdose', 'opioid treatment program', 'opioid use', 'opioid use disorder', 'overdose death', 'prevent', 'programs', 'response', 'rural counties', 'scale up', 'skills', 'social', 'social cohesion', 'social determinants', 'social health determinants', 'socioeconomics', 'success', 'treatment adherence', 'treatment program']",NIDA,GEISINGER CLINIC,K01,2020,162032,0.03205243585776088
"Technology Improving Success of Medication-Assisted Treatment in Primary Care Project Abstract The opioid epidemic is the U.S.'s most widespread behavioral public health problem, with a higher number of deaths due to drug overdose in 2016 compared to deaths due to HIV at the peak of the AIDS epidemic. Medication assisted treatment (MAT) for opioid use disorder (OUD) is highly efficacious. However, only a fraction of persons with OUD access MAT, and treatment non-adherence and drop out is common. There is a dire need to improve systems to address these issues and to expand the use of MAT for many patients who are out of care. This R44 STTR application responds to RFA-DA-19-020, HEAL Initiative: America's Startups and Small Businesses Build Technologies to Stop the Opioid Crisis. It joins an outstanding scientific team at UCLA and a small business that has developed, Opioid Addiction Recovery Support (OARS) -- a software platform that by integrating with the Electronic Health Record (EHR) improves clinical management of patients by primary care providers (PCPs) treating patients with OUD using MAT. OARS platform uses a dashboard to show real-time measurement of patient achievements in recovery. It provides opportunities for patients to interact with their PCPs, allowing for better connection to and support from their PCPs. OARS platform features artificial intelligence to analyze information from the EHR and from patients to provide relapse risk assessment for patients receiving MAT for OUD, an innovation that sets OARS apart from other software solutions. The specific aim of Phase 1 of this STTR Fast Track proposal, is to modify the OARS platform for use in primary care settings by conducting interviews with PCPs (N=20) and their patients with OUD (N=40) in primary care settings to collect data on feasibility and acceptability of engaging with OARS to inform user- centered design of OARS. The specific aims of Phase 2 of this STTR Fast Track proposal are to: (1) employ a stepped wedge design to assess the effectiveness of OARS in improving opioid agonist treatment outcomes across 6 treatment programs (N=200 treated patients) and (2) evaluate sustainability and return on investment of OARS implementation across 6 treatment programs. A commercialization plan documents progress to date for OARS platform and presents a market plan to improve both scale-up and quality of MAT services delivered by PCPs in primary care, which is a major contribution to addressing the ongoing opioid epidemic. Project Narrative With over 72,000 overdose deaths in 2017, of which 47,600 are attributable to opioid overdose, the opioid epidemic has become North Americas most widespread behavioral public health problem. Medication assisted treatment (MAT) for opioid use disorder (OUD) is highly efficacious. The Opioid Addiction Recovery Support (OARS), comprises of a healthcare team portal connected to a patient mobile application, to provide opioid related education, promote connectedness with clinicians, and track MAT treatment progress. This STTR Fast Track proposal will conduct interviews with patients that will inform optimal design of OARS and utilize a stepped wedge effectiveness design to assess the effectiveness of OARS in improving opioid agonist treatment outcomes in primary care settings and evaluate sustainability and return on investment.",Technology Improving Success of Medication-Assisted Treatment in Primary Care,10212519,R42DA050398,"['Abstinence', 'Achievement', 'Acquired Immunodeficiency Syndrome', 'Address', 'Adherence', 'Americas', 'Area', 'Artificial Intelligence', 'Behavioral', 'Belief', 'Businesses', 'Caring', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Management', 'Computer software', 'Continuity of Patient Care', 'Cost Savings', 'Custom', 'Data', 'Development', 'Dropout', 'Drops', 'Education', 'Effectiveness', 'Electronic Health Record', 'Epidemic', 'HIV', 'Interview', 'Investments', 'Length', 'Link', 'Machine Learning', 'Medical Care Team', 'Medicine', 'Methods', 'North America', 'Opiate Addiction', 'Opioid', 'Outcome', 'Outpatients', 'Overdose', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Primary Health Care', 'Provider', 'Public Health', 'Recovery', 'Relapse', 'Risk', 'Risk Assessment', 'Scientist', 'Services', 'Small Business Technology Transfer Research', 'Specialist', 'Suboxone', 'System', 'Technology', 'Testing', 'Treatment outcome', 'United States', 'Visit', 'Work', 'addiction', 'care providers', 'commercialization', 'cost', 'dashboard', 'design', 'empowered', 'experience', 'follow-up', 'implementation science', 'improved', 'indexing', 'innovation', 'insight', 'iterative design', 'medical specialties', 'medication-assisted treatment', 'mobile application', 'opioid agonist therapy', 'opioid epidemic', 'opioid overdose', 'opioid use', 'opioid use disorder', 'overdose death', 'patient population', 'phase 2 testing', 'primary care setting', 'programs', 'recruit', 'relapse risk', 'scale up', 'social stigma', 'success', 'temporal measurement', 'tool', 'treatment comparison', 'treatment program', 'treatment services', 'user centered design', 'waiver']",NIDA,"Q2I, LLC",R42,2020,4488,0.00802104583843413
"Technology Improving Success of Medication-Assisted Treatment in Primary Care Project Abstract The opioid epidemic is the U.S.'s most widespread behavioral public health problem, with a higher number of deaths due to drug overdose in 2016 compared to deaths due to HIV at the peak of the AIDS epidemic. Medication assisted treatment (MAT) for opioid use disorder (OUD) is highly efficacious. However, only a fraction of persons with OUD access MAT, and treatment non-adherence and drop out is common. There is a dire need to improve systems to address these issues and to expand the use of MAT for many patients who are out of care. This R44 STTR application responds to RFA-DA-19-020, HEAL Initiative: America's Startups and Small Businesses Build Technologies to Stop the Opioid Crisis. It joins an outstanding scientific team at UCLA and a small business that has developed, Opioid Addiction Recovery Support (OARS) -- a software platform that by integrating with the Electronic Health Record (EHR) improves clinical management of patients by primary care providers (PCPs) treating patients with OUD using MAT. OARS platform uses a dashboard to show real-time measurement of patient achievements in recovery. It provides opportunities for patients to interact with their PCPs, allowing for better connection to and support from their PCPs. OARS platform features artificial intelligence to analyze information from the EHR and from patients to provide relapse risk assessment for patients receiving MAT for OUD, an innovation that sets OARS apart from other software solutions. The specific aim of Phase 1 of this STTR Fast Track proposal, is to modify the OARS platform for use in primary care settings by conducting interviews with PCPs (N=20) and their patients with OUD (N=40) in primary care settings to collect data on feasibility and acceptability of engaging with OARS to inform user- centered design of OARS. The specific aims of Phase 2 of this STTR Fast Track proposal are to: (1) employ a stepped wedge design to assess the effectiveness of OARS in improving opioid agonist treatment outcomes across 6 treatment programs (N=200 treated patients) and (2) evaluate sustainability and return on investment of OARS implementation across 6 treatment programs. A commercialization plan documents progress to date for OARS platform and presents a market plan to improve both scale-up and quality of MAT services delivered by PCPs in primary care, which is a major contribution to addressing the ongoing opioid epidemic. ! Project Narrative With over 72,000 overdose deaths in 2017, of which 47,600 are attributable to opioid overdose, the opioid epidemic has become North Americas most widespread behavioral public health problem. Medication assisted treatment (MAT) for opioid use disorder (OUD) is highly efficacious. The Opioid Addiction Recovery Support (OARS), comprises of a healthcare team portal connected to a patient mobile application, to provide opioid related education, promote connectedness with clinicians, and track MAT treatment progress. This STTR Fast Track proposal will conduct interviews with patients that will inform optimal design of OARS and utilize a stepped wedge effectiveness design to assess the effectiveness of OARS in improving opioid agonist treatment outcomes in primary care settings and evaluate sustainability and return on investment.",Technology Improving Success of Medication-Assisted Treatment in Primary Care,9912034,R42DA050398,"['Abstinence', 'Achievement', 'Acquired Immunodeficiency Syndrome', 'Address', 'Adherence', 'Americas', 'Area', 'Artificial Intelligence', 'Behavioral', 'Belief', 'Businesses', 'Caring', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Management', 'Computer software', 'Continuity of Patient Care', 'Cost Savings', 'Custom', 'Data', 'Development', 'Dropout', 'Drops', 'Education', 'Effectiveness', 'Electronic Health Record', 'Epidemic', 'HIV', 'Interview', 'Investments', 'Length', 'Link', 'Machine Learning', 'Medical Care Team', 'Medicine', 'Methods', 'North America', 'Opiate Addiction', 'Opioid', 'Outcome', 'Outpatients', 'Overdose', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Primary Health Care', 'Provider', 'Public Health', 'Recovery', 'Relapse', 'Risk', 'Risk Assessment', 'Scientist', 'Services', 'Small Business Technology Transfer Research', 'Specialist', 'Suboxone', 'System', 'Technology', 'Testing', 'Treatment outcome', 'United States', 'Visit', 'Work', 'addiction', 'care providers', 'commercialization', 'cost', 'dashboard', 'design', 'empowered', 'experience', 'follow-up', 'implementation science', 'improved', 'indexing', 'innovation', 'insight', 'iterative design', 'medical specialties', 'medication-assisted treatment', 'mobile application', 'opioid agonist therapy', 'opioid epidemic', 'opioid overdose', 'opioid use', 'opioid use disorder', 'overdose death', 'patient population', 'phase 2 testing', 'primary care setting', 'programs', 'recruit', 'relapse risk', 'scale up', 'social stigma', 'success', 'temporal measurement', 'tool', 'treatment program', 'treatment services', 'user centered design', 'waiver']",NIDA,"Q2I, LLC",R42,2019,225000,0.00802104583843413
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6375859,P01CA051198,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2001,2071652,0.00881989642103082
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6094628,P01CA051198,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2000,1926078,0.00881989642103082
"Data Driven Strategies for Substance Misuse Identification in Hospitalized Patients PROJECT SUMMARY  The rate of substance use-related hospital visits in the US continues to increase, and now outpaces visits for heart disease and respiratory failure. The prevalence of substance misuse (nonmedical use of opioids and/or benzodiazepines, illicit drugs, and/or alcohol) in hospitalized patients is estimated to be 15%-25% and far exceeds the prevalence in the general population. With over 35 million hospitalized patients per year, tens of millions of patients are not screened for substance misuse during their stay. Despite the recommendation for self-report questionnaires (single-question universal screens, Alcohol Use Disorders Identification Test [AUDIT], Drug Abuse Screening Tool [DAST]), screening rates remains low in hospitals. Current screening methods are resource-intensive, so a comprehensive and automated approach to substance misuse screening that will augment current clinical workflow would therefore be of great utility.  In the advent of Meaningful Use in the electronic health record (EHR), efficiency for substance misuse detection may be improved by leveraging data collected during usual care. Documentation of substance use is common and occurs in 97% of provider admission notes, but their free text format renders them difficult to mine and analyze. Natural Language Processing (NLP) and machine learning are subfields of artificial intelligence (AI) that provide a solution to analyze text data in the EHR to identify substance misuse. Modern NLP has fused with machine learning, another sub-field of AI focused on learning from data. In particular, the most powerful NLP methods rely on supervised learning, a type of machine learning that takes advantage of current reference standards to make predictions about unseen cases  In our earlier version of an NLP and machine learning tool, our opioid and alcohol misuse classifiers successfully used data from clinical notes collected in the first 24 hours of hospital admission to reach a sensitivity and specificity above 75% for detecting alcohol or opioid misuse. We will improve the performance of our baseline, individual NLP single-substance classifiers for alcohol and opioid misuse by implementing multi-label and multi-task machine learning methods. These methods will take advantage of information shared across different types of substance misuse and better capture the state of a patient within a single model. The resulting classifier will be capable of jointly inferring all types of substance misuse (alcohol misuse, opioid misuse, and non-opioid illicit misuse) including polysubstance use, and cater to each individual patients substance use treatment needs.  We aim to train and test our substance misuse classifiers at Rush in a retrospective dataset of over 35,000 hospitalizations that have been manually screened with the universal screen, AUDIT, and DAST. The top performing classifier will then be tested prospectively to: (1) externally validate its screening performance in a hospital without established screening; and (2) test its effectiveness against usual care at a hospital with questionnaire-based substance misuse screening. We hypothesize that a single-model NLP substance misuse classifier will provide a standardized, interoperable, and accurate approach for universal screening in hospitalized patients and guiding interventions. PROJECT NARRATIVE We anticipate that the research proposed will provide novel and critically important tools in artificial intelligence for the detection of substance misuse from the electronic health record (EHR). Development and validation of the substance misuse classifier would enable a standardized approach to perform screening on all patient encounters on a daily basis in health systems. We will rigorously develop and test substance misuse classifier retrospectively and then examine its performance prospectively in both a nave and mature screening program. This will serve as the first step towards a comprehensive universal screener that leverages available data in the EHR.",Data Driven Strategies for Substance Misuse Identification in Hospitalized Patients,10026785,R01DA051464,"['Admission activity', 'Adopted', 'Adult', 'Alcohol or Other Drugs use', 'Alcohols', 'Artificial Intelligence', 'Benzodiazepines', 'Caring', 'Clinical', 'Clinical Data', 'Computing Methodologies', 'Consult', 'Costs and Benefits', 'Data', 'Data Set', 'Detection', 'Development', 'Documentation', 'Effectiveness', 'Electronic Health Record', 'Felis catus', 'General Population', 'Goals', 'Health Care Sector', 'Health system', 'Heart Diseases', 'Hospitalization', 'Hospitals', 'Hour', 'Illicit Drugs', 'Individual', 'Inpatients', 'Intake', 'Interruption', 'Intervention', 'Interviewer', 'Label', 'Learning', 'Light', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Patient Self-Report', 'Patients', 'Performance', 'Prevalence', 'Primary Health Care', 'Provider', 'Publishing', 'Questionnaires', 'Recommendation', 'Reference Standards', 'Research', 'Resources', 'Respiratory Failure', 'Risk', 'Risk Factors', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Social Work', 'Source', 'Standardization', 'Substance Abuse Detection', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'Validation', 'Visit', 'addiction', 'alcohol misuse', 'alcohol use disorder', 'base', 'clinical decision support', 'cohort', 'comparison intervention', 'design', 'effectiveness evaluation', 'improved', 'individual patient', 'interoperability', 'machine learning method', 'multitask', 'non-opioid analgesic', 'novel', 'opioid misuse', 'prospective', 'prospective test', 'response', 'routine care', 'screening', 'screening program', 'substance misuse', 'supervised learning', 'support tools', 'tool', 'treatment as usual', 'trend', 'unstructured data']",NIDA,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,663889,-0.0033513366267254744
"SENTENCE PROCESSING IN JAPANESE AND ENGLISH The end goal of research in natural language processing is to provide a          psychologically plausible computational account of human language                processing. To this end, cross-linguistic investigation of sentence              processing can provide critically significant results which elucidate the        interaction between the grammars of particular languages and the                 mechanisms of human language processing system. In the proposed research,        one critical aspect of sentence processing, namely, how speakers of              Japanese and English deal with temporal ambiguities that are encountered         during on-line processing of a sentence.                                                                                                                          In particular, we ask how speakers of Japanese deal with a high degree of        indeterminacy early in the sentence. In order to investigate whether             Japanese speakers are engaged in extensive reanalyses en route to a              correct interpretation, five types of sentences are proposed to be               examined: sentences with relative clauses; sentences with stative verbs;         passive and causative sentences; sentences with verbs of giving and              receiving; and sentences with lexical homonymy. These sentences all              contain structures that might trigger reanalysis. Syntactic reanalysis of        grammatical relations as well as reanalysis of thematic role assignments         will be examined. The sentences will be tested by three psycholinguistic         experiments: eye-movement monitoring; self-paced reading methods; and on-        line grammaticality judgement task. Two questionnaires concerning peoples'       subjective judgments of conscious reanalysis and difficulty of the               sentence will also be conducted to supplement the experimental data.                                                                                              The results of the Japanese studies will then be contrasted to English           data (available in the literature) to ask whether the ways in which              Japanese speakers process temporal ambiguity are similar to that of              English speakers. Using these cross-linguistic results, we will address          the question of whether a single mechanism can account for the way               speakers of Japanese and English deal with temporal ambiguity, or                alternatively, whether their differences are better accounted for by             invoking two different parsing mechanisms.                                        n/a",SENTENCE PROCESSING IN JAPANESE AND ENGLISH,2675164,R29MH051655,"['Japanese', ' behavioral /social science research tag', ' differential semantics', ' eye movements', ' human subject', ' language', ' nonEnglish language', ' psycholinguistics', ' questionnaires']",NIMH,DUKE UNIVERSITY,R29,1998,118155,0.02288742780398318
"SENTENCE PROCESSING IN JAPANESE AND ENGLISH The end goal of research in natural language processing is to provide a          psychologically plausible computational account of human language                processing. To this end, cross-linguistic investigation of sentence              processing can provide critically significant results which elucidate the        interaction between the grammars of particular languages and the                 mechanisms of human language processing system. In the proposed research,        one critical aspect of sentence processing, namely, how speakers of              Japanese and English deal with temporal ambiguities that are encountered         during on-line processing of a sentence.                                                                                                                          In particular, we ask how speakers of Japanese deal with a high degree of        indeterminacy early in the sentence. In order to investigate whether             Japanese speakers are engaged in extensive reanalyses en route to a              correct interpretation, five types of sentences are proposed to be               examined: sentences with relative clauses; sentences with stative verbs;         passive and causative sentences; sentences with verbs of giving and              receiving; and sentences with lexical homonymy. These sentences all              contain structures that might trigger reanalysis. Syntactic reanalysis of        grammatical relations as well as reanalysis of thematic role assignments         will be examined. The sentences will be tested by three psycholinguistic         experiments: eye-movement monitoring; self-paced reading methods; and on-        line grammaticality judgement task. Two questionnaires concerning peoples'       subjective judgments of conscious reanalysis and difficulty of the               sentence will also be conducted to supplement the experimental data.                                                                                              The results of the Japanese studies will then be contrasted to English           data (available in the literature) to ask whether the ways in which              Japanese speakers process temporal ambiguity are similar to that of              English speakers. Using these cross-linguistic results, we will address          the question of whether a single mechanism can account for the way               speakers of Japanese and English deal with temporal ambiguity, or                alternatively, whether their differences are better accounted for by             invoking two different parsing mechanisms.                                        n/a",SENTENCE PROCESSING IN JAPANESE AND ENGLISH,2445534,R29MH051655,"['Japanese', ' behavioral /social science research tag', ' differential semantics', ' eye movements', ' human subject', ' language', ' nonEnglish language', ' psycholinguistics', ' questionnaires']",NIMH,DUKE UNIVERSITY,R29,1997,68208,0.02288742780398318
"Use Frailty Status to Predict Postoperative Outcomes in Elderly Patient Frailty is increasingly recognized as a leading indicator of poor health outcomes, even death, as well as a barometer of how well patients respond to treatment. To truly provide patient-centered care, providers should be aware of each patient's frailty status and incorporate it into clinical decision making. Providers can now offer a number of invasive and aggressive procedures for cardiovascular disease, which involve risk, and can be painful. The treatment intensity need to match the expected patient outcome, yet providers do not have a reliable method to estimate prognosis for frail patients. In the study proposed here, we will use a novel approach that leverages the electronic health record (EHR) in identifying patient frailty status, with the goal of supporting retrospective clinical studies and prospective clinical decision making. Our preliminary studies have demonstrated the availability of frailty-related findings in EHR, the feasibility of extracting frailty findings, and the feasibility of using EHR-extracted frailty for outcome prediction. The specific aims of the project are to 1) Create a frailty ontology building on existing functional status and quality of life measurements; 2) Develop ontology guided, natural language processing (NLP) methods for extracting frailty descriptions and measurements; 3) Develop a model to aggregate NLP-extracted frailty findings to generate a patient-level frailty score; 4) Examine the all-cause mortality and all-cause hospital readmission one year after major cardiac procedures in heart failure patients with different frailty scores and assess the impact of this information on surgical decision making. Frailty is an important, but often overlooked, determinant of health outcomes in older adults. Providers can now offer invasive and aggressive treatments for various conditions, but these interventions involve risk and careful patient selection that balances risk and benefit is imperative. We will develop automated methods to extract frailty information from clinical records and generate an aggregated frailty score, which will enable retrospective analyses of EHR data for risk prediction and support prospective clinical decisional making.",Use Frailty Status to Predict Postoperative Outcomes in Elderly Patient,9354376,R56AG052536,"['Address', 'Affect', 'American', 'Atrial Fibrillation', 'Benefits and Risks', 'Cardiac', 'Cardiac Surgery procedures', 'Cardiovascular Diseases', 'Caregivers', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collection', 'Comorbidity', 'Critical Care', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Devices', 'Dimensions', 'Disease', 'Documentation', 'Elderly', 'Electronic Health Record', 'Equilibrium', 'Fatigue', 'Goals', 'Health', 'Heart failure', 'Hospitalization', 'Implantable Defibrillators', 'Informatics', 'Intervention', 'Investigation', 'Life', 'Life Expectancy', 'Malnutrition', 'Measurement', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Modeling', 'Natural Language Processing', 'Ontology', 'Operative Surgical Procedures', 'Outcome', 'Pain', 'Patient Care', 'Patient Selection', 'Patient-Centered Care', 'Patient-Focused Outcomes', 'Patients', 'Perioperative', 'Population', 'Postoperative Period', 'Procedures', 'Provider', 'Quality of life', 'Records', 'Research Personnel', 'Risk', 'Technology', 'Veterans', 'base', 'clinical decision-making', 'cohort', 'comparative effectiveness', 'exercise capacity', 'frailty', 'functional status', 'hospital readmission', 'indexing', 'individualized medicine', 'interest', 'mortality', 'novel strategies', 'older patient', 'outcome forecast', 'outcome prediction', 'patient population', 'predictive modeling', 'prospective', 'treatment choice', 'treatment planning', 'trend']",NIA,GEORGE WASHINGTON UNIVERSITY,R56,2016,616197,0.007665296579373619
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (Bio-REP) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (Bio- REP) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,10208373,R33AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'data infrastructure', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R33,2020,792718,-0.014520699950653332
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (Bio-REP) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (Bio- REP) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,9749915,R21AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R21,2019,198750,-0.014520699950653332
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (Bio-REP) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (Bio- REP) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,9503117,R21AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R21,2018,238500,-0.014520699950653332
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,9873880,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'ROC Curve', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'acute care', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'large scale data', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2020,376860,0.025145557902951185
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,9637480,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'Receiver Operating Characteristics', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2019,432969,0.025145557902951185
"Safety Promotion through Early Event Detection in the Elderly (SPEEDe) ABSTRACT Adverse events (AEs)  harm to patients that results from medical care  affect as many as 13.5% of hospitalized patients; half of these AEs are preventable and AEs particularly affect the elderly. AEs are notoriously difficult to measure accurately. A variety of paper and electronic trigger tools have been developed to identify AEs; however, their positive predictive value (PPV) is low, requiting subsequent, time-intensive manual chart review to accurately measure AEs. In the proposed project, we will use innovative, state-of-the-art machine interactive learning (IML) techniques to refine existing AE triggers, improving their accuracy substantially. We will also develop a novel AE Explorer to speed review of possible AEs, as well as an innovative package of predictive analytics tools and methods to measure and detect them. Our approach combines and compares expert-driven improvement with the most recent IML techniques to make triggers more accurate, with the ultimate goal of creating triggers that are accurate enough to stand in as proxies for actual measurement of harm. We call our approach Safety Promotion through Early Event Detection in the Elderly, or SPEEDe. Our team of accomplished machine learning, patient safety, risk management, AE detection, geriatric medicine and trigger tool experts will work together to carry out the specific aims of this project: (1) prototype and rapidly iterate a trigger review dashboard (the Adverse Event Explorer) using a user-centered design process, (2) develop and evaluate novel Interactive Machine Learning approaches for more efficient and accurate adverse event chart review and trigger refinement, and (3) Integrate Interactive Machine Learning into the Adverse Event Explorer and evaluate it prospectively in a clinical setting. PROJECT NARRATIVE Adverse events  harm to patients that results from medical care  are common and difficult to identify and measure using existing tools. Accurate real-time measures of adverse events would enable organizations to track harm over time, identify and prioritize areas for safety improvements, evaluate whether patient safety programs are effective, and communicate risks of harm to patients and caregivers. Through SPEEDe, we will develop an innovative machine- learning approach for accurately detecting adverse events in the elderly in real-time.",Safety Promotion through Early Event Detection in the Elderly (SPEEDe),10093288,R01AG062499,"['Active Learning', 'Adopted', 'Adverse event', 'Affect', 'Area', 'Benchmarking', 'Caregivers', 'Caring', 'Cessation of life', 'Clinical', 'Computer software', 'Detection', 'Elderly', 'Environment', 'Event', 'Feedback', 'Foundations', 'Frequencies', 'Geriatrics', 'Goals', 'Gold', 'Grant', 'Hospitals', 'Human', 'Human Resources', 'Incentives', 'Intuition', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Memory', 'Minority', 'Modeling', 'Paper', 'Patients', 'Performance', 'Personal Satisfaction', 'Policies', 'Predictive Analytics', 'Predictive Value', 'Process', 'Proxy', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Management', 'Safety', 'Sampling', 'Screening procedure', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'Work', 'advanced analytics', 'analytical method', 'analytical tool', 'base', 'biomedical informatics', 'cost', 'dashboard', 'detector', 'forging', 'hands-on learning', 'health information technology', 'improved', 'innovation', 'iterative design', 'machine learning method', 'novel', 'open source', 'patient safety', 'prevent', 'programs', 'prospective', 'prototype', 'supervised learning', 'tool', 'user centered design']",NIA,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,705459,0.03315700081646017
"Safety Promotion through Early Event Detection in the Elderly (SPEEDe) ABSTRACT Adverse events (AEs)  harm to patients that results from medical care  affect as many as 13.5% of hospitalized patients; half of these AEs are preventable and AEs particularly affect the elderly. AEs are notoriously difficult to measure accurately. A variety of paper and electronic trigger tools have been developed to identify AEs; however, their positive predictive value (PPV) is low, requiting subsequent, time-intensive manual chart review to accurately measure AEs. In the proposed project, we will use innovative, state-of-the-art machine interactive learning (IML) techniques to refine existing AE triggers, improving their accuracy substantially. We will also develop a novel AE Explorer to speed review of possible AEs, as well as an innovative package of predictive analytics tools and methods to measure and detect them. Our approach combines and compares expert-driven improvement with the most recent IML techniques to make triggers more accurate, with the ultimate goal of creating triggers that are accurate enough to stand in as proxies for actual measurement of harm. We call our approach Safety Promotion through Early Event Detection in the Elderly, or SPEEDe. Our team of accomplished machine learning, patient safety, risk management, AE detection, geriatric medicine and trigger tool experts will work together to carry out the specific aims of this project: (1) prototype and rapidly iterate a trigger review dashboard (the Adverse Event Explorer) using a user-centered design process, (2) develop and evaluate novel Interactive Machine Learning approaches for more efficient and accurate adverse event chart review and trigger refinement, and (3) Integrate Interactive Machine Learning into the Adverse Event Explorer and evaluate it prospectively in a clinical setting. PROJECT NARRATIVE Adverse events  harm to patients that results from medical care  are common and difficult to identify and measure using existing tools. Accurate real-time measures of adverse events would enable organizations to track harm over time, identify and prioritize areas for safety improvements, evaluate whether patient safety programs are effective, and communicate risks of harm to patients and caregivers. Through SPEEDe, we will develop an innovative machine- learning approach for accurately detecting adverse events in the elderly in real-time.",Safety Promotion through Early Event Detection in the Elderly (SPEEDe),9711286,R01AG062499,"['Active Learning', 'Adopted', 'Adverse event', 'Affect', 'Area', 'Benchmarking', 'Caregivers', 'Caring', 'Cessation of life', 'Clinical', 'Computer software', 'Detection', 'Elderly', 'Environment', 'Event', 'Feedback', 'Foundations', 'Frequencies', 'Geriatrics', 'Goals', 'Gold', 'Grant', 'Hospitals', 'Human', 'Human Resources', 'Incentives', 'Intuition', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Memory', 'Minority', 'Modeling', 'Paper', 'Patients', 'Performance', 'Personal Satisfaction', 'Policies', 'Predictive Analytics', 'Predictive Value', 'Process', 'Proxy', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Management', 'Safety', 'Sampling', 'Screening procedure', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'Work', 'analytical method', 'analytical tool', 'base', 'biomedical informatics', 'cost', 'dashboard', 'detector', 'forging', 'hands-on learning', 'health information technology', 'improved', 'innovation', 'iterative design', 'learning strategy', 'novel', 'open source', 'patient safety', 'prevent', 'programs', 'prospective', 'prototype', 'supervised learning', 'tool', 'user centered design']",NIA,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,802341,0.03315700081646017
"EXEMPLAR-BASED MEDICAL TEXT CLASSIFICATION The goal of this research is to develop improved techniques, both fully          automated and computer-assisted, for classification of medical text.  The        technical approach is exemplar-based: robust information retrieval methods       find similar, previously-classified texts, and corresponding codes are           used to suggest likely classifications for a new text.  Phase I focused          upon implementing experimental software to establish baseline performance        with several variations of the exemplar-based approach.                                                                                                           Phase II builds upon this work to implement a complete Coder's Workstation       (CWS).  Based upon Phase I results and assessments of commercial                 opportunities, Phase II will focus upon shorter texts (<12 words), which         are best suited for automated methods.  A ""short-similarity"" capability          will be added to the Phase I approach to further enhance performance with        shorter texts.  To evaluate and refine the CWS, Phase II will include            extensive ""beta testing"" of the software at the Brigham and Women's              Hospital and the Mayo Clinic.                                                                                                                                     The major technical innovation of this project is the development of             highly automated classification software that is sensitive to term               similarities.  The major health-related contributions are large potential        savings in coding expenses, reduced time demands upon physicians for             coding, and improved consistency in classification of free text for              research studies.                                                                                                                                                 PROPOSED COMMERCIAL APPLICATION:  The proposed technology will have              important commercial application within hospitals, insurance companies,          and pharmaceutical companies which currently expend significant resources        on coding of free text (ICD9, CPT4, COSTART, etc.).  The founders of             Belmont Research Inc. have extensive experience in creating and marketing        software to support biomedical applications.                                      n/a",EXEMPLAR-BASED MEDICAL TEXT CLASSIFICATION,2429835,R44CA065250,"['artificial intelligence', ' computer program /software', ' computer system design /evaluation', ' disease /disorder classification', ' human data', ' information retrieval', ' medical records', ' vocabulary development for information system']",NCI,"BELMONT RESEARCH, INC.",R44,1997,387794,0.018912785699083324
"EXEMPLAR-BASED MEDICAL TEXT CLASSIFICATION The goal of this research is to develop improved techniques for fully automated and computer-assisted classification of medical text. A primary focus will be mechanisms that support easy-to-construct classifiers, thus enabling research on existing collections of free-text that are now difficult to analyze.  The proposed approach is exemplar-based: i.e., compare new text with a training set of previously classified texts, and use the classifications of the closest retrieved texts to generate suggested codes for the new text. Natural language extraction techniques will preprocess texts to assist the retrieval machinery.  Phase I will conduct a series of experiments to test the approach, utilizing coded radiology and pathology reports from Brigham and Women's Hospital and HCHP in Boston. Phase II will develop a full software prototype and deploy it for on-site evaluation. Advanced retrieval techniques and expert system back ends for alarming will also be explored in Phase II.  The major technical innovation is a novel combination of document retrieval and natural language extraction technologies to permit easy construction of automated medical text classifiers. The major health- related contribution is an enhanced ability to classify existing free-text records to permit statistical analysis for research and clinical quality- measurement initiatives.  n/a",EXEMPLAR-BASED MEDICAL TEXT CLASSIFICATION,2108095,R43CA065250,"['artificial intelligence', ' computer system design /evaluation', ' disease /disorder classification', ' human data', ' information retrieval', ' medical records']",NCI,"BELMONT RESEARCH, INC.",R43,1994,80985,0.030924982086388855
"Nurses' documentation of patient diagnoses, symptoms and interventions for home care patients with Alzheimer's Disease and related dementias: A natural language processing study PROJECT SUMMARY Alzheimer's disease and related dementias (ADRD) represent a looming public health crisis, affecting roughly 5 million people and 11% of older adults in the United States. Studies on patient transitions across healthcare settings suggests that older adults with chronic conditions are vulnerable to inadequate transfer of information, putting them at risk for diminished quality of care, medication errors and potentially preventable complications. Patients at varied stages along the ADRD trajectory  especially those with multiple chronic conditions  may experience unique risks due to the loss of information across care settings. In a recent study, we developed a longitudinal dataset on a diverse cohort of 56,652 patients  mostly aged 65+ with multiple comorbidities  receiving home health care (HHC) services from a large non-profit home care provider. For patients admitted to HHC in 2010-2012, we identified subgroups of patients with ADRD diagnoses made prior to and after HHC admission. Outside the scope of this prior study remains a vast and largely unexplored data source  nurses free-text clinical notes captured in the electronic health record. With roughly 1 million entries of nurses free- text notes associated with the study population, there is a wealth of potential information from which to gain new insights and a need for innovative methods to analyze this unstructured data source. In this study, we propose to use natural language processing (NLP) techniques, a method for systematically analyzing free-text content that draws upon machine learning. Using the dataset developed in the prior study, this study aims to: 1. Expand and improve an existing NLP system to automatically identify the following information in the  nursing free-text notes: (i) knowledge of the patient having a previously established ADRD diagnosis; (ii)  observations of cognitive symptoms and related patient/caregiver needs; and (iii) mentions of interventions  to address these needs. 2. For patients who do not have an ADRD diagnosis prior to HHC admission, determine whether nurses free-  text documentation of cognitive symptoms identified in the NLP predict subsequent ADRD diagnoses  during the 4-year follow-up period. 3. Among patients diagnosed with ADRD prior to HHC admission, determine whether nurses free-text  documentation patterns (e.g. knowledge of the patients ADRD diagnostic status, observations of cognitive  symptoms, and interventions) predict: (i) service use; and (ii) adverse health outcomes for which ADRD  patients are at heightened risk (e.g. hospitalizations due to urinary tract infection, dehydration, falls). This study will allow us to examine HHC nurses practices, which are often difficult to observe systematically, and identify strategies to address the complex needs of their patients with ADRD and un-diagnosed patients who may be on a path toward ADRD diagnosis. The long-term goal of this research is to develop a home- based intervention that aims to improve quality of life for patients and caregivers along the ADRD trajectory. PROJECT NARRATIVE Alzheimer's disease and related dementias (ADRD) affect about 5 million people in the U.S. Home health care nurses provide care for many people with ADRD and document what they observe about their patients needs in the form of free-text notes. This study will use a method known as natural language processing to gain new knowledge from nurses notes and identify ways to better support people with ADRD and their caregivers.","Nurses' documentation of patient diagnoses, symptoms and interventions for home care patients with Alzheimer's Disease and related dementias: A natural language processing study",10056750,R21AG065753,"['Address', 'Admission activity', 'Affect', 'Alzheimer&apos', 's disease patient', 'Alzheimer&apos', 's disease related dementia', 'Ambulatory Care', 'Assessment tool', 'Awareness', 'Care given by nurses', 'Caregivers', 'Caring', 'Chronic', 'Classification', 'Clinical', 'Clinical Nursing', 'Clinical assessments', 'Cognitive', 'Communication', 'Complex', 'Data', 'Data Set', 'Data Sources', 'Dehydration', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Family', 'Family Caregiver', 'Foundations', 'Funding', 'Future', 'Goals', 'Health', 'Home Care Services', 'Home Health Care Agencies', 'Home environment', 'Hospitalization', 'Individual', 'Intervention', 'Knowledge', 'Link', 'Machine Learning', 'Medical Care Team', 'Medicare claim', 'Medication Errors', 'Methods', 'Natural Language Processing', 'Neurobehavioral Manifestations', 'New York', 'Nurses', 'Nursing Homes', 'Nursing Services', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Provider', 'Public Health', 'Quality of Care', 'Quality of life', 'Research', 'Risk', 'Risk Management', 'Services', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States', 'Urinary tract infection', 'Visiting Nurse', 'Work', 'aged', 'base', 'care coordination', 'care providers', 'cohort', 'comorbidity', 'ethnic diversity', 'experience', 'falls', 'follow-up', 'health care service', 'health care settings', 'hospice environment', 'improved', 'innovation', 'insight', 'longitudinal dataset', 'multiple chronic conditions', 'patient home care', 'patient subsets', 'racial and ethnic', 'study population', 'unstructured data']",NIA,VISITING NURSE SERVICE OF NEW YORK,R21,2020,260660,-0.030608094100985556
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimers Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimers Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,9998610,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,855710,-0.00477783784852771
"Flexible NLP system for MEDLINE information extraction DESCRIPTION (provided by applicant): This Small Business Innovation and Research Phase I project focuses on the development of the fully automatic system for extraction of the protein function information from MEDLINE abstracts and conversion it into a form of a conceptual graph. All existent protein function databases depend on human experts who cannot keep up with the exponential growth of protein function information freely available in MEDLINE. There is an urgent need for an automatic system capable of extracting protein function information from literature. The system we proposed will be based on advanced natural language processing (NLP) technologies, and uses it as a fast and reliable way to extract information about protein function from human readable sources. To this end, we have developed and tested MedScan - a prototype of such system that parses scientific abstracts and converts protein function information into a form of a conceptual graph. It consists of a preprocessor module selecting candidate sentences from MEDLINE, an NLP module utilizing proprietary linguistic model to parse the selected sentences, and an information extraction module utilizing developed ontology to extract and validate protein function information. The results of MedScan evaluation indicate that it is a feasible candidate for a proposed task. In Phase II, the software system will be developed to assist the researchers to quickly access, search and navigate through the MEDLINE content, and to visualize and analyze the large volumes of protein function data. We will also extend our approach to other areas including pharmacogenomics and extraction of clinically relevant information. n/a",Flexible NLP system for MEDLINE information extraction,6693928,R43GM067276,"['computer program /software', ' computer system design /evaluation', ' information dissemination', ' information retrieval', ' information systems', ' molecular biology information system', ' protein structure function']",NIGMS,"ARIADNE GENOMICS, INC.",R43,2003,100000,0.01098602170589198
"Using Machine Learning to Improve Readmission Prediction in Alzheimer's Disease and Related Dementia Project Summary/Abstract By 2060, approximately 14 million adults are expected to live with Alzheimers disease and related dementia (ADRD). Although ADRD patients represent 10% of the general geriatric population, they account for 37% of the direct healthcare expenditures. Compared to other older adults, ADRD patients are at a significantly higher risk of hospitalization and unplanned 30-day hospital readmission (hereafter readmission). Readmissions are costly and expose ADRD patients to expedited cognitive decline, premature institutionalization, and death. Availability of a caregiver after hospital discharge is critical for ADRD patients to ensure adherence to diet, medications, and follow-up appointments. There is a paucity of evidence examining readmission among the ADRD population. Most risk-assessment tools (e.g. LACE Index) have poor discrimination power and lack inclusion of influential medical and social features, and caregiver availability particular to ADRD patients. A potential solution is to develop a risk tool using hospitals electronic health records (EHRs) because they contain salient clinical and sociodemographic features as well as a wealth of information from physicians, nurses and social workers notes (unstructured EHRs data). The specific research aims for this proposal are to (1) develop and validate a risk-assessment tool for predicting readmission among ADRD patients; (2) examine the feasibility/acceptability and clinical/economic utility of the readmission risk- assessment tool; and (3) develop a natural language processing (NLP) algorithm to extract information on caregiver availability from unstructured EHRs (exploratory). We hypothesize that the predictive power of our risk tool will be at least 20% higher than that of LACE Index (the current risk tool used in the Michigan Medicine hospitals). To accomplish this project, my mentors and I have defined a set of targeted career goals and educational training. My training aims include (1) gain familiarity with the clinical aspects of ADRD (linked with Research Aim 1); (2) acquire methodological skills in machine learning and predictive modeling (linked with Research Aim 1); (3) develop an understanding of the logistics of the ADRD patient discharge and care transition processes (linked with Research Aim 2); and (4) gain proficiency in NLP and algorithm validation (linked with Research Aim 3). By completion of this award, I will have used EHRs and data science to develop a validated risk-assessment tool for readmission for hospitalized ADRD patients. The results will enable efficient and targeted discharge planning to reduce readmission and wasteful spending. It will also provide pilot data needed to apply for an R01 examining the optimization of discharge process/location for hospitalized ADRD patients. This career development award will lay the foundation for me to become a unique health economist specialized in efficient care transitions for ADRD patients. Narrative Patients with Alzheimers disease and related dementia (ADRD) are at higher risk of hospitalization and 30-day readmission (readmission) compared to other older adults. Readmission is expensive and increases the risk of institutionalization and premature death among ADRD patients. The main goal of this proposal is to use Michigan Medicines electronic health records to develop a tool to identify high-risk ADRD patients.",Using Machine Learning to Improve Readmission Prediction in Alzheimer's Disease and Related Dementia,10039692,K01AG068361,"['Address', 'Adherence', 'Adult', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'American', 'Appointment', 'Artificial Intelligence', 'Assessment tool', 'Award', 'Caregivers', 'Caring', 'Cessation of life', 'Clinical', 'Cognitive', 'Communities', 'Data', 'Data Science', 'Diet', 'Discharge Plannings', 'Discrimination', 'Economics', 'Elderly', 'Electronic Health Record', 'Emergency department visit', 'Ensure', 'Familiarity', 'Foundations', 'General Population', 'Goals', 'Health', 'Health Expenditures', 'Healthcare', 'Hospitalization', 'Hospitals', 'Impaired cognition', 'Influentials', 'Institutionalization', 'Intervention', 'K-Series Research Career Programs', 'Length of Stay', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measurable', 'Medical', 'Medical History', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Michigan', 'Natural Language Processing', 'Nurses', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Education', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Predictive Value', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Risk Reduction', 'Sensitivity and Specificity', 'Services', 'Social Workers', 'Socioeconomic Status', 'Source', 'Stress', 'System', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Validation', 'analytical method', 'base', 'career', 'comorbidity', 'cost', 'electronic structure', 'follow-up', 'frailty', 'health data', 'high risk', 'hospital readmission', 'improved', 'indexing', 'innovation', 'multidisciplinary', 'patient population', 'predictive modeling', 'predictive tools', 'premature', 'readmission risk', 'skills', 'social', 'sociodemographics', 'tool', 'unstructured data']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2020,130140,-0.04930689553576387
"Improving Cancer Screening Through A Tailored Technology-Based Intervention Cancer is the second leading cause of death in the United States. Health disparities exist in cancer screening and mortality. Although cancer mortality rates have decreased steadily over the past 25 years, the racial gap persists, and socioeconomic disparities are widening. Improved early detection and treatment can decrease cancer mortality, but many barriers exist to screening uptake. Cancer screening is often a trade-off for both patients and clinicians among different cancer screenings and other preventive opportunities, each of which have their own barriers to completion. This study seeks to improve quality of care and reduce health disparities in cancer mortality by using informatics to better tailor clinical discussions in order to enhance patient motivation to receive screening services and help overcome barriers to screening. The study has the following aims: 1) to develop a predictive model that identifies patients > 50 years old eligible for lung, breast and colorectal cancer screening who are at high-risk for missing these screenings; 2) to develop and pilot test a prototype shared decision-making support tool for patients and clinicians that will increase screening uptake; 3) to perform a pragmatic trial of the refined multilevel intervention that utilizes a shared decision-making support tool for patients and clinicians.  During the planning phase, data from the electronic health record (EHR) will be combined with supplementary data sources (e.g. Area Health Resource File, LexisNexis) to identify patients at risk of not completing recommended screening for these cancers. Hold-out cross-validation will be used to estimate model accuracy. Machine learning model building following feature selection will utilize logistic regression and decision trees to ensure the models are easily transferable to other healthcare settings and interpretable. This predictive model will be used to develop and pilot test an application that will (A) utilize predictive modeling to identify eligible patients likely to miss screening; (B) determine, after providing patient education, patient preferences and concerns regarding screening through self-report augmented by predictive modelling; (C) identify available community resources to facilitate screening; (D) provide this information to patients and to clinicians in the EHR prior to clinical visits to assist shared decision-making conversations and support active problem solving of identified barriers. This multilevel intervention will be pilot-tested and refined within 4 academic primary care practices over 6 months (N=24 clinicians; 8181 potential screenings yearly). A pragmatic trial will be conducted during the R33 phase using a stepped wedge cluster randomized design (N=45 clinicians; 11,239 potential screenings yearly). Completed cancer screening will be the primary outcome. Patient experience, clinician satisfaction and utilization will also be assessed. If successful, this approach will lead to an intervention tailored to the patient and their community that leverages information technology in a scalable way that is transferrable to other clinical settings and types of preventive services. PROJECT NARRATIVE Significant disparities exist in breast, colorectal and lung cancer, the leading causes of cancer mortality, requiring the development of new interventions that increase screening uptake in diverse populations. We propose an intervention that employs a multilevel approach that leverages the Electronic Health Records (EHR) and supplementary data sources to develop a predictive model to identify eligible patients at high-risk of not obtaining screening and to facilitate improved shared decision-making conversations using an EHR based decision-making support tool that interacts with patients and clinicians. By personalizing the approach to screening and improving the quality of patient-clinician interactions, we hope to enhance patient motivation to receive screening services and reduce health disparities.",Improving Cancer Screening Through A Tailored Technology-Based Intervention,10051055,R61AG068951,"['Advisory Committees', 'African American', 'Age', 'Area', 'Cancer Etiology', 'Cause of Death', 'Clinic', 'Clinical', 'Colorectal Cancer', 'Communities', 'Data', 'Data Sources', 'Decision Making', 'Decision Trees', 'Development', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Ethnic group', 'Health', 'Health Resources', 'Hispanics', 'Individual', 'Informatics', 'Information Technology', 'Intervention', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Modeling', 'Motivation', 'Patient Education', 'Patient Preferences', 'Patient Self-Report', 'Patients', 'Phase', 'Population Heterogeneity', 'Preventive', 'Preventive screening', 'Preventive service', 'Primary Health Care', 'Problem Solving', 'Quality of Care', 'Race', 'Randomized', 'Resources', 'Risk', 'Rural Community', 'Screening for cancer', 'Services', 'Source', 'Technology', 'Testing', 'United States', 'Validation', 'Visit', 'base', 'cancer health disparity', 'cancer type', 'colorectal cancer screening', 'design', 'electronic data', 'experience', 'feature selection', 'health care settings', 'health disparity', 'high risk', 'improved', 'low socioeconomic status', 'malignant breast neoplasm', 'model building', 'mortality', 'personalized approach', 'pragmatic trial', 'predictive modeling', 'preference', 'primary outcome', 'prototype', 'racial and ethnic', 'regression trees', 'satisfaction', 'screening', 'screening guidelines', 'sex', 'shared decision making', 'socioeconomic disparity', 'support tools', 'tool', 'treatment as usual', 'uptake']",NIA,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R61,2020,279223,-0.016661921770138595
"Low-cost detection of dementia using electronic health records data: validation and testing of the eRADAR algorithm in a pragmatic, patient-centered trial. Nearly half of people currently living with dementia have not received a diagnosis, delaying access to treatment as well as education and support for the patient and family. Thus, NIA has requested applications to support pragmatic clinical trials of low-cost tools to improve detection of cognitive decline in clinical settings (RFA-AG- 20-051). With pilot funding from NIA, we used machine learning to develop a low-cost tool called eRADAR (electronic health record Risk of Alzheimer's and Dementia Assessment Rule), which uses easily accessible information in the electronic health record (EHR) to help identify patients with undiagnosed dementia. In addition, we interviewed patients, caregivers, clinicians, and healthcare system leaders to inform pragmatic implementation of eRADAR in clinical settings. Stakeholders felt strongly that such a tool should be implemented through primary care, in the context of existing clinical relationships, and would need to be accompanied by additional support for patients and clinicians. Our current proposal is heavily informed by this development work. In Aim 1, we will use EHR data to evaluate eRADAR's performance in different patient subgroups, including by race/ethnicity, in two healthcare systems to inform selection of cut- points for use in clinical settings. We will select an optimal cut-point to use for targeted dementia assessment with stakeholder input, balancing sensitivity, specificity, and positive predictive value. In Aim 2, we will perform a pragmatic clinical trial to determine whether implementing eRADAR as part of a supported outreach process to high-risk patients improves dementia detection. The setting will be primary care clinics within Kaiser Permanente Washington (KPWA), an integrated healthcare delivery system in Washington State, and the University of California, San Francisco (UCSF), an urban, academic healthcare system with a diverse patient population. The study includes 6 clinics with ~24,000 patients age 65. Within each clinic, primary care providers (PCPs) will be randomly assigned to have their patients with high eRADAR scores targeted for outreach (intervention) or to usual care (control). Our clinical research staffwhose roles were designed to reflect existing roles within these healthcare systems to maximize pragmatismwill reach out to patients with high eRADAR scores, conduct an assessment for cognitive impairment, make follow-up recommendations to PCPs, and support patients after diagnosis. Patients with high eRADAR scores in both treatment arms will be followed to determine the impact of eRADAR on new diagnoses of dementia (primary outcome) as assessed from the EHR (again, to maximize pragmatism). In Aim 3, we will explore the impact of eRADAR implementation on secondary outcomes including healthcare utilization and experience of patients and family members. If this pragmatic trial is successful, the eRADAR tool and process could be spread to other healthcare systems, potentially improving detection of cognitive decline, patient care, and quality of life. Most patients with cognitive impairment are diagnosed relatively late in the disease process, and about half of people living with dementia are undiagnosed. We have developed a low-cost tool called eRADAR (electronic health record Risk of Alzheimer's and Dementia Assessment Rule) that uses information in electronic health records to help identify patients with undiagnosed dementia. This study will determine whether a supported process of reaching out to patients with high eRADAR scores as part of primary care leads to earlier detection of dementia and improves patient care.","Low-cost detection of dementia using electronic health records data: validation and testing of the eRADAR algorithm in a pragmatic, patient-centered trial.",10091300,R01AG069734,"['Academic Medical Centers', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'California', 'Caregivers', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Element', 'Dementia', 'Detection', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Education', 'Electronic Health Record', 'Emergency department visit', 'Equilibrium', 'Ethnic Origin', 'Family', 'Family member', 'Funding', 'Goals', 'Health Services Accessibility', 'Healthcare Systems', 'Impaired cognition', 'Inpatients', 'Integrated Delivery of Health Care', 'Intervention', 'Interview', 'Laboratories', 'Machine Learning', 'Measures', 'Mental Depression', 'Participant', 'Patient Care', 'Patient Education', 'Patients', 'Pattern', 'Performance', 'Population Heterogeneity', 'Pragmatic clinical trial', 'Predictive Value', 'Preventive Intervention', 'Primary Health Care', 'Procedures', 'Process', 'Quality of Care', 'Quality of life', 'Race', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Request for Applications', 'Research Design', 'Research Support', 'Retrospective Studies', 'Risk', 'Role', 'San Francisco', 'Sensitivity and Specificity', 'Services', 'Stroke', 'Subgroup', 'Surveys', 'Symptoms', 'System', 'Testing', 'Traumatic Brain Injury', 'Underweight', 'Universities', 'Validation', 'Visit', 'Washington', 'Work', 'base', 'care providers', 'clinical care', 'comparison intervention', 'cost', 'dementia risk', 'design', 'electronic structure', 'experience', 'follow-up', 'formative assessment', 'health care service utilization', 'high risk', 'human old age (65+)', 'improved', 'medication compliance', 'neuroimaging', 'outreach', 'patient oriented', 'patient population', 'patient subsets', 'pragmatic trial', 'primary outcome', 'satisfaction', 'secondary outcome', 'sex', 'tool', 'treatment arm', 'treatment as usual', 'usual care arm']",NIA,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2020,650000,0.013382356594382463
"A Technology-Driven Intervention to Improve Early Detection and Management of Cognitive Impairment Project Summary The prevalence of Alzheimers disease (AD) and AD-related dementias (ADRD) is expected to triple by 2050, contributing to decreased quality of life, increased medical care utilization, and additional burden on an already stressed primary care system. Many clinicians lack confidence to assess, diagnose and manage cognitive impairment (CI), and more than 50% of patients with CI are undiagnosed. Unfortunately, studies show that even in settings with high rates of standardized CI screening, very few patients who screen positive have documentation of any clinician follow-up action. To address these important problems, in phase 1 (R61) of this project, we will develop and validate a machine learning model (called MC-PLUS) using results from brief Mini- Cog (MC) screens completed routinely at Annual Medicare Wellness exams and electronic health record (EHR) data to identify patients at elevated risk of a future dementia diagnosis (AD/ADRD). We will also develop and validate a web-based and EHR-integrated CI clinical decision support (CI-CDS) system to engage patients and clinicians in conversation about elevated dementia risk, and to give clinicians the confidence and tools they need to diagnose and manage CI. Both MC-PLUS and the CI-CDS system will be added into an existing web-based CDS platform that has high use rates and primary care clinician satisfaction, and is already seamlessly integrated within the EHR. This CDS platform improves outcomes for patients with chronic diseases such as diabetes and high cardiovascular risk as shown in published studies. We will systematically validate the CI-CDS system with expert champions prior to conducting a pilot test at one primary care clinic. After milestones for success are demonstrated, we will begin phase 2 (R33), a large pragmatic trial with 30 primary care clinics randomized to receive CI-CDS or usual care (UC). We will evaluate change in clinician confidence in CI detection and care management in CI-CDS compared to UC clinics. If successful, the CI-CDS system will improve rates of new CI diagnosis and narrow existing sociodemographic disparities in adults with elevated dementia risk identified by MC-PLUS at index visit in CI-CDS compared to UC clinics. We will evaluate the impact of the intervention on care management and care plans using EHR data and chart audits. We will assess determinants of clinician actions in response to the CDS system using behavior change theory and technology acceptance constructs, and conduct phone surveys of patient and caregiver dyads to evaluate intervention effects on feelings of preparedness for decision making and distress. The CI-CDS system is immediately scalable to large numbers of patients through the existing non-commercialized CDS platform already in use for millions of patients in care systems spanning 14 states. The CDS system implemented as described could maximize return on massive investments that have been made in EHR systems, and provide a prototype to rapidly and consistently translate evolving evidence-based CI guidelines into personalized CI care and guidance within primary care. Project Narrative Most experts advocate for early detection of cognitive impairment (CI) so that patients and caregivers can be prepared for making difficult decisions and to improve quality of life, but studies show that screening alone isnt sufficient to change clinician actions related to early detection. Using predictive modelling developed with machine learning methods and sophisticated clinical decision support (CDS) tools, it is possible to identify patients at elevated risk for CI and make it much easier for primary care to engage and support patients and caregivers in meaningful care planning. In this project, we implement and evaluate a low-cost, highly scalable CI-CDS system integrated within the electronic health record that has high potential to improve early CI detection and care and translate massive public and private sector investments in health informatics into tangible health benefits for large numbers of people.",A Technology-Driven Intervention to Improve Early Detection and Management of Cognitive Impairment,10092423,R61AG069770,"['Accident and Emergency department', 'Address', 'Adult', 'Advocate', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Attention', 'Caregivers', 'Caring', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Data', 'Decision Making', 'Dementia', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Distress', 'Documentation', 'Early Diagnosis', 'Electronic Health Record', 'Ethnic Origin', 'Family', 'Feeling', 'Foundations', 'Future', 'Gender', 'Guidelines', 'Health Benefit', 'Health Expenditures', 'Impaired cognition', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investments', 'Machine Learning', 'Medical', 'Medicare', 'Modeling', 'Newly Diagnosed', 'Office Visits', 'Online Systems', 'Patient Care Planning', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Predictive Value', 'Prevalence', 'Primary Health Care', 'Printing', 'Private Sector', 'Public Health Informatics', 'Public Sector', 'Publishing', 'Quality of life', 'Race', 'Randomized', 'Readiness', 'Recommendation', 'Reporting', 'Risk', 'Socioeconomic Status', 'Specialist', 'Standardization', 'Stress', 'Suggestion', 'Surveys', 'System', 'Technology', 'Telephone', 'Testing', 'Theory of Change', 'Translating', 'Visit', 'Work', 'base', 'behavior change', 'cardiovascular risk factor', 'care systems', 'clinical decision support', 'cost', 'dementia risk', 'evidence base', 'follow-up', 'health care service utilization', 'improved', 'improved outcome', 'indexing', 'intervention effect', 'machine learning method', 'mild cognitive impairment', 'personalized care', 'pragmatic trial', 'predictive modeling', 'prototype', 'randomized trial', 'response', 'satisfaction', 'screening', 'sociodemographics', 'success', 'support tools', 'tool', 'treatment as usual']",NIA,HEALTHPARTNERS INSTITUTE,R61,2020,592048,-0.0019319490718898225
"Algorithms to Identify Systemic Lupus from Electronic Health Record Data Abstract  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. The personal and economic costs in decreased quality of life and increase in healthcare expenditures, respectively, highlight the critical unmet need to develop new therapeutic strategies to treat lupus, so that treatment or participation in clinical trials occurs as early as possible to mitigate against disease-related damage. Therefore, it is important to find better ways to identify SLE patents.  Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. Despite this potential, to date few accurate algorithms have been developed to identify SLE patients using EHR data. Construction of an effective algorithm, either by rule-based or machine learning methods, requires access to at two data resources not commonly available: 1) a validated gold standard patient data set with clear documentation of criteria that are indicative of SLE that can be compared against EHR data and 2) an integrated health record dataset that contains data from multiple health care institutions and reflects that SLE patients receive healthcare at multiple institutions and healthcare providers given their chronic, progressive disease. Over the past several years, our team has created both key resources: the Chicago Lupus Database (CLD), a physician-validated registry of 880 patients and gold standard data set and the Chicago HealthLNK Data Repository (HDR), a regional data resource including integrated medical records for 2.1 million patients across multiple institutions. Jointly, these two datasets enable the creation, testing and validation of algorithms for the identification of SLE in EHR data and provide a more complete picture of a patient population at risk for lupus.  We propose three specific aims to address the need to reduce the time to identify those with SLE in order to initiate treatment in a timelier fashion and to identify candidates for clinical trials. These aims are: 1) To create and validate a series of algorithms to identify SLE patients in EHR data against a gold standard curated registry, CLD, using validated classification criteria for SLE to build concepts for rule-based and machine learning methods that incorporate structured data, laboratory data, and unstructured data, e.g., physician notes, 2) To determine whether identification of SLE patients is improved when algorithms to identify SLE patients are extended to an integrated medical record dataset that includes data from multiple health care institutions, and 3) To use clustering techniques on SLE patients identified from EHR data to isolate clinically distinct sub-populations of patients, which could inform patient selection for participation in clinical trials. Project Narrative  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. This study will test and validate algorithms for the identification of SLE from EHR data and thus will help provide a more complete picture of a patient population at risk for lupus.",Algorithms to Identify Systemic Lupus from Electronic Health Record Data,9536683,R21AR072263,"['Address', 'Affect', 'Algorithms', 'American', 'Autoimmune Process', 'Caring', 'Chicago', 'Chronic', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Collection', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Flare', 'General Population', 'Goals', 'Gold', 'Health Expenditures', 'Health Personnel', 'Health system', 'Healthcare', 'Institution', 'Laboratories', 'Legal patent', 'Lupus', 'Machine Learning', 'Medical Care Costs', 'Medical Records', 'Medicine', 'Patient Selection', 'Patients', 'Phenotype', 'Physicians', 'Populations at Risk', 'Progressive Disease', 'Quality of Care', 'Quality of life', 'Registries', 'Research', 'Resources', 'Sensitivity and Specificity', 'Series', 'Site', 'Source', 'Structure', 'Symptoms', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Time', 'Validation', 'base', 'clinical candidate', 'clinical practice', 'data resource', 'data warehouse', 'economic cost', 'health care settings', 'health record', 'improved', 'learning strategy', 'mortality', 'novel therapeutic intervention', 'patient population', 'patient subsets', 'personalized medicine', 'prevent', 'standard of care', 'targeted treatment', 'therapeutic evaluation']",NIAMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2018,173800,0.08180479884379618
"Algorithms to Identify Systemic Lupus from Electronic Health Record Data Abstract  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. The personal and economic costs in decreased quality of life and increase in healthcare expenditures, respectively, highlight the critical unmet need to develop new therapeutic strategies to treat lupus, so that treatment or participation in clinical trials occurs as early as possible to mitigate against disease-related damage. Therefore, it is important to find better ways to identify SLE patents.  Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. Despite this potential, to date few accurate algorithms have been developed to identify SLE patients using EHR data. Construction of an effective algorithm, either by rule-based or machine learning methods, requires access to at two data resources not commonly available: 1) a validated gold standard patient data set with clear documentation of criteria that are indicative of SLE that can be compared against EHR data and 2) an integrated health record dataset that contains data from multiple health care institutions and reflects that SLE patients receive healthcare at multiple institutions and healthcare providers given their chronic, progressive disease. Over the past several years, our team has created both key resources: the Chicago Lupus Database (CLD), a physician-validated registry of 880 patients and gold standard data set and the Chicago HealthLNK Data Repository (HDR), a regional data resource including integrated medical records for 2.1 million patients across multiple institutions. Jointly, these two datasets enable the creation, testing and validation of algorithms for the identification of SLE in EHR data and provide a more complete picture of a patient population at risk for lupus.  We propose three specific aims to address the need to reduce the time to identify those with SLE in order to initiate treatment in a timelier fashion and to identify candidates for clinical trials. These aims are: 1) To create and validate a series of algorithms to identify SLE patients in EHR data against a gold standard curated registry, CLD, using validated classification criteria for SLE to build concepts for rule-based and machine learning methods that incorporate structured data, laboratory data, and unstructured data, e.g., physician notes, 2) To determine whether identification of SLE patients is improved when algorithms to identify SLE patients are extended to an integrated medical record dataset that includes data from multiple health care institutions, and 3) To use clustering techniques on SLE patients identified from EHR data to isolate clinically distinct sub-populations of patients, which could inform patient selection for participation in clinical trials. Project Narrative  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. This study will test and validate algorithms for the identification of SLE from EHR data and thus will help provide a more complete picture of a patient population at risk for lupus.",Algorithms to Identify Systemic Lupus from Electronic Health Record Data,9375416,R21AR072263,"['Address', 'Affect', 'Algorithms', 'American', 'Autoimmune Process', 'Caring', 'Chicago', 'Chronic', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Collection', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Expenditure', 'Flare', 'General Population', 'Goals', 'Gold', 'Health Personnel', 'Health system', 'Healthcare', 'Institution', 'Laboratories', 'Legal patent', 'Lupus', 'Machine Learning', 'Medical', 'Medical Records', 'Medicine', 'Patient Selection', 'Patients', 'Phenotype', 'Physicians', 'Populations at Risk', 'Progressive Disease', 'Quality of Care', 'Quality of life', 'Registries', 'Research', 'Resources', 'Sensitivity and Specificity', 'Series', 'Site', 'Source', 'Structure', 'Symptoms', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Time', 'Validation', 'base', 'clinical candidate', 'clinical practice', 'cost', 'data resource', 'economic cost', 'health record', 'improved', 'learning strategy', 'mortality', 'novel therapeutic intervention', 'patient population', 'personalized medicine', 'prevent', 'standard of care', 'targeted treatment', 'therapeutic evaluation']",NIAMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2017,208395,0.08180479884379618
"EHR-based patient safety: Automated error detection in neonatal intensive care     DESCRIPTION (provided by applicant): In the field of neonatal patient safety, the paucity of systematic research is a critical barrier to progress. Notably missing are studies that meticulously investigate Electronic Health Records (EHR) and information technology in detecting neonatal intensive care-related errors. The expert panel at the National Institute of Child Health and Human Development (NICHHD) identified multiple gaps in the current knowledge of neonatal patient safety research. The proposed work is a well focused response to three dimensions of the Funding Opportunity Announcement:  1.Develop prospective and retrospective study designs to collect data on patient safety and adverse events.  2.Study the strength and limitations of current methods of error reporting systems.  3.Study the usefulness of commercial IT systems and EHRs in reducing medical errors.  In our study we seek to shift patient safety research toward an automated and computerized approach to achieve a more comprehensive patient safety paradigm. We will develop novel Electronic Health Record (EHR) content-based automated algorithms that are new to patient safety research to 1) detect errors (Aim 1) and 2) categorize subsequent harm (Aim 2). State of the art information extraction and statistical classification techniques from the field of clinical Natural Language Processing (NLP) will be adapted to the patient safety research tasks.  In Aim 1 we will fill the gap in the literatre by implementing a focused manual review of 700 charts (one full year of patient admissions at our institution) in one of the largest Neonatal Intensive Care Units (NICU) in the nation. Using a trigger tool, we will identify errors occurring in three specified categories - laboratory test errrs, medication/fluid errors, and airway management errors. We will develop novel algorithms for automated EHR-based detection of the errors and evaluate the performance of the new algorithms against the performance of both trigger tool review by human chart reviewers (current gold standard) and the voluntary incident reporting system (accepted standard). In Aim 2, we will study the utility of novel EHR-based information extraction and statistical algorithms for the automated categorization of errors according to the resulting level of harm.  Our proposed work has the potential to accomplish a paradigm shift in the methods of neonatal patient safety research and practice. The study is a fundamental step to automating patient safety monitoring on a large scale and improving error identification and patient safety in NICUs for millions of children every year.          We are developing an automated error detection technique to improve the safety of newborn babies during hospital care. Our work is the first known attempt to use text analysis in the electronic health records on a large scale to reduce the cost while at the same time increase the speed and comprehensiveness of error detection in the clinical care of newborns.            ",EHR-based patient safety: Automated error detection in neonatal intensive care,8517787,R21HD072883,"['Adverse event', 'Algorithms', 'Caring', 'Categories', 'Cessation of life', 'Characteristics', 'Child', 'Child health care', 'Classification', 'Clinical', 'Data', 'Detection', 'Dimensions', 'Electronic Health Record', 'Foundations', 'Funding Opportunities', 'Gold', 'Hospitals', 'Hour', 'Human', 'Human Development', 'Information Systems', 'Information Technology', 'Institutes', 'Institution', 'Intervention', 'Knowledge', 'Laboratories', 'Liquid substance', 'Literature', 'Manuals', 'Medical Errors', 'Medication Errors', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Neonatal', 'Neonatal Intensive Care', 'Neonatal Intensive Care Units', 'Newborn Infant', 'Patient Admission', 'Patient Monitoring', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Prevention', 'Process', 'Prospective Studies', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Risk', 'Safety', 'Solid', 'Specific qualifier value', 'Speed', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Work', 'base', 'clinical care', 'computerized', 'cost', 'design', 'experience', 'improved', 'indexing', 'innovation', 'novel', 'patient safety', 'phrases', 'response', 'tool']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R21,2013,254095,0.05787644101385696
"EHR-based patient safety: Automated error detection in neonatal intensive care     DESCRIPTION (provided by applicant): In the field of neonatal patient safety, the paucity of systematic research is a critical barrier to progress. Notably missing are studies that meticulously investigate Electronic Health Records (EHR) and information technology in detecting neonatal intensive care-related errors. The expert panel at the National Institute of Child Health and Human Development (NICHHD) identified multiple gaps in the current knowledge of neonatal patient safety research. The proposed work is a well focused response to three dimensions of the Funding Opportunity Announcement:  1.Develop prospective and retrospective study designs to collect data on patient safety and adverse events.  2.Study the strength and limitations of current methods of error reporting systems.  3.Study the usefulness of commercial IT systems and EHRs in reducing medical errors.  In our study we seek to shift patient safety research toward an automated and computerized approach to achieve a more comprehensive patient safety paradigm. We will develop novel Electronic Health Record (EHR) content-based automated algorithms that are new to patient safety research to 1) detect errors (Aim 1) and 2) categorize subsequent harm (Aim 2). State of the art information extraction and statistical classification techniques from the field of clinical Natural Language Processing (NLP) will be adapted to the patient safety research tasks.  In Aim 1 we will fill the gap in the literatre by implementing a focused manual review of 700 charts (one full year of patient admissions at our institution) in one of the largest Neonatal Intensive Care Units (NICU) in the nation. Using a trigger tool, we will identify errors occurring in three specified categories - laboratory test errrs, medication/fluid errors, and airway management errors. We will develop novel algorithms for automated EHR-based detection of the errors and evaluate the performance of the new algorithms against the performance of both trigger tool review by human chart reviewers (current gold standard) and the voluntary incident reporting system (accepted standard). In Aim 2, we will study the utility of novel EHR-based information extraction and statistical algorithms for the automated categorization of errors according to the resulting level of harm.  Our proposed work has the potential to accomplish a paradigm shift in the methods of neonatal patient safety research and practice. The study is a fundamental step to automating patient safety monitoring on a large scale and improving error identification and patient safety in NICUs for millions of children every year.        PUBLIC HEALTH RELEVANCE: We are developing an automated error detection technique to improve the safety of newborn babies during hospital care. Our work is the first known attempt to use text analysis in the electronic health records on a large scale to reduce the cost while at the same time increase the speed and comprehensiveness of error detection in the clinical care of newborns.              We are developing an automated error detection technique to improve the safety of newborn babies during hospital care. Our work is the first known attempt to use text analysis in the electronic health records on a large scale to reduce the cost while at the same time increase the speed and comprehensiveness of error detection in the clinical care of newborns.            ",EHR-based patient safety: Automated error detection in neonatal intensive care,8334934,R21HD072883,"['Adverse event', 'Algorithms', 'Caring', 'Categories', 'Cessation of life', 'Characteristics', 'Child', 'Child health care', 'Classification', 'Clinical', 'Data', 'Detection', 'Dimensions', 'Electronic Health Record', 'Foundations', 'Funding Opportunities', 'Gold', 'Hospitals', 'Hour', 'Human', 'Human Development', 'Information Systems', 'Information Technology', 'Institutes', 'Institution', 'Intervention', 'Knowledge', 'Laboratories', 'Liquid substance', 'Literature', 'Manuals', 'Medical Errors', 'Medication Errors', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Neonatal', 'Neonatal Intensive Care', 'Neonatal Intensive Care Units', 'Newborn Infant', 'Patient Admission', 'Patient Monitoring', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Prevention', 'Process', 'Prospective Studies', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Risk', 'Safety', 'Solid', 'Specific qualifier value', 'Speed', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Work', 'base', 'clinical care', 'computerized', 'cost', 'design', 'experience', 'improved', 'indexing', 'innovation', 'novel', 'patient safety', 'phrases', 'response', 'tool']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R21,2012,153000,0.06290076426937893
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,9486584,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Infection', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'informatics infrastructure', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2018,484387,0.011740938636038856
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,9880374,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction model', 'structured data', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2020,592632,0.011740938636038856
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,9657648,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics\xa0tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction model', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2019,636882,0.011740938636038856
"Comparative Effectiveness of Treat-To-Target Approach versus Routine Care in Management of Gout Gout is a highly prevalent, painful inflammatory arthritis, caused by crystallization of uric acid in joint tissues. Gout flares cause impaired quality of life and physical function, leading to lost work days, disability, high healthcare costs. Patients with gout are also known to be at an increased risk of cardiovascular diseases (CVD), kidney disease, and mortality. Previous studies suggest a potential beneficial effect of urate-lowering therapy on the risk of CVD and renal function. Over the past decade, the American College of Rheumatology and the European League Against Rheumatism recommend a treat-to-target (TTT) approach that lowers serum uric acid (SUA) level below 6 mg/dl to reduce acute gout attacks, based on the upper limit of water solubility of uric acid under normal physiologic circumstances. However, the 2016 American College of Physicians (ACP) guidelines for gout management recommend use of urate-lowering therapy but support a treat-to-avoid symptoms strategy without monitoring SUA rather than the TTT strategy because of inconclusive evidence in the literature. Such discrepancies in treatment guidelines from various societies urge the need for comparative effectiveness research of the treatment strategies for gout.  Rigorous epidemiologic studies utilizing high-quality observational data from electronic health records (EHR) or insurance claims databases can be an important tool for comparative effectiveness research. The primary objective of this 3-year proposal is to provide high-quality, timely evidence on the comparative effectiveness of two different treatment strategies, TTT versus usual care, for management of gout. We will pursue this objective by utilizing the linked Partners EHR-Medicare database (2007-2016); this linked database includes all patients aged 65 years enrolled in Medicare Parts A/B/D who had 1 encounter at one of the Partners Healthcare hospitals. We will have longitudinal, clinically important data on patients demographics, body mass index, visit notes, laboratory results including SUA and serum creatinine, as well as all Medicare claims for inpatient and outpatient visits, procedures, and prescription drugs. The two specific aims of this 3-year proposal are: 1) to examine the effect of TTT strategy on the risk of gout flares versus usual care and 2) to assess the effect of TTT strategy on the risk of kidney disease and CVD versus usual care.  Given the substantial prevalence of gout, the suboptimal management of gout and lack of comparative trial of different treatment strategies, this proposed study will make an immediate, important contribution to the management of gout in clinical practice. This work will not only investigate the effects of different treatment strategies on gout flares but also on common comorbidities in patients with gout such as kidney and CVD. Furthermore, this proposed study will advance understanding of how to improve ascertainment of dynamic outcomes and control for time-varying confounding by utilizing sophisticated and innovative epidemiologic as well as bioinformatics methods in a large EHR database linked with Medicare claims. Narrative Gout is a common, painful inflammatory arthritis caused by crystallization of uric acid in joint tissues. Xanthine oxidase inhibitors, allopurinol and febuxostat, are the mainstay of urate-lowering treatment for gout. While rheumatology societies recommend a treat-to-target (TTT) approach that lowers serum uric acid below 6 mg/dl to reduce acute gout attacks, there is currently no clinical data whether TTT approach is better than urate- lowering therapy but no regular monitoring of uric acid levels (i.e., usual care); therefore, this 3-year research proposal examines the comparative effectiveness of the two different treatment strategies, TTT versus usual care, for management of chronic gout in a real-world setting.",Comparative Effectiveness of Treat-To-Target Approach versus Routine Care in Management of Gout,9975704,R01AR073314,"['Acute', 'Affect', 'Algorithms', 'Allopurinol', 'American', 'American College of Physicians', 'Bioinformatics', 'Body mass index', 'Cardiovascular Diseases', 'Caring', 'Chronic', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Comparative Effectiveness Research', 'Coronary', 'Creatinine', 'Crystallization', 'Data', 'Data Set', 'Databases', 'Drug Prescriptions', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'European', 'Flare', 'Glomerular Filtration Rate', 'Gold', 'Gout', 'Guidelines', 'Health Care Costs', 'Health Insurance', 'Healthcare', 'Heart failure', 'High Prevalence', 'Hospitalization', 'Hospitals', 'Hypertension', 'Hyperuricemia', 'Impairment', 'Inflammatory', 'Inflammatory Arthritis', 'Inpatients', 'Joints', 'Kidney Diseases', 'Laboratories', 'Link', 'Literature', 'Medical Societies', 'Medicare', 'Medicare Part A', 'Medicare claim', 'Methods', 'Monitor', 'Myocardial Infarction', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Outpatients', 'Pain', 'Patients', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Physical Function', 'Physiological', 'Prevalence', 'Procedures', 'Prognostic Factor', 'Quality of life', 'Randomized Controlled Trials', 'Renal function', 'Research Proposals', 'Rheumatism', 'Rheumatology', 'Risk', 'Role', 'Serum', 'Societies', 'Statistical Methods', 'Stroke', 'Symptoms', 'Time', 'Tissues', 'Urate', 'Uric Acid', 'Visit', 'Work', 'active comparator', 'base', 'cardiovascular disorder risk', 'clinical practice', 'college', 'comorbidity', 'comparative effectiveness', 'comparative trial', 'cost', 'demographics', 'design', 'disability', 'drug efficacy', 'efficacy study', 'electronic data', 'epidemiology study', 'febuxostat', 'human old age (65+)', 'improved', 'innovation', 'insurance claims', 'mortality', 'population based', 'rheumatologist', 'routine care', 'tool', 'treatment as usual', 'treatment guidelines', 'treatment strategy', 'water solubility', 'xanthine oxidase inhibitor']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,435018,0.03066068467691293
"Comparative Effectiveness of Treat-To-Target Approach versus Routine Care in Management of Gout Gout is a highly prevalent, painful inflammatory arthritis, caused by crystallization of uric acid in joint tissues. Gout flares cause impaired quality of life and physical function, leading to lost work days, disability, high healthcare costs. Patients with gout are also known to be at an increased risk of cardiovascular diseases (CVD), kidney disease, and mortality. Previous studies suggest a potential beneficial effect of urate-lowering therapy on the risk of CVD and renal function. Over the past decade, the American College of Rheumatology and the European League Against Rheumatism recommend a treat-to-target (TTT) approach that lowers serum uric acid (SUA) level below 6 mg/dl to reduce acute gout attacks, based on the upper limit of water solubility of uric acid under normal physiologic circumstances. However, the 2016 American College of Physicians (ACP) guidelines for gout management recommend use of urate-lowering therapy but support a treat-to-avoid symptoms strategy without monitoring SUA rather than the TTT strategy because of inconclusive evidence in the literature. Such discrepancies in treatment guidelines from various societies urge the need for comparative effectiveness research of the treatment strategies for gout.  Rigorous epidemiologic studies utilizing high-quality observational data from electronic health records (EHR) or insurance claims databases can be an important tool for comparative effectiveness research. The primary objective of this 3-year proposal is to provide high-quality, timely evidence on the comparative effectiveness of two different treatment strategies, TTT versus usual care, for management of gout. We will pursue this objective by utilizing the linked Partners EHR-Medicare database (2007-2016); this linked database includes all patients aged 65 years enrolled in Medicare Parts A/B/D who had 1 encounter at one of the Partners Healthcare hospitals. We will have longitudinal, clinically important data on patients demographics, body mass index, visit notes, laboratory results including SUA and serum creatinine, as well as all Medicare claims for inpatient and outpatient visits, procedures, and prescription drugs. The two specific aims of this 3-year proposal are: 1) to examine the effect of TTT strategy on the risk of gout flares versus usual care and 2) to assess the effect of TTT strategy on the risk of kidney disease and CVD versus usual care.  Given the substantial prevalence of gout, the suboptimal management of gout and lack of comparative trial of different treatment strategies, this proposed study will make an immediate, important contribution to the management of gout in clinical practice. This work will not only investigate the effects of different treatment strategies on gout flares but also on common comorbidities in patients with gout such as kidney and CVD. Furthermore, this proposed study will advance understanding of how to improve ascertainment of dynamic outcomes and control for time-varying confounding by utilizing sophisticated and innovative epidemiologic as well as bioinformatics methods in a large EHR database linked with Medicare claims. Narrative Gout is a common, painful inflammatory arthritis caused by crystallization of uric acid in joint tissues. Xanthine oxidase inhibitors, allopurinol and febuxostat, are the mainstay of urate-lowering treatment for gout. While rheumatology societies recommend a treat-to-target (TTT) approach that lowers serum uric acid below 6 mg/dl to reduce acute gout attacks, there is currently no clinical data whether TTT approach is better than urate- lowering therapy but no regular monitoring of uric acid levels (i.e., usual care); therefore, this 3-year research proposal examines the comparative effectiveness of the two different treatment strategies, TTT versus usual care, for management of chronic gout in a real-world setting.",Comparative Effectiveness of Treat-To-Target Approach versus Routine Care in Management of Gout,9659038,R01AR073314,"['Acute', 'Affect', 'Algorithms', 'Allopurinol', 'American', 'American College of Physicians', 'Bioinformatics', 'Body mass index', 'Cardiovascular Diseases', 'Caring', 'Chronic', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Comorbidity', 'Coronary', 'Creatinine', 'Crystallization', 'Data', 'Data Set', 'Databases', 'Drug Prescriptions', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'European', 'Flare', 'Glomerular Filtration Rate', 'Gold', 'Gout', 'Guidelines', 'Health Care Costs', 'Health Insurance', 'Healthcare', 'Heart failure', 'High Prevalence', 'Hospitalization', 'Hospitals', 'Hypertension', 'Hyperuricemia', 'Impairment', 'Inflammatory', 'Inflammatory Arthritis', 'Inpatients', 'Joints', 'Kidney Diseases', 'Laboratories', 'Link', 'Literature', 'Medical Societies', 'Medicare', 'Medicare Part A', 'Medicare claim', 'Methods', 'Monitor', 'Myocardial Infarction', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Outpatients', 'Pain', 'Patients', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Physical Function', 'Physiological', 'Prevalence', 'Procedures', 'Prognostic Factor', 'Quality of life', 'Randomized Controlled Trials', 'Renal function', 'Research Proposals', 'Rheumatism', 'Rheumatology', 'Risk', 'Role', 'Serum', 'Societies', 'Statistical Methods', 'Stroke', 'Symptoms', 'Time', 'Tissues', 'Urate', 'Uric Acid', 'Visit', 'Work', 'active comparator', 'base', 'cardiovascular disorder risk', 'clinical practice', 'college', 'comparative effectiveness', 'comparative trial', 'cost', 'demographics', 'design', 'disability', 'drug efficacy', 'effectiveness research', 'efficacy study', 'electronic data', 'epidemiology study', 'febuxostat', 'human old age (65+)', 'improved', 'innovation', 'insurance claims', 'mortality', 'population based', 'rheumatologist', 'routine care', 'tool', 'treatment as usual', 'treatment guidelines', 'treatment strategy', 'water solubility', 'xanthine oxidase inhibitor']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,492573,0.03066068467691293
"Advancing Quality and Outcomes Measurement in Rheumatology PROJECT SUMMARY Healthcare has changed rapidly in the last decade with the widespread use of electronic health records (EHRs) and the creation of national EHR-based data networks that aim to improve the quality of care. The American College of Rheumatology's RISE registry is a federally Qualified Clinical Data Registry that collects EHR data from the practices of almost 1000 rheumatologists nationally, analyzes these data centrally, and continuously feeds back performance on quality measures to practices via a web-based dashboard. In this K24 proposal, the applicant proposes to utilize novel methods in clinical informatics to increase the accuracy of quality measurement, while also developing and testing new EHR-based quality measures relevant to rheumatic diseases. The proposed research will leverage her strong research portfolio, including grants from the National Institute of Arthritis and Musculoskeletal and Skin Diseases and the Agency for Healthcare Research and Quality, her successful track record of achieving national endorsement for EHR-based quality measures, existing data from over 1.4 million patients in the RISE database, and the outstanding institutional environment at the University of California, San Francisco. It will also support her ongoing career development in clinical informatics methods relevant to EHR-based clinical research. For this five year K24 award proposal, she plans to increase the time spent mentoring junior investigators in the field or quality and outcomes measurement in rheumatology, with the goal of helping trainees successfully launch academic research careers in patient- oriented research. Aligned with a comprehensive mentoring plan, the proposal outlines two specific aims, including using natural language processing to increase the accuracy of EHR-based quality measurement in RISE, and developing and validating new, prototype electronic clinical quality measures to monitor and address high impact gaps in care for patients with rheumatic disease. The work will prioritize outcome measures and use eMeasurement standards, including the Quality Data Model and Health Quality Measures Format to develop, specify and test measures. Measures developed through this research and mentoring program will be candidates for nationwide dissemination across rheumatology practices to improve care for individuals with rheumatic disease. PROJECT NARRATIVE This mid-career investigator award will support a program in patient-oriented research in rheumatic diseases at the University of California, San Francisco. The award will allow the applicant to expand her research on the development and validation of health care quality measures and support her mentoring of early investigators. The proposed research aims to create quality measures that can be deployed across rheumatology practices to improve the quality of care, while training new researchers to perform innovative patient-oriented research in the area of electronic health record-based quality and outcomes measurement.",Advancing Quality and Outcomes Measurement in Rheumatology,9873905,K24AR074534,"['Address', 'Algorithms', 'American', 'Area', 'Award', 'Back', 'Benchmarking', 'California', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Collection', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Dictionary', 'Disease', 'Electronic Health Record', 'Environment', 'Feeds', 'Foundations', 'Funding', 'Goals', 'Gout', 'Grant', 'Growth', 'Health', 'Healthcare', 'Healthcare Systems', 'High Prevalence', 'Individual', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Leadership', 'Learning', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Monitor', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Preventive care', 'Process', 'Public Health', 'Quality of Care', 'Registries', 'Research', 'Research Personnel', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Role', 'Safety', 'San Francisco', 'Scientist', 'Specific qualifier value', 'Testing', 'Text', 'Time', 'Training', 'United States', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vision', 'Work', 'base', 'career', 'career development', 'college', 'comorbidity', 'dashboard', 'data mining', 'data modeling', 'data registry', 'data standards', 'data warehouse', 'design', 'digital', 'evidence base', 'health care quality', 'improved', 'informatics infrastructure', 'innovation', 'interest', 'learning progression', 'novel', 'patient oriented', 'patient oriented research', 'patient registry', 'patient safety', 'programs', 'prototype', 'research study', 'rheumatologist', 'structured data', 'success', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K24,2020,189666,0.06391731710928626
"Advancing Quality and Outcomes Measurement in Rheumatology PROJECT SUMMARY Healthcare has changed rapidly in the last decade with the widespread use of electronic health records (EHRs) and the creation of national EHR-based data networks that aim to improve the quality of care. The American College of Rheumatology's RISE registry is a federally Qualified Clinical Data Registry that collects EHR data from the practices of almost 1000 rheumatologists nationally, analyzes these data centrally, and continuously feeds back performance on quality measures to practices via a web-based dashboard. In this K24 proposal, the applicant proposes to utilize novel methods in clinical informatics to increase the accuracy of quality measurement, while also developing and testing new EHR-based quality measures relevant to rheumatic diseases. The proposed research will leverage her strong research portfolio, including grants from the National Institute of Arthritis and Musculoskeletal and Skin Diseases and the Agency for Healthcare Research and Quality, her successful track record of achieving national endorsement for EHR-based quality measures, existing data from over 1.4 million patients in the RISE database, and the outstanding institutional environment at the University of California, San Francisco. It will also support her ongoing career development in clinical informatics methods relevant to EHR-based clinical research. For this five year K24 award proposal, she plans to increase the time spent mentoring junior investigators in the field or quality and outcomes measurement in rheumatology, with the goal of helping trainees successfully launch academic research careers in patient- oriented research. Aligned with a comprehensive mentoring plan, the proposal outlines two specific aims, including using natural language processing to increase the accuracy of EHR-based quality measurement in RISE, and developing and validating new, prototype electronic clinical quality measures to monitor and address high impact gaps in care for patients with rheumatic disease. The work will prioritize outcome measures and use eMeasurement standards, including the Quality Data Model and Health Quality Measures Format to develop, specify and test measures. Measures developed through this research and mentoring program will be candidates for nationwide dissemination across rheumatology practices to improve care for individuals with rheumatic disease. PROJECT NARRATIVE This mid-career investigator award will support a program in patient-oriented research in rheumatic diseases at the University of California, San Francisco. The award will allow the applicant to expand her research on the development and validation of health care quality measures and support her mentoring of early investigators. The proposed research aims to create quality measures that can be deployed across rheumatology practices to improve the quality of care, while training new researchers to perform innovative patient-oriented research in the area of electronic health record-based quality and outcomes measurement.",Advancing Quality and Outcomes Measurement in Rheumatology,9645973,K24AR074534,"['Address', 'Algorithms', 'American', 'Area', 'Award', 'Back', 'Benchmarking', 'California', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Collection', 'Comorbidity', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Analyses', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Dictionary', 'Disease', 'Electronic Health Record', 'Environment', 'Feeds', 'Foundations', 'Funding', 'Goals', 'Gout', 'Grant', 'Growth', 'Health', 'Healthcare', 'Healthcare Systems', 'High Prevalence', 'Individual', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Leadership', 'Learning', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Monitor', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Preventive care', 'Process', 'Public Health', 'Quality of Care', 'Registries', 'Research', 'Research Personnel', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Role', 'Safety', 'San Francisco', 'Scientist', 'Specific qualifier value', 'Structure', 'Testing', 'Text', 'Time', 'Training', 'United States', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vision', 'Work', 'base', 'career', 'career development', 'college', 'dashboard', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'design', 'digital', 'evidence base', 'feeding', 'health care quality', 'improved', 'informatics infrastructure', 'innovation', 'interest', 'learning progression', 'novel', 'patient oriented', 'patient oriented research', 'patient registry', 'patient safety', 'programs', 'prototype', 'research study', 'rheumatologist', 'success', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K24,2019,189666,0.06391731710928626
"Identification of biologically relevant subtypes of hidradenitis suppurativa Project Summary Hidradenitis suppurativa (HS) is a neglected, prevalent, chronic, stigmatizing, and debilitating disease that has recently been prioritized for study by NIAMS. Evidence suggests that some HS patients choose to self-manage symptoms remaining unconnected to healthcare, and some seek medical care for repeated outbreaks of boils but never receive a diagnosis. Such hidden populations create challenges for designing research studies that are generalizable. Precision medicine initiatives and resources offer opportunities to rapidly increase our knowledge about biological causes of HS and to improve the care that HS patients receive. For example, the NIH has made considerable investments in the development of data repositories that link genetic data to EHR for hundreds of thousands of patients, including the NHGRI-funded eMERGE Network and the NIH-funded All of Us Research Program. Columbia University investigators are integral members of these nationwide programs, both as a recruitment site, as well as a data and research center (5U01HG008680, 1OT2OD026556). Engaging research participants who are willing to contribute longitudinal data is a major obstacle to precision medicine initiatives. The publics use of the Internet and social media to obtain and exchange health-related information has created opportunities to rapidly and efficiently assemble large longitudinal cohorts, yet there are important differences from traditional research methods and best practice guidelines have yet to be developed. Columbia University is at the forefront of the development and application of these methods. A major challenge to implementing precision medicine arises from patients who share a diagnosis but have different biological causes of disease. HS patients have a high burden of comorbidities and we hypothesize that sets of comorbidities that tend to present together in individual patients can be used to identify biologically relevant disease subtypes. Here we will use three approaches to identify patterns of comorbidities within patients, to characterize the generalizability of the results from studies conducted in EHR, and to use genetic data to biologically validate comorbidities and resolve causality underlying disease associations. Training in biomedical informatics and Internet-based survey research will allow the applicant to use EHR data and Internet resources for assembling cohorts to conduct these studies, and complement her previous training in epidemiology, biostatistics, molecular biology and human genetics, providing fluency across several domains that are crucial for advancing precision medicine initiatives. Completion of this proposal will achieve the applicants long-term goal of obtaining advanced training aimed at implementing precision medicine in the treatment of skin disease. Project Narrative This project addresses the imperative needs of hidradenitis suppurativa (HS) patients who suffer from pain, stigma, diminished quality of life, decreased work productivity, and increased healthcare costs that arise from managing a difficult-to-treat, debilitating disease with a high burden of comorbidities. We will conduct studies of HS comorbidities to identify biologically distinct subclasses of HS in large samples of patients using data in electronic health records and data collected from Internet surveys. This work will improve the precision of HS diagnoses and set up the infrastructure for future large-scale studies of HS.",Identification of biologically relevant subtypes of hidradenitis suppurativa,9977561,K01AR075111,"['Abscess', 'Address', 'Advertising', 'Affect', 'All of Us Research Program', 'Anogenital region', 'Attenuated', 'Automobile Driving', 'Axilla', 'Biological', 'Biology', 'Biometry', 'Caring', 'Chronic', 'Cicatrix', 'Clinical', 'Code', 'Communities', 'Complement', 'Consent', 'Data', 'Data Reporting', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Economic Burden', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Enrollment', 'Epidemiology', 'Etiology', 'Funding', 'Furuncles', 'Future', 'Genetic', 'Genetic Risk', 'Genome', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Heterogeneity', 'Hidradenitis Suppurativa', 'Human Genetics', 'Individual', 'Infrastructure', 'Inguinal region', 'International Classification of Disease Codes', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Leg', 'Lesion', 'Link', 'Liquid substance', 'Literature', 'Longitudinal cohort', 'Maps', 'Medical', 'Medical Research', 'Methods', 'Molecular Biology', 'Molecular Diagnosis', 'Mutation', 'National Human Genome Research Institute', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Pain', 'Participant', 'Pathogenesis', 'Patient Care', 'Patients', 'Pattern', 'Phenotype', 'Physiological', 'Plant Roots', 'Population', 'Practice Guidelines', 'Precision Medicine Initiative', 'Prevalence', 'Productivity', 'Publishing', 'Quality of life', 'Randomized', 'Recording of previous events', 'Records', 'Recurrence', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Site', 'Stigmatization', 'Subgroup', 'Surveys', 'Symptoms', 'Syndrome', 'Testing', 'Time', 'Training', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Universities', 'Validation', 'Work', 'arm', 'base', 'biomedical informatics', 'clinical Diagnosis', 'cohort', 'comorbidity', 'data resource', 'data sharing', 'data warehouse', 'design', 'disorder subtype', 'effective therapy', 'genome wide association study', 'health care service utilization', 'health data', 'improved', 'individual patient', 'instrument', 'large datasets', 'learning strategy', 'medically underserved', 'member', 'multidimensional data', 'neglect', 'online resource', 'patient engagement', 'patient stratification', 'patient subsets', 'precision medicine', 'prevent', 'programs', 'psychosocial', 'recruit', 'research study', 'skin disorder', 'social media', 'social stigma', 'symptom self management', 'tool', 'unsupervised learning', 'validation studies']",NIAMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2020,121288,-0.005206430688171566
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7672256,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Readability', 'Reader', 'Reading', 'Self Care', 'Self Management', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'fourth grade', 'improved', 'instrument', 'literacy', 'ninth grade', 'patient oriented', 'prevent', 'programs', 'tenth grade', 'tool', 'web site']",NIDDK,UNIVERSITY OF UTAH,R01,2009,398216,0.03796018753938722
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7475712,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2008,438476,0.03796018753938722
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7671784,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2008,48482,0.03796018753938722
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7303652,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2007,435682,0.03796018753938722
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance  existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of  health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted  readability levels with no critical information loss, using statistical natural language processing  techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive  impact on reader comprehension. We will use as a test bed for our system a general internal medicine  clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public. n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7492453,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2007,47853,0.03796018753938722
"An In Silico, Medical Record-based Model for Understanding the INitiation of Autoimmune Events (IMMUNE) Abstract More than 80% of cancer patients who undergo immune checkpoint inhibitor (ICI) therapy experience immune related adverse events, including autoimmunity, following treatment. The etiology of autoimmune disease in humans is poorly understood and effective treatments are limited. Inbred mice are a valuable tool for understanding basic biological mechanisms of disease, but are less effective for understanding human autoimmunity. Therefore, it is critical to develop minimally invasive human models to provide real world insights into the mechanisms, development and therapy for autoimmunity. The widespread use of electronic health records (EHRs) in healthcare and the depth of data collected for cancer patients, presents an important opportunity to identify risk factors for the development of autoimmune disease following immunotherapy. Our project brings together a team of immunologists, oncologists, informaticists and machine learning experts working within an EHR network, to identify a cohort of cancer patients who have undergone ICI therapy. From this cohort we will design and implement a broad and deep longitudinal database of EHR data, including treatment and response data and laboratory results, to enable the development of phenotypic profiles and models for autoimmune disease development in humans. The overarching goal of this project proposal is to test the feasibility and effectiveness of using a hybrid in silico / in vivo model system combined with machine learning strategies as a platform for understanding the etiology of autoimmune disease. In the R61 Phase we propose to identify patients who develop rheumatoid arthritis (RA) in the in the presence or absence of cancer, and control cohort, using a physician-validated cohort of cancer patients and data from EHR, and use machine learning strategies to develop phenotypic profiles for RA in the presence or absence of cancer and ICI therapy. In the R33 Phase we will and develop and assess phenotypic profiles for global biomarkers tolerance disruption using machine learning and determine if family history is a predictor of the development of autoimmunity following ICI therapy. Our proposal, to develop an in silico based model for exploring the onset of autoimmunity, makes a leap forward for translational immunology and the exploration of mechanisms of human autoimmune disease development by leveraging the power of the information collected in EHR to predict outcomes. The phenotypic profiles developed could significantly accelerate precision medicine approaches for employing ICIs that minimize the potential autoimmune disease based on personal genetic, environmental and social information. NARRATIVE More than 80% of cancer patients who undergo immune checkpoint inhibitor (ICI) therapy experience immune related adverse events, including autoimmunity, following treatment. The overarching goal of this proposal is to test the feasibility and effectiveness of using a physician-validated cohort of cancer patients combined with data from electronic health records (EHRs), and with machine learning strategies as a platform for understanding the mechanisms of human autoimmune disease. The developed model could significantly accelerate precision medicine approaches for employing ICI therapy that minimize potential autoimmune disease based on personal genetic, environmental and social information.","An In Silico, Medical Record-based Model for Understanding the INitiation of Autoimmune Events (IMMUNE)",9912591,R61AR076824,"['Adverse effects', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Biological', 'Biological Markers', 'Biological Models', 'Cancer Control', 'Cancer Patient', 'Classification', 'Clinical Data', 'Cohort Studies', 'Computer Simulation', 'Data', 'Development', 'Disease', 'Electronic Health Record', 'Etiology', 'Event', 'Family', 'Funding', 'Genetic', 'Genomics', 'Goals', 'Health', 'Healthcare', 'Human', 'Hybrids', 'Immune Tolerance', 'Immune checkpoint inhibitor', 'Immunologist', 'Immunology', 'Immunotherapy', 'Inbred Mouse', 'Individual', 'Institution', 'Insulin-Dependent Diabetes Mellitus', 'Laboratories', 'Low Prevalence', 'Machine Learning', 'Malignant Neoplasms', 'Medical Records', 'Modeling', 'National Human Genome Research Institute', 'Oncologist', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Physicians', 'Recording of previous events', 'Research', 'Rheumatoid Arthritis', 'Risk Factors', 'Supervision', 'System', 'Testing', 'Touch sensation', 'Use Effectiveness', 'base', 'checkpoint therapy', 'clinical care', 'cohort', 'data modeling', 'design', 'effective therapy', 'electronic data', 'experience', 'human model', 'immune-related adverse events', 'in vivo Model', 'insight', 'learning strategy', 'longitudinal database', 'minimally invasive', 'multidisciplinary', 'novel', 'outcome prediction', 'portability', 'precision medicine', 'profiles in patients', 'social', 'tool', 'treatment response', 'unsupervised learning']",NIAMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R61,2019,395000,0.029774834795756457
"Sarcopenia: computable phenotypes and clinical outcomes. PROJECT SUMMARY  Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function. Sarcopenia contributes to disability, increased hospitalizations, healthcare costs, and risk of death. Despite being under- recognized clinically, sarcopenia is a major public health concern, with the worldwide prevalence projected to increase by up to 72% in the next 30 years. However, limited knowledge of sarcopenia among clinicians, combined with time pressures in clinical encounters delay its detection, and limit opportunity for intervention or recruitment into clinical trials. To overcome this barrier to detecting sarcopenia, we propose to use advanced big data and machine learning methods to identify additional component variables predicting sarcopenia among the rich electronic health record (EHR) data and develop a validated and portable sarcopenia computable phenotype (which uses a computer algorithm to detect patient characteristics or outcomes from the EHR). This innovative proposal takes advantage of key resources at Indiana University and its affiliation with the Regenstrief Institute and the Indiana Network for Patient Care (INPC), a statewide multi-health system clinical data warehouse including >100 healthcare entities and >18 million unique patients with both coded and text-based data, combined with the ability to perform comprehensive musculoskeletal measurements in the Musculoskeletal Function Imaging and Tissue (MSK-FIT) Core funded through a NIAMS Core Center for Clinical Research grant (P30AR072581). Our long-term goal is to accurately identify patients with, or at risk for, sarcopenia and its consequences in order to provide targeted interventions. We hypothesize that by using medical informatics and machine learning innovations, computable phenotypes can identify patients with sarcopenia from the EHR, predict deficits in measured muscle strength and physical function, and prospectively predict risk of hospitalization and death. In Aim 1, we will categorize >2000 adult participants in the MSK-FIT Core with accessible EHR data, as either sarcopenic or nonsarcopenic according to measurements of muscle strength, muscle mass and physical performance. We will then use 75% of the MSK- FIT Core cohort to train machine deep learning algorithms to detect combinations of variables from these subjects EHR predicting whether the patient is sarcopenic or not sarcopenic. The performance of the resulting computable phenotype will then be tested in the remaining 25% of the MSK-FIT Core participants. In Aim 2, we will test the performance of the sarcopenia computable phenotype to detect a clinically meaningful phenotype in the entire INPC adult population (>18 million), by evaluating the ability to predict the rate of hospitalizations and death among patients rated as sarcopenic versus matched controls. Such a computable phenotype will then enable large scale targeted recruitment, pragmatic clinical trials, clinical evaluation and intervention. PROJECT NARRATIVE Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function, and contributing to disability, increased hospitalizations and risk of death. Despite being underrecognized clinically, sarcopenia is a major public health concern, with projected large increases in its prevalence worldwide. The overall goal of this grant is to use advanced, state-of-the art biomedical informatics and big data methods to generate a tool using electronic health record data to detect patients with sarcopenia early and facilitate patient recruitment, engagement and clinical interventions to treat sarcopenia.",Sarcopenia: computable phenotypes and clinical outcomes.,9970930,R01AR077273,"['Adult', 'Aging', 'Algorithms', 'Automated Clinical Decision Support', 'Awareness', 'Big Data', 'Big Data Methods', 'Birth', 'Cessation of life', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Computational algorithm', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Diet', 'Disease', 'Electronic Health Record', 'Exercise', 'Funding', 'Goals', 'Grant', 'Hand Strength', 'Health Care Costs', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Image', 'Impairment', 'Indiana', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical Informatics', 'Methods', 'Muscle', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Outcome', 'Participant', 'Patient Care', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmacology', 'Phenotype', 'Physical Function', 'Physical Performance', 'Physicians', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Process', 'Provider', 'Public Health', 'Public Health Informatics', 'Publishing', 'Race', 'Reporting', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Supervision', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'Universities', 'age group', 'base', 'biomedical informatics', 'clinical center', 'clinical data warehouse', 'clinical encounter', 'cohort', 'comorbidity', 'computable phenotypes', 'deep learning algorithm', 'disability', 'electronic data', 'experience', 'hospitalization rates', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality risk', 'muscle form', 'muscle strength', 'performance tests', 'physical conditioning', 'population health', 'portability', 'pressure', 'prevent', 'prospective', 'ranpirnase', 'recruit', 'reduced muscle mass', 'research clinical testing', 'sarcopenia', 'sex', 'text searching', 'tool']",NIAMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2020,235788,0.032212386651456315
"Probabilistic Modeling of Information from Images and Text in Online Journals    DESCRIPTION (provided by applicant): The goal of this project is to build a software toolkit that will enable a biologist to create, from a collection of on-line articles, a database of protein subcellular localization information that can be queried, browsed, or used to support data-mining activities. We have developed a system, called SLIF, which can harvest fluorescence microscope images from online papers, analyze them using image-processing methods, and annotate them with information appearing in the accompanying textual description. We propose to improve and extend this system so as to produce a robust, comprehensive toolkit for extracting information about subcellular localization from the text and images found in online journals, as well as analyzing, verifying and querying the resulting body of information.           n/a",Probabilistic Modeling of Information from Images and Text in Online Journals,7458122,R01GM078622,"['3-Dimensional', 'Architecture', 'Area', 'Arts', 'Biomedical Research', 'Blast Cell', 'Classification', 'Collection', 'Computer software', 'Condition', 'Data', 'Data Set', 'Databases', 'Depth', 'Exhibits', 'Facility Construction Funding Category', 'Feeds', 'Fluorescence Microscopy', 'Future', 'Genes', 'Glycine decarboxylase', 'Goals', 'Harvest', 'Image', 'Individual', 'Journals', 'Literature', 'Location', 'Measures', 'Methods', 'Names', 'Numbers', 'Ontology', 'Operative Surgical Procedures', 'Paper', 'Pattern', 'Property', 'Protein Databases', 'Proteins', 'Proteomics', 'PubMed', 'Publications', 'Range', 'Reading', 'Research Personnel', 'Resources', 'Sampling', 'Scientist', 'Semantics', 'Standards of Weights and Measures', 'Statistical Models', 'Structure', 'Subcellular structure', 'System', 'Text', 'Time', 'Work', 'abstracting', 'base', 'cell type', 'data mining', 'fluorescence microscope', 'genome sequencing', 'high throughput screening', 'image processing', 'improved', 'intracellular protein transport', 'open source', 'programs', 'protein localization location', 'research study', 'text searching', 'tool', 'two-dimensional']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2008,255967,0.012871648534967566
"Probabilistic Modeling of Information from Images and Text in Online Journals    DESCRIPTION (provided by applicant): The goal of this project is to build a software toolkit that will enable a biologist to create, from a collection of on-line articles, a database of protein subcellular localization information that can be queried, browsed, or used to support data-mining activities. We have developed a system, called SLIF, which can harvest fluorescence microscope images from online papers, analyze them using image-processing methods, and annotate them with information appearing in the accompanying textual description. We propose to improve and extend this system so as to produce a robust, comprehensive toolkit for extracting information about subcellular localization from the text and images found in online journals, as well as analyzing, verifying and querying the resulting body of information.           n/a",Probabilistic Modeling of Information from Images and Text in Online Journals,7241547,R01GM078622,"['3-Dimensional', 'Architecture', 'Area', 'Arts', 'Biomedical Research', 'Blast Cell', 'Classification', 'Collection', 'Computer software', 'Condition', 'Data', 'Data Set', 'Databases', 'Depth', 'Exhibits', 'Facility Construction Funding Category', 'Feeds', 'Fluorescence Microscopy', 'Future', 'Genes', 'Glycine decarboxylase', 'Goals', 'Harvest', 'Image', 'Individual', 'Journals', 'Literature', 'Location', 'Measures', 'Methods', 'Names', 'Numbers', 'Ontology', 'Operative Surgical Procedures', 'Paper', 'Pattern', 'Property', 'Protein Databases', 'Proteins', 'Proteomics', 'PubMed', 'Publications', 'Range', 'Reading', 'Research Personnel', 'Resources', 'Sampling', 'Scientist', 'Semantics', 'Standards of Weights and Measures', 'Statistical Models', 'Structure', 'Subcellular structure', 'System', 'Text', 'Time', 'Work', 'abstracting', 'base', 'cell type', 'data mining', 'fluorescence microscope', 'genome sequencing', 'high throughput screening', 'image processing', 'improved', 'intracellular protein transport', 'open source', 'programs', 'protein localization location', 'research study', 'text searching', 'tool', 'two-dimensional']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2007,256309,0.012871648534967566
"Distributed, Collaborative Intelligent Agents for Proactive Post-Marketing Drug S    DESCRIPTION (provided by applicant): Healthcare systems and insurers nationwide regularly make decisions regarding which drugs to include or exclude from their formularies based on evidence concerning benefits, risks, and costs of the medications. A major barrier to effective drug selection is the lack of sufficient published information on the safety of drugs, particularly new drugs. A computerized system operating at healthcare facilities that could provide continuous, active surveillance and timely identification of potential safety issues following the introduction of a new drug to a formulary is highly desirable. Such a system could lead to safer drug use policy, more cost-effective formulary decisions, better healthcare, and earlier detection of adverse drug reactions (ADRs). The implications of such technology for improving a national drug surveillance system will be apparent because ADRs can complicate the patient's medical condition, increase morbidity, and result in death (about 7,000 deaths per year in the U.S. were attributed to ADRs). At present, evidence on safety issues that would inform these decisions is generated primarily by the FDA's post-marketing surveillance system MedWatch(tm). MedWatch(tm) is a passive system that depends on voluntary, spontaneous reports. Because the system is limited by low reporting rates and the slow accumulation of sufficient events to enable a critical analysis, delays occur in the identification and withdrawal of problematic drugs from the market or labeling them with black box warnings. These delays have resulted in unnecessary mortality, morbidity, and costs of healthcare.   We propose to develop an innovative team-based agent system, named ADRMonitor, for actively monitoring and detecting signal pairs implicating anticipated or potential ADRs at a healthcare facility. Each ADRMonitor user (e.g., physicians and drug safety officers) will have his/her own software agent that is accessible via the Internet and plays two roles -- assisting the user in his/her decision-making, and collaborating with agents of other team members. A key feature of the proposed approach is that the agents will continuously and autonomously collaborate with one another. They anticipate information needs of their teammates and share information proactively so that the users can be alerted timely about signal pairs.    To demonstrate the feasibility, we plan to develop a prototype of ADRMonitor in this two-year pilot project, which will be undertaken collaboratively by our multidisciplinary team. Our preliminary design and analysis show the proposed methodology to be promising. The proposed effort represents a critical first step toward a subsequent development of a more comprehensive ADRMonitor in later phases of this research endeavor that would use the signal pairs to detect ADRs and expand the resultant system to cover healthcare in a region or across the country. The proposed methodology is general in nature and can be adapted for other important applications such as bioterrorism surveillance.    PUBLIC HEALTH RELEVANCE: A computerized system operating at healthcare facilities that could provide continuous, active surveillance and timely identification of potential safety issues following the introduction of a new drug to a formulary is highly desirable. Such a system could lead to safer drug use policy, more cost-effective formulary decisions, better healthcare, and earlier detection of adverse drug reactions (ADRs). The implications of such technology for improving a national drug surveillance system will be apparent because ADRs can complicate the patient's medical condition, increase morbidity, and result in death (about 7,000 deaths per year in the U.S. were attributed to ADRs).          n/a","Distributed, Collaborative Intelligent Agents for Proactive Post-Marketing Drug S",7677848,R21GM082821,"['Address', 'Adverse reactions', 'Antihypertensive Agents', 'Architecture', 'Artificial Intelligence', 'Benefits and Risks', 'Bioterrorism', 'Boxing', 'Cessation of life', 'Cisapride', 'Clinical', 'Clinical Medicine', 'Cognitive', 'Computer software', 'Computerized Medical Record', 'Country', 'Data Security', 'Decision Making', 'Detection', 'Development', 'Dose', 'Drug usage', 'Early Diagnosis', 'Event', 'Family Practice', 'Formularies', 'Frequencies', 'Health Care Costs', 'Health care facility', 'Healthcare', 'Healthcare Systems', 'Insurance Carriers', 'Internal Medicine', 'Internet', 'Label', 'Lead', 'Literature', 'Marketing', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Nature', 'Operating System', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Phase', 'Physicians', 'Pilot Projects', 'Play', 'Policies', 'Publishing', 'Reaction', 'Reporting', 'Research', 'Risk', 'Role', 'Safety', 'Signal Transduction', 'System', 'Technology', 'Testing', 'Uncertainty', 'Universities', 'Withdrawal', 'base', 'cohort', 'computerized', 'cost', 'design', 'drug market', 'effective therapy', 'empowered', 'improved', 'information processing', 'innovation', 'interest', 'member', 'mortality', 'multidisciplinary', 'novel', 'patient privacy', 'post-market', 'prototype', 'public health relevance', 'software development']",NIGMS,WAYNE STATE UNIVERSITY,R21,2009,178089,0.03660085014901502
"Distributed, Collaborative Intelligent Agents for Proactive Post-Marketing Drug S    DESCRIPTION (provided by applicant): Healthcare systems and insurers nationwide regularly make decisions regarding which drugs to include or exclude from their formularies based on evidence concerning benefits, risks, and costs of the medications. A major barrier to effective drug selection is the lack of sufficient published information on the safety of drugs, particularly new drugs. A computerized system operating at healthcare facilities that could provide continuous, active surveillance and timely identification of potential safety issues following the introduction of a new drug to a formulary is highly desirable. Such a system could lead to safer drug use policy, more cost-effective formulary decisions, better healthcare, and earlier detection of adverse drug reactions (ADRs). The implications of such technology for improving a national drug surveillance system will be apparent because ADRs can complicate the patient's medical condition, increase morbidity, and result in death (about 7,000 deaths per year in the U.S. were attributed to ADRs). At present, evidence on safety issues that would inform these decisions is generated primarily by the FDA's post-marketing surveillance system MedWatch(tm). MedWatch(tm) is a passive system that depends on voluntary, spontaneous reports. Because the system is limited by low reporting rates and the slow accumulation of sufficient events to enable a critical analysis, delays occur in the identification and withdrawal of problematic drugs from the market or labeling them with black box warnings. These delays have resulted in unnecessary mortality, morbidity, and costs of healthcare.   We propose to develop an innovative team-based agent system, named ADRMonitor, for actively monitoring and detecting signal pairs implicating anticipated or potential ADRs at a healthcare facility. Each ADRMonitor user (e.g., physicians and drug safety officers) will have his/her own software agent that is accessible via the Internet and plays two roles -- assisting the user in his/her decision-making, and collaborating with agents of other team members. A key feature of the proposed approach is that the agents will continuously and autonomously collaborate with one another. They anticipate information needs of their teammates and share information proactively so that the users can be alerted timely about signal pairs.    To demonstrate the feasibility, we plan to develop a prototype of ADRMonitor in this two-year pilot project, which will be undertaken collaboratively by our multidisciplinary team. Our preliminary design and analysis show the proposed methodology to be promising. The proposed effort represents a critical first step toward a subsequent development of a more comprehensive ADRMonitor in later phases of this research endeavor that would use the signal pairs to detect ADRs and expand the resultant system to cover healthcare in a region or across the country. The proposed methodology is general in nature and can be adapted for other important applications such as bioterrorism surveillance.    PUBLIC HEALTH RELEVANCE: A computerized system operating at healthcare facilities that could provide continuous, active surveillance and timely identification of potential safety issues following the introduction of a new drug to a formulary is highly desirable. Such a system could lead to safer drug use policy, more cost-effective formulary decisions, better healthcare, and earlier detection of adverse drug reactions (ADRs). The implications of such technology for improving a national drug surveillance system will be apparent because ADRs can complicate the patient's medical condition, increase morbidity, and result in death (about 7,000 deaths per year in the U.S. were attributed to ADRs).          n/a","Distributed, Collaborative Intelligent Agents for Proactive Post-Marketing Drug S",7532069,R21GM082821,"['Address', 'Adverse reactions', 'Antihypertensive Agents', 'Architecture', 'Artificial Intelligence', 'Benefits and Risks', 'Bioterrorism', 'Boxing', 'Cessation of life', 'Cisapride', 'Class', 'Clinical', 'Clinical Medicine', 'Cognitive', 'Computer information processing', 'Computer software', 'Computerized Medical Record', 'Condition', 'Country', 'Data Security', 'Decision Making', 'Detection', 'Development', 'Dose', 'Drug usage', 'Early Diagnosis', 'Event', 'Family Practice', 'Formularies', 'Frequencies', 'Health Care Costs', 'Health care facility', 'Healthcare', 'Healthcare Systems', 'Insurance Carriers', 'Internal Medicine', 'Internet', 'Label', 'Lead', 'Literature', 'Marketing', 'Medical', 'Medical Surveillance', 'Medical center', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Nature', 'Operating System', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Phase', 'Physicians', 'Pilot Projects', 'Play', 'Policies', 'Population Surveillance', 'Publishing', 'Rate', 'Reaction', 'Reporting', 'Research', 'Risk', 'Role', 'Safety', 'Signal Transduction', 'System', 'Technology', 'Testing', 'Uncertainty', 'United States Food and Drug Administration', 'Universities', 'Withdrawal', 'base', 'cohort', 'computerized', 'cost', 'design', 'drug market', 'improved', 'innovation', 'interest', 'member', 'mortality', 'multidisciplinary', 'novel', 'patient privacy', 'post-market', 'prototype', 'software development']",NIGMS,WAYNE STATE UNIVERSITY,R21,2008,228780,0.03660085014901502
"Childhood obesity surveillance using electronic health records data     DESCRIPTION (provided by applicant): Childhood obesity is associated with high financial cost and increased morbidity and mortality in adulthood. Health care spending due to obesity is estimated to be as high as \$210 billion annually, or 21\% of total national spending. A childhood obesity surveillance system will discern disparities, detect aberrant signals, design targeted interventions, and track change over time. In addition to national public health surveillance systems, local data are increasingly necessary to reflect regional trends. Current systems in Wisconsin are subject to (1) bias estimation of obesity rates, (2) limited data in school-aged children ages 5-10 years, (3) insufficient power to estimate disparities in local subgroups, and (4) limited ability to track local changes over time. Therefore, the impact of investments and collective efforts in Wisconsin childhood obesity prevention has been difficult to measure. This, in turn, demands approaches that overcome and transcend the posited limitations. Since large electronic health records (EHRs) systems have been developed to routinely collect information over time, there has been a paradigm shift and accelerated improvements in the use of EHR data for the purpose of population health promotion and tracking of progress. The University of Wisconsin Population Health Information Exchange (PHINEX) database contains de- identified EHR data from a multicenter healthcare system located primarily in south central Wisconsin. In partnership with The Wisconsin Obesity Prevention Initiative, we aim to create an EHR model for a childhood obesity prevention surveillance system. We propose to develop innovative statistical machine learning methods using the platform of PHINEX for childhood obesity prevention purposes. This enhance and extend surveillance activities of childhood obesity conditions, and increase the effectiveness of evidence-based interventions aimed at changing policies, systems, and environments associated with childhood obesity. We plan to address the following aims: (1) robust estimation of the spatiotemporal prevalence at area level, (2) hot spot detection on areas with aberrant obesity incidence, and (3) prediction for childhood weight gain phenotypes. The developed and implemented surveillance system can benefit future planning, legislation and implementation in other states and/or surveillance of other acute and chronic health conditions. PUBLIC HEALTH RELEVANCE: Childhood obesity has emerged as a leading health concern in the 21st century. Current data sources from which childhood obesity estimates are derived in most systems are primarily cross-sectional, are from small sample sizes, and/or have limited generalizability. Large electronic health records (EHRs) systems have been developed to routinely collect information over time, which provide unprecedented opportunities for individual and population health surveillance. We propose to develop innovative statistical machine learning methods to increase the use of large EHR data for childhood obesity prevention purposes, extending the scope of public health surveillance.",Childhood obesity surveillance using electronic health records data,9328110,R21HD086754,"['Accounting', 'Acute', 'Address', 'Adolescent', 'Adult', 'Affordable Care Act', 'Age', 'Area', 'Biometry', 'Caring', 'Child', 'Childhood', 'Chronic', 'Clinical Informatics', 'Collaborations', 'Comorbidity', 'Complement', 'Complex', 'County', 'Data', 'Data Collection', 'Data Sources', 'Databases', 'Decision Making', 'Detection', 'Development', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Environment', 'Epidemiology', 'Evaluation', 'Evidence based intervention', 'Family Practice', 'Financial cost', 'Future', 'Geography', 'Goals', 'Growth', 'Health', 'Health Care Costs', 'Health Personnel', 'Health Promotion', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Hot Spot', 'Incidence', 'Individual', 'Interdisciplinary Study', 'Intervention', 'Investments', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Municipalities', 'Obesity', 'Overweight', 'Phenotype', 'Policies', 'Population Surveillance', 'Prevalence', 'Prevention strategy', 'Protocols documentation', 'Reporting', 'Risk', 'Risk Factors', 'Sample Size', 'School-Age Population', 'Signal Transduction', 'Smiling', 'Statistical Methods', 'Statistical Models', 'Statutes and Laws', 'Subgroup', 'System', 'Techniques', 'Time', 'Transcend', 'Uncertainty', 'United States', 'Universities', 'Variant', 'Weight Gain', 'Wisconsin', 'Work', 'base', 'cost', 'cost effective', 'data resource', 'data structure', 'design', 'evidence base', 'improved', 'innovation', 'interest', 'intervention program', 'learning strategy', 'mortality', 'novel', 'obesity in children', 'obesity prevention', 'population based', 'population health', 'public health intervention', 'public health relevance', 'spatiotemporal', 'statistics', 'success', 'tool', 'trend', 'user friendly software']",NICHD,FRED HUTCHINSON CANCER RESEARCH CENTER,R21,2017,259287,0.06510305481158336
"Childhood obesity surveillance using electronic health records data     DESCRIPTION (provided by applicant): Childhood obesity is associated with high financial cost and increased morbidity and mortality in adulthood. Health care spending due to obesity is estimated to be as high as \$210 billion annually, or 21\% of total national spending. A childhood obesity surveillance system will discern disparities, detect aberrant signals, design targeted interventions, and track change over time. In addition to national public health surveillance systems, local data are increasingly necessary to reflect regional trends. Current systems in Wisconsin are subject to (1) bias estimation of obesity rates, (2) limited data in school-aged children ages 5-10 years, (3) insufficient power to estimate disparities in local subgroups, and (4) limited ability to track local changes over time. Therefore, the impact of investments and collective efforts in Wisconsin childhood obesity prevention has been difficult to measure. This, in turn, demands approaches that overcome and transcend the posited limitations. Since large electronic health records (EHRs) systems have been developed to routinely collect information over time, there has been a paradigm shift and accelerated improvements in the use of EHR data for the purpose of population health promotion and tracking of progress. The University of Wisconsin Population Health Information Exchange (PHINEX) database contains de- identified EHR data from a multicenter healthcare system located primarily in south central Wisconsin. In partnership with The Wisconsin Obesity Prevention Initiative, we aim to create an EHR model for a childhood obesity prevention surveillance system. We propose to develop innovative statistical machine learning methods using the platform of PHINEX for childhood obesity prevention purposes. This enhance and extend surveillance activities of childhood obesity conditions, and increase the effectiveness of evidence-based interventions aimed at changing policies, systems, and environments associated with childhood obesity. We plan to address the following aims: (1) robust estimation of the spatiotemporal prevalence at area level, (2) hot spot detection on areas with aberrant obesity incidence, and (3) prediction for childhood weight gain phenotypes. The developed and implemented surveillance system can benefit future planning, legislation and implementation in other states and/or surveillance of other acute and chronic health conditions.         PUBLIC HEALTH RELEVANCE: Childhood obesity has emerged as a leading health concern in the 21st century. Current data sources from which childhood obesity estimates are derived in most systems are primarily cross-sectional, are from small sample sizes, and/or have limited generalizability. Large electronic health records (EHRs) systems have been developed to routinely collect information over time, which provide unprecedented opportunities for individual and population health surveillance. We propose to develop innovative statistical machine learning methods to increase the use of large EHR data for childhood obesity prevention purposes, extending the scope of public health surveillance.            ",Childhood obesity surveillance using electronic health records data,9018958,R21HD086754,"['Accounting', 'Acute', 'Address', 'Adolescent', 'Adult', 'Affordable Care Act', 'Age', 'Area', 'Biometry', 'Caring', 'Child', 'Childhood', 'Chronic', 'Clinical Informatics', 'Collaborations', 'Comorbidity', 'Complement', 'Complex', 'County', 'Data', 'Data Collection', 'Data Sources', 'Databases', 'Decision Making', 'Detection', 'Development', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Environment', 'Epidemiology', 'Evaluation', 'Evidence based intervention', 'Family Practice', 'Financial cost', 'Future', 'Geography', 'Goals', 'Growth', 'Health', 'Health Care Costs', 'Health Personnel', 'Health Promotion', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Hot Spot', 'Incidence', 'Individual', 'Intervention', 'Investments', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Obesity', 'Overweight', 'Phenotype', 'Policies', 'Population', 'Population Surveillance', 'Prevalence', 'Prevention strategy', 'Protocols documentation', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'School-Age Population', 'Signal Transduction', 'Smiling', 'Statistical Methods', 'Statistical Models', 'Statutes and Laws', 'Subgroup', 'System', 'Techniques', 'Time', 'Transcend', 'Uncertainty', 'United States', 'Universities', 'Variant', 'Weight Gain', 'Wisconsin', 'Work', 'base', 'cost', 'cost effective', 'data structure', 'design', 'evidence base', 'improved', 'innovation', 'interest', 'intervention program', 'learning strategy', 'mortality', 'novel', 'obesity in children', 'obesity prevention', 'population based', 'population health', 'public health intervention', 'public health relevance', 'spatiotemporal', 'statistics', 'success', 'tool', 'trend', 'user friendly software']",NICHD,FRED HUTCHINSON CANCER RESEARCH CENTER,R21,2016,234419,0.06510305481158336
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design.The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children. Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis.","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9864083,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Infrastructure', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Pediatric cohort', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness study', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient health information', 'patient registry', 'pediatric emergency', 'pediatric patients', 'predictive modeling', 'repository', 'risk prediction model', 'septic patients', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,611937,-0.007866146779342432
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design.The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children. Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis.","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9626417,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Infrastructure', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Pediatric cohort', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient registry', 'pediatric emergency', 'pediatric patients', 'predictive modeling', 'repository', 'risk prediction model', 'septic patients', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,616807,-0.007866146779342432
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design.The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children. Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis.","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9419932,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient registry', 'pediatric emergency', 'pediatric patients', 'predictive modeling', 'repository', 'septic patients', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2018,623932,-0.007866146779342432
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design.The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children. Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis.","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9239711,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient registry', 'pediatric patients', 'predictive modeling', 'repository', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2017,735263,-0.007866146779342432
"Real-time detection of deviations in clinical care in ICU data streams DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates belo 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.",Real-time detection of deviations in clinical care in ICU data streams,9278178,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Research', 'Research Personnel', 'Signal Transduction', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical data warehouse', 'clinical practice', 'computer science', 'cost', 'data archive', 'design', 'improved', 'individual patient', 'knowledge base', 'learning strategy', 'liver transplantation', 'multidisciplinary', 'prototype', 'public health relevance']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,543819,0.033854666638075265
"Real-time detection of deviations in clinical care in ICU data streams DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates belo 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.",Real-time detection of deviations in clinical care in ICU data streams,9095389,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Decision Making', 'Detection', 'Development', 'Electronics', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Information Systems', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Research', 'Research Personnel', 'Signal Transduction', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'data archive', 'design', 'improved', 'individual patient', 'knowledge base', 'learning strategy', 'liver transplantation', 'multidisciplinary', 'prototype']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,548500,0.033854666638075265
"Real-time detection of deviations in clinical care in ICU data streams DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates belo 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.",Real-time detection of deviations in clinical care in ICU data streams,8912480,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Decision Making', 'Detection', 'Development', 'Electronics', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Individual', 'Information Systems', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Relative (related person)', 'Research', 'Research Personnel', 'Signal Transduction', 'Solutions', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'design', 'improved', 'knowledge base', 'liver transplantation', 'multidisciplinary', 'prototype']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,583203,0.033854666638075265
"Real-time detection of deviations in clinical care in ICU data streams  PROJECT SUMMARY / ABSTRACT Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates below 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.                ",Real-time detection of deviations in clinical care in ICU data streams,8641014,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Decision Making', 'Detection', 'Development', 'Electronics', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Individual', 'Information Systems', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Relative (related person)', 'Research', 'Research Personnel', 'Signal Transduction', 'Solutions', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'design', 'improved', 'knowledge base', 'liver transplantation', 'multidisciplinary', 'prototype', 'public health relevance']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,580180,0.033854666638075265
"Detecting deviations in clinical care in ICU data streams    DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient [1]. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our preliminary studies provide support that such deviations often indicate clinically important events for which it is worthwhile to raise an alert. We propose an evaluation based on physician assessment of alerts that are generated from a retrospective set of intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.    PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.           PROJECT NARRATIVE There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.",Detecting deviations in clinical care in ICU data streams,7698505,R01GM088224,"['Algorithms', 'Anticoagulants', 'Belief', 'Cardiac', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Disadvantaged', 'Drops', 'Electronics', 'Evaluation', 'Event', 'Future', 'Healthcare', 'Heparin', 'Individual', 'Industry', 'Information Systems', 'Intensive Care Units', 'Knowledge', 'Lead', 'Left', 'Machine Learning', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platelet Count measurement', 'Play', 'Practice Management', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Services', 'Signal Transduction', 'Solutions', 'Statistical Models', 'Stream', 'System', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'cost', 'experience', 'follow-up', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'public health relevance', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,499603,0.048830514378991205
"Detecting deviations in clinical care in ICU data streams    DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient [1]. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our preliminary studies provide support that such deviations often indicate clinically important events for which it is worthwhile to raise an alert. We propose an evaluation based on physician assessment of alerts that are generated from a retrospective set of intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.    PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.           PROJECT NARRATIVE There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.",Detecting deviations in clinical care in ICU data streams,8098786,R01GM088224,"['Algorithms', 'Anticoagulants', 'Belief', 'Cardiac', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Disadvantaged', 'Drops', 'Electronics', 'Evaluation', 'Event', 'Future', 'Healthcare', 'Heparin', 'Individual', 'Industry', 'Information Systems', 'Intensive Care Units', 'Knowledge', 'Lead', 'Left', 'Machine Learning', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platelet Count measurement', 'Play', 'Practice Management', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Services', 'Signal Transduction', 'Solutions', 'Statistical Models', 'Stream', 'System', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'cost', 'experience', 'follow-up', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'public health relevance', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,498467,0.048830514378991205
"Detecting deviations in clinical care in ICU data streams    DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient [1]. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our preliminary studies provide support that such deviations often indicate clinically important events for which it is worthwhile to raise an alert. We propose an evaluation based on physician assessment of alerts that are generated from a retrospective set of intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.    PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.           PROJECT NARRATIVE There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.",Detecting deviations in clinical care in ICU data streams,7918929,R01GM088224,"['Algorithms', 'Anticoagulants', 'Belief', 'Cardiac', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Disadvantaged', 'Drops', 'Electronics', 'Evaluation', 'Event', 'Future', 'Healthcare', 'Heparin', 'Individual', 'Industry', 'Information Systems', 'Intensive Care Units', 'Knowledge', 'Lead', 'Left', 'Machine Learning', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platelet Count measurement', 'Play', 'Practice Management', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Services', 'Signal Transduction', 'Solutions', 'Statistical Models', 'Stream', 'System', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'cost', 'experience', 'follow-up', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'public health relevance', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,493140,0.048830514378991205
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.       PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.         ","Annotation, development and evaluation for clinical information extraction",8501543,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,370221,0.0490968982420634
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8288078,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,663130,0.046673727429782375
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8133360,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,664617,0.046673727429782375
"Annotation, development and evaluation for clinical information extraction (transfer) Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible. In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction (transfer)",8868500,R01GM090187,[' '],NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2013,297936,0.0490968982420634
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8231171,R01GM090187,[' '],NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,642650,0.046673727429782375
"Exploring Natural Language Processing, Image Processing, Machine Learning, and Us DESCRIPTION (provided by applicant): Most biomedical text mining systems target only text information and do not provide intelligent access to other important data such as Figures. More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biomedical articles nearly always incorporate images that are the crucial content of biomedical knowledge discovery. Biomedical scientists need to access images to validate research facts and to formulate or to test novel research hypotheses. Evaluation has shown that textual statements reported in the literature are frequently noisy (i.e., contain ""false facts""). Capturing images that are essentially experimental ""evidence"" to support the textual ""fact"" will benefit biomedical information systems, databases, and biomedical scientists. We are developing a biomedical literature figure search engine BioFigureSearch. We develop innovative algorithms and models in natural language processing, image processing, machine learning and user interfacing. The deliverables will be novel biomedical natural language figure processing (bNLfP) algorithms and iBioFigureSearch allowing biomedical scientists to access figure data effectively, and open-source tools that will enhance biomedical information retrieval, summarization, and question answering. The bNLfP algorithms we will be developing can be applied or integrated into other biomedical text-mining systems. This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.","Exploring Natural Language Processing, Image Processing, Machine Learning, and Us",8840267,R01GM095476,"['Address', 'Algorithms', 'Automobile Driving', 'Biomedical Computing', 'Cognitive', 'Collaborations', 'Collection', 'Comprehension', 'Computer Simulation', 'Data', 'Databases', 'Diagnostic', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Genomics', 'Human', 'Hybrids', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Licensing', 'Literature', 'Machine Learning', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Process', 'Prognostic Marker', 'Proteins', 'PubMed', 'Publications', 'Publishing', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Semantics', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'abstracting', 'base', 'biomedical information system', 'biomedical scientist', 'design', 'genome-wide', 'image processing', 'improved', 'innovation', 'medical schools', 'natural language', 'novel', 'open source', 'response', 'text searching', 'tool']",NIGMS,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2015,490160,0.0029642737099593404
"Exploring Natural Language Processing, Image Processing, Machine Learning, and Us DESCRIPTION (provided by applicant): Most biomedical text mining systems target only text information and do not provide intelligent access to other important data such as Figures. More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biomedical articles nearly always incorporate images that are the crucial content of biomedical knowledge discovery. Biomedical scientists need to access images to validate research facts and to formulate or to test novel research hypotheses. Evaluation has shown that textual statements reported in the literature are frequently noisy (i.e., contain ""false facts""). Capturing images that are essentially experimental ""evidence"" to support the textual ""fact"" will benefit biomedical information systems, databases, and biomedical scientists. We are developing a biomedical literature figure search engine BioFigureSearch. We develop innovative algorithms and models in natural language processing, image processing, machine learning and user interfacing. The deliverables will be novel biomedical natural language figure processing (bNLfP) algorithms and iBioFigureSearch allowing biomedical scientists to access figure data effectively, and open-source tools that will enhance biomedical information retrieval, summarization, and question answering. The bNLfP algorithms we will be developing can be applied or integrated into other biomedical text-mining systems. This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.","Exploring Natural Language Processing, Image Processing, Machine Learning, and Us",8734439,R01GM095476,"['Address', 'Algorithms', 'Automobile Driving', 'Biomedical Computing', 'Cognitive', 'Collaborations', 'Collection', 'Comprehension', 'Computer Simulation', 'Data', 'Databases', 'Diagnostic', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Genomics', 'Human', 'Hybrids', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Licensing', 'Literature', 'Machine Learning', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Process', 'Prognostic Marker', 'Proteins', 'PubMed', 'Publications', 'Publishing', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Semantics', 'System', 'T-Cell Receptor-Rearrangement Excision DNA Circles', 'Techniques', 'Testing', 'Text', 'Validation', 'abstracting', 'base', 'biomedical information system', 'biomedical scientist', 'design', 'genome-wide', 'image processing', 'improved', 'innovation', 'medical schools', 'natural language', 'novel', 'open source', 'response', 'text searching', 'tool']",NIGMS,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2014,489755,0.0029642737099593404
"Exploring Natural Language Processing, Image Processing, Machine Learning, and Us DESCRIPTION (provided by applicant): Most biomedical text mining systems target only text information and do not provide intelligent access to other important data such as Figures. More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biomedical articles nearly always incorporate images that are the crucial content of biomedical knowledge discovery. Biomedical scientists need to access images to validate research facts and to formulate or to test novel research hypotheses. Evaluation has shown that textual statements reported in the literature are frequently noisy (i.e., contain ""false facts""). Capturing images that are essentially experimental ""evidence"" to support the textual ""fact"" will benefit biomedical information systems, databases, and biomedical scientists. We are developing a biomedical literature figure search engine BioFigureSearch. We develop innovative algorithms and models in natural language processing, image processing, machine learning and user interfacing. The deliverables will be novel biomedical natural language figure processing (bNLfP) algorithms and iBioFigureSearch allowing biomedical scientists to access figure data effectively, and open-source tools that will enhance biomedical information retrieval, summarization, and question answering. The bNLfP algorithms we will be developing can be applied or integrated into other biomedical text-mining systems. This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.","Exploring Natural Language Processing, Image Processing, Machine Learning, and Us",8474789,R01GM095476,"['Address', 'Algorithms', 'Automobile Driving', 'Biomedical Computing', 'Cognitive', 'Collaborations', 'Collection', 'Comprehension', 'Computer Simulation', 'Data', 'Databases', 'Diagnostic', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Genomics', 'Human', 'Hybrids', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Licensing', 'Literature', 'Machine Learning', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Process', 'Prognostic Marker', 'Proteins', 'PubMed', 'Publications', 'Publishing', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Semantics', 'System', 'T-Cell Receptor-Rearrangement Excision DNA Circles', 'Techniques', 'Testing', 'Text', 'Validation', 'abstracting', 'base', 'biomedical information system', 'biomedical scientist', 'design', 'genome-wide', 'image processing', 'improved', 'innovation', 'medical schools', 'natural language', 'novel', 'open source', 'response', 'text searching', 'tool']",NIGMS,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2013,486484,0.0029642737099593404
"Exploring Natural Language Processing, Image Processing, Machine Learning, and Us    DESCRIPTION (provided by applicant): Most biomedical text mining systems target only text information and do not provide intelligent access to other important data such as Figures. More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biomedical articles nearly always incorporate images that are the crucial content of biomedical knowledge discovery. Biomedical scientists need to access images to validate research facts and to formulate or to test novel research hypotheses. Evaluation has shown that textual statements reported in the literature are frequently noisy (i.e., contain ""false facts""). Capturing images that are essentially experimental ""evidence"" to support the textual ""fact"" will benefit biomedical information systems, databases, and biomedical scientists. We are developing a biomedical literature figure search engine BioFigureSearch. We develop innovative algorithms and models in natural language processing, image processing, machine learning and user interfacing. The deliverables will be novel biomedical natural language figure processing (bNLfP) algorithms and iBioFigureSearch allowing biomedical scientists to access figure data effectively, and open-source tools that will enhance biomedical information retrieval, summarization, and question answering. The bNLfP algorithms we will be developing can be applied or integrated into other biomedical text-mining systems.       This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.","Exploring Natural Language Processing, Image Processing, Machine Learning, and Us",8309015,R01GM095476,"['Address', 'Algorithms', 'Automobile Driving', 'Biomedical Computing', 'Cognitive', 'Collaborations', 'Collection', 'Comprehension', 'Computer Simulation', 'Data', 'Databases', 'Diagnostic', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Genomics', 'Human', 'Hybrids', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Licensing', 'Literature', 'Machine Learning', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Process', 'Prognostic Marker', 'Proteins', 'PubMed', 'Publications', 'Publishing', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Semantics', 'System', 'T-Cell Receptor-Rearrangement Excision DNA Circles', 'Techniques', 'Testing', 'Text', 'Validation', 'abstracting', 'base', 'biomedical information system', 'biomedical scientist', 'design', 'genome-wide', 'image processing', 'improved', 'innovation', 'medical schools', 'natural language', 'novel', 'open source', 'response', 'text searching', 'tool']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2012,179306,0.0029642737099593404
"Exploring Natural Language Processing, Image Processing, Machine Learning, and Us    DESCRIPTION (provided by applicant): Most biomedical text mining systems target only text information and do not provide intelligent access to other important data such as Figures. More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biomedical articles nearly always incorporate images that are the crucial content of biomedical knowledge discovery. Biomedical scientists need to access images to validate research facts and to formulate or to test novel research hypotheses. Evaluation has shown that textual statements reported in the literature are frequently noisy (i.e., contain ""false facts""). Capturing images that are essentially experimental ""evidence"" to support the textual ""fact"" will benefit biomedical information systems, databases, and biomedical scientists. We are developing a biomedical literature figure search engine BioFigureSearch. We develop innovative algorithms and models in natural language processing, image processing, machine learning and user interfacing. The deliverables will be novel biomedical natural language figure processing (bNLfP) algorithms and iBioFigureSearch allowing biomedical scientists to access figure data effectively, and open-source tools that will enhance biomedical information retrieval, summarization, and question answering. The bNLfP algorithms we will be developing can be applied or integrated into other biomedical text-mining systems.      PUBLIC HEALTH RELEVANCE: This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.          This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.","Exploring Natural Language Processing, Image Processing, Machine Learning, and Us",8106768,R01GM095476,"['Address', 'Algorithms', 'Automobile Driving', 'Biomedical Computing', 'Cognitive', 'Collaborations', 'Collection', 'Comprehension', 'Computer Simulation', 'Data', 'Databases', 'Diagnostic', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Genomics', 'Human', 'Hybrids', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Knowledge', 'Knowledge Discovery', 'Libraries', 'Licensing', 'Literature', 'Machine Learning', 'Measures', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Process', 'Prognostic Marker', 'Proteins', 'PubMed', 'Publications', 'Publishing', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Semantics', 'System', 'T-Cell Receptor-Rearrangement Excision DNA Circles', 'Techniques', 'Testing', 'Text', 'Validation', 'abstracting', 'base', 'biomedical information system', 'biomedical scientist', 'design', 'genome-wide', 'image processing', 'improved', 'innovation', 'medical schools', 'natural language', 'novel', 'open source', 'response', 'text searching', 'tool']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2011,500273,0.0032663496249319512
"Exploring Natural Language Processing, Image Processing, Machine Learning, and Us DESCRIPTION (provided by applicant): Most biomedical text mining systems target only text information and do not provide intelligent access to other important data such as Figures. More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biomedical articles nearly always incorporate images that are the crucial content of biomedical knowledge discovery. Biomedical scientists need to access images to validate research facts and to formulate or to test novel research hypotheses. Evaluation has shown that textual statements reported in the literature are frequently noisy (i.e., contain ""false facts""). Capturing images that are essentially experimental ""evidence"" to support the textual ""fact"" will benefit biomedical information systems, databases, and biomedical scientists. We are developing a biomedical literature figure search engine BioFigureSearch. We develop innovative algorithms and models in natural language processing, image processing, machine learning and user interfacing. The deliverables will be novel biomedical natural language figure processing (bNLfP) algorithms and iBioFigureSearch allowing biomedical scientists to access figure data effectively, and open-source tools that will enhance biomedical information retrieval, summarization, and question answering. The bNLfP algorithms we will be developing can be applied or integrated into other biomedical text-mining systems. This project proposes innovative algorithms and models in natural language processing, image processing, machine learning, and user interfacing, to return figures in response to biomedical queries. It is anticipated that the algorithms, models, and tools developed will significantly enhance biomedical scientists' access to figures reported in literature, and thereby expedite biomedical knowledge discovery.","Exploring Natural Language Processing, Image Processing, Machine Learning, and Us",8701603,R01GM095476,[' '],NIGMS,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2012,332000,0.0029642737099593404
"Machine Learning for Identifying Adverse Drug Events     DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA. PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.",Machine Learning for Identifying Adverse Drug Events,9522037,R01GM097618,"['Address', 'Adverse drug effect', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Coxibs', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'International', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'data warehouse', 'experience', 'improved', 'interest', 'learning strategy', 'natural language', 'novel', 'novel therapeutics', 'patient safety', 'prediction algorithm', 'predictive modeling', 'programs', 'public health relevance', 'response', 'statistics', 'synergism']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,536041,0.03917016316115883
"Machine Learning for Identifying Adverse Drug Events     DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA. PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.",Machine Learning for Identifying Adverse Drug Events,9323511,R01GM097618,"['Address', 'Adverse drug effect', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Coxibs', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'International', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'experience', 'improved', 'interest', 'learning strategy', 'natural language', 'novel', 'novel therapeutics', 'patient safety', 'prediction algorithm', 'predictive modeling', 'programs', 'public health relevance', 'response', 'statistics', 'synergism']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2017,536041,0.03917016316115883
"Machine Learning for Identifying Adverse Drug Events     DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA. PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.",Machine Learning for Identifying Adverse Drug Events,9145227,R01GM097618,"['Accounting', 'Address', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Evaluation Research', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'experience', 'improved', 'inhibitor/antagonist', 'interest', 'international partnership', 'learning strategy', 'natural language', 'novel', 'novel therapeutics', 'patient safety', 'post-market', 'prediction algorithm', 'predictive modeling', 'programs', 'response', 'statistics']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2016,539889,0.03917016316115883
"Machine Learning for Identifying Adverse Drug Events     DESCRIPTION (provided by applicant): Because of the profound effect of adverse drug events (ADEs) on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post-marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA formed the Observational Medical Outcomes Partnership (OMOP) to develop and compare methods for identification of ADEs, and the FDA announced its Sentinel Initiative. Congress created the Reagan Udall Foundation (RUF) for the FDA in response to the FDA's own ""FDA Science and Mission at Risk"" report, and two years ago OMOP activities were incorporated into RUF. As the FDA moves forward with its development of Sentinel, including work on Mini-Sentinel, there is a need for researchers around the country to continue to develop better methods, and better evaluation methodologies for those methods. A robust research community working on algorithms for pharmacosurveillance, using electronic health records (EHRs) and claims databases will provide a substrate of ever-improving methods on which the nation's regulatory pharmacovigilance infrastructure can build. Indeed an important motivation of OMOP and Mini-Sentinel was to spur the development of such a community. Machine learning has attracted widespread attention across a range of disciplines for its ability to construct accurate predictive models. Therefore machine learning is especially appropriate for the problems of ADE identification and prediction: identifying ADEs from observational data, and predicting which patients are most at risk of suffering the identified ADE. Our current award has demonstrated the ability of machine learning to address both of these tasks. It has added to the existing evidence that consideration of temporal ordering of events, such as drug exposure and diagnoses, is critical for accuracy in identification and prediction of ADEs. The proposed work seeks to further improve upon these methods by building on recent advances in the field of machine learning, by our group and by others, in graphical model learning and in explicit modeling of irregularly-sampled temporal data. The latter is especially important because observational health databases, such as EHRs and claims databases, are not simple time series. Patients typically do not come into the clinic at regular intervals and have the same labs, vitals, and other measurements in lock step with one another. Building better ADE detection and prediction algorithms cannot be accomplished simply by machine learning research, even if that research is taking account of related work from relevant parts of computer science, statistics, biostatistics, epidemiology, pharmaco-epidemiology, and clinical research. Better methods are needed also for evaluation, that is, for estimating how well a new algorithm, or a new use of an existing algorithm, will perform at identifying ADEs associated with a new drug on the market, or at predicting which patients are most at risk of that ADE. More research and evaluation is also needed at the systems level: how can we best construct end-to-end pharmacovigilance systems that sit atop a large observational database and flag potential ADEs for human experts to further investigate? What kinds of information and statistics should such a system provide to the human experts?        This renewal will address the following aims: (1) improve upon machine learning methods for identification and prediction of ADEs, taking advantage of synergies between these two distinct tasks; (2) improve upon existing methods for evaluating ADE detection, building on advances in machine learning for information extraction from scientific literature; (3) improve upon existing methods for evaluating ADE prediction, building upon advances in machine learning for automated support of phenotyping and also building upon improved methods for efficiently obtaining expert labeling of borderline examples of a phenotype; and (4) use the methods developed in the first three aims to construct and evaluate an end-to-end pharmacosurveillance system integrated with the Marshfield Clinic EHR Data Warehouse. Machine learning plays a central and unifying role throughout all four aims. Our investigator team consists of machine learning researchers with experience in analysis of clinical, genomic, and natural language data (Page, Natarajan), a leading pharmaco-epidemiologist with expertise in building systems to efficiently obtain expert evaluation and labeling of phenotypes (Hansen), a leader in phenotyping from EHR data (Peissig), and an MD/PhD practicing physician with years of experience and leadership in the study of ADEs (Caldwell). In addition to building on results of the prior award, we will build on our experiences with OMOP, the International Warfarin Pharmacogenetics Consortium, the DARPA Machine Reading Program, and interactions with the FDA.         PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It also addresses the needs for improved evaluation and integrated systems approaches.            ",Machine Learning for Identifying Adverse Drug Events,8964138,R01GM097618,"['Accounting', 'Address', 'Adverse drug event', 'Algorithms', 'Attention', 'Award', 'Biometry', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Congresses', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Discipline', 'Doctor of Philosophy', 'Drug Exposure', 'Early Diagnosis', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Evaluation Methodology', 'Evaluation Research', 'Event', 'Foundations', 'Genomics', 'Health', 'Human', 'Institute of Medicine (U.S.)', 'International', 'Label', 'Leadership', 'Learning', 'Life', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Markov Chains', 'Measurement', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Motivation', 'Myocardial Infarction', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Physicians', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Priority', 'Risk', 'Role', 'Safety', 'Sampling', 'Science', 'Sentinel', 'Series', 'Serious Adverse Event', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Wisconsin', 'Work', 'base', 'computer science', 'cost', 'data mining', 'experience', 'improved', 'inhibitor/antagonist', 'interest', 'natural language', 'novel', 'patient safety', 'post-market', 'predictive modeling', 'programs', 'public health relevance', 'response', 'statistics']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2015,608132,0.03917016316115883
"Machine Learning for Identifying Adverse Drug Events    DESCRIPTION (provided by applicant): Because of the direct effect on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post- marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA have formed the Observational Medical Outcomes partnership to develop and compare methods for identification of adverse drug events (ADEs), and the FDA has announced its Sentinel Initiative. The proposed work will develop and study machine learning for ADE identification and prediction. The latter, easier task of ADE prediction assumes that an ADE has already been identified -- such as the association between Cox2 inhibitors (Cox2ib) and myocardial infarction (MI) - and the goal is to construct a model that can accurately predict which patients are most susceptible to having the ADE, e.g., having an MI if they take a Cox2 inhibitor. Our preliminary results show that using machine learning we can already make predictions at 75% sensitivity with 75% specificity. The task of ADE identification is more difficult than ADE prediction, because we do not have an observed class variable. Given that a new drug has been placed on the market, this task seeks to determine whether any previously-unanticipated adverse event is caused by the drug. Because we do not know in advance what this event is - it may not even correspond to an existing diagnosis code - this task does not neatly fit into the standard supervised learning paradigm. Our approach is to use reverse machine learning to build a post- marketing surveillance tool in order to predict and/or detect adverse reactions to drugs from electronic medical records (EMRs) or claims data. We show both theoretically and with preliminary empirical results that this approach can discover one or more subgroups of patients who are characterized by previously-unanticipated adverse events - events that patients on the drug suffer at a higher rate than patients not on the drug. These events do not have to correspond to previously-defined ADEs. In order to build and evaluate a machine learning-based system for ADE identification and prediction, this proposal will address the following specific aims: (1) apply supervised machine learning to the task of ADE prediction - predicting which patients are most likely to suffer a known ADE if given the drug; (2) apply reverse machine learning to identify novel ADEs; (3) provide a complete software system for machine learning-based identification and prediction of ADEs. This system will be tested on both the Marshfield Clinic's EMR, some preliminary results of which are presented in this proposal, and on real and synthetic datasets available through the Observational Medical Outcomes Partnership (OMOP).        Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It will further develop and thoroughly evaluate novel machine learning approaches to these difficult tasks.            ",Machine Learning for Identifying Adverse Drug Events,8466993,R01GM097618,"['Address', 'Adverse event', 'Adverse reactions', 'Algorithms', 'Area Under Curve', 'Classification', 'Clinic', 'Clinical', 'Code', 'Computerized Medical Record', 'Congresses', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Diagnosis', 'Event', 'Foundations', 'Future', 'Genetic Crossing Over', 'Goals', 'Health', 'Hemorrhage', 'Institute of Medicine (U.S.)', 'Learning', 'Left', 'Life', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'ROC Curve', 'Recording of previous events', 'Research Priority', 'Risk', 'Sensitivity and Specificity', 'Sentinel', 'Specificity', 'Subgroup', 'Supervision', 'System', 'Testing', 'Training', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Work', 'base', 'computer based statistical methods', 'cost', 'data mining', 'improved', 'inhibitor/antagonist', 'novel', 'novel strategies', 'patient safety', 'post-market', 'software systems', 'standard measure', 'tool', 'vector']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,520751,0.025328443143789688
"Machine Learning for Identifying Adverse Drug Events    DESCRIPTION (provided by applicant): Because of the direct effect on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post- marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA have formed the Observational Medical Outcomes partnership to develop and compare methods for identification of adverse drug events (ADEs), and the FDA has announced its Sentinel Initiative. The proposed work will develop and study machine learning for ADE identification and prediction. The latter, easier task of ADE prediction assumes that an ADE has already been identified -- such as the association between Cox2 inhibitors (Cox2ib) and myocardial infarction (MI) - and the goal is to construct a model that can accurately predict which patients are most susceptible to having the ADE, e.g., having an MI if they take a Cox2 inhibitor. Our preliminary results show that using machine learning we can already make predictions at 75% sensitivity with 75% specificity. The task of ADE identification is more difficult than ADE prediction, because we do not have an observed class variable. Given that a new drug has been placed on the market, this task seeks to determine whether any previously-unanticipated adverse event is caused by the drug. Because we do not know in advance what this event is - it may not even correspond to an existing diagnosis code - this task does not neatly fit into the standard supervised learning paradigm. Our approach is to use reverse machine learning to build a post- marketing surveillance tool in order to predict and/or detect adverse reactions to drugs from electronic medical records (EMRs) or claims data. We show both theoretically and with preliminary empirical results that this approach can discover one or more subgroups of patients who are characterized by previously-unanticipated adverse events - events that patients on the drug suffer at a higher rate than patients not on the drug. These events do not have to correspond to previously-defined ADEs. In order to build and evaluate a machine learning-based system for ADE identification and prediction, this proposal will address the following specific aims: (1) apply supervised machine learning to the task of ADE prediction - predicting which patients are most likely to suffer a known ADE if given the drug; (2) apply reverse machine learning to identify novel ADEs; (3) provide a complete software system for machine learning-based identification and prediction of ADEs. This system will be tested on both the Marshfield Clinic's EMR, some preliminary results of which are presented in this proposal, and on real and synthetic datasets available through the Observational Medical Outcomes Partnership (OMOP).        Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It will further develop and thoroughly evaluate novel machine learning approaches to these difficult tasks.            ",Machine Learning for Identifying Adverse Drug Events,8274647,R01GM097618,"['Address', 'Adverse event', 'Adverse reactions', 'Algorithms', 'Area Under Curve', 'Classification', 'Clinic', 'Clinical', 'Code', 'Computerized Medical Record', 'Congresses', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Diagnosis', 'Event', 'Foundations', 'Future', 'Genetic Crossing Over', 'Goals', 'Health', 'Hemorrhage', 'Institute of Medicine (U.S.)', 'Learning', 'Left', 'Life', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'ROC Curve', 'Recording of previous events', 'Research Priority', 'Risk', 'Sensitivity and Specificity', 'Sentinel', 'Specificity', 'Subgroup', 'Supervision', 'System', 'Testing', 'Training', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Work', 'base', 'computer based statistical methods', 'cost', 'data mining', 'improved', 'inhibitor/antagonist', 'novel', 'novel strategies', 'patient safety', 'post-market', 'software systems', 'standard measure', 'tool', 'vector']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,537272,0.025328443143789688
"Machine Learning for Identifying Adverse Drug Events    DESCRIPTION (provided by applicant): Because of the direct effect on patient safety, the FDA, AHRQ and Institute of Medicine have flagged post- marketing pharmacovigilance of emerging medications as a high national research priority. The FDA, Foundation for the NIH and PhARMA have formed the Observational Medical Outcomes partnership to develop and compare methods for identification of adverse drug events (ADEs), and the FDA has announced its Sentinel Initiative. The proposed work will develop and study machine learning for ADE identification and prediction. The latter, easier task of ADE prediction assumes that an ADE has already been identified -- such as the association between Cox2 inhibitors (Cox2ib) and myocardial infarction (MI) - and the goal is to construct a model that can accurately predict which patients are most susceptible to having the ADE, e.g., having an MI if they take a Cox2 inhibitor. Our preliminary results show that using machine learning we can already make predictions at 75% sensitivity with 75% specificity. The task of ADE identification is more difficult than ADE prediction, because we do not have an observed class variable. Given that a new drug has been placed on the market, this task seeks to determine whether any previously-unanticipated adverse event is caused by the drug. Because we do not know in advance what this event is - it may not even correspond to an existing diagnosis code - this task does not neatly fit into the standard supervised learning paradigm. Our approach is to use reverse machine learning to build a post- marketing surveillance tool in order to predict and/or detect adverse reactions to drugs from electronic medical records (EMRs) or claims data. We show both theoretically and with preliminary empirical results that this approach can discover one or more subgroups of patients who are characterized by previously-unanticipated adverse events - events that patients on the drug suffer at a higher rate than patients not on the drug. These events do not have to correspond to previously-defined ADEs. In order to build and evaluate a machine learning-based system for ADE identification and prediction, this proposal will address the following specific aims: (1) apply supervised machine learning to the task of ADE prediction - predicting which patients are most likely to suffer a known ADE if given the drug; (2) apply reverse machine learning to identify novel ADEs; (3) provide a complete software system for machine learning-based identification and prediction of ADEs. This system will be tested on both the Marshfield Clinic's EMR, some preliminary results of which are presented in this proposal, and on real and synthetic datasets available through the Observational Medical Outcomes Partnership (OMOP).      PUBLIC HEALTH RELEVANCE: Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It will further develop and thoroughly evaluate novel machine learning approaches to these difficult tasks.              Adverse drug events (ADEs) carry a high cost each year in life, health and money. Congress, the FDA, the NIH and PhARMA have responded with new initiatives for identifying and predicting occurrences of ADEs. It has been widely recognized within initiatives such as Sentinel and the Observational Medical Outcomes Partnership that addressing ADEs requires data, standards and methods for data analysis and mining. This proposal addresses the need for new methods for both identifying previously- unanticipated ADEs and predicting occurrences of a known ADE. It will further develop and thoroughly evaluate novel machine learning approaches to these difficult tasks.            ",Machine Learning for Identifying Adverse Drug Events,8085232,R01GM097618,"['Address', 'Adverse event', 'Adverse reactions', 'Algorithms', 'Area Under Curve', 'Classification', 'Clinic', 'Clinical', 'Code', 'Computerized Medical Record', 'Congresses', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Diagnosis', 'Event', 'Foundations', 'Future', 'Genetic Crossing Over', 'Goals', 'Health', 'Hemorrhage', 'Institute of Medicine (U.S.)', 'Learning', 'Left', 'Life', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Myocardial Infarction', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'ROC Curve', 'Recording of previous events', 'Research Priority', 'Risk', 'Sensitivity and Specificity', 'Sentinel', 'Specificity', 'Subgroup', 'Supervision', 'System', 'Testing', 'Training', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Validation', 'Warfarin', 'Work', 'base', 'computer based statistical methods', 'cost', 'data mining', 'improved', 'inhibitor/antagonist', 'novel', 'novel strategies', 'patient safety', 'post-market', 'software systems', 'standard measure', 'tool', 'vector']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2011,548743,0.02289423863060224
"Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response PROJECT SUMMARY The growing expansion of the approved multiple sclerosis (MS) disease-modifying treatments (DMTs) and the variable responses to MS treatment have created an unmet medical need to provide individually tailored therapy. Efforts to bring precision medicine to provide individualized MS treatment selection have been impeded by our limited understanding of the factors that determine treatment response. While genomics hold the promise for closing this knowledge gap, the insufficient number of patients with detailed treatment response data and the modest effect size of genetic variants that influence treatment responses are the main limiting factors in pharmacogenomics studies. As electronic health records (EHR) become widely adopted and increasingly standardized and as we implement sophisticated computational and statistical methods to harness the EHR data, EHR systems can become cost-effective platforms to perform large-scale treatment response studies in real-life settings. Our team with a history of productive collaborations and diverse expertise (led by PI Dr. Xia) previously developed robust algorithms to identify 5,495 MS patients from the Partners HealthCare EHR systems and then model MS disease activity in these patients using EHR data. The Partners EHR system contains longitudinal clinical information on thousands of MS patients from two large academic medical centers and is linked to a well-characterized MS patient research registry and biobanks with existing genomics data. For the proposed study, we will test the hypothesis that meaningful phenotypes of MS disease activity can be extracted from EHR data to inform treatment response, and that additional common genetic variants exist in the population and can predict therapeutic response in MS when combined with clinical features derived from EHR data. The proposed study has three aims with the overall goal to produce a computational and analytic approach capable of identifying MS disease activity in relation to treatment history using EHR data and integrate with genomics profile to develop a predictive model of therapeutic response to commonly prescribed DMTs in this cohort of 5,495 MS patients, including injectable (interferon-, glatiramer acetate) and oral (fingolimod, dimethyl fumarate) options. Specifically, we will (1) leverage narrative electronic health records data (e.g., clinical notes, radiology reports) and natural language processing (NLP) to ascertain individualized response to DMTs (n=600 for each DMT); (2) Identify clinical features from electronic health record data (e.g., diagnoses, exposures) that predict response to DMTs using a systematic phenome-wide approach; (3) Develop and test a comprehensive predictive model of individualized response to DMTs that incorporates clinical and genetic predictors. This research has the potential impact to be transformative by contributing to a major knowledge gap regarding the factors that influence treatment response and bringing precision medicine closer to individualized MS treatment selection. PROJECT NARRATIVE AND PUBLIC HEALTH RELEVANCE Multiple sclerosis (MS) is a chronic neurological condition that affects over 400,000 individuals in the United States and creates a high socioeconomic burden as a leading cause of neurological disability in young adults. Because not all patients respond the same way to a specific medication, physicians and MS patients often lose precious time searching for effective treatment with serially testing of costly medications. An individually tailored treatment can ensure early start of effective medication that can prevent relapse and progression of disability. Ultimately, this project will help gain insights into the factors that determine treatment response and enable physicians to match an individual MS patient's clinical and genomic profile with uniquely tailored therapy to maximize effectiveness, delay disease progression and reduce overall cost.",Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response,9963407,R01NS098023,"['Academic Medical Centers', 'Adopted', 'Affect', 'Algorithms', 'Biology', 'Chronic', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Fumarates', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Injectable', 'Interferon-beta', 'Knowledge', 'Life', 'Link', 'Longitudinal prospective study', 'Manuals', 'Medical', 'Mission', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Neurologic', 'Neurologist', 'Oral', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Prediction of Response to Therapy', 'Radiology Specialty', 'Recording of previous events', 'Registries', 'Relapse', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Selection for Treatments', 'Standardization', 'Statistical Methods', 'System', 'Testing', 'Time', 'TimeLine', 'Treatment Cost', 'Treatment outcome', 'United States', 'Variant', 'biobank', 'clinical predictors', 'cohort', 'copolymer 1', 'cost', 'cost effective', 'disability', 'effective therapy', 'experience', 'genetic predictors', 'genetic variant', 'genome-wide', 'genomic data', 'genomic profiles', 'individual response', 'individualized medicine', 'insight', 'multiple sclerosis patient', 'multiple sclerosis treatment', 'nervous system disorder', 'neuroimaging', 'patient response', 'phenome', 'portability', 'precision medicine', 'predicting response', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'socioeconomics', 'treatment group', 'treatment response', 'young adult']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,340616,0.0616392669365368
"Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response PROJECT SUMMARY The growing expansion of the approved multiple sclerosis (MS) disease-modifying treatments (DMTs) and the variable responses to MS treatment have created an unmet medical need to provide individually tailored therapy. Efforts to bring precision medicine to provide individualized MS treatment selection have been impeded by our limited understanding of the factors that determine treatment response. While genomics hold the promise for closing this knowledge gap, the insufficient number of patients with detailed treatment response data and the modest effect size of genetic variants that influence treatment responses are the main limiting factors in pharmacogenomics studies. As electronic health records (EHR) become widely adopted and increasingly standardized and as we implement sophisticated computational and statistical methods to harness the EHR data, EHR systems can become cost-effective platforms to perform large-scale treatment response studies in real-life settings. Our team with a history of productive collaborations and diverse expertise (led by PI Dr. Xia) previously developed robust algorithms to identify 5,495 MS patients from the Partners HealthCare EHR systems and then model MS disease activity in these patients using EHR data. The Partners EHR system contains longitudinal clinical information on thousands of MS patients from two large academic medical centers and is linked to a well-characterized MS patient research registry and biobanks with existing genomics data. For the proposed study, we will test the hypothesis that meaningful phenotypes of MS disease activity can be extracted from EHR data to inform treatment response, and that additional common genetic variants exist in the population and can predict therapeutic response in MS when combined with clinical features derived from EHR data. The proposed study has three aims with the overall goal to produce a computational and analytic approach capable of identifying MS disease activity in relation to treatment history using EHR data and integrate with genomics profile to develop a predictive model of therapeutic response to commonly prescribed DMTs in this cohort of 5,495 MS patients, including injectable (interferon-, glatiramer acetate) and oral (fingolimod, dimethyl fumarate) options. Specifically, we will (1) leverage narrative electronic health records data (e.g., clinical notes, radiology reports) and natural language processing (NLP) to ascertain individualized response to DMTs (n=600 for each DMT); (2) Identify clinical features from electronic health record data (e.g., diagnoses, exposures) that predict response to DMTs using a systematic phenome-wide approach; (3) Develop and test a comprehensive predictive model of individualized response to DMTs that incorporates clinical and genetic predictors. This research has the potential impact to be transformative by contributing to a major knowledge gap regarding the factors that influence treatment response and bringing precision medicine closer to individualized MS treatment selection. PROJECT NARRATIVE AND PUBLIC HEALTH RELEVANCE Multiple sclerosis (MS) is a chronic neurological condition that affects over 400,000 individuals in the United States and creates a high socioeconomic burden as a leading cause of neurological disability in young adults. Because not all patients respond the same way to a specific medication, physicians and MS patients often lose precious time searching for effective treatment with serially testing of costly medications. An individually tailored treatment can ensure early start of effective medication that can prevent relapse and progression of disability. Ultimately, this project will help gain insights into the factors that determine treatment response and enable physicians to match an individual MS patient's clinical and genomic profile with uniquely tailored therapy to maximize effectiveness, delay disease progression and reduce overall cost.",Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response,9747390,R01NS098023,"['Academic Medical Centers', 'Adopted', 'Affect', 'Algorithms', 'Biology', 'Chronic', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Fumarates', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Injectable', 'Interferon-beta', 'Knowledge', 'Life', 'Link', 'Longitudinal prospective study', 'Manuals', 'Medical', 'Mission', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Neurologic', 'Neurologist', 'Oral', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Prediction of Response to Therapy', 'Radiology Specialty', 'Recording of previous events', 'Registries', 'Relapse', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Selection for Treatments', 'Standardization', 'Statistical Methods', 'System', 'Testing', 'Time', 'TimeLine', 'Treatment Cost', 'Treatment outcome', 'United States', 'Variant', 'biobank', 'clinical predictors', 'cohort', 'copolymer 1', 'cost', 'cost effective', 'disability', 'effective therapy', 'experience', 'genetic predictors', 'genetic variant', 'genome-wide', 'genomic data', 'genomic profiles', 'individual response', 'individualized medicine', 'insight', 'multiple sclerosis patient', 'multiple sclerosis treatment', 'nervous system disorder', 'neuroimaging', 'patient response', 'phenome', 'portability', 'precision medicine', 'predicting response', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'socioeconomics', 'treatment group', 'treatment response', 'young adult']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,298872,0.0616392669365368
"Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response PROJECT SUMMARY The growing expansion of the approved multiple sclerosis (MS) disease-modifying treatments (DMTs) and the variable responses to MS treatment have created an unmet medical need to provide individually tailored therapy. Efforts to bring precision medicine to provide individualized MS treatment selection have been impeded by our limited understanding of the factors that determine treatment response. While genomics hold the promise for closing this knowledge gap, the insufficient number of patients with detailed treatment response data and the modest effect size of genetic variants that influence treatment responses are the main limiting factors in pharmacogenomics studies. As electronic health records (EHR) become widely adopted and increasingly standardized and as we implement sophisticated computational and statistical methods to harness the EHR data, EHR systems can become cost-effective platforms to perform large-scale treatment response studies in real-life settings. Our team with a history of productive collaborations and diverse expertise (led by PI Dr. Xia) previously developed robust algorithms to identify 5,495 MS patients from the Partners HealthCare EHR systems and then model MS disease activity in these patients using EHR data. The Partners EHR system contains longitudinal clinical information on thousands of MS patients from two large academic medical centers and is linked to a well-characterized MS patient research registry and biobanks with existing genomics data. For the proposed study, we will test the hypothesis that meaningful phenotypes of MS disease activity can be extracted from EHR data to inform treatment response, and that additional common genetic variants exist in the population and can predict therapeutic response in MS when combined with clinical features derived from EHR data. The proposed study has three aims with the overall goal to produce a computational and analytic approach capable of identifying MS disease activity in relation to treatment history using EHR data and integrate with genomics profile to develop a predictive model of therapeutic response to commonly prescribed DMTs in this cohort of 5,495 MS patients, including injectable (interferon-, glatiramer acetate) and oral (fingolimod, dimethyl fumarate) options. Specifically, we will (1) leverage narrative electronic health records data (e.g., clinical notes, radiology reports) and natural language processing (NLP) to ascertain individualized response to DMTs (n=600 for each DMT); (2) Identify clinical features from electronic health record data (e.g., diagnoses, exposures) that predict response to DMTs using a systematic phenome-wide approach; (3) Develop and test a comprehensive predictive model of individualized response to DMTs that incorporates clinical and genetic predictors. This research has the potential impact to be transformative by contributing to a major knowledge gap regarding the factors that influence treatment response and bringing precision medicine closer to individualized MS treatment selection. PROJECT NARRATIVE AND PUBLIC HEALTH RELEVANCE Multiple sclerosis (MS) is a chronic neurological condition that affects over 400,000 individuals in the United States and creates a high socioeconomic burden as a leading cause of neurological disability in young adults. Because not all patients respond the same way to a specific medication, physicians and MS patients often lose precious time searching for effective treatment with serially testing of costly medications. An individually tailored treatment can ensure early start of effective medication that can prevent relapse and progression of disability. Ultimately, this project will help gain insights into the factors that determine treatment response and enable physicians to match an individual MS patient's clinical and genomic profile with uniquely tailored therapy to maximize effectiveness, delay disease progression and reduce overall cost.",Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response,9509579,R01NS098023,"['Academic Medical Centers', 'Adopted', 'Affect', 'Algorithms', 'Biology', 'Chronic', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Fumarates', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Injectable', 'Interferon-beta', 'Knowledge', 'Life', 'Link', 'Longitudinal prospective study', 'Manuals', 'Medical', 'Mission', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Neurologic', 'Neurologist', 'Oral', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Prediction of Response to Therapy', 'Radiology Specialty', 'Recording of previous events', 'Registries', 'Relapse', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Selection for Treatments', 'Standardization', 'Statistical Methods', 'System', 'Testing', 'Time', 'TimeLine', 'Treatment Cost', 'Treatment outcome', 'United States', 'Variant', 'biobank', 'clinical predictors', 'cohort', 'copolymer 1', 'cost', 'cost effective', 'disability', 'effective therapy', 'experience', 'genetic predictors', 'genetic variant', 'genome-wide', 'genomic data', 'genomic profiles', 'individual response', 'individualized medicine', 'insight', 'multiple sclerosis patient', 'multiple sclerosis treatment', 'nervous system disorder', 'neuroimaging', 'patient response', 'phenome', 'portability', 'precision medicine', 'predicting response', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'socioeconomics', 'treatment group', 'treatment response', 'young adult']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,344656,0.0616392669365368
"Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response PROJECT SUMMARY The growing expansion of the approved multiple sclerosis (MS) disease-modifying treatments (DMTs) and the variable responses to MS treatment have created an unmet medical need to provide individually tailored therapy. Efforts to bring precision medicine to provide individualized MS treatment selection have been impeded by our limited understanding of the factors that determine treatment response. While genomics hold the promise for closing this knowledge gap, the insufficient number of patients with detailed treatment response data and the modest effect size of genetic variants that influence treatment responses are the main limiting factors in pharmacogenomics studies. As electronic health records (EHR) become widely adopted and increasingly standardized and as we implement sophisticated computational and statistical methods to harness the EHR data, EHR systems can become cost-effective platforms to perform large-scale treatment response studies in real-life settings. Our team with a history of productive collaborations and diverse expertise (led by PI Dr. Xia) previously developed robust algorithms to identify 5,495 MS patients from the Partners HealthCare EHR systems and then model MS disease activity in these patients using EHR data. The Partners EHR system contains longitudinal clinical information on thousands of MS patients from two large academic medical centers and is linked to a well-characterized MS patient research registry and biobanks with existing genomics data. For the proposed study, we will test the hypothesis that meaningful phenotypes of MS disease activity can be extracted from EHR data to inform treatment response, and that additional common genetic variants exist in the population and can predict therapeutic response in MS when combined with clinical features derived from EHR data. The proposed study has three aims with the overall goal to produce a computational and analytic approach capable of identifying MS disease activity in relation to treatment history using EHR data and integrate with genomics profile to develop a predictive model of therapeutic response to commonly prescribed DMTs in this cohort of 5,495 MS patients, including injectable (interferon-, glatiramer acetate) and oral (fingolimod, dimethyl fumarate) options. Specifically, we will (1) leverage narrative electronic health records data (e.g., clinical notes, radiology reports) and natural language processing (NLP) to ascertain individualized response to DMTs (n=600 for each DMT); (2) Identify clinical features from electronic health record data (e.g., diagnoses, exposures) that predict response to DMTs using a systematic phenome-wide approach; (3) Develop and test a comprehensive predictive model of individualized response to DMTs that incorporates clinical and genetic predictors. This research has the potential impact to be transformative by contributing to a major knowledge gap regarding the factors that influence treatment response and bringing precision medicine closer to individualized MS treatment selection. PROJECT NARRATIVE AND PUBLIC HEALTH RELEVANCE Multiple sclerosis (MS) is a chronic neurological condition that affects over 400,000 individuals in the United States and creates a high socioeconomic burden as a leading cause of neurological disability in young adults. Because not all patients respond the same way to a specific medication, physicians and MS patients often lose precious time searching for effective treatment with serially testing of costly medications. An individually tailored treatment can ensure early start of effective medication that can prevent relapse and progression of disability. Ultimately, this project will help gain insights into the factors that determine treatment response and enable physicians to match an individual MS patient's clinical and genomic profile with uniquely tailored therapy to maximize effectiveness, delay disease progression and reduce overall cost.",Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response,9358350,R01NS098023,"['Academic Medical Centers', 'Adopted', 'Affect', 'Algorithms', 'Biology', 'Chronic', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Fumarates', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Injectable', 'Interferon-beta', 'Knowledge', 'Life', 'Link', 'Longitudinal prospective study', 'Manuals', 'Medical', 'Mission', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Neurologic', 'Neurologist', 'Oral', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Radiology Specialty', 'Recording of previous events', 'Registries', 'Relapse', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Selection for Treatments', 'Standardization', 'Statistical Methods', 'System', 'Testing', 'Time', 'TimeLine', 'Treatment Cost', 'Treatment outcome', 'United States', 'Variant', 'biobank', 'clinical predictors', 'cohort', 'copolymer 1', 'cost', 'cost effective', 'disability', 'effective therapy', 'experience', 'genetic predictors', 'genetic variant', 'genome-wide', 'genomic data', 'genomic profiles', 'individualized medicine', 'insight', 'multiple sclerosis patient', 'multiple sclerosis treatment', 'nervous system disorder', 'neuroimaging', 'phenome', 'portability', 'precision medicine', 'predicting response', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'socioeconomics', 'treatment group', 'treatment response', 'young adult']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,344715,0.0616392669365368
"Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response PROJECT SUMMARY The growing expansion of the approved multiple sclerosis (MS) disease-modifying treatments (DMTs) and the variable responses to MS treatment have created an unmet medical need to provide individually tailored therapy. Efforts to bring precision medicine to provide individualized MS treatment selection have been impeded by our limited understanding of the factors that determine treatment response. While genomics hold the promise for closing this knowledge gap, the insufficient number of patients with detailed treatment response data and the modest effect size of genetic variants that influence treatment responses are the main limiting factors in pharmacogenomics studies. As electronic health records (EHR) become widely adopted and increasingly standardized and as we implement sophisticated computational and statistical methods to harness the EHR data, EHR systems can become cost-effective platforms to perform large-scale treatment response studies in real-life settings. Our team with a history of productive collaborations and diverse expertise (led by PI Dr. Xia) previously developed robust algorithms to identify 5,495 MS patients from the Partners HealthCare EHR systems and then model MS disease activity in these patients using EHR data. The Partners EHR system contains longitudinal clinical information on thousands of MS patients from two large academic medical centers and is linked to a well-characterized MS patient research registry and biobanks with existing genomics data. For the proposed study, we will test the hypothesis that meaningful phenotypes of MS disease activity can be extracted from EHR data to inform treatment response, and that additional common genetic variants exist in the population and can predict therapeutic response in MS when combined with clinical features derived from EHR data. The proposed study has three aims with the overall goal to produce a computational and analytic approach capable of identifying MS disease activity in relation to treatment history using EHR data and integrate with genomics profile to develop a predictive model of therapeutic response to commonly prescribed DMTs in this cohort of 5,495 MS patients, including injectable (interferon-, glatiramer acetate) and oral (fingolimod, dimethyl fumarate) options. Specifically, we will (1) leverage narrative electronic health records data (e.g., clinical notes, radiology reports) and natural language processing (NLP) to ascertain individualized response to DMTs (n=600 for each DMT); (2) Identify clinical features from electronic health record data (e.g., diagnoses, exposures) that predict response to DMTs using a systematic phenome-wide approach; (3) Develop and test a comprehensive predictive model of individualized response to DMTs that incorporates clinical and genetic predictors. This research has the potential impact to be transformative by contributing to a major knowledge gap regarding the factors that influence treatment response and bringing precision medicine closer to individualized MS treatment selection. PROJECT NARRATIVE AND PUBLIC HEALTH RELEVANCE Multiple sclerosis (MS) is a chronic neurological condition that affects over 400,000 individuals in the United States and creates a high socioeconomic burden as a leading cause of neurological disability in young adults. Because not all patients respond the same way to a specific medication, physicians and MS patients often lose precious time searching for effective treatment with serially testing of costly medications. An individually tailored treatment can ensure early start of effective medication that can prevent relapse and progression of disability. Ultimately, this project will help gain insights into the factors that determine treatment response and enable physicians to match an individual MS patient's clinical and genomic profile with uniquely tailored therapy to maximize effectiveness, delay disease progression and reduce overall cost.",Integrating EHR and Genomics to Predict Multiple Sclerosis Drug Response,9158403,R01NS098023,"['Academic Medical Centers', 'Adopted', 'Affect', 'Algorithms', 'Biology', 'Chronic', 'Clinical', 'Code', 'Collaborations', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Fumarates', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Injectable', 'Interferon-beta', 'Knowledge', 'Life', 'Link', 'Medical', 'Mission', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Neurologic', 'Neurologist', 'Oral', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Prospective Studies', 'Radiology Specialty', 'Recording of previous events', 'Registries', 'Relapse', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Statistical Methods', 'System', 'Testing', 'Time', 'TimeLine', 'Treatment outcome', 'United States', 'Variant', 'biobank', 'clinical predictors', 'cohort', 'copolymer 1', 'cost', 'cost effective', 'disability', 'effective therapy', 'experience', 'genetic predictors', 'genetic variant', 'genome-wide', 'genomic data', 'genomic profiles', 'individualized medicine', 'insight', 'multiple sclerosis patient', 'multiple sclerosis treatment', 'nervous system disorder', 'neuroimaging', 'phenome', 'portability', 'precision medicine', 'predicting response', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'socioeconomics', 'treatment group', 'treatment response', 'young adult']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,370421,0.0616392669365368
"Mining health data for drug safety profiles DESCRIPTION (provided by applicant): Clinical trials, which test the safety and efficacy of drugs in a controlled population, cannot identify all safety issues associated with drugs because the size and characteristics of the target population, duration of use, the concomitant disease conditions and therapies differ markedly in actual usage conditions.  On the outpatient side, medication related morbidity and mortality in the United States is estimated to result in 100,000 deaths and $177 billion in cost annually.  On the inpatient side, it is estimated that roughly 30% of hospital stays have an adverse drug event.  Current one-drug-at-a-time methods for surveillance are woefully inadequate because no one monitors the ""real life"" situation of patients getting over 3 concomitant drugs in the context of multiple co-morbidities.  In preliminary work, we have built an annotation and analysis pipeline that uses the knowledge-graph formed by public biomedical ontologies for the purpose data-mining unstructured clinical notes.  We have demonstrated that we can reproduce drug safety signals from the clinical notes on average 2.7 years ahead of the issue of a drug safety alert.  Using  this  pipeline, we  propose:  1)  to identfy and prioritize multi-drug  combinations that are worth testing; 2) to develop methods for discovering adverse event profiles of multi- drug  combinations; and  3)  to  create  an  EHR  derived  catalogue of potential adverse events of multi-drug combinations.  We will use hierarchies provided by existing public ontologies for drugs, diseases and side- effects to improve signal detection by aggregation, to reduce multiple hypothesis testing and to make a search for multi-drug side effects computationally tractable. PUBLIC HEALTH RELEVANCE: We propose to combine data from electronic medical records, adverse event reports in AERS, and prior knowledge in curated knowledgebases to construct a data-driven safety profile for drugs.  Successful development of novel methods will result in significant cost savings as well as a significant increase in patient safety, given the current rat (~30%) of occurrence of adverse drug events.  Completion of the aims will result in the first of it kind, EHR derived, resource of adverse event profiles of drugs.",Mining health data for drug safety profiles,9262239,R01GM101430,"['Adverse drug effect', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Ambulatory Care', 'Blinded', 'Catalogs', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Trials', 'Code', 'Comorbidity', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Drug Combinations', 'Drug usage', 'Electronic Health Record', 'Graph', 'Health', 'Healthcare', 'Individual', 'Inpatients', 'Knowledge', 'Label', 'Length of Stay', 'Life', 'Medical', 'Methods', 'Mining', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population Control', 'Population Growth', 'Positioning Attribute', 'Proxy', 'Rattus', 'Reporting', 'Resources', 'Safety', 'Side', 'Signal Transduction', 'Source', 'Surveillance Methods', 'System', 'Target Populations', 'Testing', 'Text', 'Time', 'United States', 'Validation', 'Work', 'aging population', 'base', 'biomedical ontology', 'blind', 'cost', 'data mining', 'drug efficacy', 'electronic data', 'health data', 'improved', 'insight', 'knowledge base', 'mortality', 'multiple drug use', 'novel', 'patient safety', 'public health relevance', 'safety testing', 'systematic review', 'tool', 'trend']",NIGMS,STANFORD UNIVERSITY,R01,2017,579554,0.029604953191607157
"Mining health data for drug safety profiles DESCRIPTION (provided by applicant): Clinical trials, which test the safety and efficacy of drugs in a controlled population, cannot identify all safety issues associated with drugs because the size and characteristics of the target population, duration of use, the concomitant disease conditions and therapies differ markedly in actual usage conditions.  On the outpatient side, medication related morbidity and mortality in the United States is estimated to result in 100,000 deaths and $177 billion in cost annually.  On the inpatient side, it is estimated that roughly 30% of hospital stays have an adverse drug event.  Current one-drug-at-a-time methods for surveillance are woefully inadequate because no one monitors the ""real life"" situation of patients getting over 3 concomitant drugs in the context of multiple co-morbidities.  In preliminary work, we have built an annotation and analysis pipeline that uses the knowledge-graph formed by public biomedical ontologies for the purpose data-mining unstructured clinical notes.  We have demonstrated that we can reproduce drug safety signals from the clinical notes on average 2.7 years ahead of the issue of a drug safety alert.  Using  this  pipeline, we  propose:  1)  to identfy and prioritize multi-drug  combinations that are worth testing; 2) to develop methods for discovering adverse event profiles of multi- drug  combinations; and  3)  to  create  an  EHR  derived  catalogue of potential adverse events of multi-drug combinations.  We will use hierarchies provided by existing public ontologies for drugs, diseases and side- effects to improve signal detection by aggregation, to reduce multiple hypothesis testing and to make a search for multi-drug side effects computationally tractable. PUBLIC HEALTH RELEVANCE: We propose to combine data from electronic medical records, adverse event reports in AERS, and prior knowledge in curated knowledgebases to construct a data-driven safety profile for drugs.  Successful development of novel methods will result in significant cost savings as well as a significant increase in patient safety, given the current rat (~30%) of occurrence of adverse drug events.  Completion of the aims will result in the first of it kind, EHR derived, resource of adverse event profiles of drugs.",Mining health data for drug safety profiles,9055718,R01GM101430,"['Adverse drug effect', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Ambulatory Care', 'Behavior Therapy', 'Blinded', 'Cataloging', 'Catalogs', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Trials', 'Code', 'Comorbidity', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Drug Combinations', 'Drug usage', 'Electronic Health Record', 'Graph', 'Growth', 'Health', 'Healthcare', 'Individual', 'Inpatients', 'Knowledge', 'Label', 'Length of Stay', 'Life', 'Medical Electronics', 'Methods', 'Mining', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population Control', 'Positioning Attribute', 'Proxy', 'Rattus', 'Reporting', 'Resources', 'Safety', 'Side', 'Signal Transduction', 'Source', 'Surveillance Methods', 'System', 'Target Populations', 'Testing', 'Text', 'Time', 'United States', 'Validation', 'Work', 'aging population', 'base', 'biomedical ontology', 'blind', 'cost', 'data mining', 'drug efficacy', 'health data', 'improved', 'insight', 'knowledge base', 'mortality', 'multiple drug use', 'novel', 'patient safety', 'safety testing', 'systematic review', 'tool', 'trend']",NIGMS,STANFORD UNIVERSITY,R01,2016,579554,0.029604953191607157
"Mining health data for drug safety profiles DESCRIPTION (provided by applicant): Clinical trials, which test the safety and efficacy of drugs in a controlled population, cannot identify all safety issues associated with drugs because the size and characteristics of the target population, duration of use, the concomitant disease conditions and therapies differ markedly in actual usage conditions.  On the outpatient side, medication related morbidity and mortality in the United States is estimated to result in 100,000 deaths and $177 billion in cost annually.  On the inpatient side, it is estimated that roughly 30% of hospital stays have an adverse drug event.  Current one-drug-at-a-time methods for surveillance are woefully inadequate because no one monitors the ""real life"" situation of patients getting over 3 concomitant drugs in the context of multiple co-morbidities.  In preliminary work, we have built an annotation and analysis pipeline that uses the knowledge-graph formed by public biomedical ontologies for the purpose data-mining unstructured clinical notes.  We have demonstrated that we can reproduce drug safety signals from the clinical notes on average 2.7 years ahead of the issue of a drug safety alert.  Using  this  pipeline, we  propose:  1)  to identfy and prioritize multi-drug  combinations that are worth testing; 2) to develop methods for discovering adverse event profiles of multi- drug  combinations; and  3)  to  create  an  EHR  derived  catalogue of potential adverse events of multi-drug combinations.  We will use hierarchies provided by existing public ontologies for drugs, diseases and side- effects to improve signal detection by aggregation, to reduce multiple hypothesis testing and to make a search for multi-drug side effects computationally tractable. PUBLIC HEALTH RELEVANCE: We propose to combine data from electronic medical records, adverse event reports in AERS, and prior knowledge in curated knowledgebases to construct a data-driven safety profile for drugs.  Successful development of novel methods will result in significant cost savings as well as a significant increase in patient safety, given the current rat (~30%) of occurrence of adverse drug events.  Completion of the aims will result in the first of it kind, EHR derived, resource of adverse event profiles of drugs.",Mining health data for drug safety profiles,8841751,R01GM101430,"['Adverse drug effect', 'Adverse drug event', 'Adverse effects', 'Adverse event', 'Ambulatory Care', 'Behavior Therapy', 'Blinded', 'Cataloging', 'Catalogs', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Trials', 'Code', 'Comorbidity', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Drug Combinations', 'Drug usage', 'Electronic Health Record', 'Graph', 'Growth', 'Health', 'Healthcare', 'Individual', 'Inpatients', 'Knowledge', 'Label', 'Length of Stay', 'Life', 'Medical Electronics', 'Methods', 'Mining', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population Control', 'Positioning Attribute', 'Proxy', 'Rattus', 'Reporting', 'Resources', 'Safety', 'Side', 'Signal Transduction', 'Source', 'Surveillance Methods', 'System', 'Target Populations', 'Testing', 'Text', 'Time', 'United States', 'Validation', 'Work', 'aging population', 'base', 'biomedical ontology', 'blind', 'cost', 'data mining', 'drug efficacy', 'health data', 'improved', 'insight', 'knowledge base', 'mortality', 'multiple drug use', 'novel', 'patient safety', 'safety testing', 'systematic review', 'tool', 'trend']",NIGMS,STANFORD UNIVERSITY,R01,2015,579554,0.029604953191607157
"Mining health data for drug safety profiles     DESCRIPTION (provided by applicant): Clinical trials, which test the safety and efficacy of drugs in a controlled population, cannot identify all safety issues associated with drugs because the size and characteristics of the target population, duration of use, the concomitant disease conditions and therapies differ markedly in actual usage conditions.  On the outpatient side, medication related morbidity and mortality in the United States is estimated to result in 100,000 deaths and $177 billion in cost annually.  On the inpatient side, it is estimated that roughly 30% of hospital stays have an adverse drug event.  Current one-drug-at-a-time methods for surveillance are woefully inadequate because no one monitors the ""real life"" situation of patients getting over 3 concomitant drugs in the context of multiple co-morbidities.  In preliminary work, we have built an annotation and analysis pipeline that uses the knowledge-graph formed by public biomedical ontologies for the purpose data-mining unstructured clinical notes.  We have demonstrated that we can reproduce drug safety signals from the clinical notes on average 2.7 years ahead of the issue of a drug safety alert.  Using  this  pipeline, we  propose:  1)  to identfy and prioritize multi-drug  combinations that are worth testing; 2) to develop methods for discovering adverse event profiles of multi- drug  combinations; and  3)  to  create  an  EHR  derived  catalogue of potential adverse events of multi-drug combinations.  We will use hierarchies provided by existing public ontologies for drugs, diseases and side- effects to improve signal detection by aggregation, to reduce multiple hypothesis testing and to make a search for multi-drug side effects computationally tractable.            PUBLIC HEALTH RELEVANCE: We propose to combine data from electronic medical records, adverse event reports in AERS, and prior knowledge in curated knowledgebases to construct a data-driven safety profile for drugs.  Successful development of novel methods will result in significant cost savings as well as a significant increase in patient safety, given the current rat (~30%) of occurrence of adverse drug events.  Completion of the aims will result in the first of it kind, EHR derived, resource of adverse event profiles of drugs.             ",Mining health data for drug safety profiles,8728954,R01GM101430,"['Adverse drug effect', 'Adverse effects', 'Adverse event', 'Ambulatory Care', 'Behavior Therapy', 'Blinded', 'Cataloging', 'Catalogs', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Trials', 'Code', 'Comorbidity', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Disease Association', 'Drug Combinations', 'Drug usage', 'Electronic Health Record', 'Event', 'Graph', 'Growth', 'Health', 'Healthcare', 'Individual', 'Inpatients', 'Knowledge', 'Label', 'Length of Stay', 'Life', 'Medical Electronics', 'Methods', 'Mining', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population Control', 'Positioning Attribute', 'Proxy', 'Rattus', 'Reporting', 'Resources', 'Safety', 'Side', 'Signal Transduction', 'Source', 'Surveillance Methods', 'System', 'Target Populations', 'Testing', 'Text', 'Time', 'United States', 'Validation', 'Work', 'aging population', 'base', 'biomedical ontology', 'blind', 'cost', 'data mining', 'drug efficacy', 'improved', 'insight', 'knowledge base', 'mortality', 'multiple drug use', 'novel', 'patient safety', 'public health relevance', 'safety testing', 'systematic review', 'tool', 'trend']",NIGMS,STANFORD UNIVERSITY,R01,2014,579554,0.029604953191607157
"Mining health data for drug safety profiles     DESCRIPTION (provided by applicant): Clinical trials, which test the safety and efficacy of drugs in a controlled population, cannot identify all safety issues associated with drugs because the size and characteristics of the target population, duration of use, the concomitant disease conditions and therapies differ markedly in actual usage conditions.  On the outpatient side, medication related morbidity and mortality in the United States is estimated to result in 100,000 deaths and $177 billion in cost annually.  On the inpatient side, it is estimated that roughly 30% of hospital stays have an adverse drug event.  Current one-drug-at-a-time methods for surveillance are woefully inadequate because no one monitors the ""real life"" situation of patients getting over 3 concomitant drugs in the context of multiple co-morbidities.  In preliminary work, we have built an annotation and analysis pipeline that uses the knowledge-graph formed by public biomedical ontologies for the purpose data-mining unstructured clinical notes.  We have demonstrated that we can reproduce drug safety signals from the clinical notes on average 2.7 years ahead of the issue of a drug safety alert.  Using  this  pipeline, we  propose:  1)  to identfy and prioritize multi-drug  combinations that are worth testing; 2) to develop methods for discovering adverse event profiles of multi- drug  combinations; and  3)  to  create  an  EHR  derived  catalogue of potential adverse events of multi-drug combinations.  We will use hierarchies provided by existing public ontologies for drugs, diseases and side- effects to improve signal detection by aggregation, to reduce multiple hypothesis testing and to make a search for multi-drug side effects computationally tractable.            PUBLIC HEALTH RELEVANCE: We propose to combine data from electronic medical records, adverse event reports in AERS, and prior knowledge in curated knowledgebases to construct a data-driven safety profile for drugs.  Successful development of novel methods will result in significant cost savings as well as a significant increase in patient safety, given the current rat (~30%) of occurrence of adverse drug events.  Completion of the aims will result in the first of it kind, EHR derived, resource of adverse event profiles of drugs.             ",Mining health data for drug safety profiles,8438322,R01GM101430,"['Adverse drug effect', 'Adverse effects', 'Adverse event', 'Ambulatory Care', 'Behavior Therapy', 'Blinded', 'Cataloging', 'Catalogs', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Trials', 'Code', 'Comorbidity', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Detection', 'Development', 'Dimensions', 'Disease', 'Disease Association', 'Drug Combinations', 'Drug usage', 'Electronic Health Record', 'Event', 'Graph', 'Growth', 'Health', 'Healthcare', 'Individual', 'Inpatients', 'Knowledge', 'Label', 'Length of Stay', 'Life', 'Medical Electronics', 'Methods', 'Mining', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Ontology', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Population Control', 'Positioning Attribute', 'Proxy', 'Rattus', 'Reporting', 'Resources', 'Safety', 'Side', 'Signal Transduction', 'Source', 'Surveillance Methods', 'System', 'Target Populations', 'Testing', 'Text', 'Time', 'United States', 'Validation', 'Work', 'aging population', 'base', 'biomedical ontology', 'blind', 'cost', 'data mining', 'drug efficacy', 'improved', 'insight', 'knowledge base', 'mortality', 'multiple drug use', 'novel', 'patient safety', 'public health relevance', 'safety testing', 'systematic review', 'tool', 'trend']",NIGMS,STANFORD UNIVERSITY,R01,2013,579554,0.029604953191607157
"Methods for High-Dimensional Statistical Inference and Individualized Risk Prediction under Semi-Competing Risks Project Summary/Abstract Patient care has been transformed by the availability of high-dimensional sources like electronic health records (EHR) and genomic data, allowing health care decisions to be tailored to individual patients. Statistical methods have been developed to efciently use such high dimensional data, but critical gaps still remain. Several common models for survival analysis have recently been extended to accommodate high-dimensional variable selection and machine learning prediction methods, but similar tools have not yet been developed for the setting of semi- competing risks. In the semi-competing risks setting, interest focuses on jointly modeling both a terminal time- to-event outcome, as well as a non-terminal time-to-event outcome which can only occur for subjects who have not yet experienced the terminal event. Examples of this exist in severe pregnancy-related diseases such as pre-eclampsia (PE - further described below). PE and subsequent delivery are natural semi-competing risks, as PE can develop before delivery, but not after. Current methods do not provide analysts with data-driven tools for uncovering important covariates from high-dimensional data, and clinicians lack meaningful, personalized predictions of patients' joint probability of experiencing one or both outcomes prospectively through time.  This proposal addresses these methodological gaps with tools for high-dimensional inference and prediction. In Aim 1, I will address the challenge of variable selection by developing a suite of regularized estimators for se- lecting important covariates from large datasets into a semi-competing risks model, and evaluating performance by simulation. In Aim 2, I will create a deep feed forward neural network modeling framework for predicting individual patients' joint probabilities of experiencing one or both outcomes of interest across future time points. Together, these aims will improve personalization of health care decisions. Software will be developed that provides researchers practical and user-friendly tools for applying these methods. In Aim 3, I will apply these approaches for semi-competing risks to evaluate risk of PE, which is globally a leading cause of maternal and fetal/neonatal mortality and morbidity. Using EHR pregnancy data from 50,000 births between 2011-2020, I will use the proposed variable selection methods to develop a model identifying risk factors for PE along with factors affecting time-to-delivery among PE patients. Through this work, I will also build a deep learning model in order to jointly predict maternal PE and NICU admission of the infant, yielding personalized prediction plots to facilitate care decisions that balance maternal and fetal health risks. For ease of use by clinicians and patients, I will disseminate this prediction model using an interactive online tool. Project Narrative  Using personalized risk prediction to help clinicians and patients make health care decisions is a vital and rapidly growing way to improve outcomes and quality of care. However, in the common survival analysis setting known as semi-competing risks where both a non-terminal event and a terminal event are of interest, there lack adequate methods for modeling patients' joint risks using high-dimensional data sources such as electronic health records. The focus of this proposal is the development of statistical and machine-learning methods for this setting to predict individual patients' prospective joint risk over time of experiencing one or both outcomes of interest, and apply them to risk stratication and individualized prediction of outcomes for preeclampsia in pregnant women.",Methods for High-Dimensional Statistical Inference and Individualized Risk Prediction under Semi-Competing Risks,9992419,F31HD102159,"['Address', 'Admission activity', 'Affect', 'Algorithms', 'Birth', 'Caring', 'Characteristics', 'Clinical', 'Code', 'Collaborations', 'Computer software', 'Data', 'Data Sources', 'Decision Making', 'Developed Countries', 'Developing Countries', 'Development', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Equilibrium', 'Event', 'Fellowship', 'Fetal health', 'Future', 'Goals', 'Health', 'Healthcare', 'Infant', 'Israel', 'Joints', 'Journals', 'Lasso', 'Machine Learning', 'Manuscripts', 'Maternal Health', 'Medical center', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mothers', 'Neonatal', 'Neonatal Mortality', 'Neural Network Simulation', 'Outcome', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Pre-Eclampsia', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Probability', 'Publications', 'Publishing', 'Quality of Care', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Risk stratification', 'Software Tools', 'Source', 'Statistical Methods', 'Survival Analysis', 'Techniques', 'Time', 'Woman', 'Work', 'deep learning', 'experience', 'falls', 'feedforward neural network', 'fetal', 'flexibility', 'genomic data', 'high dimensionality', 'improved', 'improved outcome', 'individual patient', 'insight', 'interactive tool', 'interest', 'large datasets', 'machine learning method', 'method development', 'multidimensional data', 'neonatal morbidity', 'novel', 'outcome prediction', 'personalized decision', 'personalized health care', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'prevent', 'prospective', 'simulation', 'skills', 'statistical and machine learning', 'tailored health care', 'theories', 'tool', 'unborn child', 'user-friendly']",NICHD,HARVARD SCHOOL OF PUBLIC HEALTH,F31,2020,39120,0.03769695369427959
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,9033918,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2016,562809,0.0702060836416552
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,8826771,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2015,571551,0.0702060836416552
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,8920720,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2014,160000,0.0702060836416552
"Natural language processing for clinical and translational research     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.                ",Natural language processing for clinical and translational research,8640959,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'public health relevance', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2014,580082,0.0702060836416552
"Natural language processing for clinical and translational research     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.                ",Natural language processing for clinical and translational research,8505753,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'public health relevance', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2013,630706,0.0702060836416552
"Text Processing and Geospatial Uncertainty for Phylogeography of Zoonotic Viruses     DESCRIPTION (provided by applicant): Phylogeography of zoonotic viruses studies the geographical spread and genetic lineages of viruses that are transmittable between animals and humans such as avian influenza and rabies. This science can help state public health and agriculture agencies identify the animal hosts that most impact virus propagation in a particular geographic region, the migration path of the virus including its origin, and the patterns of infection in various host populations, including humans, over time. The National Center for Biotechnology Information (NCBI), specifically GenBank, provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. However, geospatial metadata such as host location is inconsistently represented and sparse across GenBank entries, with our preliminary studies showing only about 20% of the GenBank records contain specific information such as a county, town, or region within a state. While this detailed geospatial information might be included in the corresponding journal article, it is not available for immediate use in a bioinformatics or GIS application unless it is manually extracted and linked back to the appropriate sequence. Absence of precise sampling locations from easily-computable secondary data sources such as GenBank increases the difficulty of achieving accurate phylogeographic models of virus migration. We propose an infrastructure to improve phylogeographic models of virus migration by linking relevant geospatial data from the literature. This work represents the first effort to use automatically extracted geospatial data present in journal articles corresponding to GenBank records in order to enhance modeling of virus migration. Our research will extend phylogeography and zoonotic surveillance by: creating a Natural Language Processing (NLP) infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the data extracted in Aim 1 with adequate biostatistical models (Aim 2), and evaluating the impact of our approach for phylogeography and surveillance of zoonotic viruses (Aim 3). Thus, this work will provide researchers with a framework for population surveillance using an integrated biomedical informatics approach including NLP, biostatistics, bioinformatics, and database design.           We will create Natural Language Processing Infrastructure and novel phylogeographic models of zoonotic viruses that will allow state public health and agriculture agencies and other researchers to study virus migration. This will enhance population health surveillance including identification of the animal hosts that most impact virus propagation in a particular geographic region, the migration path of zoonotic pathogens, and the patterns of infection in various host populations over time, including humans. This resource will enable state agencies to implement improved public health control measures that will reduce morbidity and mortality of animals and humans from zoonotic diseases.                ",Text Processing and Geospatial Uncertainty for Phylogeography of Zoonotic Viruses,8698542,R56AI102559,"['Accounting', 'Address', 'Agriculture', 'Animals', 'Applied Research', 'Avian Influenza', 'Back', 'Bioinformatics', 'Biometry', 'Biotechnology', 'China', 'Computer software', 'Country', 'County', 'Data', 'Data Sources', 'Databases', 'Development', 'Disease', 'Epidemiologist', 'Evaluation', 'Event', 'Foundations', 'Funding', 'Genbank', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Geographic Locations', 'Goals', 'Gold', 'Habitats', 'Hantavirus', 'Human', 'Infection', 'Influenza', 'Information Systems', 'Label', 'Link', 'Literature', 'Location', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Pattern', 'Population', 'Population Surveillance', 'Process', 'Public Health', 'Publications', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Solutions', 'Surveillance Modeling', 'System', 'Techniques', 'Text', 'Time', 'Trees', 'Uncertainty', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'Work', 'animal mortality', 'biomedical informatics', 'data modeling', 'database design', 'disease transmission', 'improved', 'journal article', 'migration', 'mortality', 'novel', 'pathogen', 'population health', 'web site']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R56,2013,451478,-0.02604881318964565
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,8929257,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Health', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Population Study', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'improved', 'large-scale database', 'novel', 'open source', 'personalized medicine', 'rapid growth', 'rare variant', 'response', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY,R01,2015,598996,0.007838729826677425
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers.         PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.            ",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,8629996,R01GM103859,"['Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Medicine', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Population Study', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'improved', 'large-scale database', 'novel', 'open source', 'public health relevance', 'rapid growth', 'rare variant', 'response', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY,R01,2014,648591,0.007838729826677425
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,9068953,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Health', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'genomic data', 'improved', 'large-scale database', 'novel', 'open source', 'personalized medicine', 'rapid growth', 'rare variant', 'response', 'study population', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2016,536892,0.007838729826677425
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,9307936,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Databases', 'Disease', 'Drug Exposure', 'Drug Modelings', 'Drug toxicity', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'cost', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'genomic data', 'improved', 'longitudinal dataset', 'novel', 'open source', 'personalized medicine', 'phenotypic data', 'public health relevance', 'rapid growth', 'rare variant', 'response', 'study population', 'success', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,600474,0.007838729826677425
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as EHR-driven phenotyping is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9707366,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'interoperability', 'knowledge base', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2018,429621,0.08838602858511882
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as EHR-driven phenotyping is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,10021669,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Consumption', 'Data', 'Data Element', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Fast Healthcare Interoperability Resources', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare Systems', 'Human', 'Informatics', 'Infrastructure', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness study', 'computable phenotypes', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'knowledge base', 'meetings', 'phenotyping algorithm', 'portability', 'precision medicine', 'repository', 'structured data', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2020,706851,0.08838602858511882
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as EHR-driven phenotyping is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9774075,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Consumption', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Fast Healthcare Interoperability Resources', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare Systems', 'Human', 'Informatics', 'Infrastructure', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'knowledge base', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2019,706851,0.08838602858511882
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as EHR-driven phenotyping is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9547873,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'interoperability', 'knowledge base', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2018,706851,0.08838602858511882
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as EHR-driven phenotyping is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9381197,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Event', 'Exclusion Criteria', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Intuition', 'Knowledge', 'Learning', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'database query', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'interoperability', 'knowledge base', 'learning strategy', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2017,745771,0.08838602858511882
"Natural language processing for characterizing psychopathology     DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9445485,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'patient subsets', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'readmission risk', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,376490,0.06958941250479753
"Natural language processing for characterizing psychopathology     DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9254614,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,377260,0.06958941250479753
"Natural language processing for characterizing psychopathology     DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions.         PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.            ",Natural language processing for characterizing psychopathology,9105846,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electronics', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Process', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Severities', 'Stratification', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'cohort', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2016,413500,0.06958941250479753
"Web Software to develop an RDoC-Compatible Adaptive Diagnostic Nosology, the SID-5 n psychiatry, clinical judgment has been the predominant method of diagnosis. The `gold standard for clinical research is the Structured Clinical Interview for DSM-5 (SCID-5). The SCID-5 promotes reliability, but its validity is questionable. There is growing recognition that biomarkers can be used to identify more homogeneous patient populations, but there is substantial phenotypic discordance for schizophrenia even in identical twins. In the absence of symptom data, biomarkers alone are unlikely to yield a clinical diagnosis.  In a past SBIR project, TeleSage Inc. successfully converted the paper SCID into a web-based software program. The NetSCID-5 is now widely used in research. Nevertheless, in order to achieve the goal of turning clinical care networks into centers for research (Insel, Director's Blog, 2012) and furthering the RDoC initiative, we need a means of gathering rigorous diagnostic data in routine clinical care. This software must (a) require minimal clinician time, (b) allow clinics to bill according to the current DSM-5 categories, and (c) be able to gather the large amount of data necessary to inform a broad research agenda including machine learning techniques. TeleSage proposes to develop a self-report diagnostic assessment that satisfies both immediate clinical needs and broader research goals: the Screening Interview for Diagnosis or SID.  TeleSage has worked with an expert panel including Dr. Michael First, the primary author of the SCID- 5, iteratively developing and testing self-report items. Based on expert panel review and cognitive interviewing, we identified a final set of 661 unique self-report, Likert-scale items covering all of the individual sub-symptoms described within each of the SCID criteria. TeleSage has also created a behavioral health PORTAL that includes the NetSCID-5, IRT/CAT item administration, randomization, and longitudinal reporting capabilities. The PORTAL exchanges data and reports with several EHRs including the NetSmart EHR system.  This Direct-to-Phase II application aims to create the SID, which will (a) reside on our existing secure web PORTAL, (b) administer simple Likert-scale self-report items, (c) generate DSM-5 and ICD-10 diagnoses for billing, (d) use minimal clinician time, (e) pull pre-defined data fields from the EHR (e.g. family history, demographic, and biomarker data), (f) be able to add new self-report items for exploration, (g) integrate with machine learning tools, and (h) send raw data and interpretive reports to EHR systems. Because of these features, we believe that the SID has the potential to be used widely by both clinicians and researchers.  The SID is intended to help transcend DSM-5 and to support RDoC. The SID product must be commercially successful and useful both in routine clinical care and research. The SID is intended to facilitate the development and evolution of a new behavioral health nosology based on the aggregation of biomarker and symptom data, a nosology that is more analogous to those found in other fields of medicine. The Structured Clinical Interview for DSM-5 (SCID-5) represents the current diagnostic gold standard in behavioral health and yields much more reliable diagnoses than the unstructured patient interviews that predominate in clinical settings; however, the full SCID-5 is a lengthy and complex paper-and-pencil instrument that takes approximately 90 minutes to administer and is thus seldom used outside of clinical research settings. We want to create a new, self-report software tool that will save clinicians time relative to the paper SCID, significantly reduce diagnostic error rates, greatly increase the reliability of diagnoses in routine clinical care, and integrate seamlessly into Electronic Health Record (EHR) systems: the Screening Inventory for Diagnosis (SID). The SID is a self-report, computer-adaptive diagnostic assessment, based on easy-to- understand, five-point Likert-scale items. The SID is intended to help transcend DSM-5, support RDoC, and facilitate the development and evolution of a new behavioral health nosology based on the aggregation of biomarker and symptom data.","Web Software to develop an RDoC-Compatible Adaptive Diagnostic Nosology, the SID-5",9255772,R44MH108177,"['Adult', 'Algorithms', 'Alleles', 'Area', 'Behavioral', 'Biological Markers', 'Blood Chemical Analysis', 'Brain scan', 'Categories', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Complex', 'Computer software', 'Computers', 'DSM-IV', 'DSM-V', 'Data', 'Data Reporting', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Differential Diagnosis', 'Electronic Health Record', 'Ensure', 'Equipment and supply inventories', 'Evolution', 'Family', 'Future', 'Gene Frequency', 'Genes', 'Goals', 'Gold', 'Healthcare', 'Hour', 'Individual', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Internet', 'Intervention', 'Interview', 'Judgment', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medicine', 'Mental Health', 'Methodology', 'Methods', 'Monozygotic twins', 'Online Systems', 'Paper', 'Participant', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Pilot Projects', 'Population', 'Psyche structure', 'Psychiatry', 'Public Sector', 'Publishing', 'Questionnaires', 'Randomized', 'Recording of previous events', 'Reporting', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Sampling', 'Savings', 'Schedule', 'Schizophrenia', 'Secure', 'Severities', 'Small Business Innovation Research Grant', 'Software Tools', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Transcend', 'Update', 'Work', 'base', 'behavioral health', 'clinical Diagnosis', 'clinical care', 'data exchange', 'disease classification', 'epigenetic marker', 'follow-up', 'health care service', 'instrument', 'mental health center', 'patient population', 'personalized medicine', 'programs', 'satisfaction', 'screening', 'specific biomarkers', 'symptom cluster', 'tool', 'usability', 'web portal']",NIMH,"TELESAGE, INC.",R44,2017,433630,0.043566030621549935
"BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO)     DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's.              n/a",BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO),8840825,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Beds', 'Benchmarking', 'Big Data', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Child health care', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Development', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Names', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'data visualization', 'design', 'emergency service responder', 'experience', 'genetic variant', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'interoperability', 'medical information system', 'novel', 'open source', 'parallel processing', 'performance tests', 'processing speed', 'repository', 'research study', 'response', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R01,2015,529458,0.019989074869853362
"Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictio DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to  explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index  patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's. n/a",Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictio,8599828,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Beds', 'Benchmarking', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Child health care', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Development', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Mutation', 'Names', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'design', 'emergency service responder', 'experience', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'interoperability', 'medical information system', 'novel', 'open source', 'parallel processing', 'performance tests', 'processing speed', 'repository', 'research study', 'response', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual']",NIGMS,UNIVERSITY OF UTAH,R01,2013,568249,0.019989074869853362
"BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO) DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's. n/a",BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO),9066173,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Assessment tool', 'Beds', 'Benchmarking', 'Big Data', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Names', 'National Institute of Child Health and Human Development', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'data visualization', 'design', 'emergency service responder', 'experience', 'genetic variant', 'genome analysis', 'genome sequencing', 'genomic data', 'improved', 'indexing', 'interoperability', 'learning strategy', 'medical information system', 'novel', 'open source', 'outcome prediction', 'parallel processing', 'performance tests', 'personalized care', 'predict clinical outcome', 'processing speed', 'reference genome', 'repository', 'research study', 'response', 'search engine', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual', 'whole genome']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R01,2016,507805,0.019989074869853362
"Biocreative Conference Grant DESCRIPTION (provided by applicant): The goal of this proposal is to provide a venue for the evaluation of biomedical text mining tools via the shared task paradigm, particularly tools with relevance to problems in biocuration. Biocurators will help define use cases and desired functionalities; stakeholders will come to agreement on task definitions, data sets, and evaluation metrics; text mining teams will then work on these consensus tasks and come together to share their results and gain further feedback from biocurators. PUBLIC HEALTH RELEVANCE: This project consists of the evaluation of biomedical text mining tools, particularly ones applied to projects in biocuration. The results of biocuration are extensively used in modern medical practice, particularly personalized medicine, so the work of the grant has the potential to have a substantial impact on the cutting edge of human healthcare.",Biocreative Conference Grant,9135507,R13GM109648,"['Agreement', 'Algorithms', 'Awareness', 'Bioinformatics', 'Clinical', 'Consensus', 'Data Set', 'Databases', 'Development', 'Doctor of Philosophy', 'Educational workshop', 'Evaluation', 'Feedback', 'Fostering', 'Goals', 'Grant', 'Health', 'Healthcare', 'Housing', 'Human', 'Medical', 'Methods', 'Publishing', 'Research Personnel', 'Series', 'Staging', 'Work', 'career', 'interdisciplinary collaboration', 'personalized medicine', 'student participation', 'symposium', 'text searching', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R13,2016,12000,0.013465647143470599
"Biocreative Conference Grant DESCRIPTION (provided by applicant): The goal of this proposal is to provide a venue for the evaluation of biomedical text mining tools via the shared task paradigm, particularly tools with relevance to problems in biocuration. Biocurators will help define use cases and desired functionalities; stakeholders will come to agreement on task definitions, data sets, and evaluation metrics; text mining teams will then work on these consensus tasks and come together to share their results and gain further feedback from biocurators. PUBLIC HEALTH RELEVANCE: This project consists of the evaluation of biomedical text mining tools, particularly ones applied to projects in biocuration. The results of biocuration are extensively used in modern medical practice, particularly personalized medicine, so the work of the grant has the potential to have a substantial impact on the cutting edge of human healthcare.",Biocreative Conference Grant,8912507,R13GM109648,"['Agreement', 'Algorithms', 'Awareness', 'Bioinformatics', 'Clinical', 'Consensus', 'Data Set', 'Databases', 'Development', 'Doctor of Philosophy', 'Educational workshop', 'Evaluation', 'Feedback', 'Fostering', 'Goals', 'Grant', 'Health', 'Healthcare', 'Housing', 'Human', 'Medical', 'Methods', 'Publishing', 'Research Personnel', 'Series', 'Staging', 'Students', 'Work', 'career', 'interdisciplinary collaboration', 'personalized medicine', 'symposium', 'text searching', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R13,2015,12000,0.013465647143470599
"Biocreative Conference Grant     DESCRIPTION (provided by applicant): The goal of this proposal is to provide a venue for the evaluation of biomedical text mining tools via the shared task paradigm, particularly tools with relevance to problems in biocuration. Biocurators will help define use cases and desired functionalities; stakeholders will come to agreement on task definitions, data sets, and evaluation metrics; text mining teams will then work on these consensus tasks and come together to share their results and gain further feedback from biocurators.         PUBLIC HEALTH RELEVANCE: This project consists of the evaluation of biomedical text mining tools, particularly ones applied to projects in biocuration. The results of biocuration are extensively used in modern medical practice, particularly personalized medicine, so the work of the grant has the potential to have a substantial impact on the cutting edge of human healthcare.            ",Biocreative Conference Grant,8786017,R13GM109648,"['Agreement', 'Algorithms', 'Awareness', 'Bioinformatics', 'Clinical', 'Consensus', 'Data Set', 'Databases', 'Development', 'Doctor of Philosophy', 'Educational workshop', 'Evaluation', 'Feedback', 'Fostering', 'Goals', 'Grant', 'Healthcare', 'Housing', 'Human', 'Medical', 'Medicine', 'Methods', 'Metric', 'Publishing', 'Research Personnel', 'Series', 'Staging', 'Students', 'Work', 'career', 'interdisciplinary collaboration', 'public health relevance', 'symposium', 'text searching', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R13,2014,12000,0.013465647143470599
"Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities Abstract: We propose in this application to use truly unique resources available to the Vanderbilt University research community to identify and characterize genetic risk factors for neuropsychiatric disorders. Our overarching hypothesis is that co-morbid phenotypes that cut across neuropsychiatric disorders can be used to identify more homogeneous genetic risk factors that will also be cross-cutting for neuropsychiatric diseases. To address this hypothesis, we will harness the long-standing strengths in neuroscience at Vanderbilt including extensive expertise in conducting in vivo and in vitro experimental validation studies, the strong team of investigators with long-standing research programs in key co-morbid phenotypes and neuropsychiatric disease, and our track record in developing and applying novel integrative approaches for genome investigation. The clinical data warehouse at Vanderbilt is called the Synthetic Derivative (SD), and contains continuously updated electronic health records (EHR) on more than 2,500,000 individuals. DNA samples are available on more than 217,000 of the individuals in the SD through BioVU, the biobank at Vanderbilt University. Individuals with more longitudinal data some going back as long as 20-30 years have been prioritized for genome investigation, and genome interrogation (GWAS or whole genome sequencing) will be available on > 120,000 of these subjects in 2018. The SD provides unprecedented power for characterizing cross-cutting comorbidities for neuropsychiatric disorders, and the large number of BioVU samples with genome interrogation coupled with the novel analytic approaches we have devised to optimize genome investigations in BioVU create a dynamic engine for discovery research. Our specific aims are to: 1) Use EHR data on more than 2,500,000 individuals to investigate the relationship between neuropsychiatric disorders and comorbid phenotypes shared among multiple of these disorders; 2) Use the novel PrediXcan approach to identify genes for which genetically predicted expression is significantly associated with neuropsychiatric disease, neuropsychiatric disease plus comorbidity, or comorbidity for more than 120,000 samples in BioVU; and 3) Prioritize genes for validation using improved network and pathway analyses, and then experimentally validate genes implicated in neuropsychiatric and comorbid phenotypes. Public Health Statement Studying patients with neuropsychiatric disorders that also have other health problems (seizures, sleep disorders, gastrointestinal disease, etc) using electronic health records from a large biobank may improve our ability to identify genes that contribute to these disorders.",Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities,9921484,R01MH113362,"['Address', 'Affect', 'Architecture', 'Attention deficit hyperactivity disorder', 'Back', 'Behavior', 'Biological Assay', 'Biological Markers', 'Biological Models', 'Biology', 'Bipolar Disorder', 'Cells', 'Code', 'Communities', 'Coupled', 'DNA', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Dysmorphology', 'Electronic Health Record', 'Epilepsy', 'Gastrointestinal Diseases', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Gilles de la Tourette syndrome', 'Health', 'Heritability', 'In Vitro', 'Individual', 'Investigation', 'Knock-in', 'Knock-out', 'Knowledge', 'Knowledge Portal', 'Learning', 'Link', 'Major Depressive Disorder', 'Medical', 'Mendelian disorder', 'Modeling', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacy facility', 'Phenotype', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Schizophrenia', 'Seizures', 'Services', 'Sleep Disorders', 'Specificity', 'Swimming', 'System', 'Test Result', 'Testing', 'Tissues', 'Transcript', 'United States National Institutes of Health', 'Universities', 'Update', 'Validation', 'Variant', 'Zebrafish', 'autism spectrum disorder', 'base', 'behavioral phenotyping', 'biobank', 'biomedical informatics', 'brain morphology', 'cell type', 'clinical data warehouse', 'comorbidity', 'congenital anomaly', 'craniofacial', 'database of Genotypes and Phenotypes', 'gastrointestinal function', 'genetic architecture', 'genetic risk factor', 'genetic testing', 'genome sequencing', 'genome wide association study', 'improved', 'in vivo', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'overexpression', 'programs', 'psychiatric genomics', 'targeted treatment', 'text searching', 'validation studies', 'whole genome']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,694113,-0.00032594411895032875
"Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities Abstract: We propose in this application to use truly unique resources available to the Vanderbilt University research community to identify and characterize genetic risk factors for neuropsychiatric disorders. Our overarching hypothesis is that co-morbid phenotypes that cut across neuropsychiatric disorders can be used to identify more homogeneous genetic risk factors that will also be cross-cutting for neuropsychiatric diseases. To address this hypothesis, we will harness the long-standing strengths in neuroscience at Vanderbilt including extensive expertise in conducting in vivo and in vitro experimental validation studies, the strong team of investigators with long-standing research programs in key co-morbid phenotypes and neuropsychiatric disease, and our track record in developing and applying novel integrative approaches for genome investigation. The clinical data warehouse at Vanderbilt is called the Synthetic Derivative (SD), and contains continuously updated electronic health records (EHR) on more than 2,500,000 individuals. DNA samples are available on more than 217,000 of the individuals in the SD through BioVU, the biobank at Vanderbilt University. Individuals with more longitudinal data some going back as long as 20-30 years have been prioritized for genome investigation, and genome interrogation (GWAS or whole genome sequencing) will be available on > 120,000 of these subjects in 2018. The SD provides unprecedented power for characterizing cross-cutting comorbidities for neuropsychiatric disorders, and the large number of BioVU samples with genome interrogation coupled with the novel analytic approaches we have devised to optimize genome investigations in BioVU create a dynamic engine for discovery research. Our specific aims are to: 1) Use EHR data on more than 2,500,000 individuals to investigate the relationship between neuropsychiatric disorders and comorbid phenotypes shared among multiple of these disorders; 2) Use the novel PrediXcan approach to identify genes for which genetically predicted expression is significantly associated with neuropsychiatric disease, neuropsychiatric disease plus comorbidity, or comorbidity for more than 120,000 samples in BioVU; and 3) Prioritize genes for validation using improved network and pathway analyses, and then experimentally validate genes implicated in neuropsychiatric and comorbid phenotypes. Public Health Statement Studying patients with neuropsychiatric disorders that also have other health problems (seizures, sleep disorders, gastrointestinal disease, etc) using electronic health records from a large biobank may improve our ability to identify genes that contribute to these disorders.",Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities,9691051,R01MH113362,"['Address', 'Affect', 'Architecture', 'Attention deficit hyperactivity disorder', 'Back', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Markers', 'Biological Models', 'Biology', 'Bipolar Disorder', 'Cells', 'Code', 'Communities', 'Comorbidity', 'Coupled', 'DNA', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Dysmorphology', 'Electronic Health Record', 'Epilepsy', 'Gastrointestinal Diseases', 'Gene Expression', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Gilles de la Tourette syndrome', 'Health', 'Heritability', 'In Vitro', 'Individual', 'Investigation', 'Knock-in', 'Knock-out', 'Knowledge', 'Learning', 'Link', 'Major Depressive Disorder', 'Medical', 'Mendelian disorder', 'Modeling', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacy facility', 'Phenotype', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Schizophrenia', 'Seizures', 'Services', 'Sleep Disorders', 'Specificity', 'Swimming', 'System', 'Test Result', 'Testing', 'Tissues', 'Transcript', 'United States National Institutes of Health', 'Universities', 'Update', 'Validation', 'Variant', 'Zebrafish', 'autism spectrum disorder', 'base', 'biobank', 'biomedical informatics', 'brain morphology', 'cell type', 'clinical data warehouse', 'congenital anomaly', 'craniofacial', 'database of Genotypes and Phenotypes', 'gastrointestinal function', 'genetic architecture', 'genetic risk factor', 'genome sequencing', 'genome wide association study', 'improved', 'in vivo', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'overexpression', 'programs', 'targeted treatment', 'text searching', 'validation studies', 'whole genome']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,694113,-0.00032594411895032875
"Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities Abstract: We propose in this application to use truly unique resources available to the Vanderbilt University research community to identify and characterize genetic risk factors for neuropsychiatric disorders. Our overarching hypothesis is that co-morbid phenotypes that cut across neuropsychiatric disorders can be used to identify more homogeneous genetic risk factors that will also be cross-cutting for neuropsychiatric diseases. To address this hypothesis, we will harness the long-standing strengths in neuroscience at Vanderbilt including extensive expertise in conducting in vivo and in vitro experimental validation studies, the strong team of investigators with long-standing research programs in key co-morbid phenotypes and neuropsychiatric disease, and our track record in developing and applying novel integrative approaches for genome investigation. The clinical data warehouse at Vanderbilt is called the Synthetic Derivative (SD), and contains continuously updated electronic health records (EHR) on more than 2,500,000 individuals. DNA samples are available on more than 217,000 of the individuals in the SD through BioVU, the biobank at Vanderbilt University. Individuals with more longitudinal data some going back as long as 20-30 years have been prioritized for genome investigation, and genome interrogation (GWAS or whole genome sequencing) will be available on > 120,000 of these subjects in 2018. The SD provides unprecedented power for characterizing cross-cutting comorbidities for neuropsychiatric disorders, and the large number of BioVU samples with genome interrogation coupled with the novel analytic approaches we have devised to optimize genome investigations in BioVU create a dynamic engine for discovery research. Our specific aims are to: 1) Use EHR data on more than 2,500,000 individuals to investigate the relationship between neuropsychiatric disorders and comorbid phenotypes shared among multiple of these disorders; 2) Use the novel PrediXcan approach to identify genes for which genetically predicted expression is significantly associated with neuropsychiatric disease, neuropsychiatric disease plus comorbidity, or comorbidity for more than 120,000 samples in BioVU; and 3) Prioritize genes for validation using improved network and pathway analyses, and then experimentally validate genes implicated in neuropsychiatric and comorbid phenotypes. Public Health Statement Studying patients with neuropsychiatric disorders that also have other health problems (seizures, sleep disorders, gastrointestinal disease, etc) using electronic health records from a large biobank may improve our ability to identify genes that contribute to these disorders.",Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities,9531459,R01MH113362,"['Address', 'Affect', 'Architecture', 'Attention deficit hyperactivity disorder', 'Back', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Markers', 'Biological Models', 'Biology', 'Bipolar Disorder', 'Cells', 'Code', 'Communities', 'Comorbidity', 'Coupled', 'DNA', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Dysmorphology', 'Electronic Health Record', 'Epilepsy', 'Gastrointestinal Diseases', 'Gene Expression', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Gilles de la Tourette syndrome', 'Health', 'Heritability', 'In Vitro', 'Individual', 'Investigation', 'Knock-in', 'Knock-out', 'Knowledge', 'Learning', 'Link', 'Major Depressive Disorder', 'Medical', 'Mendelian disorder', 'Modeling', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacy facility', 'Phenotype', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Schizophrenia', 'Seizures', 'Services', 'Sleep Disorders', 'Specificity', 'Swimming', 'System', 'Test Result', 'Testing', 'Tissues', 'Transcript', 'United States National Institutes of Health', 'Universities', 'Update', 'Validation', 'Variant', 'Zebrafish', 'autism spectrum disorder', 'base', 'biobank', 'biomedical informatics', 'brain morphology', 'cell type', 'clinical data warehouse', 'congenital anomaly', 'craniofacial', 'database of Genotypes and Phenotypes', 'gastrointestinal function', 'genetic architecture', 'genetic risk factor', 'genome sequencing', 'genome wide association study', 'improved', 'in vivo', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'overexpression', 'programs', 'targeted treatment', 'text searching', 'validation studies', 'whole genome']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,694113,-0.00032594411895032875
"Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities Abstract: We propose in this application to use truly unique resources available to the Vanderbilt University research community to identify and characterize genetic risk factors for neuropsychiatric disorders. Our overarching hypothesis is that co-morbid phenotypes that cut across neuropsychiatric disorders can be used to identify more homogeneous genetic risk factors that will also be cross-cutting for neuropsychiatric diseases. To address this hypothesis, we will harness the long-standing strengths in neuroscience at Vanderbilt including extensive expertise in conducting in vivo and in vitro experimental validation studies, the strong team of investigators with long-standing research programs in key co-morbid phenotypes and neuropsychiatric disease, and our track record in developing and applying novel integrative approaches for genome investigation. The clinical data warehouse at Vanderbilt is called the Synthetic Derivative (SD), and contains continuously updated electronic health records (EHR) on more than 2,500,000 individuals. DNA samples are available on more than 217,000 of the individuals in the SD through BioVU, the biobank at Vanderbilt University. Individuals with more longitudinal data some going back as long as 20-30 years have been prioritized for genome investigation, and genome interrogation (GWAS or whole genome sequencing) will be available on > 120,000 of these subjects in 2018. The SD provides unprecedented power for characterizing cross-cutting comorbidities for neuropsychiatric disorders, and the large number of BioVU samples with genome interrogation coupled with the novel analytic approaches we have devised to optimize genome investigations in BioVU create a dynamic engine for discovery research. Our specific aims are to: 1) Use EHR data on more than 2,500,000 individuals to investigate the relationship between neuropsychiatric disorders and comorbid phenotypes shared among multiple of these disorders; 2) Use the novel PrediXcan approach to identify genes for which genetically predicted expression is significantly associated with neuropsychiatric disease, neuropsychiatric disease plus comorbidity, or comorbidity for more than 120,000 samples in BioVU; and 3) Prioritize genes for validation using improved network and pathway analyses, and then experimentally validate genes implicated in neuropsychiatric and comorbid phenotypes. Public Health Statement Studying patients with neuropsychiatric disorders that also have other health problems (seizures, sleep disorders, gastrointestinal disease, etc) using electronic health records from a large biobank may improve our ability to identify genes that contribute to these disorders.",Discovering Biology for Neuropsychiatric Diseases Through Omics Studies on Comorbidities,9333934,R01MH113362,"['Address', 'Affect', 'Architecture', 'Attention deficit hyperactivity disorder', 'Back', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Markers', 'Biological Models', 'Biology', 'Bipolar Disorder', 'Cells', 'Code', 'Communities', 'Comorbidity', 'Coupled', 'DNA', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Dysmorphology', 'Electronic Health Record', 'Epilepsy', 'Gastrointestinal Diseases', 'Gene Expression', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Gilles de la Tourette syndrome', 'Health', 'Heritability', 'In Vitro', 'Individual', 'Investigation', 'Knock-in', 'Knock-out', 'Knowledge', 'Learning', 'Link', 'Major Depressive Disorder', 'Medical', 'Mendelian disorder', 'Modeling', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacy facility', 'Phenotype', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Schizophrenia', 'Seizures', 'Services', 'Sleep Disorders', 'Specificity', 'Swimming', 'System', 'Test Result', 'Testing', 'Tissues', 'Transcript', 'United States National Institutes of Health', 'Universities', 'Update', 'Validation', 'Variant', 'Zebrafish', 'autism spectrum disorder', 'base', 'biobank', 'biomedical informatics', 'brain morphology', 'cell type', 'clinical data warehouse', 'congenital anomaly', 'craniofacial', 'database of Genotypes and Phenotypes', 'gastrointestinal function', 'genetic risk factor', 'genome sequencing', 'genome wide association study', 'improved', 'in vivo', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'overexpression', 'programs', 'targeted treatment', 'text searching', 'validation studies', 'whole genome']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,759644,-0.00032594411895032875
"Evaluating the Impact of Changes in Opioid Prescribing Across Health Systems Implementing Zero Suicide This timely supplement would support our goals for the current award: An Evaluation of the National Zero Suicide Model Across Learning Healthcare Systems (U01MH114087) by capitalizing on a natural experiment, the planned the national roll-out of safety planning templates in behavioral health departments across five Kaiser Permanente regions and Henry Ford Health System in 2019. Safety planning is a highly recommended practice within the Zero Suicide (ZS) framework, but little is known about the effectiveness of the individual elements that can make up a safety plan, such as lethal means assessment, identification of supportive contacts, coping skills, warning signs, and sources of distraction. The current Zero Suicide award proposes to examine the impact of safety planning and lethal means assessment using a stepped-wedged interrupted time- series (ITS) approach, measuring each as a binary variable (e.g. safety planning did or did not occur). The ITS approach requires that some sites implement safety planning (intervention sites for safety planning), while others do not (control sites for safety planning). The proposed ITS approach is now problematic without further work for two reasons: 1) All Kaiser Permanente sites and Henry Ford have decided to uniformly implement safety planning around the same time, therefore there are no control sites 2) Without control sites, metrics that can accurately measure variation in safety planning/lethal means assessment at baseline and then longitudinally thereafter would enable our evaluation to take place, but all of the documentation lives in text- based clinical narratives. In working with our health system leads on the development of Zero Suicide metrics, we have been informed that the rate for safety planning and lethal means assessment at baseline is not zero, but the actual rate is unknown. This supplement will support development of new metrics using Natural Language Processing to determine baseline rates, from which, we can quantify the change in safety planning and lethal means assessment practice longitudinally after implementation of new safety planning templates using our Zero Suicide main award. Furthermore, we propose to take advantage of the newly implemented templates to address an important mediator of the effect of safety planning on suicide outcomes, the impact of fidelity to the new templates, which we define as quality, completeness, and level of integration with ongoing care. We propose the following three specific aims for this supplemental work: 1) Identify key terms for safety planning and lethal means assessment 1.) Develop Natural Language Processing (NLP) metrics to assess the occurrence of safety planning and lethal means assessment at three Zero Suicide sites 2) Implement NLP queries for identification of safety planning and lethal means assessment and measure baseline rates 3) Upon implementation of electronic safety planning templates in medical records, develop and implement metrics using NLP for assessing fidelity (completeness, quality, integration with care) to safety planning templates. Project Narrative: This supplement to the current award: An Evaluation of the National Zero Suicide Model Across Learning Healthcare Systems (U01MH114087) will take advantage of a national roll-out for safety planning templates in the electronic medical record across 5 Kaiser Permanente regions and Henry Ford Health System. It will support the development of innovative measures using natural language processing to efficiently quantify the baseline rates of safety planning and lethal means assessment across multiple sites, which will enable a rigorous evaluation to take place upon implementation of the new electronic templates. Furthermore, we propose to take advantage of the safety planning template roll-out by measuring fidelity (quality, completeness, and level of integration with care), because it may be an important mediator of the relationship between safety planning and suicide outcomes.",Evaluating the Impact of Changes in Opioid Prescribing Across Health Systems Implementing Zero Suicide,9676620,U01MH114087,"['Accident and Emergency department', 'Address', 'Adopted', 'Algorithms', 'Award', 'Caring', 'Clinical', 'Code', 'Colorado', 'Computerized Medical Record', 'Coping Skills', 'Country', 'Development', 'Disease', 'Documentation', 'Effectiveness', 'Elements', 'Evaluation', 'Firearms', 'Frequencies', 'Future', 'Goals', 'Health', 'Health system', 'Healthcare Systems', 'Individual', 'Institutes', 'Interruption', 'Intervention', 'Investigation', 'Learning', 'Measures', 'Mediator of activation protein', 'Medical Records', 'Mental Health', 'Mining', 'Natural Language Processing', 'Natural experiment', 'Outcome', 'Pharmaceutical Preparations', 'Predictive Value', 'Process', 'Research', 'Research Personnel', 'Safety', 'Series', 'Site', 'Source', 'Standardization', 'Suicide', 'Suicide prevention', 'System', 'Text', 'Time', 'Variant', 'Work', 'base', 'behavioral health', 'behavioral outcome', 'design', 'distraction', 'health plan', 'health record', 'improved', 'innovation', 'method development', 'prescription opioid', 'reducing suicide', 'safety practice', 'suicidal behavior', 'suicide model', 'tool']",NIMH,HENRY FORD HEALTH SYSTEM,U01,2018,262124,0.008481900658788113
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9607596,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Big Data Methods', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,762619,0.07685805628657931
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9199581,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Injectable', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2017,798827,0.07685805628657931
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9421556,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,793522,0.07685805628657931
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9029656,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Process', 'Public Health', 'Research', 'Semantics', 'Solid', 'Stream', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,844963,0.07685805628657931
"Machine Learning Approach to Identify Candidates for Epilepsy Surgery Project Summary/Abstract Despite the widespread adoption of new drug classes to treat epilepsy, approximately one third of patients do not respond to anti-epileptic medication. Patients with drug-resistant epilepsy (DRE) suffer permanent memory and cognitive impairment from uncontrolled seizures. Only 8-10% of patients with DRE obtain long-term seizure freedom. About half of patients with DRE are eligible for surgical treatment, which results in seizure freedom in 58-73% of patients. However, it is difficult to determine when patients with DRE need surgery. DRE has a complex disease course that fluctuates according to weekly and monthly patterns. Further, neurologists report that they lack the resources (i.e. time) needed to analyze and interpret large amounts of electronic health record (EHR) data to determine surgical candidacy. This results in substantial delays in treatment - 6 years in pediatrics and 20 years in adults, on average - and contributes to avoidable morbidity and mortality. Automated systems are capable of assisting clinicians in identifying candidates for epilepsy surgery two years earlier in the disease course. One such system uses natural language processing to analyze free-text neurology notes in a real-time clinical setting. This system was able to increase the rate of surgical candidate identification by 46%, but it could still be improved in two important ways. First, the system is not able to incorporate results from EEG and MRIs - the most influential factors on surgical candidacy - into its recommendations. Second, it does not utilize rich information hidden in structured EHR data that captures epilepsy disease burden. A system that fuses information from all three data sources (neurology notes, EEG and MRI reports, and structured data) would drastically improve the accuracy and impact of the model. In the proposed research, I will first develop a deep learning (DL) approach for fusing multi-modal EHR data. Specifically, I will use recent advances in deep representation learning to produce richer features from both free- text and structured data. I will represent free-text in neurology notes and EEG and MRI reports with word embedding vectors, and medication, procedure, and visit codes with medical concept vectors. I will combine disparate data sources with a deep neural network to produce high-level representations of surgical candidacy. This will enable me to estimate patients' risk of future epilepsy surgery. Second, I will establish the generalizability of this approach using a neighboring hospital's EHR data and validate the system in a clinical setting. This contribution will be significant because it will increase the number of surgical candidates identified earlier in the disease course, thereby reducing epilepsy disease sequelae. This proposal will lay the groundwork for nationwide expansion of the DL system and generate the only automated DL system designed to improve the timeliness of surgical referral rates in the adult population. Project Narrative Automating the identification of patients with epilepsy who would benefit from surgical treatment is imperative to reducing morbidity and mortality from uncontrolled seizures. This research proposal will develop and clinically validate a generalizable deep learning framework for analyzing multi-modal electronic health record data to predict epilepsy surgery candidacy. Implementing this system into clinical care is expected to reduce the time to surgery by 45%, which would prevent one epilepsy-related death for every 58 patients who receive surgery.",Machine Learning Approach to Identify Candidates for Epilepsy Surgery,10066989,F31NS115447,"['Address', 'Adoption', 'Adult', 'Antiepileptic Agents', 'Area', 'Benchmarking', 'Caring', 'Cessation of life', 'Child', 'Classification', 'Clinical', 'Code', 'Complex', 'Data', 'Data Sources', 'Disease', 'Electroencephalography', 'Electronic Health Record', 'Ensure', 'Epilepsy', 'Evaluation', 'Exposure to', 'Failure', 'Freedom', 'Future', 'Goals', 'Gold', 'Guidelines', 'Healthcare', 'Hospitals', 'Impaired cognition', 'Influentials', 'Intractable Epilepsy', 'Label', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical', 'Memory impairment', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Neurologic', 'Neurologist', 'Neurology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient risk', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Procedures', 'Provider', 'Quality-Adjusted Life Years', 'ROC Curve', 'Recommendation', 'Reporting', 'Research', 'Research Proposals', 'Resources', 'Savings', 'Schedule', 'Seizures', 'Sensitivity and Specificity', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Universities', 'Update', 'Validation', 'Visit', 'automated analysis', 'base', 'burden of illness', 'candidate identification', 'case control', 'clinical care', 'cohort', 'deep learning', 'deep neural network', 'design', 'electronic structure', 'improved', 'learning classifier', 'magnetic resonance imaging/electroencephalography', 'mortality', 'multidimensional data', 'multimodality', 'novel', 'novel drug class', 'prevent', 'prospective', 'prospective test', 'structured data', 'tool', 'vector']",NINDS,CINCINNATI CHILDRENS HOSP MED CTR,F31,2020,39617,0.013843678896084958
"2/2 Leveraging electronic health records for pharmacogenomics of psychiatric diorders Abstract  Schizophrenia (SCZ) and major depressive disorder (MDD) are highly heritable, debilitating diseases with lifetime prevalences of ~1% and 15%, respectively. Both disorders carry substantial morbidity and mortality and are associated with severe societal and personal costs. Despite the availability of efficacious treatments for both disorders, ~1/3 of individuals will not achieve symptomatic improvement even after multiple rounds of medication. Identifying individuals at greater risk for such treatment nonresponse, or treatment resistance, could facilitate more targeted interventions for these individuals.  A burgeoning literature has identified genomic variation associated with treatment response. In particular, antidepressant response has been suggested to be highly heritable; convergent data from rodent studies likewise suggest that antipsychotic and antidepressant response phenotypes are influenced by genetic variation. However, treatment studies to date have had minimal success in identifying variants associated with psychotropic response, likely as a result of limited sample sizes: prior efforts required sequential treatment trials and prospective assessment to characterize outcomes. Longitudinal electronic health records (EHR) data provide an opportunity to efficiently characterize treatment response in many individuals in real-world settings. Coupled with large and expanding biobanks, these cohorts allow for low- cost, large-scale genomic studies that finally achieve sufficient power to detect realistic effect sizes.  The investigators now propose to apply these approaches to the EHRs of two large regional health systems, each linked to a large biobank, to investigate treatment resistance in SCZ and MDD. They will apply canonical indicators of treatment resistance - clozapine treatment for SCZ, and electroconvulsive therapy (ECT) for MDD - to identify coded and uncoded clinical features associated with high probability of treatment resistance in EHR data. These predictors will themselves provide a useful baseline for identifying high risk individuals. Then, they will apply these to study the entire affected population of each biobank, extending existing genomic data with additional genome-wide association, yielding more than 25,000 antidepressant-treated individuals and 2,200 antipsychotic-treated individuals. Rather than simply conducting a case-control study, they will examine treatment resistance as a quantitative trait, applying a method developed by the investigators and shown to substantially increase power for such traits.  The project combines expertise in clinical informatics, machine learning, and analysis of large scale genomics, as well as domain-specific expertise in psychiatric treatment resistance. Spanning two distinct health systems, the algorithms and methods developed have maximal portability, facilitating next- step investigations. Successful identification of risk variants will facilitate efforts at clinical risk stratification as well as investigation of the biology underlying treatment resistance. Public Health Statement Despite the availability of effective treatments for schizophrenia and major depressive disorder, around 1/3 of individuals will not have symptomatic improvement after multiple treatment trials. If individuals at high risk for treatment resistance could be identified early, it might be possible to find more effective treatments for them. In particular, this study seeks to use electronic health records and biobanks to identify genomic variation associated with treatment resistance.",2/2 Leveraging electronic health records for pharmacogenomics of psychiatric diorders,9861268,R01MH116269,"['Academic Medical Centers', 'Address', 'Affect', 'Antidepressive Agents', 'Antipsychotic Agents', 'Biology', 'Case-Control Studies', 'Clinical', 'Clinical Informatics', 'Clozapine', 'Code', 'Consumption', 'Coupled', 'DNA', 'Data', 'Development', 'Discrimination', 'Disease', 'Effectiveness', 'Electroconvulsive Therapy', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'General Hospitals', 'Generations', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Heritability', 'Hospitals', 'Individual', 'Intervention', 'Investigation', 'Label', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Massachusetts', 'Measures', 'Medical Genetics', 'Mental disorders', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patient Triage', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Population', 'Prevalence', 'Probability', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Public Health', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Risk', 'Risk stratification', 'Rodent', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Sequential Treatment', 'Site', 'Structure', 'Suicide attempt', 'Supervision', 'System', 'Therapeutic', 'Time', 'Treatment Failure', 'Treatment Step', 'Treatment outcome', 'Variant', 'Work', 'adverse outcome', 'algorithmic methodologies', 'base', 'biobank', 'biomedical resource', 'clinical predictors', 'clinical risk', 'cohort', 'cost', 'design', 'determinants of treatment resistance', 'effective therapy', 'genetic association', 'genome wide association study', 'genomic data', 'genomic predictors', 'genomic variation', 'high risk', 'improved', 'in silico', 'mortality', 'neuropsychiatric disorder', 'personalized intervention', 'portability', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'response', 'risk variant', 'success', 'symptomatic improvement', 'therapy resistant', 'trait', 'treatment response', 'treatment risk', 'treatment strategy', 'treatment trial']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,425000,-0.011435404573953513
"2/2 Leveraging electronic health records for pharmacogenomics of psychiatric diorders Abstract  Schizophrenia (SCZ) and major depressive disorder (MDD) are highly heritable, debilitating diseases with lifetime prevalences of ~1% and 15%, respectively. Both disorders carry substantial morbidity and mortality and are associated with severe societal and personal costs. Despite the availability of efficacious treatments for both disorders, ~1/3 of individuals will not achieve symptomatic improvement even after multiple rounds of medication. Identifying individuals at greater risk for such treatment nonresponse, or treatment resistance, could facilitate more targeted interventions for these individuals.  A burgeoning literature has identified genomic variation associated with treatment response. In particular, antidepressant response has been suggested to be highly heritable; convergent data from rodent studies likewise suggest that antipsychotic and antidepressant response phenotypes are influenced by genetic variation. However, treatment studies to date have had minimal success in identifying variants associated with psychotropic response, likely as a result of limited sample sizes: prior efforts required sequential treatment trials and prospective assessment to characterize outcomes. Longitudinal electronic health records (EHR) data provide an opportunity to efficiently characterize treatment response in many individuals in real-world settings. Coupled with large and expanding biobanks, these cohorts allow for low- cost, large-scale genomic studies that finally achieve sufficient power to detect realistic effect sizes.  The investigators now propose to apply these approaches to the EHRs of two large regional health systems, each linked to a large biobank, to investigate treatment resistance in SCZ and MDD. They will apply canonical indicators of treatment resistance - clozapine treatment for SCZ, and electroconvulsive therapy (ECT) for MDD - to identify coded and uncoded clinical features associated with high probability of treatment resistance in EHR data. These predictors will themselves provide a useful baseline for identifying high risk individuals. Then, they will apply these to study the entire affected population of each biobank, extending existing genomic data with additional genome-wide association, yielding more than 25,000 antidepressant-treated individuals and 2,200 antipsychotic-treated individuals. Rather than simply conducting a case-control study, they will examine treatment resistance as a quantitative trait, applying a method developed by the investigators and shown to substantially increase power for such traits.  The project combines expertise in clinical informatics, machine learning, and analysis of large scale genomics, as well as domain-specific expertise in psychiatric treatment resistance. Spanning two distinct health systems, the algorithms and methods developed have maximal portability, facilitating next- step investigations. Successful identification of risk variants will facilitate efforts at clinical risk stratification as well as investigation of the biology underlying treatment resistance. Public Health Statement Despite the availability of effective treatments for schizophrenia and major depressive disorder, around 1/3 of individuals will not have symptomatic improvement after multiple treatment trials. If individuals at high risk for treatment resistance could be identified early, it might be possible to find more effective treatments for them. In particular, this study seeks to use electronic health records and biobanks to identify genomic variation associated with treatment resistance.",2/2 Leveraging electronic health records for pharmacogenomics of psychiatric diorders,9661173,R01MH116269,"['Academic Medical Centers', 'Address', 'Affect', 'Antidepressive Agents', 'Antipsychotic Agents', 'Biology', 'Case-Control Studies', 'Clinical', 'Clinical Informatics', 'Clozapine', 'Code', 'Computer Simulation', 'Consumption', 'Coupled', 'DNA', 'Data', 'Development', 'Discrimination', 'Disease', 'Effectiveness', 'Electroconvulsive Therapy', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'General Hospitals', 'Generations', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Heritability', 'Hospitals', 'Individual', 'Intervention', 'Investigation', 'Label', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Massachusetts', 'Measures', 'Medical Genetics', 'Mental disorders', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patient Triage', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Population', 'Prevalence', 'Probability', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Public Health', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Risk', 'Risk stratification', 'Rodent', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Sequential Treatment', 'Site', 'Structure', 'Suicide attempt', 'Supervision', 'System', 'Therapeutic', 'Time', 'Treatment Failure', 'Treatment Step', 'Treatment outcome', 'Variant', 'Work', 'adverse outcome', 'algorithmic methodologies', 'base', 'biobank', 'biomedical resource', 'clinical predictors', 'clinical risk', 'cohort', 'cost', 'design', 'effective therapy', 'genetic association', 'genome wide association study', 'genomic data', 'genomic predictors', 'genomic variation', 'high risk', 'improved', 'mortality', 'neuropsychiatric disorder', 'personalized intervention', 'portability', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'response', 'risk variant', 'success', 'symptomatic improvement', 'therapy resistant', 'trait', 'treatment response', 'treatment risk', 'treatment strategy', 'treatment trial']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,425000,-0.011435404573953513
"1/2 Leveraging electronic health records for pharmacogenomics of psychiatric disorders Schizophrenia (SCZ) and major depressive disorder (MDD) are highly heritable, debilitating diseases with lifetime prevalences of ~1% and 15%, respectively. Both disorders carry substantial morbidity and mortality and are associated with severe societal and personal costs. Despite the availability of efficacious treatments for both disorders, ~1/3 of individuals will not achieve symptomatic improvement even after multiple rounds of medication. Identifying individuals at greater risk for such treatment nonresponse, or treatment resistance, could facilitate more targeted interventions for these individuals.  A burgeoning literature has identified genomic variation associated with treatment response. IN particular, antidepressant response has been suggested to be highly heritable; convergent data from rodent studies likewise suggest that antipsychotic and antidepressant response phenotypes are influenced by genetic variation. However, treatment studies to date have had minimal success in identifying variants associated with psychotropic response, likely as a result of limited sample sizes: prior efforts required sequential treatment trials and prospective assessment to characterize outcomes. Longitudinal electronic health records (EHR) data provide an opportunity to efficiently characterize treatment response in many individuals in real-world settings. Coupled with large and expanding biobanks, these cohorts allow for low- cost, large-scale genomic studies that finally achieve sufficient power to detect realistic effect sizes.  The investigators now propose to apply these approaches to the EHRs of two large regional health systems, each linked to a large biobank, to investigate treatment resistance in SCZ and MDD. They will apply canonical indicators of treatment resistance - clozapine treatment for SCZ, and electroconvulsive therapy (ECT) for MDD - to identify coded and uncoded clinical features associated with high probability of treatment resistance in EHR data. These predictors will themselves provide a useful baseline for identifying high risk individuals. Then, they will apply these to study the entire affected population of each biobank, extending existing genomic data with additional genome-wide association, yielding more than 26,000 antidepressant-treated individuals and 2,500 antipsychotic-treated individuals. Rather than simply conducting a case-control study, they will examine treatment resistance as a quantitative trait, applying a method developed by the investigators and shown to substantially increase power for such traits.  The project combines expertise in clinical informatics, machine learning, and analysis of large scale genomics, as well as domain-specific expertise in psychiatric treatment resistance. Spanning two distinct health systems, the algorithms and methods developed have maximal portability, facilitating next- step investigations. Successful identification of risk variants will facilitate efforts at clinical risk stratification as well as investigation of the biology underlying treatment resistance. Public Health Statement Despite the availability of effective treatments for schizophrenia and major depressive disorder, around 1/3 of individuals will not have symptomatic improvement after multiple treatment trials. If individuals at high risk for treatment resistance could be identified early, it might be possible to find more effective treatments for them. In particular, this study seeks to use electronic health records and biobanks to identify genomic variation associated with treatment resistance.",1/2 Leveraging electronic health records for pharmacogenomics of psychiatric disorders,9843528,R01MH116270,"['Academic Medical Centers', 'Address', 'Affect', 'Antidepressive Agents', 'Antipsychotic Agents', 'Biology', 'Case-Control Studies', 'Clinical', 'Clinical Informatics', 'Clozapine', 'Code', 'Consumption', 'Coupled', 'DNA', 'Data', 'Development', 'Discrimination', 'Disease', 'Effectiveness', 'Electroconvulsive Therapy', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'General Hospitals', 'Generations', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Heritability', 'Hospitals', 'Individual', 'Intervention', 'Investigation', 'Label', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Massachusetts', 'Measures', 'Medical Genetics', 'Mental disorders', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patient Triage', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Population', 'Prevalence', 'Probability', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Public Health', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Risk', 'Risk stratification', 'Rodent', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Sequential Treatment', 'Site', 'Structure', 'Suicide attempt', 'Supervision', 'System', 'Therapeutic', 'Time', 'Treatment Failure', 'Treatment Step', 'Treatment outcome', 'Variant', 'Work', 'adverse outcome', 'algorithmic methodologies', 'base', 'biobank', 'biomedical resource', 'clinical predictors', 'clinical risk', 'cohort', 'cost', 'design', 'determinants of treatment resistance', 'effective therapy', 'genetic association', 'genome wide association study', 'genomic data', 'genomic predictors', 'genomic variation', 'high risk', 'improved', 'in silico', 'mortality', 'neuropsychiatric disorder', 'personalized intervention', 'portability', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'response', 'risk variant', 'success', 'symptomatic improvement', 'therapy resistant', 'trait', 'treatment response', 'treatment risk', 'treatment strategy', 'treatment trial']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,421250,-0.011435404573953513
"1/2 Leveraging electronic health records for pharmacogenomics of psychiatric disorders Schizophrenia (SCZ) and major depressive disorder (MDD) are highly heritable, debilitating diseases with lifetime prevalences of ~1% and 15%, respectively. Both disorders carry substantial morbidity and mortality and are associated with severe societal and personal costs. Despite the availability of efficacious treatments for both disorders, ~1/3 of individuals will not achieve symptomatic improvement even after multiple rounds of medication. Identifying individuals at greater risk for such treatment nonresponse, or treatment resistance, could facilitate more targeted interventions for these individuals.  A burgeoning literature has identified genomic variation associated with treatment response. IN particular, antidepressant response has been suggested to be highly heritable; convergent data from rodent studies likewise suggest that antipsychotic and antidepressant response phenotypes are influenced by genetic variation. However, treatment studies to date have had minimal success in identifying variants associated with psychotropic response, likely as a result of limited sample sizes: prior efforts required sequential treatment trials and prospective assessment to characterize outcomes. Longitudinal electronic health records (EHR) data provide an opportunity to efficiently characterize treatment response in many individuals in real-world settings. Coupled with large and expanding biobanks, these cohorts allow for low- cost, large-scale genomic studies that finally achieve sufficient power to detect realistic effect sizes.  The investigators now propose to apply these approaches to the EHRs of two large regional health systems, each linked to a large biobank, to investigate treatment resistance in SCZ and MDD. They will apply canonical indicators of treatment resistance - clozapine treatment for SCZ, and electroconvulsive therapy (ECT) for MDD - to identify coded and uncoded clinical features associated with high probability of treatment resistance in EHR data. These predictors will themselves provide a useful baseline for identifying high risk individuals. Then, they will apply these to study the entire affected population of each biobank, extending existing genomic data with additional genome-wide association, yielding more than 26,000 antidepressant-treated individuals and 2,500 antipsychotic-treated individuals. Rather than simply conducting a case-control study, they will examine treatment resistance as a quantitative trait, applying a method developed by the investigators and shown to substantially increase power for such traits.  The project combines expertise in clinical informatics, machine learning, and analysis of large scale genomics, as well as domain-specific expertise in psychiatric treatment resistance. Spanning two distinct health systems, the algorithms and methods developed have maximal portability, facilitating next- step investigations. Successful identification of risk variants will facilitate efforts at clinical risk stratification as well as investigation of the biology underlying treatment resistance. Public Health Statement Despite the availability of effective treatments for schizophrenia and major depressive disorder, around 1/3 of individuals will not have symptomatic improvement after multiple treatment trials. If individuals at high risk for treatment resistance could be identified early, it might be possible to find more effective treatments for them. In particular, this study seeks to use electronic health records and biobanks to identify genomic variation associated with treatment resistance.",1/2 Leveraging electronic health records for pharmacogenomics of psychiatric disorders,9660127,R01MH116270,"['Academic Medical Centers', 'Address', 'Affect', 'Antidepressive Agents', 'Antipsychotic Agents', 'Biology', 'Case-Control Studies', 'Clinical', 'Clinical Informatics', 'Clozapine', 'Code', 'Computer Simulation', 'Consumption', 'Coupled', 'DNA', 'Data', 'Development', 'Discrimination', 'Disease', 'Effectiveness', 'Electroconvulsive Therapy', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'General Hospitals', 'Generations', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Heritability', 'Hospitals', 'Individual', 'Intervention', 'Investigation', 'Label', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Massachusetts', 'Measures', 'Medical Genetics', 'Mental disorders', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patient Triage', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Population', 'Prevalence', 'Probability', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Public Health', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Risk', 'Risk stratification', 'Rodent', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Sequential Treatment', 'Site', 'Structure', 'Suicide attempt', 'Supervision', 'System', 'Therapeutic', 'Time', 'Treatment Failure', 'Treatment Step', 'Treatment outcome', 'Variant', 'Work', 'adverse outcome', 'algorithmic methodologies', 'base', 'biobank', 'biomedical resource', 'clinical predictors', 'clinical risk', 'cohort', 'cost', 'design', 'effective therapy', 'genetic association', 'genome wide association study', 'genomic data', 'genomic predictors', 'genomic variation', 'high risk', 'improved', 'mortality', 'neuropsychiatric disorder', 'personalized intervention', 'portability', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'response', 'risk variant', 'success', 'symptomatic improvement', 'therapy resistant', 'trait', 'treatment response', 'treatment risk', 'treatment strategy', 'treatment trial']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,421250,-0.011435404573953513
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing     DESCRIPTION (provided by applicant): The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potentials, but also equally growing concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potentials for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of the research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data, and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious ad costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for much faster de- identification than manual approaches. Clinacuity, Inc. proposes to develop a new system to automatically de-identify clinical notes found in the EHR, to then improve the availability of clinical text for secondary uses, as well as ameliorate the protection of patient data confidentiality. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the text de-identification application, a reference standard that will include a random sample of clinical narratives with protected health information annotated by domain experts; 2) develop a prototype to automatically de-identify clinical text in near real-time, a prototype that will implement a novel stepwise hybrid approach to maximize sensitivity first (our priority for de-identification), and then filter out false positives to enhance positive predictive value, and also replace PHI with realistic substitutes for improved protection; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing, and also train and test the prototype with a reference standard from another healthcare organization. Commercial application: To strengthen patient information confidentiality protection, the HITECH Act heightened financial penalties incurred for breaches of PHI, even introducing criminal penalties. These new severe consequences for violation of patient information confidentiality render protection requirements even more obvious, and automatic high-accuracy clinical text de-identification, as offered by the system Clinacuity proposes, will strongly help healthcare and clinical research organizations avoid such consequences. This system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will also ease research data sharing, and help healthcare organizations protect patient data confidentiality. PUBLIC HEALTH RELEVANCE: The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical daa becoming available in electronic format, with tremendous potentials, but also equally growing concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfil the potentials for high quality healthcare and effective clinical research. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data, and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes that have been dictated and transcribed or directly typed in, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for much faster de-identification than manual approaches. The overall goal of this project is to develop a new system to automatically de-identify clinical narrative text in he Electronic Health Record, to then improve the availability of clinical text for secondary uses, as well as ameliorate the protection of patient data confidentiality.",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,8982010,R41GM116479,"['Abbreviations', 'Adoption', 'Affect', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Confidentiality of Patient Information', 'Consent', 'Data', 'Direct Costs', 'Electronic Health Record', 'Electronics', 'Enrollment', 'Eponyms', 'Gilbert Disease', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Hybrids', 'Improve Access', 'Incentives', 'Informed Consent', 'Manuals', 'Measurement', 'Measures', 'Methods', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Population', 'Predictive Value', 'Privacy', 'Reference Standards', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrospective Studies', 'Risk', 'Sampling', 'Structure', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'United States National Institutes of Health', 'Validation', 'Vision', 'Work', 'base', 'commercial application', 'common rule', 'data sharing', 'flexibility', 'health care quality', 'improved', 'novel', 'patient privacy', 'payment', 'prototype', 'statistics', 'text searching']",NIGMS,"CLINACUITY,INC.",R41,2016,223924,0.08390896419470317
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format with tremendous potential but an equally large concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potential for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary use of clinical data and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for higher accuracy and much faster de- identification than manual approaches. Clinacuity, Inc. proposes to advance a text de-identification system from a prototype to an accurate, adaptable, and robust system, integrated into the research infrastructure at our implementation and testing site (Medical University of South Carolina, Charleston, SC), and ready for commercialization efforts. To accomplish this undertaking, we will focus on the following specific aims and related objectives, while continuing to prepare the commercialization of the integrated system, with detailed market analysis, commercial roadmap development, and modern media communication: 1) Enhance the text de-identification system performance, scalability, and quality to produce an enterprise-grade solution ready for deployment; 2) Enable use of structured data for enhanced text de-identification (when structured PII is available) and for complete patient records de-identification (i.e., records combining structured and unstructured data). This aim also includes implementing one-way pseudo-identifier cryptographic hashing to enable securely linking already de-identified patient records; 3) Integrate the text de-identification system with a research data capture and management system. This includes implementation of the de-identification system as a secure web service, with standards-based access and integration. This de-identification system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will ease research data sharing (as expected for larger NIH-funded research projects) and help healthcare organizations protect patient data confidentiality. Significant time-savings will also be offered, with a process at least 200-1000 times faster than manual de-identification. The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potential, but also equally growing concern for patient confidentiality breaches. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data and protect patient data confidentiality. This project will advance a text de-identification system from a prototype to an accurate, adaptable and robust system allowing for complete patient records de-identification, integrated in the research infrastructure at our implementation and testing site and ready for commercialization efforts. It will improve access to richer, more detailed, and more accurate clinical data for clinical researchers, ease research data sharing and help healthcare organizations protect patient data confidentiality. !",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,9908962,R42GM116479,"['Adoption', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communications Media', 'Confidentiality of Patient Information', 'Data', 'Development', 'Electronic Health Record', 'Enrollment', 'Environment', 'Fast Healthcare Interoperability Resources', 'Funding', 'Growth', 'Health Insurance Portability and Accountability Act', 'Improve Access', 'Link', 'Manuals', 'Medical', 'Modernization', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Performance', 'Personally Identifiable Information', 'Phase', 'Privacy', 'Process', 'Records', 'Reference Standards', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Risk', 'Savings', 'Secure', 'Site', 'South Carolina', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'Universities', 'Visualization', 'base', 'commercial application', 'commercialization', 'cost', 'cryptography', 'data reuse', 'data sharing', 'health care quality', 'health care service organization', 'health care settings', 'health management', 'improved', 'large scale data', 'prototype', 'software development', 'standard measure', 'structured data', 'systems research', 'unstructured data', 'web services']",NIGMS,"CLINACUITY,INC.",R42,2020,759330,0.06577692088284151
"An Evaluation of Novel Domains for Predicting 30-Day Readmission DESCRIPTION (provided by applicant): The Centers for Medicare and Medicaid Services has proposed to financially penalize hospitals that have 30-day readmission rates above the national mean. As a result hospitals caring for disadvantaged populations with more needs might be penalized by current 30-day readmission models that do not include measures of social risk and functional status of the patients served. These are two important variable domains that directly impact a patient's ability to manage their disease. Social risk factors (e.g. living alone, social support, marginal housing, and alcohol abuse) and functional status (e.g. mobility, fall risk) are rarely present in administrative data, which is why so few readmission models include this data. Yet many of these variables are available in electronic health records (EHR) and the advancement of the field of informatics has made the extraction of these data feasible. These variables may improve the discriminative ability of 30-day readmission models which currently explain little of the variation in readmission rates among patients.  We propose to improve 30-day readmission models by extracting measures of social risk and functional status from the EHR using the novel method of Natural Language Processing (NLP). We will combine administrative data (VA and Medicare) and data extracted from the national EHR in the VA for 6000 patients 65 and older in 2011 to improve upon currently available 30-day hospital readmission risk prediction models for congestive heart failure (CHF), acute myocardial infarction (AMI), pneumonia and stroke. We have chosen these conditions because hospital-level 30-day readmission rates for these conditions (CHF, AMI and pneumonia) are currently or will soon be (stroke) publicly reported. Our proposal has two goals: 1) to develop, test and evaluate automated NLP algorithms designed to extract measures of social risk and functional status from the EHR and 2) to understand the impact of these two novel domains on 30-day readmission across four conditions with fundamentally different post-discharge hospital course and disease trajectories.  We propose a paradigm shift in the understanding and obtainment of factors predictive of 30-day readmission. Our overarching hypothesis is that social risk factors and functional status which directly influence a patient's self-management ability are critical factors predictive of 30-day readmission, can be extracted from the EHR, and should be included in risk prediction models. The development of better risk prediction models will allow the identification of patients at highest risk of readmission and facilitate post-discharge interventions in their care. In addition, if social risk factors and functional status are criticalin explaining variation in 30-day readmission rates, then hospitals that care for patients with a higher burden of social risk and functional needs may be inappropriately penalized by current risk predictions models that lack these measures. Also, as more hospitals adopt EHRs, we need to study more advanced technologies such as automated NLP as tools to efficiently extract information and to inform health systems about the characteristics of the patients they serve. PUBLIC HEALTH RELEVANCE: About a fifth of all Medicare patients are readmitted within 30 days of hospital discharge, potentially exposing the patients and their families to distress and unnecessary costs. An improved understanding of who is at highest risk of readmission will allow hospitals to efficiently intervene in the care of patients who may benefit the most from post-discharge interventions.",An Evaluation of Novel Domains for Predicting 30-Day Readmission,9288224,R01HL116522,"['Acute myocardial infarction', 'Adopted', 'Affect', 'Affordable Care Act', 'Alcohol abuse', 'Algorithm Design', 'Algorithms', 'Area', 'Caring', 'Characteristics', 'Clinical Data', 'Congestive Heart Failure', 'Country', 'Data', 'Data Set', 'Development', 'Disease', 'Distress', 'Electronic Health Record', 'Evaluation', 'Family', 'Goals', 'Health Status', 'Health system', 'Hospitals', 'Housing', 'Human', 'Incentives', 'Informatics', 'Intervention', 'Length of Stay', 'Measures', 'Medicare', 'Methods', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patient risk', 'Patients', 'Performance', 'Pneumonia', 'Population', 'Predictive Factor', 'Publishing', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Self Management', 'Severity of illness', 'Social support', 'Stroke', 'Substance abuse problem', 'Technology', 'Testing', 'Text', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'cost', 'demographics', 'design', 'disadvantaged population', 'fall risk', 'functional status', 'health administration', 'high risk', 'high risk behavior', 'hospital patient care', 'hospital readmission', 'improved', 'marginally housed', 'mortality', 'novel', 'payment', 'predictive modeling', 'programs', 'public health relevance', 'social', 'tool']",NHLBI,NORTHERN CALIFORNIA INSTITUTE/RES/EDU,R01,2017,585633,0.019428075829955614
"An Evaluation of Novel Domains for Predicting 30-Day Readmission DESCRIPTION (provided by applicant): The Centers for Medicare and Medicaid Services has proposed to financially penalize hospitals that have 30-day readmission rates above the national mean. As a result hospitals caring for disadvantaged populations with more needs might be penalized by current 30-day readmission models that do not include measures of social risk and functional status of the patients served. These are two important variable domains that directly impact a patient's ability to manage their disease. Social risk factors (e.g. living alone, social support, marginal housing, and alcohol abuse) and functional status (e.g. mobility, fall risk) are rarely present in administrative data, which is why so few readmission models include this data. Yet many of these variables are available in electronic health records (EHR) and the advancement of the field of informatics has made the extraction of these data feasible. These variables may improve the discriminative ability of 30-day readmission models which currently explain little of the variation in readmission rates among patients.  We propose to improve 30-day readmission models by extracting measures of social risk and functional status from the EHR using the novel method of Natural Language Processing (NLP). We will combine administrative data (VA and Medicare) and data extracted from the national EHR in the VA for 6000 patients 65 and older in 2011 to improve upon currently available 30-day hospital readmission risk prediction models for congestive heart failure (CHF), acute myocardial infarction (AMI), pneumonia and stroke. We have chosen these conditions because hospital-level 30-day readmission rates for these conditions (CHF, AMI and pneumonia) are currently or will soon be (stroke) publicly reported. Our proposal has two goals: 1) to develop, test and evaluate automated NLP algorithms designed to extract measures of social risk and functional status from the EHR and 2) to understand the impact of these two novel domains on 30-day readmission across four conditions with fundamentally different post-discharge hospital course and disease trajectories.  We propose a paradigm shift in the understanding and obtainment of factors predictive of 30-day readmission. Our overarching hypothesis is that social risk factors and functional status which directly influence a patient's self-management ability are critical factors predictive of 30-day readmission, can be extracted from the EHR, and should be included in risk prediction models. The development of better risk prediction models will allow the identification of patients at highest risk of readmission and facilitate post-discharge interventions in their care. In addition, if social risk factors and functional status are criticalin explaining variation in 30-day readmission rates, then hospitals that care for patients with a higher burden of social risk and functional needs may be inappropriately penalized by current risk predictions models that lack these measures. Also, as more hospitals adopt EHRs, we need to study more advanced technologies such as automated NLP as tools to efficiently extract information and to inform health systems about the characteristics of the patients they serve. PUBLIC HEALTH RELEVANCE: About a fifth of all Medicare patients are readmitted within 30 days of hospital discharge, potentially exposing the patients and their families to distress and unnecessary costs. An improved understanding of who is at highest risk of readmission will allow hospitals to efficiently intervene in the care of patients who may benefit the most from post-discharge interventions.",An Evaluation of Novel Domains for Predicting 30-Day Readmission,9065737,R01HL116522,"['Accounting', 'Acute myocardial infarction', 'Adopted', 'Affect', 'Affordable Care Act', 'Alcohol abuse', 'Algorithm Design', 'Algorithms', 'Area', 'Caring', 'Characteristics', 'Clinical Data', 'Congestive Heart Failure', 'Country', 'Data', 'Data Set', 'Development', 'Disease', 'Distress', 'Electronic Health Record', 'Evaluation', 'Family', 'Goals', 'Health', 'Health Status', 'Health system', 'Hospitals', 'Housing', 'Human', 'Incentives', 'Informatics', 'Intervention', 'Length of Stay', 'Life', 'Measures', 'Medicare', 'Methods', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Performance', 'Pneumonia', 'Population', 'Predictive Factor', 'Publishing', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Self Management', 'Severity of illness', 'Social support', 'Stroke', 'Substance abuse problem', 'Technology', 'Testing', 'Text', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'cost', 'demographics', 'design', 'disadvantaged population', 'fall risk', 'falls', 'functional status', 'health administration', 'high risk', 'high risk behavior', 'hospital patient care', 'hospital readmission', 'improved', 'marginally housed', 'mortality', 'novel', 'payment', 'predictive modeling', 'programs', 'social', 'tool']",NHLBI,NORTHERN CALIFORNIA INSTITUTE/RES/EDU,R01,2016,520282,0.019428075829955614
"An Evaluation of Novel Domains for Predicting 30-Day Readmission DESCRIPTION (provided by applicant): The Centers for Medicare and Medicaid Services has proposed to financially penalize hospitals that have 30-day readmission rates above the national mean. As a result hospitals caring for disadvantaged populations with more needs might be penalized by current 30-day readmission models that do not include measures of social risk and functional status of the patients served. These are two important variable domains that directly impact a patient's ability to manage their disease. Social risk factors (e.g. living alone, social support, marginal housing, and alcohol abuse) and functional status (e.g. mobility, fall risk) are rarely present in administrative data, which is why so few readmission models include this data. Yet many of these variables are available in electronic health records (EHR) and the advancement of the field of informatics has made the extraction of these data feasible. These variables may improve the discriminative ability of 30-day readmission models which currently explain little of the variation in readmission rates among patients.  We propose to improve 30-day readmission models by extracting measures of social risk and functional status from the EHR using the novel method of Natural Language Processing (NLP). We will combine administrative data (VA and Medicare) and data extracted from the national EHR in the VA for 6000 patients 65 and older in 2011 to improve upon currently available 30-day hospital readmission risk prediction models for congestive heart failure (CHF), acute myocardial infarction (AMI), pneumonia and stroke. We have chosen these conditions because hospital-level 30-day readmission rates for these conditions (CHF, AMI and pneumonia) are currently or will soon be (stroke) publicly reported. Our proposal has two goals: 1) to develop, test and evaluate automated NLP algorithms designed to extract measures of social risk and functional status from the EHR and 2) to understand the impact of these two novel domains on 30-day readmission across four conditions with fundamentally different post-discharge hospital course and disease trajectories.  We propose a paradigm shift in the understanding and obtainment of factors predictive of 30-day readmission. Our overarching hypothesis is that social risk factors and functional status which directly influence a patient's self-management ability are critical factors predictive of 30-day readmission, can be extracted from the EHR, and should be included in risk prediction models. The development of better risk prediction models will allow the identification of patients at highest risk of readmission and facilitate post-discharge interventions in their care. In addition, if social risk factors and functional status are criticalin explaining variation in 30-day readmission rates, then hospitals that care for patients with a higher burden of social risk and functional needs may be inappropriately penalized by current risk predictions models that lack these measures. Also, as more hospitals adopt EHRs, we need to study more advanced technologies such as automated NLP as tools to efficiently extract information and to inform health systems about the characteristics of the patients they serve. PUBLIC HEALTH RELEVANCE: About a fifth of all Medicare patients are readmitted within 30 days of hospital discharge, potentially exposing the patients and their families to distress and unnecessary costs. An improved understanding of who is at highest risk of readmission will allow hospitals to efficiently intervene in the care of patients who may benefit the most from post-discharge interventions.",An Evaluation of Novel Domains for Predicting 30-Day Readmission,8854133,R01HL116522,"['Accounting', 'Acute myocardial infarction', 'Adopted', 'Affect', 'Alcohol abuse', 'Algorithm Design', 'Algorithms', 'Area', 'Caring', 'Characteristics', 'Clinical Data', 'Congestive Heart Failure', 'Country', 'Data', 'Data Set', 'Development', 'Disadvantaged', 'Disease', 'Distress', 'Electronic Health Record', 'Evaluation', 'Family', 'Goals', 'Health', 'Health Status', 'Health system', 'Hospitals', 'Housing', 'Human', 'Incentives', 'Informatics', 'Intervention', 'Length of Stay', 'Life', 'Measures', 'Medicare', 'Methods', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Performance', 'Pneumonia', 'Population', 'Predictive Factor', 'Publishing', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Self Management', 'Severity of illness', 'Social support', 'Stroke', 'Substance abuse problem', 'Technology', 'Testing', 'Text', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'cost', 'demographics', 'design', 'fall risk', 'falls', 'functional status', 'health administration', 'high risk', 'high risk behavior', 'hospital patient care', 'hospital readmission', 'improved', 'marginally housed', 'mortality', 'novel', 'payment', 'predictive modeling', 'programs', 'social', 'tool']",NHLBI,NORTHERN CALIFORNIA INSTITUTE/RES/EDU,R01,2015,706251,0.019428075829955614
"An Evaluation of Novel Domains for Predicting 30-Day Readmission     DESCRIPTION (provided by applicant): The Centers for Medicare and Medicaid Services has proposed to financially penalize hospitals that have 30-day readmission rates above the national mean. As a result hospitals caring for disadvantaged populations with more needs might be penalized by current 30-day readmission models that do not include measures of social risk and functional status of the patients served. These are two important variable domains that directly impact a patient's ability to manage their disease. Social risk factors (e.g. living alone, social support, marginal housing, and alcohol abuse) and functional status (e.g. mobility, fall risk) are rarely present in administrative data, which is why so few readmission models include this data. Yet many of these variables are available in electronic health records (EHR) and the advancement of the field of informatics has made the extraction of these data feasible. These variables may improve the discriminative ability of 30-day readmission models which currently explain little of the variation in readmission rates among patients.  We propose to improve 30-day readmission models by extracting measures of social risk and functional status from the EHR using the novel method of Natural Language Processing (NLP). We will combine administrative data (VA and Medicare) and data extracted from the national EHR in the VA for 6000 patients 65 and older in 2011 to improve upon currently available 30-day hospital readmission risk prediction models for congestive heart failure (CHF), acute myocardial infarction (AMI), pneumonia and stroke. We have chosen these conditions because hospital-level 30-day readmission rates for these conditions (CHF, AMI and pneumonia) are currently or will soon be (stroke) publicly reported. Our proposal has two goals: 1) to develop, test and evaluate automated NLP algorithms designed to extract measures of social risk and functional status from the EHR and 2) to understand the impact of these two novel domains on 30-day readmission across four conditions with fundamentally different post-discharge hospital course and disease trajectories.  We propose a paradigm shift in the understanding and obtainment of factors predictive of 30-day readmission. Our overarching hypothesis is that social risk factors and functional status which directly influence a patient's self-management ability are critical factors predictive of 30-day readmission, can be extracted from the EHR, and should be included in risk prediction models. The development of better risk prediction models will allow the identification of patients at highest risk of readmission and facilitate post-discharge interventions in their care. In addition, if social risk factors and functional status are criticalin explaining variation in 30-day readmission rates, then hospitals that care for patients with a higher burden of social risk and functional needs may be inappropriately penalized by current risk predictions models that lack these measures. Also, as more hospitals adopt EHRs, we need to study more advanced technologies such as automated NLP as tools to efficiently extract information and to inform health systems about the characteristics of the patients they serve.         PUBLIC HEALTH RELEVANCE: About a fifth of all Medicare patients are readmitted within 30 days of hospital discharge, potentially exposing the patients and their families to distress and unnecessary costs. An improved understanding of who is at highest risk of readmission will allow hospitals to efficiently intervene in the care of patients who may benefit the most from post-discharge interventions.",An Evaluation of Novel Domains for Predicting 30-Day Readmission,8720810,R01HL116522,"['Accounting', 'Acute myocardial infarction', 'Adopted', 'Affect', 'Alcohol abuse', 'Algorithm Design', 'Algorithms', 'Area', 'Caring', 'Characteristics', 'Clinical Data', 'Congestive Heart Failure', 'Country', 'Data', 'Data Set', 'Development', 'Disadvantaged', 'Disease', 'Distress', 'Electronic Health Record', 'Evaluation', 'Family', 'Goals', 'Health Status', 'Health system', 'Hospitals', 'Housing', 'Human', 'Incentives', 'Informatics', 'Intervention', 'Length of Stay', 'Life', 'Measures', 'Medicare', 'Methods', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Performance', 'Pneumonia', 'Population', 'Predictive Factor', 'Publishing', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Self Management', 'Severity of illness', 'Social support', 'Stroke', 'Substance abuse problem', 'Technology', 'Testing', 'Text', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'cost', 'demographics', 'design', 'fall risk', 'falls', 'functional status', 'health administration', 'high risk', 'high risk behavior', 'hospital patient care', 'hospital readmission', 'improved', 'marginally housed', 'mortality', 'novel', 'payment', 'programs', 'public health relevance', 'social', 'tool']",NHLBI,NORTHERN CALIFORNIA INSTITUTE/RES/EDU,R01,2014,718710,0.019428075829955614
"An Evaluation of Novel Domains for Predicting 30-Day Readmission     DESCRIPTION (provided by applicant): The Centers for Medicare and Medicaid Services has proposed to financially penalize hospitals that have 30-day readmission rates above the national mean. As a result hospitals caring for disadvantaged populations with more needs might be penalized by current 30-day readmission models that do not include measures of social risk and functional status of the patients served. These are two important variable domains that directly impact a patient's ability to manage their disease. Social risk factors (e.g. living alone, social support, marginal housing, and alcohol abuse) and functional status (e.g. mobility, fall risk) are rarely present in administrative data, which is why so few readmission models include this data. Yet many of these variables are available in electronic health records (EHR) and the advancement of the field of informatics has made the extraction of these data feasible. These variables may improve the discriminative ability of 30-day readmission models which currently explain little of the variation in readmission rates among patients.  We propose to improve 30-day readmission models by extracting measures of social risk and functional status from the EHR using the novel method of Natural Language Processing (NLP). We will combine administrative data (VA and Medicare) and data extracted from the national EHR in the VA for 6000 patients 65 and older in 2011 to improve upon currently available 30-day hospital readmission risk prediction models for congestive heart failure (CHF), acute myocardial infarction (AMI), pneumonia and stroke. We have chosen these conditions because hospital-level 30-day readmission rates for these conditions (CHF, AMI and pneumonia) are currently or will soon be (stroke) publicly reported. Our proposal has two goals: 1) to develop, test and evaluate automated NLP algorithms designed to extract measures of social risk and functional status from the EHR and 2) to understand the impact of these two novel domains on 30-day readmission across four conditions with fundamentally different post-discharge hospital course and disease trajectories.  We propose a paradigm shift in the understanding and obtainment of factors predictive of 30-day readmission. Our overarching hypothesis is that social risk factors and functional status which directly influence a patient's self-management ability are critical factors predictive of 30-day readmission, can be extracted from the EHR, and should be included in risk prediction models. The development of better risk prediction models will allow the identification of patients at highest risk of readmission and facilitate post-discharge interventions in their care. In addition, if social risk factors and functional status are criticalin explaining variation in 30-day readmission rates, then hospitals that care for patients with a higher burden of social risk and functional needs may be inappropriately penalized by current risk predictions models that lack these measures. Also, as more hospitals adopt EHRs, we need to study more advanced technologies such as automated NLP as tools to efficiently extract information and to inform health systems about the characteristics of the patients they serve.         PUBLIC HEALTH RELEVANCE: About a fifth of all Medicare patients are readmitted within 30 days of hospital discharge, potentially exposing the patients and their families to distress and unnecessary costs. An improved understanding of who is at highest risk of readmission will allow hospitals to efficiently intervene in the care of patients who may benefit the most from post-discharge interventions.                ",An Evaluation of Novel Domains for Predicting 30-Day Readmission,8576427,R01HL116522,"['Accounting', 'Acute myocardial infarction', 'Adopted', 'Affect', 'Alcohol abuse', 'Algorithms', 'Area', 'Caring', 'Characteristics', 'Clinical Data', 'Congestive Heart Failure', 'Country', 'Data', 'Data Set', 'Development', 'Disadvantaged', 'Disease', 'Distress', 'Electronic Health Record', 'Evaluation', 'Family', 'Goals', 'Health Status', 'Health system', 'Hospitals', 'Housing', 'Human', 'Incentives', 'Informatics', 'Intervention', 'Length of Stay', 'Life', 'Measures', 'Medicare', 'Methods', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Performance', 'Pneumonia', 'Population', 'Predictive Factor', 'Publishing', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Self Management', 'Severity of illness', 'Social support', 'Stroke', 'Substance abuse problem', 'Technology', 'Testing', 'Text', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'cost', 'demographics', 'design', 'fall risk', 'falls', 'functional status', 'health administration', 'high risk', 'high risk behavior', 'hospital patient care', 'hospital readmission', 'improved', 'marginally housed', 'mortality', 'novel', 'payment', 'programs', 'public health relevance', 'social', 'tool']",NHLBI,NORTHERN CALIFORNIA INSTITUTE/RES/EDU,R01,2013,738594,0.019428075829955614
"Electronic Health Record Data and Predictive Analytic Methods for HF The goal of this proposal is to develop accurate, generalizable and interpretable predictive models based on electronic health records (EHR) that detect heart failure (HF) in primary care patients one to two years before a clinical diagnosis and to translate the models for use in clinical care. Case-control datasets from two large US health systems (i.e., >13,000 incident HF cases and >120,000 controls) will be created and used to address two of the three study aims. For Aim 1 (Improve prediction of pre-diagnostic HF and model generalizability), recursive neural network (RNN) models will be used to improve prediction accuracy when compared to prior work that was based on traditional machine learning models (e.g., random forest, lasso logistic regression). It is expected that RNN models will perform better because temporality of EHR events can be captured. Aim 1 will also focus on improving model generalizability (i.e., among patients within and across health systems) by leveraging RNN models and by addressing challenges caused by variation in patient level EHR data (e.g., density of data) that are independent of a patient's actual health status. Aim 2 (Identify and clinically validate pre-diagnostic HF phenotypes) will focus on the identification of pre-diagnostic HF phenotypes and the use of content from RNN models derived under Aim 1. Three levels of analysis will be completed. First, we will focus on pathophysiologic heterogeneity that is represented, in part, by HF with preserved ejection fraction (HFpEF) and HF with reduced ejection fraction (HFrEF). But, HFpEF is considered to be more heterogeneous than HFrEF. New methods will be developed to reliably identify pre-diagnostic HF phenotypes. Second, phenotypes will be clinically validated for reliability and coherence and compared to clinical judgement based on a review of the patient's record. Third, we will address a challenge with RNN models, as they generate black box solutions that are seemingly uninterpretable. We propose to develop new methods to extract and represent the content from RNN models. We hypothesize that when phenotype status is combined with information extracted from Aim 1 RNN models it will be judged by expert clinician reviews to be superior for prevention care to phenotype status when it is combined with information extracted from traditional machine learning models or to a direct review of the patient's EHR. Finally, we will prospectively validate the phenotype and RNN models using a large primary care cohort being created by Sutter and related serial biobanked blood samples. For aim 3 we will determine how accurately the models predict elevated biomarker levels that are known to be sensitive and specific indicators of HF disease progression.  The proposed research will contribute valuable knowledge that will assist doctors to identify patients who are at high-risk of incident heart failure 12 to 24 months before the actual diagnosis and that exceed what is possible when relying on traditional signs, symptoms or risk factors. Doctors will be able to provide a more targeted approach to reduce the future risk of heart failure and the risks of morbidity and accelerated mortality that high risk patients face. Moreover, the methods that are developed for the early detection of heart failure in this study will help other researchers in creating more accurate and generalizable predictive models when using electronic health records data and when applying these models for use in clinical care. ",Electronic Health Record Data and Predictive Analytic Methods for HF,9779100,R56HL116832,"['Accounting', 'Address', 'Adopted', 'Adult', 'Biochemical', 'Biological Assay', 'Biological Markers', 'Blood specimen', 'Cardiac', 'Caring', 'Clinical', 'Data', 'Data Analytics', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'EFRAC', 'Early Diagnosis', 'Electronic Health Record', 'Engineering', 'Etiology', 'Event', 'Evidence based intervention', 'Face', 'Feeds', 'Future', 'Goals', 'Health Status', 'Health system', 'Heart failure', 'Heterogeneity', 'Individual', 'Knowledge', 'Lasso', 'Logistic Regressions', 'Logistics', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Muscle Cells', 'Neural Network Simulation', 'Patient Care', 'Patient risk', 'Patients', 'Phenotype', 'Physiological', 'Population', 'Predictive Analytics', 'Prevention', 'Primary Health Care', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Sampling', 'Serum', 'Signs and Symptoms', 'Stretching', 'Symptoms', 'Testing', 'Time', 'Translating', 'Translations', 'Troponin T', 'Validation', 'Variant', 'Work', 'adjudicate', 'analytical method', 'base', 'biobank', 'case control', 'clinical Diagnosis', 'clinical care', 'cohort', 'density', 'expectation', 'feeding', 'forest', 'high risk', 'improved', 'improved outcome', 'mortality', 'patient population', 'patient subsets', 'predictive modeling', 'pressure', 'prospective', 'recurrent neural network', 'recursive neural network']",NHLBI,CALIFORNIA PACIFIC MED CTR RES INSTITUTE,R56,2018,761303,-0.021573164384653832
"Early Detection of Heart Failure via the Electronic Health Record in Primary Care DESCRIPTION (provided by applicant): Heart failure (HF) prevalence has increased and will continue so over the next 30 years with a profound individual and societal burden. Early detection of HF may be useful in mitigating this burden. The purpose of this proposal is to develop robust predictive models that make use of longitudinal electronic health record (EHR). Our long term goal is to use such models to detect HF at an earlier stage (e.g., AHA/ACA Stages A or B) than usually occurs in primary care. We have completed extensive preliminary work using 10 years of longitudinal EHR data on primary care patients. Using text mining and machine learning tools we have found that Framingham criteria are documented in the EHR long before more specific diagnostic studies are done. These symptoms are considerably more common among incident HF cases than controls two to four years before diagnosis. Moreover, clinical, laboratory, diagnostic, and other data routinely captured in the EHR predicts future HF diagnosis. We propose to extend this work on early detection of HF with the following aims: 1) To develop more sensitive and specific criteria for use of Framingham HF signs and symptoms in the early detection of HF. We have shown that positive and negative affirmation of Framingham signs and symptoms are useful in HF detection 1-4 years before diagnosis. We propose to address the following: a) Which Framingham signs and symptoms and combinations thereof are most useful for early detection? b) Are there temporal sequences and correlations among signs and symptoms that improve accuracy of detection? c) How do the criteria vary by HF subtype? We hypothesize that analysis of routinely documented signs and symptoms data will yield a clinically meaningful improvement in the accuracy of detecting HF 1 to 2 years before actual diagnosis; 2) To determine the differential improvement in accuracy of predicting diagnosis of HF by combining common fixed field EHR data with text data to improve early detection of HF. Our preliminary work indicates that longitudinal EHR data (e.g., clinical, laboratory, health behaviors, diagnoses, use of care, etc) are useful in predicting future HF diagnosis. Based on these findings, we recognize an increasingly sophisticated analysis will be required to identify how to use these data to optimize predictive power. We hypothesize that the specific models and the performance of these models will vary by HF subtypes of HF; 3) To determine how digital ECG related measures can be used alone and in combination with other data to improve early detection of HF. Real time access to digital ECG data affords unique opportunities to extract a diversity of measures that may be useful in primary care in the early detection of HF; and 4) To develop preliminary operational protocols for early detection of HF in primary care. We will need to consider how the output from the model can be used to support clinical guidance and shared decision-making. Moreover, models need to be developed for data rich and data poor settings. The long term goal of the proposed work is relevant to the national priority for adoption of EHRs in clinical practice and for meaningful use of such technology. PUBLIC HEALTH RELEVANCE: Heart Failure (HF) strikes one in 5 US citizens over age 40, has a profound impact on health, and is almost always detected too late to allow doctors to substantially reduce morbidity and mortality. We propose to use sophisticated analytic tools to search through electronic health records of patients for early signals of HF. The long term goal of our work is to use such tools to detect HF early enough to allow doctors to change the course of disease and substantially reduce HF morbidity and the risk of death.",Early Detection of Heart Failure via the Electronic Health Record in Primary Care,8824963,R01HL116832,"['Accounting', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Age', 'Caring', 'Cessation of life', 'Clinical', 'Complex', 'Costs and Benefits', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Electrocardiogram', 'Electronic Health Record', 'Employee Strikes', 'Failure', 'Future', 'Goals', 'Group Practice', 'Health', 'Health behavior', 'Heart failure', 'Hospitals', 'Individual', 'Intervention', 'Laboratories', 'Life Style', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Output', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Prevalence', 'Preventive', 'Primary Health Care', 'Process', 'Protocols documentation', 'Quality of life', 'Risk', 'Signal Transduction', 'Signs and Symptoms', 'Staging', 'Symptoms', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Work', 'aging population', 'base', 'body system', 'case control', 'clinical practice', 'cost', 'cost effective', 'digital', 'improved', 'mortality', 'novel', 'predictive modeling', 'prevent', 'rapid growth', 'shared decision making', 'text searching', 'tool', 'trend']",NHLBI,CALIFORNIA PACIFIC MED CTR RES INSTITUTE,R01,2015,461213,0.019274579274359663
"Early Detection of Heart Failure via the Electronic Health Record in Primary Care     DESCRIPTION (provided by applicant): Heart failure (HF) prevalence has increased and will continue so over the next 30 years with a profound individual and societal burden. Early detection of HF may be useful in mitigating this burden. The purpose of this proposal is to develop robust predictive models that make use of longitudinal electronic health record (EHR). Our long term goal is to use such models to detect HF at an earlier stage (e.g., AHA/ACA Stages A or B) than usually occurs in primary care. We have completed extensive preliminary work using 10 years of longitudinal EHR data on primary care patients. Using text mining and machine learning tools we have found that Framingham criteria are documented in the EHR long before more specific diagnostic studies are done. These symptoms are considerably more common among incident HF cases than controls two to four years before diagnosis. Moreover, clinical, laboratory, diagnostic, and other data routinely captured in the EHR predicts future HF diagnosis. We propose to extend this work on early detection of HF with the following aims: 1) To develop more sensitive and specific criteria for use of Framingham HF signs and symptoms in the early detection of HF. We have shown that positive and negative affirmation of Framingham signs and symptoms are useful in HF detection 1-4 years before diagnosis. We propose to address the following: a) Which Framingham signs and symptoms and combinations thereof are most useful for early detection? b) Are there temporal sequences and correlations among signs and symptoms that improve accuracy of detection? c) How do the criteria vary by HF subtype? We hypothesize that analysis of routinely documented signs and symptoms data will yield a clinically meaningful improvement in the accuracy of detecting HF 1 to 2 years before actual diagnosis; 2) To determine the differential improvement in accuracy of predicting diagnosis of HF by combining common fixed field EHR data with text data to improve early detection of HF. Our preliminary work indicates that longitudinal EHR data (e.g., clinical, laboratory, health behaviors, diagnoses, use of care, etc) are useful in predicting future HF diagnosis. Based on these findings, we recognize an increasingly sophisticated analysis will be required to identify how to use these data to optimize predictive power. We hypothesize that the specific models and the performance of these models will vary by HF subtypes of HF; 3) To determine how digital ECG related measures can be used alone and in combination with other data to improve early detection of HF. Real time access to digital ECG data affords unique opportunities to extract a diversity of measures that may be useful in primary care in the early detection of HF; and 4) To develop preliminary operational protocols for early detection of HF in primary care. We will need to consider how the output from the model can be used to support clinical guidance and shared decision-making. Moreover, models need to be developed for data rich and data poor settings. The long term goal of the proposed work is relevant to the national priority for adoption of EHRs in clinical practice and for meaningful use of such technology.         PUBLIC HEALTH RELEVANCE: Heart Failure (HF) strikes one in 5 US citizens over age 40, has a profound impact on health, and is almost always detected too late to allow doctors to substantially reduce morbidity and mortality. We propose to use sophisticated analytic tools to search through electronic health records of patients for early signals of HF. The long term goal of our work is to use such tools to detect HF early enough to allow doctors to change the course of disease and substantially reduce HF morbidity and the risk of death.                ",Early Detection of Heart Failure via the Electronic Health Record in Primary Care,8652345,R01HL116832,"['Accounting', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Age', 'Caring', 'Cessation of life', 'Clinical', 'Complex', 'Costs and Benefits', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Electrocardiogram', 'Electronic Health Record', 'Employee Strikes', 'Failure', 'Future', 'Goals', 'Group Practice', 'Health', 'Health behavior', 'Heart failure', 'Hospitals', 'Individual', 'Intervention', 'Laboratories', 'Life Style', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Output', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Prevalence', 'Preventive', 'Primary Health Care', 'Process', 'Protocols documentation', 'Quality of life', 'Risk', 'Signal Transduction', 'Signs and Symptoms', 'Staging', 'Symptoms', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Work', 'aging population', 'base', 'body system', 'case control', 'clinical practice', 'cost', 'cost effective', 'digital', 'improved', 'mortality', 'novel', 'predictive modeling', 'prevent', 'public health relevance', 'rapid growth', 'shared decision making', 'text searching', 'tool', 'trend']",NHLBI,CALIFORNIA PACIFIC MED CTR RES INSTITUTE,R01,2014,527741,0.019274579274359663
"Early Detection of Heart Failure via the Electronic Health Record in Primary Care     DESCRIPTION (provided by applicant): Heart failure (HF) prevalence has increased and will continue so over the next 30 years with a profound individual and societal burden. Early detection of HF may be useful in mitigating this burden. The purpose of this proposal is to develop robust predictive models that make use of longitudinal electronic health record (EHR). Our long term goal is to use such models to detect HF at an earlier stage (e.g., AHA/ACA Stages A or B) than usually occurs in primary care. We have completed extensive preliminary work using 10 years of longitudinal EHR data on primary care patients. Using text mining and machine learning tools we have found that Framingham criteria are documented in the EHR long before more specific diagnostic studies are done. These symptoms are considerably more common among incident HF cases than controls two to four years before diagnosis. Moreover, clinical, laboratory, diagnostic, and other data routinely captured in the EHR predicts future HF diagnosis. We propose to extend this work on early detection of HF with the following aims: 1) To develop more sensitive and specific criteria for use of Framingham HF signs and symptoms in the early detection of HF. We have shown that positive and negative affirmation of Framingham signs and symptoms are useful in HF detection 1-4 years before diagnosis. We propose to address the following: a) Which Framingham signs and symptoms and combinations thereof are most useful for early detection? b) Are there temporal sequences and correlations among signs and symptoms that improve accuracy of detection? c) How do the criteria vary by HF subtype? We hypothesize that analysis of routinely documented signs and symptoms data will yield a clinically meaningful improvement in the accuracy of detecting HF 1 to 2 years before actual diagnosis; 2) To determine the differential improvement in accuracy of predicting diagnosis of HF by combining common fixed field EHR data with text data to improve early detection of HF. Our preliminary work indicates that longitudinal EHR data (e.g., clinical, laboratory, health behaviors, diagnoses, use of care, etc) are useful in predicting future HF diagnosis. Based on these findings, we recognize an increasingly sophisticated analysis will be required to identify how to use these data to optimize predictive power. We hypothesize that the specific models and the performance of these models will vary by HF subtypes of HF; 3) To determine how digital ECG related measures can be used alone and in combination with other data to improve early detection of HF. Real time access to digital ECG data affords unique opportunities to extract a diversity of measures that may be useful in primary care in the early detection of HF; and 4) To develop preliminary operational protocols for early detection of HF in primary care. We will need to consider how the output from the model can be used to support clinical guidance and shared decision-making. Moreover, models need to be developed for data rich and data poor settings. The long term goal of the proposed work is relevant to the national priority for adoption of EHRs in clinical practice and for meaningful use of such technology.         PUBLIC HEALTH RELEVANCE: Heart Failure (HF) strikes one in 5 US citizens over age 40, has a profound impact on health, and is almost always detected too late to allow doctors to substantially reduce morbidity and mortality. We propose to use sophisticated analytic tools to search through electronic health records of patients for early signals of HF. The long term goal of our work is to use such tools to detect HF early enough to allow doctors to change the course of disease and substantially reduce HF morbidity and the risk of death.                ",Early Detection of Heart Failure via the Electronic Health Record in Primary Care,8421618,R01HL116832,"['Accounting', 'Address', 'Admission activity', 'Adoption', 'Affect', 'Age', 'Caring', 'Cessation of life', 'Clinical', 'Complex', 'Costs and Benefits', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Electrocardiogram', 'Electronic Health Record', 'Employee Strikes', 'Failure', 'Future', 'Goals', 'Group Practice', 'Health', 'Health behavior', 'Heart failure', 'Hospitals', 'Individual', 'Intervention', 'Laboratories', 'Life Style', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medicare', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Output', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Prevalence', 'Preventive', 'Primary Health Care', 'Process', 'Protocols documentation', 'Quality of life', 'Risk', 'Signal Transduction', 'Signs and Symptoms', 'Staging', 'Symptoms', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Work', 'aging population', 'base', 'body system', 'case control', 'clinical practice', 'cost', 'cost effective', 'digital', 'improved', 'mortality', 'novel', 'predictive modeling', 'prevent', 'public health relevance', 'rapid growth', 'shared decision making', 'text searching', 'tool', 'trend']",NHLBI,CALIFORNIA PACIFIC MED CTR RES INSTITUTE,R01,2013,557031,0.019274579274359663
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error     DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9665255,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Infrastructure', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,461012,0.042398636119171294
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error     DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9454246,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,461012,0.042398636119171294
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error     DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9249484,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2017,461012,0.042398636119171294
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error     DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk.         PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.                ",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9065021,R01AI117011,"['Accounting', 'Animals', 'Applied Research', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Taxon', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'improved', 'information model', 'interest', 'journal article', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2016,479735,0.042398636119171294
"BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center DESCRIPTION (provided by applicant): Biomedical and healthcare data sharing efforts are currently impaired by lack of (1) proper incentives and sharing tools for data producers, (2) practical frameworks for data standardization and indexing of data, and (3) effective data discovery mechanisms. BioCADDIE is a consortium of data producers, curators, publishers, and consumers who will work together to develop practical, sustainable solutions to the problem of biomedical and healthcare data discovery. Through task forces and corresponding pilot projects addressing the barriers enumerated above, we will promote open discussion of why millions of dollars are currently spent in the generation of data that remain captive at their origin or are shared in a sub-optimal way just to comply with mandates from funding agencies and scientific journals. We will promote the development of incentives, policies, and tools for data sharing and data discovery. We will engage researchers, clinicians, patients, and the community in general in an open dialogue focused on pros and cons of biomedical and clinical data sharing. BioCADDIE's specific aims are to: (1) Organize task forces with representatives from communities who have interest in data production, dissemination, and utilization. We will organize an annual symposium, workshops, Internet-based discussions among biomedical and clinical researchers, professional societies, journal publishers, funding agencies, clinicians, patients, and information scientists on best, sustainable practices for making data easily discoverable by different types of users. (2) Promote the development of realistic, minimal, friendly meta-data specifications and annotations for biomedical and healthcare data collections, and corresponding tools for automated indexing so that users will be able to locate data that are relevant to their specific free text searches. (3) Incubate new technologies by funding highly innovative, high-risk pilot research projects that enable the development of novel data discovery and indexing engines and have them tested by our diverse community of stakeholders. We only describe a small number of seed pilot projects in this proposal  because BioCADDIE will solicit proposals for new pilot projects every year and select them through a  review process involving the various stakeholder communities. PUBLIC HEALTH RELEVANCE: Biomedical research and healthcare data are not fully utilized in part due to lack of incentives and tools to share these data in a way that makes it possible to reproduce results and make new discoveries. We will develop a consortium involving data producers, data disseminators, and data consumers (including patients) to develop tools and processes for easy discovery and access to data.",BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center,9065210,U24AI117966,"['Address', 'Advisory Committees', 'Automated Indexing', 'Biomedical Research', 'Budgets', 'Businesses', 'Caregivers', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Compulsive Hoarding', 'Computer Interface', 'Consent', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Educational workshop', 'Financial Support', 'Funding', 'Funding Agency', 'Future', 'Generations', 'Goals', 'Golf', 'Health', 'Health Personnel', 'Health Sciences', 'Healthcare', 'Imagery', 'Incentives', 'Incubated', 'Individual', 'Institution', 'Internet', 'Journals', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modality', 'Morals', 'Patients', 'Persons', 'Philosophy', 'Pilot Projects', 'Play', 'Policies', 'Prevention strategy', 'Privacy', 'Process', 'Production', 'Publications', 'Publishing', 'Reproducibility', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rest', 'Role', 'Science', 'Scientist', 'Seeds', 'Societies', 'Solutions', 'Standardization', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Work', 'acronyms', 'base', 'coping', 'cost', 'data sharing', 'demographics', 'design', 'high risk', 'human subject protection', 'indexing', 'innovation', 'interest', 'molecular imaging', 'new technology', 'news', 'novel', 'novel strategies', 'optimism', 'research study', 'social', 'success', 'symposium', 'text searching', 'tool', 'usability']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2015,49687,0.009839533125850349
"BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center DESCRIPTION (provided by applicant): Biomedical and healthcare data sharing efforts are currently impaired by lack of (1) proper incentives and sharing tools for data producers, (2) practical frameworks for data standardization and indexing of data, and (3) effective data discovery mechanisms. BioCADDIE is a consortium of data producers, curators, publishers, and consumers who will work together to develop practical, sustainable solutions to the problem of biomedical and healthcare data discovery. Through task forces and corresponding pilot projects addressing the barriers enumerated above, we will promote open discussion of why millions of dollars are currently spent in the generation of data that remain captive at their origin or are shared in a sub-optimal way just to comply with mandates from funding agencies and scientific journals. We will promote the development of incentives, policies, and tools for data sharing and data discovery. We will engage researchers, clinicians, patients, and the community in general in an open dialogue focused on pros and cons of biomedical and clinical data sharing. BioCADDIE's specific aims are to: (1) Organize task forces with representatives from communities who have interest in data production, dissemination, and utilization. We will organize an annual symposium, workshops, Internet-based discussions among biomedical and clinical researchers, professional societies, journal publishers, funding agencies, clinicians, patients, and information scientists on best, sustainable practices for making data easily discoverable by different types of users. (2) Promote the development of realistic, minimal, friendly meta-data specifications and annotations for biomedical and healthcare data collections, and corresponding tools for automated indexing so that users will be able to locate data that are relevant to their specific free text searches. (3) Incubate new technologies by funding highly innovative, high-risk pilot research projects that enable the development of novel data discovery and indexing engines and have them tested by our diverse community of stakeholders. We only describe a small number of seed pilot projects in this proposal  because BioCADDIE will solicit proposals for new pilot projects every year and select them through a  review process involving the various stakeholder communities. PUBLIC HEALTH RELEVANCE: Biomedical research and healthcare data are not fully utilized in part due to lack of incentives and tools to share these data in a way that makes it possible to reproduce results and make new discoveries. We will develop a consortium involving data producers, data disseminators, and data consumers (including patients) to develop tools and processes for easy discovery and access to data.",BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center,9120800,U24AI117966,"['Address', 'Advisory Committees', 'Automated Indexing', 'Biomedical Research', 'Budgets', 'Businesses', 'Caregivers', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Compulsive Hoarding', 'Computer Interface', 'Consent', 'Crowding', 'Data', 'Data Collection', 'Data Discovery', 'Data Science', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Educational workshop', 'Financial Support', 'Funding', 'Funding Agency', 'Future', 'Generations', 'Goals', 'Golf', 'Health', 'Health Personnel', 'Health Sciences', 'Healthcare', 'Imagery', 'Incentives', 'Incubated', 'Individual', 'Institution', 'Internet', 'Journals', 'Manuals', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Modality', 'Morals', 'Patients', 'Persons', 'Philosophy', 'Pilot Projects', 'Play', 'Policies', 'Prevention strategy', 'Privacy', 'Process', 'Production', 'Professional Organizations', 'Publications', 'Publishing', 'Reproducibility', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rest', 'Role', 'Science', 'Scientist', 'Seeds', 'Societies', 'Standardization', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Work', 'acronyms', 'base', 'coping', 'cost', 'data access', 'data sharing', 'demographics', 'design', 'high risk', 'human subject protection', 'indexing', 'innovation', 'interest', 'molecular imaging', 'new technology', 'news', 'novel', 'novel strategies', 'optimism', 'research study', 'social', 'success', 'symposium', 'text searching', 'tool', 'usability']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2016,2000000,0.009839533125850349
"BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center DESCRIPTION (provided by applicant): Biomedical and healthcare data sharing efforts are currently impaired by lack of (1) proper incentives and sharing tools for data producers, (2) practical frameworks for data standardization and indexing of data, and (3) effective data discovery mechanisms. BioCADDIE is a consortium of data producers, curators, publishers, and consumers who will work together to develop practical, sustainable solutions to the problem of biomedical and healthcare data discovery. Through task forces and corresponding pilot projects addressing the barriers enumerated above, we will promote open discussion of why millions of dollars are currently spent in the generation of data that remain captive at their origin or are shared in a sub-optimal way just to comply with mandates from funding agencies and scientific journals. We will promote the development of incentives, policies, and tools for data sharing and data discovery. We will engage researchers, clinicians, patients, and the community in general in an open dialogue focused on pros and cons of biomedical and clinical data sharing. BioCADDIE's specific aims are to: (1) Organize task forces with representatives from communities who have interest in data production, dissemination, and utilization. We will organize an annual symposium, workshops, Internet-based discussions among biomedical and clinical researchers, professional societies, journal publishers, funding agencies, clinicians, patients, and information scientists on best, sustainable practices for making data easily discoverable by different types of users. (2) Promote the development of realistic, minimal, friendly meta-data specifications and annotations for biomedical and healthcare data collections, and corresponding tools for automated indexing so that users will be able to locate data that are relevant to their specific free text searches. (3) Incubate new technologies by funding highly innovative, high-risk pilot research projects that enable the development of novel data discovery and indexing engines and have them tested by our diverse community of stakeholders. We only describe a small number of seed pilot projects in this proposal  because BioCADDIE will solicit proposals for new pilot projects every year and select them through a  review process involving the various stakeholder communities. PUBLIC HEALTH RELEVANCE: Biomedical research and healthcare data are not fully utilized in part due to lack of incentives and tools to share these data in a way that makes it possible to reproduce results and make new discoveries. We will develop a consortium involving data producers, data disseminators, and data consumers (including patients) to develop tools and processes for easy discovery and access to data.",BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center,9269344,U24AI117966,"['Address', 'Advisory Committees', 'Automated Indexing', 'Biomedical Research', 'Budgets', 'Businesses', 'Caregivers', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Compulsive Hoarding', 'Computer Interface', 'Consent', 'Crowding', 'Data', 'Data Collection', 'Data Discovery', 'Data Science', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Educational workshop', 'Financial Support', 'Funding', 'Funding Agency', 'Future', 'Generations', 'Goals', 'Golf', 'Health', 'Health Personnel', 'Health Sciences', 'Healthcare', 'Imagery', 'Incentives', 'Incubated', 'Individual', 'Institution', 'Internet', 'Journals', 'Manuals', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Modality', 'Morals', 'Patients', 'Persons', 'Philosophy', 'Pilot Projects', 'Play', 'Policies', 'Prevention strategy', 'Privacy', 'Process', 'Production', 'Professional Organizations', 'Publications', 'Publishing', 'Reproducibility', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rest', 'Role', 'Science', 'Scientist', 'Seeds', 'Societies', 'Standardization', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Work', 'acronyms', 'base', 'coping', 'cost', 'data access', 'data sharing', 'demographics', 'design', 'high risk', 'human subject protection', 'indexing', 'innovation', 'interest', 'molecular imaging', 'new technology', 'news', 'novel', 'novel strategies', 'optimism', 'research study', 'social', 'success', 'symposium', 'text searching', 'tool', 'usability']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2016,810655,0.009839533125850349
"BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center DESCRIPTION (provided by applicant): Biomedical and healthcare data sharing efforts are currently impaired by lack of (1) proper incentives and sharing tools for data producers, (2) practical frameworks for data standardization and indexing of data, and (3) effective data discovery mechanisms. BioCADDIE is a consortium of data producers, curators, publishers, and consumers who will work together to develop practical, sustainable solutions to the problem of biomedical and healthcare data discovery. Through task forces and corresponding pilot projects addressing the barriers enumerated above, we will promote open discussion of why millions of dollars are currently spent in the generation of data that remain captive at their origin or are shared in a sub-optimal way just to comply with mandates from funding agencies and scientific journals. We will promote the development of incentives, policies, and tools for data sharing and data discovery. We will engage researchers, clinicians, patients, and the community in general in an open dialogue focused on pros and cons of biomedical and clinical data sharing. BioCADDIE's specific aims are to: (1) Organize task forces with representatives from communities who have interest in data production, dissemination, and utilization. We will organize an annual symposium, workshops, Internet-based discussions among biomedical and clinical researchers, professional societies, journal publishers, funding agencies, clinicians, patients, and information scientists on best, sustainable practices for making data easily discoverable by different types of users. (2) Promote the development of realistic, minimal, friendly meta-data specifications and annotations for biomedical and healthcare data collections, and corresponding tools for automated indexing so that users will be able to locate data that are relevant to their specific free text searches. (3) Incubate new technologies by funding highly innovative, high-risk pilot research projects that enable the development of novel data discovery and indexing engines and have them tested by our diverse community of stakeholders. We only describe a small number of seed pilot projects in this proposal  because BioCADDIE will solicit proposals for new pilot projects every year and select them through a  review process involving the various stakeholder communities. PUBLIC HEALTH RELEVANCE: Biomedical research and healthcare data are not fully utilized in part due to lack of incentives and tools to share these data in a way that makes it possible to reproduce results and make new discoveries. We will develop a consortium involving data producers, data disseminators, and data consumers (including patients) to develop tools and processes for easy discovery and access to data.",BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center,8935753,U24AI117966,"['Address', 'Advisory Committees', 'Automated Indexing', 'Biomedical Research', 'Budgets', 'Businesses', 'Caregivers', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Compulsive Hoarding', 'Computer Interface', 'Consent', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Educational workshop', 'Financial Support', 'Funding', 'Funding Agency', 'Future', 'Generations', 'Goals', 'Golf', 'Health', 'Health Personnel', 'Health Sciences', 'Healthcare', 'Imagery', 'Incentives', 'Incubated', 'Individual', 'Institution', 'Internet', 'Journals', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modality', 'Morals', 'Patients', 'Persons', 'Philosophy', 'Pilot Projects', 'Play', 'Policies', 'Prevention strategy', 'Privacy', 'Process', 'Production', 'Publications', 'Publishing', 'Reproducibility', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rest', 'Role', 'Science', 'Scientist', 'Seeds', 'Societies', 'Solutions', 'Standardization', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Work', 'acronyms', 'base', 'coping', 'cost', 'data sharing', 'demographics', 'design', 'high risk', 'human subject protection', 'indexing', 'innovation', 'interest', 'molecular imaging', 'new technology', 'news', 'novel', 'novel strategies', 'optimism', 'research study', 'social', 'success', 'symposium', 'text searching', 'tool', 'usability']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2015,1059598,0.009839533125850349
"BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center     DESCRIPTION (provided by applicant): Biomedical and healthcare data sharing efforts are currently impaired by lack of (1) proper incentives and sharing tools for data producers, (2) practical frameworks for data standardization and indexing of data, and (3) effective data discovery mechanisms. BioCADDIE is a consortium of data producers, curators, publishers, and consumers who will work together to develop practical, sustainable solutions to the problem of biomedical and healthcare data discovery. Through task forces and corresponding pilot projects addressing the barriers enumerated above, we will promote open discussion of why millions of dollars are currently spent in the generation of data that remain captive at their origin or are shared in a sub-optimal way just to comply with mandates from funding agencies and scientific journals. We will promote the development of incentives, policies, and tools for data sharing and data discovery. We will engage researchers, clinicians, patients, and the community in general in an open dialogue focused on pros and cons of biomedical and clinical data sharing. BioCADDIE's specific aims are to: (1) Organize task forces with representatives from communities who have interest in data production, dissemination, and utilization. We will organize an annual symposium, workshops, Internet-based discussions among biomedical and clinical researchers, professional societies, journal publishers, funding agencies, clinicians, patients, and information scientists on best, sustainable practices for making data easily discoverable by different types of users. (2) Promote the development of realistic, minimal, friendly meta-data specifications and annotations for biomedical and healthcare data collections, and corresponding tools for automated indexing so that users will be able to locate data that are relevant to their specific free text searches. (3) Incubate new technologies by funding highly innovative, high-risk pilot research projects that enable the development of novel data discovery and indexing engines and have them tested by our diverse community of stakeholders. We only describe a small number of seed pilot projects in this proposal  because BioCADDIE will solicit proposals for new pilot projects every year and select them through a  review process involving the various stakeholder communities.         PUBLIC HEALTH RELEVANCE: Biomedical research and healthcare data are not fully utilized in part due to lack of incentives and tools to share these data in a way that makes it possible to reproduce results and make new discoveries. We will develop a consortium involving data producers, data disseminators, and data consumers (including patients) to develop tools and processes for easy discovery and access to data.            ",BioCADDIE: Biomedical and healthCAre Data Discovery and Indexing Engine center,8819270,U24AI117966,"['Address', 'Advisory Committees', 'Automated Indexing', 'Biomedical Research', 'Budgets', 'Businesses', 'Caregivers', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Compulsive Hoarding', 'Computer Interface', 'Consent', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Educational workshop', 'Financial Support', 'Funding', 'Funding Agency', 'Future', 'Generations', 'Goals', 'Golf', 'Health', 'Health Personnel', 'Health Sciences', 'Healthcare', 'Imagery', 'Incentives', 'Incubated', 'Individual', 'Institution', 'Internet', 'Journals', 'Mails', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modality', 'Morals', 'Patients', 'Persons', 'Philosophy', 'Pilot Projects', 'Play', 'Policies', 'Prevention strategy', 'Privacy', 'Process', 'Production', 'Publications', 'Publishing', 'Reproducibility', 'Request for Applications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rest', 'Role', 'Science', 'Scientist', 'Seeds', 'Societies', 'Solutions', 'Standardization', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Work', 'acronyms', 'base', 'coping', 'cost', 'data sharing', 'demographics', 'design', 'high risk', 'human subject protection', 'indexing', 'innovation', 'interest', 'molecular imaging', 'new technology', 'news', 'novel', 'novel strategies', 'optimism', 'public health relevance', 'research study', 'social', 'success', 'symposium', 'text searching', 'tool', 'usability']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2014,1067047,0.009839533125850349
"Sci-Score, a tool suite to support Rigor and Transparency NIH and Journal Guidelines Project Summary While standards in reporting of scientific methods are absolutely critical to producing reproducible science, meeting such standards is tedious and difficult. Checklists and instructions are tough to follow often resulting in low and inconsistent compliance. Scientific journals and societies as well as the National Institutes of Health are now actively proposing general guidelines to address reproducibility issues, particularly in the reporting of methods, but the trickier part is to train the biomedical community to use these standards to effectively. To support new standards in methods reporting, especially the RRID standard for Rigor and Transparency of Key Biological Resources, we propose to build Sci-Score a text mining based tool suite to help authors meet the standard. Sci-Score will provide an automated check on compliance with the RRID standard already implemented by over 100 journals including Cell, Journal of Neuroscience, and eLife and other Rigor and transparency standards put forward by the NIH. The innovation behind Sci-score is the provision of a score, which can be obtained by individual investigators or journals. This score reflects an aspect of quality of methods reporting. We posit that the score will serve as a tool that investigators can use to compete with themselves and each other, the way they currently compete on metrics of popularity, i.e., the H-index. In Phase I of this project and before, our group has successfully developed a text mining algorithm that can detect antibodies, cell lines, organisms and digital resources (all 4 RRID types) and has created a preliminary score. We propose to extend this approach to all research inputs, like chemicals and plasmids that are requested as part of Cell press STAR Methods (http://www.cell.com/star-methods). We also propose to build a set of algorithms to detect whether authors discuss the major sources of irreproducibility outlined by NIH, including investigator blinding, proper randomization and sufficient reporting of sex and other biological variables. Resource identification along with other quality metrics will be used to score the quality of scientific methods section text. If successful, the tool could be used by editors, reviewers, and investigators to improve the quality of the scientific paper. Our Phase II specific aims include 1) enhancing and hardening the core natural language processing pipelines to recognize a broader range of sentences in near real time; 2) building a set of modular tools that will be provided for different groups of users to take advantage of the text mining capability we develop in aim 1. At the end of Phase II, we should have a commercially viable product that will be able to be licensed to serve the needs of the publishers and the broader research community. Standards for scientific methods reporting are absolutely critical to producing reproducible science, but meeting such standards is difficult. Checklists and instructions are tough to follow often resulting in low and inconsistent compliance. To support new standards in methods reporting, especially the RRID standard for Rigor and Transparency, we propose to build Sci-Score a text mining based tool suite to help authors meet the standard. Sci-Score will provide an automated check on compliance with the RRID standard implemented by over 100 journals including Cell, Journal of Neuroscience, and eLife. Sci-score provides an automated rating the quality of methods reporting in submitted articles, which provides feedback to authors, reviewers and editors on how to improve compliance with RRIDs and other standards.","Sci-Score, a tool suite to support Rigor and Transparency NIH and Journal Guidelines",9621771,R44MH119094,"['Address', 'Adherence', 'Algorithms', 'Antibodies', 'Award', 'Biological', 'Cell Line', 'Cells', 'Chemicals', 'Communities', 'Databases', 'Ethics', 'Feedback', 'Guidelines', 'Health', 'Human', 'Individual', 'Instruction', 'Journals', 'Methods', 'Mission', 'Natural Language Processing', 'Neurosciences', 'Oligonucleotide Probes', 'Organism', 'Paper', 'Performance', 'Phase', 'Plagiarism', 'Plasmids', 'Publications', 'Publishing', 'Randomized', 'Reader', 'Reagent', 'Recommendation', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Science', 'Societies', 'Software Tools', 'Source', 'Specific qualifier value', 'System', 'Talents', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'complex biological systems', 'digital', 'improved', 'indexing', 'innovation', 'meetings', 'sex', 'sound', 'text searching', 'tool']",NIMH,"SCICRUNCH, INC.",R44,2018,748748,0.01669487561477996
"Sci-Score, a tool suite to support Rigor and Transparency NIH and Journal Guidelines Project Summary While standards in reporting of scientific methods are absolutely critical to producing reproducible science, meeting such standards is tedious and difficult. Checklists and instructions are tough to follow often resulting in low and inconsistent compliance. Scientific journals and societies as well as the National Institutes of Health are now actively proposing general guidelines to address reproducibility issues, particularly in the reporting of methods, but the trickier part is to train the biomedical community to use these standards to effectively. To support new standards in methods reporting, especially the RRID standard for Rigor and Transparency of Key Biological Resources, we propose to build Sci-Score a text mining based tool suite to help authors meet the standard. Sci-Score will provide an automated check on compliance with the RRID standard already implemented by over 100 journals including Cell, Journal of Neuroscience, and eLife and other Rigor and transparency standards put forward by the NIH. The innovation behind Sci-score is the provision of a score, which can be obtained by individual investigators or journals. This score reflects an aspect of quality of methods reporting. We posit that the score will serve as a tool that investigators can use to compete with themselves and each other, the way they currently compete on metrics of popularity, i.e., the H-index. In Phase I of this project and before, our group has successfully developed a text mining algorithm that can detect antibodies, cell lines, organisms and digital resources (all 4 RRID types) and has created a preliminary score. We propose to extend this approach to all research inputs, like chemicals and plasmids that are requested as part of Cell press STAR Methods (http://www.cell.com/star-methods). We also propose to build a set of algorithms to detect whether authors discuss the major sources of irreproducibility outlined by NIH, including investigator blinding, proper randomization and sufficient reporting of sex and other biological variables. Resource identification along with other quality metrics will be used to score the quality of scientific methods section text. If successful, the tool could be used by editors, reviewers, and investigators to improve the quality of the scientific paper. Our Phase II specific aims include 1) enhancing and hardening the core natural language processing pipelines to recognize a broader range of sentences in near real time; 2) building a set of modular tools that will be provided for different groups of users to take advantage of the text mining capability we develop in aim 1. At the end of Phase II, we should have a commercially viable product that will be able to be licensed to serve the needs of the publishers and the broader research community. Standards for scientific methods reporting are absolutely critical to producing reproducible science, but meeting such standards is difficult. Checklists and instructions are tough to follow often resulting in low and inconsistent compliance. To support new standards in methods reporting, especially the RRID standard for Rigor and Transparency, we propose to build Sci-Score a text mining based tool suite to help authors meet the standard. Sci-Score will provide an automated check on compliance with the RRID standard implemented by over 100 journals including Cell, Journal of Neuroscience, and eLife. Sci-score provides an automated rating the quality of methods reporting in submitted articles, which provides feedback to authors, reviewers and editors on how to improve compliance with RRIDs and other standards.","Sci-Score, a tool suite to support Rigor and Transparency NIH and Journal Guidelines",9786847,R44MH119094,"['Address', 'Adherence', 'Algorithms', 'Antibodies', 'Award', 'Biological', 'Cell Line', 'Cells', 'Chemicals', 'Communities', 'Databases', 'Ethics', 'Feedback', 'Guidelines', 'Health', 'Human', 'Individual', 'Instruction', 'Journals', 'Methods', 'Mission', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Neurosciences', 'Oligonucleotide Probes', 'Organism', 'Paper', 'Performance', 'Phase', 'Plagiarism', 'Plasmids', 'Publications', 'Publishing', 'Randomized', 'Reader', 'Reagent', 'Recommendation', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Science', 'Societies', 'Software Tools', 'Source', 'Specific qualifier value', 'System', 'Talents', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'complex biological systems', 'digital', 'improved', 'indexing', 'innovation', 'meetings', 'sex', 'sound', 'text searching', 'tool']",NIMH,"SCICRUNCH, INC.",R44,2019,747591,0.01669487561477996
"Deriving high-quality evidence from national healthcare databases to improve suicidality detection and treatment outcomes in PTSD and TBI PROJECT SUMMARY Post-traumatic stress disorder (PTSD) has complex profiles of co-occurring medical conditions (comorbidities) and is associated with high risk of suicide, particularly among Veterans, in which it is a leading cause of death. There is a critical lack of advancement in PTSD pharmacotherapy, as illustrated by increased use of off-label medications and polypharmacy (multiple drugs used simultaneously). The consequent limited evidence on the relative risks and benefits of treatments creates a crisis in PTSD management. Moreover, PTSD and its major comorbidities [traumatic brain injury (TBI) and suicidality] often remain undocumented in electronic health records (EHR). There is also poor predictability of disease outcomes since there are frequent changes in pharmacological treatment and multiple modifying comorbidities. Our long-term goal is to improve diagnostics, secondary/tertiary prevention, and treatment outcomes of PTSD and its comorbidities via enhanced EHR utilization. To achieve our objectives, we will analyze EHR and administrative claims data from Veterans Administration (VA) and non-VA databases, collectively covering >2M PTSD and >2M TBI patients. Specifically, we aim to: (1) Identify undetected PTSD, TBI, and self-harm from EHRs (using machine learning with and without natural language language processing) to guide health service improvements. (2) Predict PTSD clinical course in the VA population through novel modeling of disease trajectories that account for time-varying treatments and biases (3) Compare the effectiveness of PTSD psychotropic monotherapies, polypharmacy, and psychotherapy to guide the choice of treatment for improved patient outcomes. By enhancing and validating a machine learning approach developed by our team, we will impute unrecorded PTSD, TBI, and self-harm from both datasets, and characterize factors associated with documentation disparities. We will model diseases trajectories with enhanced latent class analysis, focusing on self-harm, substance misuse, and psychiatric hospitalization in PTSD. With Local Control methodology innovations, we will compare the risk of PTSD in veterans with and without comorbid TBI. Finally, we will perform the largest comparative effectiveness studies (to date) of PTSD treatments on >100 monotherapy and polypharmacy regimens plus psychotherapy interventions. These studies will provide high-quality evidence on the risk of hospitalizations, substance misuse, and suicidal acts/self-harm. Successful completion of these investigations will improve the quality of decision making for providers and patients, and guide improved service delivery to the population of veterans and non-veterans with PTSD/TBI, and/or high risk of suicide. PROJECT NARRATIVE Post-traumatic stress disorder (PTSD), and its associated conditions (e.g., traumatic brain injury and suicidality) are often underdiagnosed, and have outcomes that are difficult to predict. Treatment of PTSD often involves frequent treatment changes with multi-drug regimens (polypharmacy) and off-label medications for which the relative risks and benefits are largely unknown. To address these problems, we will develop and apply methods to identify undiagnosed patients, predict disease trajectories, and compare the effectiveness of all common PTSD treatments using health records from millions of patients in Veterans Administration (VA) and non-VA databases.",Deriving high-quality evidence from national healthcare databases to improve suicidality detection and treatment outcomes in PTSD and TBI,10088135,R56MH120826,"['Address', 'Affect', 'Benefits and Risks', 'Bipolar Disorder', 'Caring', 'Cause of Death', 'Characteristics', 'Clinical', 'Clinical Research', 'Code', 'Complex', 'Coupled', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Diagnostic', 'Disease', 'Disease Management', 'Disease Outcome', 'Disease Progression', 'Disease model', 'Documentation', 'Drug Combinations', 'Effectiveness', 'Electronic Health Record', 'Event', 'Fostering', 'General Population', 'Glean', 'Goals', 'Health Services', 'Healthcare', 'Hospitalization', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Label', 'Longterm Follow-up', 'Machine Learning', 'Major Mental Illness', 'Maps', 'Mediating', 'Medical', 'Mental disorders', 'Mentally Ill Persons', 'Methodology', 'Methods', 'Military Personnel', 'Modeling', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Pharmacological Treatment', 'Pharmacotherapy', 'Phenotype', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Provider', 'Psychiatry', 'Psychotherapy', 'Regimen', 'Relative Risks', 'Reporting', 'Research Design', 'Residual state', 'Risk', 'Risk Estimate', 'Safety', 'Secondary Prevention', 'Self-Injurious Behavior', 'Source', 'Suicide', 'Symptoms', 'Time', 'Traumatic Brain Injury', 'Traumatic Stress Disorders', 'Treatment Protocols', 'Treatment outcome', 'United States Department of Veterans Affairs', 'Veterans', 'analysis pipeline', 'cohort', 'comorbidity', 'comparative', 'comparative effectiveness study', 'compare effectiveness', 'data modeling', 'effective therapy', 'experience', 'health record', 'high risk', 'improved', 'improved outcome', 'innovation', 'language processing', 'multiple drug use', 'natural language', 'novel', 'off-label drug', 'outcome forecast', 'prevent', 'psychosocial', 'service delivery', 'sociodemographic factors', 'stress related disorder', 'substance misuse', 'suicidal act', 'suicidal risk', 'tertiary prevention', 'therapy design', 'time use', 'treatment choice', 'treatment comparison']",NIMH,UNIVERSITY OF NEW MEXICO HEALTH SCIS CTR,R56,2020,776198,0.02748146251553126
"4/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders PROJECT ABSTRACT Major depressive disorder (MDD), anxiety disorders, and substance use disorders (SUDs) are common, complex psychiatric traits that frequently co-occur and are associated with significant functional impairment, increased healthcare utilization and cost, and higher mortality risk. Not only are these three conditions highly prevalent in the general population and generate a huge societal burden, but recent studies by our team and others have shown that shared covariance from common genetic variation significantly contributes to these psychiatric comorbidities. Large data sets are needed to understand how the multifaceted interplay of genetics, including polygenic risk scores (PRSs), and social determinants of health, such as employment and educational attainment, can impact the risk of these psychiatric disorders and clinical outcomes, such as multiple psychiatric hospitalizations. PRSs have shown potential for risk prediction, but the clinical utility of PRSs for psychiatric conditions is just starting to be explored. Research utilizing Electronic Health Records (EHRs) offers the promise of large data sets to examine these relationships in cohorts of patients seen in clinical practice. However, the use of EHRs is in its infancy in the study of psychiatric disorders and their treatment. This study will address critical knowledge gaps in genotype-psychiatric phenotype relationships in large, demographically and geographically diverse population-based samples derived from EHR-linked biobanks across four medical centers - Columbia, Cornell, Mayo Clinic and Mount Sinai. Our objectives are to (1) develop improved methods for EHR phenotyping of MDD, anxiety, and SUDs, and related outcomes based on a data-set of >30 million EHRs, (2) evaluate associations between PRSs and these conditions, and (3) assess the association between PRSs and outcomes including treatment resistance in MDD and healthcare utilization in patients with MDD, anxiety and SUD. The PRS analyses will utilize data from biobanks with >50,000 persons with both EHR and GWAS data. Successful completion of this study will substantially advance our understanding of the clinical utility of PRSs for commonly occurring psychiatric disorders. PROJECT NARRATIVE Major depression, anxiety disorders and substance use disorder are highly prevalent in the general population and have a huge societal burden. Given the substantial heritability of these conditions and their polygenic architecture, there is increasing interest in using quantitative polygenic risk scores (PRSs) for risk stratification. This study will analyze ""big data"" from electronic health records linked to genetic data to evaluate the prediction of clinical outcomes using PRSs and social determinants of health.","4/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders",10007905,R01MH121922,"['Address', 'Anxiety', 'Anxiety Disorders', 'Architecture', 'Big Data', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Employment', 'Environmental Risk Factor', 'European', 'Evaluation', 'Feeling suicidal', 'Funding', 'General Population', 'Genetic', 'Genetic Determinism', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Geography', 'Goals', 'Health Care Costs', 'Health system', 'Heritability', 'Hospitalization', 'Individual', 'Knowledge', 'Link', 'Machine Learning', 'Major Depressive Disorder', 'Medical', 'Medical center', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Natural Language Processing', 'New York City', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phenotype', 'Population', 'Population Heterogeneity', 'Research', 'Risk', 'Risk stratification', 'Role', 'Sampling', 'Scoring Method', 'Site', 'Substance Use Disorder', 'Suicide attempt', 'Symptoms', 'Text', 'Variant', 'base', 'biobank', 'care outcomes', 'clinical care', 'clinical practice', 'cohort', 'comorbidity', 'deep learning', 'disorder risk', 'functional disability', 'genetic epidemiology', 'genetic risk factor', 'genome wide association study', 'genome-wide', 'health care service utilization', 'improved', 'infancy', 'interest', 'large datasets', 'learning strategy', 'mortality', 'mortality risk', 'neuropsychiatric disorder', 'pleiotropism', 'polygenic risk score', 'population based', 'predict clinical outcome', 'psychogenetics', 'response', 'social health determinants', 'structured data', 'suicidal behavior', 'therapy resistant', 'trait', 'treatment-resistant depression']",NIMH,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2020,408726,0.02088322739390829
"4/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders PROJECT ABSTRACT Major depressive disorder (MDD), anxiety disorders, and substance use disorders (SUDs) are common, complex psychiatric traits that frequently co-occur and are associated with significant functional impairment, increased healthcare utilization and cost, and higher mortality risk. Not only are these three conditions highly prevalent in the general population and generate a huge societal burden, but recent studies by our team and others have shown that shared covariance from common genetic variation significantly contributes to these psychiatric comorbidities. Large data sets are needed to understand how the multifaceted interplay of genetics, including polygenic risk scores (PRSs), and social determinants of health, such as employment and educational attainment, can impact the risk of these psychiatric disorders and clinical outcomes, such as multiple psychiatric hospitalizations. PRSs have shown potential for risk prediction, but the clinical utility of PRSs for psychiatric conditions is just starting to be explored. Research utilizing Electronic Health Records (EHRs) offers the promise of large data sets to examine these relationships in cohorts of patients seen in clinical practice. However, the use of EHRs is in its infancy in the study of psychiatric disorders and their treatment. This study will address critical knowledge gaps in genotype-psychiatric phenotype relationships in large, demographically and geographically diverse population-based samples derived from EHR-linked biobanks across four medical centers - Columbia, Cornell, Mayo Clinic and Mount Sinai. Our objectives are to (1) develop improved methods for EHR phenotyping of MDD, anxiety, and SUDs, and related outcomes based on a data-set of >30 million EHRs, (2) evaluate associations between PRSs and these conditions, and (3) assess the association between PRSs and outcomes including treatment resistance in MDD and healthcare utilization in patients with MDD, anxiety and SUD. The PRS analyses will utilize data from biobanks with >50,000 persons with both EHR and GWAS data. Successful completion of this study will substantially advance our understanding of the clinical utility of PRSs for commonly occurring psychiatric disorders. PROJECT NARRATIVE Major depression, anxiety disorders and substance use disorder are highly prevalent in the general population and have a huge societal burden. Given the substantial heritability of these conditions and their polygenic architecture, there is increasing interest in using quantitative polygenic risk scores (PRSs) for risk stratification. This study will analyze ""big data"" from electronic health records linked to genetic data to evaluate the prediction of clinical outcomes using PRSs and social determinants of health.","4/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders",9877153,R01MH121922,"['Address', 'Anxiety', 'Anxiety Disorders', 'Architecture', 'Big Data', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Comorbidity', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Employment', 'Environmental Risk Factor', 'European', 'Evaluation', 'Feeling suicidal', 'Funding', 'General Population', 'Genetic', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Geography', 'Goals', 'Health Care Costs', 'Health system', 'Heritability', 'Hospitalization', 'Individual', 'Knowledge', 'Link', 'Machine Learning', 'Major Depressive Disorder', 'Medical', 'Medical center', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Natural Language Processing', 'New York City', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phenotype', 'Population', 'Population Heterogeneity', 'Research', 'Risk', 'Risk stratification', 'Role', 'Sampling', 'Scoring Method', 'Site', 'Structure', 'Substance Use Disorder', 'Suicide attempt', 'Symptoms', 'Text', 'Variant', 'base', 'biobank', 'care outcomes', 'clinical care', 'clinical practice', 'cohort', 'deep learning', 'disorder risk', 'functional disability', 'genetic epidemiology', 'genetic risk factor', 'genome wide association study', 'genome-wide', 'health care service utilization', 'improved', 'infancy', 'interest', 'learning strategy', 'mortality', 'mortality risk', 'neuropsychiatric disorder', 'pleiotropism', 'population based', 'predict clinical outcome', 'psychogenetics', 'response', 'social health determinants', 'suicidal behavior', 'therapy resistant', 'trait', 'treatment-resistant depression']",NIMH,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2019,408726,0.02088322739390829
"2/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders PROJECT ABSTRACT Major depressive disorder (MDD), anxiety disorders, and substance use disorders (SUDs) are common, complex psychiatric traits that frequently co-occur and are associated with significant functional impairment, increased healthcare utilization and cost, and higher mortality risk. Not only are these three conditions highly prevalent in the general population and generate a huge societal burden, but recent studies by our team and others have shown that shared covariance from common genetic variation significantly contributes to these psychiatric comorbidities. Large data sets are needed to understand how the multifaceted interplay of genetics, including polygenic risk scores (PRSs), and social determinants of health, such as employment and educational attainment, can impact the risk of these psychiatric disorders and clinical outcomes, such as multiple psychiatric hospitalizations. PRSs have shown potential for risk prediction, but the clinical utility of PRSs for psychiatric conditions is just starting to be explored. Research utilizing Electronic Health Records (EHRs) offers the promise of large data sets to examine these relationships in cohorts of patients seen in clinical practice. However, the use of EHRs is in its infancy in the study of psychiatric disorders and their treatment. This study will address critical knowledge gaps in genotype-psychiatric phenotype relationships in large, demographically and geographically diverse population-based samples derived from EHR-linked biobanks across four medical centers - Columbia, Cornell, Mayo Clinic and Mount Sinai. Our objectives are to (1) develop improved methods for EHR phenotyping of MDD, anxiety, and SUDs, and related outcomes based on a data-set of >30 million EHRs, (2) evaluate associations between PRSs and these conditions, and (3) assess the association between PRSs and outcomes including treatment resistance in MDD and healthcare utilization in patients with MDD, anxiety and SUD. The PRS analyses will utilize data from biobanks with >50,000 persons with both EHR and GWAS data. Successful completion of this study will substantially advance our understanding of the clinical utility of PRSs for commonly occurring psychiatric disorders. PROJECT NARRATIVE Major depression, anxiety disorders and substance use disorder are highly prevalent in the general population and have a huge societal burden. Given the substantial heritability of these conditions and their polygenic architecture, there is increasing interest in using quantitative polygenic risk scores (PRSs) for risk stratification. This study will analyze ""big data"" from electronic health records linked to genetic data to evaluate the prediction of clinical outcomes using PRSs and social determinants of health.","2/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders",10007908,R01MH121924,"['Address', 'Anxiety', 'Anxiety Disorders', 'Architecture', 'Big Data', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Employment', 'Environmental Risk Factor', 'European', 'Evaluation', 'Feeling suicidal', 'Funding', 'General Population', 'Genetic', 'Genetic Determinism', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Geography', 'Goals', 'Health Care Costs', 'Health system', 'Heritability', 'Hospitalization', 'Individual', 'Knowledge', 'Link', 'Machine Learning', 'Major Depressive Disorder', 'Medical', 'Medical center', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Natural Language Processing', 'New York City', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phenotype', 'Population', 'Population Heterogeneity', 'Research', 'Risk', 'Risk stratification', 'Role', 'Sampling', 'Scoring Method', 'Site', 'Substance Use Disorder', 'Suicide attempt', 'Symptoms', 'Text', 'Variant', 'base', 'biobank', 'care outcomes', 'clinical care', 'clinical practice', 'cohort', 'comorbidity', 'deep learning', 'disorder risk', 'functional disability', 'genetic epidemiology', 'genetic risk factor', 'genome wide association study', 'genome-wide', 'health care service utilization', 'improved', 'infancy', 'interest', 'large datasets', 'learning strategy', 'mortality', 'mortality risk', 'neuropsychiatric disorder', 'pleiotropism', 'polygenic risk score', 'population based', 'predict clinical outcome', 'psychogenetics', 'response', 'social health determinants', 'structured data', 'suicidal behavior', 'therapy resistant', 'trait', 'treatment-resistant depression']",NIMH,MAYO CLINIC ROCHESTER,R01,2020,404741,0.02088322739390829
"2/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders PROJECT ABSTRACT Major depressive disorder (MDD), anxiety disorders, and substance use disorders (SUDs) are common, complex psychiatric traits that frequently co-occur and are associated with significant functional impairment, increased healthcare utilization and cost, and higher mortality risk. Not only are these three conditions highly prevalent in the general population and generate a huge societal burden, but recent studies by our team and others have shown that shared covariance from common genetic variation significantly contributes to these psychiatric comorbidities. Large data sets are needed to understand how the multifaceted interplay of genetics, including polygenic risk scores (PRSs), and social determinants of health, such as employment and educational attainment, can impact the risk of these psychiatric disorders and clinical outcomes, such as multiple psychiatric hospitalizations. PRSs have shown potential for risk prediction, but the clinical utility of PRSs for psychiatric conditions is just starting to be explored. Research utilizing Electronic Health Records (EHRs) offers the promise of large data sets to examine these relationships in cohorts of patients seen in clinical practice. However, the use of EHRs is in its infancy in the study of psychiatric disorders and their treatment. This study will address critical knowledge gaps in genotype-psychiatric phenotype relationships in large, demographically and geographically diverse population-based samples derived from EHR-linked biobanks across four medical centers - Columbia, Cornell, Mayo Clinic and Mount Sinai. Our objectives are to (1) develop improved methods for EHR phenotyping of MDD, anxiety, and SUDs, and related outcomes based on a data-set of >30 million EHRs, (2) evaluate associations between PRSs and these conditions, and (3) assess the association between PRSs and outcomes including treatment resistance in MDD and healthcare utilization in patients with MDD, anxiety and SUD. The PRS analyses will utilize data from biobanks with >50,000 persons with both EHR and GWAS data. Successful completion of this study will substantially advance our understanding of the clinical utility of PRSs for commonly occurring psychiatric disorders. PROJECT NARRATIVE Major depression, anxiety disorders and substance use disorder are highly prevalent in the general population and have a huge societal burden. Given the substantial heritability of these conditions and their polygenic architecture, there is increasing interest in using quantitative polygenic risk scores (PRSs) for risk stratification. This study will analyze ""big data"" from electronic health records linked to genetic data to evaluate the prediction of clinical outcomes using PRSs and social determinants of health.","2/4: Leveraging EHR-linked biobanks for deep phenotyping, polygenic risk score modeling, and outcomes analysis in psychiatric disorders",9876282,R01MH121924,"['Address', 'Anxiety', 'Anxiety Disorders', 'Architecture', 'Big Data', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Comorbidity', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Employment', 'Environmental Risk Factor', 'European', 'Evaluation', 'Feeling suicidal', 'Funding', 'General Population', 'Genetic', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Geography', 'Goals', 'Health Care Costs', 'Health system', 'Heritability', 'Hospitalization', 'Individual', 'Knowledge', 'Link', 'Machine Learning', 'Major Depressive Disorder', 'Medical', 'Medical center', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Natural Language Processing', 'New York City', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phenotype', 'Population', 'Population Heterogeneity', 'Research', 'Risk', 'Risk stratification', 'Role', 'Sampling', 'Scoring Method', 'Site', 'Structure', 'Substance Use Disorder', 'Suicide attempt', 'Symptoms', 'Text', 'Variant', 'base', 'biobank', 'care outcomes', 'clinical care', 'clinical practice', 'cohort', 'deep learning', 'disorder risk', 'functional disability', 'genetic epidemiology', 'genetic risk factor', 'genome wide association study', 'genome-wide', 'health care service utilization', 'improved', 'infancy', 'interest', 'learning strategy', 'mortality', 'mortality risk', 'neuropsychiatric disorder', 'pleiotropism', 'population based', 'predict clinical outcome', 'psychogenetics', 'response', 'social health determinants', 'suicidal behavior', 'therapy resistant', 'trait', 'treatment-resistant depression']",NIMH,MAYO CLINIC ROCHESTER,R01,2019,404655,0.02088322739390829
"Developing and validating EHR-integrated readmission risk prediction models for hospitalized patients with diabetes PROJECT SUMMARY/ABSTRACT Hospital readmission is an undesirable, costly outcome that may be preventable. Hospitalized patients with diabetes are at higher risk of readmission within 30 days (30-d readmission) than patients without diabetes, and >1 million readmissions occur among diabetes patients in the US annually. Certain interventions can reduce readmission risk, but applying these interventions widely is cost prohibitive. One approach for improving the efficiency of interventions that reduce readmission risk is to target high-risk patients. We previously published a model, the Diabetes Early Readmission Risk Indicator (DERRITM), that predicts the risk of all-cause 30-d readmission of patients with diabetes. The DERRI, however, has modest predictive accuracy (C-statistic 0.63- 0.69), and requires manual data input. Recently, we demonstrated that adding variables to the DERRI substantially improves predictive accuracy (DERRIplus, C-statistic 0.82). However, using this larger model to predict readmission risk based on manual input of data would be too labor intensive for clinical settings. Indeed, most readmission risk prediction models are limited by the trade-off between accuracy and ease of use; lack of translation to a tool that integrates with clinical workflow; modest accuracy; lack of validation; and dependence on data only available after hospital discharge.  The objectives of the current proposal are: 1) To develop more accurate all-cause unplanned 30-d readmission risk prediction models using electronic health record (EHR) data of patients with diabetes (eDERRI); 2) To translate the models to an automated, EHR-based tool that predicts % readmission risk of hospitalized patients; and 3) To prospectively validate the eDERRI models and tool. The new eDERRI models will expand upon the variables in the DERRIplus based on availability in EHR data (e.g., sociodemographics, encounter history, medication use, laboratory results, comorbidities, and length of stay). To develop the models, we will leverage data from the PaTH Clinical Data Research Network (CDRN), a multi-center, 40-plus hospital member of the National Patient-Centered Clinical Research Network (PCORnet). We will apply state-of-the-art deep-learning methods to develop optimal predictive models. This project will analyze a large, multi-center cohort of nearly 340,000 discharges with cutting-edge techniques to develop better models and translate them to an automated tool that predicts readmission risk for individual patients with diabetes. The proposed tool would identify higher risk patients more likely to benefit from intervention, thus improving care and reducing costs. PROJECT NARRATIVE This project seeks to develop more accurate models that predict the risk of repeat hospitalizations among patients with diabetes. The models will be programmed into a tool that will be integrated with an electronic health record system and automatically predict the re-hospitalization risk of patients. Such a tool could be used to identify higher risk diabetes patients more likely to benefit from intervention, thus improving care and reducing costs.",Developing and validating EHR-integrated readmission risk prediction models for hospitalized patients with diabetes,9971861,R01DK122073,"['Admission activity', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Paths', 'Clinical Research', 'Collection', 'Complement', 'Data', 'Data Set', 'Dependence', 'Diabetes Mellitus', 'Electronic Health Record', 'Goals', 'Hospitalization', 'Hospitals', 'Institution', 'Insulin', 'Intervention', 'Laboratories', 'Length of Stay', 'Machine Learning', 'Manuals', 'Modeling', 'Participant', 'Patient Readmission', 'Patients', 'Pharmaceutical Preparations', 'Publishing', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'System', 'Techniques', 'Testing', 'Translating', 'Translations', 'Validation', 'Work', 'base', 'clinical practice', 'cohort', 'comorbidity', 'comorbidity Index', 'cost', 'cost outcomes', 'deep learning', 'demographics', 'design', 'diabetes risk', 'experience', 'high risk', 'hospital readmission', 'improved', 'individual patient', 'learning strategy', 'member', 'model development', 'patient oriented', 'patient subsets', 'point of care', 'predictive modeling', 'predictive tools', 'prospective', 'readmission risk', 'risk prediction model', 'sociodemographics', 'statistics', 'tool']",NIDDK,TEMPLE UNIV OF THE COMMONWEALTH,R01,2020,658109,0.03448451373596408
"Characterizing and targeting subphenotypes of schizophrenia and bipolar disorder via individually imputed tissue and cell-type specific transcriptomes PROJECT SUMMARY  Schizophrenia (SCZ) and bipolar disorder (BD) are highly heritable, severe and complex brain disorders characterized by substantial clinical and biological heterogeneity. Despite this, case-control studies often ignore such heterogeneity through their focus on the average patient, which may be the core reason for a lack of robust biomarkers indicative of an individuals treatment response and outcome. Although they are classified as independent diagnostic entities, SCZ and BD are highly genetically correlated, exhibit high relative risks among relatives of both BD & SCZ patients, and have partially overlapping symptomatology and treatment. In this project we will use tissue and cell-type specific imputed transcriptomes for individuals with SCZ or BD in our VA discovery cohort comprising the Million Veteran Program (MVP) and Cooperative Studies Program 572 (CSP #572, The Genetics of Functional Disability in Schizophrenia and Bipolar Illness), as an intermediate molecular phenotype, to identify, characterize and target subphenotypes of these disorders. Findings from the VA discovery cohort will be validated in the PsycheMERGE and BioMe cohorts.  First, we will impute tissue and cell-type specific transcriptomes for all individuals with schizophrenia (SCZ) or bipolar disorder (BD) in the VA discovery cohort. To achieve this, we will train tissue (brain and peripheral tissues) and cell-type (glutamatergic & GABAergic neurons, astrocytes, oligodendrocytes, and microglia from DLPFC) specific EpiXcan transcriptomic imputation models at the gene and isoform level. Secondly, we will use the imputed transcriptomes as an intermediate molecular phenotype to identify genetically-regulated gene expression (GReX) based subpopulations and within them the key molecular drivers using deep neural networks (DNNs). Lastly, we will identify key non-genetic biomarkers and effective treatments for each validated subphenotype. Non-genetic biomarkers will be based on pre-mined features available from the electronic health records (EHR) and features extracted from the EHR via natural language processing (NLP). The subphenotypes will be validated in the civilian cohorts PsycheMERGE and BioMe.  This project will take place at the Icahn School of Medicine, one of the leading centers of data science, genomics and precision medicine. The mentoring committee comprises experts in the fields of computational and functional genomics, integrative analysis, machine learning (including DNNs and NLP), and EHR mining. Dr. Voloudakis will develop the skills necessary to launch an independent academic career in genetically based EHR-informed precision psychiatry. PROJECT NARRATIVE  Schizophrenia (SCZ) and bipolar disorder (BD) are genetically correlated, highly heritable, severe and complex brain disorders characterized by substantial clinical and biological heterogeneity with partially overlap- ping symptomatology and treatment. This project will use tissue and cell-type specific imputed transcriptomes for individuals with SCZ or BD to identify, characterize and target subphenotypes of those disorders. We will use the Million Veteran Program and Cooperative Studies Program 572 (The Genetics of Functional Disability in Schizophrenia and Bipolar Illness) as the discovery cohorts and will validate our findings in the PsycheMERGE and BioMe cohorts.",Characterizing and targeting subphenotypes of schizophrenia and bipolar disorder via individually imputed tissue and cell-type specific transcriptomes,10055546,K08MH122911,"['Astrocytes', 'Biological', 'Biological Markers', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Case-Control Studies', 'Classification', 'Complex', 'Data Science', 'Development', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Epigenetic Process', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Glutamates', 'Goals', 'Heritability', 'Heterogeneity', 'Individual', 'Intervention', 'Machine Learning', 'Mentors', 'Methods', 'Microglia', 'Mining', 'Modeling', 'Molecular', 'Natural Language Processing', 'Neurons', 'Neurosciences', 'Oligodendroglia', 'Outcome', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacology', 'Phenotype', 'Population Genetics', 'Positioning Attribute', 'Precision therapeutics', 'Prefrontal Cortex', 'Productivity', 'Protein Isoforms', 'Psychiatry', 'Relative Risks', 'Research', 'Risk', 'Sample Size', 'Schizophrenia', 'Selection for Treatments', 'Severity of illness', 'Symptoms', 'Tissues', 'Training', 'Treatment outcome', 'Variant', 'Veterans', 'base', 'biological heterogeneity', 'career', 'cell type', 'clinical heterogeneity', 'cohort', 'comorbidity', 'computational basis', 'cooperative study', 'deep learning', 'deep neural network', 'effective therapy', 'experience', 'functional disability', 'functional genomics', 'improved', 'medical schools', 'molecular phenotype', 'neuropsychiatric disorder', 'next generation', 'non-genetic', 'novel', 'novel therapeutic intervention', 'patient subsets', 'polygenic risk score', 'precision medicine', 'programs', 'psychopharmacologic', 'skills', 'symptomatology', 'trait', 'transcriptome', 'transcriptomics', 'treatment response']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,K08,2020,191944,0.0014295109610585187
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes ?DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9655950,K01HL124045,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Genomics', 'Goals', 'Government Agencies', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare Systems', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Population Study', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Risk stratification', 'Safety', 'Science', 'Site', 'Specialist', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision support', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'epidemiology study', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'informatics\xa0tool', 'investigator training', 'mortality', 'mortality risk', 'multidisciplinary', 'novel', 'patient oriented', 'patient oriented research', 'point of care', 'portability', 'predictive modeling', 'professor', 'prognostic', 'prognostic tool', 'public health relevance', 'repository', 'research and development', 'risk prediction model', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2019,170856,0.07492179331699306
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes     DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9210555,K01HL124045,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Government Agencies', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Population Study', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Risk stratification', 'Safety', 'Science', 'Site', 'Specialist', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'epidemiology study', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'point of care', 'portability', 'predictive modeling', 'professor', 'prognostic', 'prognostic tool', 'public health relevance', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2017,170856,0.07492179331699306
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes     DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9031137,K01HL124045,"['Address', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronics', 'Epidemiologic Studies', 'Epidemiology', 'Genomics', 'Goals', 'Government', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Mining', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Safety', 'Science', 'Site', 'Specialist', 'Stratification', 'Stroke', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'physical symptom', 'point of care', 'population based', 'predictive modeling', 'professor', 'prognostic', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2016,170856,0.07492179331699306
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes     DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases.         PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.            ",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,8891601,K01HL124045,"['Address', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronics', 'Epidemiologic Studies', 'Epidemiology', 'Genomics', 'Goals', 'Government', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Mining', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Safety', 'Science', 'Site', 'Specialist', 'Stratification', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'experience', 'health information technology', 'high risk', 'improved', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'point of care', 'population based', 'predictive modeling', 'professor', 'prognostic', 'public health relevance', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2015,136485,0.07492179331699306
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes     DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9443655,K01HL124045,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Genomics', 'Goals', 'Government Agencies', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Population Study', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Risk stratification', 'Safety', 'Science', 'Site', 'Specialist', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision support', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'epidemiology study', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'patient oriented research', 'point of care', 'portability', 'predictive modeling', 'professor', 'prognostic', 'prognostic tool', 'public health relevance', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2018,170856,0.07492179331699306
"Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data Project Summary:  Coronavirus disease 19 (COVID-19) has created a major public health crisis around the world. The novel coronavirus was observed to have a long incubation period and extremely infectious during this period. No proven effective treatment or vaccine is available. Massive public interventions have been implemented in many countries and states in the United States (US) at different phases of the outbreak with varying combinations of social dis- tancing, mobility restriction and population behavioral change. Decisions on how to implement these interventions (e.g., when to impose and relax mitigation measures) rely on important statistics of COVID epidemiology (e.g., effective reproduction number) that characterize and predict the course of COVID-19 outbreak. However, there is a lack of robust and parsimonious model of COVID epidemic that can accurately reect the heterogeneity between susceptible populations and regions (e.g., demographics, healthcare capacity, social and economic determinants). There is no rigorous study to guide precision public health interventions that are tailored to a population or region depending on their characteristics. Furthermore, due to the non-randomized nature of public health interventions, it is critical to account for biases and confounding when comparing mitigation measures of COVID-19 across re- gions. To address these challenges, this project develops robust and generalizable analytic methods to evaluate public health interventions and assess individual patient risks of COVID-19 infection and complications. In Aim 1, we will develop dynamic and robust statistical models to predict the disease epidemic. The models will estimate the date of the rst unknown infection case, instantaneous effective reproduction number, and account for the incu- bation period of COVID-19 virus. Furthermore, heterogeneity in population's demographics, social and economic indicators, healthcare capacity and geographic locations will be incorporated to reect their impacts on COVID epidemic. Under a longitudinal quasi-experimental design, we will provide valid inference for comparing public health interventions implemented at different regions while accounting for confounding bias. Multiple sources of data from different states in the US will be analyzed to empirically test which states' response strategies are more effective and in which subpopulation. In Aim 2, we will focus on developing precise risk assessment tool of individ- ual COVID-19 patients using electronic health records (EHRs) collected at New York Presbyterian hospital in New York City, an epicenter of COVID-19. We will engineer features of patient's pre-conditions associated with severe COVID complications, recovery, or death. More importantly, we will engineer features that represent proxies of virus exposures from patients' geographic information. We will use machine learning techniques to create quantitative summaries of patient prognosis (e.g., transitioning to serious clinical stages, discharge, death). We will use inter- nal cross-validation and external calibration to validate developed algorithms. The project will generate evidence to guide precision public health intervention, optimal patient care, and efcient healthcare resource allocation in anticipation of a second wave of COVID epidemic and in preparation of other infectious disease outbreaks. Project Narrative:  This project aims to develop robust and generalizable analytics to evaluate public health interventions in response to coronavirus disease 19 (COVID-19) pandemic and to assess individual patient risks using multiple sources of data (e.g., ofcial reports of COVID cases, electronic health records). The project will provide quantita- tive evidence to guide precision public health interventions at the right time for the right subpopulation to effectively contain and mitigate the outbreak. It will also provide quantitative risk assessments of COVID-19 patients to facili- tate best clinical management and optimal allocation of heathcare resources.",Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data,10161345,R01GM124104,"['Accounting', 'Address', 'Algorithms', 'Assessment tool', 'Behavioral', 'Biological Markers', 'COVID-19', 'COVID-19 pandemic', 'Calibration', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Characteristics', 'Chiroptera', 'Clinical', 'Clinical Management', 'Clinical Trials', 'Communicable Diseases', 'Country', 'Critical Illness', 'Data', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Early identification', 'Electronic Health Record', 'Engineering', 'Epidemic', 'Epidemiology', 'Evaluation', 'Experimental Designs', 'Exposure to', 'Future', 'Gaussian model', 'Geographic Locations', 'Geography', 'Health', 'Healthcare', 'Heterogeneity', 'Hospitals', 'Individual', 'Infection', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'National Institute of General Medical Sciences', 'Nature', 'New York', 'New York City', 'Parents', 'Patient Care', 'Patient Care Management', 'Patient risk', 'Patients', 'Pattern', 'Phase', 'Policies', 'Population', 'Population Heterogeneity', 'Preparation', 'Presbyterian Church', 'Process', 'Proxy', 'Public Health', 'Quasi-experiment', 'Recovery', 'Reporting', 'Reproduction', 'Resource Allocation', 'Resources', 'Risk', 'Risk Assessment', 'Severities', 'Social Distance', 'Source', 'Statistical Models', 'Subgroup', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Triage', 'United States', 'Vaccines', 'Validation', 'Virus', 'Virus Diseases', 'Work', 'algorithm development', 'analytical method', 'big biomedical data', 'coronavirus disease', 'demographics', 'design', 'disease transmission', 'disorder risk', 'economic determinant', 'economic indicator', 'effective therapy', 'epidemiological model', 'high risk population', 'individual patient', 'innovation', 'intervention effect', 'learning strategy', 'machine learning algorithm', 'model building', 'mortality', 'multiple data sources', 'novel coronavirus', 'outcome forecast', 'pandemic disease', 'personalized medicine', 'predictive modeling', 'public health intervention', 'recruit', 'response', 'social', 'social determinants', 'statistical learning', 'statistics', 'tool', 'transmission process', 'vector', 'web site']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,331147,-0.01673583484411783
"Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data Project Summary/Abstract  Current medical treatment guidelines largely rely on data from randomized controlled trials that study  average effects, which may be inadequate for making individualized decisions for real-world patients. Large-scale electronic health records (EHRs) data provide unprecedented opportunities to optimize personalized treatment strategies and generate evidence relevant to real-world patients. However, there are inherent challenges in the use of EHRs, including non-experimental nature of data collection processes, heterogeneous data types with complex dependencies, irregular measurement patterns, multiple dynamic treatment sequences, and the need to balance risk and benefit of treatments. Using two high-quality EHR databases, Columbia University Medical Center's clinical data warehouse and the Indiana Network for Patient Care database, and focusing on type 2 diabetes (T2D), this proposal will develop novel and scalable statistical learning approaches that overcome these challenges to discover optimal personalized treatment strategies for T2D from real-world patients. Specifically, under Aim 1, we will develop a unified framework to learn latent temporal processes for feature extraction and dynamic patient records representation. Our approach will accommodate large-scale variables of mixed types (continuous, binary, counts) measured at irregular intervals. They extract lower-dimensional components to reflect patients' dynamic health status, account for informative healthcare documentation processes, and characterize similarities between patients. Under Aim 2, we will develop fast and efficient multi-category machine learning methods, in order to evaluate treatment propensities and adaptively learn optimal dynamic treatment regimens (DTRs) among the extensive number of treatment options observed in the EHRs. The methods will provide  sequential decisions that determine the best treatment sequence for a T2D patient given his/her EHRs. Under Aim 3, we will develop statistical learning methods to assist multi-faceted treatment decision-making, which balances risks versus benefits when evaluating a DTR. Our approach will ensure maximizing benefit to the greatest extent while controlling all risk outcomes under the safety margins. For all aims, we will develop efficient stochastic resampling algorithms to scale up the optimization for massive data sizes. We will identify optimal DTRs for T2D using the extracted information from patients' comorbidity conditions, medications, and laboratory tests, as well as records-collection processes. Our methodologies will be applied and cross-validated between the two EHR databases. The treatment strategies learned from the representative EHR databases with a diverse patient  population will be beneficial for individual patient care, assisting clinicians to adaptively choose the optimal treatment for a patient. Finally, we will disseminate our methods and results through freely available software and outreach to the informatics and clinical experts at our Centers for Translational Science and elsewhere. Project Narrative  This proposal aims to develop novel and scalable statistical learning methods to analyze electronic health records (EHRs) and use two real-world, high-quality EHR databases for personalized medicine research. The methods will handle the non-experimental nature of data collection processes, along with heterogeneous data types, dynamic treatment sequences, and the trade-off between benefit and risk outcomes. The results will complement the current knowledge base for individual patient care using evidence generated from patients in real-world clinical practices.",Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data,9891071,R01GM124104,"['Academic Medical Centers', 'Address', 'Adverse event', 'Algorithms', 'Benefits and Risks', 'Categories', 'Center for Translational Science Activities', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Dependence', 'Dimensions', 'Documentation', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Exclusion Criteria', 'Formulation', 'Gaussian model', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Indiana', 'Informatics', 'International', 'Knowledge', 'Laboratories', 'Learning', 'Length', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Process', 'Quality Control', 'Randomized Controlled Trials', 'Records', 'Research', 'Risk', 'Safety', 'Sampling', 'Structure', 'Testing', 'Time', 'Treatment Protocols', 'adaptive learning', 'adverse event risk', 'algorithmic methodologies', 'analytical tool', 'base', 'big biomedical data', 'clinical data warehouse', 'clinical decision-making', 'clinical encounter', 'clinical practice', 'comorbidity', 'complex data ', 'data modeling', 'data space', 'design', 'evidence base', 'feature extraction', 'heterogenous data', 'individual patient', 'individualized medicine', 'knowledge base', 'learning strategy', 'machine learning method', 'novel', 'optimal treatments', 'outreach', 'patient population', 'personalized decision', 'personalized medicine', 'population based', 'scale up', 'statistical learning', 'temporal measurement', 'theories', 'treatment effect', 'treatment guidelines', 'treatment response', 'treatment strategy']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,328853,0.06488991416383584
"Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data Project Summary/Abstract  Current medical treatment guidelines largely rely on data from randomized controlled trials that study  average effects, which may be inadequate for making individualized decisions for real-world patients. Large-scale electronic health records (EHRs) data provide unprecedented opportunities to optimize personalized treatment strategies and generate evidence relevant to real-world patients. However, there are inherent challenges in the use of EHRs, including non-experimental nature of data collection processes, heterogeneous data types with complex dependencies, irregular measurement patterns, multiple dynamic treatment sequences, and the need to balance risk and benefit of treatments. Using two high-quality EHR databases, Columbia University Medical Center's clinical data warehouse and the Indiana Network for Patient Care database, and focusing on type 2 diabetes (T2D), this proposal will develop novel and scalable statistical learning approaches that overcome these challenges to discover optimal personalized treatment strategies for T2D from real-world patients. Specifically, under Aim 1, we will develop a unified framework to learn latent temporal processes for feature extraction and dynamic patient records representation. Our approach will accommodate large-scale variables of mixed types (continuous, binary, counts) measured at irregular intervals. They extract lower-dimensional components to reflect patients' dynamic health status, account for informative healthcare documentation processes, and characterize similarities between patients. Under Aim 2, we will develop fast and efficient multi-category machine learning methods, in order to evaluate treatment propensities and adaptively learn optimal dynamic treatment regimens (DTRs) among the extensive number of treatment options observed in the EHRs. The methods will provide  sequential decisions that determine the best treatment sequence for a T2D patient given his/her EHRs. Under Aim 3, we will develop statistical learning methods to assist multi-faceted treatment decision-making, which balances risks versus benefits when evaluating a DTR. Our approach will ensure maximizing benefit to the greatest extent while controlling all risk outcomes under the safety margins. For all aims, we will develop efficient stochastic resampling algorithms to scale up the optimization for massive data sizes. We will identify optimal DTRs for T2D using the extracted information from patients' comorbidity conditions, medications, and laboratory tests, as well as records-collection processes. Our methodologies will be applied and cross-validated between the two EHR databases. The treatment strategies learned from the representative EHR databases with a diverse patient  population will be beneficial for individual patient care, assisting clinicians to adaptively choose the optimal treatment for a patient. Finally, we will disseminate our methods and results through freely available software and outreach to the informatics and clinical experts at our Centers for Translational Science and elsewhere. Project Narrative  This proposal aims to develop novel and scalable statistical learning methods to analyze electronic health records (EHRs) and use two real-world, high-quality EHR databases for personalized medicine research. The methods will handle the non-experimental nature of data collection processes, along with heterogeneous data types, dynamic treatment sequences, and the trade-off between benefit and risk outcomes. The results will complement the current knowledge base for individual patient care using evidence generated from patients in real-world clinical practices.",Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data,9659349,R01GM124104,"['Academic Medical Centers', 'Address', 'Adverse event', 'Algorithms', 'Benefits and Risks', 'Categories', 'Center for Translational Science Activities', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Comorbidity', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Dependence', 'Dimensions', 'Documentation', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Exclusion Criteria', 'Formulation', 'Gaussian model', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Indiana', 'Informatics', 'International', 'Knowledge', 'Laboratories', 'Learning', 'Length', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Process', 'Quality Control', 'Randomized Controlled Trials', 'Records', 'Research', 'Risk', 'Safety', 'Sampling', 'Structure', 'Testing', 'Time', 'Treatment Protocols', 'adaptive learning', 'adverse event risk', 'algorithmic methodologies', 'analytical tool', 'base', 'big biomedical data', 'clinical data warehouse', 'clinical decision-making', 'clinical practice', 'data modeling', 'data space', 'design', 'evidence base', 'individual patient', 'individualized medicine', 'knowledge base', 'learning strategy', 'novel', 'optimal treatments', 'outreach', 'patient population', 'personalized decision', 'personalized medicine', 'population based', 'scale up', 'temporal measurement', 'theories', 'treatment effect', 'treatment guidelines', 'treatment response', 'treatment strategy']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,329020,0.06488991416383584
"Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data Project Summary/Abstract  Current medical treatment guidelines largely rely on data from randomized controlled trials that study av- erage effects, which may be inadequate for making individualized decisions for real-world patients. Large-scale electronic health records (EHRs) data provide unprecedented opportunities to optimize personalized treatment strategies and generate evidence relevant to real-world patients. However, there are inherent challenges in the use of EHRs, including non-experimental nature of data collection processes, heterogeneous data types with complex dependencies, irregular measurement patterns, multiple dynamic treatment sequences, and the need to balance risk and benet of treatments. Using two high-quality EHR databases, Columbia University Medical Center's clinical data warehouse and the Indiana Network for Patient Care database, and focusing on type 2 diabetes (T2D), this proposal will develop novel and scalable statistical learning approaches that overcome these challenges to discover optimal personalized treatment strategies for T2D from real-world patients. Specically, under Aim 1, we will develop a unied framework to learn latent temporal processes for feature extraction and dynamic patient records representation. Our approach will accommodate large-scale variables of mixed types (continuous, binary, counts) measured at irregular intervals. They extract lower-dimensional components to reect patients' dynamic health status, account for informative healthcare documentation processes, and characterize similarities between patients. Under Aim 2, we will develop fast and efcient multi-category machine learning methods, in order to evaluate treatment propensities and adaptively learn optimal dynamic treatment regimens (DTRs) among the extensive number of treatment options observed in the EHRs. The methods will provide se- quential decisions that determine the best treatment sequence for a T2D patient given his/her EHRs. Under Aim 3, we will develop statistical learning methods to assist multi-faceted treatment decision-making, which balances risks versus benets when evaluating a DTR. Our approach will ensure maximizing benet to the greatest extent while controlling all risk outcomes under the safety margins. For all aims, we will develop efcient stochastic resampling algorithms to scale up the optimization for massive data sizes. We will identify optimal DTRs for T2D using the extracted information from patients' comorbidity conditions, medications, and laboratory tests, as well as records-collection processes. Our methodologies will be applied and cross-validated between the two EHR databases. The treatment strategies learned from the representative EHR databases with a diverse patient pop- ulation will be benecial for individual patient care, assisting clinicians to adaptively choose the optimal treatment for a patient. Finally, we will disseminate our methods and results through freely available software and outreach to the informatics and clinical experts at our Centers for Translational Science and elsewhere. Project Narrative  This proposal aims to develop novel and scalable statistical learning methods to analyze electronic health records (EHRs) and use two real-world, high-quality EHR databases for personalized medicine research. The methods will handle the non-experimental nature of data collection processes, along with heterogeneous data types, dynamic treatment sequences, and the trade-off between benefit and risk outcomes. The results will complement the current knowledge base for individual patient care using evidence generated from patients in real-world clinical practices.",Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data,9519452,R01GM124104,"['Academic Medical Centers', 'Address', 'Adverse event', 'Algorithms', 'Benefits and Risks', 'Categories', 'Center for Translational Science Activities', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Comorbidity', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Dependence', 'Dimensions', 'Documentation', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Exclusion Criteria', 'Formulation', 'Gaussian model', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Indiana', 'Informatics', 'International', 'Knowledge', 'Laboratories', 'Learning', 'Length', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Process', 'Quality Control', 'Randomized Controlled Trials', 'Records', 'Research', 'Risk', 'Safety', 'Sampling', 'Structure', 'Testing', 'Time', 'Treatment Protocols', 'adaptive learning', 'algorithmic methodologies', 'analytical tool', 'base', 'clinical data warehouse', 'clinical decision-making', 'clinical practice', 'data modeling', 'data space', 'design', 'evidence base', 'individual patient', 'individualized medicine', 'knowledge base', 'learning strategy', 'novel', 'optimal treatments', 'outreach', 'patient population', 'personalized decision', 'personalized medicine', 'population based', 'scale up', 'temporal measurement', 'theories', 'treatment guidelines', 'treatment response', 'treatment strategy']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,352653,0.06594696789718808
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9628032,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Guidelines', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intelligence', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Reaction', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'pharmacovigilance', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'supervised learning', 'tool']",NHLBI,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,809552,0.1012736838305931
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9698030,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,874586,0.1012736838305931
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9190384,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'cost', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2017,1177432,0.1012736838305931
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,8976618,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2016,832278,0.1012736838305931
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9275795,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2016,305257,0.1012736838305931
"EHR Anticoagulants Pharmacovigilance     DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page         PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.            ",EHR Anticoagulants Pharmacovigilance,8791564,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2015,864744,0.1012736838305931
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9418526,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2018,16608,0.1012736838305931
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9854882,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Information Retrieval', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction model', 'structured data', 'unstructured data', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2020,766226,0.04425531257226237
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9937918,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction model', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,97055,0.04425531257226237
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9637319,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction model', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,619389,0.04425531257226237
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9419767,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Severe Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,619389,0.04425531257226237
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9290660,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Severe Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,644888,0.04425531257226237
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9881338,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'adverse drug reaction', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic locus', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'phenotyping algorithm', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,395483,0.010582634969727753
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9650406,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'adverse drug reaction', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,410983,0.010582634969727753
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort - Diversity Supplement Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort - Diversity Supplement,9693037,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Reaction', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,49920,0.010582634969727753
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9441852,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Reaction', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,399573,0.010582634969727753
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9309793,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Reaction', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,406123,0.010582634969727753
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9838247,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Source', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'patient health information', 'population based', 'prevent', 'sociodemographics', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,768763,0.016454276927564574
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9615037,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Source', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'population based', 'prevent', 'sociodemographics', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2019,784820,0.016454276927564574
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9215012,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Data Sources', 'Development', 'Diagnostic', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'outcome forecast', 'population based', 'prevent', 'socioeconomics', 'surveillance data', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2017,836858,0.016454276927564574
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9395941,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Data Sources', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'population based', 'prevent', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2018,803425,0.016454276927564574
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9938607,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic Diseases', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hereditary Disease', 'Individual', 'Infrastructure', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Lipoprotein (a)', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'care providers', 'case-based', 'clinical decision support', 'clinical implementation', 'epidemiology study', 'evaluation/testing', 'family burden', 'genetic testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'phenotyping algorithm', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'screening', 'screening program', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2020,638566,0.026732987021053044
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9730585,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic Diseases', 'Genetic screening method', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heritability', 'Individual', 'Infrastructure', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Lipoprotein (a)', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'care providers', 'case-based', 'clinical decision support', 'clinical implementation', 'epidemiology study', 'evaluation/testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'screening', 'screening program', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2019,675136,0.026732987021053044
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9389934,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Caring', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'Computerized Medical Record', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic screening method', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hereditary Disease', 'Heritability', 'Individual', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Preclinical Drug Evaluation', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'case-based', 'epidemiology study', 'evaluation/testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'programs', 'screening', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2017,520081,0.026732987021053044
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9490424,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic Diseases', 'Genetic screening method', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heritability', 'Individual', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Lipoprotein (a)', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'care providers', 'case-based', 'clinical decision support', 'clinical implementation', 'epidemiology study', 'evaluation/testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'screening', 'screening program', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2018,653490,0.026732987021053044
"Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease PROJECT SUMMARY / ABSTRACT Cardiovascular disease (CVD) is the single largest killer in the United States for both men and women in every racial/ethnic group. Thus, accurate and systematic evaluation of CVD risk represents an aspect of Precision Medicine that will touch every patient. CVD risk scores that are currently the standard of care are derived from research cohorts and are particularly inaccurate in women, older patients, and those with missing data. The goal of this Precision Medicine based application is to capitalize on the depth and breadth of clinical data within electronic health record (EHR) systems to revolutionize CVD risk prediction, thereby optimizing personalized care for every patient. Our proposed approach is innovative in that we have identified and addressed the most significant barriers to development of an EHR-based risk score. Novel aspects of this research include: 1) use of complete EHR data to develop and validate algorithms to define a variety of risk factors (e.g., reproductive history), thus building a comprehensive risk profile for each patient that incorporates diagnosis and procedure codes, laboratory values, clinical test results, patient provided information (e.g., alcohol use), and natural language processing of unstructured clinical text; 2) incorporation of age at onset of risk factors; 3) use of highly flexible machine learning techniques in the form of generalized boosted regression modeling; 4) exploration of a new deep learning model for censored EHR data; and 5) determination of the extent of risk reclassification in multiple geographically-defined populations, including an underserved minority population. Furthermore, genetic studies demonstrate that incorporating variants into current risk models improves risk prediction and use of an individual's genetic risk could further enhance our ability to deliver precision medicine to every patient. Therefore, we seek to develop a sex-specific next-generation CVD risk prediction score using EHR data in combination with genetic variants. This paradigm is a significant departure from the current one that relies on scores derived from relatively small research cohorts that use only a restricted set of clinical parameters that differentially misclassify an individual's risk, especially in women. Our access to empirical clinical EHR data for hundreds of thousands of patients uniquely positions us to 1) develop a sex-specific risk prediction model for incident CVD using data from the EHR; 2) assess the performance of the sex-specific EHR risk score in an independent non-urban and rural population; and 3) identify and characterize patients for whom genetic information improves CVD prediction beyond the clinical risk score. Successful completion of these aims has the potential to impact all adult patients, drive clinical practice changes to systematically collect sex-specific risk factors, and inform attempts to embed the next-generation CVD risk score into EHR systems for automated use in clinical care. PROJECT NARRATIVE Cardiovascular disease (CVD) is the single largest killer in the United States. We propose to use electronic health record data to improve our ability to accurately classify risk and identify those who would benefit from preventive therapies. Improved risk prediction will shed light on the mechanisms of CVD and potentially reduce incidence, save lives, and lower health care costs.",Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease,9838270,R01HL136659,"['Address', 'Adult', 'Age', 'Alcohol consumption', 'Algorithms', 'Cardiovascular Diseases', 'Clinical', 'Clinical Data', 'Clinics and Hospitals', 'Code', 'Communities', 'Community Hospitals', 'County', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Ethnic group', 'Evaluation', 'Event', 'Genetic Risk', 'Genetic study', 'Geography', 'Goals', 'Health', 'Health Care Costs', 'Hybrids', 'Incidence', 'Individual', 'Laboratories', 'Latino', 'Light', 'Machine Learning', 'Minnesota', 'Modeling', 'Natural Language Processing', 'Not Hispanic or Latino', 'Patients', 'Performance', 'Population', 'Positioning Attribute', 'Prevention strategy', 'Preventive', 'Preventive therapy', 'Procedures', 'Reproducibility', 'Reproductive History', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Rural', 'Rural Population', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Touch sensation', 'United States', 'Variant', 'Wisconsin', 'Woman', 'base', 'biobank', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'clinical care', 'clinical practice', 'clinical risk', 'cohort', 'deep learning', 'electronic data', 'feature extraction', 'flexibility', 'genetic information', 'genetic panel test', 'genetic variant', 'improved', 'innovation', 'men', 'multiple data types', 'next generation', 'novel', 'older patient', 'personalized care', 'phenotyping algorithm', 'precision genetics', 'precision medicine', 'prospective', 'racial and ethnic', 'research clinical testing', 'risk prediction model', 'sex', 'standard of care', 'time use', 'underserved minority']",NHLBI,MAYO CLINIC ROCHESTER,R01,2020,794994,0.046652450760847966
"Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease PROJECT SUMMARY / ABSTRACT Cardiovascular disease (CVD) is the single largest killer in the United States for both men and women in every racial/ethnic group. Thus, accurate and systematic evaluation of CVD risk represents an aspect of Precision Medicine that will touch every patient. CVD risk scores that are currently the standard of care are derived from research cohorts and are particularly inaccurate in women, older patients, and those with missing data. The goal of this Precision Medicine based application is to capitalize on the depth and breadth of clinical data within electronic health record (EHR) systems to revolutionize CVD risk prediction, thereby optimizing personalized care for every patient. Our proposed approach is innovative in that we have identified and addressed the most significant barriers to development of an EHR-based risk score. Novel aspects of this research include: 1) use of complete EHR data to develop and validate algorithms to define a variety of risk factors (e.g., reproductive history), thus building a comprehensive risk profile for each patient that incorporates diagnosis and procedure codes, laboratory values, clinical test results, patient provided information (e.g., alcohol use), and natural language processing of unstructured clinical text; 2) incorporation of age at onset of risk factors; 3) use of highly flexible machine learning techniques in the form of generalized boosted regression modeling; 4) exploration of a new deep learning model for censored EHR data; and 5) determination of the extent of risk reclassification in multiple geographically-defined populations, including an underserved minority population. Furthermore, genetic studies demonstrate that incorporating variants into current risk models improves risk prediction and use of an individual's genetic risk could further enhance our ability to deliver precision medicine to every patient. Therefore, we seek to develop a sex-specific next-generation CVD risk prediction score using EHR data in combination with genetic variants. This paradigm is a significant departure from the current one that relies on scores derived from relatively small research cohorts that use only a restricted set of clinical parameters that differentially misclassify an individual's risk, especially in women. Our access to empirical clinical EHR data for hundreds of thousands of patients uniquely positions us to 1) develop a sex-specific risk prediction model for incident CVD using data from the EHR; 2) assess the performance of the sex-specific EHR risk score in an independent non-urban and rural population; and 3) identify and characterize patients for whom genetic information improves CVD prediction beyond the clinical risk score. Successful completion of these aims has the potential to impact all adult patients, drive clinical practice changes to systematically collect sex-specific risk factors, and inform attempts to embed the next-generation CVD risk score into EHR systems for automated use in clinical care. PROJECT NARRATIVE Cardiovascular disease (CVD) is the single largest killer in the United States. We propose to use electronic health record data to improve our ability to accurately classify risk and identify those who would benefit from preventive therapies. Improved risk prediction will shed light on the mechanisms of CVD and potentially reduce incidence, save lives, and lower health care costs.",Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease,9610723,R01HL136659,"['Address', 'Adult', 'Age', 'Alcohol consumption', 'Algorithms', 'Cardiovascular Diseases', 'Clinical', 'Clinical Data', 'Clinics and Hospitals', 'Code', 'Communities', 'Community Hospitals', 'County', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Ethnic group', 'Evaluation', 'Event', 'Genetic Risk', 'Genetic study', 'Geography', 'Goals', 'Health', 'Health Care Costs', 'Hybrids', 'Incidence', 'Individual', 'Laboratories', 'Latino', 'Light', 'Machine Learning', 'Minnesota', 'Modeling', 'Natural Language Processing', 'Not Hispanic or Latino', 'Patients', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevention strategy', 'Preventive', 'Preventive therapy', 'Procedures', 'Reproducibility', 'Reproductive History', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Rural', 'Rural Population', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Touch sensation', 'United States', 'Variant', 'Wisconsin', 'Woman', 'base', 'biobank', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'clinical care', 'clinical practice', 'clinical risk', 'cohort', 'deep learning', 'electronic data', 'flexibility', 'genetic information', 'genetic panel test', 'genetic variant', 'improved', 'innovation', 'men', 'next generation', 'novel', 'older patient', 'personalized care', 'precision genetics', 'precision medicine', 'prospective', 'racial and ethnic', 'research clinical testing', 'risk prediction model', 'sex', 'standard of care', 'time use', 'underserved minority']",NHLBI,MAYO CLINIC ROCHESTER,R01,2019,794994,0.046652450760847966
"Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease PROJECT SUMMARY / ABSTRACT Cardiovascular disease (CVD) is the single largest killer in the United States for both men and women in every racial/ethnic group. Thus, accurate and systematic evaluation of CVD risk represents an aspect of Precision Medicine that will touch every patient. CVD risk scores that are currently the standard of care are derived from research cohorts and are particularly inaccurate in women, older patients, and those with missing data. The goal of this Precision Medicine based application is to capitalize on the depth and breadth of clinical data within electronic health record (EHR) systems to revolutionize CVD risk prediction, thereby optimizing personalized care for every patient. Our proposed approach is innovative in that we have identified and addressed the most significant barriers to development of an EHR-based risk score. Novel aspects of this research include: 1) use of complete EHR data to develop and validate algorithms to define a variety of risk factors (e.g., reproductive history), thus building a comprehensive risk profile for each patient that incorporates diagnosis and procedure codes, laboratory values, clinical test results, patient provided information (e.g., alcohol use), and natural language processing of unstructured clinical text; 2) incorporation of age at onset of risk factors; 3) use of highly flexible machine learning techniques in the form of generalized boosted regression modeling; 4) exploration of a new deep learning model for censored EHR data; and 5) determination of the extent of risk reclassification in multiple geographically-defined populations, including an underserved minority population. Furthermore, genetic studies demonstrate that incorporating variants into current risk models improves risk prediction and use of an individual's genetic risk could further enhance our ability to deliver precision medicine to every patient. Therefore, we seek to develop a sex-specific next-generation CVD risk prediction score using EHR data in combination with genetic variants. This paradigm is a significant departure from the current one that relies on scores derived from relatively small research cohorts that use only a restricted set of clinical parameters that differentially misclassify an individual's risk, especially in women. Our access to empirical clinical EHR data for hundreds of thousands of patients uniquely positions us to 1) develop a sex-specific risk prediction model for incident CVD using data from the EHR; 2) assess the performance of the sex-specific EHR risk score in an independent non-urban and rural population; and 3) identify and characterize patients for whom genetic information improves CVD prediction beyond the clinical risk score. Successful completion of these aims has the potential to impact all adult patients, drive clinical practice changes to systematically collect sex-specific risk factors, and inform attempts to embed the next-generation CVD risk score into EHR systems for automated use in clinical care. PROJECT NARRATIVE Cardiovascular disease (CVD) is the single largest killer in the United States. We propose to use electronic health record data to improve our ability to accurately classify risk and identify those who would benefit from preventive therapies. Improved risk prediction will shed light on the mechanisms of CVD and potentially reduce incidence, save lives, and lower health care costs.",Harnessing the Electronic Health Record to Predict Risk of Cardiovascular Disease,9442890,R01HL136659,"['Address', 'Adult', 'Age', 'Alcohol consumption', 'Algorithms', 'Cardiovascular Diseases', 'Clinical', 'Clinical Data', 'Clinics and Hospitals', 'Code', 'Communities', 'Community Hospitals', 'County', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Ethnic group', 'Evaluation', 'Event', 'Genetic Risk', 'Genetic study', 'Geography', 'Goals', 'Health', 'Health Care Costs', 'Hybrids', 'Incidence', 'Individual', 'Laboratories', 'Latino', 'Light', 'Machine Learning', 'Minnesota', 'Modeling', 'Natural Language Processing', 'Not Hispanic or Latino', 'Patients', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevention strategy', 'Preventive', 'Preventive therapy', 'Procedures', 'Reproducibility', 'Reproductive History', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Rural', 'Rural Population', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Touch sensation', 'United States', 'Variant', 'Wisconsin', 'Woman', 'base', 'biobank', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'clinical care', 'clinical practice', 'clinical risk', 'cohort', 'deep learning', 'electronic data', 'flexibility', 'genetic information', 'genetic panel test', 'genetic variant', 'improved', 'innovation', 'men', 'next generation', 'novel', 'older patient', 'personalized care', 'precision genetics', 'precision medicine', 'predictive modeling', 'prospective', 'racial and ethnic', 'research clinical testing', 'sex', 'standard of care', 'time use', 'underserved minority']",NHLBI,MAYO CLINIC ROCHESTER,R01,2018,794994,0.046652450760847966
"Data-Driven Identification of the Acute Respiratory Distress Syndrome PROJECT SUMMARY/ABSTRACT This K01 proposal will complete Michael Sjoding, MD, MSc's training towards his long-term career goal of improving care of patients with acute respiratory disease. Dr. Sjoding is a Pulmonary and Critical Physician at the University of Michigan with master's level training in clinical study design and biostatistics. This proposal builds on Dr. Sjoding's prior expertise, providing protected time for additional training in data science, the technical methods for deriving new knowledge about human disease from Big Biomedical Data in the rich training environment at the University of Michigan. The project's research goal is to develop real-time systems to improve accuracy and timeliness of Acute Respiratory Distress Syndrome (ARDS) diagnosis using electronic health record data. ARDS is a critical illness syndrome affecting 200,000 people each year with high mortality. Under-recognition of this syndrome is the key barrier to providing evidence-based care to patients with ARDS. The research will be completed under the guidance of primary mentor Theodore J. Iwashyna, MD, PhD and co-mentors Timothy P. Hofer, MD, MSc, and Kayvan Najarian, PhD, and a scientific advisory board with additional expertise in data science and applied clinical informatics. The 5-year plan includes didactic coursework, mentored research, and professional development activities, with defined milestones to ensure successful transition to independence. The mentored research has 2 specific Aims: Aim 1. Develop a novel system for identifying ARDS digital signatures in electronic health data to accurately identify patients meeting ARDS criteria. Aim 2. Define the early natural history of developing ARDS, to more accurately predict patients' future ARDS risk. Both Aims will utilize rigorous 2-part designs, with the ARDS diagnostic and prediction models developed in the same retrospective cohort and validated in temporally distinct cohorts. In completing these high-level aims, the research will leverage high-resolution electronic health record and beside-monitoring device data to study ARDS with unprecedented detail, providing new insights into ARDS epidemiology and early natural history. This work will build to at least two R01 proposals: (1) testing the impact of a real-time electronic health record- based ARDS diagnostic system to improve evidence-based care practice, (2) defining ARDS subtypes using deep clinical phenotypic data. The work will build toward a programmatic line of research using high-resolution electronic health data to improve understanding of critical illness and respiratory disease. In completing this proposal, Dr. Sjoding will acquire unique computational expertise in data science methods, complementing his previous training, which he can then readily apply to address other research challenges in respiratory health. The ambitious but feasible training and mentored research proposed during this K01 award will allow him to achieve his goal of becoming an independent investigator. PROJECT NARRATIVE The Acute Respiratory Distress Syndrome (ARDS) is a critical illness syndrome affecting 200,000 people each year in intensive care units with a 30% mortality rate. To improve ARDS care, new approaches are urgently needed to improve ARDS identificationthe critical first step to ensuring patients receive life-saving treatments. High-resolution electronic health data may provide a clear picture of evolving ARDS; leveraging this data to develop automated systems for ARDS diagnosis will help ensure patients with ARDS are recognized early and receive timely, evidence-based treatments.",Data-Driven Identification of the Acute Respiratory Distress Syndrome,9908166,K01HL136687,"['Acute', 'Address', 'Adult Respiratory Distress Syndrome', 'Affect', 'Bayesian Network', 'Biometry', 'Caring', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Network', 'Complement', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Doctor of Philosophy', 'Educational Status', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Evidence based practice', 'Evidence based treatment', 'Future', 'Goals', 'Hour', 'Individual', 'Infrastructure', 'Intensive Care Units', 'Investigation', 'Knowledge', 'Laboratories', 'Life', 'Lung', 'Lung diseases', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural History', 'Natural Language Processing', 'Participant', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Positioning Attribute', 'Prevention trial', 'Process', 'Real-Time Systems', 'Records', 'Reference Standards', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrospective cohort', 'Retrospective cohort study', 'Risk', 'Risk Estimate', 'Risk Factors', 'Savings', 'Specificity', 'Statistical Models', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'base', 'big biomedical data', 'career', 'clinical phenotype', 'clinical practice', 'cohort', 'design', 'digital', 'electronic data', 'evidence base', 'health data', 'high risk', 'human disease', 'improved', 'insight', 'machine learning method', 'meetings', 'monitoring device', 'mortality', 'novel', 'novel strategies', 'novel therapeutics', 'phenotypic data', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'respiratory health', 'risk prediction model', 'statistical learning']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2020,172680,0.04440623691017405
"Data-Driven Identification of the Acute Respiratory Distress Syndrome PROJECT SUMMARY/ABSTRACT This K01 proposal will complete Michael Sjoding, MD, MSc's training towards his long-term career goal of improving care of patients with acute respiratory disease. Dr. Sjoding is a Pulmonary and Critical Physician at the University of Michigan with master's level training in clinical study design and biostatistics. This proposal builds on Dr. Sjoding's prior expertise, providing protected time for additional training in data science, the technical methods for deriving new knowledge about human disease from Big Biomedical Data in the rich training environment at the University of Michigan. The project's research goal is to develop real-time systems to improve accuracy and timeliness of Acute Respiratory Distress Syndrome (ARDS) diagnosis using electronic health record data. ARDS is a critical illness syndrome affecting 200,000 people each year with high mortality. Under-recognition of this syndrome is the key barrier to providing evidence-based care to patients with ARDS. The research will be completed under the guidance of primary mentor Theodore J. Iwashyna, MD, PhD and co-mentors Timothy P. Hofer, MD, MSc, and Kayvan Najarian, PhD, and a scientific advisory board with additional expertise in data science and applied clinical informatics. The 5-year plan includes didactic coursework, mentored research, and professional development activities, with defined milestones to ensure successful transition to independence. The mentored research has 2 specific Aims: Aim 1. Develop a novel system for identifying ARDS digital signatures in electronic health data to accurately identify patients meeting ARDS criteria. Aim 2. Define the early natural history of developing ARDS, to more accurately predict patients' future ARDS risk. Both Aims will utilize rigorous 2-part designs, with the ARDS diagnostic and prediction models developed in the same retrospective cohort and validated in temporally distinct cohorts. In completing these high-level aims, the research will leverage high-resolution electronic health record and beside-monitoring device data to study ARDS with unprecedented detail, providing new insights into ARDS epidemiology and early natural history. This work will build to at least two R01 proposals: (1) testing the impact of a real-time electronic health record- based ARDS diagnostic system to improve evidence-based care practice, (2) defining ARDS subtypes using deep clinical phenotypic data. The work will build toward a programmatic line of research using high-resolution electronic health data to improve understanding of critical illness and respiratory disease. In completing this proposal, Dr. Sjoding will acquire unique computational expertise in data science methods, complementing his previous training, which he can then readily apply to address other research challenges in respiratory health. The ambitious but feasible training and mentored research proposed during this K01 award will allow him to achieve his goal of becoming an independent investigator. PROJECT NARRATIVE The Acute Respiratory Distress Syndrome (ARDS) is a critical illness syndrome affecting 200,000 people each year in intensive care units with a 30% mortality rate. To improve ARDS care, new approaches are urgently needed to improve ARDS identificationthe critical first step to ensuring patients receive life-saving treatments. High-resolution electronic health data may provide a clear picture of evolving ARDS; leveraging this data to develop automated systems for ARDS diagnosis will help ensure patients with ARDS are recognized early and receive timely, evidence-based treatments.",Data-Driven Identification of the Acute Respiratory Distress Syndrome,9652672,K01HL136687,"['Acute', 'Address', 'Adult Respiratory Distress Syndrome', 'Affect', 'Bayesian Network', 'Biometry', 'Caring', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Network', 'Complement', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Doctor of Philosophy', 'Educational Status', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Evidence based practice', 'Evidence based treatment', 'Future', 'Goals', 'Hour', 'Individual', 'Infrastructure', 'Intensive Care Units', 'Investigation', 'Knowledge', 'Laboratories', 'Life', 'Lung', 'Lung diseases', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural History', 'Natural Language Processing', 'Participant', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Positioning Attribute', 'Prevention trial', 'Process', 'Real-Time Systems', 'Records', 'Reference Standards', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrospective cohort', 'Retrospective cohort study', 'Risk', 'Risk Estimate', 'Risk Factors', 'Savings', 'Specificity', 'Statistical Models', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'base', 'big biomedical data', 'career', 'clinical phenotype', 'clinical practice', 'cohort', 'design', 'digital', 'electronic data', 'evidence base', 'health data', 'high risk', 'human disease', 'improved', 'insight', 'learning strategy', 'meetings', 'monitoring device', 'mortality', 'novel', 'novel strategies', 'novel therapeutics', 'phenotypic data', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'respiratory health', 'risk prediction model']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2019,172087,0.04440623691017405
"Data-Driven Identification of the Acute Respiratory Distress Syndrome PROJECT SUMMARY/ABSTRACT This K01 proposal will complete Michael Sjoding, MD, MSc's training towards his long-term career goal of improving care of patients with acute respiratory disease. Dr. Sjoding is a Pulmonary and Critical Physician at the University of Michigan with master's level training in clinical study design and biostatistics. This proposal builds on Dr. Sjoding's prior expertise, providing protected time for additional training in data science, the technical methods for deriving new knowledge about human disease from Big Biomedical Data in the rich training environment at the University of Michigan. The project's research goal is to develop real-time systems to improve accuracy and timeliness of Acute Respiratory Distress Syndrome (ARDS) diagnosis using electronic health record data. ARDS is a critical illness syndrome affecting 200,000 people each year with high mortality. Under-recognition of this syndrome is the key barrier to providing evidence-based care to patients with ARDS. The research will be completed under the guidance of primary mentor Theodore J. Iwashyna, MD, PhD and co-mentors Timothy P. Hofer, MD, MSc, and Kayvan Najarian, PhD, and a scientific advisory board with additional expertise in data science and applied clinical informatics. The 5-year plan includes didactic coursework, mentored research, and professional development activities, with defined milestones to ensure successful transition to independence. The mentored research has 2 specific Aims: Aim 1. Develop a novel system for identifying ARDS digital signatures in electronic health data to accurately identify patients meeting ARDS criteria. Aim 2. Define the early natural history of developing ARDS, to more accurately predict patients' future ARDS risk. Both Aims will utilize rigorous 2-part designs, with the ARDS diagnostic and prediction models developed in the same retrospective cohort and validated in temporally distinct cohorts. In completing these high-level aims, the research will leverage high-resolution electronic health record and beside-monitoring device data to study ARDS with unprecedented detail, providing new insights into ARDS epidemiology and early natural history. This work will build to at least two R01 proposals: (1) testing the impact of a real-time electronic health record- based ARDS diagnostic system to improve evidence-based care practice, (2) defining ARDS subtypes using deep clinical phenotypic data. The work will build toward a programmatic line of research using high-resolution electronic health data to improve understanding of critical illness and respiratory disease. In completing this proposal, Dr. Sjoding will acquire unique computational expertise in data science methods, complementing his previous training, which he can then readily apply to address other research challenges in respiratory health. The ambitious but feasible training and mentored research proposed during this K01 award will allow him to achieve his goal of becoming an independent investigator. PROJECT NARRATIVE The Acute Respiratory Distress Syndrome (ARDS) is a critical illness syndrome affecting 200,000 people each year in intensive care units with a 30% mortality rate. To improve ARDS care, new approaches are urgently needed to improve ARDS identificationthe critical first step to ensuring patients receive life-saving treatments. High-resolution electronic health data may provide a clear picture of evolving ARDS; leveraging this data to develop automated systems for ARDS diagnosis will help ensure patients with ARDS are recognized early and receive timely, evidence-based treatments.",Data-Driven Identification of the Acute Respiratory Distress Syndrome,9292908,K01HL136687,"['Acute', 'Address', 'Adult Respiratory Distress Syndrome', 'Affect', 'Biometry', 'Caring', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Network', 'Complement', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Doctor of Philosophy', 'Educational Status', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Evidence based practice', 'Evidence based treatment', 'Future', 'Goals', 'Hour', 'Individual', 'Intensive Care Units', 'Investigation', 'Knowledge', 'Laboratories', 'Life', 'Lung', 'Lung diseases', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural History', 'Natural Language Processing', 'Participant', 'Patient Care', 'Patient risk', 'Patients', 'Performance', 'Physicians', 'Positioning Attribute', 'Prevention trial', 'Process', 'Real-Time Systems', 'Records', 'Recruitment Activity', 'Reference Standards', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrospective cohort', 'Retrospective cohort study', 'Risk', 'Risk Estimate', 'Risk Factors', 'Savings', 'Specificity', 'Statistical Models', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'base', 'big biomedical data', 'career', 'clinical phenotype', 'clinical practice', 'cohort', 'computer based statistical methods', 'design', 'digital', 'electronic data', 'evidence base', 'health data', 'high risk', 'human disease', 'improved', 'insight', 'learning strategy', 'meetings', 'monitoring device', 'mortality', 'novel', 'novel strategies', 'novel therapeutics', 'phenotypic data', 'predictive modeling', 'prevent', 'prospective', 'respiratory health']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2017,172444,0.04440623691017405
"Data-Driven Identification of the Acute Respiratory Distress Syndrome PROJECT SUMMARY/ABSTRACT This K01 proposal will complete Michael Sjoding, MD, MSc's training towards his long-term career goal of improving care of patients with acute respiratory disease. Dr. Sjoding is a Pulmonary and Critical Physician at the University of Michigan with master's level training in clinical study design and biostatistics. This proposal builds on Dr. Sjoding's prior expertise, providing protected time for additional training in data science, the technical methods for deriving new knowledge about human disease from Big Biomedical Data in the rich training environment at the University of Michigan. The project's research goal is to develop real-time systems to improve accuracy and timeliness of Acute Respiratory Distress Syndrome (ARDS) diagnosis using electronic health record data. ARDS is a critical illness syndrome affecting 200,000 people each year with high mortality. Under-recognition of this syndrome is the key barrier to providing evidence-based care to patients with ARDS. The research will be completed under the guidance of primary mentor Theodore J. Iwashyna, MD, PhD and co-mentors Timothy P. Hofer, MD, MSc, and Kayvan Najarian, PhD, and a scientific advisory board with additional expertise in data science and applied clinical informatics. The 5-year plan includes didactic coursework, mentored research, and professional development activities, with defined milestones to ensure successful transition to independence. The mentored research has 2 specific Aims: Aim 1. Develop a novel system for identifying ARDS digital signatures in electronic health data to accurately identify patients meeting ARDS criteria. Aim 2. Define the early natural history of developing ARDS, to more accurately predict patients' future ARDS risk. Both Aims will utilize rigorous 2-part designs, with the ARDS diagnostic and prediction models developed in the same retrospective cohort and validated in temporally distinct cohorts. In completing these high-level aims, the research will leverage high-resolution electronic health record and beside-monitoring device data to study ARDS with unprecedented detail, providing new insights into ARDS epidemiology and early natural history. This work will build to at least two R01 proposals: (1) testing the impact of a real-time electronic health record- based ARDS diagnostic system to improve evidence-based care practice, (2) defining ARDS subtypes using deep clinical phenotypic data. The work will build toward a programmatic line of research using high-resolution electronic health data to improve understanding of critical illness and respiratory disease. In completing this proposal, Dr. Sjoding will acquire unique computational expertise in data science methods, complementing his previous training, which he can then readily apply to address other research challenges in respiratory health. The ambitious but feasible training and mentored research proposed during this K01 award will allow him to achieve his goal of becoming an independent investigator. PROJECT NARRATIVE The Acute Respiratory Distress Syndrome (ARDS) is a critical illness syndrome affecting 200,000 people each year in intensive care units with a 30% mortality rate. To improve ARDS care, new approaches are urgently needed to improve ARDS identificationthe critical first step to ensuring patients receive life-saving treatments. High-resolution electronic health data may provide a clear picture of evolving ARDS; leveraging this data to develop automated systems for ARDS diagnosis will help ensure patients with ARDS are recognized early and receive timely, evidence-based treatments.",Data-Driven Identification of the Acute Respiratory Distress Syndrome,9461433,K01HL136687,"['Acute', 'Address', 'Adult Respiratory Distress Syndrome', 'Affect', 'Biometry', 'Caring', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Network', 'Complement', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Doctor of Philosophy', 'Educational Status', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Evidence based practice', 'Evidence based treatment', 'Future', 'Goals', 'Hour', 'Individual', 'Intensive Care Units', 'Investigation', 'Knowledge', 'Laboratories', 'Life', 'Lung', 'Lung diseases', 'Machine Learning', 'Mentored Research Scientist Development Award', 'Mentors', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural History', 'Natural Language Processing', 'Participant', 'Patient Care', 'Patient risk', 'Patients', 'Performance', 'Physicians', 'Positioning Attribute', 'Prevention trial', 'Process', 'Real-Time Systems', 'Records', 'Reference Standards', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrospective cohort', 'Retrospective cohort study', 'Risk', 'Risk Estimate', 'Risk Factors', 'Savings', 'Specificity', 'Statistical Models', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'base', 'big biomedical data', 'career', 'clinical phenotype', 'clinical practice', 'cohort', 'computer based statistical methods', 'design', 'digital', 'electronic data', 'evidence base', 'health data', 'high risk', 'human disease', 'improved', 'insight', 'learning strategy', 'meetings', 'monitoring device', 'mortality', 'novel', 'novel strategies', 'novel therapeutics', 'phenotypic data', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'respiratory health']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2018,172087,0.04440623691017405
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9899862,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Comparative Effectiveness Research', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'advanced analytics', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'improved', 'interdisciplinary approach', 'medication compliance', 'medication safety', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke therapy', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2020,163080,-0.02137545032714094
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9670145,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'medication safety', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke therapy', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2019,163080,-0.02137545032714094
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9294543,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke treatment', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2017,163080,-0.02137545032714094
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9460286,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke treatment', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2018,163080,-0.02137545032714094
"Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data SUMMARY The modernization and standardization of clinical care information systems is creating large networks of linked electronic health records (EHR) that capture key treatments and select patient outcomes for millions of patients throughout the country. The observational data emerging from these systems provide an unparalleled opportunity to learn about the effectiveness of existing and novel treatments, and to monitor potential safety issues that may arise when interventions are used in broad patient populations. However, observational clinical data have exposures that are driven by many factors and therefore aggressive adjustment is needed to remove as much confounding bias as possible in order to make attribution regarding select exposures. The field of machine learning provides a powerful collection of data-driven approaches for performing flexible, thorough confounding adjustment, but performing reliable statistical inference is particularly challenging when these techniques are used as part of the analytic strategy. We propose to advance reproducible research methods by developing and illustrating novel targeted learning tools that leverage the flexibility of machine learning methods to detect and characterize health effect signals using large-scale EHR data. Specifically, we will first develop techniques for making efficient, statistically valid and robust inference for treatment effects using state-of-the-art machine learning tools. We will also develop online learning techniques to make such inference in the context of streaming EHR data. Methodological advances will enable us to formulate a formal, rigorous and practical framework for conducting continuous, effective and reliable surveillance for safety endpoints. Finally, we will develop statistical approaches for incorporating prior information -- including demographic, epidemiologic or pharmacodynamic knowledge, for example -- to improve health effect estimation and inference when the health outcome of interest is rare and the statistical problem is thus difficult, as often occurs in safety surveillance. The ultimate goal of the proposed research is to enable biomedical researchers and public health regulators to carefully monitor and protect the health of the public by allowing them to more effectively and more reliably detect critical health effect signals that may be contained in population-scale EHR data. PROJECT NARRATIVE The modernization and standardization of clinical care information systems is creating large networks of linked electronic medical records that capture key treatments and select patient outcomes for millions of U.S. subjects. The population scale of contemporary health care data is opening new opportunities for quickly learning from observational data, and is now supporting on-going national surveillance that will monitor the risks and benefits of both existing and novel treatment paths. The objective of this proposal is to provide an inferential framework that leverages the flexibility of machine learning methods to detect health effect signals, including in the important setting of high-dimensional confounders and/or rare events, and to develop a real-time sequential updating methodology for safety signal detection.",Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data,9979940,R01HL137808,"['Algorithms', 'Benefits and Risks', 'Characteristics', 'Clinical Data', 'Complex', 'Computer software', 'Computerized Medical Record', 'Confidence Intervals', 'Country', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Estimation Techniques', 'Event', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Heterogeneity', 'Information Systems', 'Infrastructure', 'Intervention', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modernization', 'Monitor', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacodynamics', 'Population', 'Population Surveillance', 'Procedures', 'Public Health', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Safety', 'Sentinel', 'Signal Transduction', 'Standardization', 'Statistical Methods', 'Stream', 'Structural Models', 'Subgroup', 'Surveillance Program', 'System', 'Techniques', 'Testing', 'Time', 'Treatment outcome', 'Update', 'base', 'clinical care', 'comparative treatment', 'data streams', 'flexibility', 'high dimensionality', 'improved', 'interest', 'machine learning method', 'national surveillance', 'novel', 'open source', 'patient population', 'patient subsets', 'risk minimization', 'software development', 'surveillance data', 'tool', 'treatment effect', 'user-friendly']",NHLBI,UNIVERSITY OF WASHINGTON,R01,2020,485987,0.0450700071962744
"Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data SUMMARY The modernization and standardization of clinical care information systems is creating large networks of linked electronic health records (EHR) that capture key treatments and select patient outcomes for millions of patients throughout the country. The observational data emerging from these systems provide an unparalleled opportunity to learn about the effectiveness of existing and novel treatments, and to monitor potential safety issues that may arise when interventions are used in broad patient populations. However, observational clinical data have exposures that are driven by many factors and therefore aggressive adjustment is needed to remove as much confounding bias as possible in order to make attribution regarding select exposures. The field of machine learning provides a powerful collection of data-driven approaches for performing flexible, thorough confounding adjustment, but performing reliable statistical inference is particularly challenging when these techniques are used as part of the analytic strategy. We propose to advance reproducible research methods by developing and illustrating novel targeted learning tools that leverage the flexibility of machine learning methods to detect and characterize health effect signals using large-scale EHR data. Specifically, we will first develop techniques for making efficient, statistically valid and robust inference for treatment effects using state-of-the-art machine learning tools. We will also develop online learning techniques to make such inference in the context of streaming EHR data. Methodological advances will enable us to formulate a formal, rigorous and practical framework for conducting continuous, effective and reliable surveillance for safety endpoints. Finally, we will develop statistical approaches for incorporating prior information -- including demographic, epidemiologic or pharmacodynamic knowledge, for example -- to improve health effect estimation and inference when the health outcome of interest is rare and the statistical problem is thus difficult, as often occurs in safety surveillance. The ultimate goal of the proposed research is to enable biomedical researchers and public health regulators to carefully monitor and protect the health of the public by allowing them to more effectively and more reliably detect critical health effect signals that may be contained in population-scale EHR data. PROJECT NARRATIVE The modernization and standardization of clinical care information systems is creating large networks of linked electronic medical records that capture key treatments and select patient outcomes for millions of U.S. subjects. The population scale of contemporary health care data is opening new opportunities for quickly learning from observational data, and is now supporting on-going national surveillance that will monitor the risks and benefits of both existing and novel treatment paths. The objective of this proposal is to provide an inferential framework that leverages the flexibility of machine learning methods to detect health effect signals, including in the important setting of high-dimensional confounders and/or rare events, and to develop a real-time sequential updating methodology for safety signal detection.",Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data,9816009,R01HL137808,"['Algorithms', 'Benefits and Risks', 'Characteristics', 'Clinical Data', 'Complex', 'Computer software', 'Computerized Medical Record', 'Confidence Intervals', 'Country', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Estimation Techniques', 'Event', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Heterogeneity', 'Information Systems', 'Infrastructure', 'Intervention', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modernization', 'Monitor', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacodynamics', 'Population', 'Population Surveillance', 'Procedures', 'Public Health', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Safety', 'Sentinel', 'Signal Transduction', 'Standardization', 'Statistical Methods', 'Stream', 'Structural Models', 'Subgroup', 'Surveillance Program', 'System', 'Techniques', 'Testing', 'Time', 'Treatment outcome', 'Update', 'base', 'clinical care', 'comparative treatment', 'flexibility', 'high dimensionality', 'improved', 'interest', 'learning strategy', 'national surveillance', 'novel', 'open source', 'patient population', 'patient subsets', 'risk minimization', 'software development', 'surveillance data', 'tool', 'treatment effect', 'user-friendly']",NHLBI,UNIVERSITY OF WASHINGTON,R01,2019,502815,0.0450700071962744
"Addressing Bias from Missing Data in EHR Based Studies of CVD Project Summary This NHLBI K01 application supports the career development of Dr. Nrupen A. Bhavsar, PhD, an Assistant Professor of Medicine at the Duke University School of Medicine. Dr. Bhavsar is a chronic disease epidemiologist who has performed multidisciplinary studies in the epidemiology of CVD, chronic kidney disease and cancer. He is passionate about pursuing a career in clinical research at the intersection of epidemiology, informatics, and biostatistics. At the end of the award period, Dr. Bhavsar will be an independent investigator applying knowledge gained through this K01 to develop large scale EHR-based population studies that identify individuals at high risk for cardiovascular disease (CVD) events. Through training in data linkage, machine learning, and causal inference, he will apply missing data methods to conduct rigorous non-randomized studies to improve health. The topical areas of the proposed training and research are diabetes and incident CVD events in the application of data linkage, machine learning, and causal inference. Career development aim: Obtain transdisciplinary competencies within informatics, biostatistics, and population sciences to investigate methodological challenges inherent in the use of multi-health system EHR data for clinical research. The training approach will leverage didactic and experiential training complemented by analyses of data derived from a multi-health system, multi-state research collaborative. Study population: Patients who received care at one of the North Carolina or South Carolina Carolinas Collaborative institutions (Duke University Medical Center, UNC-CH Health System, Wake Forest Baptist Health Center, and 9 additional health systems collaborating within the Health Sciences of South Carolina institutions). Specific aims: This proposal will identify approaches to account for missing data when patients seek care across multiple health systems but EHR data is only available from a single health system. Estimating the systemic bias introduced by missing data for single institution studies and identifying methods for accounting for missing data biases may improve the ability of EHR data to be used for clinical research. Anticipated results: Through this NHLBI K01 Research Scientist Career Development Award, Dr. Bhavsar will acquire essential training and research experience to develop large scale EHR-based population studies in CVD. PROJECT NARRATIVE Data from the electronic health records (EHR) are increasingly being used for clinical research, yet there is limited information on the best approaches to address the methodological limitations of the EHR, such as missing data. In patients with diabetes at risk of cardiovascular disease events, I will examine the impact that missing data has on the ability to use the EHR for clinical research and develop approaches to address the biases resulting from missing data.",Addressing Bias from Missing Data in EHR Based Studies of CVD,9994001,K01HL140146,"['Academic Medical Centers', 'Accounting', 'Address', 'Area', 'Award', 'Baptist Church', 'Biometry', 'Cardiovascular Diseases', 'Caring', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cohort Studies', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Linkages', 'Data Pooling', 'Data Science', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Goals', 'Health', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitalization', 'Individual', 'Informatics', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal', 'Machine Learning', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Sciences', 'Population Study', 'Privacy', 'Publishing', 'Renal carcinoma', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Priority', 'Risk', 'Risk Factors', 'Scientist', 'South Carolina', 'Stroke', 'Training', 'Universities', 'Work', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'cardiovascular health', 'care seeking', 'career', 'career development', 'clinical care', 'cohort', 'comorbidity', 'data quality', 'distributed data', 'electronic data', 'epidemiologic data', 'epidemiology study', 'experience', 'forest', 'high risk', 'improved', 'medical schools', 'multidisciplinary', 'novel', 'patient population', 'population health', 'practical application', 'professor', 'randomized trial', 'skills', 'study population']",NHLBI,DUKE UNIVERSITY,K01,2020,165444,0.055339672534545165
"Addressing Bias from Missing Data in EHR Based Studies of CVD Project Summary This NHLBI K01 application supports the career development of Dr. Nrupen A. Bhavsar, PhD, an Assistant Professor of Medicine at the Duke University School of Medicine. Dr. Bhavsar is a chronic disease epidemiologist who has performed multidisciplinary studies in the epidemiology of CVD, chronic kidney disease and cancer. He is passionate about pursuing a career in clinical research at the intersection of epidemiology, informatics, and biostatistics. At the end of the award period, Dr. Bhavsar will be an independent investigator applying knowledge gained through this K01 to develop large scale EHR-based population studies that identify individuals at high risk for cardiovascular disease (CVD) events. Through training in data linkage, machine learning, and causal inference, he will apply missing data methods to conduct rigorous non-randomized studies to improve health. The topical areas of the proposed training and research are diabetes and incident CVD events in the application of data linkage, machine learning, and causal inference. Career development aim: Obtain transdisciplinary competencies within informatics, biostatistics, and population sciences to investigate methodological challenges inherent in the use of multi-health system EHR data for clinical research. The training approach will leverage didactic and experiential training complemented by analyses of data derived from a multi-health system, multi-state research collaborative. Study population: Patients who received care at one of the North Carolina or South Carolina Carolinas Collaborative institutions (Duke University Medical Center, UNC-CH Health System, Wake Forest Baptist Health Center, and 9 additional health systems collaborating within the Health Sciences of South Carolina institutions). Specific aims: This proposal will identify approaches to account for missing data when patients seek care across multiple health systems but EHR data is only available from a single health system. Estimating the systemic bias introduced by missing data for single institution studies and identifying methods for accounting for missing data biases may improve the ability of EHR data to be used for clinical research. Anticipated results: Through this NHLBI K01 Research Scientist Career Development Award, Dr. Bhavsar will acquire essential training and research experience to develop large scale EHR-based population studies in CVD. PROJECT NARRATIVE Data from the electronic health records (EHR) are increasingly being used for clinical research, yet there is limited information on the best approaches to address the methodological limitations of the EHR, such as missing data. In patients with diabetes at risk of cardiovascular disease events, I will examine the impact that missing data has on the ability to use the EHR for clinical research and develop approaches to address the biases resulting from missing data.",Addressing Bias from Missing Data in EHR Based Studies of CVD,9742515,K01HL140146,"['Academic Medical Centers', 'Accounting', 'Address', 'Area', 'Award', 'Baptist Church', 'Biometry', 'Cardiovascular Diseases', 'Caring', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cohort Studies', 'Comorbidity', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Linkages', 'Data Quality', 'Data Science', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Goals', 'Health', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitalization', 'Individual', 'Informatics', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal', 'Machine Learning', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Sciences', 'Population Study', 'Privacy', 'Publishing', 'Renal carcinoma', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Priority', 'Risk', 'Risk Factors', 'Scientist', 'South Carolina', 'Stroke', 'Training', 'Universities', 'Work', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'cardiovascular health', 'care seeking', 'career', 'career development', 'clinical care', 'cohort', 'distributed data', 'electronic data', 'epidemiologic data', 'epidemiology study', 'experience', 'forest', 'high risk', 'improved', 'medical schools', 'multidisciplinary', 'novel', 'patient population', 'population health', 'practical application', 'professor', 'randomized trial', 'skills', 'study population']",NHLBI,DUKE UNIVERSITY,K01,2019,165554,0.055339672534545165
"Addressing Bias from Missing Data in EHR Based Studies of CVD Project Summary This NHLBI K01 application supports the career development of Dr. Nrupen A. Bhavsar, PhD, an Assistant Professor of Medicine at the Duke University School of Medicine. Dr. Bhavsar is a chronic disease epidemiologist who has performed multidisciplinary studies in the epidemiology of CVD, chronic kidney disease and cancer. He is passionate about pursuing a career in clinical research at the intersection of epidemiology, informatics, and biostatistics. At the end of the award period, Dr. Bhavsar will be an independent investigator applying knowledge gained through this K01 to develop large scale EHR-based population studies that identify individuals at high risk for cardiovascular disease (CVD) events. Through training in data linkage, machine learning, and causal inference, he will apply missing data methods to conduct rigorous non-randomized studies to improve health. The topical areas of the proposed training and research are diabetes and incident CVD events in the application of data linkage, machine learning, and causal inference. Career development aim: Obtain transdisciplinary competencies within informatics, biostatistics, and population sciences to investigate methodological challenges inherent in the use of multi-health system EHR data for clinical research. The training approach will leverage didactic and experiential training complemented by analyses of data derived from a multi-health system, multi-state research collaborative. Study population: Patients who received care at one of the North Carolina or South Carolina Carolinas Collaborative institutions (Duke University Medical Center, UNC-CH Health System, Wake Forest Baptist Health Center, and 9 additional health systems collaborating within the Health Sciences of South Carolina institutions). Specific aims: This proposal will identify approaches to account for missing data when patients seek care across multiple health systems but EHR data is only available from a single health system. Estimating the systemic bias introduced by missing data for single institution studies and identifying methods for accounting for missing data biases may improve the ability of EHR data to be used for clinical research. Anticipated results: Through this NHLBI K01 Research Scientist Career Development Award, Dr. Bhavsar will acquire essential training and research experience to develop large scale EHR-based population studies in CVD. PROJECT NARRATIVE Data from the electronic health records (EHR) are increasingly being used for clinical research, yet there is limited information on the best approaches to address the methodological limitations of the EHR, such as missing data. In patients with diabetes at risk of cardiovascular disease events, I will examine the impact that missing data has on the ability to use the EHR for clinical research and develop approaches to address the biases resulting from missing data.",Addressing Bias from Missing Data in EHR Based Studies of CVD,9598902,K01HL140146,"['Academic Medical Centers', 'Accounting', 'Address', 'Area', 'Award', 'Baptist Church', 'Biometry', 'Cardiovascular Diseases', 'Caring', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cohort Studies', 'Comorbidity', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Linkages', 'Data Quality', 'Data Science', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Goals', 'Health', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitalization', 'Individual', 'Informatics', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal', 'Machine Learning', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Sciences', 'Population Study', 'Privacy', 'Publishing', 'Renal carcinoma', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Priority', 'Risk', 'Risk Factors', 'Scientist', 'South Carolina', 'Stroke', 'Training', 'Universities', 'Work', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'cardiovascular health', 'care seeking', 'career', 'career development', 'clinical care', 'cohort', 'distributed data', 'electronic data', 'epidemiologic data', 'epidemiology study', 'experience', 'forest', 'high risk', 'improved', 'medical schools', 'multidisciplinary', 'novel', 'patient population', 'population health', 'practical application', 'professor', 'randomized trial', 'skills', 'study population']",NHLBI,DUKE UNIVERSITY,K01,2018,166645,0.055339672534545165
"An in-silico method for epidemiological studies using Electronic Medical Records Observational epidemiological studies are effective methods for identifying  factors affecting the health and illness of populations, as well as for determining optimal  treatments for diseases, such as cancers. However, conventional epidemiological  research usually involves personnel-intensive effort (such as manual chart and public  records review) and can be very time consuming before conclusive results are obtained.  Recently, a large amount of detailed longitudinal clinical data has been accumulated at  hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data  source for epidemiological studies. However, there are two obstacles that prevent the  wide usage of EMR data in epidemiological studies. First, most of the detailed clinical  information in EMRs is embedded in narrative text and it is very costly to extract that  information manually. Second, EMRs usually have data quality problems such as  selection bias and missing data, which require adaptation of conventional statistical  methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for  observational epidemiological studies using EMR data. We hypothesize that existing  EMR data can be used for certain types of epidemiological studies in a very efficient  manner with the help of informatics methods. The informatics-based approach will  contain two major components. One is an NLP (Natural Language Processing) based  information extraction system that can automatically extract detailed clinical information  from EMR and another is a set of statistical and informatics methods that can be used to  analyze EMR-derived data. If the feasibility of this approach is proven, it will change the  standard paradigm of observational epidemiological research, because it has the  capability to answer an epidemiological question in a very short time at a very low cost.   The specific aim of this study is to develop an automated informatics approach to  extract both fine-grained cancer findings and general clinical information from EMRs and  use them to conduct cancer related epidemiological studies. We will perform both case-  control and cohort studies related to prevention and treatment of breast and colon  cancers using EMR data. The informatics approach will be validated on EMRs from two  major hospitals to demonstrate its generalizability. Epidemiological findings from our  study will be compared to reported findings for validation. Project Narrative  According to the American Cancer Society, about 7.6 million people died from various  types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,8298614,R01CA141307,"['Address', 'Affect', 'American Cancer Society', 'Breast Cancer Treatment', 'Case-Control Studies', 'Cereals', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Collection', 'Data Quality', 'Data Sources', 'Databases', 'Discipline of Nursing', 'Disease', 'Documentation', 'Effectiveness', 'Epidemiologic Studies', 'Epidemiology', 'Ethics', 'Gold', 'Health', 'Healthcare Industry', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Language', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Education', 'Methods', 'Natural Language Processing', 'Nature', 'New York', 'Observational Study', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Play', 'Population', 'Presbyterian Church', 'Prevention', 'Process', 'Quality of Care', 'Radiology Specialty', 'Randomized Clinical Trials', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Selection Bias', 'Statistical Methods', 'Structure', 'Syndrome', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic Agents', 'Therapeutic procedure', 'Time', 'Translational Research', 'Universities', 'University Hospitals', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'clinical application', 'clinical practice', 'cost', 'efficacy testing', 'improved', 'malignant breast neoplasm', 'novel', 'prevent', 'prognostic indicator', 'public health research', 'statistics', 'treatment effect']",NCI,VANDERBILT UNIVERSITY,R01,2012,56569,0.0485824875515213
"An in-silico method for epidemiological studies using Electronic Medical Records DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation. Narrative: According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,7925776,R01CA141307,"['Affect', 'American Cancer Society', 'Breast', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2010,259993,0.0485824875515213
"An in-silico method for epidemiological studies using Electronic Medical Records    DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation.      Narrative: According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of   cancers and to determine optimal treatments of cancers, and epidemiological study is   one of the methods to achieve it. This proposed study will use natural language   processing technologies to automatically extract fine-grained cancer information from   existing patient electronic medical records and use it to conduct cancer related   epidemiological studies, thus accelerating knowledge accumulation of cancer research.      SPECIAL REVIEW NOTE: In order to conform to the scientific objectives outlined in the program announcement RFA-GM-09-008, EUREKA applications submitted to the NCI were initially evaluated by a group of reviewers representing diverse scientific interests. The priority score reflects the average of all the scores given by the full committee after a thorough discussion.            Project Narrative According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of cancers and to determine optimal treatments of cancers, and epidemiological study is one of the methods to achieve it. This proposed study will use natural language processing technologies to automatically extract fine-grained cancer information from existing patient electronic medical records and use it to conduct cancer related epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,7726747,R01CA141307,"['Affect', 'American Cancer Society', 'Breast', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'NIH Program Announcements', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'interest', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2009,273337,0.05347506376385217
"An in-silico method for epidemiological studies using Electronic Medical Records DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation.  Project Narrative According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of cancers and to determine optimal treatments of cancers, and epidemiological study is one of the methods to achieve it. This proposed study will use natural language processing technologies to automatically extract fine-grained cancer information from existing patient electronic medical records and use it to conduct cancer related epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,8110041,R01CA141307,"['Affect', 'American Cancer Society', 'Breast Cancer Treatment', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2011,252298,0.0485824875515213
"An insilico method for epidemiological studies using Electonic Medical Records Observational epidemiological studies are effective methods for identifying  factors affecting the health and illness of populations, as well as for determining optimal  treatments for diseases, such as cancers. However, conventional epidemiological  research usually involves personnel-intensive effort (such as manual chart and public  records review) and can be very time consuming before conclusive results are obtained.  Recently, a large amount of detailed longitudinal clinical data has been accumulated at  hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data  source for epidemiological studies. However, there are two obstacles that prevent the  wide usage of EMR data in epidemiological studies. First, most of the detailed clinical  information in EMRs is embedded in narrative text and it is very costly to extract that  information manually. Second, EMRs usually have data quality problems such as  selection bias and missing data, which require adaptation of conventional statistical  methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for  observational epidemiological studies using EMR data. We hypothesize that existing  EMR data can be used for certain types of epidemiological studies in a very efficient  manner with the help of informatics methods. The informatics-based approach will  contain two major components. One is an NLP (Natural Language Processing) based  information extraction system that can automatically extract detailed clinical information  from EMR and another is a set of statistical and informatics methods that can be used to  analyze EMR-derived data. If the feasibility of this approach is proven, it will change the  standard paradigm of observational epidemiological research, because it has the  capability to answer an epidemiological question in a very short time at a very low cost.   The specific aim of this study is to develop an automated informatics approach to  extract both fine-grained cancer findings and general clinical information from EMRs and  use them to conduct cancer related epidemiological studies. We will perform both case-  control and cohort studies related to prevention and treatment of breast and colon  cancers using EMR data. The informatics approach will be validated on EMRs from two  major hospitals to demonstrate its generalizability. Epidemiological findings from our  study will be compared to reported findings for validation. Project Narrative  According to the American Cancer Society, about 7.6 million people died from various  types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An insilico method for epidemiological studies using Electonic Medical Records,8589201,R01CA141307,[' '],NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2012,195838,0.04381797818742201
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this eld typically produce an all-cause risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest  at best  reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classication models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signicantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identication and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9906933,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'clinical center', 'clinical encounter', 'comorbidity', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'statistical learning', 'structured data', 'supportive environment', 'trend', 'trial design', 'unstructured data']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2020,194806,-0.056226952024507997
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this eld typically produce an all-cause risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest  at best  reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classication models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signicantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identication and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9681485,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Comorbidity', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'supportive environment', 'trend', 'trial design']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2019,195076,-0.056226952024507997
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this eld typically produce an all-cause risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest  at best  reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classication models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signicantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identication and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9505570,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Comorbidity', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patient risk', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'collaborative environment', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'skills', 'social', 'trend', 'trial design']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2018,195205,-0.056226952024507997
"Improving the measurement and analysis of long-term, patient-centered outcomes following acute respiratory failure PROJECT SUMMARY/ABSTRACT This Pathway to Independence Award application is submitted by a pulmonary and critical care epidemiologist committed to improving the quality of patient-oriented research for patients experiencing acute respiratory failure (ARF). Worldwide, millions of patients develop ARF annually. In the U.S., nearly one million patients with ARF require mechanical ventilation annually, accounting for a quarter of all intensive care unit (ICU) admissions. As improvements in ICU care reduce such patients in-hospital mortality rates, attention has shifted to the challenges ARF survivors face in regaining their prior cognitive, physical, and psychosocial functioning. However, there is a key barrier for randomized clinical trials (RCTs) testing new interventions to improve ARF survivorship  that is, the current lack of an endpoint that (1) captures long-term patient dispositions, (2) incorporates patient preferences and perspectives, and (3) is able to be analyzed without concern for statistical biases. The overarching goal of this research is to support clinical innovation by developing new approaches to measure and report long-term patient-centered outcomes that overcome the methodological barriers currently limiting ARF RCTs. The applicant will accomplish his goals under the mentorship of established researchers in critical care, patient-centered outcomes research, statistics, and informatics to assure his transition to a tenure-track faculty position in the R00 phase and his emergence as a leading pulmonary and critical care epidemiologist. First, the applicant will use an innovative combination of qualitative and quantitative research methods to elicit and integrate ARF survivors and their caregivers perspectives into a new patient-centered, long-term composite outcome measure (K99 phase). During the R00 phase, the applicant will recruit ARF survivors to participate in a prospective cohort, and follow these patients to describe the burden of ARF survivorship over 1-year using the new endpoint developed during the K99 phase. This endeavor will also provide key data that will facilitate sample size calculations in future ARF RCTs. Data from this cohort will additionally be used to develop an electronic health record (EHR)-based algorithm to predict risks for adverse long-term outcomes among ARF patients early in their ICU stays. Thus, this K99/R00 will augment ARF research by establishing a new outcome measure anchored in patient perspectives, improving the understanding and clinical prognostication of post-ICU morbidity following ARF, and facilitate the efficiency and clinical relevance of future ARF RCTs by enabling measurement of patients baseline risks for different outcomes. Concurrently, the didactic work, individual study, and hands-on learning in mixed-methods research, natural language processing, and predictive analytics will fill key training gaps for the applicant, thereby positioning him for a successful, independently-funded research career advancing the science of outcomes measurement and analysis for ARF RCTs. PROJECT NARRATIVE Randomized trials testing strategies to improve long-term outcomes for survivors of acute respiratory failure (ARF) are hampered by the lack of valid, patient-centered endpoints. Using interviews with ARF survivors and their caregivers, statistical simulation, consensus building among stakeholders, and a prospective cohort study, the applicant will develop, describe the epidemiology of, and predict a new patient-oriented outcome that will support trials of innovative approaches to improve ARF survivorship outcomes.","Improving the measurement and analysis of long-term, patient-centered outcomes following acute respiratory failure",9967226,R00HL141678,"['Accounting', 'Acute respiratory failure', 'Address', 'Admission activity', 'Algorithms', 'Attention', 'Award', 'Caregivers', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Cognitive', 'Communities', 'Competence', 'Consensus', 'Critical Care', 'Data', 'Electronic Health Record', 'Enrollment', 'Epidemiologist', 'Epidemiology', 'Face', 'Faculty', 'Financial Support', 'Funding', 'Future', 'Goals', 'Grant', 'Health', 'Hospital Mortality', 'Hospitals', 'Individual', 'Informatics', 'Intensive Care Units', 'Intervention', 'Interview', 'Lung', 'Machine Learning', 'Measurement', 'Measures', 'Mechanical ventilation', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Preferences', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Physical Function', 'Physicians', 'Positioning Attribute', 'Predictive Analytics', 'Process', 'Property', 'Prospective Studies', 'Prospective cohort', 'Prospective cohort study', 'Provider', 'Quality of life', 'Randomized Clinical Trials', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Risk', 'Rogaine', 'Sample Size', 'Science', 'Statistical Bias', 'Structure', 'Survivors', 'Testing', 'Time', 'Training', 'Work', 'base', 'care outcomes', 'career', 'clinically relevant', 'cognitive function', 'cohort', 'design', 'emotional functioning', 'experience', 'hands-on learning', 'high risk', 'improved', 'innovation', 'novel strategies', 'outcome prediction', 'patient health information', 'patient oriented', 'patient oriented research', 'prediction algorithm', 'prognostic', 'psychosocial', 'randomized trial', 'recruit', 'residence', 'simulation', 'statistics', 'structured data', 'survivorship', 'tenure track', 'unstructured data', 'ventilation']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R00,2020,249000,0.024974259328124623
"Improving the measurement and analysis of long-term, patient-centered outcomes following acute respiratory failure PROJECT SUMMARY/ABSTRACT This Pathway to Independence Award application is submitted by a pulmonary and critical care epidemiologist committed to improving the quality of patient-oriented research for patients experiencing acute respiratory failure (ARF). Worldwide, millions of patients develop ARF annually. In the U.S., nearly one million patients with ARF require mechanical ventilation annually, accounting for a quarter of all intensive care unit (ICU) admissions. As improvements in ICU care reduce such patients in-hospital mortality rates, attention has shifted to the challenges ARF survivors face in regaining their prior cognitive, physical, and psychosocial functioning. However, there is a key barrier for randomized clinical trials (RCTs) testing new interventions to improve ARF survivorship  that is, the current lack of an endpoint that (1) captures long-term patient dispositions, (2) incorporates patient preferences and perspectives, and (3) is able to be analyzed without concern for statistical biases. The overarching goal of this research is to support clinical innovation by developing new approaches to measure and report long-term patient-centered outcomes that overcome the methodological barriers currently limiting ARF RCTs. The applicant will accomplish his goals under the mentorship of established researchers in critical care, patient-centered outcomes research, statistics, and informatics to assure his transition to a tenure-track faculty position in the R00 phase and his emergence as a leading pulmonary and critical care epidemiologist. First, the applicant will use an innovative combination of qualitative and quantitative research methods to elicit and integrate ARF survivors and their caregivers perspectives into a new patient-centered, long-term composite outcome measure (K99 phase). During the R00 phase, the applicant will recruit ARF survivors to participate in a prospective cohort, and follow these patients to describe the burden of ARF survivorship over 1-year using the new endpoint developed during the K99 phase. This endeavor will also provide key data that will facilitate sample size calculations in future ARF RCTs. Data from this cohort will additionally be used to develop an electronic health record (EHR)-based algorithm to predict risks for adverse long-term outcomes among ARF patients early in their ICU stays. Thus, this K99/R00 will augment ARF research by establishing a new outcome measure anchored in patient perspectives, improving the understanding and clinical prognostication of post-ICU morbidity following ARF, and facilitate the efficiency and clinical relevance of future ARF RCTs by enabling measurement of patients baseline risks for different outcomes. Concurrently, the didactic work, individual study, and hands-on learning in mixed-methods research, natural language processing, and predictive analytics will fill key training gaps for the applicant, thereby positioning him for a successful, independently-funded research career advancing the science of outcomes measurement and analysis for ARF RCTs. PROJECT NARRATIVE Randomized trials testing strategies to improve long-term outcomes for survivors of acute respiratory failure (ARF) are hampered by the lack of valid, patient-centered endpoints. Using interviews with ARF survivors and their caregivers, statistical simulation, consensus building among stakeholders, and a prospective cohort study, the applicant will develop, describe the epidemiology of, and predict a new patient-oriented outcome that will support trials of innovative approaches to improve ARF survivorship outcomes.","Improving the measurement and analysis of long-term, patient-centered outcomes following acute respiratory failure",9681489,K99HL141678,"['Accounting', 'Acute respiratory failure', 'Address', 'Admission activity', 'Algorithms', 'Attention', 'Award', 'Caregivers', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Cognitive', 'Communities', 'Competence', 'Consensus', 'Critical Care', 'Data', 'Electronic Health Record', 'Emotional', 'Enrollment', 'Environmental air flow', 'Epidemiologist', 'Epidemiology', 'Face', 'Faculty', 'Financial Support', 'Funding', 'Future', 'Goals', 'Grant', 'Health', 'Hospital Mortality', 'Hospitals', 'Individual', 'Informatics', 'Intensive Care Units', 'Intervention', 'Interview', 'Lung', 'Machine Learning', 'Measurement', 'Measures', 'Mechanical ventilation', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Preferences', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Physicians', 'Positioning Attribute', 'Predictive Analytics', 'Process', 'Property', 'Prospective Studies', 'Prospective cohort', 'Prospective cohort study', 'Provider', 'Quality of life', 'Randomized Clinical Trials', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Risk', 'Rogaine', 'Sample Size', 'Science', 'Statistical Bias', 'Structure', 'Survivors', 'Testing', 'Time', 'Training', 'Work', 'base', 'care outcomes', 'career', 'clinically relevant', 'cohort', 'design', 'experience', 'hands-on learning', 'high risk', 'improved', 'innovation', 'novel strategies', 'outcome prediction', 'patient oriented', 'patient oriented research', 'prediction algorithm', 'prognostic', 'psychosocial', 'randomized trial', 'recruit', 'residence', 'simulation', 'statistics', 'survivorship', 'tenure track']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K99,2019,108012,0.024974259328124623
"Improving the measurement and analysis of long-term, patient-centered outcomes following acute respiratory failure PROJECT SUMMARY/ABSTRACT This Pathway to Independence Award application is submitted by a pulmonary and critical care epidemiologist committed to improving the quality of patient-oriented research for patients experiencing acute respiratory failure (ARF). Worldwide, millions of patients develop ARF annually. In the U.S., nearly one million patients with ARF require mechanical ventilation annually, accounting for a quarter of all intensive care unit (ICU) admissions. As improvements in ICU care reduce such patients in-hospital mortality rates, attention has shifted to the challenges ARF survivors face in regaining their prior cognitive, physical, and psychosocial functioning. However, there is a key barrier for randomized clinical trials (RCTs) testing new interventions to improve ARF survivorship  that is, the current lack of an endpoint that (1) captures long-term patient dispositions, (2) incorporates patient preferences and perspectives, and (3) is able to be analyzed without concern for statistical biases. The overarching goal of this research is to support clinical innovation by developing new approaches to measure and report long-term patient-centered outcomes that overcome the methodological barriers currently limiting ARF RCTs. The applicant will accomplish his goals under the mentorship of established researchers in critical care, patient-centered outcomes research, statistics, and informatics to assure his transition to a tenure-track faculty position in the R00 phase and his emergence as a leading pulmonary and critical care epidemiologist. First, the applicant will use an innovative combination of qualitative and quantitative research methods to elicit and integrate ARF survivors and their caregivers perspectives into a new patient-centered, long-term composite outcome measure (K99 phase). During the R00 phase, the applicant will recruit ARF survivors to participate in a prospective cohort, and follow these patients to describe the burden of ARF survivorship over 1-year using the new endpoint developed during the K99 phase. This endeavor will also provide key data that will facilitate sample size calculations in future ARF RCTs. Data from this cohort will additionally be used to develop an electronic health record (EHR)-based algorithm to predict risks for adverse long-term outcomes among ARF patients early in their ICU stays. Thus, this K99/R00 will augment ARF research by establishing a new outcome measure anchored in patient perspectives, improving the understanding and clinical prognostication of post-ICU morbidity following ARF, and facilitate the efficiency and clinical relevance of future ARF RCTs by enabling measurement of patients baseline risks for different outcomes. Concurrently, the didactic work, individual study, and hands-on learning in mixed-methods research, natural language processing, and predictive analytics will fill key training gaps for the applicant, thereby positioning him for a successful, independently-funded research career advancing the science of outcomes measurement and analysis for ARF RCTs. PROJECT NARRATIVE Randomized trials testing strategies to improve long-term outcomes for survivors of acute respiratory failure (ARF) are hampered by the lack of valid, patient-centered endpoints. Using interviews with ARF survivors and their caregivers, statistical simulation, consensus building among stakeholders, and a prospective cohort study, the applicant will develop, describe the epidemiology of, and predict a new patient-oriented outcome that will support trials of innovative approaches to improve ARF survivorship outcomes.","Improving the measurement and analysis of long-term, patient-centered outcomes following acute respiratory failure",9505095,K99HL141678,"['Accounting', 'Acute respiratory failure', 'Address', 'Admission activity', 'Algorithms', 'Attention', 'Award', 'Caregivers', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Cognitive', 'Communities', 'Competence', 'Consensus', 'Critical Care', 'Data', 'Electronic Health Record', 'Emotional', 'Enrollment', 'Environmental air flow', 'Epidemiologist', 'Epidemiology', 'Face', 'Faculty', 'Financial Support', 'Funding', 'Future', 'Goals', 'Grant', 'Health', 'Hospital Mortality', 'Hospitals', 'Individual', 'Informatics', 'Intensive Care Units', 'Intervention', 'Interview', 'Lung', 'Machine Learning', 'Measurement', 'Measures', 'Mechanical ventilation', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monte Carlo Method', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Preferences', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Physicians', 'Positioning Attribute', 'Predictive Analytics', 'Process', 'Property', 'Prospective Studies', 'Prospective cohort', 'Prospective cohort study', 'Provider', 'Quality of life', 'Randomized Clinical Trials', 'Reporting', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Risk', 'Rogaine', 'Sample Size', 'Science', 'Statistical Bias', 'Structure', 'Survivors', 'Testing', 'Time', 'Training', 'Work', 'base', 'care outcomes', 'career', 'clinically relevant', 'cohort', 'design', 'experience', 'hands-on learning', 'high risk', 'improved', 'innovation', 'novel strategies', 'outcome prediction', 'patient oriented', 'patient oriented research', 'prediction algorithm', 'prognostic', 'psychosocial', 'randomized trial', 'recruit', 'residence', 'simulation', 'statistics', 'survivorship', 'tenure track']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K99,2018,105743,0.024974259328124623
"Early Warning Method and Technologies for Improving Cancer Care and Targeted Inte    DESCRIPTION (provided by applicant): Substantial evidence gathered over the last 50 years shows that adherence poses a crucial barrier to effective treatment and survival for cancer and other chronic diseases. At least one in five cancer patients do not adhere to treatment regimen, with much higher disease-specific rates. This non-adherence, or deviation from the recommended and expected clinical path, can dramatically increase costs of care, hospitalizations, adverse outcomes and the chance of preventable death. What causes non-adherence to treatment regimens is currently not rigorously understood. Current adherence research methods largely rely on survey instruments that have limited scale and scope, provide lagging information that inhibits timely intervention, and offer little actionable information to help patients to adhere to their care regimens. Further, the nature and timing of intervention to improve adherence have not been researched in depth. With continuous changes in cancer treatment, newer proactive approaches and methods for surveillance of patient adherence and targeted interventions are needed. In this project, we examine the feasibility and validity of a novel approach that uses a computational model to glean fine-grained attributes of cancer patients from standard electronic medical records. Our preliminary work has shown that electronic records to contain free-form text describing patient sentiment, vitals, medical condition, side effects, social history and family status written by physicians, nurses, medical assistants, and other staff during every visit encounter. With the steady adoption of electronic medical records by clinicians across the US (currently 29% and rising at 12% per year), clinical notes found in electronic records offer a tantalizing source of insight into patient adherence and behavior. Current adherence research has not tapped this rich source of data, even though many disciplines including biomedical informatics have employed natural language processing and text-mining techniques to glean patterns in semi- structured biomedical data. We aim to employ similar but novel, scalable computational models to glean a rich set of risk factors for patient non-adherence from 1 million patient encounter records, corresponding to 24,050 patients that span a 10 year time-horizon. Our objectives are to estimate the risk of a patient's ability to adhere to a prescribed regimen and enable targeted and timely interventions by using computational analysis of unstructured and structured fields in standard clinical documentation.  PUBLIC HEALTH RELEVANCE: We aim to show the feasibility of an early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.                        Project Narrative We aim to show the feasibility of an early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.  ",Early Warning Method and Technologies for Improving Cancer Care and Targeted Inte,7746912,R43CA141899,"['Adherence', 'Adoption', 'Adverse effects', 'Behavior', 'Behavioral', 'Cancer Patient', 'Caring', 'Cereals', 'Cessation of life', 'Chronic Disease', 'Clinical', 'Clinical Paths', 'Clinical Trials', 'Community Clinical Oncology Program', 'Computer Analysis', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Set', 'Data Sources', 'Discipline', 'Disease', 'Documentation', 'Electronics', 'Emotional', 'Employment', 'Family history of', 'Glean', 'Hospitalization', 'Individual', 'Intervention', 'Malignant Neoplasms', 'Medical', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Nurses', 'Nutritionist', 'Outcome', 'Patient Noncompliance', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Psychologist', 'Quality of Care', 'Records', 'Research', 'Research Methodology', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scientific Advances and Accomplishments', 'Semantics', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Social Workers', 'Source', 'Structure', 'Surveillance Methods', 'Surveys', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Treatment Protocols', 'Visit', 'Weight', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer care', 'cancer therapy', 'clinical practice', 'compliance behavior', 'cost', 'effective therapy', 'follow-up', 'improved', 'innovation', 'insight', 'mathematical algorithm', 'novel', 'novel strategies', 'patient safety', 'psychologic', 'public health relevance', 'social', 'text searching']",NCI,"360FRESH, INC.",R43,2009,100000,0.04676623781275942
"Autonomous diagnosis and management of the critically ill during air transport (ADMIT) Project Summary/Abstract: Cardiorespiratory instability (CRI) is common in trauma patients and other acutely ill patients being transferred from trauma sites or between hospital centers. Although paramedics/nurses (PM/RN) have some success in rescuing unstable patients with CRI using defined protocols and decrease incidence of inter-transport severe circulatory shock, the shock recognition tools available and resuscitation endpoints are limited to blood pressure and heart rate thresholds. However, CRI is often unrecognized until it is well established when patients are more refractory to treatment, or progressed to organ injury. If one could accurately predict who, when and why these critically ill patients develop CRI, then effective preemptive treatments could be given to improve care and triage resulting in better use of healthcare resources. We have shown that an integrated monitoring system alert obtained from continuous noninvasively acquired monitoring parameters coupled to a care algorithm improved step-down unit (SDU) patient outcomes. We also applied machine learning (ML) modeling to our clinically-relevant porcine model of hemorrhagic shock to characterize responses to hypovolemia, hemorrhage, and resuscitation, predict which animals would or would not collapse during hypovolemia, and identify occult bleeding 5 minutes earlier than with traditional monitoring. We now propose to apply our work to vulnerable STAT MedEvac air transported patients. We will validate these approaches in our existing >5,000 patient STAT MedEvac database, containing highly granular continuous non-invasive monitoring waveforms of air transported critically ill patients linked to their primary care and inpatient electronic health records (EHR). This level of patient information and granularity linked to treatment data and patient outcomes is unprecedented. We will extend our analysis to include more complex CRI, richer data, deeper analytics, and larger libraries of critically ill patients while in air transport, linking our proven Functional Hemodynamic Monitoring (FHM) principles for pathophysiologic diagnosis and resuscitation with non-invasive monitoring to operationalize personalized resuscitation. We will concurrently running two specific aims. First, we will develop through the Carnegie Melon University Auton Lab multivariable models through ML data-driven classification techniques to predict CRI. We will do this initially on our existing porcine hemorrhagic shock model data (n=60) and then on our STAT MedEvac dataset linked to EHR (n >5,000 patients), determining the minimal data (measures, sampling frequency, observation duration) required to robustly identify deviation from health, likely CRI cause, and response to treatment (endpoint of resuscitation), as well as the incremental benefit of additional variables, analysis, lead-time and sampling frequency to predict CRI and response to treatment, and examine the trade-offs between model parsimony and specificity. Second, we will evaluate our existing clinical decision support (CDS) tools to interface with FHM principles and ML- defined interactions, and trial this in silico first on our porcine hemorrhagic shock resuscitation, then on our STAT MedEvac data, followed by prospective human simulation on flight crew PM/RN (n=160) during annual training for agreement and benefit, defining effectiveness based on diagnosis accuracy, time to diagnosis, intervention choice accuracy and time to intervention. This iterative process will modify the existing CDS platform into one more specifically suited for air transport scenarios. Finally, we will evaluate the resultant semi-autonomous management protocol initially in retrospect in 100 STAT MedEvac patients and 10 Emergency Department trauma patients and then prospectively by active CDS in a final 100 STAT MedEvac patients. We will prospectively analyze the effectiveness of these calibrated CDS tools for predictive ability of the various ML models and apply the best, most practical and parsimonious predictive models for clinical care during transport based on patient population, pathological processes and support staff. Project narrative We propose to develop and trial of proactive approach to diagnosis and management of vulnerable critically ill patients during STAT MedEvac air transport from trauma sites and inter-hospital transfer. We will use machine learning approaches to plumb our existing rich >5500 patient STAT MedEvac waveform data linked to their electronic health records to define level of severity, predict impending cardiovascular instability and to both drive in-flight resuscitation and alert receiving Emergency Department triage. We will use our existing clinically relevant porcine model of hemorrhagic shock to focus initial human instability algorithms and then refine our existing graph user interface clinical decisions support (CDS) algorithm, first in animal and with paramedic/nurse dyads in human simulation and then during actual STAT MedEvac air transport and Emergency Department care of trauma patients creating a scalable CDS platform to support paramedic/nurse smart monitoring and proactive resuscitation of these high risk patients.",Autonomous diagnosis and management of the critically ill during air transport (ADMIT),9738159,R01HL141916,"['Accident and Emergency department', 'Acute', 'Agreement', 'Air', 'Algorithms', 'Animals', 'Blood Pressure', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical Treatment', 'Complex', 'Computer Simulation', 'Coupled', 'Critical Illness', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Emergency Care', 'Emergency Department Physician', 'Environment', 'Family suidae', 'Frequencies', 'Graph', 'Health', 'Healthcare', 'Heart Rate', 'Hemorrhage', 'Hemorrhagic Shock', 'Hospitals', 'Human', 'Hypovolemia', 'Incidence', 'Injury', 'Inpatients', 'Intervention', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Measures', 'Mechanical ventilation', 'Medical', 'Melons', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Normal Range', 'Nurses', 'Organ', 'Organ failure', 'Paramedical Personnel', 'Pathologic Processes', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physiological', 'Primary Health Care', 'Process', 'Protocols documentation', 'Records', 'Refractory', 'Resources', 'Resuscitation', 'Running', 'Sampling', 'Sepsis', 'Series', 'Serious Adverse Event', 'Severities', 'Shock', 'Site', 'Specificity', 'Standardization', 'Stream', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Trauma', 'Trauma patient', 'Traumatic Hemorrhage', 'Triage', 'Universities', 'Validation', 'Weaning', 'Work', 'advanced system', 'base', 'clinical care', 'clinical decision support', 'clinically relevant', 'cost', 'data modeling', 'demographics', 'diagnostic accuracy', 'hemodynamics', 'high risk', 'improved', 'indexing', 'insight', 'iterative design', 'mortality', 'non-invasive monitor', 'patient population', 'predictive modeling', 'predictive tools', 'prospective', 'response', 'signal processing', 'simulation', 'success', 'support tools', 'tool', 'treatment response']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,763789,0.015639983278878906
"Autonomous diagnosis and management of the critically ill during air transport (ADMIT) Project Summary/Abstract: Cardiorespiratory instability (CRI) is common in trauma patients and other acutely ill patients being transferred from trauma sites or between hospital centers. Although paramedics/nurses (PM/RN) have some success in rescuing unstable patients with CRI using defined protocols and decrease incidence of inter-transport severe circulatory shock, the shock recognition tools available and resuscitation endpoints are limited to blood pressure and heart rate thresholds. However, CRI is often unrecognized until it is well established when patients are more refractory to treatment, or progressed to organ injury. If one could accurately predict who, when and why these critically ill patients develop CRI, then effective preemptive treatments could be given to improve care and triage resulting in better use of healthcare resources. We have shown that an integrated monitoring system alert obtained from continuous noninvasively acquired monitoring parameters coupled to a care algorithm improved step-down unit (SDU) patient outcomes. We also applied machine learning (ML) modeling to our clinically-relevant porcine model of hemorrhagic shock to characterize responses to hypovolemia, hemorrhage, and resuscitation, predict which animals would or would not collapse during hypovolemia, and identify occult bleeding 5 minutes earlier than with traditional monitoring. We now propose to apply our work to vulnerable STAT MedEvac air transported patients. We will validate these approaches in our existing >5,000 patient STAT MedEvac database, containing highly granular continuous non-invasive monitoring waveforms of air transported critically ill patients linked to their primary care and inpatient electronic health records (EHR). This level of patient information and granularity linked to treatment data and patient outcomes is unprecedented. We will extend our analysis to include more complex CRI, richer data, deeper analytics, and larger libraries of critically ill patients while in air transport, linking our proven Functional Hemodynamic Monitoring (FHM) principles for pathophysiologic diagnosis and resuscitation with non-invasive monitoring to operationalize personalized resuscitation. We will concurrently running two specific aims. First, we will develop through the Carnegie Melon University Auton Lab multivariable models through ML data-driven classification techniques to predict CRI. We will do this initially on our existing porcine hemorrhagic shock model data (n=60) and then on our STAT MedEvac dataset linked to EHR (n >5,000 patients), determining the minimal data (measures, sampling frequency, observation duration) required to robustly identify deviation from health, likely CRI cause, and response to treatment (endpoint of resuscitation), as well as the incremental benefit of additional variables, analysis, lead-time and sampling frequency to predict CRI and response to treatment, and examine the trade-offs between model parsimony and specificity. Second, we will evaluate our existing clinical decision support (CDS) tools to interface with FHM principles and ML- defined interactions, and trial this in silico first on our porcine hemorrhagic shock resuscitation, then on our STAT MedEvac data, followed by prospective human simulation on flight crew PM/RN (n=160) during annual training for agreement and benefit, defining effectiveness based on diagnosis accuracy, time to diagnosis, intervention choice accuracy and time to intervention. This iterative process will modify the existing CDS platform into one more specifically suited for air transport scenarios. Finally, we will evaluate the resultant semi-autonomous management protocol initially in retrospect in 100 STAT MedEvac patients and 10 Emergency Department trauma patients and then prospectively by active CDS in a final 100 STAT MedEvac patients. We will prospectively analyze the effectiveness of these calibrated CDS tools for predictive ability of the various ML models and apply the best, most practical and parsimonious predictive models for clinical care during transport based on patient population, pathological processes and support staff. Project narrative We propose to develop and trial of proactive approach to diagnosis and management of vulnerable critically ill patients during STAT MedEvac air transport from trauma sites and inter-hospital transfer. We will use machine learning approaches to plumb our existing rich >5500 patient STAT MedEvac waveform data linked to their electronic health records to define level of severity, predict impending cardiovascular instability and to both drive in-flight resuscitation and alert receiving Emergency Department triage. We will use our existing clinically relevant porcine model of hemorrhagic shock to focus initial human instability algorithms and then refine our existing graph user interface clinical decisions support (CDS) algorithm, first in animal and with paramedic/nurse dyads in human simulation and then during actual STAT MedEvac air transport and Emergency Department care of trauma patients creating a scalable CDS platform to support paramedic/nurse smart monitoring and proactive resuscitation of these high risk patients.",Autonomous diagnosis and management of the critically ill during air transport (ADMIT),9912846,R01HL141916,"['Accident and Emergency department', 'Acute', 'Agreement', 'Air', 'Algorithms', 'Animals', 'Blood Pressure', 'Cardiovascular system', 'Caring', 'Classification', 'Clinical Treatment', 'Complex', 'Coupled', 'Critical Illness', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Emergency Care', 'Emergency Department Physician', 'Environment', 'Family suidae', 'Frequencies', 'Graph', 'Health', 'Healthcare', 'Heart Rate', 'Hemorrhage', 'Hemorrhagic Shock', 'Hospitals', 'Human', 'Hypovolemia', 'Incidence', 'Inpatients', 'Intervention', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Measures', 'Mechanical ventilation', 'Medical', 'Melons', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Normal Range', 'Nurses', 'Organ failure', 'Paramedical Personnel', 'Pathologic Processes', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Physiological', 'Primary Health Care', 'Process', 'Protocols documentation', 'Records', 'Refractory', 'Resources', 'Resuscitation', 'Running', 'Sampling', 'Sepsis', 'Series', 'Serious Adverse Event', 'Severities', 'Shock', 'Site', 'Specificity', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Trauma', 'Trauma patient', 'Traumatic Hemorrhage', 'Triage', 'Universities', 'Validation', 'Weaning', 'Work', 'advanced system', 'base', 'clinical care', 'clinical decision support', 'clinically relevant', 'cost', 'data modeling', 'data streams', 'demographics', 'diagnostic accuracy', 'effectiveness evaluation', 'hemodynamics', 'high risk', 'improved', 'in silico', 'indexing', 'insight', 'iterative design', 'mortality', 'non-invasive monitor', 'organ injury', 'patient population', 'predictive modeling', 'predictive tools', 'prospective', 'response', 'signal processing', 'simulation', 'success', 'support tools', 'tool', 'treatment response']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,761406,0.015639983278878906
"Identifying palliative care needs among hospitalized patients with chronic obstructive pulmonary disease PROJECT SUMMARY Millions of Americans with COPD experience burdensome symptoms, reduced quality of life, and undesirable end-of-life care. Increasing palliative care for this vulnerable population is widely advocated to improve these important patient-centered outcomes. Yet patients with COPD rarely receive palliative care due, in part, to difficulties identifying which patients have unmet palliative care needs and palliative care workforce shortages. The proposed study's core objective is to address the national priority of improving palliative care for patients with COPD by developing an efficient, innovative, and patient-centered method to identify those with unmet palliative care needs. Specifically, the candidate seeks to (1) assess patients with COPD to determine their palliative care needs; (2) develop and validate an electronic health record-based classification model for each domain of palliative care needs; and (3) evaluate the relationship between the probability of having unmet palliative care needs and patient-centered clinical outcomes. The study will involve an in-person cross- sectional survey of 432 hospitalized patients with COPD of any stage. Participants will complete a validated survey to capture a wide variety of palliative care needs, which will be supplemented with expert chart review to identify patients with needs in any of three clinically relevant and actionable domains. These cases will be used as the patient-reported reference standard for development and validation of domain-specific classification models leveraging natural language processing of unstructured clinical text in electronic health records and machine learning methods. Finally, a large, multicenter retrospective cohort study will evaluate the associations between different probabilities of having unmet palliative care needs and several clinical outcomes important to patients, caregivers, and hospitals. This will enable the identification of thresholds of probabilities of unmet needs above which COPD patients' risks of undesirable clinical outcomes increase. Such patients will then be targeted for enrollment in future trials testing interventions to improve these outcomes. Completion of this research will build upon the candidate's past training, which includes a Masters in Health Policy Research obtained with NHLBI T32 support, an F32-supported post-doctoral fellowship, and a career development award from the National Palliative Care Research Center, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. The candidate's rigorous training plan, focused on obtaining advanced skills in multisite prospective research, patient-centered outcomes research, and advanced bioinformatics methods will allow her to submit successful R01 or PCORI applications testing interventions directly informed by the results of this work. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a supportive environment for her to develop an independent research career focused on improving the uptake and effectiveness of palliative care for patients with COPD and other cardiopulmonary diseases. PROJECT NARRATIVE Patients with COPD experience burdensome symptoms, reduced quality of life, and low quality end-of-life care. Palliative care may improve such outcomes, yet resources are strained and it is difficult to identify which patients are most in need. The aims of this research are to provide new knowledge regarding the unmet palliative care needs of patients with COPD and to develop a novel and scalable method to identify patients with such needs in order to reduce patients' suffering and improve quality of life.",Identifying palliative care needs among hospitalized patients with chronic obstructive pulmonary disease,9746515,K23HL143181,"['Address', 'Adherence', 'Advocate', 'Age', 'American', 'Award', 'Beds', 'Bioinformatics', 'Calibration', 'Caregivers', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Clinical Research', 'Comorbidity', 'Consult', 'Cross-Sectional Studies', 'Data', 'Data Reporting', 'Data Sources', 'Development', 'Discrimination', 'Disease', 'Distress', 'Education', 'Educational process of instructing', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Fellowship', 'Future', 'Goals', 'Health Policy', 'Hospitals', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Machine Learning', 'Manuals', 'Marital Status', 'Medical', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nurses', 'Observational Study', 'Outcome', 'Outcomes Research', 'Palliative Care', 'Participant', 'Patient Care', 'Patient Outcomes Assessments', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Persons', 'Physicians', 'Policy Research', 'Postdoctoral Fellow', 'Prevalence', 'Probability', 'Process', 'Professional Organizations', 'Pulmonary Heart Disease', 'Quality of life', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Retrospective cohort study', 'Risk', 'Sampling', 'Site', 'Social Work', 'Social support', 'Structure', 'Surveys', 'Symptoms', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'Triage', 'Validation', 'Visit', 'Vulnerable Populations', 'Work', 'base', 'career', 'clinically actionable', 'clinically relevant', 'cohort', 'end of life', 'end of life care', 'experience', 'functional status', 'hospital services', 'improved', 'improved outcome', 'innovation', 'learning strategy', 'medical specialties', 'novel', 'patient oriented', 'physical symptom', 'prospective', 'psychosocial', 'randomized trial', 'readmission rates', 'recruit', 'skills', 'study population', 'supportive environment', 'uptake']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2019,174140,0.032271634392460904
"Identifying palliative care needs among hospitalized patients with chronic obstructive pulmonary disease PROJECT SUMMARY Millions of Americans with COPD experience burdensome symptoms, reduced quality of life, and undesirable end-of-life care. Increasing palliative care for this vulnerable population is widely advocated to improve these important patient-centered outcomes. Yet patients with COPD rarely receive palliative care due, in part, to difficulties identifying which patients have unmet palliative care needs and palliative care workforce shortages. The proposed study's core objective is to address the national priority of improving palliative care for patients with COPD by developing an efficient, innovative, and patient-centered method to identify those with unmet palliative care needs. Specifically, the candidate seeks to (1) assess patients with COPD to determine their palliative care needs; (2) develop and validate an electronic health record-based classification model for each domain of palliative care needs; and (3) evaluate the relationship between the probability of having unmet palliative care needs and patient-centered clinical outcomes. The study will involve an in-person cross- sectional survey of 432 hospitalized patients with COPD of any stage. Participants will complete a validated survey to capture a wide variety of palliative care needs, which will be supplemented with expert chart review to identify patients with needs in any of three clinically relevant and actionable domains. These cases will be used as the patient-reported reference standard for development and validation of domain-specific classification models leveraging natural language processing of unstructured clinical text in electronic health records and machine learning methods. Finally, a large, multicenter retrospective cohort study will evaluate the associations between different probabilities of having unmet palliative care needs and several clinical outcomes important to patients, caregivers, and hospitals. This will enable the identification of thresholds of probabilities of unmet needs above which COPD patients' risks of undesirable clinical outcomes increase. Such patients will then be targeted for enrollment in future trials testing interventions to improve these outcomes. Completion of this research will build upon the candidate's past training, which includes a Masters in Health Policy Research obtained with NHLBI T32 support, an F32-supported post-doctoral fellowship, and a career development award from the National Palliative Care Research Center, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. The candidate's rigorous training plan, focused on obtaining advanced skills in multisite prospective research, patient-centered outcomes research, and advanced bioinformatics methods will allow her to submit successful R01 or PCORI applications testing interventions directly informed by the results of this work. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a supportive environment for her to develop an independent research career focused on improving the uptake and effectiveness of palliative care for patients with COPD and other cardiopulmonary diseases. PROJECT NARRATIVE Patients with COPD experience burdensome symptoms, reduced quality of life, and low quality end-of-life care. Palliative care may improve such outcomes, yet resources are strained and it is difficult to identify which patients are most in need. The aims of this research are to provide new knowledge regarding the unmet palliative care needs of patients with COPD and to develop a novel and scalable method to identify patients with such needs in order to reduce patients' suffering and improve quality of life.",Identifying palliative care needs among hospitalized patients with chronic obstructive pulmonary disease,10004708,K23HL143181,"['Address', 'Adherence', 'Advocate', 'Age', 'American', 'Award', 'Beds', 'Bioinformatics', 'Calibration', 'Caregivers', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Clinical Research', 'Consult', 'Cross-Sectional Studies', 'Data', 'Data Reporting', 'Data Sources', 'Development', 'Discrimination', 'Disease', 'Distress', 'Education', 'Educational process of instructing', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Fellowship', 'Future', 'Goals', 'Health Policy', 'Hospitals', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Machine Learning', 'Manuals', 'Marital Status', 'Medical', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nurses', 'Observational Study', 'Outcome', 'Outcomes Research', 'Palliative Care', 'Participant', 'Patient Care', 'Patient Outcomes Assessments', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Persons', 'Physicians', 'Policy Research', 'Postdoctoral Fellow', 'Prevalence', 'Probability', 'Process', 'Professional Organizations', 'Pulmonary Heart Disease', 'Quality of life', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Retrospective cohort study', 'Risk', 'Sampling', 'Site', 'Social Work', 'Social support', 'Structure', 'Surveys', 'Symptoms', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'Triage', 'Validation', 'Visit', 'Vulnerable Populations', 'Work', 'base', 'career', 'clinical center', 'clinically actionable', 'clinically relevant', 'cohort', 'comorbidity', 'end of life', 'end of life care', 'experience', 'functional status', 'hospital services', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'medical specialties', 'novel', 'patient oriented', 'physical symptom', 'prospective', 'psychosocial', 'randomized trial', 'readmission rates', 'recruit', 'skills', 'study population', 'supportive environment', 'unstructured data', 'uptake']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2020,173628,0.032271634392460904
"Identifying palliative care needs among hospitalized patients with chronic obstructive pulmonary disease PROJECT SUMMARY Millions of Americans with COPD experience burdensome symptoms, reduced quality of life, and undesirable end-of-life care. Increasing palliative care for this vulnerable population is widely advocated to improve these important patient-centered outcomes. Yet patients with COPD rarely receive palliative care due, in part, to difficulties identifying which patients have unmet palliative care needs and palliative care workforce shortages. The proposed study's core objective is to address the national priority of improving palliative care for patients with COPD by developing an efficient, innovative, and patient-centered method to identify those with unmet palliative care needs. Specifically, the candidate seeks to (1) assess patients with COPD to determine their palliative care needs; (2) develop and validate an electronic health record-based classification model for each domain of palliative care needs; and (3) evaluate the relationship between the probability of having unmet palliative care needs and patient-centered clinical outcomes. The study will involve an in-person cross- sectional survey of 432 hospitalized patients with COPD of any stage. Participants will complete a validated survey to capture a wide variety of palliative care needs, which will be supplemented with expert chart review to identify patients with needs in any of three clinically relevant and actionable domains. These cases will be used as the patient-reported reference standard for development and validation of domain-specific classification models leveraging natural language processing of unstructured clinical text in electronic health records and machine learning methods. Finally, a large, multicenter retrospective cohort study will evaluate the associations between different probabilities of having unmet palliative care needs and several clinical outcomes important to patients, caregivers, and hospitals. This will enable the identification of thresholds of probabilities of unmet needs above which COPD patients' risks of undesirable clinical outcomes increase. Such patients will then be targeted for enrollment in future trials testing interventions to improve these outcomes. Completion of this research will build upon the candidate's past training, which includes a Masters in Health Policy Research obtained with NHLBI T32 support, an F32-supported post-doctoral fellowship, and a career development award from the National Palliative Care Research Center, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. The candidate's rigorous training plan, focused on obtaining advanced skills in multisite prospective research, patient-centered outcomes research, and advanced bioinformatics methods will allow her to submit successful R01 or PCORI applications testing interventions directly informed by the results of this work. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a supportive environment for her to develop an independent research career focused on improving the uptake and effectiveness of palliative care for patients with COPD and other cardiopulmonary diseases. PROJECT NARRATIVE Patients with COPD experience burdensome symptoms, reduced quality of life, and low quality end-of-life care. Palliative care may improve such outcomes, yet resources are strained and it is difficult to identify which patients are most in need. The aims of this research are to provide new knowledge regarding the unmet palliative care needs of patients with COPD and to develop a novel and scalable method to identify patients with such needs in order to reduce patients' suffering and improve quality of life.",Identifying palliative care needs among hospitalized patients with chronic obstructive pulmonary disease,9582440,K23HL143181,"['Address', 'Adherence', 'Advocate', 'Age', 'American', 'Award', 'Beds', 'Bioinformatics', 'Calibration', 'Caregivers', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Clinical Research', 'Comorbidity', 'Consult', 'Cross-Sectional Studies', 'Data', 'Data Reporting', 'Data Sources', 'Development', 'Discrimination', 'Disease', 'Distress', 'Education', 'Educational process of instructing', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Fellowship', 'Future', 'Goals', 'Health Policy', 'Hospitals', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Machine Learning', 'Manuals', 'Marital Status', 'Medical', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nurses', 'Observational Study', 'Outcome', 'Outcomes Research', 'Palliative Care', 'Participant', 'Patient Care', 'Patient Outcomes Assessments', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Persons', 'Physicians', 'Policy Research', 'Postdoctoral Fellow', 'Prevalence', 'Probability', 'Process', 'Professional Organizations', 'Pulmonary Heart Disease', 'Quality of life', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Retrospective cohort study', 'Risk', 'Sampling', 'Site', 'Social Work', 'Social support', 'Structure', 'Surveys', 'Symptoms', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'Triage', 'Validation', 'Visit', 'Vulnerable Populations', 'Work', 'base', 'career', 'clinically actionable', 'clinically relevant', 'cohort', 'collaborative environment', 'end of life', 'end of life care', 'experience', 'functional status', 'hospital readmission', 'hospital services', 'improved', 'improved outcome', 'innovation', 'learning strategy', 'medical specialties', 'novel', 'patient oriented', 'physical symptom', 'prospective', 'psychosocial', 'randomized trial', 'recruit', 'skills', 'study population', 'uptake']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2018,174635,0.032271634392460904
"Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data PROJECT SUMMARY An estimated 47% of Americans 65 years of age and older take statins, which are highly effective in lowering low-density lipoprotein (LDL) cholesterol, preventing atherosclerotic cardiovascular disease (ASCVD), and reducing all-cause mortality. Unfortunately, ~50% of patients prescribed statins do not obtain these critical benefits because they discontinue use within 1 year of treatment initiation. There, Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with ASCVD. In clinical practice, statin-associated symptoms (SAS) often result in dose reduction or discontinuation of these life-saving medications. Currently, physicians employ reactive strategies to manage SAS concerns after they manifest, such as offering an alternative statin treatment plan (e.g., reducing dosage or changing medication) or a `statin holiday'. However, with numerous statin treatment strategies available and no means of optimizing their match to a given patient, physician decision-making is based on minimal patient data elements. Moreover, using a single patient's data to identify the optimal statin regimen and treatment plan is inadequate to ensure that the harms of statin use are minimized and the benefits are maximized. A decision- support system, by contrast, can use a vast number of variables from a large number of patients (big data) to match an optimal statin treatment plan to an individual patient prospectively. We propose to use complex patient information to develop and test an effective predictive model and tool, the personalized statin treatment plan (PSTP) platform, which could be used by physicians to optimize personalized statin treatment to minimize harms (SAS and statin discontinuation) while at the same time maximizing benefits (LDL reduction). The proposed study leverages data from the OptumLabs Data Warehouse (which includes more than 20 years of insurance claims and electronic health records data from more than 150 million patients across the United States), as well as clinical trial simulations, for model development, validation, and evaluation. We will address the following specific aims: 1) Develop and validate a deep-learning model to predict both SAS and statin discontinuation using linked insurance claims and EHR data; 2) Develop and validate the PSTP platform to identify statin treatment plans that optimize both LDL reduction (benefit) and SAS and statin discontinuation (harm) for a given patient profile; and 3) Evaluate the PSTP relative to current and guideline-driven practices using CTS to assess clinical benefits and harms. The proposed study will produce a precision-medicine tool to empower physicians to make proactive clinical decisions regarding statin treatment planning (i.e., selecting the statin drug and dosage optimized for a particular patient to maximize LDL reduction and minimize statin discontinuation and SAS) before any statin is prescribed. The implementation of such a tool would substantially improve public health by reducing statin discontinuation and sub-optimal clinical outcomes inherent in current reactive statin-prescribing strategies based on non-personalized statin treatment plans. PROJECT NARRATIVE About 50% of patients prescribed statins do not obtain critical benefits in lowering low-density lipoprotein cholesterol, preventing atherosclerotic cardiovascular disease, and reducing all-cause mortality because they discontinue use within 1 year of treatment initiation largely due to statin-associated symptoms. Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with atherosclerotic cardiovascular disease. The proposed study will produce a personalized (precision)-medicine tool using big data to empower physicians to make proactive clinical decisions for prescribing statins that will maximize LDL reduction and minimize statin discontinuation and statin-associated symptoms.",Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data,9869932,R01HL143390,"['Address', 'Adverse event', 'Age-Years', 'Algorithms', 'American', 'Atherosclerosis', 'Big Data', 'Blood', 'Cardiology', 'Characteristics', 'Cholesterol', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Element', 'Data Set', 'Decision Making', 'Decision Support Systems', 'Dose', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Evaluation', 'Goals', 'Guidelines', 'Harm Reduction', 'Health Care Costs', 'Holidays', 'Individual', 'Internet', 'LDL Cholesterol Lipoproteins', 'Life', 'Link', 'Low-Density Lipoproteins', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physicians', 'Positioning Attribute', 'Preventive', 'Public Health', 'Regimen', 'Research', 'Savings', 'Surveys', 'Testing', 'Time', 'Treatment Protocols', 'United States', 'Validation', 'Work', 'associated symptom', 'base', 'clinical practice', 'cohort', 'comorbidity', 'data warehouse', 'deep learning', 'dosage', 'experience', 'improved', 'individual patient', 'insurance claims', 'model development', 'mortality', 'novel', 'personalized intervention', 'personalized medicine', 'precision medicine', 'predictive modeling', 'predictive tools', 'prevent', 'profiles in patients', 'prospective', 'response', 'simulation', 'success', 'tool', 'treatment guidelines', 'treatment planning', 'treatment strategy']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2020,758900,0.00932887429544186
"Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data PROJECT SUMMARY An estimated 47% of Americans 65 years of age and older take statins, which are highly effective in lowering low-density lipoprotein (LDL) cholesterol, preventing atherosclerotic cardiovascular disease (ASCVD), and reducing all-cause mortality. Unfortunately, ~50% of patients prescribed statins do not obtain these critical benefits because they discontinue use within 1 year of treatment initiation. There, Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with ASCVD. In clinical practice, statin-associated symptoms (SAS) often result in dose reduction or discontinuation of these life-saving medications. Currently, physicians employ reactive strategies to manage SAS concerns after they manifest, such as offering an alternative statin treatment plan (e.g., reducing dosage or changing medication) or a `statin holiday'. However, with numerous statin treatment strategies available and no means of optimizing their match to a given patient, physician decision-making is based on minimal patient data elements. Moreover, using a single patient's data to identify the optimal statin regimen and treatment plan is inadequate to ensure that the harms of statin use are minimized and the benefits are maximized. A decision- support system, by contrast, can use a vast number of variables from a large number of patients (big data) to match an optimal statin treatment plan to an individual patient prospectively. We propose to use complex patient information to develop and test an effective predictive model and tool, the personalized statin treatment plan (PSTP) platform, which could be used by physicians to optimize personalized statin treatment to minimize harms (SAS and statin discontinuation) while at the same time maximizing benefits (LDL reduction). The proposed study leverages data from the OptumLabs Data Warehouse (which includes more than 20 years of insurance claims and electronic health records data from more than 150 million patients across the United States), as well as clinical trial simulations, for model development, validation, and evaluation. We will address the following specific aims: 1) Develop and validate a deep-learning model to predict both SAS and statin discontinuation using linked insurance claims and EHR data; 2) Develop and validate the PSTP platform to identify statin treatment plans that optimize both LDL reduction (benefit) and SAS and statin discontinuation (harm) for a given patient profile; and 3) Evaluate the PSTP relative to current and guideline-driven practices using CTS to assess clinical benefits and harms. The proposed study will produce a precision-medicine tool to empower physicians to make proactive clinical decisions regarding statin treatment planning (i.e., selecting the statin drug and dosage optimized for a particular patient to maximize LDL reduction and minimize statin discontinuation and SAS) before any statin is prescribed. The implementation of such a tool would substantially improve public health by reducing statin discontinuation and sub-optimal clinical outcomes inherent in current reactive statin-prescribing strategies based on non-personalized statin treatment plans. PROJECT NARRATIVE About 50% of patients prescribed statins do not obtain critical benefits in lowering low-density lipoprotein cholesterol, preventing atherosclerotic cardiovascular disease, and reducing all-cause mortality because they discontinue use within 1 year of treatment initiation largely due to statin-associated symptoms. Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with atherosclerotic cardiovascular disease. The proposed study will produce a personalized (precision)-medicine tool using big data to empower physicians to make proactive clinical decisions for prescribing statins that will maximize LDL reduction and minimize statin discontinuation and statin-associated symptoms.",Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data,9684080,R01HL143390,"['Address', 'Adverse event', 'Age-Years', 'Algorithms', 'American', 'Atherosclerosis', 'Big Data', 'Blood', 'Cardiology', 'Characteristics', 'Cholesterol', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Comorbidity', 'Complex', 'Data', 'Data Element', 'Data Set', 'Decision Making', 'Decision Support Systems', 'Dose', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Evaluation', 'Goals', 'Guidelines', 'Harm Reduction', 'Health Care Costs', 'Holidays', 'Individual', 'Internet', 'LDL Cholesterol Lipoproteins', 'Life', 'Link', 'Low-Density Lipoproteins', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physicians', 'Positioning Attribute', 'Preventive', 'Public Health', 'Regimen', 'Research', 'Savings', 'Surveys', 'Testing', 'Time', 'Treatment Protocols', 'United States', 'Validation', 'Work', 'associated symptom', 'base', 'clinical practice', 'cohort', 'data warehouse', 'deep learning', 'dosage', 'experience', 'improved', 'individual patient', 'insurance claims', 'model development', 'mortality', 'novel', 'personalized intervention', 'personalized medicine', 'precision medicine', 'predictive modeling', 'predictive tools', 'prevent', 'profiles in patients', 'prospective', 'response', 'simulation', 'success', 'tool', 'treatment guidelines', 'treatment planning', 'treatment strategy']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2019,782736,0.00932887429544186
"USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING    DESCRIPTION (provided by applicant): Understanding mechanisms of action is key to improving psychosocial interventions for cancer and other chronic disease conditions. In cancer, emotional expression has been identified as one possible mediator of the effect of psychosocial intervention on patient-reported outcomes. However, scientific evaluations of psychological mechanisms of adjustment to cancer and other chronic diseases are constrained by limitations associated with self-report measures. Because self-care resources, peer-to-peer networks, and more recent forms of psychosocial intervention are increasingly being delivered online, linguistic and behavioral data can be used to characterize internal coping processes, social interactions, and other manifest behaviors. Few tools are currently available for harnessing text as a potential data source, and signal detection indices of existing tools leave room for considerable improvement in these methodologies (Bantum & Owen, 2009). In the present study, natural language processing and other tools of computational linguistics will be used to develop a machine-learning classifier to identify emotional expression in electronic text data. The aims of the study are: 1) to annotate a large text corpus from cancer survivors using an objective and reliable emotion-coding procedure, 2) to incorporate linguistic and psychological features into a machine-learning classification method and identify which of these features are most strongly associated with codes assigned by trained human raters, and 3) to develop combined psychological and natural language processing (NLP) methods for identifying linguistic markers of emotional coping behaviors. To accomplish these aims, a comprehensive corpus of emotionally-laden cancer communications will be developed from 5 existing linguistic datasets. Five raters will be selected and undergo a rigorous training procedure for coding emotional expression using an emotion-coding system previously developed by the research. Coding will take place using an Internet-based coding interface that will allow the investigators to continuously monitor inter-rater reliability. Simultaneous with the coding process, the investigators will link the electronic text data with key linguistic and psychological features, including Linguistic Inquiry and Word Count (LIWC), Affective Norms for English Words (ANEW), WordNet, part of speech tags, patterns of capitalization and punctuation, emoticons, and textual context. A machine-learning classifier, using tools of natural language processing, will then be applied to the text/feature data and validated against human-rated emotion codes. The long-term objective of this research is to advance a methodology for objectively identifying coping behavior, particularly emotional expression, in order to supplement self-report measures and improve scientific understanding of adjustment to chronic disease, trauma, or other psychological conditions. This work is essential for identifying mechanisms of action in psychosocial interventions for cancer survivors and others and has significance for the fields of medicine, psychology, computational linguistics, and artificial intelligence.      PUBLIC HEALTH RELEVANCE: Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.           Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.",USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING,8120220,R21CA143642,"['Affective', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Cancer Intervention', 'Cancer Survivor', 'Categories', 'Characteristics', 'Chronic Disease', 'Classification', 'Code', 'Cognitive', 'Communication', 'Coping Behavior', 'Coping Skills', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Distress', 'Educational process of instructing', 'Effectiveness of Interventions', 'Electronics', 'Emotional', 'Emotions', 'Goals', 'Health', 'Health behavior', 'Heart Rate', 'Human', 'Hydrocortisone', 'Individual', 'Internet', 'Intervention', 'Intervention Studies', 'Left', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medicine', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Predictive Value', 'Problem Solving', 'Procedures', 'Process', 'Psychological adjustment', 'Psychology', 'Publishing', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Recovery', 'Regulation', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Sampling', 'Scientific Evaluation', 'Screening procedure', 'Self Care', 'Signal Transduction', 'Social Interaction', 'Social support', 'Specificity', 'Speech', 'Survey Methodology', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Treatment/Psychosocial Effects', 'Work', 'anticancer research', 'base', 'behavior observation', 'computerized', 'computerized tools', 'coping', 'effective intervention', 'emotional experience', 'experience', 'improved', 'indexing', 'innovation', 'lexical', 'natural language', 'peer', 'programs', 'psychologic', 'psychosocial', 'public health relevance', 'showing emotion', 'skills', 'skills training', 'symptom management', 'tool']",NCI,LOMA LINDA UNIVERSITY,R21,2011,161797,0.029071679703128385
"USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING    DESCRIPTION (provided by applicant): Understanding mechanisms of action is key to improving psychosocial interventions for cancer and other chronic disease conditions. In cancer, emotional expression has been identified as one possible mediator of the effect of psychosocial intervention on patient-reported outcomes. However, scientific evaluations of psychological mechanisms of adjustment to cancer and other chronic diseases are constrained by limitations associated with self-report measures. Because self-care resources, peer-to-peer networks, and more recent forms of psychosocial intervention are increasingly being delivered online, linguistic and behavioral data can be used to characterize internal coping processes, social interactions, and other manifest behaviors. Few tools are currently available for harnessing text as a potential data source, and signal detection indices of existing tools leave room for considerable improvement in these methodologies (Bantum & Owen, 2009). In the present study, natural language processing and other tools of computational linguistics will be used to develop a machine-learning classifier to identify emotional expression in electronic text data. The aims of the study are: 1) to annotate a large text corpus from cancer survivors using an objective and reliable emotion-coding procedure, 2) to incorporate linguistic and psychological features into a machine-learning classification method and identify which of these features are most strongly associated with codes assigned by trained human raters, and 3) to develop combined psychological and natural language processing (NLP) methods for identifying linguistic markers of emotional coping behaviors. To accomplish these aims, a comprehensive corpus of emotionally-laden cancer communications will be developed from 5 existing linguistic datasets. Five raters will be selected and undergo a rigorous training procedure for coding emotional expression using an emotion-coding system previously developed by the research. Coding will take place using an Internet-based coding interface that will allow the investigators to continuously monitor inter-rater reliability. Simultaneous with the coding process, the investigators will link the electronic text data with key linguistic and psychological features, including Linguistic Inquiry and Word Count (LIWC), Affective Norms for English Words (ANEW), WordNet, part of speech tags, patterns of capitalization and punctuation, emoticons, and textual context. A machine-learning classifier, using tools of natural language processing, will then be applied to the text/feature data and validated against human-rated emotion codes. The long-term objective of this research is to advance a methodology for objectively identifying coping behavior, particularly emotional expression, in order to supplement self-report measures and improve scientific understanding of adjustment to chronic disease, trauma, or other psychological conditions. This work is essential for identifying mechanisms of action in psychosocial interventions for cancer survivors and others and has significance for the fields of medicine, psychology, computational linguistics, and artificial intelligence.      PUBLIC HEALTH RELEVANCE: Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.           Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.",USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING,7991498,R21CA143642,"['Affective', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Cancer Intervention', 'Cancer Survivor', 'Categories', 'Characteristics', 'Chronic Disease', 'Classification', 'Code', 'Cognitive', 'Communication', 'Coping Behavior', 'Coping Skills', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Distress', 'Educational process of instructing', 'Effectiveness of Interventions', 'Electronics', 'Emotional', 'Emotions', 'Goals', 'Health', 'Health behavior', 'Heart Rate', 'Human', 'Hydrocortisone', 'Individual', 'Internet', 'Intervention', 'Intervention Studies', 'Left', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medicine', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Predictive Value', 'Problem Solving', 'Procedures', 'Process', 'Psychological adjustment', 'Psychology', 'Publishing', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Recovery', 'Regulation', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Sampling', 'Scientific Evaluation', 'Screening procedure', 'Self Care', 'Signal Transduction', 'Social Interaction', 'Social support', 'Specificity', 'Speech', 'Survey Methodology', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Treatment/Psychosocial Effects', 'Work', 'anticancer research', 'base', 'behavior observation', 'computerized', 'computerized tools', 'coping', 'effective intervention', 'emotional experience', 'experience', 'improved', 'indexing', 'innovation', 'lexical', 'natural language', 'peer', 'programs', 'psychologic', 'psychosocial', 'public health relevance', 'showing emotion', 'skills', 'skills training', 'symptom management', 'tool']",NCI,LOMA LINDA UNIVERSITY,R21,2010,223207,0.029071679703128385
"Clinical practice patterns and healthcare resource utilization in acute exacerbation of idiopathic pulmonary fibrosis: using real world data to bridge the evidence gap PROJECT SUMMARY/ ABSTRACT This F32 fellowship award will provide Dr. Erica Farrand with the support necessary to accomplish the following goals: (1) to become an expert in patient-oriented clinical research in idiopathic pulmonary fibrosis (IPF); (2) to develop a unique skill set in collecting, analyzing and interpreting real-world data; (3) to gain advanced skills in epidemiology, biostatistics and data science methods to conduct clinical research; (4) to advance the IPF field by improving our understanding of the clinical impact of acute exacerbation of IPF. To achieve these goals, Dr. Farrand will conduct clinical investigations in two distinct healthcare systems, the University of California San Francisco (UCSF) Health and Kaiser Permanente Northern California (KPNC). IPF is a progressive fibrotic lung disease associated with high morbidity and mortality and over $1 billion in healthcare cost annually. Acute exacerbation of IPF, is an acute respiratory deterioration and arguably the most clinically significant event in the natural history of the disease. The fundamental aim of this NRSA proposal is to leverage the electronic health records of UCSF Health and KPNC to generate real-world evidence regarding the epidemiology of acute exacerbation of IPF, the nature and variability of its clinical management and health care utilization across settings, and the impact of common management strategies on clinical outcomes. Research in this fellowship will utilize electronic health record data to define the acute exacerbation population using a case-validated diagnostic algorithm (Aim 1), document the scope and impact of acute exacerbation on clinical practice and healthcare resource utilization, comparing the UCSF and KPNC systems (Aim 2), and determine the association of common management approaches with hospital based and short-term patient-outcomes (Aim 3). This project will demonstrate the power of leveraging high-quality electronic health record data to both advance our understanding of a clinical condition and document the association of treatment interventions with patient and system level outcomes NARRATIVE Episodes of acute respiratory deterioration known as acute exacerbations are the most clinically significant events in the natural history of idiopathic pulmonary fibrosis (IPF), and limited data exist to guide the management of acute exacerbations of IPF. The impact of acute exacerbations on health care resource utilization across health care settings has not been characterized. Leveraging high-quality real-world data from the electronic health records of two large medical systems, we will address this knowledge gap by defining the clinical impact of acute exacerbation of IPF on the patient and healthcare system level; this work will demonstrate the power of real-world data for clinical research, and lay the foundation for future pragmatic studies of IPF.",Clinical practice patterns and healthcare resource utilization in acute exacerbation of idiopathic pulmonary fibrosis: using real world data to bridge the evidence gap,9610527,F32HL143920,"['Acute', 'Address', 'Admission activity', 'Adrenal Cortex Hormones', 'Affect', 'Algorithms', 'Ambulatory Care', 'Antibiotics', 'Anticoagulation', 'Award', 'Bilateral', 'Biometry', 'California', 'Caring', 'Cessation of life', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Practice Patterns', 'Clinical Research', 'Code', 'Collaborations', 'Communities', 'Data', 'Data Science', 'Deterioration', 'Diagnostic', 'Diagnostic Imaging', 'Electronic Health Record', 'Epidemiology', 'Event', 'Fellowship', 'Foundations', 'Future', 'Goals', 'Health', 'Health Care Costs', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Intensive Care', 'International', 'Intervention', 'Knowledge', 'Learning', 'Length of Stay', 'Lung diseases', 'Mechanical ventilation', 'Medical', 'Medical center', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Research Service Awards', 'Natural History', 'Natural Language Processing', 'Nature', 'Outcome', 'Oxygen', 'Palliative Care', 'Patient-Focused Outcomes', 'Patients', 'Population', 'Positioning Attribute', 'Practice Management', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'San Francisco', 'System', 'Time', 'Universities', 'Validation', 'Ventilator', 'Visit', 'Work', 'base', 'clinical investigation', 'clinical practice', 'clinically relevant', 'clinically significant', 'cohort', 'community setting', 'comparative effectiveness', 'day length', 'disease natural history', 'effectiveness trial', 'electronic data', 'evidence based guidelines', 'health care service utilization', 'health care settings', 'idiopathic pulmonary fibrosis', 'improved', 'insight', 'medical schools', 'member', 'mortality', 'multidisciplinary', 'patient oriented', 'pragmatic trial', 'prognostic', 'prospective test', 'respiratory', 'skills', 'survival outcome']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2018,71077,0.026225903837169696
"Personalized Patient data and behavioral nudges to improve adherence to chronic cardiovascular medications Abstract Our objective in this project is to employ population level pharmacy data and delivery of nudges via cell phone text messaging and artificially intelligent (AI) interactive chat bot to improve medication adherence and patient outcomes in 3 integrated healthcare delivery systems (HCS): University of Colorado Health System (UCHealth), VA Eastern Colorado Health Care System (VA), and Denver Health Medical Center (DH). We will identify patients with chronic cardiovascular (CV) conditions taking medications to treat hypertension, atrial fibrillation, coronary artery disease, diabetes and/or hyperlipidemia. We will leverage pharmacy refill data to identify episodes of non-adherence through gaps in medication refills and randomize individuals to 1 of 4 study arms when they have a first refill gap: 1) usual care; 2) generic text message reminder; 3) tailored and engaging text messages optimized to facilitate behavior change; or 4) optimized text messages plus a pre- programmed AI interactive chat bot designed to support identification and resolution of barriers to medication refill and adherence. In the UG3 phase (year 1), we will develop and program a theoretically informed technology-based (a) text message library and (b) chat bot content library using multiple and iterative N of 1 within subject studies to optimize content for a range of diverse patients. These outcomes will inform a pilot intervention to demonstrate feasibility of delivering the intervention and preliminary effects in all 3 HCS. We will also engage patient, provider and health systems stakeholders in designing, refining, and implementing the pilot intervention. In the UH3 phase (years 2-5), we will conduct a pragmatic patient-level randomized intervention across 3 HCS to improve adherence to chronic CV medications. We will evaluate the intervention using a mixed methods approach and apply the RE-AIM (reach, effectiveness, adoption, implementation, and maintenance) framework. In addition, we will assess the context and implementation processes to inform local tailoring, adaptations and modifications, and eventual expansion of the intervention. Project Narrative Given the increasing prevalence of chronic diseases that require ongoing treatment with medications, the problem of medication non-adherence is unlikely to go away and will grow. This study will employ population level pharmacy data to identify non-adherent patients and utilize ubiquitous cell phone technology to send them tailored, engaging and motivating text messages and text message based chat through an artificially intelligent (AI) interactive chat bot to improve cardiac medication adherence and patient outcomes in 3 integrated healthcare delivery systems. This study will advance medication adherence research and the intervention could be applied to multiple clinical conditions requiring medications for long term treatment and other NIH institutes.!",Personalized Patient data and behavioral nudges to improve adherence to chronic cardiovascular medications,9986013,UH3HL144163,"['Acute myocardial infarction', 'Adherence', 'Adoption', 'Artificial Intelligence', 'Atrial Fibrillation', 'Attention', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Body Weight decreased', 'Cardiac', 'Cardiovascular system', 'Cellular Phone', 'Chronic', 'Chronic Disease', 'Clinical', 'Colorado', 'Coronary Arteriosclerosis', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Disease', 'Effectiveness', 'Event', 'Goals', 'Health', 'Health Care Costs', 'Health Promotion', 'Health Technology', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Human', 'Hyperlipidemia', 'Hypertension', 'Individual', 'Institutes', 'Integrated Delivery of Health Care', 'Intervention', 'Intervention Studies', 'Libraries', 'Maintenance', 'Measures', 'Medical center', 'Methods', 'Modification', 'Morbidity - disease rate', 'Outcome', 'Patient Education', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Phase', 'Pilot Projects', 'Population', 'Prevalence', 'Process', 'Provider', 'Randomized', 'Recommendation', 'Research', 'Resolution', 'Resources', 'Self Management', 'Study Subject', 'System', 'Technology', 'Testing', 'Text Messaging', 'United States National Institutes of Health', 'Universities', 'base', 'behavior change', 'behavioral economics', 'blood pressure regulation', 'chatbot', 'copayment', 'cost', 'design', 'digital', 'evidence base', 'financial incentive', 'four-arm study', 'health care delivery', 'health care service utilization', 'improved', 'individual response', 'medication compliance', 'medication nonadherence', 'mortality', 'primary outcome', 'programs', 'randomized trial', 'response', 'safety net', 'secondary outcome', 'smoking cessation', 'theories', 'treatment as usual']",NHLBI,UNIVERSITY OF COLORADO DENVER,UH3,2020,1436253,0.030673801584315527
"Personalized Patient data and behavioral nudges to improve adherence to chronic cardiovascular medications Abstract Our objective in this project is to employ population level pharmacy data and delivery of nudges via cell phone text messaging and artificially intelligent (AI) interactive chat bot to improve medication adherence and patient outcomes in 3 integrated healthcare delivery systems (HCS): University of Colorado Health System (UCHealth), VA Eastern Colorado Health Care System (VA), and Denver Health Medical Center (DH). We will identify patients with chronic cardiovascular (CV) conditions taking medications to treat hypertension, atrial fibrillation, coronary artery disease, diabetes and/or hyperlipidemia. We will leverage pharmacy refill data to identify episodes of non-adherence through gaps in medication refills and randomize individuals to 1 of 4 study arms when they have a first refill gap: 1) usual care; 2) generic text message reminder; 3) tailored and engaging text messages optimized to facilitate behavior change; or 4) optimized text messages plus a pre- programmed AI interactive chat bot designed to support identification and resolution of barriers to medication refill and adherence. In the UG3 phase (year 1), we will develop and program a theoretically informed technology-based (a) text message library and (b) chat bot content library using multiple and iterative N of 1 within subject studies to optimize content for a range of diverse patients. These outcomes will inform a pilot intervention to demonstrate feasibility of delivering the intervention and preliminary effects in all 3 HCS. We will also engage patient, provider and health systems stakeholders in designing, refining, and implementing the pilot intervention. In the UH3 phase (years 2-5), we will conduct a pragmatic patient-level randomized intervention across 3 HCS to improve adherence to chronic CV medications. We will evaluate the intervention using a mixed methods approach and apply the RE-AIM (reach, effectiveness, adoption, implementation, and maintenance) framework. In addition, we will assess the context and implementation processes to inform local tailoring, adaptations and modifications, and eventual expansion of the intervention. Project Narrative Given the increasing prevalence of chronic diseases that require ongoing treatment with medications, the problem of medication non-adherence is unlikely to go away and will grow. This study will employ population level pharmacy data to identify non-adherent patients and utilize ubiquitous cell phone technology to send them tailored, engaging and motivating text messages and text message based chat through an artificially intelligent (AI) interactive chat bot to improve cardiac medication adherence and patient outcomes in 3 integrated healthcare delivery systems. This study will advance medication adherence research and the intervention could be applied to multiple clinical conditions requiring medications for long term treatment and other NIH institutes.!",Personalized Patient data and behavioral nudges to improve adherence to chronic cardiovascular medications,9750927,UH3HL144163,"['Acute myocardial infarction', 'Adherence', 'Adoption', 'Artificial Intelligence', 'Atrial Fibrillation', 'Attention', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Body Weight decreased', 'Cardiac', 'Cardiovascular system', 'Cellular Phone', 'Chronic', 'Chronic Disease', 'Clinical', 'Colorado', 'Coronary Arteriosclerosis', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Disease', 'Effectiveness', 'Event', 'Goals', 'Health', 'Health Care Costs', 'Health Promotion', 'Health Technology', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Human', 'Hyperlipidemia', 'Hypertension', 'Individual', 'Institutes', 'Integrated Delivery of Health Care', 'Intervention', 'Intervention Studies', 'Libraries', 'Maintenance', 'Measures', 'Medical center', 'Methods', 'Modification', 'Morbidity - disease rate', 'Outcome', 'Patient Education', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Phase', 'Pilot Projects', 'Population', 'Prevalence', 'Process', 'Provider', 'Randomized', 'Recommendation', 'Research', 'Resolution', 'Resources', 'Self Management', 'Study Subject', 'System', 'Technology', 'Testing', 'Text Messaging', 'United States National Institutes of Health', 'Universities', 'arm', 'base', 'behavior change', 'behavioral economics', 'blood pressure regulation', 'chatbot', 'copayment', 'cost', 'design', 'digital', 'evidence base', 'financial incentive', 'health care delivery', 'health care service utilization', 'improved', 'individual response', 'medication compliance', 'medication nonadherence', 'mortality', 'primary outcome', 'programs', 'randomized trial', 'response', 'safety net', 'secondary outcome', 'smoking cessation', 'theories', 'treatment as usual']",NHLBI,UNIVERSITY OF COLORADO DENVER,UH3,2019,1455863,0.030673801584315527
"SURPASS: (Statin Use and Risk Prediction of Atherosclerotic Cardiovascular Disease in minority Subgroups) PROJECT SUMMARY Despite advances in technology, cardiovascular disease (CVD) remains the leading cause of death, disability, and healthcare costs in the U.S. Yet, there is a tremendous gap in accurate cardiovascular risk prediction and prevention, particularly in racial/ethnic minorities. Furthermore, there is significant heterogeneity in CVD risks and outcomes for disaggregated Hispanic and Asian subgroups. The current cardiovascular risk assessment tools have not been well-validated in these diverse populations, and it remains largely unknown why minority patients are less likely to start and more likely to stop life-saving therapies. The overall goal of Dr. Rodriguezs K01 application is to address gaps in knowledge about CVD prediction and treatment in understudied racial/ethnic minority populations. The proposed study will utilize the electronic health record (EHR) data from an established NHLBI-funded cohort enriched with disaggregated Hispanic and Asian patients. Using this cohort, Dr. Rodriguez will first test the ACC/AHA Pooled Cohort Equations in disaggregated Asian and Hispanic subgroups using a large diverse mixed-payer cohort of 1,234,751 patients from two large healthcare systems in Northern California and Hawaii. Secondly, she will build new CVD risk prediction models for diverse patient subgroups using machine learning techniques. Finally, she will identify reasons for statin underuse and discontinuation using natural language processing in the EHR. This study, which will evaluate existing data from real-world clinical practice in a stable population, will inform future risk prediction models and cholesterol treatment guidelines for diverse racial/ethnic groups. The proposal is aligned with the NHBLIs strategic goals to eliminate health disparities and inequities by leveraging epidemiology and data science to understand and solve complex health problems. This proposal will also prepare Dr. Rodriguez to meet her long-term goal of becoming a national leader and independent investigator in CVD prevention and minority health. The proposed didactic and applied data science experiences, including training in advanced epidemiological methods and machine learning, will prepare Dr. Rodriguez to apply her research to other areas of CVD prevention and populations. This training program builds on the strengths of Stanford University in health services research, epidemiology, and biomedical informatics. Her mentorship team, led by Dr. Latha Palaniappan, includes experts in cardiovascular prevention and health services research (Dr. Heidenreich, co-mentor), applied statistical analyses (Dr. Robert Tibshirani, advisor), machine learning in the EHR (Dr. Nigam Shah, advisor), and chronic disease prediction and medical decision making (Dr. Michael Pignone, advisor). Dr. Rodriguezs team is committed to ensuring the success of the proposal as well as overseeing her advanced training in their respective areas of expertise. The research and training plan proposed in this K01 application will develop Dr. Rodriguez into a unique and highly-skilled clinician researcher ready to compete for R-level funding and launch her independent research career. ! PROJECT NARRATIVE Cardiovascular disease (CVD) is the leading cause of death for racial/ethnic minority groups in the U.S., yet current CVD risk prediction algorithms fail to adequately assess risk in these populations. The proposal will address this substantial knowledge gap by validating current risk prediction models in racial/ethnic minority subgroups, improving risk prediction using modern machine learning techniques, and identifying reasons for statin discontinuation. Findings from this study will provide the foundation for clinical guidelines, research agendas, and public health interventions to improve CVD prevention strategies in diverse populations. !",SURPASS: (Statin Use and Risk Prediction of Atherosclerotic Cardiovascular Disease in minority Subgroups),9851429,K01HL144607,"['Address', 'Adherence', 'American', 'American Heart Association', 'Area', 'Asians', 'Assessment tool', 'Atherosclerosis', 'Biometry', 'Calibration', 'California', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cause of Death', 'Cholesterol', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Data', 'Data Science', 'Decision Making', 'Diagnosis', 'Discrimination', 'Disease Outcome', 'Electronic Health Record', 'Ensure', 'Epidemiologic Methods', 'Epidemiology', 'Equation', 'Ethnic group', 'Event', 'Foundations', 'Funding', 'Future', 'Goals', 'Guidelines', 'Hawaii', 'Health', 'Health Care Costs', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Heterogeneity', 'Hispanics', 'Hypersensitivity', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Mexican Americans', 'Minority', 'Minority Groups', 'Modeling', 'Modernization', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Not Hispanic or Latino', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Prevention strategy', 'Preventive Intervention', 'Puerto Rican', 'Research', 'Research Personnel', 'Research Training', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Savings', 'Scientist', 'South Asian', 'Stable Populations', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States', 'Universities', 'Validation', 'Veterans', 'Woman', 'Work', 'atherosclerosis risk', 'base', 'biomedical informatics', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'career', 'clinical practice', 'cohort', 'college', 'disability', 'disparity reduction', 'epidemiologic data', 'ethnic minority population', 'evidence base', 'experience', 'health difference', 'health disparity', 'high risk', 'high risk population', 'i(19)', 'improved', 'innovation', 'machine learning algorithm', 'men', 'minority health', 'mortality', 'neural network', 'patient subsets', 'prediction algorithm', 'prevention service', 'public health intervention', 'racial and ethnic', 'racial and ethnic disparities', 'racial diversity', 'racial minority', 'random forest', 'risk prediction model', 'side effect', 'skills', 'structured data', 'success', 'supervised learning', 'support vector machine', 'treatment guidelines', 'unstructured data']",NHLBI,STANFORD UNIVERSITY,K01,2020,172001,0.02790781522116215
"SURPASS: (Statin Use and Risk Prediction of Atherosclerotic Cardiovascular Disease in minority Subgroups) PROJECT SUMMARY Despite advances in technology, cardiovascular disease (CVD) remains the leading cause of death, disability, and healthcare costs in the U.S. Yet, there is a tremendous gap in accurate cardiovascular risk prediction and prevention, particularly in racial/ethnic minorities. Furthermore, there is significant heterogeneity in CVD risks and outcomes for disaggregated Hispanic and Asian subgroups. The current cardiovascular risk assessment tools have not been well-validated in these diverse populations, and it remains largely unknown why minority patients are less likely to start and more likely to stop life-saving therapies. The overall goal of Dr. Rodriguezs K01 application is to address gaps in knowledge about CVD prediction and treatment in understudied racial/ethnic minority populations. The proposed study will utilize the electronic health record (EHR) data from an established NHLBI-funded cohort enriched with disaggregated Hispanic and Asian patients. Using this cohort, Dr. Rodriguez will first test the ACC/AHA Pooled Cohort Equations in disaggregated Asian and Hispanic subgroups using a large diverse mixed-payer cohort of 1,234,751 patients from two large healthcare systems in Northern California and Hawaii. Secondly, she will build new CVD risk prediction models for diverse patient subgroups using machine learning techniques. Finally, she will identify reasons for statin underuse and discontinuation using natural language processing in the EHR. This study, which will evaluate existing data from real-world clinical practice in a stable population, will inform future risk prediction models and cholesterol treatment guidelines for diverse racial/ethnic groups. The proposal is aligned with the NHBLIs strategic goals to eliminate health disparities and inequities by leveraging epidemiology and data science to understand and solve complex health problems. This proposal will also prepare Dr. Rodriguez to meet her long-term goal of becoming a national leader and independent investigator in CVD prevention and minority health. The proposed didactic and applied data science experiences, including training in advanced epidemiological methods and machine learning, will prepare Dr. Rodriguez to apply her research to other areas of CVD prevention and populations. This training program builds on the strengths of Stanford University in health services research, epidemiology, and biomedical informatics. Her mentorship team, led by Dr. Latha Palaniappan, includes experts in cardiovascular prevention and health services research (Dr. Heidenreich, co-mentor), applied statistical analyses (Dr. Robert Tibshirani, advisor), machine learning in the EHR (Dr. Nigam Shah, advisor), and chronic disease prediction and medical decision making (Dr. Michael Pignone, advisor). Dr. Rodriguezs team is committed to ensuring the success of the proposal as well as overseeing her advanced training in their respective areas of expertise. The research and training plan proposed in this K01 application will develop Dr. Rodriguez into a unique and highly-skilled clinician researcher ready to compete for R-level funding and launch her independent research career. ! PROJECT NARRATIVE Cardiovascular disease (CVD) is the leading cause of death for racial/ethnic minority groups in the U.S., yet current CVD risk prediction algorithms fail to adequately assess risk in these populations. The proposal will address this substantial knowledge gap by validating current risk prediction models in racial/ethnic minority subgroups, improving risk prediction using modern machine learning techniques, and identifying reasons for statin discontinuation. Findings from this study will provide the foundation for clinical guidelines, research agendas, and public health interventions to improve CVD prevention strategies in diverse populations. !",SURPASS: (Statin Use and Risk Prediction of Atherosclerotic Cardiovascular Disease in minority Subgroups),9645316,K01HL144607,"['Address', 'Adherence', 'American', 'American Heart Association', 'Area', 'Asians', 'Assessment tool', 'Atherosclerosis', 'Biometry', 'Calibration', 'California', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cause of Death', 'Cholesterol', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Data', 'Data Science', 'Decision Making', 'Diagnosis', 'Discrimination', 'Disease Outcome', 'Electronic Health Record', 'Ensure', 'Epidemiologic Methods', 'Epidemiology', 'Equation', 'Ethnic group', 'Event', 'Foundations', 'Funding', 'Future', 'Goals', 'Guidelines', 'Hawaii', 'Health', 'Health Care Costs', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Heterogeneity', 'Hispanics', 'Hypersensitivity', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Mexican Americans', 'Minority', 'Minority Groups', 'Modeling', 'Modernization', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Not Hispanic or Latino', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Prevention strategy', 'Preventive Intervention', 'Puerto Rican', 'Research', 'Research Personnel', 'Research Training', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Savings', 'Scientist', 'South Asian', 'Stable Populations', 'Statistical Data Interpretation', 'Statistical Methods', 'Structure', 'Subgroup', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States', 'Universities', 'Validation', 'Veterans', 'Woman', 'Work', 'atherosclerosis risk', 'base', 'biomedical informatics', 'cardiovascular disorder prevention', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'career', 'clinical practice', 'cohort', 'college', 'disability', 'disparity reduction', 'epidemiologic data', 'ethnic minority population', 'evidence base', 'experience', 'health difference', 'health disparity', 'high risk', 'high risk population', 'i(19)', 'improved', 'innovation', 'machine learning algorithm', 'men', 'minority health', 'mortality', 'neural network', 'patient subsets', 'prediction algorithm', 'prevention service', 'public health intervention', 'racial and ethnic', 'racial and ethnic disparities', 'racial diversity', 'racial minority', 'random forest', 'risk prediction model', 'side effect', 'skills', 'success', 'supervised learning', 'treatment guidelines']",NHLBI,STANFORD UNIVERSITY,K01,2019,172692,0.02790781522116215
"Machine Learning of Physiological Waveforms and Electronic Health Record Data to Predict, Diagnose, and Treat Hemodynamic Instability in Surgical Patients Project Summary / Abstract If one could accurately predict who, when and why patients develop cardiorespiratory instability (CRI) during surgery, then effective preemptive treatments could be given to improve postoperative outcome and more effectively use healthcare resources. But signs of shock often occur late once organ injury is already present. The goal of this proposal is to develop, validate, and test real-time intraoperative risk prediction tools based on electronic health record (EHR) data and high-fidelity physiological waveforms to predict CRI and make the databases of intraoperative data and waveforms used for these developments freely accessible. This is extremely relevant because although 5.7 million Americans are admitted to an Intensive Care Units (ICU) in one year, more than 42 millions undergo surgery annually. Previous and ongoing studies conducted in the ICU and in the step down unit have built the architecture to collect real-time high-fidelity physiological waveform data streams and integrate them with patient demographics from the EHR to build large data sets, and derive actionable fused parameters based on machine learning (ML) analytics as well as display information in real time at the bedside to drive clinical decision support (CDS) in the critical care setting. The goal of this proposal is to apply these ML approaches to the complex and time compressed environment of high-risk surgery where greater patient and disease variability exist and shorter period of time is available to deliver truly personalized medicine approaches. The work will be initiated using an already existing annotated intraoperative database from the University of California Irvine including EHR and high-fidelity waveform data. This operating room database already exists and needs only to be extracted. This data will be used for the initial training and development of the ML model that will then be tested on prospectively collected University of California Los Angeles and University of Pittsburgh Medical Center databases. Simultaneously, this approach will use existing knowledge of CRI patterns derived from previous step down unit / intensive care unit cohorts, MIMIC II data, University of California Irvine data, and animal studies to create smart alarms and graphic user interface for clinical decision support based on functional hemodynamic monitoring principles. The next step will then leverage the focus on the issues and strengths of the intraoperative environment, some of which can be listed as: 1) Known patients characteristics before surgery to define pre-stress baseline, allowing functional hemodynamic monitoring stress evaluations, preconditioning, and other preoperative calibrations, 2) High degree of direct observation and data density during most phases of surgery allowing close semi-autonomous monitoring and titration of novel treatment algorithms early, 3) Defined stages in the initial part of surgery (induction, intubation, skin incision) allowing ML approaches to build large common relational database registries, and 4) Defined surgical procedure and stressors (anesthesia induction, intra-abdominal air insufflation, and other surgery-specific interventions), which will alter the impact of CRI on measured variables. Project Narrative The purpose of this study is to first develop multivariable models through data-driven classification techniques to predict parsimoniously cardiorespiratory instability, etiology and response to treatment in patients undergoing high-risk surgery. Using high-fidelity intraoperative physiological waveform data augmented with extensive electronic health record derived annotation and applying machine learning approaches we will characterize and quantify common patterns in subjects destined to develop cardiorespiratory instability during high-risk surgery. We will use these inputs in simulated real-time bedside management to develop an iteratively designed prototype clinical decision support system suitable for intraoperative care.","Machine Learning of Physiological Waveforms and Electronic Health Record Data to Predict, Diagnose, and Treat Hemodynamic Instability in Surgical Patients",9846016,R01HL144692,"['Acute', 'Adopted', 'Air', 'Algorithms', 'American', 'Anesthesia procedures', 'Animals', 'Architecture', 'Calibration', 'California', 'Caring', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Management', 'Clinical Research', 'Complex', 'Critical Care', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Environment', 'Etiology', 'Evaluation', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Homeostasis', 'Hospital Mortality', 'Hospitals', 'Hypotension', 'Insufflation', 'Intensive Care Units', 'Intervention', 'Intra-abdominal', 'Intraoperative Care', 'Intraoperative Period', 'Intubation', 'Knowledge', 'Lead', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Modeling', 'Monitor', 'Nature', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Pathologic Processes', 'Patient Care', 'Patients', 'Pattern', 'Perioperative', 'Phase', 'Physiological', 'Postoperative Complications', 'Postoperative Period', 'Process', 'Recommendation', 'Registries', 'Resources', 'Resuscitation', 'Risk', 'Running', 'Sampling', 'Shock', 'Signal Transduction', 'Skin', 'Specificity', 'Stress', 'Surgical incisions', 'System', 'Techniques', 'Testing', 'Time', 'Titrations', 'Training', 'Universities', 'Validation', 'Variant', 'Work', 'base', 'clinical care', 'clinical decision support', 'clinical risk', 'cohort', 'data integration', 'data streams', 'data structure', 'database structure', 'deep neural network', 'demographics', 'density', 'diagnostic accuracy', 'effectiveness evaluation', 'electronic data', 'graphical user interface', 'hemodynamics', 'high risk', 'improved', 'information display', 'insight', 'interoperability', 'iterative design', 'large datasets', 'machine learning algorithm', 'model development', 'mortality', 'neural network algorithm', 'novel', 'organ injury', 'patient population', 'personalized medicine', 'preconditioning', 'predictive modeling', 'predictive tools', 'pressure', 'prospective', 'prototype', 'relational database', 'response', 'simulation environment', 'stressor', 'structured data', 'support tools', 'surgical risk', 'tool', 'treatment response']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,648089,0.03438403641278662
"Machine Learning of Physiological Waveforms and Electronic Health Record Data to Predict, Diagnose, and Treat Hemodynamic Instability in Surgical Patients Project Summary / Abstract If one could accurately predict who, when and why patients develop cardiorespiratory instability (CRI) during surgery, then effective preemptive treatments could be given to improve postoperative outcome and more effectively use healthcare resources. But signs of shock often occur late once organ injury is already present. The goal of this proposal is to develop, validate, and test real-time intraoperative risk prediction tools based on electronic health record (EHR) data and high-fidelity physiological waveforms to predict CRI and make the databases of intraoperative data and waveforms used for these developments freely accessible. This is extremely relevant because although 5.7 million Americans are admitted to an Intensive Care Units (ICU) in one year, more than 42 millions undergo surgery annually. Previous and ongoing studies conducted in the ICU and in the step down unit have built the architecture to collect real-time high-fidelity physiological waveform data streams and integrate them with patient demographics from the EHR to build large data sets, and derive actionable fused parameters based on machine learning (ML) analytics as well as display information in real time at the bedside to drive clinical decision support (CDS) in the critical care setting. The goal of this proposal is to apply these ML approaches to the complex and time compressed environment of high-risk surgery where greater patient and disease variability exist and shorter period of time is available to deliver truly personalized medicine approaches. The work will be initiated using an already existing annotated intraoperative database from the University of California Irvine including EHR and high-fidelity waveform data. This operating room database already exists and needs only to be extracted. This data will be used for the initial training and development of the ML model that will then be tested on prospectively collected University of California Los Angeles and University of Pittsburgh Medical Center databases. Simultaneously, this approach will use existing knowledge of CRI patterns derived from previous step down unit / intensive care unit cohorts, MIMIC II data, University of California Irvine data, and animal studies to create smart alarms and graphic user interface for clinical decision support based on functional hemodynamic monitoring principles. The next step will then leverage the focus on the issues and strengths of the intraoperative environment, some of which can be listed as: 1) Known patients characteristics before surgery to define pre-stress baseline, allowing functional hemodynamic monitoring stress evaluations, preconditioning, and other preoperative calibrations, 2) High degree of direct observation and data density during most phases of surgery allowing close semi-autonomous monitoring and titration of novel treatment algorithms early, 3) Defined stages in the initial part of surgery (induction, intubation, skin incision) allowing ML approaches to build large common relational database registries, and 4) Defined surgical procedure and stressors (anesthesia induction, intra-abdominal air insufflation, and other surgery-specific interventions), which will alter the impact of CRI on measured variables. Project Narrative The purpose of this study is to first develop multivariable models through data-driven classification techniques to predict parsimoniously cardiorespiratory instability, etiology and response to treatment in patients undergoing high-risk surgery. Using high-fidelity intraoperative physiological waveform data augmented with extensive electronic health record derived annotation and applying machine learning approaches we will characterize and quantify common patterns in subjects destined to develop cardiorespiratory instability during high-risk surgery. We will use these inputs in simulated real-time bedside management to develop an iteratively designed prototype clinical decision support system suitable for intraoperative care.","Machine Learning of Physiological Waveforms and Electronic Health Record Data to Predict, Diagnose, and Treat Hemodynamic Instability in Surgical Patients",9643500,R01HL144692,"['Acute', 'Adopted', 'Air', 'Algorithms', 'American', 'Anesthesia procedures', 'Animals', 'Architecture', 'Calibration', 'California', 'Caring', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Management', 'Clinical Research', 'Clinical effectiveness', 'Complex', 'Critical Care', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Environment', 'Etiology', 'Evaluation', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Homeostasis', 'Hospital Mortality', 'Hospitals', 'Hypotension', 'Injury', 'Insufflation', 'Intensive Care Units', 'Intervention', 'Intra-abdominal', 'Intraoperative Care', 'Intraoperative Period', 'Intubation', 'Knowledge', 'Lead', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Modeling', 'Monitor', 'Nature', 'Operating Rooms', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Pathologic Processes', 'Patient Care', 'Patients', 'Pattern', 'Perioperative', 'Phase', 'Physiological', 'Postoperative Complications', 'Postoperative Period', 'Process', 'Recommendation', 'Registries', 'Resources', 'Resuscitation', 'Risk', 'Running', 'Sampling', 'Shock', 'Signal Transduction', 'Skin', 'Specificity', 'Stream', 'Stress', 'Surgical incisions', 'System', 'Techniques', 'Testing', 'Time', 'Titrations', 'Training', 'Universities', 'Validation', 'Variant', 'Work', 'base', 'clinical care', 'clinical decision support', 'clinical risk', 'cohort', 'data integration', 'data structure', 'database structure', 'deep neural network', 'demographics', 'density', 'diagnostic accuracy', 'electronic data', 'graphical user interface', 'hemodynamics', 'high risk', 'improved', 'information display', 'insight', 'interoperability', 'iterative design', 'machine learning algorithm', 'model development', 'mortality', 'neural network algorithm', 'novel', 'patient population', 'personalized medicine', 'preconditioning', 'predictive modeling', 'predictive tools', 'pressure', 'prospective', 'prototype', 'relational database', 'response', 'simulation', 'stressor', 'support tools', 'surgical risk', 'tool', 'treatment response']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,694170,0.03438403641278662
"Quantifying Compliance to the New 2017 Hypertension Treatment Guidelines and Investigating the Association Between Guideline Compliance and Patients' Trajectory of Blood Pressure Project Summary/Abstract Blood pressure (BP) of 140/90 mm Hg doubles the risk of cardiovascular diseases (CVD) and the total cost of hypertension reaches as high as $51 billion per year. Despite the enormous risk and cost associated with hypertension, less than half (48.3%) of hypertensive patients have a controlled blood pressure (BP) in the United States. Clinical trials demonstrated that a high rate of BP control (up to 85%) can be achieved with currently available therapies and strictly following recommended treatment protocols. This suggests that a higher proportion of uncontrolled BP could be explained by less aggressive treatment, poorer follow-up, and use of fewer or less effective drugs. The 2017 guideline for high BP management was recently published and lowered the threshold for the initiation of medication and definition of uncontrolled BP to BP 130/80 mm Hg (from 140/90) for patients with CVD or higher risk of CVD. This challenges physicians to change their traditional hypertension management and could worsen the already low rate of compliance (range 25-65%) to hypertension treatment guidelines. Furthermore, conclusions from previous studies regarding compliance to older hypertension treatment guidelines were compromised due to failure to evaluate multiple aspects of hypertension care, such as comorbidities, follow-up and laboratory assessments; and use of subjective assessment such as physician self-report. The wide-spread adoption of electronic health record (EHR) technology and the vital patient information present in EHR data provide an exceptional opportunity to objectively evaluate several aspects of hypertension care, such as medications prescribed, laboratory procedures ordered, BP level achieved, follow-up monitoring examinations, demographic and comorbid information. We, therefore, propose to use the Northwestern Medicine Enterprise Data Warehouse (NMEDW)  an integrated EHR database of health information from 2.9 million patients to 1) assess compliance to the 2017 hypertension management guidelines for 5 years since its release (2018-2022); 2) investigate whether patients age, race, body mass index, history of diabetes, CVD, chronic kidney disease, medication adherence, presence of health insurance and regular physician, and physican speciality predict level of compliance to the new treatment guideline; and 3) examine the association between level of compliance to the 2017 hypertension treatment guidelines and prospective patient BP trajectory over 5 years (2019-2023). Newly diagnosed hypertensive patients demographics, BP, medications, lab results, follow-up visit, and comorbid conditions will be assessed from the NMEDW and will be compared to criteria developed based on the 2017 hypertension treatment guidelines to quantify compliance to the guideline. The proposed study provides the candidate an opportunity to learn EHR data-mining skills to assess association between compliance to the new hypertension treatment guideline and patient BP trajectory and to identify predictors of this compliance, as a first step, in designing future targeted interventions to enhance guideline compliance and BP control. Project Narrative The 2017 hypertension treatment guideline lowered the threshold for the initiation of hypertensive medication and definition of uncontrolled blood pressure (BP) to BP 130/80 mm Hg (from 140/90). This could worsen the already low rate of compliance (25-65%) to treatment guidelines. In this study, we will evaluate physician compliance to the 2017 hypertension treatment guideline and its association with patient BP using electronic health record data that comprises information on several aspects of hypertension care. Findings of this study will help in designing future targeted interventions to enhance compliance to treatment guideline and BP control.",Quantifying Compliance to the New 2017 Hypertension Treatment Guidelines and Investigating the Association Between Guideline Compliance and Patients' Trajectory of Blood Pressure,9870519,K01HL145345,"['Address', 'Adherence', 'Adoption', 'Adult', 'Adverse drug effect', 'Age', 'Algorithms', 'American', 'Blood Pressure', 'Body mass index', 'Cardiovascular Diseases', 'Caring', 'Chronic Kidney Failure', 'Clinical Research', 'Clinical Trials', 'Data', 'Databases', 'Diabetes Mellitus', 'Diastolic blood pressure', 'Disease', 'Dose', 'E-learning', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Failure', 'Feedback', 'Future', 'Guidelines', 'Health', 'Health Insurance', 'Hypertension', 'Intervention', 'Knowledge', 'Laboratories', 'Laboratory Procedures', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medicine', 'Minority', 'Monitor', 'Natural Language Processing', 'Newly Diagnosed', 'Obesity', 'Patient Care', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Predisposition', 'Prevalence', 'Procedures', 'Provider', 'Publishing', 'Race', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Technology', 'Time', 'Titrations', 'Treatment Protocols', 'United States', 'Visit', 'aggressive therapy', 'base', 'blood pressure medication', 'blood pressure regulation', 'cardiovascular disorder risk', 'comorbidity', 'computerized', 'cost', 'data mining', 'data warehouse', 'demographics', 'design', 'follow-up', 'high risk', 'hypertension control', 'hypertension treatment', 'improved', 'medication compliance', 'phenotyping algorithm', 'prospective', 'skills', 'treatment guidelines']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,K01,2020,120966,0.020111237673739228
"Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response SUMMARY Drug-induced cardiac toxicity, in the form of QT prolongation and torsade de pointes, is an uncommon but devastating side effect of over one hundred currently marketed drugs. The ubiquity of drug-induced QT prolongation (diLQTS) across medical specialties and conditions creates a challenge for providers seeking to prescribe known QT-prolonging medications, particularly for non-cardiac conditions. Work by our group to develop automated clinical decision support (CDS) tools that alert providers of patient risk has shown promise towards reducing the number of prescriptions to at-risk individuals. However, these tools rely on a history of an electrocardiogram (ECG) with QT prolongation to identify at-risk patients, and thus exclude a large number of potentially at-risk individuals who have not had an ECG within our system. Through a unique institutional partnership with Google, in which a copy of our entire electronic health record (EHR) is stored on the Google Cloud Platform (GCP), we have developed preliminary deep-learning models to predict risk of diLQTS. We have also validated the genetic association with the QT interval and diLQTS across several real-world populations using an aggregate polygenic risk score. Through creation of an institutional biobank with certification for clinical application of results, as well as cloud-based integration of EHR data with genetic data, we have the capability to leverage our existing infrastructure to study the role of deep learning and genetics to reduce the risk of diLQTS. This investigation will combine our unique research and clinical infrastructure on the University of Colorado Anschutz Medical Campus with our investigative team composed of experts in the study of pharmacogenomics and medical informatics to develop and study an end-to-end CDS tool incorporating genetics and deep learning to predict risk of diLQTS. The specific aims of this application include the following: (1) develop and test a cloud-based, deep-learning model using EHR data on in- and outpatients to predict risk of diLQTS; (2) validate genetic predictors of diLQTS using institutional biobank samples, and a multi-ethnic external population; and (3) develop and test CDS tools using these advanced methods to reduce the risk of diLQTS. We will use a common data model (Observational Medical Outcomes Partnership) mapped from EHR data, as well as a custom DNA array (Multi-Ethnic Genotyping Array) designed for imputation across a variety of non-European ancestries, to ensure that the our prediction model and findings from this study can be replicated in other institutions and populations in the future. In such a way, this investigation will not only provide insight into the use of machine learning and genetics for risk prediction of diLQTS, but it will also create a blueprint for future advanced CDS development for other conditions. PROJECT NARRATIVE The goal of this project is the development of a clinical decision support tool that can be used to predict the risk of drug-induced QT prolongation based on deep learning and genetics. This tool could be used to prevent potentially fatal side effects of medications when alternatives are available, or increase vigilance when safer alternatives are not available. This study is specifically designed so that the models created can be directly applied across other institutional medical record systems beyond the study population.",Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response,9887500,R01HL146824,"['Adherence', 'Adverse drug effect', 'Arrhythmia', 'Artificial Intelligence', 'Automated Clinical Decision Support', 'Benefits and Risks', 'Biometry', 'Cardiotoxicity', 'Certification', 'Clinical', 'Cluster randomized trial', 'Colorado', 'Custom', 'DNA', 'Data', 'Data Science', 'Decision Analysis', 'Development', 'Electrocardiogram', 'Electronic Health Record', 'Ensure', 'Excision', 'Future', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Health Technology', 'Health system', 'Heritability', 'Hospitals', 'Individual', 'Information Technology', 'Infrastructure', 'Inpatients', 'Institution', 'Investigation', 'Long QT Syndrome', 'Machine Learning', 'Maps', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Modeling', 'Outcome', 'Outpatients', 'Participant', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Population', 'Protocols documentation', 'Provider', 'Recording of previous events', 'Relative Risks', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Risk stratification', 'Role', 'Sample Size', 'Sampling', 'Science', 'System', 'Technology', 'Testing', 'Time', 'Torsades de Pointes', 'Toxic effect', 'Universities', 'Validation', 'Variant', 'Work', 'analytical tool', 'base', 'biobank', 'classification algorithm', 'clinical application', 'clinical decision support', 'clinical implementation', 'clinical infrastructure', 'cloud based', 'cloud platform', 'cloud storage', 'data modeling', 'data warehouse', 'deep learning', 'design', 'disorder risk', 'drug market', 'electronic data', 'experience', 'genetic association', 'genetic epidemiology', 'genetic information', 'genetic predictors', 'genetic variant', 'genome wide association study', 'health data', 'improved', 'innovation', 'insight', 'machine learning method', 'medical schools', 'medical specialties', 'patient safety', 'personalized medicine', 'polygenic risk score', 'practical application', 'predictive modeling', 'prevent', 'primary outcome', 'response', 'secondary outcome', 'side effect', 'study population', 'support tools', 'tool', 'trend', 'vigilance']",NHLBI,UNIVERSITY OF COLORADO DENVER,R01,2020,777314,0.030079890542205855
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7944035,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Epidemiology', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2010,494477,-0.01601176914634452
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7839706,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2009,497857,-0.01601176914634452
"Using artificial intelligence to enable early identification and treatment of peripheral artery disease ABSTRACT The purpose of this award is to provide Dr. Elsie Ross, Assistant Professor of Surgery (Vascular Surgery) and Medicine (Biomedical Informatics Research) at Stanford University, the support necessary to transition her from a junior investigator into an independent surgeon-scientist in translational biomedical informatics. Dr. Ross is a vascular surgeon with an advanced degree in health services research and postdoctoral training in biomedical informatics. Her long-term goal is to combine her interdisciplinary training to develop and implement machine learning tools that will enable the delivery of precise, high-value care to patients with cardiovascular diseases. Her career development activities focus on advancing her ability to translate informatics discoveries into viable clinical tools by 1) completing didactic courses to deepen and expand her knowledge of deep learning algorithms, clinical trials and implementation science, 2) designing and conducting her first independent human subjects clinical research study evaluating the performance of machine learning technology, 3) implementing and evaluating the effects of an electronic health record (EHR)-based screening tool to identify latent vascular disease, and 4) strengthening her previous training in cost-effectiveness analysis to enable her future aim of evaluating the associated costs and utility of pro-active, automated disease screening. The candidate has convened a mentorship team that includes Dr. Nigam Shah, a biomedical informatics expert who combines machine learning, text-mining and medical ontologies to enable a learning health care system; Dr. Kenneth Mahaffey a world-expert in cardiovascular clinical trials; and Dr. Paul Heidenreich, an expert in implementation sciences with a focus on the use of EHR interventions to improve care quality for cardiovascular patients and evaluating the cost-effectiveness of new technologies. The research proposal builds on the candidate's prior work with using machine learning and EHR data to evaluate and predict cardiovascular disease outcomes. The candidate now proposes to characterize the performance of machine learning algorithms in identifying patients with peripheral artery disease (PAD) using EHR data (Aim 1), evaluate whether learned classification models perform better than traditional risk factors for identification of undiagnosed PAD in a prospective patient cohort (Aim 2), and implement an EHR-based screening tool to identify patients with undiagnosed PAD and evaluate the diagnosis and treatment effects (Aim 3). Completion of the proposed research will result in a novel, EHR-based screening tool for identification of undiagnosed vascular disease that can decrease PAD-related cardiovascular morbidity and mortality through earlier and more aggressive medical management. This research will also form the basis for an R01 application before the end of the award to conduct a multi-site randomized-controlled clinical trial to evaluate the impact of EHR- based proactive PAD screening. ! ! ! PROJECT NARRATIVE Peripheral artery disease is a prevalent yet under-diagnosed condition that can lead to limb loss, stroke, heart attacks and/or premature death. Work proposed in this grant aims to develop technology using electronic health records and machine learning algorithms to automatically identify patients with undiagnosed peripheral artery disease and recommend treatment. Such technology could improve the health and longevity of patients with peripheral artery disease by ensuring that patients are diagnosed early and appropriately treated.",Using artificial intelligence to enable early identification and treatment of peripheral artery disease,9987727,K01HL148639,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'American', 'Applications Grants', 'Artificial Intelligence', 'Award', 'Awareness', 'Blood Vessels', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Cost Effectiveness Analysis', 'Cost utility', 'Costs and Benefits', 'Current Procedural Terminology Codes', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Disease Outcome', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Evaluation', 'Event', 'Foundations', 'Future', 'Goals', 'Grant', 'Health', 'Health Services Research', 'Healthcare', 'Healthcare Systems', 'Image', 'Informatics', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Limb structure', 'Logistic Regressions', 'Longevity', 'Machine Learning', 'Medical', 'Medicare', 'Medicine', 'Mentorship', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Newly Diagnosed', 'Noise', 'Notification', 'Ontology', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Peripheral arterial disease', 'Physicians', 'Quality of Care', 'Randomized', 'Randomized Controlled Clinical Trials', 'Recommendation', 'Records', 'Research', 'Research Personnel', 'Research Proposals', 'Research Training', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Stroke', 'Structure', 'Surgeon', 'Symptoms', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Universities', 'Vascular Diseases', 'Work', 'base', 'biomedical informatics', 'care burden', 'career', 'career development', 'clinical center', 'clinical data warehouse', 'clinical implementation', 'cohort', 'computing resources', 'cost', 'cost effective', 'cost outcomes', 'cost-effectiveness evaluation', 'data analysis pipeline', 'deep learning algorithm', 'design', 'disease diagnosis', 'disorder risk', 'electronic data', 'high risk', 'human subject', 'human very old age (85+)', 'implementation science', 'improved', 'machine learning algorithm', 'mortality', 'new technology', 'novel', 'post-doctoral training', 'premature', 'prevent', 'professor', 'prospective', 'random forest', 'randomized trial', 'recurrent neural network', 'research study', 'screening', 'text searching', 'tool', 'treatment effect']",NHLBI,STANFORD UNIVERSITY,K01,2020,161736,0.021811219784077632
"Using artificial intelligence to enable early identification and treatment of peripheral artery disease ABSTRACT The purpose of this award is to provide Dr. Elsie Ross, Assistant Professor of Surgery (Vascular Surgery) and Medicine (Biomedical Informatics Research) at Stanford University, the support necessary to transition her from a junior investigator into an independent surgeon-scientist in translational biomedical informatics. Dr. Ross is a vascular surgeon with an advanced degree in health services research and postdoctoral training in biomedical informatics. Her long-term goal is to combine her interdisciplinary training to develop and implement machine learning tools that will enable the delivery of precise, high-value care to patients with cardiovascular diseases. Her career development activities focus on advancing her ability to translate informatics discoveries into viable clinical tools by 1) completing didactic courses to deepen and expand her knowledge of deep learning algorithms, clinical trials and implementation science, 2) designing and conducting her first independent human subjects clinical research study evaluating the performance of machine learning technology, 3) implementing and evaluating the effects of an electronic health record (EHR)-based screening tool to identify latent vascular disease, and 4) strengthening her previous training in cost-effectiveness analysis to enable her future aim of evaluating the associated costs and utility of pro-active, automated disease screening. The candidate has convened a mentorship team that includes Dr. Nigam Shah, a biomedical informatics expert who combines machine learning, text-mining and medical ontologies to enable a learning health care system; Dr. Kenneth Mahaffey a world-expert in cardiovascular clinical trials; and Dr. Paul Heidenreich, an expert in implementation sciences with a focus on the use of EHR interventions to improve care quality for cardiovascular patients and evaluating the cost-effectiveness of new technologies. The research proposal builds on the candidate's prior work with using machine learning and EHR data to evaluate and predict cardiovascular disease outcomes. The candidate now proposes to characterize the performance of machine learning algorithms in identifying patients with peripheral artery disease (PAD) using EHR data (Aim 1), evaluate whether learned classification models perform better than traditional risk factors for identification of undiagnosed PAD in a prospective patient cohort (Aim 2), and implement an EHR-based screening tool to identify patients with undiagnosed PAD and evaluate the diagnosis and treatment effects (Aim 3). Completion of the proposed research will result in a novel, EHR-based screening tool for identification of undiagnosed vascular disease that can decrease PAD-related cardiovascular morbidity and mortality through earlier and more aggressive medical management. This research will also form the basis for an R01 application before the end of the award to conduct a multi-site randomized-controlled clinical trial to evaluate the impact of EHR- based proactive PAD screening. ! ! ! PROJECT NARRATIVE Peripheral artery disease is a prevalent yet under-diagnosed condition that can lead to limb loss, stroke, heart attacks and/or premature death. Work proposed in this grant aims to develop technology using electronic health records and machine learning algorithms to automatically identify patients with undiagnosed peripheral artery disease and recommend treatment. Such technology could improve the health and longevity of patients with peripheral artery disease by ensuring that patients are diagnosed early and appropriately treated.",Using artificial intelligence to enable early identification and treatment of peripheral artery disease,9806796,K01HL148639,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'American', 'Applications Grants', 'Artificial Intelligence', 'Award', 'Awareness', 'Blood Vessels', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Cost Effectiveness Analysis', 'Cost utility', 'Costs and Benefits', 'Current Procedural Terminology Codes', 'Data', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Disease Outcome', 'Early Diagnosis', 'Early identification', 'Early treatment', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Evaluation', 'Event', 'Foundations', 'Future', 'Goals', 'Grant', 'Health', 'Health Services Research', 'Healthcare', 'Healthcare Systems', 'Image', 'Informatics', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Limb structure', 'Logistic Regressions', 'Longevity', 'Machine Learning', 'Medical', 'Medicare', 'Medicine', 'Mentorship', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Newly Diagnosed', 'Noise', 'Notification', 'Ontology', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Peripheral arterial disease', 'Physicians', 'Quality of Care', 'Randomized', 'Randomized Controlled Clinical Trials', 'Recommendation', 'Records', 'Research', 'Research Personnel', 'Research Proposals', 'Research Training', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Stroke', 'Structure', 'Surgeon', 'Symptoms', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Universities', 'Vascular Diseases', 'Work', 'analysis pipeline', 'base', 'biomedical informatics', 'care burden', 'career', 'career development', 'clinical data warehouse', 'clinical implementation', 'cohort', 'computing resources', 'cost', 'cost effective', 'cost outcomes', 'cost-effectiveness evaluation', 'deep learning algorithm', 'design', 'disease diagnosis', 'disorder risk', 'electronic data', 'high risk', 'human subject', 'human very old age (85+)', 'implementation science', 'improved', 'machine learning algorithm', 'mortality', 'new technology', 'novel', 'post-doctoral training', 'premature', 'prevent', 'professor', 'prospective', 'random forest', 'randomized trial', 'recurrent neural network', 'research study', 'screening', 'text searching', 'tool', 'treatment effect']",NHLBI,STANFORD UNIVERSITY,K01,2019,162000,0.021811219784077632
"Clinical Informatics to Advance Epidemiology and Pharmacogenetics of Serious Cutaneous Adverse Drug Reactions Project Summary  Severe cutaneous adverse reactions (SCARs) are morbid immunologic reactions to drugs that confer a mortality of 10-50%. Over the last decade, significant promise for prediction and prevention has come from the discovery that many SCARs are associated with variation within HLA class I alleles. For HLA-B*15:02, this has led to routine pre-prescription screening for carbamazepine in many Southeast Asian countries and a significant reduction in cases of carbamazepine SJS/TEN. Despite this progress, there is little known about genetic and epidemiological risk factors for SCARs related to commonly used drugs such as antibiotics. There is also limited information about HLA risk for SCARs across the diverse populations present in the United States. Furthermore, imprecision of clinical phenotyping and lack of standardized coding has led to challenges in finding SCAR cases in the electronic health record (EHR). Our proposed study aims to address critical challenges and gaps in our knowledge of antibiotic SCARs.  In Aim 1, we will leverage advanced informatics and longitudinal EHR data for over 11 million patients from Partners HealthCare System since the 1980s to identify SCAR cases. We will create, optimize and standardize reproducible methods for finding SCAR cases and validating a cohort of SCAR patients. This iterative process will be used to refine and disseminate an electronic phenotype to be validated cross-institutionally.  In Aim 2, we will analyze SCAR prevalence and conduct a case-control study to identify drug-specific and patient-specific risk factors for antibiotic-associated SCARs. We will compare clinical sequelae, quality of life and adherence of SCAR patients compared to controls through validated survey instruments.  In Aim 3, we will identify candidate HLA and genetic associations from patients with validated antibiotic- associated SCARs. We will examine difference in genetic risk in minority and health disparity populations and predict that we will be powered to establish HLA associations for vancomycin DRESS (i.e., drug reaction with eosinophilia and systemic symptoms) and sulfonamide antimicrobial and beta-lactam SCAR. HLA alone, or in combination with clinical risk factors, can lead to improved SCAR prevention and early diagnosis. We will establish a data sharing platform, in the form of an online electronic phenotype and patient registry, that can be used to enlarge SCAR cohorts for future large-scale genomics studies.  The roadmap we develop will translate into the development of electronic phenotypes for serious adverse drug reactions that facilitate genetic discovery. Knowledge gained will be crucial to the translation of genetic data into clinical decision making. This is in close alignment with NIHs research mission to accelerate genetic discovery for iatrogenic and preventable drug-induced diseases that will translate into prevention, earlier diagnosis and an enhanced mechanistic understanding that may lead to targeted therapeutic approaches. Narrative  Severe cutaneous adverse reactions (SCARs) result in substantial morbidity, long term disability, health care burden and a mortality of 10-50%. To advance the science of clinical and genetic risk factor identification for antibiotic SCAR, we will leverage large electronic health record (EHR) data and advanced informatics technology. Through case validation we will create an informatics roadmap for other institutions with similar EHR data to identify SCAR cases and we will establish a data sharing platform, including an online electronic phenotype and patient registry, that can be used to enlarge SCAR cohorts for future large-scale genomics studies.",Clinical Informatics to Advance Epidemiology and Pharmacogenetics of Serious Cutaneous Adverse Drug Reactions,10018800,R01AI150295,"['Address', 'Adherence', 'Adverse event', 'Adverse reactions', 'Affect', 'African American', 'Alleles', 'Allergic Reaction', 'Allopurinol', 'Antibiotics', 'Autoimmune Diseases', 'Autoimmune Process', 'Biological Markers', 'Carbamazepine', 'Case-Control Studies', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Sciences', 'Code', 'Country', 'Cutaneous', 'Data', 'Dermatology', 'Development', 'Diagnostic', 'Disease', 'Drug Administration Routes', 'Drug Exposure', 'Drug Prescriptions', 'Drug usage', 'Early Diagnosis', 'Electronic Health Record', 'Eosinophilia', 'Epidemiology', 'Ethnic group', 'Female', 'Future', 'Genetic', 'Genetic Risk', 'Genetic Translation', 'Genomics', 'Goals', 'HLA Antigens', 'Healthcare', 'Healthcare Systems', 'Histocompatibility Antigens Class I', 'Hypersensitivity', 'Iatrogenesis', 'Immunologics', 'Immunology', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'International', 'Knowledge', 'Lead', 'Machine Learning', 'Mandatory Reporting', 'Medical Genetics', 'Methodology', 'Methods', 'Minority', 'Mission', 'Modeling', 'Monobactams', 'Morbidity - disease rate', 'Natural Language Processing', 'Nevirapine', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacology', 'Phenotype', 'Population', 'Population Heterogeneity', 'Prevalence', 'Prevention', 'Process', 'Quality of life', 'Race', 'Reaction', 'Registries', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Risk Factors', 'Risk stratification', 'Science', 'Source', 'Specificity', 'Standardization', 'Stevens-Johnson Syndrome', 'Sulfonamides', 'Surveys', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Text', 'Toxic Epidermal Necrolysis', 'Translating', 'Translations', 'United States', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vancomycin', 'Variant', 'abacavir', 'adverse drug reaction', 'antimicrobial', 'base', 'beta-Lactams', 'care burden', 'case control', 'case finding', 'clinical decision-making', 'clinical phenotype', 'clinical practice', 'clinical risk', 'clinically relevant', 'cohort', 'comorbidity', 'data sharing', 'data warehouse', 'design', 'disability', 'dosage', 'genetic association', 'genetic risk factor', 'health disparity', 'immunoreaction', 'improved', 'medication compliance', 'medication safety', 'minority health', 'mortality', 'patient population', 'patient registry', 'prevent', 'racial and ethnic', 'screening', 'sex', 'sharing platform', 'southeast Asian', 'targeted treatment']",NIAID,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,696239,0.07022695911679458
"Clinical Informatics to Advance Epidemiology and Pharmacogenetics of Serious Cutaneous Adverse Drug Reactions Project Summary  Severe cutaneous adverse reactions (SCARs) are morbid immunologic reactions to drugs that confer a mortality of 10-50%. Over the last decade, significant promise for prediction and prevention has come from the discovery that many SCARs are associated with variation within HLA class I alleles. For HLA-B*15:02, this has led to routine pre-prescription screening for carbamazepine in many Southeast Asian countries and a significant reduction in cases of carbamazepine SJS/TEN. Despite this progress, there is little known about genetic and epidemiological risk factors for SCARs related to commonly used drugs such as antibiotics. There is also limited information about HLA risk for SCARs across the diverse populations present in the United States. Furthermore, imprecision of clinical phenotyping and lack of standardized coding has led to challenges in finding SCAR cases in the electronic health record (EHR). Our proposed study aims to address critical challenges and gaps in our knowledge of antibiotic SCARs.  In Aim 1, we will leverage advanced informatics and longitudinal EHR data for over 11 million patients from Partners HealthCare System since the 1980s to identify SCAR cases. We will create, optimize and standardize reproducible methods for finding SCAR cases and validating a cohort of SCAR patients. This iterative process will be used to refine and disseminate an electronic phenotype to be validated cross-institutionally.  In Aim 2, we will analyze SCAR prevalence and conduct a case-control study to identify drug-specific and patient-specific risk factors for antibiotic-associated SCARs. We will compare clinical sequelae, quality of life and adherence of SCAR patients compared to controls through validated survey instruments.  In Aim 3, we will identify candidate HLA and genetic associations from patients with validated antibiotic- associated SCARs. We will examine difference in genetic risk in minority and health disparity populations and predict that we will be powered to establish HLA associations for vancomycin DRESS (i.e., drug reaction with eosinophilia and systemic symptoms) and sulfonamide antimicrobial and beta-lactam SCAR. HLA alone, or in combination with clinical risk factors, can lead to improved SCAR prevention and early diagnosis. We will establish a data sharing platform, in the form of an online electronic phenotype and patient registry, that can be used to enlarge SCAR cohorts for future large-scale genomics studies.  The roadmap we develop will translate into the development of electronic phenotypes for serious adverse drug reactions that facilitate genetic discovery. Knowledge gained will be crucial to the translation of genetic data into clinical decision making. This is in close alignment with NIHs research mission to accelerate genetic discovery for iatrogenic and preventable drug-induced diseases that will translate into prevention, earlier diagnosis and an enhanced mechanistic understanding that may lead to targeted therapeutic approaches. Narrative  Severe cutaneous adverse reactions (SCARs) result in substantial morbidity, long term disability, health care burden and a mortality of 10-50%. To advance the science of clinical and genetic risk factor identification for antibiotic SCAR, we will leverage large electronic health record (EHR) data and advanced informatics technology. Through case validation we will create an informatics roadmap for other institutions with similar EHR data to identify SCAR cases and we will establish a data sharing platform, including an online electronic phenotype and patient registry, that can be used to enlarge SCAR cohorts for future large-scale genomics studies.",Clinical Informatics to Advance Epidemiology and Pharmacogenetics of Serious Cutaneous Adverse Drug Reactions,9857829,R01AI150295,"['Address', 'Adherence', 'Adverse event', 'Adverse reactions', 'Affect', 'African American', 'Alleles', 'Allergic Reaction', 'Allopurinol', 'Antibiotics', 'Autoimmune Diseases', 'Autoimmune Process', 'Biological Markers', 'Carbamazepine', 'Case-Control Studies', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Sciences', 'Code', 'Comorbidity', 'Country', 'Cutaneous', 'Data', 'Dermatology', 'Development', 'Diagnostic', 'Disease', 'Drug Administration Routes', 'Drug Exposure', 'Drug Prescriptions', 'Drug usage', 'Early Diagnosis', 'Electronic Health Record', 'Eosinophilia', 'Epidemiology', 'Ethnic group', 'Female', 'Future', 'Genetic', 'Genetic Risk', 'Genetic Translation', 'Genomics', 'Goals', 'HLA Antigens', 'Healthcare', 'Healthcare Systems', 'Histocompatibility Antigens Class I', 'Hypersensitivity', 'Iatrogenesis', 'Immunologics', 'Immunology', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'International', 'Knowledge', 'Lead', 'Machine Learning', 'Mandatory Reporting', 'Medical Genetics', 'Methodology', 'Methods', 'Minority', 'Mission', 'Modeling', 'Monobactams', 'Morbidity - disease rate', 'Natural Language Processing', 'Nevirapine', 'Outpatients', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacology', 'Phenotype', 'Population', 'Population Heterogeneity', 'Prevalence', 'Prevention', 'Process', 'Quality of life', 'Race', 'Reaction', 'Registries', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Risk Factors', 'Risk stratification', 'Science', 'Source', 'Specificity', 'Standardization', 'Stevens-Johnson Syndrome', 'Sulfonamides', 'Surveys', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Text', 'Toxic Epidermal Necrolysis', 'Translating', 'Translations', 'United States', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vancomycin', 'Variant', 'abacavir', 'adverse drug reaction', 'antimicrobial', 'base', 'beta-Lactams', 'care burden', 'case control', 'case finding', 'clinical decision-making', 'clinical phenotype', 'clinical practice', 'clinical risk', 'clinically relevant', 'cohort', 'data sharing', 'data warehouse', 'design', 'disability', 'dosage', 'genetic association', 'genetic risk factor', 'health disparity', 'immunoreaction', 'improved', 'medication compliance', 'medication safety', 'minority health', 'mortality', 'patient population', 'patient registry', 'prevent', 'racial and ethnic', 'screening', 'sex', 'southeast Asian', 'targeted treatment']",NIAID,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,689571,0.07022695911679458
"Use of Machine Learning on Integrated Electronic Medical Record, Genetic and Waveform Data to Predict Perioperative Cardiorespiratory Instability Project Summary/Abstract  The objective of this K01 application is to give Dr. Hofer the necessary training and research experience to establish himself as an independent investigator focused on using machine learning (ML) on a variety of healthcare data to predict outcomes during the perioperative period. The career development activities consist of escalating coursework on machine learning beginning with an online course of ML fundamentals and ending with a UCLA course on ML applications in healthcare. Augmenting these courses are tutorials on the application of these techniques to healthcare data and a research program is designed to use ML on healthcare data to predict perioperative cardio-respiratory instability (CRI)  specifically hypotension and arrhythmia.  To achieve these goals, Dr. Hofer has established an outstanding team of leaders in machine learning, perioperative medicine, and clinical informatics. Dr. Maxime Cannesson, his primary mentor, is an expert in perioperative medicine and the use of ML on physiologic signals. Dr. Eran Halperin, the co-mentor for this pro- posal, is an expert in ML and its application to genomic and other healthcare data. Dr. Hofer has ongoing collab- orations with Drs. Cannesson and Halperin on joint projects. Both Drs. Cannesson and Halperin have a strong track record of mentoring individuals who have progressed to independent and productive academic careers. Dr. Hofer will be aided by an advisory committee consisting of Dr. Douglas Bell (who will provide guidance on integrating data from multiple sources), Dr. Mohammed Mahbouba (providing support regarding data security and creating enterprise level analytic solutions) and Dr. Jeanine Wiener-Kronish (providing guidance on the most relevant questions in perioperative outcome prediction).  Challenges managing CRI have been implicated in the more than 15 million annual postoperative com- plications, costing more than $165 billion, however no scores exist to predict CRI. This study will leverage unique infrastructure at UCLA where whole EMR data has been combined with physiologic waveforms and genomic data on more than 30,000 patients. This proposal will use a variety of ML techniques on these data to create predictive models for CRI.  In summary, this proposal will provide Dr. Hofer with both technical training in ML and hands on experi- ence in using ML to predict perioperative outcomes. This study has the potential to create models that will help clinicians predict, and thus avoid, perioperative instability, thereby improving patient outcomes. Additionally, this program will provide Dr. Hofer with the tools he needs to successfully compete for a R01 focusing on using ML models on a variety of healthcare data to predict the downstream effects of CRI  perioperative complications. Project Narrative During the perioperative period hemodynamic instability is the norm rather than the exception; the ability of clinicians to manage this instability has been associated with postoperative complications affecting more than 15 million Americans and costing more than $165 billion each year. There are no current risk scores that predict instability in real time, however the recent widespread adoption of electronic medical records and creation of genomic biobanks creates unique opportunities to develop scores that are both accurate and precise. We will use machine learning techniques to create risk scores for perioperative cardiorespiratory instability  specifically hypotension and arrhythmia  using combined electronic medical record, genomic and physiologic waveform data.","Use of Machine Learning on Integrated Electronic Medical Record, Genetic and Waveform Data to Predict Perioperative Cardiorespiratory Instability",10055690,K01HL150318,"['Acute', 'Adoption', 'Advisory Committees', 'Affect', 'African American', 'Algorithms', 'American', 'Arrhythmia', 'Atlases', 'California', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computerized Medical Record', 'Data', 'Data Security', 'Databases', 'Disease', 'Ensure', 'Event', 'Functional disorder', 'Genetic', 'Genetic Databases', 'Genetic Risk', 'Genomics', 'Goals', 'Health', 'Healthcare', 'Hypotension', 'Individual', 'Infrastructure', 'Inpatients', 'Joints', 'Latino', 'Logistic Regressions', 'Los Angeles', 'Machine Learning', 'Manuals', 'Medical Genetics', 'Medical History', 'Medicine', 'Mentors', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Operative Surgical Procedures', 'Outcome', 'Outpatients', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perioperative', 'Perioperative complication', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Physiology', 'Population Analysis', 'Population Heterogeneity', 'Postoperative Complications', 'Prevalence', 'Process', 'Provider', 'Recurrence', 'Research', 'Research Personnel', 'Risk', 'Signal Transduction', 'Subgroup', 'Techniques', 'Time', 'Training', 'Universities', 'Work', 'acute stress', 'automated algorithm', 'base', 'biobank', 'biological adaptation to stress', 'career', 'career development', 'cost', 'deep neural network', 'design', 'diverse data', 'electronic data', 'ethnic minority population', 'experience', 'feeding', 'genetic information', 'genetic profiling', 'genomic data', 'hemodynamics', 'improved', 'long short term memory', 'multiple data sources', 'online course', 'outcome prediction', 'phenotyping algorithm', 'prediction algorithm', 'predictive modeling', 'pressure', 'prevent', 'programs', 'random forest', 'structured data', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,K01,2020,175284,0.029083545731169478
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",9946212,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Communities', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2020,611043,0.011356906675241899
"Addressing variability in peripheral arterial disease outcomes using machine learning techniques Project Summary/Abstract: Peripheral arterial disease (PAD) is a major cause of morbidity and mortality in the United States, affecting over eight million Americans, of whom 100,000 a year suffer major amputation. Current guidelines dictate medical treatment and aggressive risk factor modification for all PAD patients, whether symptomatic or not, with revascularization attempts for patients with chronic limb threatening ischemia (CLTI) or lifestyle-limiting claudication. Despite strongly-worded standards of care, variability in PAD outcomes persists. Prior research has demonstrated that some demographic factors such as gender, race, and socioeconomic status are associated with worse PAD care and outcomes even when controlling for comorbidities. It is unknown what specific patient, provider, and healthcare system factors lead to these disparities. Efforts to understand which patients will suffer worse outcomes and disease progression have been hampered by contemporary outcomes research techniques. The majority of PAD outcomes research relies on administrative claims databases, procedural registries, or single center retrospective reviews. While each of these methods has some advantages, none offer the combination of patient- and disease-specific data, information about care provision on a provider and health-system level, and outcomes across a range of possible locations. Furthermore, use of any of these methods at the scale necessary to draw powerful conclusions is prohibitively time- and resource-intensive. The overall objective of this research is to use a novel natural language processing model to build a combined EHR/CMS database and to use that database to predict which PAD patients are at highest risk of poor outcomes with improved power and precision. This proposal contains plans for collaboration with Duke Forge, who bring expertise in natural language processing and machine learning in order to efficiently identify PAD patients within our EHR and efficiently abstract information about them. Once identified, these patients can be linked to their CMS outcomes, allowing for assessment of how patient-, physician-, and healthcare-specific factors affect PAD outcomes. Our central hypothesis is that natural language processing powered by machine learning will permit efficient identification of patients with PAD, thereby facilitating higher-powered and higher-quality investigation into disparities in PAD outcomes. This research will pave the way for future interventions targeting sources of outcome inequality, possibly including access to care, physician adherence to national guidelines, and patient preferences or health literacy. Project Narrative: Peripheral arterial disease affects more than eight million Americans, with over one hundred thousand amputations performed yearly. Despite the prevalence and morbidity of this disease, there is a lack of knowledge about which patients will require amputation, multiple surgeries or hospitalizations, or suffer cardiovascular- related death. This proposal uses natural language processing to improve on current research methodology in order to account for patient-specific, physician-specific, and system-specific factors in peripheral arterial disease care and outcomes.",Addressing variability in peripheral arterial disease outcomes using machine learning techniques,10066805,F32HL151181,"['Address', 'Adherence', 'Affect', 'American', 'Amputation', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Chronic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Country', 'Data', 'Data Set', 'Databases', 'Demographic Factors', 'Disease', 'Disease Outcome', 'Disease Progression', 'Documentation', 'Elements', 'Failure', 'Female', 'Future', 'Gender', 'Goals', 'Guidelines', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Inequality', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Intervention', 'Investigation', 'Ischemia', 'Knowledge', 'Lead', 'Life Style', 'Light', 'Limb structure', 'Link', 'Location', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patient Preferences', 'Patients', 'Peripheral arterial disease', 'Physicians', 'Prevalence', 'Process', 'Provider', 'Race', 'Registries', 'Research', 'Research Methodology', 'Research Technics', 'Resources', 'Risk', 'Risk Factors', 'Socioeconomic Status', 'Source', 'Stroke', 'System', 'Techniques', 'Text', 'Time', 'Training', 'United States', 'Work', 'adjudicate', 'base', 'care outcomes', 'claudication', 'cohort', 'comorbidity', 'cost', 'demographics', 'design', 'effective intervention', 'health literacy', 'high risk', 'improved', 'low socioeconomic status', 'mortality', 'novel', 'patient subsets', 'tool', 'treatment effect']",NHLBI,DUKE UNIVERSITY,F32,2020,82476,0.05490334819391928
"A framework to stratify patient cohorts for clinical management PROJECT SUMMARY  Existing Electronic Health Record (EHR) systems have limited functionality to find patients that can benefit by particular interventions. Hence, clinicians are unable to proactively reach-out to these patients, leading to an ever-widening evidence-care gap. The goal of this proposal is to improve healthcare delivery. The objective is to develop a data-framework for accurately finding patients that can benefits from large/population scale interventions. We will investigate two dimensions for improving the patient searchincreasing the resolution of the search (aim 1) and increasing the quality of the data that the search is performed on (aim 2). In aim 1 we will test the hypothesis that a rule-based model of the relevant clinical guideline, will find patients with higher accuracy than the conventional queries. The rational is that the rule-based approach will allow complex groupings of the eligibility criteria and will thereby provide a higher resolution of search than conventional query. In aim 2 we will investigate whether machine learning (ML) can improve the accuracy of patient data and contribute to the accuracy of search results obtained through the conventional query and the guideline rule-base. In addition to the above aims, in aim 3 we will automate deployment of the rule-base and ML models and minimize the manual effort for developing ML models. This proposal builds on the lipid management program at Brigham and Women's hospital (BWH). Our work will be focused on finding patients for lipid- management; however, our methodology and tooling will be generalizable to other medical areas and institutions. The study team includes national experts in cardiology, machine learning, health information technology (HIT) and open-source software development. We will create an open-source software platform (i2b2-ML) by extending the popular `Informatics for Integration Biology and the Bedside' (i2b2) platform that we have developed and supported over the past 10 years and that is used by over 200 medical centers. I2b2-ML will extend i2b2's proven ability to characterize patient cohorts for research into the clinical realm. Our study will yield methodology for accurately finding patients that can benefit by clinical intervention and will thereby enable cost-effectiveness of population programs. It will directly help scale the lipid management program at BWH to benefit a wider patient population. Our detailed characterization of the gaps in lipid management at a large healthcare system will potentially inform improvements in the lipid management guideline. The methodology and tooling developed in this project will be disseminated in open-source for potential incorporation in the clinical data infrastructure at other institutions, which will facilitate implementation of population-scale clinical programs across the nation. In addition, the resultant infrastructure will serve as a platform for development of artificial intelligence-based applications to improve clinical care. These outcomes are expected to have a positive impact on health care delivery so that more patients will get the optimal care. PROJECT NARRATIVE We propose developing Informatics for Integrating Biology and the Bedside (i2b2), a well-established, open source, platform that is currently used at over 200 hospitals and medical centers to use machine learning for identifying patient groups receiving suboptimal care. The proposed work will enable healthcare institutions across the United States to proactively reach-out to these patients, for delivering the appropriate clinical intervention. This pioneering research directly impacts public health by improving the quality of care.",A framework to stratify patient cohorts for clinical management,9942560,R01HL151643,"['Area', 'Artificial Intelligence', 'Biology', 'Cardiology', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Code', 'Complex', 'Computer software', 'Cues', 'Data', 'Development', 'Diabetes Mellitus', 'Effectiveness', 'Electronic Health Record', 'Eligibility Determination', 'Evidence based intervention', 'Goals', 'Grouping', 'Guidelines', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Intervention', 'Laboratories', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical center', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Population Programs', 'Procedures', 'Public Health', 'Quality of Care', 'Research', 'Resolution', 'Structure', 'System', 'Testing', 'Therapeutic', 'Time', 'United States', 'Woman', 'Work', 'base', 'clinical care', 'clinically relevant', 'cohort', 'cost effectiveness', 'data framework', 'data infrastructure', 'health care delivery', 'health information technology', 'improved', 'insight', 'machine learning algorithm', 'machine learning method', 'open source', 'patient population', 'patient registry', 'patient stratification', 'phrases', 'precision medicine', 'programs', 'repository', 'software development', 'structured data', 'tool', 'two-dimensional']",NHLBI,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,847357,0.03839691565525865
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing DESCRIPTION (provided by applicant):  Colonoscopy is the predominant method for screening for colorectal cancer in the US. Yet, its effectiveness in screening is limited by variation in performance. For example, the rate at which physicians detect cancer precursors called adenomas during a colonoscopy has been shown to vary three-fold from one physician to another. A patient whose colonoscopy is performed by a physician with a low adenoma detection rate has a higher risk of subsequent colorectal cancer.  Our proposal centers on measuring, understanding, and improving colonoscopy quality. The major innovation of this work is to use natural language processing (NLP) to measure the quality of colonoscopy. NLP is a field of computer science in which a computer is trained to ""read"" text to identify relevant data We developed and validated the first NLP-based computer software application (C-QUAL) that analyzes colonoscopy and associated pathology reports. Our primary quality measure is adenoma detection rate because it is a common, validated measure that is linked to colorectal cancer incidence. However, we also use a number of secondary quality measures. We applied C-QUAL to almost 25,000 colonoscopy reports in one health system and found large variation in physician's performance on the quality measures. Building on this prior work, our goal is to use C-QUAL to measure colonoscopy quality across a spectrum of US practice environments, to understand what drives variation in colonoscopy quality, and to improve colonoscopy quality. In Aim 1, we propose to use the C-QUAL tool to measure performance in 4 diverse health care systems. This will be one of the largest assessments of the variation in adenoma detection rates and will span different geographic regions, payment systems, and practice settings. In Aim 2, we seek to understand why there is variation in quality. We will survey providers at the 4 health care systems about factors that might affect quality. We will link those survey results to the adenoma detection rates assessed in Aim 1 and look for key associations. It is assumed, but not proven, that providing feedback to physicians on colonoscopy quality will improve care. In Aim 3, we assess whether feedback to physicians does drive quality improvement and, building on Aim 2, explore which types of physicians may respond to feedback. Our proposal is the first to use this innovative method to measure colonoscopy quality and to use the quality scores to decrease the variation in colonoscopy performance. Together the results of the 3 aims are consistent with the NCI's focus on improving the quality of colorectal cancer screening. PUBLIC HEALTH RELEVANCE: Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and provide physician feedback to stimulate quality improvement.",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,9025565,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Caring', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Health', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Site', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'programs', 'screening', 'symposium', 'tool', 'trend']",NCI,HARVARD MEDICAL SCHOOL,R01,2016,409330,0.02702394660218163
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing DESCRIPTION (provided by applicant):  Colonoscopy is the predominant method for screening for colorectal cancer in the US. Yet, its effectiveness in screening is limited by variation in performance. For example, the rate at which physicians detect cancer precursors called adenomas during a colonoscopy has been shown to vary three-fold from one physician to another. A patient whose colonoscopy is performed by a physician with a low adenoma detection rate has a higher risk of subsequent colorectal cancer.  Our proposal centers on measuring, understanding, and improving colonoscopy quality. The major innovation of this work is to use natural language processing (NLP) to measure the quality of colonoscopy. NLP is a field of computer science in which a computer is trained to ""read"" text to identify relevant data We developed and validated the first NLP-based computer software application (C-QUAL) that analyzes colonoscopy and associated pathology reports. Our primary quality measure is adenoma detection rate because it is a common, validated measure that is linked to colorectal cancer incidence. However, we also use a number of secondary quality measures. We applied C-QUAL to almost 25,000 colonoscopy reports in one health system and found large variation in physician's performance on the quality measures. Building on this prior work, our goal is to use C-QUAL to measure colonoscopy quality across a spectrum of US practice environments, to understand what drives variation in colonoscopy quality, and to improve colonoscopy quality. In Aim 1, we propose to use the C-QUAL tool to measure performance in 4 diverse health care systems. This will be one of the largest assessments of the variation in adenoma detection rates and will span different geographic regions, payment systems, and practice settings. In Aim 2, we seek to understand why there is variation in quality. We will survey providers at the 4 health care systems about factors that might affect quality. We will link those survey results to the adenoma detection rates assessed in Aim 1 and look for key associations. It is assumed, but not proven, that providing feedback to physicians on colonoscopy quality will improve care. In Aim 3, we assess whether feedback to physicians does drive quality improvement and, building on Aim 2, explore which types of physicians may respond to feedback. Our proposal is the first to use this innovative method to measure colonoscopy quality and to use the quality scores to decrease the variation in colonoscopy performance. Together the results of the 3 aims are consistent with the NCI's focus on improving the quality of colorectal cancer screening. PUBLIC HEALTH RELEVANCE: Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and provide physician feedback to stimulate quality improvement.",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,8830936,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Caring', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Health', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Site', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'programs', 'screening', 'symposium', 'tool', 'trend']",NCI,HARVARD MEDICAL SCHOOL,R01,2015,494533,0.02702394660218163
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing     DESCRIPTION (provided by applicant):  Colonoscopy is the predominant method for screening for colorectal cancer in the US. Yet, its effectiveness in screening is limited by variation in performance. For example, the rate at which physicians detect cancer precursors called adenomas during a colonoscopy has been shown to vary three-fold from one physician to another. A patient whose colonoscopy is performed by a physician with a low adenoma detection rate has a higher risk of subsequent colorectal cancer.  Our proposal centers on measuring, understanding, and improving colonoscopy quality. The major innovation of this work is to use natural language processing (NLP) to measure the quality of colonoscopy. NLP is a field of computer science in which a computer is trained to ""read"" text to identify relevant data We developed and validated the first NLP-based computer software application (C-QUAL) that analyzes colonoscopy and associated pathology reports. Our primary quality measure is adenoma detection rate because it is a common, validated measure that is linked to colorectal cancer incidence. However, we also use a number of secondary quality measures. We applied C-QUAL to almost 25,000 colonoscopy reports in one health system and found large variation in physician's performance on the quality measures. Building on this prior work, our goal is to use C-QUAL to measure colonoscopy quality across a spectrum of US practice environments, to understand what drives variation in colonoscopy quality, and to improve colonoscopy quality. In Aim 1, we propose to use the C-QUAL tool to measure performance in 4 diverse health care systems. This will be one of the largest assessments of the variation in adenoma detection rates and will span different geographic regions, payment systems, and practice settings. In Aim 2, we seek to understand why there is variation in quality. We will survey providers at the 4 health care systems about factors that might affect quality. We will link those survey results to the adenoma detection rates assessed in Aim 1 and look for key associations. It is assumed, but not proven, that providing feedback to physicians on colonoscopy quality will improve care. In Aim 3, we assess whether feedback to physicians does drive quality improvement and, building on Aim 2, explore which types of physicians may respond to feedback. Our proposal is the first to use this innovative method to measure colonoscopy quality and to use the quality scores to decrease the variation in colonoscopy performance. Together the results of the 3 aims are consistent with the NCI's focus on improving the quality of colorectal cancer screening.           PUBLIC HEALTH RELEVANCE: Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and provide physician feedback to stimulate quality improvement.                  ",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,8641674,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Caring', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Metric', 'Monitor', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Site', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'public health relevance', 'screening', 'symposium', 'tool', 'trend']",NCI,HARVARD MEDICAL SCHOOL,R01,2014,547410,0.02702394660218163
"Automated Dynamic Lists for Efficient Electronic Health Record Management DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment. PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.",Automated Dynamic Lists for Efficient Electronic Health Record Management,8926527,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype']",NCI,"CLINACUITY,INC.",R41,2014,24960,0.10108631411958426
"Automated Dynamic Lists for Efficient Electronic Health Record Management     DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Dynamic Lists for Efficient Electronic Health Record Management,8830154,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype', 'public health relevance']",NCI,"CLINACUITY,INC.",R41,2014,119730,0.10108631411958426
"Automated Dynamic Lists for Efficient Electronic Health Record Management     DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Dynamic Lists for Efficient Electronic Health Record Management,8590856,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype', 'public health relevance']",NCI,"CLINACUITY,INC.",R41,2013,81334,0.10108631411958426
"Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record     DESCRIPTION (provided by applicant): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposed a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer, and established its feasibility. To advance this new system from a prototype to an accurate, adaptable, and robust system, integrated into the commercial EHR system used in our implementation and testing site (Huntsman Cancer Institute and University of Utah Hospital, Salt Lake City, Utah), and ready for commercialization efforts, we will work on the following aims: 1) enhance the NLP system performance, scalability, and quality, 2) develop an advanced visualization interface for local adaptation of the NLP system, and 3) integrate the NLP system with a commercial EHR system. A large and varied reference standard for training and testing the information extraction application will also be developed, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute and at the University of Utah Hospital (Salt Lake City, Utah), with problems and allergies annotated by domain experts. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare & Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and its output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment. PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.",Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record,9357564,R42CA180190,"['Adverse drug event', 'Cessation of life', 'Cities', 'Clinical', 'Code', 'Communications Media', 'Complex', 'Development', 'Disease', 'Electronic Health Record', 'Ensure', 'Environment', 'Excision', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'Hospitals', 'Huntsman Cancer Institute at the University of Utah', 'Hybrids', 'Hypersensitivity', 'Imagery', 'Incentives', 'Injury', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Modernization', 'Natural Language Processing', 'Outpatients', 'Output', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Savings', 'Secure', 'Site', 'Sodium Chloride', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Utah', 'Work', 'base', 'cancer care', 'commercial application', 'commercialization', 'computerized physician order entry', 'cost', 'design', 'improved', 'payment', 'prevent', 'processing speed', 'prototype', 'public health relevance', 'software development', 'standard measure', 'usability', 'web services']",NCI,"CLINACUITY,INC.",R42,2017,767485,0.1225054284986488
"Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record     DESCRIPTION (provided by applicant): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposed a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer, and established its feasibility. To advance this new system from a prototype to an accurate, adaptable, and robust system, integrated into the commercial EHR system used in our implementation and testing site (Huntsman Cancer Institute and University of Utah Hospital, Salt Lake City, Utah), and ready for commercialization efforts, we will work on the following aims: 1) enhance the NLP system performance, scalability, and quality, 2) develop an advanced visualization interface for local adaptation of the NLP system, and 3) integrate the NLP system with a commercial EHR system. A large and varied reference standard for training and testing the information extraction application will also be developed, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute and at the University of Utah Hospital (Salt Lake City, Utah), with problems and allergies annotated by domain experts. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare & Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and its output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record,9138574,R42CA180190,"['Adverse drug event', 'Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinical', 'Code', 'Communications Media', 'Complex', 'Development', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Environment', 'Excision', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'Hospitals', 'Huntsman Cancer Institute at the University of Utah', 'Hybrids', 'Hypersensitivity', 'Imagery', 'Incentives', 'Injury', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Secure', 'Site', 'Sodium Chloride', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Utah', 'Work', 'base', 'commercial application', 'commercialization', 'computerized physician order entry', 'design', 'improved', 'payment', 'prevent', 'processing speed', 'prototype', 'public health relevance', 'software development', 'standard measure', 'usability', 'web services']",NCI,"CLINACUITY,INC.",R42,2016,684880,0.1225054284986488
"EMR Adverse Drug Event Detection for Pharmacovigilance DESCRIPTION (provided by applicant): Adverse drug events (ADEs) result in substantial patient morbidity and lead to over 100,000 deaths yearly. The timely identification of previously unknown toxicities of cancer drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Medical Record (EMR), discharge summaries, and lab results contain ADE information and biomedical natural language processing (BioNLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. The objectives for this proposal are to develop ""intelligent"" BioNLP approaches to extract disease, medication, and structured ADE information from EMRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PUBLIC HEALTH RELEVANCE: EMR Adverse Drug Event Detection This project proposes innovative intelligent biomedical natural language process approaches to automatically extract adverse drug event from the Electronic Medical Record. It is anticipated that the data resources, algorithms, and the Pharmacovigilance Toolkit developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EMR Adverse Drug Event Detection for Pharmacovigilance,9123554,U01CA180975,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Antineoplastic Agents', 'Biology', 'Boxing', 'Cancer Center', 'Cancer Research Network', 'Cessation of life', 'Clinical', 'Clinical Oncology', 'Clinical Trials', 'Collaborations', 'Common Terminology Criteria for Adverse Events', 'Comprehensive Cancer Center', 'Computerized Medical Record', 'Data', 'Detection', 'Discipline of Nursing', 'Disease', 'Drug toxicity', 'Elements', 'Future', 'Goals', 'Health Promotion', 'Hematology', 'Hospitals', 'Informatics', 'Injury', 'Inpatients', 'Intervention', 'Knowledge', 'Language', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Outpatients', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Prevention', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Safety', 'Severities', 'Signal Transduction', 'Structure', 'System', 'Terminology', 'Testing', 'Therapeutic', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Weight', 'Work', 'abstracting', 'disorder prevention', 'firewall', 'improved', 'innovation', 'insight', 'lenalidomide', 'medical schools', 'mortality', 'novel', 'oncology', 'open source', 'patient safety', 'post-market', 'public health relevance', 'response', 'tool']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U01,2016,336980,0.049261067990440575
"EMR Adverse Drug Event Detection for Pharmacovigilance DESCRIPTION (provided by applicant): Adverse drug events (ADEs) result in substantial patient morbidity and lead to over 100,000 deaths yearly. The timely identification of previously unknown toxicities of cancer drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Medical Record (EMR), discharge summaries, and lab results contain ADE information and biomedical natural language processing (BioNLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. The objectives for this proposal are to develop ""intelligent"" BioNLP approaches to extract disease, medication, and structured ADE information from EMRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PUBLIC HEALTH RELEVANCE: EMR Adverse Drug Event Detection This project proposes innovative intelligent biomedical natural language process approaches to automatically extract adverse drug event from the Electronic Medical Record. It is anticipated that the data resources, algorithms, and the Pharmacovigilance Toolkit developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EMR Adverse Drug Event Detection for Pharmacovigilance,8913078,U01CA180975,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Antineoplastic Agents', 'Biology', 'Boxing', 'Cancer Center', 'Cancer Research Network', 'Cessation of life', 'Clinical', 'Clinical Oncology', 'Clinical Trials', 'Collaborations', 'Common Terminology Criteria for Adverse Events', 'Comprehensive Cancer Center', 'Computerized Medical Record', 'Data', 'Detection', 'Discipline of Nursing', 'Disease', 'Drug toxicity', 'Elements', 'Future', 'Goals', 'Health Promotion', 'Hematology', 'Hospitals', 'Informatics', 'Injury', 'Inpatients', 'Intervention', 'Knowledge', 'Language', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Outpatients', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Prevention', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Safety', 'Severities', 'Signal Transduction', 'Structure', 'System', 'Terminology', 'Testing', 'Therapeutic', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Weight', 'Work', 'abstracting', 'disorder prevention', 'firewall', 'improved', 'innovation', 'insight', 'lenalidomide', 'medical schools', 'mortality', 'novel', 'oncology', 'open source', 'patient safety', 'post-market', 'public health relevance', 'response', 'tool']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U01,2015,339117,0.049261067990440575
"EMR Adverse Drug Event Detection for Pharmacovigilance     DESCRIPTION (provided by applicant): Adverse drug events (ADEs) result in substantial patient morbidity and lead to over 100,000 deaths yearly. The timely identification of previously unknown toxicities of cancer drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Medical Record (EMR), discharge summaries, and lab results contain ADE information and biomedical natural language processing (BioNLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. The objectives for this proposal are to develop ""intelligent"" BioNLP approaches to extract disease, medication, and structured ADE information from EMRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified.         PUBLIC HEALTH RELEVANCE: EMR Adverse Drug Event Detection This project proposes innovative intelligent biomedical natural language process approaches to automatically extract adverse drug event from the Electronic Medical Record. It is anticipated that the data resources, algorithms, and the Pharmacovigilance Toolkit developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.            ",EMR Adverse Drug Event Detection for Pharmacovigilance,8772667,U01CA180975,"['Adverse event', 'Algorithms', 'Antineoplastic Agents', 'Biology', 'Boxing', 'Cancer Center', 'Cancer Research Network', 'Cessation of life', 'Clinical', 'Clinical Oncology', 'Clinical Trials', 'Collaborations', 'Common Terminology Criteria for Adverse Events', 'Comprehensive Cancer Center', 'Computerized Medical Record', 'Data', 'Detection', 'Discipline of Nursing', 'Disease', 'Drug toxicity', 'Elements', 'Event', 'Future', 'Goals', 'Health Promotion', 'Hematology', 'Hospitals', 'Informatics', 'Injury', 'Inpatients', 'Intervention', 'Knowledge', 'Language', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Outpatients', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Prevention', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Safety', 'Severities', 'Signal Transduction', 'Structure', 'System', 'Terminology', 'Testing', 'Therapeutic', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Weight', 'Work', 'abstracting', 'disorder prevention', 'firewall', 'improved', 'innovation', 'insight', 'lenalidomide', 'medical schools', 'mortality', 'novel', 'oncology', 'open source', 'patient safety', 'post-market', 'public health relevance', 'response', 'tool']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U01,2014,374997,0.049261067990440575
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9994228,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Management Resources', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Information Retrieval', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data exchange', 'data harmonization', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'informatics tool', 'interest', 'learning algorithm', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'pharmacovigilance', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2020,618291,0.07316829714817964
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9774751,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'informatics\xa0tool', 'interest', 'learning algorithm', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'pharmacovigilance', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2019,600683,0.07316829714817964
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics     DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9674607,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2018,79500,0.07316829714817964
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics     DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9789497,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2018,79500,0.07316829714817964
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics     DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9548987,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2018,620106,0.07316829714817964
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics     DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9331533,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Award', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2017,623596,0.07316829714817964
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics     DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities.         PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.            ",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9094161,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Award', 'Benefits and Risks', 'CCL4 gene', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Intervention', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'novel', 'open source', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2016,652772,0.07316829714817964
"Scalable Clinical Decision Support for Individualized Cancer Risk Management Project Summary / Abstract We propose to enable a scalable clinical decision support (CDS) platform that helps clinicians and patients select cancer screening strategies that are best suited to each individual. This kind of CDS is important because increased evidence supports personalizing cancer screening decisions according to each individual's unique cancer risks. While a highly desired goal, individualizing screening at a population scale requires the implementation of patient-specific risk assessments for several types of cancer. This is quite challenging in today's overwhelmed primary care environment. Our proposed CDS platform addresses this challenge by (i) automating the risk stratification process at the population level based on EHR data and patient reported data; (ii) prioritizing patients for case review by genetic counselors; and (iii) automatically communicating risk and screening recommendations with primary care providers and their patients. We will integrate the CDS platform with the Epic EHR and test it at the University of Utah Health Care community clinics and the Huntsman Cancer Institute. We will assess the generalizability of the CDS platform with a different EHR (Cerner) at a different institution (Intermountain Healthcare). To maximize the dissemination potential for the proposed cancer risk screening platform, we will extend two well-established open source CDS platforms: OpenCDS and OpenInfobutton. These platforms are reference implementations of international EHR standards that are required for EHR certification in the US. We will also obtain software certification from the Open Source EHR Alliance, share the CDS platform and our experiences with other awardees in the ITCR Program, present the CDS platform at national and international cancer and informatics conferences; and engage with relevant stakeholders through a technical expert panel. Any healthcare organization with a certified EHR will be able to use the proposed CDS platform. Therefore, if successful, this proposal can have a significant impact on disseminating individualized cancer screening practices according to the best available evidence. The proposed research addresses the need for individualizing cancer screening according to the risk of an individual. We propose to enable software that scans electronic health records of entire patient populations to automatically detect those at a high risk to develop specific types of cancer according to cancer guidelines. Genetic counselors will review patients identified by the software, and discuss optimal cancer screening strategies with the patient and their primary care providers.",Scalable Clinical Decision Support for Individualized Cancer Risk Management,9979779,U24CA204800,"['Address', 'Adoption', 'Algorithms', 'Architecture', 'Breast Cancer Detection', 'Breast Cancer Risk Factor', 'Certification', 'Colorectal Cancer', 'Computer software', 'Coupled', 'Data', 'Data Reporting', 'Detection', 'Documentation', 'Ecosystem', 'Electronic Health Record', 'Environment', 'Family', 'Goals', 'Guidelines', 'Healthcare', 'Healthcare Systems', 'Incentives', 'Individual', 'Informatics', 'Information Retrieval', 'Infrastructure', 'Institutes', 'Institution', 'International', 'Intervention', 'Logic', 'Malignant Neoplasms', 'Modality', 'National Comprehensive Cancer Network', 'Natural Language Processing pipeline', 'Patient Care', 'Patients', 'Population', 'Primary Health Care', 'Process', 'Provider', 'PubMed', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Management', 'Risk stratification', 'Scanning', 'Screening for cancer', 'System', 'Technology', 'Testing', 'Universities', 'Utah', 'base', 'cancer risk', 'cancer type', 'care providers', 'clinical decision support', 'colorectal cancer risk', 'community clinic', 'design', 'experience', 'genetic counselor', 'health care service organization', 'healthcare community', 'high risk', 'improved', 'incentive program', 'malignant breast neoplasm', 'online course', 'online resource', 'open source', 'patient population', 'personalized screening', 'primary care setting', 'programs', 'screening', 'screening guidelines', 'support tools', 'symposium', 'web services']",NCI,UNIVERSITY OF UTAH,U24,2020,745481,0.06318183699325636
"Scalable Clinical Decision Support for Individualized Cancer Risk Management Project Summary / Abstract We propose to enable a scalable clinical decision support (CDS) platform that helps clinicians and patients select cancer screening strategies that are best suited to each individual. This kind of CDS is important because increased evidence supports personalizing cancer screening decisions according to each individual's unique cancer risks. While a highly desired goal, individualizing screening at a population scale requires the implementation of patient-specific risk assessments for several types of cancer. This is quite challenging in today's overwhelmed primary care environment. Our proposed CDS platform addresses this challenge by (i) automating the risk stratification process at the population level based on EHR data and patient reported data; (ii) prioritizing patients for case review by genetic counselors; and (iii) automatically communicating risk and screening recommendations with primary care providers and their patients. We will integrate the CDS platform with the Epic EHR and test it at the University of Utah Health Care community clinics and the Huntsman Cancer Institute. We will assess the generalizability of the CDS platform with a different EHR (Cerner) at a different institution (Intermountain Healthcare). To maximize the dissemination potential for the proposed cancer risk screening platform, we will extend two well-established open source CDS platforms: OpenCDS and OpenInfobutton. These platforms are reference implementations of international EHR standards that are required for EHR certification in the US. We will also obtain software certification from the Open Source EHR Alliance, share the CDS platform and our experiences with other awardees in the ITCR Program, present the CDS platform at national and international cancer and informatics conferences; and engage with relevant stakeholders through a technical expert panel. Any healthcare organization with a certified EHR will be able to use the proposed CDS platform. Therefore, if successful, this proposal can have a significant impact on disseminating individualized cancer screening practices according to the best available evidence. The proposed research addresses the need for individualizing cancer screening according to the risk of an individual. We propose to enable software that scans electronic health records of entire patient populations to automatically detect those at a high risk to develop specific types of cancer according to cancer guidelines. Genetic counselors will review patients identified by the software, and discuss optimal cancer screening strategies with the patient and their primary care providers.",Scalable Clinical Decision Support for Individualized Cancer Risk Management,9749060,U24CA204800,"['Address', 'Adoption', 'Algorithms', 'Architecture', 'Breast Cancer Detection', 'Breast Cancer Risk Factor', 'Certification', 'Colorectal Cancer', 'Community Healthcare', 'Computer software', 'Coupled', 'Data', 'Data Reporting', 'Detection', 'Documentation', 'Ecosystem', 'Electronic Health Record', 'Environment', 'Family', 'Goals', 'Guidelines', 'Healthcare', 'Healthcare Systems', 'Incentives', 'Individual', 'Informatics', 'Information Retrieval', 'Infrastructure', 'Institutes', 'Institution', 'International', 'Intervention', 'Logic', 'Malignant Neoplasms', 'Modality', 'National Comprehensive Cancer Network', 'Natural Language Processing pipeline', 'Patient Care', 'Patients', 'Population', 'Primary Health Care', 'Process', 'Provider', 'PubMed', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Management', 'Risk stratification', 'Scanning', 'Screening for cancer', 'System', 'Technology', 'Testing', 'Universities', 'Utah', 'base', 'cancer risk', 'cancer type', 'care providers', 'clinical decision support', 'colorectal cancer risk', 'community clinic', 'design', 'experience', 'genetic counselor', 'health care service organization', 'healthcare community', 'high risk', 'improved', 'incentive program', 'malignant breast neoplasm', 'online course', 'online resource', 'open source', 'patient population', 'personalized screening', 'primary care setting', 'programs', 'screening', 'screening guidelines', 'support tools', 'symposium', 'web services']",NCI,UNIVERSITY OF UTAH,U24,2019,733691,0.06318183699325636
"Scalable Clinical Decision Support for Individualized Cancer Risk Management Project Summary / Abstract We propose to enable a scalable clinical decision support (CDS) platform that helps clinicians and patients select cancer screening strategies that are best suited to each individual. This kind of CDS is important because increased evidence supports personalizing cancer screening decisions according to each individual's unique cancer risks. While a highly desired goal, individualizing screening at a population scale requires the implementation of patient-specific risk assessments for several types of cancer. This is quite challenging in today's overwhelmed primary care environment. Our proposed CDS platform addresses this challenge by (i) automating the risk stratification process at the population level based on EHR data and patient reported data; (ii) prioritizing patients for case review by genetic counselors; and (iii) automatically communicating risk and screening recommendations with primary care providers and their patients. We will integrate the CDS platform with the Epic EHR and test it at the University of Utah Health Care community clinics and the Huntsman Cancer Institute. We will assess the generalizability of the CDS platform with a different EHR (Cerner) at a different institution (Intermountain Healthcare). To maximize the dissemination potential for the proposed cancer risk screening platform, we will extend two well-established open source CDS platforms: OpenCDS and OpenInfobutton. These platforms are reference implementations of international EHR standards that are required for EHR certification in the US. We will also obtain software certification from the Open Source EHR Alliance, share the CDS platform and our experiences with other awardees in the ITCR Program, present the CDS platform at national and international cancer and informatics conferences; and engage with relevant stakeholders through a technical expert panel. Any healthcare organization with a certified EHR will be able to use the proposed CDS platform. Therefore, if successful, this proposal can have a significant impact on disseminating individualized cancer screening practices according to the best available evidence. The proposed research addresses the need for individualizing cancer screening according to the risk of an individual. We propose to enable software that scans electronic health records of entire patient populations to automatically detect those at a high risk to develop specific types of cancer according to cancer guidelines. Genetic counselors will review patients identified by the software, and discuss optimal cancer screening strategies with the patient and their primary care providers.",Scalable Clinical Decision Support for Individualized Cancer Risk Management,9534547,U24CA204800,"['Address', 'Adoption', 'Algorithms', 'Architecture', 'Breast Cancer Detection', 'Breast Cancer Risk Factor', 'Certification', 'Clinic', 'Colorectal Cancer', 'Community Healthcare', 'Computer software', 'Coupled', 'Data', 'Data Reporting', 'Detection', 'Documentation', 'Ecosystem', 'Electronic Health Record', 'Environment', 'Family', 'Goals', 'Guidelines', 'Healthcare', 'Healthcare Systems', 'Incentives', 'Individual', 'Informatics', 'Information Retrieval', 'Institutes', 'Institution', 'International', 'Intervention', 'Logic', 'Malignant Neoplasms', 'Modality', 'National Comprehensive Cancer Network', 'Natural Language Processing', 'Patient Care', 'Patient risk', 'Patients', 'Population', 'Primary Health Care', 'Process', 'Provider', 'PubMed', 'Recommendation', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Risk', 'Risk Assessment', 'Risk Management', 'Risk stratification', 'Scanning', 'Screening for cancer', 'System', 'Technology', 'Testing', 'Universities', 'Utah', 'base', 'cancer risk', 'cancer type', 'care providers', 'clinical decision support', 'colorectal cancer risk', 'design', 'experience', 'genetic counselor', 'healthcare community', 'high risk', 'improved', 'incentive program', 'malignant breast neoplasm', 'online course', 'online resource', 'open source', 'patient population', 'personalized screening', 'primary care setting', 'programs', 'screening', 'support tools', 'symposium', 'web services']",NCI,UNIVERSITY OF UTAH,U24,2018,752888,0.06318183699325636
"Scalable Clinical Decision Support for Individualized Cancer Risk Management Project Summary / Abstract We propose to enable a scalable clinical decision support (CDS) platform that helps clinicians and patients select cancer screening strategies that are best suited to each individual. This kind of CDS is important because increased evidence supports personalizing cancer screening decisions according to each individual's unique cancer risks. While a highly desired goal, individualizing screening at a population scale requires the implementation of patient-specific risk assessments for several types of cancer. This is quite challenging in today's overwhelmed primary care environment. Our proposed CDS platform addresses this challenge by (i) automating the risk stratification process at the population level based on EHR data and patient reported data; (ii) prioritizing patients for case review by genetic counselors; and (iii) automatically communicating risk and screening recommendations with primary care providers and their patients. We will integrate the CDS platform with the Epic EHR and test it at the University of Utah Health Care community clinics and the Huntsman Cancer Institute. We will assess the generalizability of the CDS platform with a different EHR (Cerner) at a different institution (Intermountain Healthcare). To maximize the dissemination potential for the proposed cancer risk screening platform, we will extend two well-established open source CDS platforms: OpenCDS and OpenInfobutton. These platforms are reference implementations of international EHR standards that are required for EHR certification in the US. We will also obtain software certification from the Open Source EHR Alliance, share the CDS platform and our experiences with other awardees in the ITCR Program, present the CDS platform at national and international cancer and informatics conferences; and engage with relevant stakeholders through a technical expert panel. Any healthcare organization with a certified EHR will be able to use the proposed CDS platform. Therefore, if successful, this proposal can have a significant impact on disseminating individualized cancer screening practices according to the best available evidence. The proposed research addresses the need for individualizing cancer screening according to the risk of an individual. We propose to enable software that scans electronic health records of entire patient populations to automatically detect those at a high risk to develop specific types of cancer according to cancer guidelines. Genetic counselors will review patients identified by the software, and discuss optimal cancer screening strategies with the patient and their primary care providers.",Scalable Clinical Decision Support for Individualized Cancer Risk Management,9295773,U24CA204800,"['Address', 'Adoption', 'Algorithms', 'Architecture', 'Breast Cancer Detection', 'Certification', 'Clinic', 'Clinical', 'Colorectal Cancer', 'Community Healthcare', 'Computer software', 'Coupled', 'Data', 'Data Reporting', 'Detection', 'Documentation', 'Ecosystem', 'Electronic Health Record', 'Environment', 'Family', 'Goals', 'Guidelines', 'Healthcare', 'Healthcare Systems', 'Incentives', 'Individual', 'Informatics', 'Information Retrieval', 'Institutes', 'Institution', 'International', 'Intervention', 'Logic', 'Malignant Neoplasms', 'Modality', 'National Comprehensive Cancer Network', 'Natural Language Processing', 'Patient Care', 'Patient risk', 'Patients', 'Population', 'Primary Health Care', 'Process', 'Provider', 'PubMed', 'Recommendation', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Risk', 'Risk Assessment', 'Risk Management', 'Risk stratification', 'Scanning', 'Screening for cancer', 'System', 'Technology', 'Testing', 'Universities', 'Utah', 'base', 'cancer risk', 'cancer type', 'design', 'experience', 'genetic counselor', 'healthcare community', 'high risk', 'improved', 'malignant breast neoplasm', 'online course', 'online resource', 'open source', 'patient population', 'personalized screening', 'primary care setting', 'programs', 'screening', 'support tools', 'symposium', 'web services']",NCI,UNIVERSITY OF UTAH,U24,2017,766250,0.06318183699325636
"Drug Repurposing for Cancer Therapy: From Man to Molecules to Man Abstract This project aims to develop and implement multiple but integrated computational tools for drug repurposing by exploiting complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records), electronic databases of chemical-biological interactions and pathways, and laboratory data (biological screening of chemical libraries). We expect that tools to be developed in this project will be useful for repurposing observational textual data for research projects (addressing the second challenge of the underlying RFA). In addition, the envisioned translation of this data into a format amenable to quantitative modeling of drug effects will also enable integration of textual and laboratory data to create minable metadata (cf. the third challenge). Project Narrative  This project aims to develop and implement computational tools for drug repurposing by exploiting two complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records) and laboratory data (biological screening of chemical libraries). The proposed tools and underlying computational framework will employ observational human data together with experimental bioactivity data to discover and validate novel therapeutic applications of existing drugs, i.e., following the knowledge discovery path from man to molecules to man.",Drug Repurposing for Cancer Therapy: From Man to Molecules to Man,9548186,U01CA207160,"['Address', 'Adverse drug effect', 'Animal Cancer Model', 'Big Data', 'Biological', 'Biological Assay', 'Biological Models', 'Cancer Patient', 'Cells', 'Chemicals', 'Clinical Trials', 'Collection', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Disease', 'Docking', 'Drug Modelings', 'Drug Targeting', 'Electronic Health Record', 'Generations', 'Goals', 'Human', 'In Vitro', 'Internet', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Link', 'Literature', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Names', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Physicians', 'PubChem', 'PubMed', 'Publications', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Research Project Grants', 'Semantics', 'Source', 'Stream', 'Structure', 'Technology', 'Text', 'Therapeutic Effect', 'Translations', 'Validation', 'base', 'cancer therapy', 'cognitive computing', 'computer based Semantic Analysis', 'computer framework', 'computer studies', 'computerized tools', 'drug candidate', 'genomic data', 'health record', 'high reward', 'human data', 'in vivo', 'man', 'molecular modeling', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'repository', 'screening', 'small molecule libraries', 'social media', 'text searching', 'tool', 'virtual']",NCI,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2018,335618,-0.012248955947595156
"Drug Repurposing for Cancer Therapy: From Man to Molecules to Man Abstract This project aims to develop and implement multiple but integrated computational tools for drug repurposing by exploiting complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records), electronic databases of chemical-biological interactions and pathways, and laboratory data (biological screening of chemical libraries). We expect that tools to be developed in this project will be useful for repurposing observational textual data for research projects (addressing the second challenge of the underlying RFA). In addition, the envisioned translation of this data into a format amenable to quantitative modeling of drug effects will also enable integration of textual and laboratory data to create minable metadata (cf. the third challenge). Project Narrative  This project aims to develop and implement computational tools for drug repurposing by exploiting two complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records) and laboratory data (biological screening of chemical libraries). The proposed tools and underlying computational framework will employ observational human data together with experimental bioactivity data to discover and validate novel therapeutic applications of existing drugs, i.e., following the knowledge discovery path from man to molecules to man.",Drug Repurposing for Cancer Therapy: From Man to Molecules to Man,9337383,U01CA207160,"['Address', 'Adverse drug effect', 'Animal Cancer Model', 'Big Data', 'Biological', 'Biological Assay', 'Biological Models', 'Cancer Patient', 'Cells', 'Chemicals', 'Clinical Trials', 'Cognitive', 'Collection', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Disease', 'Docking', 'Drug Modelings', 'Drug Targeting', 'Electronic Health Record', 'Generations', 'Goals', 'Human', 'In Vitro', 'Internet', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Link', 'Literature', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Models', 'Names', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Physicians', 'PubChem', 'PubMed', 'Publications', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Research Project Grants', 'Semantics', 'Source', 'Stream', 'Structure', 'Technology', 'Text', 'Therapeutic Effect', 'Translations', 'Validation', 'base', 'cancer therapy', 'computer based Semantic Analysis', 'computer framework', 'computer studies', 'computerized tools', 'drug candidate', 'genomic data', 'health record', 'high reward', 'human data', 'in vivo', 'man', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'repository', 'screening', 'small molecule libraries', 'social media', 'text searching', 'tool', 'virtual']",NCI,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2017,417119,-0.012248955947595156
"Drug Repurposing for Cancer Therapy: From Man to Molecules to Man Abstract This project aims to develop and implement multiple but integrated computational tools for drug repurposing by exploiting complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records), electronic databases of chemical-biological interactions and pathways, and laboratory data (biological screening of chemical libraries). We expect that tools to be developed in this project will be useful for repurposing observational textual data for research projects (addressing the second challenge of the underlying RFA). In addition, the envisioned translation of this data into a format amenable to quantitative modeling of drug effects will also enable integration of textual and laboratory data to create minable metadata (cf. the third challenge). Project Narrative  This project aims to develop and implement computational tools for drug repurposing by exploiting two complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records) and laboratory data (biological screening of chemical libraries). The proposed tools and underlying computational framework will employ observational human data together with experimental bioactivity data to discover and validate novel therapeutic applications of existing drugs, i.e., following the knowledge discovery path from man to molecules to man.",Drug Repurposing for Cancer Therapy: From Man to Molecules to Man,9161354,U01CA207160,"['Address', 'Adverse drug effect', 'Animal Cancer Model', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Biological Assay', 'Cancer Patient', 'Cells', 'Chemicals', 'Clinical Trials', 'Cognitive', 'Collection', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Disease', 'Docking', 'Drug Targeting', 'Electronic Health Record', 'Electronics', 'Generations', 'Goals', 'Human', 'In Vitro', 'Internet', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Link', 'Literature', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Models', 'Names', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Physicians', 'PubChem', 'PubMed', 'Publications', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Research Project Grants', 'Semantics', 'Source', 'Stream', 'Structure', 'Technology', 'Text', 'Therapeutic Effect', 'Translations', 'Validation', 'abstracting', 'base', 'cancer therapy', 'computer based Semantic Analysis', 'computer framework', 'computer studies', 'computerized tools', 'drug candidate', 'genomic data', 'health record', 'high reward', 'human data', 'in vivo', 'man', 'molecular modeling', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'repository', 'screening', 'small molecule libraries', 'social media', 'text searching', 'tool', 'virtual']",NCI,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2016,437810,-0.012248955947595156
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9994848,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Consumption', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Treatment Side Effects', 'Universities', 'Work', 'Writing', 'base', 'cancer clinical trial', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'clinical implementation', 'cohort', 'data pipeline', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'oncology trial', 'prospective', 'secondary analysis', 'side effect', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2020,169884,-0.0003654541624990212
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9762876,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Consumption', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Treatment Side Effects', 'Universities', 'Work', 'Writing', 'base', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'clinical implementation', 'cohort', 'data pipeline', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'oncology trial', 'prospective', 'secondary analysis', 'side effect', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2019,168764,-0.0003654541624990212
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9452250,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse effects', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Nephrotoxic', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Universities', 'Work', 'Writing', 'base', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'cohort', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'prospective', 'secondary analysis', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2017,169044,-0.0003654541624990212
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9568724,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse effects', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Universities', 'Work', 'Writing', 'base', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'clinical implementation', 'cohort', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'oncology trial', 'prospective', 'secondary analysis', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2018,169028,-0.0003654541624990212
"Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort PROJECT SUMMARY AND ABSTRACT The purpose of this K07 proposal is to provide Jeffrey Lee, MD, MAS with the protected time and resources to pursue the additional training needed to reach his long-term goal of becoming an independent clinical investigator, focused on colorectal cancer (CRC) prevention. Screening has been shown to reduce the incidence and mortality for CRC. However, screening has resulted in a growing cohort of patients with adenomatous polyps (adenomas) and little is known about effectively managing their post-polypectomy surveillance. With limited data available in the literature to determine the appropriate timing and frequency of follow-up colonoscopy for patients after adenoma removal, recommendations for post-polypectomy surveillance from our national guidelines have been imprecise at best. For example, the currently recommended range of 5-10 years for a surveillance colonoscopy for patients with a single adenoma covers a two-fold difference in exam frequency, with resultant two-fold impact on patient risk, cost, and colonoscopy capacity. To help optimize the timing of colonoscopic surveillance and guide appropriate utilization of this invasive and costly resource, stratification of CRC risk after colonoscopic polypectomy from a large community-based cohort with long-term follow-up is needed. Building on his prior work in CRC screening, Dr. Lee seeks to fill this knowledge gap by optimizing surveillance practices in post-polypectomy patients according to patient-, polyp-, and colonoscopy exam-related factors. Specifically, he will determine the long- term CRC risk in patients after colonoscopic polypectomy in a very large real world community-based population (Aim 1). He will also identify patient-, polyp-, and exam-related risk factors associated with incident CRC in these patients (Aim 2). Finally, he will develop a CRC risk prediction model that will identify post- polypectomy patients at high and low risk for developing subsequent CRC (Aim 3). To achieve these goals, Dr. Lee and his mentors have designed a career development plan for research and educational training to obtain: 1) knowledge and expertise in advanced epidemiologic methods for design and analysis of cohort studies; 2) knowledge in medical informatics methods; and 3) predictive modeling skills. To achieve the proposed research aims, Dr. Lee will leverage the rich electronic health records of Kaiser Permanente Northern California, a large community-based healthcare system, in which data on patient, physician, colonoscopy, pathology, and CRC status have been collected since 1994. In addition, Dr. Lee will use an established natural language processing tool to efficiently collect data and evaluate potential confounding variables from more than 600,000 colonoscopy reports in order to address one of the main practical challenges that have limited the feasibility of large-scale population-based studies. Thus, completion of these aims has the potential to improve prevention and early detection of CRC, impact current surveillance guidelines for post-polypectomy patients, and reduce overuse and underuse of surveillance colonoscopy. Importantly, this proposal is realistic and feasible within the award period and will allow Dr. Lee to continue to build research skills, generate preliminary data, create additional collaborative relationships, and compete for R01 funding. In summary, this K07 award will support and accelerate the career development activities of Dr. Lee and allow him to successfully launch into the next phase of his career as an independent investigator. PROJECT NARRATIVE Randomized controlled trials have shown that screening reduces the incidence of and mortality from colorectal cancer (CRC), the second leading cause of cancer deaths in the United States. However, screening has resulted in a growing cohort of patients with adenomatous polyps and little is known about effectively managing their post-polypectomy surveillance. Thus in this proposal, we will determine the long-term risk and risk factors of CRC after colonoscopic polypectomy, and develop a CRC risk prediction model to tailor surveillancein post- polypectomy patients using a large, community-based cohort.","Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort",9986702,K07CA212057,"['Address', 'Adenomatous Polyps', 'Adherence', 'Age', 'Award', 'California', 'Cancer Etiology', 'Cessation of life', 'Chemopreventive Agent', 'Clinical Investigator', 'Cohort Analysis', 'Cohort Studies', 'Colonoscopy', 'Colorectal Cancer', 'Communities', 'Confounding Factors (Epidemiology)', 'DNA', 'Data', 'Development', 'Development Plans', 'Electronic Health Record', 'Epidemiologic Methods', 'Excision', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health Care Costs', 'Healthcare Systems', 'Incidence', 'Knowledge', 'Lead', 'Link', 'Literature', 'Longterm Follow-up', 'Malignant Neoplasms', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Outcome', 'Pathology', 'Patient risk', 'Patients', 'Phase', 'Physicians', 'Policies', 'Polypectomy', 'Polyps', 'Population', 'Population Research', 'Population Study', 'Prevention', 'Randomized Controlled Trials', 'Recommendation', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Scheme', 'Stratification', 'Surveillance Modeling', 'Surveillance Program', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Unnecessary Procedures', 'Work', 'Writing', 'adenoma', 'base', 'career', 'career development', 'cohort', 'colorectal cancer prevention', 'colorectal cancer risk', 'colorectal cancer screening', 'community based participatory research', 'cost', 'design', 'evidence base', 'follow-up', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'population based', 'predictive modeling', 'premalignant', 'risk prediction model', 'screening', 'skills', 'surveillance strategy', 'tool']",NCI,KAISER FOUNDATION RESEARCH INSTITUTE,K07,2020,171720,0.03814250038375123
"Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort PROJECT SUMMARY AND ABSTRACT The purpose of this K07 proposal is to provide Jeffrey Lee, MD, MAS with the protected time and resources to pursue the additional training needed to reach his long-term goal of becoming an independent clinical investigator, focused on colorectal cancer (CRC) prevention. Screening has been shown to reduce the incidence and mortality for CRC. However, screening has resulted in a growing cohort of patients with adenomatous polyps (adenomas) and little is known about effectively managing their post-polypectomy surveillance. With limited data available in the literature to determine the appropriate timing and frequency of follow-up colonoscopy for patients after adenoma removal, recommendations for post-polypectomy surveillance from our national guidelines have been imprecise at best. For example, the currently recommended range of 5-10 years for a surveillance colonoscopy for patients with a single adenoma covers a two-fold difference in exam frequency, with resultant two-fold impact on patient risk, cost, and colonoscopy capacity. To help optimize the timing of colonoscopic surveillance and guide appropriate utilization of this invasive and costly resource, stratification of CRC risk after colonoscopic polypectomy from a large community-based cohort with long-term follow-up is needed. Building on his prior work in CRC screening, Dr. Lee seeks to fill this knowledge gap by optimizing surveillance practices in post-polypectomy patients according to patient-, polyp-, and colonoscopy exam-related factors. Specifically, he will determine the long- term CRC risk in patients after colonoscopic polypectomy in a very large real world community-based population (Aim 1). He will also identify patient-, polyp-, and exam-related risk factors associated with incident CRC in these patients (Aim 2). Finally, he will develop a CRC risk prediction model that will identify post- polypectomy patients at high and low risk for developing subsequent CRC (Aim 3). To achieve these goals, Dr. Lee and his mentors have designed a career development plan for research and educational training to obtain: 1) knowledge and expertise in advanced epidemiologic methods for design and analysis of cohort studies; 2) knowledge in medical informatics methods; and 3) predictive modeling skills. To achieve the proposed research aims, Dr. Lee will leverage the rich electronic health records of Kaiser Permanente Northern California, a large community-based healthcare system, in which data on patient, physician, colonoscopy, pathology, and CRC status have been collected since 1994. In addition, Dr. Lee will use an established natural language processing tool to efficiently collect data and evaluate potential confounding variables from more than 600,000 colonoscopy reports in order to address one of the main practical challenges that have limited the feasibility of large-scale population-based studies. Thus, completion of these aims has the potential to improve prevention and early detection of CRC, impact current surveillance guidelines for post-polypectomy patients, and reduce overuse and underuse of surveillance colonoscopy. Importantly, this proposal is realistic and feasible within the award period and will allow Dr. Lee to continue to build research skills, generate preliminary data, create additional collaborative relationships, and compete for R01 funding. In summary, this K07 award will support and accelerate the career development activities of Dr. Lee and allow him to successfully launch into the next phase of his career as an independent investigator. PROJECT NARRATIVE Randomized controlled trials have shown that screening reduces the incidence of and mortality from colorectal cancer (CRC), the second leading cause of cancer deaths in the United States. However, screening has resulted in a growing cohort of patients with adenomatous polyps and little is known about effectively managing their post-polypectomy surveillance. Thus in this proposal, we will determine the long-term risk and risk factors of CRC after colonoscopic polypectomy, and develop a CRC risk prediction model to tailor surveillancein post- polypectomy patients using a large, community-based cohort.","Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort",9766215,K07CA212057,"['Address', 'Adenomatous Polyps', 'Adherence', 'Age', 'Award', 'California', 'Cancer Etiology', 'Cessation of life', 'Chemopreventive Agent', 'Clinical Investigator', 'Cohort Analysis', 'Cohort Studies', 'Colonoscopy', 'Colorectal Cancer', 'Communities', 'Confounding Factors (Epidemiology)', 'DNA', 'Data', 'Development', 'Development Plans', 'Electronic Health Record', 'Epidemiologic Methods', 'Excision', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health Care Costs', 'Healthcare Systems', 'Incidence', 'Knowledge', 'Lead', 'Link', 'Literature', 'Longterm Follow-up', 'Malignant Neoplasms', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Outcome', 'Pathology', 'Patient risk', 'Patients', 'Phase', 'Physicians', 'Policies', 'Polypectomy', 'Polyps', 'Population', 'Population Research', 'Population Study', 'Premalignant', 'Prevention', 'Randomized Controlled Trials', 'Recommendation', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Scheme', 'Stratification', 'Surveillance Modeling', 'Surveillance Program', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Unnecessary Procedures', 'Work', 'Writing', 'adenoma', 'base', 'career', 'career development', 'cohort', 'colorectal cancer prevention', 'colorectal cancer risk', 'colorectal cancer screening', 'community based participatory research', 'cost', 'design', 'evidence base', 'follow-up', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'population based', 'predictive modeling', 'risk prediction model', 'screening', 'skills', 'surveillance strategy', 'tool']",NCI,KAISER FOUNDATION RESEARCH INSTITUTE,K07,2019,171720,0.03814250038375123
"Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort PROJECT SUMMARY AND ABSTRACT The purpose of this K07 proposal is to provide Jeffrey Lee, MD, MAS with the protected time and resources to pursue the additional training needed to reach his long-term goal of becoming an independent clinical investigator, focused on colorectal cancer (CRC) prevention. Screening has been shown to reduce the incidence and mortality for CRC. However, screening has resulted in a growing cohort of patients with adenomatous polyps (adenomas) and little is known about effectively managing their post-polypectomy surveillance. With limited data available in the literature to determine the appropriate timing and frequency of follow-up colonoscopy for patients after adenoma removal, recommendations for post-polypectomy surveillance from our national guidelines have been imprecise at best. For example, the currently recommended range of 5-10 years for a surveillance colonoscopy for patients with a single adenoma covers a two-fold difference in exam frequency, with resultant two-fold impact on patient risk, cost, and colonoscopy capacity. To help optimize the timing of colonoscopic surveillance and guide appropriate utilization of this invasive and costly resource, stratification of CRC risk after colonoscopic polypectomy from a large community-based cohort with long-term follow-up is needed. Building on his prior work in CRC screening, Dr. Lee seeks to fill this knowledge gap by optimizing surveillance practices in post-polypectomy patients according to patient-, polyp-, and colonoscopy exam-related factors. Specifically, he will determine the long- term CRC risk in patients after colonoscopic polypectomy in a very large real world community-based population (Aim 1). He will also identify patient-, polyp-, and exam-related risk factors associated with incident CRC in these patients (Aim 2). Finally, he will develop a CRC risk prediction model that will identify post- polypectomy patients at high and low risk for developing subsequent CRC (Aim 3). To achieve these goals, Dr. Lee and his mentors have designed a career development plan for research and educational training to obtain: 1) knowledge and expertise in advanced epidemiologic methods for design and analysis of cohort studies; 2) knowledge in medical informatics methods; and 3) predictive modeling skills. To achieve the proposed research aims, Dr. Lee will leverage the rich electronic health records of Kaiser Permanente Northern California, a large community-based healthcare system, in which data on patient, physician, colonoscopy, pathology, and CRC status have been collected since 1994. In addition, Dr. Lee will use an established natural language processing tool to efficiently collect data and evaluate potential confounding variables from more than 600,000 colonoscopy reports in order to address one of the main practical challenges that have limited the feasibility of large-scale population-based studies. Thus, completion of these aims has the potential to improve prevention and early detection of CRC, impact current surveillance guidelines for post-polypectomy patients, and reduce overuse and underuse of surveillance colonoscopy. Importantly, this proposal is realistic and feasible within the award period and will allow Dr. Lee to continue to build research skills, generate preliminary data, create additional collaborative relationships, and compete for R01 funding. In summary, this K07 award will support and accelerate the career development activities of Dr. Lee and allow him to successfully launch into the next phase of his career as an independent investigator. PROJECT NARRATIVE Randomized controlled trials have shown that screening reduces the incidence of and mortality from colorectal cancer (CRC), the second leading cause of cancer deaths in the United States. However, screening has resulted in a growing cohort of patients with adenomatous polyps and little is known about effectively managing their post-polypectomy surveillance. Thus in this proposal, we will determine the long-term risk and risk factors of CRC after colonoscopic polypectomy, and develop a CRC risk prediction model to tailor surveillancein post- polypectomy patients using a large, community-based cohort.","Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort",9543446,K07CA212057,"['Address', 'Adenomatous Polyps', 'Adherence', 'Age', 'Award', 'California', 'Cancer Etiology', 'Cessation of life', 'Chemopreventive Agent', 'Clinical Investigator', 'Cohort Analysis', 'Cohort Studies', 'Colonoscopy', 'Colorectal Cancer', 'Communities', 'Confounding Factors (Epidemiology)', 'DNA', 'Data', 'Development', 'Development Plans', 'Electronic Health Record', 'Epidemiologic Methods', 'Excision', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health Care Costs', 'Healthcare Systems', 'Incidence', 'Knowledge', 'Lead', 'Link', 'Literature', 'Malignant Neoplasms', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Outcome', 'Pathology', 'Patient risk', 'Patients', 'Phase', 'Physicians', 'Policies', 'Polypectomy', 'Polyps', 'Population', 'Population Research', 'Population Study', 'Premalignant', 'Prevention', 'Randomized Controlled Trials', 'Recommendation', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Scheme', 'Stratification', 'Surveillance Modeling', 'Surveillance Program', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Unnecessary Procedures', 'Work', 'Writing', 'adenoma', 'base', 'career', 'career development', 'cohort', 'colorectal cancer prevention', 'colorectal cancer risk', 'colorectal cancer screening', 'community based participatory research', 'cost', 'design', 'evidence base', 'follow-up', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'population based', 'predictive modeling', 'screening', 'skills', 'surveillance strategy', 'tool']",NCI,KAISER FOUNDATION RESEARCH INSTITUTE,K07,2018,171720,0.03814250038375123
"Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort PROJECT SUMMARY AND ABSTRACT The purpose of this K07 proposal is to provide Jeffrey Lee, MD, MAS with the protected time and resources to pursue the additional training needed to reach his long-term goal of becoming an independent clinical investigator, focused on colorectal cancer (CRC) prevention. Screening has been shown to reduce the incidence and mortality for CRC. However, screening has resulted in a growing cohort of patients with adenomatous polyps (adenomas) and little is known about effectively managing their post-polypectomy surveillance. With limited data available in the literature to determine the appropriate timing and frequency of follow-up colonoscopy for patients after adenoma removal, recommendations for post-polypectomy surveillance from our national guidelines have been imprecise at best. For example, the currently recommended range of 5-10 years for a surveillance colonoscopy for patients with a single adenoma covers a two-fold difference in exam frequency, with resultant two-fold impact on patient risk, cost, and colonoscopy capacity. To help optimize the timing of colonoscopic surveillance and guide appropriate utilization of this invasive and costly resource, stratification of CRC risk after colonoscopic polypectomy from a large community-based cohort with long-term follow-up is needed. Building on his prior work in CRC screening, Dr. Lee seeks to fill this knowledge gap by optimizing surveillance practices in post-polypectomy patients according to patient-, polyp-, and colonoscopy exam-related factors. Specifically, he will determine the long- term CRC risk in patients after colonoscopic polypectomy in a very large real world community-based population (Aim 1). He will also identify patient-, polyp-, and exam-related risk factors associated with incident CRC in these patients (Aim 2). Finally, he will develop a CRC risk prediction model that will identify post- polypectomy patients at high and low risk for developing subsequent CRC (Aim 3). To achieve these goals, Dr. Lee and his mentors have designed a career development plan for research and educational training to obtain: 1) knowledge and expertise in advanced epidemiologic methods for design and analysis of cohort studies; 2) knowledge in medical informatics methods; and 3) predictive modeling skills. To achieve the proposed research aims, Dr. Lee will leverage the rich electronic health records of Kaiser Permanente Northern California, a large community-based healthcare system, in which data on patient, physician, colonoscopy, pathology, and CRC status have been collected since 1994. In addition, Dr. Lee will use an established natural language processing tool to efficiently collect data and evaluate potential confounding variables from more than 600,000 colonoscopy reports in order to address one of the main practical challenges that have limited the feasibility of large-scale population-based studies. Thus, completion of these aims has the potential to improve prevention and early detection of CRC, impact current surveillance guidelines for post-polypectomy patients, and reduce overuse and underuse of surveillance colonoscopy. Importantly, this proposal is realistic and feasible within the award period and will allow Dr. Lee to continue to build research skills, generate preliminary data, create additional collaborative relationships, and compete for R01 funding. In summary, this K07 award will support and accelerate the career development activities of Dr. Lee and allow him to successfully launch into the next phase of his career as an independent investigator. PROJECT NARRATIVE Randomized controlled trials have shown that screening reduces the incidence of and mortality from colorectal cancer (CRC), the second leading cause of cancer deaths in the United States. However, screening has resulted in a growing cohort of patients with adenomatous polyps and little is known about effectively managing their post-polypectomy surveillance. Thus in this proposal, we will determine the long-term risk and risk factors of CRC after colonoscopic polypectomy, and develop a CRC risk prediction model to tailor surveillancein post- polypectomy patients using a large, community-based cohort.","Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort",9352810,K07CA212057,"['Address', 'Adenomatous Polyps', 'Adherence', 'Age', 'Award', 'California', 'Cancer Etiology', 'Cessation of life', 'Chemopreventive Agent', 'Clinical Investigator', 'Cohort Analysis', 'Cohort Studies', 'Colonoscopy', 'Colorectal Cancer', 'Communities', 'Confounding Factors (Epidemiology)', 'DNA', 'Data', 'Development', 'Development Plans', 'Electronic Health Record', 'Epidemiologic Methods', 'Excision', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health Care Costs', 'Healthcare Systems', 'Incidence', 'Knowledge', 'Lead', 'Link', 'Literature', 'Malignant Neoplasms', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Cancer Institute', 'Natural Language Processing', 'Outcome', 'Pathology', 'Patient risk', 'Patients', 'Phase', 'Physicians', 'Policies', 'Polypectomy', 'Polyps', 'Population', 'Population Research', 'Population Study', 'Premalignant', 'Prevention', 'Randomized Controlled Trials', 'Recommendation', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Risk stratification', 'Scheme', 'Stratification', 'Surveillance Modeling', 'Surveillance Program', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Unnecessary Procedures', 'Work', 'Writing', 'adenoma', 'base', 'cancer risk', 'career', 'career development', 'cohort', 'colorectal cancer prevention', 'colorectal cancer screening', 'community based participatory research', 'cost', 'design', 'evidence base', 'follow-up', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'population based', 'predictive modeling', 'screening', 'skills', 'surveillance strategy', 'tool']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K07,2017,67563,0.03814250038375123
"Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort PROJECT SUMMARY AND ABSTRACT The purpose of this K07 proposal is to provide Jeffrey Lee, MD, MAS with the protected time and resources to pursue the additional training needed to reach his long-term goal of becoming an independent clinical investigator, focused on colorectal cancer (CRC) prevention. Screening has been shown to reduce the incidence and mortality for CRC. However, screening has resulted in a growing cohort of patients with adenomatous polyps (adenomas) and little is known about effectively managing their post-polypectomy surveillance. With limited data available in the literature to determine the appropriate timing and frequency of follow-up colonoscopy for patients after adenoma removal, recommendations for post-polypectomy surveillance from our national guidelines have been imprecise at best. For example, the currently recommended range of 5-10 years for a surveillance colonoscopy for patients with a single adenoma covers a two-fold difference in exam frequency, with resultant two-fold impact on patient risk, cost, and colonoscopy capacity. To help optimize the timing of colonoscopic surveillance and guide appropriate utilization of this invasive and costly resource, stratification of CRC risk after colonoscopic polypectomy from a large community-based cohort with long-term follow-up is needed. Building on his prior work in CRC screening, Dr. Lee seeks to fill this knowledge gap by optimizing surveillance practices in post-polypectomy patients according to patient-, polyp-, and colonoscopy exam-related factors. Specifically, he will determine the long- term CRC risk in patients after colonoscopic polypectomy in a very large real world community-based population (Aim 1). He will also identify patient-, polyp-, and exam-related risk factors associated with incident CRC in these patients (Aim 2). Finally, he will develop a CRC risk prediction model that will identify post- polypectomy patients at high and low risk for developing subsequent CRC (Aim 3). To achieve these goals, Dr. Lee and his mentors have designed a career development plan for research and educational training to obtain: 1) knowledge and expertise in advanced epidemiologic methods for design and analysis of cohort studies; 2) knowledge in medical informatics methods; and 3) predictive modeling skills. To achieve the proposed research aims, Dr. Lee will leverage the rich electronic health records of Kaiser Permanente Northern California, a large community-based healthcare system, in which data on patient, physician, colonoscopy, pathology, and CRC status have been collected since 1994. In addition, Dr. Lee will use an established natural language processing tool to efficiently collect data and evaluate potential confounding variables from more than 600,000 colonoscopy reports in order to address one of the main practical challenges that have limited the feasibility of large-scale population-based studies. Thus, completion of these aims has the potential to improve prevention and early detection of CRC, impact current surveillance guidelines for post-polypectomy patients, and reduce overuse and underuse of surveillance colonoscopy. Importantly, this proposal is realistic and feasible within the award period and will allow Dr. Lee to continue to build research skills, generate preliminary data, create additional collaborative relationships, and compete for R01 funding. In summary, this K07 award will support and accelerate the career development activities of Dr. Lee and allow him to successfully launch into the next phase of his career as an independent investigator. PROJECT NARRATIVE Randomized controlled trials have shown that screening reduces the incidence of and mortality from colorectal cancer (CRC), the second leading cause of cancer deaths in the United States. However, screening has resulted in a growing cohort of patients with adenomatous polyps and little is known about effectively managing their post-polypectomy surveillance. Thus in this proposal, we will determine the long-term risk and risk factors of CRC after colonoscopic polypectomy, and develop a CRC risk prediction model to tailor surveillancein post- polypectomy patients using a large, community-based cohort.","Optimizing long-term post-polypectomy surveillance for colorectal cancer prevention using a prediction rule developed from a large, community-based cohort",9224101,K07CA212057,"['Address', 'Adenomatous Polyps', 'Adherence', 'Age', 'Award', 'California', 'Cancer Etiology', 'Cancerous', 'Cessation of life', 'Chemopreventive Agent', 'Clinical Investigator', 'Cohort Studies', 'Colonoscopy', 'Colorectal Cancer', 'Communities', 'Confounding Factors (Epidemiology)', 'DNA', 'Data', 'Development', 'Development Plans', 'Electronic Health Record', 'Epidemiologic Methods', 'Excision', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health Care Costs', 'Healthcare Systems', 'Incidence', 'Knowledge', 'Lead', 'Link', 'Literature', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'National Cancer Institute', 'Natural Language Processing', 'Outcome', 'Pathology', 'Patient risk', 'Patients', 'Phase', 'Physicians', 'Policies', 'Polypectomy', 'Polyps', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Recommendation', 'Regimen', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Scheme', 'Stratification', 'Surveillance Program', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'adenoma', 'base', 'cancer risk', 'career', 'career development', 'cohort', 'colorectal cancer prevention', 'colorectal cancer screening', 'community based participatory research', 'cost', 'design', 'evidence base', 'follow-up', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'population based', 'predictive modeling', 'screening', 'skills', 'surveillance strategy', 'tool']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K07,2016,177057,0.03814250038375123
"Understanding the Multilevel Drivers of Liver Cancer Disparities Project Summary/Abstract From 2000-2014, hepatocellular carcinoma, or HCC, incidence rates increased nearly 4% per year, while most cancers in the United States were on the decline. HCC disproportionately impacts minority racial/ethnic groups who are diagnosed at rates approximately twice that of non-Hispanic Whites. To inform primary prevention strategies that will reduce disparities in HCC risk, we need to determine the relative contribution of well- established and emerging (e.g., hepatitis B virus, hepatitis C virus, alcohol, smoking, cirrhosis, NAFLD, metabolic disorders, diabetes, HIV infection), and novel (e.g., medications, comorbidities, neighborhood attributes) risk factors to these disparities. To inform secondary and tertiary prevention strategies to reduce disparities in HCC burden, we need to understand the multilevel factors that contribute to HCC surveillance disparities. Answering these gaps in knowledge requires a robust high-quality study with a sample enriched for racial/ethnic minorities. Thus, we propose to leverage existing multi-disciplinary collaborations to develop an integrated dataset that includes electronic health records (EHR) data linked to population-based state cancer registry data and geospatial contextual data. This multilevel resource will include data on nearly 2.3 million individuals from three healthcare systems (mixed payer, integrated healthcare, federally qualified health centers) in California and Hawaii, thus providing diversity in healthcare settings and enrichment for racial/ethnic minorities: 59,400 are Black, 189,500 are Hispanic, and 441,700 are Asian American/Native Hawaiian/Pacific Islander (AANHPI). With this resource, we specifically aim to: (1) assess the relative importance of established and emerging examine the extent to which these factors independently and jointly contribute to racial/ethnic disparities in HCC risk; (2) discover novel risk factors and assess their relative importance to HCC risk; and (3) assess racial/ethnic disparities in adherence with surveillance for HCC as well as examine the extent to which these disparities are attributable to modifiable individual-, clinician-, system-, and neighborhood factors (Aim 3). For Aim 1, using prospective data, we will assess the relative importance of risk factors and their contribution to racial/ethnic disparities in HCC risk with causal inference methods. For Aim 2, we will apply innovative machine learning methods to identify novel factors and validate their associations with HCC risk using modeling strategy from Aim 1. For Aim 3, we will use multilevel generalized linear regression to investigate the patient, clinician, institutional and geographic factors that contribute to disparities in HCC surveillance. Given the importance of sex and age/birth cohort for HCC risk, these social determinants will be considered together with race/ethnicity using an intersectional approach. By applying a multilevel framework to understand how biological, clinical, and social factors at multiple levels contribute to HCC disparities in incidence and surveillance, the proposed study will identify modifiable factors that can be translated to the clinical and community settings to collaboratively identify strategies to ameliorate racial/ethnic disparities in HCC. Project Narrative While most cancer incidence and mortality in the United States are declining, the burden of liver cancer is increasing; yet, we do not understand what causes 40% of these cancers. Furthermore, this cancer impacts racial/ethnic groups disproportionately, with minority racial/ethnic groups who are diagnosed at rates approximately twice that of non-Hispanic Whites. Therefore we propose to study the relative contribution of established and emerging risk factors, discover and validate novel risk factors, and to understand patient, clinician, healthcare system and geographic factors that influence surveillance; these findings can then be used to inform strategies in clinical and community settings to reduce the burden of liver cancer particularly for those at high risk.",Understanding the Multilevel Drivers of Liver Cancer Disparities,9997828,R01CA225478,"['Address', 'Adherence', 'Alcohols', 'Asian Americans', 'Behavioral Sciences', 'Biological', 'Biological Factors', 'Biology', 'Biometry', 'Birth', 'California', 'Caring', 'Characteristics', 'Cirrhosis', 'Clinical', 'Data', 'Data Set', 'Diabetes Mellitus', 'Diagnosis', 'Education', 'Electronic Health Record', 'Environmental Risk Factor', 'Epidemiologic Monitoring', 'Ethnic Origin', 'Ethnic group', 'Federally Qualified Health Center', 'Female', 'Fibrinogen', 'Future', 'Geographic Factor', 'Geography', 'HIV Infections', 'Hawaii', 'Health Insurance', 'Health Maintenance Organizations', 'Health Services Research', 'Healthcare', 'Healthcare Systems', 'Hepatitis B', 'Hepatitis B Virus', 'Hepatitis C', 'Hepatitis C virus', 'Heterogeneity', 'Hispanics', 'Incidence', 'Individual', 'Infection', 'Institution', 'Insurance Coverage', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Knowledge', 'Language', 'Linear Regressions', 'Link', 'Liver neoplasms', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Metabolic Diseases', 'Methods', 'Modeling', 'Native Hawaiian', 'Neighborhoods', 'Not Hispanic or Latino', 'Pacific Island Americans', 'Patients', 'Pharmaceutical Preparations', 'Prevention strategy', 'Preventive measure', 'Primary Prevention', 'Primary carcinoma of the liver cells', 'Race', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Sampling Studies', 'Secondary Prevention', 'Services', 'Shapes', 'Smoking', 'Social Sciences', 'System', 'Tobacco smoking behavior', 'Translating', 'Translations', 'United States', 'built environment', 'cancer epidemiology', 'cancer health disparity', 'chronic alcohol ingestion', 'cohort', 'community setting', 'comorbidity', 'data registry', 'disparity reduction', 'electronic data', 'ethnic minority population', 'evidence base', 'experience', 'follow-up', 'health care settings', 'high risk', 'innovation', 'machine learning method', 'male', 'mortality', 'neoplasm registry', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'novel', 'population based', 'prospective', 'racial and ethnic', 'racial and ethnic disparities', 'racial minority', 'sex', 'social', 'social determinants', 'social disparities', 'social factors', 'socioeconomics', 'tertiary prevention']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,645058,0.0033862905800803866
"Understanding the Multilevel Drivers of Liver Cancer Disparities Project Summary/Abstract From 2000-2014, hepatocellular carcinoma, or HCC, incidence rates increased nearly 4% per year, while most cancers in the United States were on the decline. HCC disproportionately impacts minority racial/ethnic groups who are diagnosed at rates approximately twice that of non-Hispanic Whites. To inform primary prevention strategies that will reduce disparities in HCC risk, we need to determine the relative contribution of well- established and emerging (e.g., hepatitis B virus, hepatitis C virus, alcohol, smoking, cirrhosis, NAFLD, metabolic disorders, diabetes, HIV infection), and novel (e.g., medications, comorbidities, neighborhood attributes) risk factors to these disparities. To inform secondary and tertiary prevention strategies to reduce disparities in HCC burden, we need to understand the multilevel factors that contribute to HCC surveillance disparities. Answering these gaps in knowledge requires a robust high-quality study with a sample enriched for racial/ethnic minorities. Thus, we propose to leverage existing multi-disciplinary collaborations to develop an integrated dataset that includes electronic health records (EHR) data linked to population-based state cancer registry data and geospatial contextual data. This multilevel resource will include data on nearly 2.3 million individuals from three healthcare systems (mixed payer, integrated healthcare, federally qualified health centers) in California and Hawaii, thus providing diversity in healthcare settings and enrichment for racial/ethnic minorities: 59,400 are Black, 189,500 are Hispanic, and 441,700 are Asian American/Native Hawaiian/Pacific Islander (AANHPI). With this resource, we specifically aim to: (1) assess the relative importance of established and emerging examine the extent to which these factors independently and jointly contribute to racial/ethnic disparities in HCC risk; (2) discover novel risk factors and assess their relative importance to HCC risk; and (3) assess racial/ethnic disparities in adherence with surveillance for HCC as well as examine the extent to which these disparities are attributable to modifiable individual-, clinician-, system-, and neighborhood factors (Aim 3). For Aim 1, using prospective data, we will assess the relative importance of risk factors and their contribution to racial/ethnic disparities in HCC risk with causal inference methods. For Aim 2, we will apply innovative machine learning methods to identify novel factors and validate their associations with HCC risk using modeling strategy from Aim 1. For Aim 3, we will use multilevel generalized linear regression to investigate the patient, clinician, institutional and geographic factors that contribute to disparities in HCC surveillance. Given the importance of sex and age/birth cohort for HCC risk, these social determinants will be considered together with race/ethnicity using an intersectional approach. By applying a multilevel framework to understand how biological, clinical, and social factors at multiple levels contribute to HCC disparities in incidence and surveillance, the proposed study will identify modifiable factors that can be translated to the clinical and community settings to collaboratively identify strategies to ameliorate racial/ethnic disparities in HCC. Project Narrative While most cancer incidence and mortality in the United States are declining, the burden of liver cancer is increasing; yet, we do not understand what causes 40% of these cancers. Furthermore, this cancer impacts racial/ethnic groups disproportionately, with minority racial/ethnic groups who are diagnosed at rates approximately twice that of non-Hispanic Whites. Therefore we propose to study the relative contribution of established and emerging risk factors, discover and validate novel risk factors, and to understand patient, clinician, healthcare system and geographic factors that influence surveillance; these findings can then be used to inform strategies in clinical and community settings to reduce the burden of liver cancer particularly for those at high risk.",Understanding the Multilevel Drivers of Liver Cancer Disparities,9679122,R01CA225478,"['Address', 'Adherence', 'Alcohols', 'Asian Americans', 'Behavioral Sciences', 'Biological', 'Biological Factors', 'Biology', 'Biometry', 'Birth', 'California', 'Caring', 'Characteristics', 'Cirrhosis', 'Clinical', 'Comorbidity', 'Data', 'Data Set', 'Diabetes Mellitus', 'Diagnosis', 'Education', 'Electronic Health Record', 'Environmental Risk Factor', 'Epidemiologic Monitoring', 'Ethnic Origin', 'Ethnic group', 'Federally Qualified Health Center', 'Female', 'Fibrinogen', 'Future', 'Geographic Factor', 'Geography', 'HIV Infections', 'Hawaii', 'Health Insurance', 'Health Maintenance Organizations', 'Health Services Research', 'Healthcare', 'Healthcare Systems', 'Hepatitis B', 'Hepatitis B Virus', 'Hepatitis C', 'Hepatitis C virus', 'Heterogeneity', 'Hispanics', 'Incidence', 'Individual', 'Infection', 'Institution', 'Insurance Coverage', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Knowledge', 'Language', 'Linear Regressions', 'Link', 'Liver neoplasms', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Metabolic Diseases', 'Methods', 'Modeling', 'Native Hawaiian', 'Neighborhoods', 'Not Hispanic or Latino', 'Pacific Island Americans', 'Patients', 'Pharmaceutical Preparations', 'Prevention strategy', 'Preventive measure', 'Primary Prevention', 'Primary carcinoma of the liver cells', 'Race', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Sampling Studies', 'Secondary Prevention', 'Services', 'Shapes', 'Smoking', 'Social Sciences', 'System', 'Tobacco smoking behavior', 'Translating', 'Translations', 'United States', 'built environment', 'cancer epidemiology', 'cancer health disparity', 'chronic alcohol ingestion', 'cohort', 'community setting', 'data registry', 'disparity reduction', 'electronic data', 'ethnic minority population', 'evidence base', 'experience', 'follow-up', 'health care settings', 'high risk', 'innovation', 'intersectionality', 'learning strategy', 'male', 'mortality', 'neoplasm registry', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'novel', 'population based', 'prospective', 'racial and ethnic', 'racial and ethnic disparities', 'racial minority', 'sex', 'social', 'social disparities', 'socioeconomics', 'tertiary prevention']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2019,680549,0.0033862905800803866
"Leveraging Twitter to Monitor Nicotine and Tobacco Cancer Communication Patterns in Twitter data have revolutionized understanding of public health events such as influenza outbreaks. While researchers have begun to examine messaging related to substance use on Twitter, this project will strengthen the use of Twitter as an infoveillance tool to more rigorously examine nicotine, tobacco, and cancer- related communication. Twitter is particularly suited to this work because its users are commonly adolescents, young adults, and racial and ethnic minorities, all of whom are at increased risk for nicotine and tobacco product (NTP) use and related health consequences. Additionally, due to the openness of the platform, searches are replicable and transparent, enabling large-scale systematic research. Therefore, our multidisciplinary team of experts in diverse relevant fieldsincluding public health, behavioral science, computational linguistics, computer science, biomedical informatics, and information privacy and securitywill build upon our previous research to develop and validate structured algorithms providing automated surveillance of Twitters multifaceted and continuously evolving information related to NTPs. First, we will qualitatively assess a stratified random sample of relevant NTP-related tweets for specific coded variables, such as the messages primary sentiment and other key information of potential value (e.g., whether a message involves buying/selling, policy/law, and cancer-related communication). Tweets will be obtained directly from Twitter using software we developed that leverages a comprehensive list of Twitter-optimized search strings related to NTPs. Second, we will statistically determine what message characteristics (e.g., the presence of certain words, punctuation, and/or structures) are most strongly associated with each of the coded variables for each search string. Using this information, we will create specialized Machine Learning (ML) algorithms based on state-of-the-art methods from Natural Language Processing (NLP) to automatically assess and categorize future Twitter data. Third, we will use this information to provide automatic assessment of current and future streaming data. Time series analyses using seasonal Auto-Regressive Integrated Moving Averages (ARIMA) will determine if there are significant changes over time in volume of messaging related to each specific coded variables of interest. Trends will be examined at the daily, weekly, and monthly level, because each of these levels is potentially valuable for intervention. To maximize the translational value of this project, we will partner with public health department stakeholders who are experts in streamlining dissemination of actionable trends data. In summary, this project will substantially advance our understanding of representations of NTPs on social mediaas well as our ability to conduct automated surveillance and analysis of this content. This project will result in important and concrete deliverables, including open-source algorithms for future researchers and processes to quickly disseminate actionable data for tailoring community- level interventions. For this project, we gathered a team of public health researchers and computer scientists to leverage the power of Twitter as a novel surveillance tool to better understand communication about nicotine and tobacco products (NTPs) and related messages about cancer and cancer prevention. We will gather a random sample of Twitter messages (tweets) related to NTPs and examine them in depth and use this information to create specialized computer algorithms that can automatically categorize future Twitter data. Then, we will examine changes over time related to attitudes towards and interest in NTPs, as well as cancer-related discussion around various NTPs, which will dramatically improve our ability to better understand Twitter as a tool for this type of surveillance.",Leveraging Twitter to Monitor Nicotine and Tobacco Cancer Communication,10111658,R01CA225773,"['Adolescent', 'Affect', 'Alcohol or Other Drugs use', 'Algorithms', 'Attitude', 'Behavioral', 'Behavioral Sciences', 'Cancer Control', 'Categories', 'Characteristics', 'Cigarette', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Computers', 'County', 'Data', 'Disease Outbreaks', 'Electronic cigarette', 'Epidemiologic Methods', 'Event', 'Food', 'Football game', 'Future', 'Gold', 'Health', 'Health Care Costs', 'Individual', 'Influenza A Virus, H1N1 Subtype', 'Intervention', 'Laws', 'Linguistics', 'Literature', 'Malignant Neoplasms', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Nicotine', 'Outcome', 'Pattern', 'Policies', 'Privacy', 'Process', 'Public Health', 'Public Opinion', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Scientist', 'Security', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Tobacco', 'Tobacco use', 'Twitter', 'Work', 'automated analysis', 'base', 'biomedical informatics', 'cancer prevention', 'computer program', 'computer science', 'computerized tools', 'data standards', 'data streams', 'ethnic minority population', 'geographic difference', 'hookah', 'improved', 'influenza outbreak', 'interest', 'machine learning algorithm', 'mortality', 'multidisciplinary', 'nicotine use', 'novel', 'open source', 'phrases', 'prospective', 'racial minority', 'social', 'social media', 'software development', 'statistics', 'time use', 'tobacco products', 'tool', 'trend', 'vaping', 'young adult']",NCI,UNIVERSITY OF ARKANSAS AT FAYETTEVILLE,R01,2020,491992,0.02661842883949422
"Leveraging Twitter to monitor nicotine and tobacco-related cancer communication Patterns in Twitter data have revolutionized understanding of public health events such as influenza outbreaks. While researchers have begun to examine messaging related to substance use on Twitter, this project will strengthen the use of Twitter as an infoveillance tool to more rigorously examine nicotine, tobacco, and cancer- related communication. Twitter is particularly suited to this work because its users are commonly adolescents, young adults, and racial and ethnic minorities, all of whom are at increased risk for nicotine and tobacco product (NTP) use and related health consequences. Additionally, due to the openness of the platform, searches are replicable and transparent, enabling large-scale systematic research. Therefore, our multidisciplinary team of experts in diverse relevant fieldsincluding public health, behavioral science, computational linguistics, computer science, biomedical informatics, and information privacy and securitywill build upon our previous research to develop and validate structured algorithms providing automated surveillance of Twitters multifaceted and continuously evolving information related to NTPs. First, we will qualitatively assess a stratified random sample of relevant NTP-related tweets for specific coded variables, such as the messages primary sentiment and other key information of potential value (e.g., whether a message involves buying/selling, policy/law, and cancer-related communication). Tweets will be obtained directly from Twitter using software we developed that leverages a comprehensive list of Twitter-optimized search strings related to NTPs. Second, we will statistically determine what message characteristics (e.g., the presence of certain words, punctuation, and/or structures) are most strongly associated with each of the coded variables for each search string. Using this information, we will create specialized Machine Learning (ML) algorithms based on state-of-the-art methods from Natural Language Processing (NLP) to automatically assess and categorize future Twitter data. Third, we will use this information to provide automatic assessment of current and future streaming data. Time series analyses using seasonal Auto-Regressive Integrated Moving Averages (ARIMA) will determine if there are significant changes over time in volume of messaging related to each specific coded variables of interest. Trends will be examined at the daily, weekly, and monthly level, because each of these levels is potentially valuable for intervention. To maximize the translational value of this project, we will partner with public health department stakeholders who are experts in streamlining dissemination of actionable trends data. In summary, this project will substantially advance our understanding of representations of NTPs on social mediaas well as our ability to conduct automated surveillance and analysis of this content. This project will result in important and concrete deliverables, including open-source algorithms for future researchers and processes to quickly disseminate actionable data for tailoring community- level interventions. For this project, we gathered a team of public health researchers and computer scientists to leverage the power of Twitter as a novel surveillance tool to better understand communication about nicotine and tobacco products (NTPs) and related messages about cancer and cancer prevention. We will gather a random sample of Twitter messages (tweets) related to NTPs and examine them in depth and use this information to create specialized computer algorithms that can automatically categorize future Twitter data. Then, we will examine changes over time related to attitudes towards and interest in NTPs, as well as cancer-related discussion around various NTPs, which will dramatically improve our ability to better understand Twitter as a tool for this type of surveillance.",Leveraging Twitter to monitor nicotine and tobacco-related cancer communication,9656981,R01CA225773,"['Adolescent', 'Affect', 'Alcohol or Other Drugs use', 'Algorithms', 'Attitude', 'Behavioral', 'Behavioral Sciences', 'Cancer Control', 'Categories', 'Characteristics', 'Cigarette', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Computers', 'County', 'Data', 'Disease Outbreaks', 'Electronic cigarette', 'Epidemiologic Methods', 'Event', 'Food', 'Football game', 'Future', 'Gold', 'Health', 'Health Care Costs', 'Individual', 'Influenza A Virus, H1N1 Subtype', 'Intervention', 'Laws', 'Linguistics', 'Literature', 'Malignant Neoplasms', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Nicotine', 'Outcome', 'Pattern', 'Policies', 'Privacy', 'Process', 'Public Health', 'Public Opinion', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Scientist', 'Security', 'Specificity', 'Stream', 'Structure', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Tobacco', 'Tobacco use', 'Tobacco-Related Carcinoma', 'Twitter', 'Work', 'automated analysis', 'base', 'biomedical informatics', 'cancer prevention', 'computer program', 'computer science', 'computerized tools', 'ethnic minority population', 'geographic difference', 'hookah', 'improved', 'influenza outbreak', 'interest', 'machine learning algorithm', 'mortality', 'multidisciplinary', 'nicotine use', 'novel', 'open source', 'phrases', 'prospective', 'racial minority', 'social', 'social media', 'software development', 'statistics', 'time use', 'tobacco products', 'tool', 'trend', 'vaping', 'young adult']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,431185,0.02661842883949422
"Leveraging Twitter to monitor nicotine and tobacco-related cancer communication Patterns in Twitter data have revolutionized understanding of public health events such as influenza outbreaks. While researchers have begun to examine messaging related to substance use on Twitter, this project will strengthen the use of Twitter as an infoveillance tool to more rigorously examine nicotine, tobacco, and cancer- related communication. Twitter is particularly suited to this work because its users are commonly adolescents, young adults, and racial and ethnic minorities, all of whom are at increased risk for nicotine and tobacco product (NTP) use and related health consequences. Additionally, due to the openness of the platform, searches are replicable and transparent, enabling large-scale systematic research. Therefore, our multidisciplinary team of experts in diverse relevant fieldsincluding public health, behavioral science, computational linguistics, computer science, biomedical informatics, and information privacy and securitywill build upon our previous research to develop and validate structured algorithms providing automated surveillance of Twitters multifaceted and continuously evolving information related to NTPs. First, we will qualitatively assess a stratified random sample of relevant NTP-related tweets for specific coded variables, such as the messages primary sentiment and other key information of potential value (e.g., whether a message involves buying/selling, policy/law, and cancer-related communication). Tweets will be obtained directly from Twitter using software we developed that leverages a comprehensive list of Twitter-optimized search strings related to NTPs. Second, we will statistically determine what message characteristics (e.g., the presence of certain words, punctuation, and/or structures) are most strongly associated with each of the coded variables for each search string. Using this information, we will create specialized Machine Learning (ML) algorithms based on state-of-the-art methods from Natural Language Processing (NLP) to automatically assess and categorize future Twitter data. Third, we will use this information to provide automatic assessment of current and future streaming data. Time series analyses using seasonal Auto-Regressive Integrated Moving Averages (ARIMA) will determine if there are significant changes over time in volume of messaging related to each specific coded variables of interest. Trends will be examined at the daily, weekly, and monthly level, because each of these levels is potentially valuable for intervention. To maximize the translational value of this project, we will partner with public health department stakeholders who are experts in streamlining dissemination of actionable trends data. In summary, this project will substantially advance our understanding of representations of NTPs on social mediaas well as our ability to conduct automated surveillance and analysis of this content. This project will result in important and concrete deliverables, including open-source algorithms for future researchers and processes to quickly disseminate actionable data for tailoring community- level interventions. For this project, we gathered a team of public health researchers and computer scientists to leverage the power of Twitter as a novel surveillance tool to better understand communication about nicotine and tobacco products (NTPs) and related messages about cancer and cancer prevention. We will gather a random sample of Twitter messages (tweets) related to NTPs and examine them in depth and use this information to create specialized computer algorithms that can automatically categorize future Twitter data. Then, we will examine changes over time related to attitudes towards and interest in NTPs, as well as cancer-related discussion around various NTPs, which will dramatically improve our ability to better understand Twitter as a tool for this type of surveillance.",Leveraging Twitter to monitor nicotine and tobacco-related cancer communication,9503469,R01CA225773,"['Adolescent', 'Affect', 'Alcohol or Other Drugs use', 'Algorithms', 'Attitude', 'Behavioral', 'Behavioral Sciences', 'Cancer Control', 'Categories', 'Characteristics', 'Cigarette', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Computers', 'County', 'Data', 'Disease Outbreaks', 'Electronic cigarette', 'Epidemiologic Methods', 'Event', 'Food', 'Football game', 'Future', 'Gold', 'Health', 'Health Care Costs', 'Individual', 'Influenza A Virus, H1N1 Subtype', 'Intervention', 'Laws', 'Linguistics', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Nicotine', 'Outcome', 'Pattern', 'Policies', 'Privacy', 'Process', 'Public Health', 'Public Opinion', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Scientist', 'Security', 'Specificity', 'Stream', 'Structure', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Tobacco', 'Tobacco use', 'Tobacco-Related Carcinoma', 'Work', 'base', 'biomedical informatics', 'cancer prevention', 'computer program', 'computer science', 'computerized tools', 'ethnic minority population', 'geographic difference', 'hookah', 'improved', 'influenza outbreak', 'interest', 'mortality', 'multidisciplinary', 'nicotine use', 'novel', 'open source', 'phrases', 'prospective', 'racial and ethnic', 'racial minority', 'social', 'social media', 'software development', 'statistics', 'time use', 'tool', 'trend', 'vaping', 'young adult']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,505649,0.02661842883949422
"Identifying False HPV-Vaccine Information and Modeling Its Impact on Risk Perceptions PROJECT SUMMARY/ABSTRACT Human papillomavirus (HPV) is the most common sexually transmitted infection in the United States, with over 30,000 new HPV-related-cancers are diagnosed annually. Although HPV vaccines have been approved by the Food and Drug Administration (FDA) since 2006 and recommended for routine vaccination for school-age girls and boys, vaccination rates remain low. One reason that has contributed to low vaccination rates is incorrect risk perceptions around HPV vaccines such as the high perceived risks of adverse events or side effects from the HPV vaccine. Incorrect risk perceptions are often rooted in the false information about HPV vaccines that people are exposed to in their daily life, including social media. The impact of social media on health information is substantial. Negative social-media HPV-vaccine information has been found to have an association with low vaccination coverage. Given the negative consequences of false information, there is a need to develop a robust and scalable way to detect false HPV-vaccine information before it propagates and negatively impacts behavior. The overarching goal of the proposed research is to build a model to identify false HPV-vaccine information on Twitter, demonstrate its impact on individual risk perceptions and measure its underlying mechanisms on risk perception formation. We propose a novel approach to leverage machine learning, natural language processing, network analysis, crowdsourcing/expert data annotation, psycholinguistic analysis and statistical modeling to investigate the false HPV-vaccine information collectively (in terms of its detection and propagation patterns) and individually (in terms of its impact and underlying cognitive mechanisms). Our study will first build a computational model to detect false HPV-vaccine information on Twitter. By modeling the domain-specific HPV- vaccine related text content, information-veracity related linguistic features, individual and collective user behaviors, and dissemination patterns, our model will be able to detect false HPV-vaccine information before it gets verified and spreads widely. We will then investigate the impact of false HPV-vaccine information on risk perceptions around HPV vaccination operationalized by natural language processing methods and a developed HPV-vaccine Risk Lexicon. We will further conduct psycholinguistic analysis on the false HPV-vaccine information and use statistical modeling to uncover the underlying mechanism of risk perceptions. Our study will make a critical and timely contribution to identifying the false HPV-vaccine information and its impact, which has the potential to be applied to other health topics. This proposed project will also address the National Cancer Institute priorities in promoting HPV vaccines and combating misinformation in cancer prevention and control. PROJECT NARRATIVE The uptake of human papillomavirus (HPV) vaccine remains low in part because of incorrect perceptions of vaccination risks, which has been linked to the spread of false HPV-vaccine information. The proposed study seeks to build a computational model to detect false HPV-vaccine information on social media (Twitter) and determine its impact on risk perceptions of the HPV vaccine. The findings will provide important contributions to understand the impact of false health information on HPV vaccination behavior and could be expanded to other health topics.",Identifying False HPV-Vaccine Information and Modeling Its Impact on Risk Perceptions,9954963,R21CA237483,"['Address', 'Affect', 'Age', 'Anxiety', 'Attitude', 'Behavior', 'Cancer Control', 'Categories', 'Cognitive', 'Communication', 'Comprehension', 'Computer Models', 'Data', 'Decision Making', 'Detection', 'Diagnosis', 'Electronic cigarette', 'Event', 'Exposure to', 'Fright', 'Goals', 'Harm Reduction', 'Health', 'Human Papilloma Virus Vaccination', 'Human Papilloma Virus Vaccine', 'Human Papilloma Virus-Related Malignant Neoplasm', 'Human Papillomavirus', 'Human papilloma virus infection', 'Individual', 'Information Dissemination', 'Knowledge', 'Lesion', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Misinformation', 'Modeling', 'National Cancer Institute', 'Natural Language Processing', 'Neural Network Simulation', 'Participant', 'Pathway Analysis', 'Patients', 'Pattern', 'Perception', 'Plant Roots', 'Politics', 'Property', 'Psycholinguistics', 'Psychological reinforcement', 'Research', 'Risk', 'Safety', 'School-Age Population', 'Semantics', 'Sexually Transmitted Diseases', 'Source', 'Statistical Models', 'Text', 'Time', 'Twitter', 'United States', 'United States Food and Drug Administration', 'Vaccination', 'Vaccines', 'Work', 'adverse event risk', 'boys', 'cancer diagnosis', 'cancer prevention', 'combat', 'crowdsourcing', 'deep learning', 'girls', 'high risk', 'information model', 'information processing', 'multilevel analysis', 'news', 'novel strategies', 'premalignant', 'prevent', 'recurrent neural network', 'response', 'risk perception', 'side effect', 'social media', 'theories', 'uptake']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,211659,0.009342104451912029
"Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data PROJECT SUMMARY Large electronic health record research (EHR) data integrated with -omics data from linked biorepositories have expanded opportunities for precision medicine research. These integrated datasets open opportunities for developing accurate EHR-based personalized cancer risk and progression prediction models, which can be easily incorporated into clinical practice and ultimately realize the promise of precision oncology. However, efficiently and effectively using EHR for cancer research remains challenging due to practical and methodological obstacles. For example, obtaining precise event time information such as time of cancer recurrence is a major bottleneck in using EHR for precision medicine research due to the requirement of laborious medical record review and the lack of documentation. Simple estimates of the event time based on billing or procedure codes may poorly approximate the true event time. Naive use of such estimated event times can lead to highly biased estimates due to the approximation error. Such biases impose challenges to performing pragmatic trials when the study endpoint is time to events and captured using EHR. The overall goal of this proposal is to fill these methodological gaps in risk assessment for cancer research using EHR data, which will advance our ability to achieve the promise of precision oncology. Statistical algorithms and software will be developed to (i) automatically assign event time information using longitudinally recorded EHR information; and (ii) to perform accurate risk assessment using noisy proxies of event times. The proposed tools for risk assessment using imperfect EHR data without requiring extensive manual chart review could greatly improve the utility of EHR for oncology research. PROJECT NARRATIVE This proposal addresses major methodological gaps in effectively utilizing EHR data for risk assessment due to the noisy nature of EHR data. We propose novel statistical algorithms and software to (i) efficiently annotate event time by combining multiple longitudinally recorded code information and (ii) to provide precise risk estimates using noisy proxies of event times. By drawing upon the rich albeit imperfect data from bio-repository linked EHR, our algorithms will advance our ability to use EHR data for precision oncology research.",Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data,9955220,R21CA242940,"['Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Biological', 'Boston', 'Cancer Patient', 'Clinical', 'Clinical Trials', 'Code', 'Cohort Studies', 'Data', 'Data Set', 'Diagnosis', 'Documentation', 'Electronic Health Record', 'Event', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Infrastructure', 'Label', 'Laboratories', 'Lead', 'Link', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measurement', 'Medical Records', 'Methodology', 'Methods', 'Nature', 'Oncology', 'Patients', 'Phenotype', 'Procedures', 'Progression-Free Survivals', 'Proxy', 'Registries', 'Research', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Software Tools', 'Source', 'Statistical Algorithm', 'Supervision', 'Testing', 'Time', 'adjudicate', 'anticancer research', 'base', 'biobank', 'cancer recurrence', 'cancer risk', 'clinical practice', 'cohort', 'electronic data', 'evidence base', 'genomic data', 'improved', 'large datasets', 'learning algorithm', 'multimodality', 'novel', 'patient population', 'patient subsets', 'pragmatic trial', 'precision medicine', 'precision oncology', 'predictive modeling', 'repository', 'supervised learning', 'tool', 'tumor progression', 'user friendly software', 'web site']",NCI,HARVARD SCHOOL OF PUBLIC HEALTH,R21,2020,177510,0.06521464998110277
"Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data PROJECT SUMMARY Large electronic health record research (EHR) data integrated with -omics data from linked biorepositories have expanded opportunities for precision medicine research. These integrated datasets open opportunities for developing accurate EHR-based personalized cancer risk and progression prediction models, which can be easily incorporated into clinical practice and ultimately realize the promise of precision oncology. However, efficiently and effectively using EHR for cancer research remains challenging due to practical and methodological obstacles. For example, obtaining precise event time information such as time of cancer recurrence is a major bottleneck in using EHR for precision medicine research due to the requirement of laborious medical record review and the lack of documentation. Simple estimates of the event time based on billing or procedure codes may poorly approximate the true event time. Naive use of such estimated event times can lead to highly biased estimates due to the approximation error. Such biases impose challenges to performing pragmatic trials when the study endpoint is time to events and captured using EHR. The overall goal of this proposal is to fill these methodological gaps in risk assessment for cancer research using EHR data, which will advance our ability to achieve the promise of precision oncology. Statistical algorithms and software will be developed to (i) automatically assign event time information using longitudinally recorded EHR information; and (ii) to perform accurate risk assessment using noisy proxies of event times. The proposed tools for risk assessment using imperfect EHR data without requiring extensive manual chart review could greatly improve the utility of EHR for oncology research. PROJECT NARRATIVE This proposal addresses major methodological gaps in effectively utilizing EHR data for risk assessment due to the noisy nature of EHR data. We propose novel statistical algorithms and software to (i) efficiently annotate event time by combining multiple longitudinally recorded code information and (ii) to provide precise risk estimates using noisy proxies of event times. By drawing upon the rich albeit imperfect data from bio-repository linked EHR, our algorithms will advance our ability to use EHR data for precision oncology research.",Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data,9827744,R21CA242940,"['Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Biological', 'Boston', 'Cancer Patient', 'Clinical', 'Clinical Trials', 'Code', 'Cohort Studies', 'Data', 'Data Set', 'Diagnosis', 'Documentation', 'Electronic Health Record', 'Event', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Infrastructure', 'Label', 'Laboratories', 'Lead', 'Link', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measurement', 'Medical Records', 'Methodology', 'Methods', 'Nature', 'Patients', 'Phenotype', 'Procedures', 'Progression-Free Survivals', 'Proxy', 'Registries', 'Research', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Software Tools', 'Source', 'Statistical Algorithm', 'Supervision', 'Testing', 'Time', 'adjudicate', 'anticancer research', 'base', 'biobank', 'cancer recurrence', 'cancer risk', 'clinical practice', 'cohort', 'electronic data', 'evidence base', 'genomic data', 'improved', 'learning algorithm', 'multimodality', 'novel', 'oncology', 'patient population', 'patient subsets', 'pragmatic trial', 'precision medicine', 'precision oncology', 'predictive modeling', 'repository', 'supervised learning', 'tool', 'tumor progression', 'user friendly software', 'web site']",NCI,HARVARD SCHOOL OF PUBLIC HEALTH,R21,2019,192385,0.06521464998110277
"Natural Language Processing Platform for Cancer Surveillance PROJECT SUMMARY/ABSTRACT This UG3/UH3 proposal titled Natural Language Processing Platform for Cancer Surveillance is in response to Research Area 1 of PAR 16-349 (https://grants.nih.gov/grants/guide/pa-files/par-16-349.html) specifically addressing the development of natural language processing (NLP) tools to facilitate automatic/unsupervised/minimally supervised extraction of specific discrete cancer-related data from various types of unstructured electronic medical records (EMRs) related to the activities of cancer registries. It is submitted through a multi-PI mechanism  Prof. Guergana Savova from Boston Childrens Hospital/Harvard Medical School, Dr. Jeremy Warner from Vanderbilt University Medical Center, Prof. Harry Hochheiser from the University of Pittsburgh, and Prof. Eric Durbin from the Kentucky Cancer Registry/University of Kentucky. The current proposal builds on prior work funded by the NCI Informatics Tools for Cancer Research (ITCR) program (https://itcr.cancer.gov/ ). We envision building on our work to date to advance methods for information extraction of clinical phenotyping data needed to fuel a new cancer surveillance paradigm that would benefit hospital-based, state-based, and national cancer registries. In this new paradigm, surveillance programs would use the methods to enhance the speed, accuracy, and ease of cancer reporting. The proposed DeepPhe*CR platform could be deployed at local sites or centrally, and could eventually be integrated into existing or new visualization and abstraction tools as needed by the cancer surveillance community. Although there has been some previous work on automatic phenotype extraction from the various streams of data including the clinical narrative for specific types of cancer or individual variables for cancer surveillance, the proposed work will be a step towards a generalizable information extraction. This generalizability enables extensibility and scalability. Interoperability is reinforced through the modeling part of the proposed project which is grounded in most recent advances in biomedical ontologies, terminologies, community-adopted conventions and standards. Our planned partnership with three SEER cancer registries provides our decision-making processes with a solid foundation in large-scale cancer surveillance. PROJECT NARRATIVE This UG3/UH3 proposal titled Natural Language Processing Platform for Cancer Surveillance is in response to Research Area 1 of PAR 16-349 specifically addressing the development of natural language processing tools to facilitate automatic/unsupervised/minimally supervised extraction of specific discrete cancer-related data from various types of unstructured electronic medical records. We envision building on our work to date to advance methods for information extraction of clinical phenotyping data needed to fuel a new cancer surveillance paradigm that would benefit hospital-based, state-based, and national cancer registries.",Natural Language Processing Platform for Cancer Surveillance,9980862,UG3CA243120,"['Academic Medical Centers', 'Address', 'Adopted', 'Advanced Development', 'Agreement', 'Architecture', 'Area', 'Automation', 'Automobile Driving', 'Biological Markers', 'Boston', 'Breslow Thickness', 'Cancer Research Project', 'Cancer Surveillance Research Program', 'Characteristics', 'Clinical', 'Collaborations', 'Colorectal', 'Communities', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Contractor', 'Data', 'Data Element', 'Data Management Resources', 'Data Sources', 'Decision Making', 'Development', 'Diagnosis', 'Division of Cancer Control and Population Sciences', 'Documentation', 'Elements', 'Environment', 'Extensible Markup Language', 'Family', 'Feeds', 'Foundations', 'Funding', 'Gene Proteins', 'Genomics', 'Goals', 'Grant', 'Handedness', 'Histologic', 'Histology', 'Hospitals', 'Human', 'Individual', 'Information Retrieval', 'Kentucky', 'Link', 'Location', 'Louisiana', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Maps', 'Massachusetts', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Oncology', 'Ontology', 'Output', 'Ovarian', 'Pathology', 'Pathology Report', 'Pediatric Hospitals', 'Performance', 'Phase', 'Phenotype', 'Positioning Attribute', 'Process', 'Prostate', 'Provider', 'Radiation therapy', 'Radiology Specialty', 'Registries', 'Reporting', 'Research', 'Site', 'Solid', 'Source', 'Speed', 'Supervision', 'Surveillance Program', 'Terminology', 'Text', 'Tumor Debulking', 'Ulcer', 'Universities', 'Validation', 'Visualization', 'Work', 'base', 'biomedical ontology', 'calcification', 'cancer diagnosis', 'cancer invasiveness', 'cancer type', 'clinical encounter', 'clinical phenotype', 'cohort', 'data management', 'data streams', 'data visualization', 'demographics', 'informatics tool', 'innovation', 'interoperability', 'malignant breast neoplasm', 'medical schools', 'melanoma', 'neoplasm registry', 'novel', 'open source', 'patient health information', 'phenotypic data', 'point of care', 'response', 'satisfaction', 'software development', 'success', 'symposium', 'tool', 'transmission process', 'treatment center', 'tumor']",NCI,BOSTON CHILDREN'S HOSPITAL,UG3,2020,410684,0.048132417228852586
"Natural Language Processing Platform for Cancer Surveillance PROJECT SUMMARY/ABSTRACT This UG3/UH3 proposal titled Natural Language Processing Platform for Cancer Surveillance is in response to Research Area 1 of PAR 16-349 (https://grants.nih.gov/grants/guide/pa-files/par-16-349.html) specifically addressing the development of natural language processing (NLP) tools to facilitate automatic/unsupervised/minimally supervised extraction of specific discrete cancer-related data from various types of unstructured electronic medical records (EMRs) related to the activities of cancer registries. It is submitted through a multi-PI mechanism  Prof. Guergana Savova from Boston Childrens Hospital/Harvard Medical School, Dr. Jeremy Warner from Vanderbilt University Medical Center, Prof. Harry Hochheiser from the University of Pittsburgh, and Prof. Eric Durbin from the Kentucky Cancer Registry/University of Kentucky. The current proposal builds on prior work funded by the NCI Informatics Tools for Cancer Research (ITCR) program (https://itcr.cancer.gov/ ). We envision building on our work to date to advance methods for information extraction of clinical phenotyping data needed to fuel a new cancer surveillance paradigm that would benefit hospital-based, state-based, and national cancer registries. In this new paradigm, surveillance programs would use the methods to enhance the speed, accuracy, and ease of cancer reporting. The proposed DeepPhe*CR platform could be deployed at local sites or centrally, and could eventually be integrated into existing or new visualization and abstraction tools as needed by the cancer surveillance community. Although there has been some previous work on automatic phenotype extraction from the various streams of data including the clinical narrative for specific types of cancer or individual variables for cancer surveillance, the proposed work will be a step towards a generalizable information extraction. This generalizability enables extensibility and scalability. Interoperability is reinforced through the modeling part of the proposed project which is grounded in most recent advances in biomedical ontologies, terminologies, community-adopted conventions and standards. Our planned partnership with three SEER cancer registries provides our decision-making processes with a solid foundation in large-scale cancer surveillance. PROJECT NARRATIVE This UG3/UH3 proposal titled Natural Language Processing Platform for Cancer Surveillance is in response to Research Area 1 of PAR 16-349 specifically addressing the development of natural language processing tools to facilitate automatic/unsupervised/minimally supervised extraction of specific discrete cancer-related data from various types of unstructured electronic medical records. We envision building on our work to date to advance methods for information extraction of clinical phenotyping data needed to fuel a new cancer surveillance paradigm that would benefit hospital-based, state-based, and national cancer registries.",Natural Language Processing Platform for Cancer Surveillance,9830835,UG3CA243120,"['Academic Medical Centers', 'Address', 'Adopted', 'Advanced Development', 'Agreement', 'Architecture', 'Area', 'Automation', 'Automobile Driving', 'Biological Markers', 'Boston', 'Breslow Thickness', 'Cancer Research Project', 'Cancer Surveillance Research Program', 'Characteristics', 'Clinical', 'Collaborations', 'Colorectal', 'Communities', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Contractor', 'Data', 'Data Element', 'Data Sources', 'Decision Making', 'Development', 'Diagnosis', 'Division of Cancer Control and Population Sciences', 'Documentation', 'Elements', 'Environment', 'Extensible Markup Language', 'Family', 'Feeds', 'Foundations', 'Funding', 'Gene Proteins', 'Genomics', 'Goals', 'Grant', 'Handedness', 'Histologic', 'Histology', 'Hospitals', 'Human', 'Imagery', 'Individual', 'Kentucky', 'Link', 'Location', 'Louisiana', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Maps', 'Massachusetts', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Ontology', 'Output', 'Ovarian', 'Pathology', 'Pathology Report', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Phenotype', 'Positioning Attribute', 'Process', 'Prostate', 'Provider', 'Radiation therapy', 'Radiology Specialty', 'Registries', 'Reporting', 'Research', 'Site', 'Solid', 'Source', 'Speed', 'Stream', 'Supervision', 'Surveillance Program', 'System', 'Terminology', 'Text', 'Tumor Debulking', 'Ulcer', 'Universities', 'Validation', 'Work', 'base', 'biomedical ontology', 'calcification', 'cancer diagnosis', 'cancer invasiveness', 'cancer type', 'clinical phenotype', 'cohort', 'data management', 'data visualization', 'demographics', 'feeding', 'informatics\xa0tool', 'innovation', 'interoperability', 'malignant breast neoplasm', 'medical schools', 'melanoma', 'neoplasm registry', 'novel', 'oncology', 'open source', 'phenotypic data', 'point of care', 'response', 'satisfaction', 'software development', 'success', 'symposium', 'tool', 'transmission process', 'treatment center', 'tumor']",NCI,BOSTON CHILDREN'S HOSPITAL,UG3,2019,461775,0.048132417228852586
"Using Electronic Health Records from a Large Clinical Data Research Network to Understand Cancer Burden and Cancer Risks Among Transgender and Gender Nonconforming (TGNC) Individuals ABSTRACT Transgender and gender nonconforming (TGNC) people face a disproportionate burden of adverse health outcomes. Although there is a growing body of literature on the unique health issues among TGNC populations, they remain severely underserved as existing data on TGNC health are scarce. Under-reporting is common due to issues related to social and economic marginalization, stigma, and discrimination, leading to challenges in obtaining population-based estimates since TGNC individuals are often unwilling to self-identify and reluctant to participate in traditional surveys. Further, past TGNC research has primarily focused on mental health, substance use and abuse, and sexual transmitted infections and diseases. There is limited data available on age-related chronic conditions such as cancer, the second leading cause of death in the United States. Nonetheless, cancer is one of the top research priorities among the TGNC population. With a rapidly growing aging TGNC population, there is an urgent need to characterize the cancer burden among these individuals and understand how cancer impact them differentially compared to non-TGNC individuals. On the other hand, rapid adoption of electronic health record (EHR) systems has made longitudinal clinical data available for research. EHRs contain not only important structured data, such as demographics, diagnoses, procedures, and medications, but also unstructured clinical narratives such as physicians notes. More than 80 percent of the clinical information is documented in clinical narratives, which contain more detailed patient information including gender identity and cancer risk factors. Motivated by these observations and built upon our previous studies on 1) the adequacy of TGNC gender identity terms, 2) clinical natural language processing methods for information extraction, and 3) EHR-based cohort studies, we propose to conduct a population-based cohort analysis to examine the cancer burden and risk factors among TGNC people using a unique data source from a large network of EHRsOneFlorida, one of the 13 PCORI-funded clinical data research networks (CDRNs) contributing to the PCORnet. Using both structured and unstructured OneFlorida data, we will first develop computable phenotypes to identify TGNC individuals and subsequently evaluate their cancer risk. Our research is significant because: 1) no population-based cohort studies on cancer risk have been conducted among the TGNC population. Our results will support the development of tailored, evidence- based cancer screening programs for TGNC people; 2) our research will create a cohort of TGNC people that can be not only tracked longitudinally in EHR but also recruited for future clinical studies; and 3) working with a PCORnet CDRN makes our analysis framework generalizable to the overall PCORNet. Overall, the proposed research will advance our knowledge in cancer among the aging TGNC population. PROJECT NARRATIVE Our project will fill an important gap in our knowledge of cancer burden and risk factors in transgender and gender nonconforming (TGNC) people, a sexual and gender minority (SGM) group. A computable phenotype that can accurately identify TGNC cohorts in large networks of electronic health records (EHRs) enables us to monitor TGNC health longitudinally, which is significant for aging-related diseases such as cancer. Built upon this work, our future work can focus on building informatics tools to support the long-term surveillance and health monitoring of SGMs using large-scale national networks of EHRs.",Using Electronic Health Records from a Large Clinical Data Research Network to Understand Cancer Burden and Cancer Risks Among Transgender and Gender Nonconforming (TGNC) Individuals,10056679,R21CA245858,"['Adoption', 'Age', 'Aging', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Behavioral', 'Cancer Burden', 'Caring', 'Cause of Death', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Analysis', 'Cohort Studies', 'Coin', 'County', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Economics', 'Electronic Health Record', 'Face', 'Florida', 'Funding', 'Future', 'Gender', 'Gender Identity', 'Gold', 'Health', 'Health behavior', 'Hormone use', 'Hospitals', 'Human Papilloma Virus-Related Malignant Neoplasm', 'Human Papillomavirus', 'Incidence', 'Individual', 'Information Retrieval', 'Knowledge', 'Literature', 'Logistic Models', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Mental Health', 'Methods', 'Minority Groups', 'Modeling', 'Monitor', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Procedures', 'Reporting', 'Research', 'Research Priority', 'Risk', 'Risk Behaviors', 'Risk Factors', 'Screening for cancer', 'Sex Behavior', 'Sexual and Gender Minorities', 'Sexually Transmitted Diseases', 'Source', 'Structure', 'Substance abuse problem', 'Surveys', 'System', 'Tobacco', 'Tobacco use', 'United States', 'Work', 'age related', 'aging population', 'base', 'cancer risk', 'cancer statistics', 'cancer type', 'clinical practice', 'cohort', 'comorbidity', 'computable phenotypes', 'data registry', 'deep learning', 'demographics', 'evidence base', 'gender nonconforming', 'health care service organization', 'health service use', 'high risk', 'informatics tool', 'malignant breast neoplasm', 'neoplasm registry', 'phenotyping algorithm', 'population based', 'programs', 'recruit', 'screening program', 'social', 'social exclusion', 'social stigma', 'stem', 'structured data', 'study population', 'transgender']",NCI,UNIVERSITY OF FLORIDA,R21,2020,392115,0.04451961745966461
"Deep clinical trajectory modeling to optimize accrual to cancer clinical trials PROJECT SUMMARY/ABSTRACT Electronic health records (EHRs) are now ubiquitous in routine cancer care delivery. The large volumes of data that EHRs contain could constitute an important resource for research and quality improvement, but to date, EHRs have not fully realized this potential. Important clinical endpoints, such as disease histology, stage, response, progression, and burden, are often recorded in the EHR only in unstructured free-text form. Even when structured data are available, they may be recorded only at one point in time, such as diagnosis, and may not be as relevant later in a patient's dynamic disease trajectory. These barriers prevent scalable analysis of EHR data for even relatively straightforward research tasks, such as identification of a cohort of patients potentially eligible for clinical trials. Identifying patients for trials is an important challenge in cancer research, since under 5% of adults with cancer have historically enrolled in therapeutic trials. Tools are in development to better match patients to trials, but no such tools are both publicly available and capable of incorporating time- specific patient phenotypes generated using unstructured EHR data. Recent rapid innovation in deep learning techniques could provide novel solutions to these challenges. In ongoing work, I have found that natural language processing based on a neural network architecture can reliably extract clinically relevant oncologic endpoints from free-text radiology reports. My goal is to develop an independent research program focused on leveraging such methods to put the EHR to use at scale for discovery and improving cancer care delivery. My specific aims are (1) to develop and validate a clinically relevant, dynamic, pre-trained cancer trajectory model by applying deep learning to integrated structured and unstructured EHR data; (2) to apply transfer learning to a pre-trained cancer trajectory model to match patients to clinical trials using EHR data and clinical trial protocols; and (3) to pilot the incorporation of cancer trajectory modeling into an institutional clinical trial matching tool. In the near term, this work will facilitate accrual to clinical trials at our institution. During the independent research portion of the proposal, it will constitute the basis for a general framework for conducting scalable cancer research using EHR data. PROJECT NARRATIVE Electronic health records (EHRs) are now ubiquitous in routine cancer care delivery, but their utility for research and quality improvement has been limited by a dearth of methods for integrating the unstructured data in which most key cancer outcomes are encoded within EHRs. I propose to apply recent innovations in deep learning to integrate structured and unstructured data to create a dynamic pre-trained model of cancer patients' treatment trajectories, and to apply this model to identify patients who are appropriate candidates for clinical trials at times when they are eligible. I will then evaluate the effect of trajectory modeling on clinical trial accrual as I prepare for an independent research career focused on clinical cancer data science.",Deep clinical trajectory modeling to optimize accrual to cancer clinical trials,9880481,K99CA245899,"['Academia', 'Adult', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Computers', 'Dana-Farber Cancer Institute', 'Data', 'Data Science', 'Data Scientist', 'Development', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Goals', 'Government', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Histology', 'Institution', 'Intervention', 'Label', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Oncologist', 'Oncology', 'Outcome', 'Pathology Report', 'Patients', 'Phenotype', 'Primary Neoplasm', 'Psychological Transfer', 'Radiology Specialty', 'Randomized', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Source', 'Structure', 'Systemic Therapy', 'Techniques', 'Technology', 'Text', 'Therapeutic Trials', 'Time', 'Training', 'Work', 'anticancer research', 'base', 'burden of illness', 'cancer care', 'cancer clinical trial', 'care delivery', 'career', 'clinical candidate', 'clinical practice', 'clinical trial enrollment', 'clinically relevant', 'cohort', 'data registry', 'deep learning', 'design', 'electronic data', 'genomic data', 'improved', 'innovation', 'learning strategy', 'multiple data types', 'neoplasm registry', 'neural network architecture', 'novel', 'palliative', 'patient population', 'precision medicine clinical trials', 'prevent', 'programs', 'response', 'skills', 'structural genomics', 'structured data', 'survival prediction', 'tool', 'tumor progression', 'unstructured data']",NCI,DANA-FARBER CANCER INST,K99,2020,170176,0.050899143795468164
"Improving Population Representativeness of the Inference from Non-Probability Sample Analysis SUMMARY The critical role of population-representativeness for estimating disease incidence and prevalence has been widely accepted in epidemiologic studies. Improving population representativeness of nonprobability samples, such as samples of volunteers in epidemiologic studies or electronic health records, however, has received little attention by biostatisticians or epidemiologists. In this project, we propose two innovative pseudoweight construction methods: 1) two-step matching, and 2) calibration, under an adapted exchangeability assumption, for unbiased estimation of disease incidence and prevalence in the target population. The proposed methods, combined with machine learning methods for propensity score estimation, will achieve significant bias reduction, especially when selection into nonprobability samples is driven by complex relationships between the covariates. We will quantify the bias reduced by the proposed pseudoweights, numerically and empirically, on the estimation of disease incidence and prevalence in the target population. Monte Carlo simulation studies are designed under varying degrees of departure from the adapted exchangeability assumption to evaluate the bias of the proposed estimates. The robustness of the proposed estimators against varying sample sizes, number of clusters in survey, and complexities of the true propensity score modeling will be investigated in scenarios that differ by levels of non-linearity, non-additivity and correlations between covariates in the true propensity model. Using data from National Institutes of Health and the American Association of Retired Persons (NIH-AARP, a nonprobability cohort sample) data and the US National Health Interview Survey (NHIS, a probability survey sample), the proposed methods will be applied to estimate the prevalence of self-reported diseases and all-cause or all-cancer mortality rates for people aged 50-71 in the US. To test our methods, we will purposely select outcome variables that are available in both the NIH-AARP and the NHIS. Thus, the amount of bias in NIH-AARP estimates corrected by the proposed pseudoweights can be quantified in practice, assuming the weighted NHIS estimate is true. The proposed methods, although motivated by the volunteer-based epidemiological studies, have wide applications outside of epidemiology, such as electronic health records or web surveys. The results from this project can be used by epidemiologists and health policy makers to improve the understanding of the health-related characteristics in the general population. Computer software that implements the proposed methods will be made available for public use. PROJECT NARRATIVE The project proposes innovative pseudoweights construction methods for nonprobability samples, such as samples of volunteers in epidemiologic studies or electronic health records, to improve their population representativeness. The project will quantify the amount of bias reduced by the proposed pseudoweights, numerically and empirically, on the estimation of population parameters such as disease incidence and prevalence. The result can be used by epidemiologists and health policy makers to improve the understanding of the health related characteristics in the general population.",Improving Population Representativeness of the Inference from Non-Probability Sample Analysis,10046869,R03CA252782,"['American', 'Attention', 'Calibration', 'Characteristics', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Equilibrium', 'General Population', 'Health', 'Health Policy', 'Incidence', 'Internet', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monte Carlo Method', 'National Health Interview Survey', 'Outcome', 'Patient Self-Report', 'Policy Maker', 'Population', 'Prevalence', 'Probability', 'Probability Samples', 'Research', 'Role', 'Sample Size', 'Sampling', 'Source', 'Surveys', 'Target Populations', 'Testing', 'Trees', 'United States National Institutes of Health', 'Weight', 'aged', 'base', 'cohort', 'complex data ', 'design', 'epidemiology study', 'flexibility', 'improved', 'innovation', 'machine learning method', 'mortality', 'random forest', 'retiree', 'software development', 'volunteer']",NCI,"UNIV OF MARYLAND, COLLEGE PARK",R03,2020,154500,0.036748888988138134
IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS. Surveillance Epidemiology and End Results (SEER) Electronic Data Capture Software Support and Installations. n/a,IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS.,9162089,61201500033I,"['Artificial Intelligence', 'Award', 'Computer software', 'Contracts', 'Data', 'Diagnostic Imaging', 'Electronics', 'Hour', 'Laboratories', 'Maintenance', 'Malignant Neoplasms', 'Medical Surveillance', 'Medicine', 'Pathology', 'Reporting', 'Update', 'electronic data']",NCI,"ARTIFICIAL INTELLIGENCE IN MEDICINE, INC",N03,2015,1135265,0.028728648937496295
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC) This study seeks to leverage electronic pathology (ePath) reports through NLP and machine learning methods to automate the annotation of NSCLC lung cases with results from EGFR and ALK gene mutation testing.  Objectives:  1)	Develop and implement machine-learned predictive NLP models to automatically process ePath reports to ascertain the use of and reported results of EGFR and ALK testing in stage IV non-squamous NSCLC cases.   2)	Conduct a multiphase validation study of the NLP algorithms initially involving cases included in the Kentucky SEER registry, and posteriorly validating the algorithms for cases in the Seattle_Puget Sound SEER registry. 3)	Develop and evaluate an open source, distributable software implementation of the NLP algorithms, an accompanying application programming interface (API), and documentation that can be integrated into SEER*DMS and other registry software applications. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC),9161889,61201300013I,"['ALK gene', 'Algorithms', 'Automated Annotation', 'Computer software', 'Documentation', 'EGFR gene', 'Electronics', 'Epidermal Growth Factor Receptor', 'Gene Mutation', 'Kentucky', 'Lung', 'Machine Learning', 'Methods', 'Modeling', 'Molecular Profiling', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Process', 'Registries', 'Reporting', 'Staging', 'Testing', 'c-erbB-1 Proto-Oncogenes', 'open source', 'programs', 'sound', 'validation studies']",NCI,UNIVERSITY OF KENTUCKY,N01,2015,87813,-0.04740201931122392
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC). The overarching goal of this research proposal is to develop and validate Natural Language Processing (NLP) algorithms for ascertainment of use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC cases.  Successful achievement of this goal will occur through the accomplishment of the study objectives outlined below.  Objectives: 1)	 Develop Natural Language Processing (NLP) algorithms to ascertain use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC registry cases diagnosed between 09/01/2011 and 12/31/2013. 2)	Conduct a multiphase validation study of NLP algorithms for ascertainment of EGFR and ALK testing initially involving cases included in the Seattle Puget-Sound SEER registry, and posteriorly validating the NLP algorithms in the Kentucky SEER registry. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC).,9161888,61201300012I,"['Achievement', 'Algorithms', 'Cells', 'Diagnosis', 'Electronics', 'Epidermal Growth Factor Receptor', 'Goals', 'Kentucky', 'Lung', 'Molecular Profiling', 'Natural Language Processing', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Registries', 'Research Proposals', 'Staging', 'Techniques', 'Testing', 'neoplasm registry', 'sound', 'validation studies']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,N01,2015,156435,0.04086624410486176
"IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP n/a","IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP",9581371,61201400011I,"['Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N01,2017,9923,0.08190472822332977
"IGF::CL::IGF  MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015. MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015 n/a","IGF::CL::IGF  MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015.",9162846,61201400011I,"['Educational workshop', 'Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N03,2015,16100,0.054090799960107336
NIST Assistance with NTP SR Automation NIEHS seeks advice from NIST in the areas of human language technology and natural language processing component evaluations that support the measurement of systems that automatically extract toxicology information from publications to support the complex human task of systematic review of literature. NIST is positioned to assist NIEHS building upon existing test and evaluation infrastructure through its Text Analysis Conference (TAC) program. NIST is coordinating the 2019 Systematic Review Information Extraction evaluation (SRIE 2019) task for NIEHS as part of the Retrieval Groups Text Analysis Conference (TAC) program. This coordination includes advising NIEHS on developing annotation guidelines; advising NIEHS on dataset construction and distribution; writing guidelines for the evaluation task; developing scoring methods and supporting software; including the evaluation task as part of the TAC program and call for participation; accepting participant submissions in the evaluation; evaluating those submissions; and reporting results of the evaluation. NIST and NIH will design an evaluation task in this domain. n/a,NIST Assistance with NTP SR Automation,9794240,ES18001002,"['Advertisements', 'Area', 'Automation', 'Complex', 'Computer software', 'Data Set', 'Development', 'Evaluation', 'Guidelines', 'Human', 'Language', 'Measurement', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Participant', 'Positioning Attribute', 'Preparation', 'Publications', 'Reporting', 'Research', 'Research Infrastructure', 'Retrieval', 'Review Literature', 'Scoring Method', 'System', 'Technology', 'Testing', 'Text', 'Toxicology', 'United States National Institutes of Health', 'Writing', 'biomedical informatics', 'design', 'programs', 'symposium', 'systematic review']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2018,200000,-0.008933219593504384
"AUTOMATED ANALYSIS OF BIOMEDICAL TEXT The purpose of this contract is to develop methods to analyze and represent information in biomedical texts.  This will require sophisticated natural language processing capabilities, involving lexical, syntactic, semantic and pragmatic analysis of these texts. The Natural Language Systems group of the Lister Hill Center for Biomedical Communications is pursuing this work as an intramural research project and seeks to collaborate with outside organizations presently conducting closely related research.  The overall objective of this contract is to establish methods for testing the hypothesis that access to a bibliographic database, such as the National Library of Medicine's MEDLINE database, can be improved by automated analysis of the free test in the system.  The project work will involve modification and extension of aspects of a natural language parser.  The MEDLINE database has citation records for several million articles in biomedicine, representing several thousand journals. Each citation record includes the title, an author prepared abstract when available, author and journal names, and a set of Medical Subject Headings under which the article has been indexed by expert indexers.  The free text in the system is found in the title and abstract fields of the citation records.  Titles are normally complex noun phrases, while abstracts are composed of well-formed, although highly specialized, English sentences.  The purpose of the work under this contract is to develop methods for parsing this text.  The parsing procedure should result in a set of well-specified logical forms, representing the meaning of the phrases and sentences in the citation record.  n/a",AUTOMATED ANALYSIS OF BIOMEDICAL TEXT,2320317,01LM083521,"['abstracting', ' information retrieval', ' information systems', ' language', ' literature survey', ' semantics']",NLM,UNISYS,N01,1988,155723,0.03989505236649854
